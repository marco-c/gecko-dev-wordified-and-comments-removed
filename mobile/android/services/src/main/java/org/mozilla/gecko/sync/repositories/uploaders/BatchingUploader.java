package
org
.
mozilla
.
gecko
.
sync
.
repositories
.
uploaders
;
import
android
.
net
.
Uri
;
import
android
.
support
.
annotation
.
VisibleForTesting
;
import
org
.
mozilla
.
gecko
.
background
.
common
.
log
.
Logger
;
import
org
.
mozilla
.
gecko
.
sync
.
InfoConfiguration
;
import
org
.
mozilla
.
gecko
.
sync
.
Server11RecordPostFailedException
;
import
org
.
mozilla
.
gecko
.
sync
.
net
.
SyncResponse
;
import
org
.
mozilla
.
gecko
.
sync
.
net
.
SyncStorageResponse
;
import
org
.
mozilla
.
gecko
.
sync
.
repositories
.
Server11RepositorySession
;
import
org
.
mozilla
.
gecko
.
sync
.
repositories
.
delegates
.
RepositorySessionStoreDelegate
;
import
org
.
mozilla
.
gecko
.
sync
.
repositories
.
domain
.
Record
;
import
java
.
util
.
ArrayList
;
import
java
.
util
.
concurrent
.
Executor
;
import
java
.
util
.
concurrent
.
atomic
.
AtomicLong
;
public
class
BatchingUploader
{
private
static
final
String
LOG_TAG
=
"
BatchingUploader
"
;
private
final
Uri
collectionUri
;
private
volatile
boolean
recordUploadFailed
=
false
;
private
final
BatchMeta
batchMeta
;
private
final
Payload
payload
;
private
volatile
Boolean
inBatchingMode
;
private
final
Object
payloadLock
=
new
Object
(
)
;
protected
Executor
workQueue
;
protected
final
RepositorySessionStoreDelegate
sessionStoreDelegate
;
protected
final
Server11RepositorySession
repositorySession
;
protected
AtomicLong
uploadTimestamp
=
new
AtomicLong
(
0
)
;
protected
static
final
int
PER_RECORD_OVERHEAD_BYTE_COUNT
=
RecordUploadRunnable
.
RECORD_SEPARATOR
.
length
;
protected
static
final
int
PER_PAYLOAD_OVERHEAD_BYTE_COUNT
=
RecordUploadRunnable
.
RECORDS_END
.
length
;
static
{
if
(
RecordUploadRunnable
.
RECORD_SEPARATOR
.
length
!
=
RecordUploadRunnable
.
RECORDS_START
.
length
)
{
throw
new
IllegalStateException
(
"
Separator
and
start
tokens
must
be
of
the
same
length
"
)
;
}
}
public
BatchingUploader
(
final
Server11RepositorySession
repositorySession
final
Executor
workQueue
final
RepositorySessionStoreDelegate
sessionStoreDelegate
)
{
this
.
repositorySession
=
repositorySession
;
this
.
workQueue
=
workQueue
;
this
.
sessionStoreDelegate
=
sessionStoreDelegate
;
this
.
collectionUri
=
Uri
.
parse
(
repositorySession
.
getServerRepository
(
)
.
collectionURI
(
)
.
toString
(
)
)
;
InfoConfiguration
config
=
repositorySession
.
getServerRepository
(
)
.
getInfoConfiguration
(
)
;
this
.
batchMeta
=
new
BatchMeta
(
payloadLock
config
.
maxTotalBytes
config
.
maxTotalRecords
repositorySession
.
getServerRepository
(
)
.
getCollectionLastModified
(
)
)
;
this
.
payload
=
new
Payload
(
payloadLock
config
.
maxPostBytes
config
.
maxPostRecords
)
;
}
public
void
process
(
final
Record
record
)
{
final
String
guid
=
record
.
guid
;
final
byte
[
]
recordBytes
=
record
.
toJSONBytes
(
)
;
final
long
recordDeltaByteCount
=
recordBytes
.
length
+
PER_RECORD_OVERHEAD_BYTE_COUNT
;
Logger
.
debug
(
LOG_TAG
"
Processing
a
record
with
guid
:
"
+
guid
)
;
if
(
(
recordDeltaByteCount
+
PER_PAYLOAD_OVERHEAD_BYTE_COUNT
)
>
payload
.
maxBytes
)
{
sessionStoreDelegate
.
onRecordStoreFailed
(
new
RecordTooLargeToUpload
(
)
guid
)
;
return
;
}
synchronized
(
payloadLock
)
{
final
boolean
canFitRecordIntoBatch
=
batchMeta
.
canFit
(
recordDeltaByteCount
)
;
final
boolean
canFitRecordIntoPayload
=
payload
.
canFit
(
recordDeltaByteCount
)
;
if
(
canFitRecordIntoBatch
&
&
canFitRecordIntoPayload
)
{
Logger
.
debug
(
LOG_TAG
"
Record
fits
into
the
current
batch
and
payload
"
)
;
addAndFlushIfNecessary
(
recordDeltaByteCount
recordBytes
guid
)
;
}
else
if
(
canFitRecordIntoBatch
)
{
Logger
.
debug
(
LOG_TAG
"
Current
payload
won
'
t
fit
incoming
record
uploading
payload
.
"
)
;
flush
(
false
false
)
;
Logger
.
debug
(
LOG_TAG
"
Recording
the
incoming
record
into
a
new
payload
"
)
;
addAndFlushIfNecessary
(
recordDeltaByteCount
recordBytes
guid
)
;
}
else
{
Logger
.
debug
(
LOG_TAG
"
Current
batch
won
'
t
fit
incoming
record
committing
batch
.
"
)
;
flush
(
true
false
)
;
Logger
.
debug
(
LOG_TAG
"
Recording
the
incoming
record
into
a
new
batch
"
)
;
batchMeta
.
reset
(
)
;
addAndFlushIfNecessary
(
recordDeltaByteCount
recordBytes
guid
)
;
}
}
}
private
void
addAndFlushIfNecessary
(
long
byteCount
byte
[
]
recordBytes
String
guid
)
{
boolean
isPayloadFull
=
payload
.
addAndEstimateIfFull
(
byteCount
recordBytes
guid
)
;
boolean
isBatchFull
=
batchMeta
.
addAndEstimateIfFull
(
byteCount
)
;
if
(
isBatchFull
)
{
flush
(
true
false
)
;
batchMeta
.
reset
(
)
;
}
else
if
(
isPayloadFull
)
{
flush
(
false
false
)
;
}
}
public
void
noMoreRecordsToUpload
(
)
{
Logger
.
debug
(
LOG_TAG
"
Received
'
no
more
records
to
upload
'
signal
.
"
)
;
workQueue
.
execute
(
new
Runnable
(
)
{
Override
public
void
run
(
)
{
commitIfNecessaryAfterLastPayload
(
)
;
}
}
)
;
}
VisibleForTesting
protected
void
commitIfNecessaryAfterLastPayload
(
)
{
synchronized
(
payload
)
{
if
(
!
payload
.
isEmpty
(
)
)
{
flush
(
true
true
)
;
}
else
if
(
batchMeta
.
needToCommit
(
)
&
&
Boolean
.
TRUE
.
equals
(
inBatchingMode
)
)
{
flush
(
true
true
)
;
}
else
{
finished
(
uploadTimestamp
)
;
}
}
}
public
void
payloadSucceeded
(
final
SyncStorageResponse
response
final
boolean
isCommit
final
boolean
isLastPayload
)
{
if
(
inBatchingMode
=
=
null
)
{
throw
new
IllegalStateException
(
"
Can
'
t
process
payload
success
until
we
know
if
we
'
re
in
a
batching
mode
"
)
;
}
if
(
!
inBatchingMode
|
|
isCommit
)
{
for
(
String
guid
:
batchMeta
.
getSuccessRecordGuids
(
)
)
{
sessionStoreDelegate
.
onRecordStoreSucceeded
(
guid
)
;
}
}
if
(
isLastPayload
)
{
finished
(
response
.
normalizedTimestampForHeader
(
SyncResponse
.
X_LAST_MODIFIED
)
)
;
}
}
public
void
lastPayloadFailed
(
)
{
finished
(
uploadTimestamp
)
;
}
private
void
finished
(
long
lastModifiedTimestamp
)
{
bumpTimestampTo
(
uploadTimestamp
lastModifiedTimestamp
)
;
finished
(
uploadTimestamp
)
;
}
private
void
finished
(
AtomicLong
lastModifiedTimestamp
)
{
repositorySession
.
storeDone
(
lastModifiedTimestamp
.
get
(
)
)
;
}
public
BatchMeta
getCurrentBatch
(
)
{
return
batchMeta
;
}
public
void
setInBatchingMode
(
boolean
inBatchingMode
)
{
this
.
inBatchingMode
=
inBatchingMode
;
this
.
batchMeta
.
setIsUnlimited
(
!
inBatchingMode
)
;
}
public
Boolean
getInBatchingMode
(
)
{
return
inBatchingMode
;
}
public
void
setLastModified
(
final
Long
lastModified
final
boolean
isCommit
)
throws
BatchingUploaderException
{
if
(
inBatchingMode
=
=
null
)
{
throw
new
IllegalStateException
(
"
Can
'
t
process
Last
-
Modified
before
we
know
we
'
re
in
a
batching
mode
.
"
)
;
}
batchMeta
.
setLastModified
(
lastModified
isCommit
|
|
!
inBatchingMode
)
;
}
public
void
recordSucceeded
(
final
String
recordGuid
)
{
Logger
.
debug
(
LOG_TAG
"
Record
store
succeeded
:
"
+
recordGuid
)
;
batchMeta
.
recordSucceeded
(
recordGuid
)
;
}
public
void
recordFailed
(
final
String
recordGuid
)
{
recordFailed
(
new
Server11RecordPostFailedException
(
)
recordGuid
)
;
}
public
void
recordFailed
(
final
Exception
e
final
String
recordGuid
)
{
Logger
.
debug
(
LOG_TAG
"
Record
store
failed
for
guid
"
+
recordGuid
+
"
with
exception
:
"
+
e
.
toString
(
)
)
;
recordUploadFailed
=
true
;
sessionStoreDelegate
.
onRecordStoreFailed
(
e
recordGuid
)
;
}
public
Server11RepositorySession
getRepositorySession
(
)
{
return
repositorySession
;
}
private
static
void
bumpTimestampTo
(
final
AtomicLong
current
long
newValue
)
{
while
(
true
)
{
long
existing
=
current
.
get
(
)
;
if
(
existing
>
newValue
)
{
return
;
}
if
(
current
.
compareAndSet
(
existing
newValue
)
)
{
return
;
}
}
}
private
void
flush
(
final
boolean
isCommit
final
boolean
isLastPayload
)
{
final
ArrayList
<
byte
[
]
>
outgoing
;
final
ArrayList
<
String
>
outgoingGuids
;
final
long
byteCount
;
synchronized
(
payloadLock
)
{
outgoing
=
payload
.
getRecordsBuffer
(
)
;
outgoingGuids
=
payload
.
getRecordGuidsBuffer
(
)
;
byteCount
=
payload
.
getByteCount
(
)
;
}
workQueue
.
execute
(
new
RecordUploadRunnable
(
new
BatchingAtomicUploaderMayUploadProvider
(
)
collectionUri
batchMeta
new
PayloadUploadDelegate
(
this
outgoingGuids
isCommit
isLastPayload
)
outgoing
byteCount
isCommit
)
)
;
payload
.
reset
(
)
;
}
private
class
BatchingAtomicUploaderMayUploadProvider
implements
MayUploadProvider
{
public
boolean
mayUpload
(
)
{
return
!
recordUploadFailed
;
}
}
public
static
class
BatchingUploaderException
extends
Exception
{
private
static
final
long
serialVersionUID
=
1L
;
}
public
static
class
RecordTooLargeToUpload
extends
BatchingUploaderException
{
private
static
final
long
serialVersionUID
=
1L
;
}
public
static
class
LastModifiedDidNotChange
extends
BatchingUploaderException
{
private
static
final
long
serialVersionUID
=
1L
;
}
public
static
class
LastModifiedChangedUnexpectedly
extends
BatchingUploaderException
{
private
static
final
long
serialVersionUID
=
1L
;
}
public
static
class
TokenModifiedException
extends
BatchingUploaderException
{
private
static
final
long
serialVersionUID
=
1L
;
}
;
}
