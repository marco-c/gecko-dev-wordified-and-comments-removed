"
"
"
Robustly
perform
a
checkout
.
This
extension
provides
the
hg
robustcheckout
command
for
ensuring
a
working
directory
is
updated
to
the
specified
revision
from
a
source
repo
using
best
practices
to
ensure
optimal
clone
times
and
storage
efficiency
.
"
"
"
from
__future__
import
absolute_import
import
contextlib
import
errno
import
functools
import
os
import
random
import
re
import
socket
import
time
from
mercurial
.
i18n
import
_
from
mercurial
.
node
import
hex
from
mercurial
import
(
    
commands
    
error
    
exchange
    
extensions
    
cmdutil
    
hg
    
pycompat
    
scmutil
    
util
)
testedwith
=
'
3
.
8
3
.
9
4
.
0
4
.
1
'
minimumhgversion
=
'
3
.
8
'
cmdtable
=
{
}
command
=
cmdutil
.
command
(
cmdtable
)
if
os
.
name
=
=
'
nt
'
:
    
import
ctypes
    
kernel32
=
ctypes
.
windll
.
kernel32
    
DeleteFile
=
kernel32
.
DeleteFileW
    
DeleteFile
.
argtypes
=
[
ctypes
.
c_wchar_p
]
    
DeleteFile
.
restype
=
ctypes
.
c_bool
    
def
unlinklong
(
fn
)
:
        
normalized_path
=
'
\
\
\
\
?
\
\
'
+
os
.
path
.
normpath
(
fn
)
        
if
not
DeleteFile
(
normalized_path
)
:
            
raise
OSError
(
errno
.
EPERM
"
couldn
'
t
remove
long
path
"
fn
)
else
:
    
def
unlinklong
(
fn
)
:
        
os
.
unlink
(
fn
)
def
unlinkwrapper
(
unlinkorig
fn
ui
)
:
    
'
'
'
Calls
unlink_long
if
original
unlink
function
fails
.
'
'
'
    
try
:
        
ui
.
debug
(
'
calling
unlink_orig
%
s
\
n
'
%
fn
)
        
return
unlinkorig
(
fn
)
    
except
WindowsError
as
e
:
        
if
e
.
winerror
!
=
3
:
            
raise
        
ui
.
debug
(
'
caught
WindowsError
ERROR_PATH_NOT_FOUND
;
'
                 
'
calling
unlink_long
%
s
\
n
'
%
fn
)
        
return
unlinklong
(
fn
)
contextlib
.
contextmanager
def
wrapunlink
(
ui
)
:
    
'
'
'
Context
manager
that
temporarily
monkeypatches
unlink
functions
.
'
'
'
    
purgemod
=
extensions
.
find
(
'
purge
'
)
    
to_wrap
=
[
(
purgemod
.
util
'
unlink
'
)
]
    
wrapped
=
functools
.
partial
(
unlinkwrapper
ui
=
ui
)
    
originals
=
{
}
    
for
mod
func
in
to_wrap
:
        
ui
.
debug
(
'
wrapping
%
s
%
s
\
n
'
%
(
mod
func
)
)
        
originals
[
mod
func
]
=
extensions
.
wrapfunction
(
mod
func
wrapped
)
    
try
:
        
yield
    
finally
:
        
for
mod
func
in
to_wrap
:
            
ui
.
debug
(
'
restoring
%
s
%
s
\
n
'
%
(
mod
func
)
)
            
setattr
(
mod
func
originals
[
mod
func
]
)
def
purgewrapper
(
orig
ui
*
args
*
*
kwargs
)
:
    
'
'
'
Runs
original
purge
(
)
command
with
unlink
monkeypatched
.
'
'
'
    
with
wrapunlink
(
ui
)
:
        
return
orig
(
ui
*
args
*
*
kwargs
)
command
(
'
robustcheckout
'
[
    
(
'
'
'
upstream
'
'
'
'
URL
of
upstream
repo
to
clone
from
'
)
    
(
'
r
'
'
revision
'
'
'
'
Revision
to
check
out
'
)
    
(
'
b
'
'
branch
'
'
'
'
Branch
to
check
out
'
)
    
(
'
'
'
purge
'
False
'
Whether
to
purge
the
working
directory
'
)
    
(
'
'
'
sharebase
'
'
'
'
Directory
where
shared
repos
should
be
placed
'
)
    
(
'
'
'
networkattempts
'
3
'
Maximum
number
of
attempts
for
network
'
                               
'
operations
'
)
    
]
    
'
[
OPTION
]
.
.
.
URL
DEST
'
    
norepo
=
True
)
def
robustcheckout
(
ui
url
dest
upstream
=
None
revision
=
None
branch
=
None
                   
purge
=
False
sharebase
=
None
networkattempts
=
None
)
:
    
"
"
"
Ensure
a
working
copy
has
the
specified
revision
checked
out
.
"
"
"
    
if
not
revision
and
not
branch
:
        
raise
error
.
Abort
(
'
must
specify
one
of
-
-
revision
or
-
-
branch
'
)
    
if
revision
and
branch
:
        
raise
error
.
Abort
(
'
cannot
specify
both
-
-
revision
and
-
-
branch
'
)
    
if
revision
:
        
if
len
(
revision
)
<
12
or
len
(
revision
)
>
40
or
not
re
.
match
(
'
^
[
a
-
f0
-
9
]
+
'
revision
)
:
            
raise
error
.
Abort
(
'
-
-
revision
must
be
a
SHA
-
1
fragment
12
-
40
'
                              
'
characters
long
'
)
    
sharebase
=
sharebase
or
ui
.
config
(
'
share
'
'
pool
'
)
    
if
not
sharebase
:
        
raise
error
.
Abort
(
'
share
base
directory
not
defined
;
refusing
to
operate
'
                          
hint
=
'
define
share
.
pool
config
option
or
pass
-
-
sharebase
'
)
    
ui
.
setconfig
(
'
worker
'
'
backgroundclose
'
False
)
    
ui
.
setconfig
(
'
progress
'
'
delay
'
1
.
0
)
    
ui
.
setconfig
(
'
progress
'
'
refresh
'
1
.
0
)
    
ui
.
setconfig
(
'
progress
'
'
assume
-
tty
'
True
)
    
sharebase
=
os
.
path
.
realpath
(
sharebase
)
    
return
_docheckout
(
ui
url
dest
upstream
revision
branch
purge
                       
sharebase
networkattempts
)
def
_docheckout
(
ui
url
dest
upstream
revision
branch
purge
sharebase
                
networkattemptlimit
networkattempts
=
None
)
:
    
if
not
networkattempts
:
        
networkattempts
=
[
1
]
    
def
callself
(
)
:
        
return
_docheckout
(
ui
url
dest
upstream
revision
branch
purge
                           
sharebase
networkattemptlimit
networkattempts
)
    
ui
.
write
(
'
ensuring
%
s
%
s
is
available
at
%
s
\
n
'
%
(
url
revision
or
branch
                                                      
dest
)
)
    
destvfs
=
scmutil
.
vfs
(
dest
audit
=
False
realpath
=
True
)
    
if
destvfs
.
exists
(
)
and
not
destvfs
.
exists
(
'
.
hg
'
)
:
        
raise
error
.
Abort
(
'
destination
exists
but
no
.
hg
directory
'
)
    
if
destvfs
.
exists
(
'
.
hg
'
)
and
not
destvfs
.
exists
(
'
.
hg
/
sharedpath
'
)
:
        
ui
.
warn
(
'
(
destination
is
not
shared
;
deleting
)
\
n
'
)
        
destvfs
.
rmtree
(
forcibly
=
True
)
    
if
destvfs
.
exists
(
'
.
hg
/
sharedpath
'
)
:
        
storepath
=
destvfs
.
read
(
'
.
hg
/
sharedpath
'
)
.
strip
(
)
        
ui
.
write
(
'
(
existing
repository
shared
store
:
%
s
)
\
n
'
%
storepath
)
        
if
not
os
.
path
.
exists
(
storepath
)
:
            
ui
.
warn
(
'
(
shared
store
does
not
exist
;
deleting
)
\
n
'
)
            
destvfs
.
rmtree
(
forcibly
=
True
)
        
elif
not
re
.
search
(
'
[
a
-
f0
-
9
]
{
40
}
/
\
.
hg
'
storepath
.
replace
(
'
\
\
'
'
/
'
)
)
:
            
ui
.
warn
(
'
(
shared
store
does
not
belong
to
pooled
storage
;
'
                    
'
deleting
to
improve
efficiency
)
\
n
'
)
            
destvfs
.
rmtree
(
forcibly
=
True
)
    
def
deletesharedstore
(
)
:
        
storepath
=
destvfs
.
read
(
'
.
hg
/
sharedpath
'
)
.
strip
(
)
        
if
storepath
.
endswith
(
'
.
hg
'
)
:
            
storepath
=
os
.
path
.
dirname
(
storepath
)
        
storevfs
=
scmutil
.
vfs
(
storepath
audit
=
False
)
        
storevfs
.
rmtree
(
forcibly
=
True
)
    
def
handlerepoerror
(
e
)
:
        
if
e
.
message
=
=
_
(
'
abandoned
transaction
found
'
)
:
            
ui
.
warn
(
'
(
abandoned
transaction
found
;
trying
to
recover
)
\
n
'
)
            
repo
=
hg
.
repository
(
ui
dest
)
            
if
not
repo
.
recover
(
)
:
                
ui
.
warn
(
'
(
could
not
recover
repo
state
;
'
                        
'
deleting
shared
store
)
\
n
'
)
                
deletesharedstore
(
)
            
ui
.
warn
(
'
(
attempting
checkout
from
beginning
)
\
n
'
)
            
return
callself
(
)
        
raise
    
def
handlenetworkfailure
(
)
:
        
if
networkattempts
[
0
]
>
=
networkattemptlimit
:
            
raise
error
.
Abort
(
'
reached
maximum
number
of
network
attempts
;
'
                              
'
giving
up
\
n
'
)
        
ui
.
warn
(
'
(
retrying
after
network
failure
on
attempt
%
d
of
%
d
)
\
n
'
%
                
(
networkattempts
[
0
]
networkattemptlimit
)
)
        
backoff
=
(
2
*
*
networkattempts
[
0
]
-
1
)
*
1
.
5
        
jittermin
=
ui
.
configint
(
'
robustcheckout
'
'
retryjittermin
'
1000
)
        
jittermax
=
ui
.
configint
(
'
robustcheckout
'
'
retryjittermax
'
5000
)
        
backoff
+
=
float
(
random
.
randint
(
jittermin
jittermax
)
)
/
1000
.
0
        
ui
.
warn
(
'
(
waiting
%
.
2fs
before
retry
)
\
n
'
%
backoff
)
        
time
.
sleep
(
backoff
)
        
networkattempts
[
0
]
+
=
1
    
def
handlepullerror
(
e
)
:
        
"
"
"
Handle
an
exception
raised
during
a
pull
.
        
Returns
True
if
caller
should
call
callself
(
)
to
retry
.
        
"
"
"
        
if
isinstance
(
e
error
.
Abort
)
:
            
if
e
.
args
[
0
]
=
=
_
(
'
repository
is
unrelated
'
)
:
                
ui
.
warn
(
'
(
repository
is
unrelated
;
deleting
)
\
n
'
)
                
destvfs
.
rmtree
(
forcibly
=
True
)
                
return
True
            
elif
e
.
args
[
0
]
.
startswith
(
_
(
'
stream
ended
unexpectedly
'
)
)
:
                
ui
.
warn
(
'
%
s
\
n
'
%
e
.
args
[
0
]
)
                
handlenetworkfailure
(
)
                
return
True
        
elif
isinstance
(
e
pycompat
.
urlerr
.
urlerror
)
:
            
if
isinstance
(
e
.
reason
socket
.
error
)
:
                
ui
.
warn
(
'
socket
error
:
%
s
\
n
'
%
e
.
reason
)
                
handlenetworkfailure
(
)
                
return
True
        
return
False
    
created
=
False
    
if
not
destvfs
.
exists
(
)
:
        
if
util
.
safehasattr
(
util
'
ensuredirs
'
)
:
            
makedirs
=
util
.
ensuredirs
        
else
:
            
makedirs
=
util
.
makedirs
        
makedirs
(
os
.
path
.
dirname
(
destvfs
.
base
)
notindexed
=
True
)
        
makedirs
(
sharebase
notindexed
=
True
)
        
if
upstream
:
            
ui
.
write
(
'
(
cloning
from
upstream
repo
%
s
)
\
n
'
%
upstream
)
        
cloneurl
=
upstream
or
url
        
try
:
            
res
=
hg
.
clone
(
ui
{
}
cloneurl
dest
=
dest
update
=
False
                           
shareopts
=
{
'
pool
'
:
sharebase
'
mode
'
:
'
identity
'
}
)
        
except
(
error
.
Abort
pycompat
.
urlerr
.
urlerror
)
as
e
:
            
if
handlepullerror
(
e
)
:
                
return
callself
(
)
            
raise
        
except
error
.
RepoError
as
e
:
            
return
handlerepoerror
(
e
)
        
except
error
.
RevlogError
as
e
:
            
ui
.
warn
(
'
(
repo
corruption
:
%
s
;
deleting
shared
store
)
\
n
'
%
e
.
message
)
            
deletesharedstore
(
)
            
return
callself
(
)
        
if
res
is
None
:
            
raise
error
.
Abort
(
'
clone
failed
'
)
        
if
not
destvfs
.
exists
(
'
.
hg
/
sharedpath
'
)
:
            
raise
error
.
Abort
(
'
clone
did
not
create
a
shared
repo
'
)
        
created
=
True
    
repo
=
hg
.
repository
(
ui
dest
)
    
havewantedrev
=
False
    
if
revision
and
revision
in
repo
:
        
ctx
=
repo
[
revision
]
        
if
not
ctx
.
hex
(
)
.
startswith
(
revision
)
:
            
raise
error
.
Abort
(
'
-
-
revision
argument
is
ambiguous
'
                              
hint
=
'
must
be
the
first
12
+
characters
of
a
'
                                   
'
SHA
-
1
fragment
'
)
        
checkoutrevision
=
ctx
.
hex
(
)
        
havewantedrev
=
True
    
if
not
havewantedrev
:
        
ui
.
write
(
'
(
pulling
to
obtain
%
s
)
\
n
'
%
(
revision
or
branch
)
)
        
remote
=
None
        
try
:
            
remote
=
hg
.
peer
(
repo
{
}
url
)
            
pullrevs
=
[
remote
.
lookup
(
revision
or
branch
)
]
            
checkoutrevision
=
hex
(
pullrevs
[
0
]
)
            
if
branch
:
                
ui
.
warn
(
'
(
remote
resolved
%
s
to
%
s
;
'
                        
'
result
is
not
deterministic
)
\
n
'
%
                        
(
branch
checkoutrevision
)
)
            
if
checkoutrevision
in
repo
:
                
ui
.
warn
(
'
(
revision
already
present
locally
;
not
pulling
)
\
n
'
)
            
else
:
                
pullop
=
exchange
.
pull
(
repo
remote
heads
=
pullrevs
)
                
if
not
pullop
.
rheads
:
                    
raise
error
.
Abort
(
'
unable
to
pull
requested
revision
'
)
        
except
(
error
.
Abort
pycompat
.
urlerr
.
urlerror
)
as
e
:
            
if
handlepullerror
(
e
)
:
                
return
callself
(
)
            
raise
        
except
error
.
RepoError
as
e
:
            
return
handlerepoerror
(
e
)
        
except
error
.
RevlogError
as
e
:
            
ui
.
warn
(
'
(
repo
corruption
:
%
s
;
deleting
shared
store
)
\
n
'
%
e
.
message
)
            
deletesharedstore
(
)
            
return
callself
(
)
        
finally
:
            
if
remote
:
                
remote
.
close
(
)
    
if
purge
and
not
created
:
        
ui
.
write
(
'
(
purging
working
directory
)
\
n
'
)
        
purgeext
=
extensions
.
find
(
'
purge
'
)
        
if
purgeext
.
purge
(
ui
repo
all
=
True
abort_on_err
=
True
                          
*
*
{
'
print
'
:
None
'
print0
'
:
None
'
dirs
'
:
None
                             
'
files
'
:
None
}
)
:
            
raise
error
.
Abort
(
'
error
purging
'
)
    
if
commands
.
update
(
ui
repo
rev
=
checkoutrevision
clean
=
True
)
:
        
raise
error
.
Abort
(
'
error
updating
'
)
    
ui
.
write
(
'
updated
to
%
s
\
n
'
%
checkoutrevision
)
    
return
None
def
extsetup
(
ui
)
:
    
for
ext
in
(
'
purge
'
'
share
'
)
:
        
try
:
            
extensions
.
find
(
ext
)
        
except
KeyError
:
            
extensions
.
load
(
ui
ext
None
)
    
purgemod
=
extensions
.
find
(
'
purge
'
)
    
extensions
.
wrapcommand
(
purgemod
.
cmdtable
'
purge
'
purgewrapper
)
