#
include
"
memory_hooks
.
h
"
#
include
"
nscore
.
h
"
#
include
"
mozilla
/
Assertions
.
h
"
#
include
"
mozilla
/
Atomics
.
h
"
#
include
"
mozilla
/
FastBernoulliTrial
.
h
"
#
include
"
mozilla
/
IntegerPrintfMacros
.
h
"
#
include
"
mozilla
/
JSONWriter
.
h
"
#
include
"
mozilla
/
MemoryReporting
.
h
"
#
include
"
mozilla
/
PlatformMutex
.
h
"
#
include
"
mozilla
/
ProfilerCounts
.
h
"
#
include
"
mozilla
/
ThreadLocal
.
h
"
#
include
"
mozilla
/
ThreadSafety
.
h
"
#
include
"
GeckoProfiler
.
h
"
#
include
"
prenv
.
h
"
#
include
"
replace_malloc
.
h
"
#
include
<
ctype
.
h
>
#
include
<
errno
.
h
>
#
include
<
limits
.
h
>
#
include
<
stdarg
.
h
>
#
include
<
stdio
.
h
>
#
include
<
stdlib
.
h
>
#
include
<
string
.
h
>
#
ifdef
XP_WIN
#
include
<
windows
.
h
>
#
include
<
process
.
h
>
#
else
#
include
<
pthread
.
h
>
#
include
<
sys
/
types
.
h
>
#
include
<
unistd
.
h
>
#
endif
#
ifdef
ANDROID
#
include
<
android
/
log
.
h
>
#
endif
static
mozilla
:
:
FastBernoulliTrial
*
gBernoulli
;
namespace
mozilla
:
:
profiler
{
static
bool
profiler_add_native_allocation_marker
(
int64_t
aSize
uintptr_t
aMemoryAddress
)
{
if
(
!
profiler_thread_is_being_profiled_for_markers
(
profiler_main_thread_id
(
)
)
)
{
return
false
;
}
if
(
profiler_is_locked_on_current_thread
(
)
)
{
return
false
;
}
struct
NativeAllocationMarker
{
static
constexpr
mozilla
:
:
Span
<
const
char
>
MarkerTypeName
(
)
{
return
mozilla
:
:
MakeStringSpan
(
"
Native
allocation
"
)
;
}
static
void
StreamJSONMarkerData
(
mozilla
:
:
baseprofiler
:
:
SpliceableJSONWriter
&
aWriter
int64_t
aSize
uintptr_t
aMemoryAddress
ProfilerThreadId
aThreadId
)
{
aWriter
.
IntProperty
(
"
size
"
aSize
)
;
aWriter
.
IntProperty
(
"
memoryAddress
"
static_cast
<
int64_t
>
(
aMemoryAddress
)
)
;
aWriter
.
IntProperty
(
"
threadId
"
static_cast
<
int64_t
>
(
aThreadId
.
ToNumber
(
)
)
)
;
}
static
mozilla
:
:
MarkerSchema
MarkerTypeDisplay
(
)
{
return
mozilla
:
:
MarkerSchema
:
:
SpecialFrontendLocation
{
}
;
}
}
;
profiler_add_marker
(
"
Native
allocation
"
geckoprofiler
:
:
category
:
:
OTHER
{
MarkerThreadId
:
:
MainThread
(
)
MarkerStack
:
:
Capture
(
)
}
NativeAllocationMarker
{
}
aSize
aMemoryAddress
profiler_current_thread_id
(
)
)
;
return
true
;
}
static
malloc_table_t
gMallocTable
;
static
size_t
MallocSizeOf
(
const
void
*
aPtr
)
{
return
gMallocTable
.
malloc_usable_size
(
const_cast
<
void
*
>
(
aPtr
)
)
;
}
static
void
EnsureBernoulliIsInstalled
(
)
{
if
(
!
gBernoulli
)
{
gBernoulli
=
new
FastBernoulliTrial
(
0
.
0003
0x8e26eeee166bc8ca
0x56820f304a9c9ae0
)
;
}
}
class
InfallibleAllocWithoutHooksPolicy
{
static
void
ExitOnFailure
(
const
void
*
aP
)
{
if
(
!
aP
)
{
MOZ_CRASH
(
"
Profiler
memory
hooks
out
of
memory
;
aborting
"
)
;
}
}
public
:
template
<
typename
T
>
static
T
*
maybe_pod_malloc
(
size_t
aNumElems
)
{
if
(
aNumElems
&
mozilla
:
:
tl
:
:
MulOverflowMask
<
sizeof
(
T
)
>
:
:
value
)
{
return
nullptr
;
}
return
(
T
*
)
gMallocTable
.
malloc
(
aNumElems
*
sizeof
(
T
)
)
;
}
template
<
typename
T
>
static
T
*
maybe_pod_calloc
(
size_t
aNumElems
)
{
return
(
T
*
)
gMallocTable
.
calloc
(
aNumElems
sizeof
(
T
)
)
;
}
template
<
typename
T
>
static
T
*
maybe_pod_realloc
(
T
*
aPtr
size_t
aOldSize
size_t
aNewSize
)
{
if
(
aNewSize
&
mozilla
:
:
tl
:
:
MulOverflowMask
<
sizeof
(
T
)
>
:
:
value
)
{
return
nullptr
;
}
return
(
T
*
)
gMallocTable
.
realloc
(
aPtr
aNewSize
*
sizeof
(
T
)
)
;
}
template
<
typename
T
>
static
T
*
pod_malloc
(
size_t
aNumElems
)
{
T
*
p
=
maybe_pod_malloc
<
T
>
(
aNumElems
)
;
ExitOnFailure
(
p
)
;
return
p
;
}
template
<
typename
T
>
static
T
*
pod_calloc
(
size_t
aNumElems
)
{
T
*
p
=
maybe_pod_calloc
<
T
>
(
aNumElems
)
;
ExitOnFailure
(
p
)
;
return
p
;
}
template
<
typename
T
>
static
T
*
pod_realloc
(
T
*
aPtr
size_t
aOldSize
size_t
aNewSize
)
{
T
*
p
=
maybe_pod_realloc
(
aPtr
aOldSize
aNewSize
)
;
ExitOnFailure
(
p
)
;
return
p
;
}
template
<
typename
T
>
static
void
free_
(
T
*
aPtr
size_t
aSize
=
0
)
{
gMallocTable
.
free
(
aPtr
)
;
}
static
void
reportAllocOverflow
(
)
{
ExitOnFailure
(
nullptr
)
;
}
bool
checkSimulatedOOM
(
)
const
{
return
true
;
}
}
;
class
MOZ_CAPABILITY
(
"
mutex
"
)
Mutex
:
private
:
:
mozilla
:
:
detail
:
:
MutexImpl
{
public
:
Mutex
(
)
=
default
;
void
Lock
(
)
MOZ_CAPABILITY_ACQUIRE
(
)
{
:
:
mozilla
:
:
detail
:
:
MutexImpl
:
:
lock
(
)
;
}
void
Unlock
(
)
MOZ_CAPABILITY_RELEASE
(
)
{
:
:
mozilla
:
:
detail
:
:
MutexImpl
:
:
unlock
(
)
;
}
}
;
class
MOZ_SCOPED_CAPABILITY
MutexAutoLock
{
MutexAutoLock
(
const
MutexAutoLock
&
)
=
delete
;
void
operator
=
(
const
MutexAutoLock
&
)
=
delete
;
Mutex
&
mMutex
;
public
:
explicit
MutexAutoLock
(
Mutex
&
aMutex
)
MOZ_CAPABILITY_ACQUIRE
(
aMutex
)
:
mMutex
(
aMutex
)
{
mMutex
.
Lock
(
)
;
}
~
MutexAutoLock
(
)
MOZ_CAPABILITY_RELEASE
(
)
{
mMutex
.
Unlock
(
)
;
}
}
;
class
AllocationTracker
{
typedef
mozilla
:
:
HashSet
<
const
void
*
mozilla
:
:
DefaultHasher
<
const
void
*
>
InfallibleAllocWithoutHooksPolicy
>
AllocationSet
;
public
:
AllocationTracker
(
)
=
default
;
void
AddMemoryAddress
(
const
void
*
memoryAddress
)
{
MutexAutoLock
lock
(
mMutex
)
;
if
(
!
mAllocations
.
put
(
memoryAddress
)
)
{
MOZ_CRASH
(
"
Out
of
memory
while
tracking
native
allocations
.
"
)
;
}
;
}
void
Reset
(
)
{
MutexAutoLock
lock
(
mMutex
)
;
mAllocations
.
clearAndCompact
(
)
;
}
bool
RemoveMemoryAddressIfFound
(
const
void
*
memoryAddress
)
{
MutexAutoLock
lock
(
mMutex
)
;
auto
ptr
=
mAllocations
.
lookup
(
memoryAddress
)
;
if
(
ptr
)
{
mAllocations
.
remove
(
ptr
)
;
return
true
;
}
return
false
;
}
private
:
AllocationSet
mAllocations
;
Mutex
mMutex
MOZ_UNANNOTATED
;
}
;
static
AllocationTracker
*
gAllocationTracker
;
static
void
EnsureAllocationTrackerIsInstalled
(
)
{
if
(
!
gAllocationTracker
)
{
gAllocationTracker
=
new
AllocationTracker
(
)
;
}
}
#
if
!
defined
(
XP_DARWIN
)
&
&
!
defined
(
XP_LINUX
)
#
define
PROFILER_THREAD_LOCAL
(
T
)
MOZ_THREAD_LOCAL
(
T
)
#
else
#
define
PROFILER_THREAD_LOCAL
(
T
)
\
:
:
mozilla
:
:
detail
:
:
ThreadLocal
<
T
:
:
mozilla
:
:
detail
:
:
ThreadLocalKeyStorage
>
#
endif
class
MOZ_RAII
ThreadIntercept
{
static
PROFILER_THREAD_LOCAL
(
bool
)
tlsIsBlocked
;
static
mozilla
:
:
Atomic
<
bool
mozilla
:
:
Relaxed
>
sAllocationsFeatureEnabled
;
bool
mIsBlockingTLS
;
bool
mIsBlocked
;
public
:
static
void
Init
(
)
{
tlsIsBlocked
.
infallibleInit
(
)
;
MOZ_ASSERT
(
!
tlsIsBlocked
.
get
(
)
)
;
}
ThreadIntercept
(
)
{
mIsBlockingTLS
=
sAllocationsFeatureEnabled
&
&
!
tlsIsBlocked
.
get
(
)
;
if
(
mIsBlockingTLS
)
{
MOZ_ASSERT
(
!
tlsIsBlocked
.
get
(
)
)
;
tlsIsBlocked
.
set
(
true
)
;
mIsBlocked
=
profiler_is_locked_on_current_thread
(
)
;
}
else
{
mIsBlocked
=
true
;
}
}
~
ThreadIntercept
(
)
{
if
(
mIsBlockingTLS
)
{
MOZ_ASSERT
(
tlsIsBlocked
.
get
(
)
)
;
tlsIsBlocked
.
set
(
false
)
;
}
}
bool
IsBlocked
(
)
const
{
return
mIsBlocked
;
}
static
void
EnableAllocationFeature
(
)
{
sAllocationsFeatureEnabled
=
true
;
}
static
void
DisableAllocationFeature
(
)
{
sAllocationsFeatureEnabled
=
false
;
}
}
;
PROFILER_THREAD_LOCAL
(
bool
)
ThreadIntercept
:
:
tlsIsBlocked
;
mozilla
:
:
Atomic
<
bool
mozilla
:
:
Relaxed
>
ThreadIntercept
:
:
sAllocationsFeatureEnabled
(
false
)
;
static
void
AllocCallback
(
void
*
aPtr
size_t
aReqSize
)
{
if
(
!
aPtr
)
{
return
;
}
ThreadIntercept
threadIntercept
;
if
(
threadIntercept
.
IsBlocked
(
)
)
{
return
;
}
AUTO_PROFILER_LABEL
(
"
AllocCallback
"
PROFILER
)
;
size_t
actualSize
=
gMallocTable
.
malloc_usable_size
(
aPtr
)
;
MOZ_ASSERT
(
gBernoulli
"
gBernoulli
must
be
properly
installed
for
the
memory
hooks
.
"
)
;
if
(
gBernoulli
-
>
trial
(
actualSize
)
&
&
profiler_add_native_allocation_marker
(
static_cast
<
int64_t
>
(
actualSize
)
reinterpret_cast
<
uintptr_t
>
(
aPtr
)
)
)
{
MOZ_ASSERT
(
gAllocationTracker
"
gAllocationTracker
must
be
properly
installed
for
the
memory
"
"
hooks
.
"
)
;
gAllocationTracker
-
>
AddMemoryAddress
(
aPtr
)
;
}
}
static
void
FreeCallback
(
void
*
aPtr
)
{
if
(
!
aPtr
)
{
return
;
}
ThreadIntercept
threadIntercept
;
if
(
threadIntercept
.
IsBlocked
(
)
)
{
return
;
}
AUTO_PROFILER_LABEL
(
"
FreeCallback
"
PROFILER
)
;
MOZ_ASSERT
(
gAllocationTracker
"
gAllocationTracker
must
be
properly
installed
for
the
memory
hooks
.
"
)
;
if
(
gAllocationTracker
-
>
RemoveMemoryAddressIfFound
(
aPtr
)
)
{
size_t
unsignedSize
=
MallocSizeOf
(
aPtr
)
;
int64_t
signedSize
=
-
(
static_cast
<
int64_t
>
(
unsignedSize
)
)
;
profiler_add_native_allocation_marker
(
signedSize
reinterpret_cast
<
uintptr_t
>
(
aPtr
)
)
;
}
}
}
using
namespace
mozilla
:
:
profiler
;
static
void
*
replace_malloc
(
size_t
aSize
)
{
void
*
ptr
=
gMallocTable
.
malloc
(
aSize
)
;
AllocCallback
(
ptr
aSize
)
;
return
ptr
;
}
static
void
*
replace_calloc
(
size_t
aCount
size_t
aSize
)
{
void
*
ptr
=
gMallocTable
.
calloc
(
aCount
aSize
)
;
AllocCallback
(
ptr
aCount
*
aSize
)
;
return
ptr
;
}
static
void
*
replace_realloc
(
void
*
aOldPtr
size_t
aSize
)
{
if
(
!
aOldPtr
)
{
return
replace_malloc
(
aSize
)
;
}
FreeCallback
(
aOldPtr
)
;
void
*
ptr
=
gMallocTable
.
realloc
(
aOldPtr
aSize
)
;
if
(
ptr
)
{
AllocCallback
(
ptr
aSize
)
;
}
else
{
AllocCallback
(
aOldPtr
gMallocTable
.
malloc_usable_size
(
aOldPtr
)
)
;
}
return
ptr
;
}
static
void
*
replace_memalign
(
size_t
aAlignment
size_t
aSize
)
{
void
*
ptr
=
gMallocTable
.
memalign
(
aAlignment
aSize
)
;
AllocCallback
(
ptr
aSize
)
;
return
ptr
;
}
static
void
replace_free
(
void
*
aPtr
)
{
FreeCallback
(
aPtr
)
;
gMallocTable
.
free
(
aPtr
)
;
}
static
void
*
replace_moz_arena_malloc
(
arena_id_t
aArena
size_t
aSize
)
{
void
*
ptr
=
gMallocTable
.
moz_arena_malloc
(
aArena
aSize
)
;
AllocCallback
(
ptr
aSize
)
;
return
ptr
;
}
static
void
*
replace_moz_arena_calloc
(
arena_id_t
aArena
size_t
aCount
size_t
aSize
)
{
void
*
ptr
=
gMallocTable
.
moz_arena_calloc
(
aArena
aCount
aSize
)
;
AllocCallback
(
ptr
aCount
*
aSize
)
;
return
ptr
;
}
static
void
*
replace_moz_arena_realloc
(
arena_id_t
aArena
void
*
aPtr
size_t
aSize
)
{
void
*
ptr
=
gMallocTable
.
moz_arena_realloc
(
aArena
aPtr
aSize
)
;
AllocCallback
(
ptr
aSize
)
;
return
ptr
;
}
static
void
replace_moz_arena_free
(
arena_id_t
aArena
void
*
aPtr
)
{
FreeCallback
(
aPtr
)
;
gMallocTable
.
moz_arena_free
(
aArena
aPtr
)
;
}
static
void
*
replace_moz_arena_memalign
(
arena_id_t
aArena
size_t
aAlignment
size_t
aSize
)
{
void
*
ptr
=
gMallocTable
.
moz_arena_memalign
(
aArena
aAlignment
aSize
)
;
AllocCallback
(
ptr
aSize
)
;
return
ptr
;
}
static
arena_id_t
replace_moz_create_arena_with_params
(
arena_params_t
*
aParams
)
{
return
gMallocTable
.
moz_create_arena_with_params
(
aParams
)
;
}
static
void
replace_moz_dispose_arena
(
arena_id_t
aArenaId
)
{
return
gMallocTable
.
moz_dispose_arena
(
aArenaId
)
;
}
static
void
replace_moz_set_max_dirty_page_modifier
(
int32_t
aModifier
)
{
return
gMallocTable
.
moz_set_max_dirty_page_modifier
(
aModifier
)
;
}
static
bool
replace_moz_enable_deferred_purge
(
bool
aEnable
)
{
return
gMallocTable
.
moz_enable_deferred_purge
(
aEnable
)
;
}
static
purge_result_t
replace_moz_may_purge_one_now
(
bool
aPeekOnly
uint32_t
aReuseGraceMS
)
{
return
gMallocTable
.
moz_may_purge_one_now
(
aPeekOnly
aReuseGraceMS
)
;
}
void
replace_init
(
malloc_table_t
*
aMallocTable
ReplaceMallocBridge
*
*
aBridge
)
{
gMallocTable
=
*
aMallocTable
;
#
define
MALLOC_FUNCS
(
MALLOC_FUNCS_MALLOC_BASE
|
MALLOC_FUNCS_ARENA
)
#
define
MALLOC_DECL
(
name
.
.
.
)
aMallocTable
-
>
name
=
replace_
#
#
name
;
#
include
"
malloc_decls
.
h
"
}
void
profiler_replace_remove
(
)
{
}
namespace
mozilla
:
:
profiler
{
void
remove_memory_hooks
(
)
{
jemalloc_replace_dynamic
(
nullptr
)
;
}
void
enable_native_allocations
(
)
{
MOZ_ASSERT
(
!
PR_GetEnv
(
"
XPCOM_MEM_BLOAT_LOG
"
)
"
The
bloat
log
feature
is
not
compatible
with
the
native
"
"
allocations
instrumentation
.
"
)
;
EnsureBernoulliIsInstalled
(
)
;
EnsureAllocationTrackerIsInstalled
(
)
;
ThreadIntercept
:
:
EnableAllocationFeature
(
)
;
jemalloc_replace_dynamic
(
replace_init
)
;
}
void
disable_native_allocations
(
)
{
ThreadIntercept
:
:
DisableAllocationFeature
(
)
;
if
(
gAllocationTracker
)
{
gAllocationTracker
-
>
Reset
(
)
;
}
}
void
memory_hooks_tls_init
(
)
{
ThreadIntercept
:
:
Init
(
)
;
}
}
