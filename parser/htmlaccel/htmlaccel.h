#
ifndef
mozilla_htmlaccel_htmlaccel_h
#
define
mozilla_htmlaccel_htmlaccel_h
#
include
<
string
.
h
>
#
include
<
stdint
.
h
>
#
include
"
mozilla
/
Attributes
.
h
"
#
if
!
defined
(
__LITTLE_ENDIAN__
)
#
error
"
A
little
-
endian
target
is
required
.
"
#
endif
#
if
!
(
defined
(
__aarch64__
)
|
|
defined
(
__SSSE3__
)
)
#
error
"
Must
be
targeting
aarch64
or
SSSE3
.
"
#
endif
#
if
!
(
defined
(
__GNUC__
)
|
|
defined
(
__clang__
)
)
#
error
"
A
compiler
that
supports
GCC
-
style
portable
SIMD
is
required
.
"
#
endif
#
if
defined
(
__aarch64__
)
#
include
<
arm_neon
.
h
>
#
else
#
include
<
tmmintrin
.
h
>
typedef
uint8_t
uint8x16_t
__attribute__
(
(
vector_size
(
16
)
)
)
;
#
endif
namespace
mozilla
:
:
htmlaccel
{
namespace
detail
{
#
if
defined
(
__aarch64__
)
const
uint8x16_t
INVERTED_ADVANCES
=
{
16
15
14
13
12
11
10
9
8
7
6
5
4
3
2
1
}
;
MOZ_ALWAYS_INLINE_EVEN_DEBUG
uint8x16_t
TableLookup
(
uint8x16_t
aTable
uint8x16_t
aNibbles
)
{
return
vqtbl1q_u8
(
aTable
aNibbles
)
;
}
#
else
MOZ_ALWAYS_INLINE_EVEN_DEBUG
uint8x16_t
TableLookup
(
uint8x16_t
aTable
uint8x16_t
aNibbles
)
{
return
reinterpret_cast
<
uint8x16_t
>
(
_mm_shuffle_epi8
(
aTable
aNibbles
)
)
;
}
#
endif
const
uint8x16_t
ALL_ZEROS
=
{
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
}
;
const
uint8x16_t
NIBBLE_MASK
=
{
0xF
0xF
0xF
0xF
0xF
0xF
0xF
0xF
0xF
0xF
0xF
0xF
0xF
0xF
0xF
0xF
}
;
const
uint8x16_t
SURROGATE_MASK
=
{
0xF8
0xF8
0xF8
0xF8
0xF8
0xF8
0xF8
0xF8
0xF8
0xF8
0xF8
0xF8
0xF8
0xF8
0xF8
0xF8
}
;
const
uint8x16_t
SURROGATE_MATCH
=
{
0xD8
0xD8
0xD8
0xD8
0xD8
0xD8
0xD8
0xD8
0xD8
0xD8
0xD8
0xD8
0xD8
0xD8
0xD8
0xD8
}
;
const
uint8x16_t
ZERO_LT_AMP_CR
=
{
0
2
1
1
1
1
'
&
'
1
1
1
1
1
'
<
'
'
\
r
'
1
1
}
;
const
uint8x16_t
ZERO_LT_AMP_CR_LF
=
{
0
2
1
1
1
1
'
&
'
1
1
1
'
\
n
'
1
'
<
'
'
\
r
'
1
1
}
;
MOZ_ALWAYS_INLINE_EVEN_DEBUG
uint8x16_t
StrideToMask
(
const
char16_t
*
aArr
uint8x16_t
aTable
bool
aAllowSurrogates
)
{
uint8x16_t
first
;
uint8x16_t
second
;
memcpy
(
&
first
aArr
16
)
;
memcpy
(
&
second
aArr
+
8
16
)
;
uint8x16_t
low_halves
=
__builtin_shufflevector
(
first
second
0
2
4
6
8
10
12
14
16
18
20
22
24
26
28
30
)
;
uint8x16_t
high_halves
=
__builtin_shufflevector
(
first
second
1
3
5
7
9
11
13
15
17
19
21
23
25
27
29
31
)
;
uint8x16_t
high_half_matches
=
high_halves
=
=
ALL_ZEROS
;
uint8x16_t
low_half_matches
=
low_halves
=
=
TableLookup
(
aTable
low_halves
&
NIBBLE_MASK
)
;
uint8x16_t
ret
=
low_half_matches
&
high_half_matches
;
if
(
!
aAllowSurrogates
)
{
ret
|
=
(
high_halves
&
SURROGATE_MASK
)
=
=
SURROGATE_MATCH
;
}
return
ret
;
}
MOZ_ALWAYS_INLINE_EVEN_DEBUG
int32_t
AccelerateTextNode
(
const
char16_t
*
aInput
const
char16_t
*
aEnd
uint8x16_t
aTable
bool
aAllowSurrogates
)
{
const
char16_t
*
current
=
aInput
;
while
(
aEnd
-
current
>
=
16
)
{
uint8x16_t
mask
=
StrideToMask
(
current
aTable
aAllowSurrogates
)
;
#
if
defined
(
__aarch64__
)
uint8_t
max
=
vmaxvq_u8
(
mask
&
INVERTED_ADVANCES
)
;
if
(
max
!
=
0
)
{
return
int32_t
(
(
current
-
aInput
)
+
16
-
max
)
;
}
#
else
int
int_mask
=
_mm_movemask_epi8
(
mask
)
;
if
(
int_mask
!
=
0
)
{
return
int32_t
(
(
current
-
aInput
)
+
__builtin_ctz
(
int_mask
)
)
;
}
#
endif
current
+
=
16
;
}
return
int32_t
(
current
-
aInput
)
;
}
}
}
#
endif
