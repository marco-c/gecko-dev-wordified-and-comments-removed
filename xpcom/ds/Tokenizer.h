#
ifndef
Tokenizer_h__
#
define
Tokenizer_h__
#
include
"
nsString
.
h
"
#
include
"
mozilla
/
CheckedInt
.
h
"
#
include
"
mozilla
/
UniquePtr
.
h
"
#
include
"
nsTArray
.
h
"
namespace
mozilla
{
class
TokenizerBase
{
public
:
enum
TokenType
:
uint32_t
{
TOKEN_UNKNOWN
TOKEN_RAW
TOKEN_ERROR
TOKEN_INTEGER
TOKEN_WORD
TOKEN_CHAR
TOKEN_WS
TOKEN_EOL
TOKEN_EOF
TOKEN_CUSTOM0
=
1000
}
;
enum
ECaseSensitivity
{
CASE_SENSITIVE
CASE_INSENSITIVE
}
;
class
Token
{
TokenType
mType
;
nsDependentCSubstring
mWord
;
nsCString
mCustom
;
char
mChar
;
uint64_t
mInteger
;
ECaseSensitivity
mCustomCaseInsensitivity
;
bool
mCustomEnabled
;
nsDependentCSubstring
mFragment
;
friend
class
TokenizerBase
;
void
AssignFragment
(
nsACString
:
:
const_char_iterator
begin
nsACString
:
:
const_char_iterator
end
)
;
static
Token
Raw
(
)
;
public
:
Token
(
)
;
Token
(
const
Token
&
aOther
)
;
Token
&
operator
=
(
const
Token
&
aOther
)
;
static
Token
Word
(
const
nsACString
&
aWord
)
;
static
Token
Char
(
const
char
aChar
)
;
static
Token
Number
(
const
uint64_t
aNumber
)
;
static
Token
Whitespace
(
)
;
static
Token
NewLine
(
)
;
static
Token
EndOfFile
(
)
;
static
Token
Error
(
)
;
bool
Equals
(
const
Token
&
aOther
)
const
;
TokenType
Type
(
)
const
{
return
mType
;
}
char
AsChar
(
)
const
;
nsDependentCSubstring
AsString
(
)
const
;
uint64_t
AsInteger
(
)
const
;
nsDependentCSubstring
Fragment
(
)
const
{
return
mFragment
;
}
}
;
Token
AddCustomToken
(
const
nsACString
&
aValue
ECaseSensitivity
aCaseInsensitivity
bool
aEnabled
=
true
)
;
template
<
uint32_t
N
>
Token
AddCustomToken
(
const
char
(
&
aValue
)
[
N
]
ECaseSensitivity
aCaseInsensitivity
bool
aEnabled
=
true
)
{
return
AddCustomToken
(
nsDependentCSubstring
(
aValue
N
-
1
)
aCaseInsensitivity
aEnabled
)
;
}
void
RemoveCustomToken
(
Token
&
aToken
)
;
void
EnableCustomToken
(
Token
const
&
aToken
bool
aEnable
)
;
enum
class
Mode
{
FULL
CUSTOM_ONLY
}
;
void
SetTokenizingMode
(
Mode
aMode
)
;
MOZ_MUST_USE
bool
HasFailed
(
)
const
;
protected
:
explicit
TokenizerBase
(
const
char
*
aWhitespaces
=
nullptr
const
char
*
aAdditionalWordChars
=
nullptr
)
;
bool
HasInput
(
)
const
;
nsACString
:
:
const_char_iterator
Parse
(
Token
&
aToken
)
const
;
bool
IsEnd
(
const
nsACString
:
:
const_char_iterator
&
caret
)
const
;
bool
IsPending
(
const
nsACString
:
:
const_char_iterator
&
caret
)
const
;
bool
IsWordFirst
(
const
char
aInput
)
const
;
bool
IsWord
(
const
char
aInput
)
const
;
bool
IsNumber
(
const
char
aInput
)
const
;
bool
IsCustom
(
const
nsACString
:
:
const_char_iterator
&
caret
const
Token
&
aCustomToken
uint32_t
*
aLongest
=
nullptr
)
const
;
static
void
AssignFragment
(
Token
&
aToken
nsACString
:
:
const_char_iterator
begin
nsACString
:
:
const_char_iterator
end
)
;
bool
mPastEof
;
bool
mHasFailed
;
bool
mInputFinished
;
Mode
mMode
;
uint32_t
mMinRawDelivery
;
const
char
*
mWhitespaces
;
const
char
*
mAdditionalWordChars
;
nsACString
:
:
const_char_iterator
mCursor
;
nsACString
:
:
const_char_iterator
mEnd
;
nsTArray
<
UniquePtr
<
Token
>
>
mCustomTokens
;
uint32_t
mNextCustomTokenID
;
private
:
TokenizerBase
(
)
=
delete
;
TokenizerBase
(
const
TokenizerBase
&
)
=
delete
;
TokenizerBase
(
TokenizerBase
&
&
)
=
delete
;
TokenizerBase
(
const
TokenizerBase
&
&
)
=
delete
;
TokenizerBase
&
operator
=
(
const
TokenizerBase
&
)
=
delete
;
}
;
class
Tokenizer
:
public
TokenizerBase
{
public
:
explicit
Tokenizer
(
const
nsACString
&
aSource
const
char
*
aWhitespaces
=
nullptr
const
char
*
aAdditionalWordChars
=
nullptr
)
;
explicit
Tokenizer
(
const
char
*
aSource
const
char
*
aWhitespaces
=
nullptr
const
char
*
aAdditionalWordChars
=
nullptr
)
;
MOZ_MUST_USE
bool
Next
(
Token
&
aToken
)
;
MOZ_MUST_USE
bool
Check
(
const
TokenType
aTokenType
Token
&
aResult
)
;
MOZ_MUST_USE
bool
Check
(
const
Token
&
aToken
)
;
enum
WhiteSkipping
{
DONT_INCLUDE_NEW_LINE
=
0
INCLUDE_NEW_LINE
=
1
}
;
void
SkipWhites
(
WhiteSkipping
aIncludeNewLines
=
DONT_INCLUDE_NEW_LINE
)
;
void
SkipUntil
(
Token
const
&
aToken
)
;
MOZ_MUST_USE
bool
CheckWhite
(
)
{
return
Check
(
Token
:
:
Whitespace
(
)
)
;
}
MOZ_MUST_USE
bool
CheckChar
(
const
char
aChar
)
{
return
Check
(
Token
:
:
Char
(
aChar
)
)
;
}
MOZ_MUST_USE
bool
CheckChar
(
bool
(
*
aClassifier
)
(
const
char
aChar
)
)
;
MOZ_MUST_USE
bool
CheckWord
(
const
nsACString
&
aWord
)
{
return
Check
(
Token
:
:
Word
(
aWord
)
)
;
}
template
<
uint32_t
N
>
MOZ_MUST_USE
bool
CheckWord
(
const
char
(
&
aWord
)
[
N
]
)
{
return
Check
(
Token
:
:
Word
(
nsDependentCString
(
aWord
N
-
1
)
)
)
;
}
MOZ_MUST_USE
bool
CheckEOL
(
)
{
return
Check
(
Token
:
:
NewLine
(
)
)
;
}
MOZ_MUST_USE
bool
CheckEOF
(
)
{
return
Check
(
Token
:
:
EndOfFile
(
)
)
;
}
MOZ_MUST_USE
bool
ReadChar
(
char
*
aValue
)
;
MOZ_MUST_USE
bool
ReadChar
(
bool
(
*
aClassifier
)
(
const
char
aChar
)
char
*
aValue
)
;
MOZ_MUST_USE
bool
ReadWord
(
nsACString
&
aValue
)
;
MOZ_MUST_USE
bool
ReadWord
(
nsDependentCSubstring
&
aValue
)
;
template
<
typename
T
>
MOZ_MUST_USE
bool
ReadInteger
(
T
*
aValue
)
{
MOZ_RELEASE_ASSERT
(
aValue
)
;
nsACString
:
:
const_char_iterator
rollback
=
mRollback
;
nsACString
:
:
const_char_iterator
cursor
=
mCursor
;
Token
t
;
if
(
!
Check
(
TOKEN_INTEGER
t
)
)
{
return
false
;
}
mozilla
:
:
CheckedInt
<
T
>
checked
(
t
.
AsInteger
(
)
)
;
if
(
!
checked
.
isValid
(
)
)
{
mRollback
=
rollback
;
mCursor
=
cursor
;
mHasFailed
=
true
;
return
false
;
}
*
aValue
=
checked
.
value
(
)
;
return
true
;
}
void
Rollback
(
)
;
enum
ClaimInclusion
{
INCLUDE_LAST
EXCLUDE_LAST
}
;
void
Record
(
ClaimInclusion
aInclude
=
EXCLUDE_LAST
)
;
void
Claim
(
nsACString
&
aResult
ClaimInclusion
aInclude
=
EXCLUDE_LAST
)
;
void
Claim
(
nsDependentCSubstring
&
aResult
ClaimInclusion
aInclude
=
EXCLUDE_LAST
)
;
MOZ_MUST_USE
bool
ReadUntil
(
Token
const
&
aToken
nsDependentCSubstring
&
aResult
ClaimInclusion
aInclude
=
EXCLUDE_LAST
)
;
MOZ_MUST_USE
bool
ReadUntil
(
Token
const
&
aToken
nsACString
&
aResult
ClaimInclusion
aInclude
=
EXCLUDE_LAST
)
;
protected
:
nsACString
:
:
const_char_iterator
mRecord
;
nsACString
:
:
const_char_iterator
mRollback
;
private
:
Tokenizer
(
)
=
delete
;
Tokenizer
(
const
Tokenizer
&
)
=
delete
;
Tokenizer
(
Tokenizer
&
&
)
=
delete
;
Tokenizer
(
const
Tokenizer
&
&
)
=
delete
;
Tokenizer
&
operator
=
(
const
Tokenizer
&
)
=
delete
;
}
;
}
#
endif
