var
acorn
=
require
(
"
acorn
"
)
;
var
sourceMap
=
require
(
"
source
-
map
"
)
;
const
NEWLINE_CODE
=
10
;
const
PRE_ARRAY_LITERAL_TOKENS
=
new
Set
(
[
"
typeof
"
"
void
"
"
delete
"
"
case
"
"
do
"
"
=
"
"
in
"
"
{
"
"
*
"
"
/
"
"
%
"
"
else
"
"
;
"
"
+
+
"
"
-
-
"
"
+
"
"
-
"
"
~
"
"
!
"
"
:
"
"
?
"
"
>
>
"
"
>
>
>
"
"
<
<
"
"
|
|
"
"
&
&
"
"
<
"
"
>
"
"
<
=
"
"
>
=
"
"
instanceof
"
"
&
"
"
^
"
"
|
"
"
=
=
"
"
!
=
"
"
=
=
=
"
"
!
=
=
"
"
"
"
}
"
]
)
;
function
isArrayLiteral
(
token
lastToken
)
{
if
(
token
.
type
.
label
!
=
"
[
"
)
{
return
false
;
}
if
(
!
lastToken
)
{
return
true
;
}
if
(
lastToken
.
type
.
isAssign
)
{
return
true
;
}
return
PRE_ARRAY_LITERAL_TOKENS
.
has
(
lastToken
.
type
.
keyword
|
|
lastToken
.
type
.
label
)
;
}
const
PREVENT_ASI_AFTER_TOKENS
=
new
Set
(
[
"
*
"
"
/
"
"
%
"
"
+
"
"
-
"
"
<
<
"
"
>
>
"
"
>
>
>
"
"
<
"
"
>
"
"
<
=
"
"
>
=
"
"
instanceof
"
"
in
"
"
=
=
"
"
!
=
"
"
=
=
=
"
"
!
=
=
"
"
&
"
"
^
"
"
|
"
"
&
&
"
"
|
|
"
"
"
"
.
"
"
=
"
"
*
=
"
"
/
=
"
"
%
=
"
"
+
=
"
"
-
=
"
"
<
<
=
"
"
>
>
=
"
"
>
>
>
=
"
"
&
=
"
"
^
=
"
"
|
=
"
"
delete
"
"
void
"
"
typeof
"
"
~
"
"
!
"
"
new
"
"
(
"
]
)
;
const
PREVENT_ASI_BEFORE_TOKENS
=
new
Set
(
[
"
*
"
"
/
"
"
%
"
"
<
<
"
"
>
>
"
"
>
>
>
"
"
<
"
"
>
"
"
<
=
"
"
>
=
"
"
instanceof
"
"
in
"
"
=
=
"
"
!
=
"
"
=
=
=
"
"
!
=
=
"
"
&
"
"
^
"
"
|
"
"
&
&
"
"
|
|
"
"
"
"
.
"
"
=
"
"
*
=
"
"
/
=
"
"
%
=
"
"
+
=
"
"
-
=
"
"
<
<
=
"
"
>
>
=
"
"
>
>
>
=
"
"
&
=
"
"
^
=
"
"
|
=
"
"
(
"
]
)
;
function
isIdentifierLike
(
token
)
{
const
ttl
=
token
.
type
.
label
;
return
(
ttl
=
=
"
name
"
|
|
ttl
=
=
"
num
"
|
|
ttl
=
=
"
privateId
"
|
|
!
!
token
.
type
.
keyword
)
;
}
function
isASI
(
token
lastToken
)
{
if
(
!
lastToken
)
{
return
false
;
}
if
(
token
.
loc
.
start
.
line
=
=
=
lastToken
.
loc
.
start
.
line
)
{
return
false
;
}
if
(
lastToken
.
type
.
keyword
=
=
"
return
"
|
|
lastToken
.
type
.
keyword
=
=
"
yield
"
|
|
(
lastToken
.
type
.
label
=
=
"
name
"
&
&
lastToken
.
value
=
=
"
yield
"
)
)
{
return
true
;
}
if
(
PREVENT_ASI_AFTER_TOKENS
.
has
(
lastToken
.
type
.
label
|
|
lastToken
.
type
.
keyword
)
)
{
return
false
;
}
if
(
PREVENT_ASI_BEFORE_TOKENS
.
has
(
token
.
type
.
label
|
|
token
.
type
.
keyword
)
)
{
return
false
;
}
return
true
;
}
function
isLineDelimiter
(
token
stack
)
{
if
(
token
.
isArrayLiteral
)
{
return
true
;
}
const
ttl
=
token
.
type
.
label
;
const
top
=
stack
.
at
(
-
1
)
;
return
(
(
ttl
=
=
"
;
"
&
&
top
!
=
"
(
"
)
|
|
ttl
=
=
"
{
"
|
|
(
ttl
=
=
"
"
&
&
top
!
=
"
(
"
)
|
|
(
ttl
=
=
"
:
"
&
&
(
top
=
=
"
case
"
|
|
top
=
=
"
default
"
)
)
)
;
}
function
appendNewline
(
token
write
stack
)
{
if
(
isLineDelimiter
(
token
stack
)
)
{
write
(
"
\
n
"
)
;
return
true
;
}
return
false
;
}
function
needsSpaceAfter
(
token
lastToken
)
{
if
(
lastToken
&
&
needsSpaceBetweenTokens
(
token
lastToken
)
)
{
return
true
;
}
if
(
token
.
type
.
isAssign
)
{
return
true
;
}
if
(
token
.
type
.
binop
!
=
null
&
&
lastToken
)
{
return
true
;
}
if
(
token
.
type
.
label
=
=
"
?
"
)
{
return
true
;
}
return
false
;
}
function
needsSpaceBeforeLastToken
(
lastToken
)
{
if
(
lastToken
.
type
.
isLoop
)
{
return
true
;
}
if
(
lastToken
.
type
.
isAssign
)
{
return
true
;
}
if
(
lastToken
.
type
.
binop
!
=
null
)
{
return
true
;
}
const
lastTokenTypeLabel
=
lastToken
.
type
.
label
;
if
(
lastTokenTypeLabel
=
=
"
?
"
)
{
return
true
;
}
if
(
lastTokenTypeLabel
=
=
"
:
"
)
{
return
true
;
}
if
(
lastTokenTypeLabel
=
=
"
"
)
{
return
true
;
}
if
(
lastTokenTypeLabel
=
=
"
;
"
)
{
return
true
;
}
if
(
lastTokenTypeLabel
=
=
"
{
"
)
{
return
true
;
}
return
false
;
}
function
isBreakContinueOrReturnStatement
(
lastTokenKeyword
)
{
return
(
lastTokenKeyword
=
=
"
break
"
|
|
lastTokenKeyword
=
=
"
continue
"
|
|
lastTokenKeyword
=
=
"
return
"
)
;
}
function
needsSpaceBeforeLastTokenKeywordAfterNotDot
(
lastTokenKeyword
)
{
return
(
lastTokenKeyword
!
=
"
debugger
"
&
&
lastTokenKeyword
!
=
"
null
"
&
&
lastTokenKeyword
!
=
"
true
"
&
&
lastTokenKeyword
!
=
"
false
"
&
&
lastTokenKeyword
!
=
"
this
"
&
&
lastTokenKeyword
!
=
"
default
"
)
;
}
function
needsSpaceBeforeClosingParen
(
tokenTypeLabel
)
{
return
(
tokenTypeLabel
!
=
"
)
"
&
&
tokenTypeLabel
!
=
"
]
"
&
&
tokenTypeLabel
!
=
"
;
"
&
&
tokenTypeLabel
!
=
"
"
&
&
tokenTypeLabel
!
=
"
.
"
)
;
}
function
needsSpaceBetweenTokens
(
token
lastToken
)
{
if
(
needsSpaceBeforeLastToken
(
lastToken
)
)
{
return
true
;
}
const
ltt
=
lastToken
.
type
.
label
;
if
(
ltt
=
=
"
num
"
&
&
token
.
type
.
label
=
=
"
.
"
)
{
return
true
;
}
const
ltk
=
lastToken
.
type
.
keyword
;
const
ttl
=
token
.
type
.
label
;
if
(
ltk
!
=
null
&
&
ttl
!
=
"
.
"
)
{
if
(
isBreakContinueOrReturnStatement
(
ltk
)
)
{
return
ttl
!
=
"
;
"
;
}
if
(
needsSpaceBeforeLastTokenKeywordAfterNotDot
(
ltk
)
)
{
return
true
;
}
}
if
(
ltt
=
=
"
)
"
&
&
needsSpaceBeforeClosingParen
(
ttl
)
)
{
return
true
;
}
if
(
isIdentifierLike
(
token
)
&
&
isIdentifierLike
(
lastToken
)
)
{
return
true
;
}
if
(
token
.
type
.
label
=
=
"
{
"
&
&
lastToken
.
type
.
label
=
=
"
name
"
)
{
return
true
;
}
return
false
;
}
function
needsSpaceBeforeClosingCurlyBracket
(
tokenTypeKeyword
)
{
return
(
tokenTypeKeyword
=
=
"
else
"
|
|
tokenTypeKeyword
=
=
"
catch
"
|
|
tokenTypeKeyword
=
=
"
finally
"
)
;
}
function
needsLineBreakBeforeClosingCurlyBracket
(
tokenTypeLabel
)
{
return
(
tokenTypeLabel
!
=
"
(
"
&
&
tokenTypeLabel
!
=
"
;
"
&
&
tokenTypeLabel
!
=
"
"
&
&
tokenTypeLabel
!
=
"
)
"
&
&
tokenTypeLabel
!
=
"
.
"
&
&
tokenTypeLabel
!
=
"
template
"
&
&
tokenTypeLabel
!
=
"
"
)
;
}
function
prependWhiteSpace
(
token
lastToken
addedNewline
addedSpace
write
options
indentLevel
stack
)
{
const
ttk
=
token
.
type
.
keyword
;
const
ttl
=
token
.
type
.
label
;
let
newlineAdded
=
addedNewline
;
let
spaceAdded
=
addedSpace
;
const
ltt
=
lastToken
?
.
type
?
.
label
;
if
(
lastToken
&
&
ltt
=
=
"
}
"
)
{
if
(
(
ttk
=
=
"
while
"
&
&
stack
.
at
(
-
1
)
=
=
"
do
"
)
|
|
needsSpaceBeforeClosingCurlyBracket
(
ttk
)
)
{
write
(
"
"
)
;
spaceAdded
=
true
;
}
else
if
(
needsLineBreakBeforeClosingCurlyBracket
(
ttl
)
)
{
write
(
"
\
n
"
)
;
newlineAdded
=
true
;
}
}
if
(
(
ttl
=
=
"
:
"
&
&
stack
.
at
(
-
1
)
=
=
"
?
"
)
|
|
(
ttl
=
=
"
}
"
&
&
stack
.
at
(
-
1
)
=
=
"
{
"
)
)
{
write
(
"
"
)
;
spaceAdded
=
true
;
}
if
(
lastToken
&
&
ltt
!
=
"
}
"
&
&
ltt
!
=
"
.
"
&
&
ttk
=
=
"
else
"
)
{
write
(
"
"
)
;
spaceAdded
=
true
;
}
function
ensureNewline
(
)
{
if
(
!
newlineAdded
)
{
write
(
"
\
n
"
)
;
newlineAdded
=
true
;
}
}
if
(
isASI
(
token
lastToken
)
)
{
ensureNewline
(
)
;
}
if
(
decrementsIndent
(
ttl
stack
)
)
{
ensureNewline
(
)
;
}
if
(
newlineAdded
)
{
if
(
ttk
=
=
"
case
"
|
|
ttk
=
=
"
default
"
)
{
write
(
options
.
indent
.
repeat
(
indentLevel
-
1
)
)
;
}
else
{
write
(
options
.
indent
.
repeat
(
indentLevel
)
)
;
}
}
else
if
(
!
spaceAdded
&
&
needsSpaceAfter
(
token
lastToken
)
)
{
write
(
"
"
)
;
spaceAdded
=
true
;
}
}
const
escapeCharacters
=
{
"
\
\
"
:
"
\
\
\
\
"
"
\
n
"
:
"
\
\
n
"
"
\
r
"
:
"
\
\
r
"
"
\
t
"
:
"
\
\
t
"
"
\
v
"
:
"
\
\
v
"
"
\
f
"
:
"
\
\
f
"
"
\
0
"
:
"
\
\
x00
"
"
\
u2028
"
:
"
\
\
u2028
"
"
\
u2029
"
:
"
\
\
u2029
"
"
'
"
:
"
\
\
'
"
}
;
const
regExpString
=
"
(
"
+
Object
.
values
(
escapeCharacters
)
.
join
(
"
|
"
)
+
"
)
"
;
const
escapeCharactersRegExp
=
new
RegExp
(
regExpString
"
g
"
)
;
function
sanitizerReplaceFunc
(
_
c
)
{
return
escapeCharacters
[
c
]
;
}
function
sanitize
(
str
)
{
return
str
.
replace
(
escapeCharactersRegExp
sanitizerReplaceFunc
)
;
}
function
addToken
(
token
write
)
{
if
(
token
.
type
.
label
=
=
"
string
"
)
{
write
(
'
{
sanitize
(
token
.
value
)
}
'
token
.
loc
.
start
.
line
token
.
loc
.
start
.
column
true
)
;
}
else
if
(
token
.
type
.
label
=
=
"
regexp
"
)
{
write
(
String
(
token
.
value
.
value
)
token
.
loc
.
start
.
line
token
.
loc
.
start
.
column
true
)
;
}
else
{
let
value
;
if
(
token
.
value
!
=
null
)
{
value
=
token
.
value
;
if
(
token
.
type
.
label
=
=
=
"
privateId
"
)
{
value
=
#
{
value
}
;
}
}
else
{
value
=
token
.
type
.
label
;
}
write
(
String
(
value
)
token
.
loc
.
start
.
line
token
.
loc
.
start
.
column
true
)
;
}
}
function
belongsOnStack
(
token
)
{
const
ttl
=
token
.
type
.
label
;
const
ttk
=
token
.
type
.
keyword
;
return
(
ttl
=
=
"
{
"
|
|
ttl
=
=
"
(
"
|
|
ttl
=
=
"
[
"
|
|
ttl
=
=
"
?
"
|
|
ttl
=
=
"
{
"
|
|
ttk
=
=
"
do
"
|
|
ttk
=
=
"
switch
"
|
|
ttk
=
=
"
case
"
|
|
ttk
=
=
"
default
"
)
;
}
function
shouldStackPop
(
token
stack
)
{
const
ttl
=
token
.
type
.
label
;
const
ttk
=
token
.
type
.
keyword
;
const
top
=
stack
.
at
(
-
1
)
;
return
(
ttl
=
=
"
]
"
|
|
ttl
=
=
"
)
"
|
|
ttl
=
=
"
}
"
|
|
(
ttl
=
=
"
:
"
&
&
(
top
=
=
"
case
"
|
|
top
=
=
"
default
"
|
|
top
=
=
"
?
"
)
)
|
|
(
ttk
=
=
"
while
"
&
&
top
=
=
"
do
"
)
)
;
}
function
decrementsIndent
(
tokenType
stack
)
{
const
top
=
stack
.
at
(
-
1
)
;
return
(
(
tokenType
=
=
"
}
"
&
&
top
!
=
"
{
"
)
|
|
(
tokenType
=
=
"
]
"
&
&
top
=
=
"
[
\
n
"
)
)
;
}
function
incrementsIndent
(
token
)
{
return
(
token
.
type
.
label
=
=
"
{
"
|
|
token
.
isArrayLiteral
|
|
token
.
type
.
keyword
=
=
"
switch
"
)
;
}
function
addComment
(
write
indentLevel
options
block
text
line
column
nextToken
)
{
const
indentString
=
options
.
indent
.
repeat
(
indentLevel
)
;
const
needNewLineAfter
=
!
block
|
|
!
(
nextToken
&
&
nextToken
.
loc
.
start
.
line
=
=
line
)
;
if
(
block
)
{
const
commentLinesText
=
text
.
split
(
new
RegExp
(
/
\
n
{
indentString
}
/
"
g
"
)
)
.
join
(
\
n
{
indentString
}
)
;
write
(
{
indentString
}
/
*
{
commentLinesText
}
*
/
{
needNewLineAfter
?
"
\
n
"
:
"
"
}
)
;
}
else
{
write
(
{
indentString
}
/
/
{
text
}
\
n
)
;
}
return
needNewLineAfter
;
}
export
function
prettyFast
(
input
options
=
{
}
)
{
let
indentLevel
=
0
;
const
{
url
:
file
}
=
options
;
const
sourceMapGenerator
=
new
sourceMap
.
SourceMapGenerator
(
{
file
}
)
;
let
currentCode
=
"
"
;
let
currentLine
=
1
;
let
currentColumn
=
0
;
const
write
=
(
str
line
column
isToken
)
=
>
{
currentCode
+
=
str
;
if
(
isToken
)
{
sourceMapGenerator
.
addMapping
(
{
source
:
file
generated
:
{
line
column
}
original
:
{
line
:
currentLine
column
:
currentColumn
}
name
:
null
}
)
;
}
for
(
let
idx
=
0
length
=
str
.
length
;
idx
<
length
;
idx
+
+
)
{
if
(
str
.
charCodeAt
(
idx
)
=
=
=
NEWLINE_CODE
)
{
currentLine
+
+
;
currentColumn
=
0
;
}
else
{
currentColumn
+
+
;
}
}
}
;
let
addedNewline
=
false
;
let
addedSpace
=
false
;
let
ttl
;
let
ttk
;
let
lastToken
;
const
stack
=
[
]
;
const
tokenQueue
=
getTokens
(
input
options
)
;
for
(
let
i
=
0
len
=
tokenQueue
.
length
;
i
<
len
;
i
+
+
)
{
const
token
=
tokenQueue
[
i
]
;
const
nextToken
=
tokenQueue
[
i
+
1
]
;
if
(
token
.
comment
)
{
let
commentIndentLevel
=
indentLevel
;
if
(
lastToken
?
.
loc
?
.
end
?
.
line
=
=
token
.
loc
.
start
.
line
)
{
commentIndentLevel
=
0
;
write
(
"
"
)
;
}
addedNewline
=
addComment
(
write
commentIndentLevel
options
token
.
block
token
.
text
token
.
loc
.
start
.
line
token
.
loc
.
start
.
column
nextToken
)
;
addedSpace
=
!
addedNewline
;
continue
;
}
ttk
=
token
.
type
.
keyword
;
if
(
ttk
&
&
lastToken
?
.
type
?
.
label
=
=
"
.
"
)
{
token
.
type
=
acorn
.
tokTypes
.
name
;
}
ttl
=
token
.
type
.
label
;
if
(
ttl
=
=
"
eof
"
)
{
if
(
!
addedNewline
)
{
write
(
"
\
n
"
)
;
}
break
;
}
token
.
isArrayLiteral
=
isArrayLiteral
(
token
lastToken
)
;
if
(
belongsOnStack
(
token
)
)
{
if
(
token
.
isArrayLiteral
)
{
stack
.
push
(
"
[
\
n
"
)
;
}
else
{
stack
.
push
(
ttl
|
|
ttk
)
;
}
}
if
(
decrementsIndent
(
ttl
stack
)
)
{
indentLevel
-
-
;
if
(
ttl
=
=
"
}
"
&
&
stack
.
at
(
-
2
)
=
=
"
switch
"
)
{
indentLevel
-
-
;
}
}
prependWhiteSpace
(
token
lastToken
addedNewline
addedSpace
write
options
indentLevel
stack
)
;
addToken
(
token
write
)
;
addedSpace
=
false
;
if
(
!
nextToken
|
|
!
nextToken
.
comment
|
|
token
.
loc
.
end
.
line
!
=
nextToken
.
loc
.
start
.
line
)
{
addedNewline
=
appendNewline
(
token
write
stack
)
;
}
if
(
shouldStackPop
(
token
stack
)
)
{
stack
.
pop
(
)
;
if
(
ttl
=
=
"
}
"
&
&
stack
.
at
(
-
1
)
=
=
"
switch
"
)
{
stack
.
pop
(
)
;
}
}
if
(
incrementsIndent
(
token
)
)
{
indentLevel
+
+
;
}
if
(
!
lastToken
)
{
lastToken
=
{
loc
:
{
start
:
{
}
end
:
{
}
}
}
;
}
lastToken
.
start
=
token
.
start
;
lastToken
.
end
=
token
.
end
;
lastToken
.
loc
.
start
.
line
=
token
.
loc
.
start
.
line
;
lastToken
.
loc
.
start
.
column
=
token
.
loc
.
start
.
column
;
lastToken
.
loc
.
end
.
line
=
token
.
loc
.
end
.
line
;
lastToken
.
loc
.
end
.
column
=
token
.
loc
.
end
.
column
;
lastToken
.
type
=
token
.
type
;
lastToken
.
value
=
token
.
value
;
lastToken
.
isArrayLiteral
=
token
.
isArrayLiteral
;
}
return
{
code
:
currentCode
map
:
sourceMapGenerator
}
;
}
function
getTokens
(
input
options
)
{
const
tokens
=
[
]
;
const
res
=
acorn
.
tokenizer
(
input
{
locations
:
true
ecmaVersion
:
options
.
ecmaVersion
|
|
"
latest
"
onComment
(
block
text
start
end
startLoc
endLoc
)
{
tokens
.
push
(
{
type
:
{
}
comment
:
true
block
text
loc
:
{
start
:
startLoc
end
:
endLoc
}
}
)
;
}
}
)
;
for
(
;
;
)
{
const
token
=
res
.
getToken
(
)
;
tokens
.
push
(
token
)
;
if
(
token
.
type
.
label
=
=
"
eof
"
)
{
break
;
}
}
return
tokens
;
}
