var
acorn
=
require
(
"
acorn
"
)
;
var
sourceMap
=
require
(
"
source
-
map
"
)
;
const
NEWLINE_CODE
=
10
;
export
function
prettyFast
(
input
options
)
{
return
new
PrettyFast
(
options
)
.
getPrettifiedCodeAndSourceMap
(
input
)
;
}
const
PRE_ARRAY_LITERAL_TOKENS
=
new
Set
(
[
"
typeof
"
"
void
"
"
delete
"
"
case
"
"
do
"
"
=
"
"
in
"
"
of
"
"
.
.
.
"
"
{
"
"
*
"
"
/
"
"
%
"
"
else
"
"
;
"
"
+
+
"
"
-
-
"
"
+
"
"
-
"
"
~
"
"
!
"
"
:
"
"
?
"
"
>
>
"
"
>
>
>
"
"
<
<
"
"
|
|
"
"
&
&
"
"
<
"
"
>
"
"
<
=
"
"
>
=
"
"
instanceof
"
"
&
"
"
^
"
"
|
"
"
=
=
"
"
!
=
"
"
=
=
=
"
"
!
=
=
"
"
"
"
}
"
]
)
;
const
PRE_OBJECT_LITERAL_TOKENS
=
new
Set
(
[
"
typeof
"
"
void
"
"
delete
"
"
=
"
"
in
"
"
of
"
"
.
.
.
"
"
*
"
"
/
"
"
%
"
"
+
+
"
"
-
-
"
"
+
"
"
-
"
"
~
"
"
!
"
"
>
>
"
"
>
>
>
"
"
<
<
"
"
<
"
"
>
"
"
<
=
"
"
>
=
"
"
instanceof
"
"
&
"
"
^
"
"
|
"
"
=
=
"
"
!
=
"
"
=
=
=
"
"
!
=
=
"
]
)
;
class
PrettyFast
{
constructor
(
options
=
{
}
)
{
this
.
#
indentLevel
=
0
;
this
.
#
indentChar
=
options
.
indent
;
this
.
#
sourceMapGenerator
=
options
.
sourceMapGenerator
|
|
new
sourceMap
.
SourceMapGenerator
(
{
file
:
options
.
url
}
)
;
this
.
#
file
=
options
.
url
;
this
.
#
hasOriginalStartLine
=
"
originalStartLine
"
in
options
;
this
.
#
hasOriginalStartColumn
=
"
originalStartColumn
"
in
options
;
this
.
#
hasGeneratedStartLine
=
"
generatedStartLine
"
in
options
;
this
.
#
originalStartLine
=
options
.
originalStartLine
;
this
.
#
originalStartColumn
=
options
.
originalStartColumn
;
this
.
#
generatedStartLine
=
options
.
generatedStartLine
;
this
.
#
prefixWithNewLine
=
options
.
prefixWithNewLine
;
}
#
indentChar
;
#
indentLevel
;
#
file
;
#
hasOriginalStartLine
;
#
hasOriginalStartColumn
;
#
hasGeneratedStartLine
;
#
originalStartLine
;
#
originalStartColumn
;
#
prefixWithNewLine
;
#
generatedStartLine
;
#
sourceMapGenerator
;
#
addedNewline
=
false
;
#
addedSpace
=
false
;
#
currentCode
=
"
"
;
#
currentLine
=
1
;
#
currentColumn
=
0
;
#
lastToken
;
#
stack
=
[
]
;
getPrettifiedCodeAndSourceMap
(
input
)
{
if
(
this
.
#
prefixWithNewLine
)
{
this
.
#
write
(
"
\
n
"
)
;
}
const
tokenQueue
=
this
.
#
getTokens
(
input
)
;
for
(
let
i
=
0
len
=
tokenQueue
.
length
;
i
<
len
;
i
+
+
)
{
const
token
=
tokenQueue
[
i
]
;
const
nextToken
=
tokenQueue
[
i
+
1
]
;
this
.
#
handleToken
(
token
nextToken
)
;
if
(
!
this
.
#
lastToken
)
{
this
.
#
lastToken
=
{
loc
:
{
start
:
{
}
end
:
{
}
}
}
;
}
this
.
#
lastToken
.
start
=
token
.
start
;
this
.
#
lastToken
.
end
=
token
.
end
;
this
.
#
lastToken
.
loc
.
start
.
line
=
token
.
loc
.
start
.
line
;
this
.
#
lastToken
.
loc
.
start
.
column
=
token
.
loc
.
start
.
column
;
this
.
#
lastToken
.
loc
.
end
.
line
=
token
.
loc
.
end
.
line
;
this
.
#
lastToken
.
loc
.
end
.
column
=
token
.
loc
.
end
.
column
;
this
.
#
lastToken
.
type
=
token
.
type
;
this
.
#
lastToken
.
value
=
token
.
value
;
}
return
{
code
:
this
.
#
currentCode
map
:
this
.
#
sourceMapGenerator
}
;
}
#
write
(
str
line
column
isToken
)
{
this
.
#
currentCode
+
=
str
;
if
(
isToken
)
{
this
.
#
sourceMapGenerator
.
addMapping
(
{
source
:
this
.
#
file
generated
:
{
line
:
this
.
#
hasOriginalStartLine
?
line
+
(
this
.
#
originalStartLine
-
1
)
:
line
column
:
line
=
=
1
&
&
this
.
#
hasOriginalStartColumn
?
column
+
this
.
#
originalStartColumn
:
column
}
original
:
{
line
:
this
.
#
hasGeneratedStartLine
?
this
.
#
currentLine
+
(
this
.
#
generatedStartLine
-
1
)
:
this
.
#
currentLine
column
:
this
.
#
currentColumn
}
name
:
null
}
)
;
}
for
(
let
idx
=
0
length
=
str
.
length
;
idx
<
length
;
idx
+
+
)
{
if
(
str
.
charCodeAt
(
idx
)
=
=
=
NEWLINE_CODE
)
{
this
.
#
currentLine
+
+
;
this
.
#
currentColumn
=
0
;
}
else
{
this
.
#
currentColumn
+
+
;
}
}
}
#
writeToken
(
token
)
{
if
(
token
.
type
.
label
=
=
"
string
"
)
{
this
.
#
write
(
'
{
sanitize
(
token
.
value
)
}
'
token
.
loc
.
start
.
line
token
.
loc
.
start
.
column
true
)
;
}
else
if
(
token
.
type
.
label
=
=
"
regexp
"
)
{
this
.
#
write
(
String
(
token
.
value
.
value
)
token
.
loc
.
start
.
line
token
.
loc
.
start
.
column
true
)
;
}
else
{
let
value
;
if
(
token
.
value
!
=
null
)
{
value
=
token
.
value
;
if
(
token
.
type
.
label
=
=
=
"
privateId
"
)
{
value
=
#
{
value
}
;
}
}
else
{
value
=
token
.
type
.
label
;
}
this
.
#
write
(
String
(
value
)
token
.
loc
.
start
.
line
token
.
loc
.
start
.
column
true
)
;
}
}
#
getTokens
(
input
)
{
const
tokens
=
[
]
;
const
res
=
acorn
.
tokenizer
(
input
{
locations
:
true
ecmaVersion
:
"
latest
"
onComment
(
block
text
start
end
startLoc
endLoc
)
{
tokens
.
push
(
{
type
:
{
}
comment
:
true
block
text
loc
:
{
start
:
startLoc
end
:
endLoc
}
}
)
;
}
}
)
;
for
(
;
;
)
{
const
token
=
res
.
getToken
(
)
;
tokens
.
push
(
token
)
;
if
(
token
.
type
.
label
=
=
"
eof
"
)
{
break
;
}
}
return
tokens
;
}
#
handleToken
(
token
nextToken
)
{
if
(
token
.
comment
)
{
let
commentIndentLevel
=
this
.
#
indentLevel
;
if
(
this
.
#
lastToken
?
.
loc
?
.
end
?
.
line
=
=
token
.
loc
.
start
.
line
)
{
commentIndentLevel
=
0
;
this
.
#
write
(
"
"
)
;
}
this
.
#
addComment
(
commentIndentLevel
token
.
block
token
.
text
token
.
loc
.
start
.
line
nextToken
)
;
return
;
}
const
ttk
=
token
.
type
.
keyword
;
if
(
ttk
&
&
this
.
#
lastToken
?
.
type
?
.
label
=
=
"
.
"
)
{
token
.
type
=
acorn
.
tokTypes
.
name
;
}
const
ttl
=
token
.
type
.
label
;
if
(
ttl
=
=
"
eof
"
)
{
if
(
!
this
.
#
addedNewline
)
{
this
.
#
write
(
"
\
n
"
)
;
}
return
;
}
if
(
belongsOnStack
(
token
)
)
{
let
stackEntry
;
if
(
isArrayLiteral
(
token
this
.
#
lastToken
)
)
{
stackEntry
=
nextToken
?
.
type
?
.
label
=
=
=
"
]
"
?
"
[
"
:
"
[
\
n
"
;
}
else
if
(
isObjectLiteral
(
token
this
.
#
lastToken
)
)
{
stackEntry
=
nextToken
?
.
type
?
.
label
=
=
=
"
}
"
?
"
{
"
:
"
{
\
n
"
;
}
else
if
(
ttl
=
=
"
{
"
)
{
stackEntry
=
"
{
\
n
"
;
}
else
{
stackEntry
=
ttl
|
|
ttk
;
}
this
.
#
stack
.
push
(
stackEntry
)
;
}
this
.
#
maybeDecrementIndent
(
token
)
;
this
.
#
prependWhiteSpace
(
token
)
;
this
.
#
writeToken
(
token
)
;
this
.
#
addedSpace
=
false
;
if
(
!
nextToken
|
|
!
nextToken
.
comment
|
|
token
.
loc
.
end
.
line
!
=
nextToken
.
loc
.
start
.
line
)
{
this
.
#
maybeAppendNewline
(
token
)
;
}
this
.
#
maybePopStack
(
token
)
;
this
.
#
maybeIncrementIndent
(
token
)
;
}
#
maybePopStack
(
token
)
{
const
ttl
=
token
.
type
.
label
;
const
ttk
=
token
.
type
.
keyword
;
const
top
=
this
.
#
stack
.
at
(
-
1
)
;
if
(
ttl
=
=
"
]
"
|
|
ttl
=
=
"
)
"
|
|
ttl
=
=
"
}
"
|
|
(
ttl
=
=
"
:
"
&
&
(
top
=
=
"
case
"
|
|
top
=
=
"
default
"
|
|
top
=
=
"
?
"
)
)
|
|
(
ttk
=
=
"
while
"
&
&
top
=
=
"
do
"
)
)
{
this
.
#
stack
.
pop
(
)
;
if
(
ttl
=
=
"
}
"
&
&
this
.
#
stack
.
at
(
-
1
)
=
=
"
switch
"
)
{
this
.
#
stack
.
pop
(
)
;
}
}
}
#
maybeIncrementIndent
(
token
)
{
if
(
(
token
.
type
.
label
=
=
"
{
"
&
&
this
.
#
stack
.
at
(
-
1
)
=
=
=
"
{
\
n
"
)
|
|
(
token
.
type
.
label
=
=
"
[
"
&
&
this
.
#
stack
.
at
(
-
1
)
=
=
=
"
[
\
n
"
)
|
|
token
.
type
.
keyword
=
=
"
switch
"
)
{
this
.
#
indentLevel
+
+
;
}
}
#
shouldDecrementIndent
(
token
)
{
const
top
=
this
.
#
stack
.
at
(
-
1
)
;
const
ttl
=
token
.
type
.
label
;
return
(
ttl
=
=
"
}
"
&
&
top
=
=
"
{
\
n
"
)
|
|
(
ttl
=
=
"
]
"
&
&
top
=
=
"
[
\
n
"
)
;
}
#
maybeDecrementIndent
(
token
)
{
if
(
!
this
.
#
shouldDecrementIndent
(
token
)
)
{
return
;
}
const
ttl
=
token
.
type
.
label
;
this
.
#
indentLevel
-
-
;
if
(
ttl
=
=
"
}
"
&
&
this
.
#
stack
.
at
(
-
2
)
=
=
"
switch
"
)
{
this
.
#
indentLevel
-
-
;
}
}
#
addComment
(
indentLevel
block
text
line
nextToken
)
{
const
indentString
=
this
.
#
indentChar
.
repeat
(
indentLevel
)
;
const
needNewLineAfter
=
!
block
|
|
!
(
nextToken
&
&
nextToken
.
loc
.
start
.
line
=
=
line
)
;
if
(
block
)
{
const
commentLinesText
=
text
.
split
(
new
RegExp
(
/
\
n
{
indentString
}
/
"
g
"
)
)
.
join
(
\
n
{
indentString
}
)
;
this
.
#
write
(
{
indentString
}
/
*
{
commentLinesText
}
*
/
{
needNewLineAfter
?
"
\
n
"
:
"
"
}
)
;
}
else
{
this
.
#
write
(
{
indentString
}
/
/
{
text
}
\
n
)
;
}
this
.
#
addedNewline
=
needNewLineAfter
;
this
.
#
addedSpace
=
!
needNewLineAfter
;
}
#
prependWhiteSpace
(
token
)
{
const
ttk
=
token
.
type
.
keyword
;
const
ttl
=
token
.
type
.
label
;
let
newlineAdded
=
this
.
#
addedNewline
;
let
spaceAdded
=
this
.
#
addedSpace
;
const
ltt
=
this
.
#
lastToken
?
.
type
?
.
label
;
if
(
this
.
#
lastToken
&
&
ltt
=
=
"
}
"
)
{
if
(
(
ttk
=
=
"
while
"
&
&
this
.
#
stack
.
at
(
-
1
)
=
=
"
do
"
)
|
|
needsSpaceBeforeClosingCurlyBracket
(
ttk
)
)
{
this
.
#
write
(
"
"
)
;
spaceAdded
=
true
;
}
else
if
(
needsLineBreakBeforeClosingCurlyBracket
(
ttl
)
)
{
this
.
#
write
(
"
\
n
"
)
;
newlineAdded
=
true
;
}
}
if
(
(
ttl
=
=
"
:
"
&
&
this
.
#
stack
.
at
(
-
1
)
=
=
"
?
"
)
|
|
(
ttl
=
=
"
}
"
&
&
this
.
#
stack
.
at
(
-
1
)
=
=
"
{
"
)
)
{
this
.
#
write
(
"
"
)
;
spaceAdded
=
true
;
}
if
(
this
.
#
lastToken
&
&
ltt
!
=
"
}
"
&
&
ltt
!
=
"
.
"
&
&
ttk
=
=
"
else
"
)
{
this
.
#
write
(
"
"
)
;
spaceAdded
=
true
;
}
const
ensureNewline
=
(
)
=
>
{
if
(
!
newlineAdded
)
{
this
.
#
write
(
"
\
n
"
)
;
newlineAdded
=
true
;
}
}
;
if
(
isASI
(
token
this
.
#
lastToken
)
)
{
ensureNewline
(
)
;
}
if
(
this
.
#
shouldDecrementIndent
(
token
)
)
{
ensureNewline
(
)
;
}
if
(
newlineAdded
)
{
let
indentLevel
=
this
.
#
indentLevel
;
if
(
ttk
=
=
"
case
"
|
|
ttk
=
=
"
default
"
)
{
indentLevel
-
-
;
}
this
.
#
write
(
this
.
#
indentChar
.
repeat
(
indentLevel
)
)
;
}
else
if
(
!
spaceAdded
&
&
needsSpaceAfter
(
token
this
.
#
lastToken
)
)
{
this
.
#
write
(
"
"
)
;
spaceAdded
=
true
;
}
}
#
maybeAppendNewline
(
token
)
{
if
(
!
isLineDelimiter
(
token
this
.
#
stack
)
)
{
this
.
#
addedNewline
=
false
;
return
;
}
this
.
#
write
(
"
\
n
"
)
;
this
.
#
addedNewline
=
true
;
}
}
function
isArrayLiteral
(
token
lastToken
)
{
if
(
token
.
type
.
label
!
=
"
[
"
)
{
return
false
;
}
if
(
!
lastToken
)
{
return
true
;
}
if
(
lastToken
.
type
.
isAssign
)
{
return
true
;
}
return
PRE_ARRAY_LITERAL_TOKENS
.
has
(
lastToken
.
type
.
keyword
|
|
(
lastToken
.
type
.
label
=
=
"
name
"
?
lastToken
.
value
:
lastToken
.
type
.
label
)
)
;
}
function
isObjectLiteral
(
token
lastToken
)
{
if
(
token
.
type
.
label
!
=
"
{
"
)
{
return
false
;
}
if
(
!
lastToken
)
{
return
false
;
}
if
(
lastToken
.
type
.
isAssign
)
{
return
true
;
}
return
PRE_OBJECT_LITERAL_TOKENS
.
has
(
lastToken
.
type
.
keyword
|
|
lastToken
.
type
.
label
)
;
}
const
PREVENT_ASI_AFTER_TOKENS
=
new
Set
(
[
"
*
"
"
/
"
"
%
"
"
+
"
"
-
"
"
<
<
"
"
>
>
"
"
>
>
>
"
"
<
"
"
>
"
"
<
=
"
"
>
=
"
"
instanceof
"
"
in
"
"
=
=
"
"
!
=
"
"
=
=
=
"
"
!
=
=
"
"
&
"
"
^
"
"
|
"
"
&
&
"
"
|
|
"
"
"
"
.
"
"
=
"
"
*
=
"
"
/
=
"
"
%
=
"
"
+
=
"
"
-
=
"
"
<
<
=
"
"
>
>
=
"
"
>
>
>
=
"
"
&
=
"
"
^
=
"
"
|
=
"
"
delete
"
"
void
"
"
typeof
"
"
~
"
"
!
"
"
new
"
"
(
"
]
)
;
const
PREVENT_ASI_BEFORE_TOKENS
=
new
Set
(
[
"
*
"
"
/
"
"
%
"
"
<
<
"
"
>
>
"
"
>
>
>
"
"
<
"
"
>
"
"
<
=
"
"
>
=
"
"
instanceof
"
"
in
"
"
=
=
"
"
!
=
"
"
=
=
=
"
"
!
=
=
"
"
&
"
"
^
"
"
|
"
"
&
&
"
"
|
|
"
"
"
"
.
"
"
=
"
"
*
=
"
"
/
=
"
"
%
=
"
"
+
=
"
"
-
=
"
"
<
<
=
"
"
>
>
=
"
"
>
>
>
=
"
"
&
=
"
"
^
=
"
"
|
=
"
"
(
"
]
)
;
function
isIdentifierLike
(
token
)
{
const
ttl
=
token
.
type
.
label
;
return
(
ttl
=
=
"
name
"
|
|
ttl
=
=
"
num
"
|
|
ttl
=
=
"
privateId
"
|
|
!
!
token
.
type
.
keyword
)
;
}
function
isASI
(
token
lastToken
)
{
if
(
!
lastToken
)
{
return
false
;
}
if
(
token
.
loc
.
start
.
line
=
=
=
lastToken
.
loc
.
start
.
line
)
{
return
false
;
}
if
(
lastToken
.
type
.
keyword
=
=
"
return
"
|
|
lastToken
.
type
.
keyword
=
=
"
yield
"
|
|
(
lastToken
.
type
.
label
=
=
"
name
"
&
&
lastToken
.
value
=
=
"
yield
"
)
)
{
return
true
;
}
if
(
PREVENT_ASI_AFTER_TOKENS
.
has
(
lastToken
.
type
.
label
|
|
lastToken
.
type
.
keyword
)
)
{
return
false
;
}
if
(
PREVENT_ASI_BEFORE_TOKENS
.
has
(
token
.
type
.
label
|
|
token
.
type
.
keyword
)
)
{
return
false
;
}
return
true
;
}
function
isLineDelimiter
(
token
stack
)
{
const
ttl
=
token
.
type
.
label
;
const
top
=
stack
.
at
(
-
1
)
;
return
(
(
ttl
=
=
"
;
"
&
&
top
!
=
"
(
"
)
|
|
(
ttl
=
=
"
{
"
&
&
top
=
=
"
{
\
n
"
)
|
|
(
ttl
=
=
"
[
"
&
&
top
=
=
"
[
\
n
"
)
|
|
(
ttl
=
=
"
"
&
&
top
!
=
"
(
"
)
|
|
(
ttl
=
=
"
:
"
&
&
(
top
=
=
"
case
"
|
|
top
=
=
"
default
"
)
)
)
;
}
function
needsSpaceAfter
(
token
lastToken
)
{
if
(
lastToken
&
&
needsSpaceBetweenTokens
(
token
lastToken
)
)
{
return
true
;
}
if
(
token
.
type
.
isAssign
)
{
return
true
;
}
if
(
token
.
type
.
binop
!
=
null
&
&
lastToken
)
{
return
true
;
}
if
(
token
.
type
.
label
=
=
"
?
"
)
{
return
true
;
}
return
false
;
}
function
needsSpaceBeforeLastToken
(
lastToken
)
{
if
(
lastToken
.
type
.
isLoop
)
{
return
true
;
}
if
(
lastToken
.
type
.
isAssign
)
{
return
true
;
}
if
(
lastToken
.
type
.
binop
!
=
null
)
{
return
true
;
}
if
(
lastToken
.
value
=
=
"
of
"
)
{
return
true
;
}
const
lastTokenTypeLabel
=
lastToken
.
type
.
label
;
if
(
lastTokenTypeLabel
=
=
"
?
"
)
{
return
true
;
}
if
(
lastTokenTypeLabel
=
=
"
:
"
)
{
return
true
;
}
if
(
lastTokenTypeLabel
=
=
"
"
)
{
return
true
;
}
if
(
lastTokenTypeLabel
=
=
"
;
"
)
{
return
true
;
}
if
(
lastTokenTypeLabel
=
=
"
{
"
)
{
return
true
;
}
return
false
;
}
function
isBreakContinueOrReturnStatement
(
lastTokenKeyword
)
{
return
(
lastTokenKeyword
=
=
"
break
"
|
|
lastTokenKeyword
=
=
"
continue
"
|
|
lastTokenKeyword
=
=
"
return
"
)
;
}
function
needsSpaceBeforeLastTokenKeywordAfterNotDot
(
lastTokenKeyword
)
{
return
(
lastTokenKeyword
!
=
"
debugger
"
&
&
lastTokenKeyword
!
=
"
null
"
&
&
lastTokenKeyword
!
=
"
true
"
&
&
lastTokenKeyword
!
=
"
false
"
&
&
lastTokenKeyword
!
=
"
this
"
&
&
lastTokenKeyword
!
=
"
default
"
)
;
}
function
needsSpaceBeforeClosingParen
(
tokenTypeLabel
)
{
return
(
tokenTypeLabel
!
=
"
)
"
&
&
tokenTypeLabel
!
=
"
]
"
&
&
tokenTypeLabel
!
=
"
;
"
&
&
tokenTypeLabel
!
=
"
"
&
&
tokenTypeLabel
!
=
"
.
"
)
;
}
function
needsSpaceBetweenTokens
(
token
lastToken
)
{
if
(
needsSpaceBeforeLastToken
(
lastToken
)
)
{
return
true
;
}
const
ltt
=
lastToken
.
type
.
label
;
if
(
ltt
=
=
"
num
"
&
&
token
.
type
.
label
=
=
"
.
"
)
{
return
true
;
}
const
ltk
=
lastToken
.
type
.
keyword
;
const
ttl
=
token
.
type
.
label
;
if
(
ltk
!
=
null
&
&
ttl
!
=
"
.
"
)
{
if
(
isBreakContinueOrReturnStatement
(
ltk
)
)
{
return
ttl
!
=
"
;
"
;
}
if
(
needsSpaceBeforeLastTokenKeywordAfterNotDot
(
ltk
)
)
{
return
true
;
}
}
if
(
ltt
=
=
"
)
"
&
&
needsSpaceBeforeClosingParen
(
ttl
)
)
{
return
true
;
}
if
(
isIdentifierLike
(
token
)
&
&
isIdentifierLike
(
lastToken
)
)
{
return
true
;
}
if
(
token
.
type
.
label
=
=
"
{
"
&
&
lastToken
.
type
.
label
=
=
"
name
"
)
{
return
true
;
}
return
false
;
}
function
needsSpaceBeforeClosingCurlyBracket
(
tokenTypeKeyword
)
{
return
(
tokenTypeKeyword
=
=
"
else
"
|
|
tokenTypeKeyword
=
=
"
catch
"
|
|
tokenTypeKeyword
=
=
"
finally
"
)
;
}
function
needsLineBreakBeforeClosingCurlyBracket
(
tokenTypeLabel
)
{
return
(
tokenTypeLabel
!
=
"
(
"
&
&
tokenTypeLabel
!
=
"
;
"
&
&
tokenTypeLabel
!
=
"
"
&
&
tokenTypeLabel
!
=
"
)
"
&
&
tokenTypeLabel
!
=
"
.
"
&
&
tokenTypeLabel
!
=
"
template
"
&
&
tokenTypeLabel
!
=
"
"
)
;
}
const
escapeCharacters
=
{
"
\
\
"
:
"
\
\
\
\
"
"
\
n
"
:
"
\
\
n
"
"
\
r
"
:
"
\
\
r
"
"
\
t
"
:
"
\
\
t
"
"
\
v
"
:
"
\
\
v
"
"
\
f
"
:
"
\
\
f
"
"
\
0
"
:
"
\
\
x00
"
"
\
u2028
"
:
"
\
\
u2028
"
"
\
u2029
"
:
"
\
\
u2029
"
"
'
"
:
"
\
\
'
"
}
;
const
regExpString
=
"
(
"
+
Object
.
values
(
escapeCharacters
)
.
join
(
"
|
"
)
+
"
)
"
;
const
escapeCharactersRegExp
=
new
RegExp
(
regExpString
"
g
"
)
;
function
sanitizerReplaceFunc
(
_
c
)
{
return
escapeCharacters
[
c
]
;
}
function
sanitize
(
str
)
{
return
str
.
replace
(
escapeCharactersRegExp
sanitizerReplaceFunc
)
;
}
function
belongsOnStack
(
token
)
{
const
ttl
=
token
.
type
.
label
;
const
ttk
=
token
.
type
.
keyword
;
return
(
ttl
=
=
"
{
"
|
|
ttl
=
=
"
(
"
|
|
ttl
=
=
"
[
"
|
|
ttl
=
=
"
?
"
|
|
ttl
=
=
"
{
"
|
|
ttk
=
=
"
do
"
|
|
ttk
=
=
"
switch
"
|
|
ttk
=
=
"
case
"
|
|
ttk
=
=
"
default
"
)
;
}
