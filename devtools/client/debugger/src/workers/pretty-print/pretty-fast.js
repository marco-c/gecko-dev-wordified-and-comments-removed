var
acorn
=
require
(
"
acorn
"
)
;
var
sourceMap
=
require
(
"
source
-
map
"
)
;
var
SourceNode
=
sourceMap
.
SourceNode
;
const
PRE_ARRAY_LITERAL_TOKENS
=
{
typeof
:
true
void
:
true
delete
:
true
case
:
true
do
:
true
"
=
"
:
true
in
:
true
"
{
"
:
true
"
*
"
:
true
"
/
"
:
true
"
%
"
:
true
else
:
true
"
;
"
:
true
"
+
+
"
:
true
"
-
-
"
:
true
"
+
"
:
true
"
-
"
:
true
"
~
"
:
true
"
!
"
:
true
"
:
"
:
true
"
?
"
:
true
"
>
>
"
:
true
"
>
>
>
"
:
true
"
<
<
"
:
true
"
|
|
"
:
true
"
&
&
"
:
true
"
<
"
:
true
"
>
"
:
true
"
<
=
"
:
true
"
>
=
"
:
true
instanceof
:
true
"
&
"
:
true
"
^
"
:
true
"
|
"
:
true
"
=
=
"
:
true
"
!
=
"
:
true
"
=
=
=
"
:
true
"
!
=
=
"
:
true
"
"
:
true
"
}
"
:
true
}
;
function
isArrayLiteral
(
token
lastToken
)
{
if
(
token
.
type
.
label
!
=
"
[
"
)
{
return
false
;
}
if
(
!
lastToken
)
{
return
true
;
}
if
(
lastToken
.
type
.
isAssign
)
{
return
true
;
}
return
!
!
PRE_ARRAY_LITERAL_TOKENS
[
lastToken
.
type
.
keyword
|
|
lastToken
.
type
.
label
]
;
}
const
PREVENT_ASI_AFTER_TOKENS
=
{
"
*
"
:
true
"
/
"
:
true
"
%
"
:
true
"
+
"
:
true
"
-
"
:
true
"
<
<
"
:
true
"
>
>
"
:
true
"
>
>
>
"
:
true
"
<
"
:
true
"
>
"
:
true
"
<
=
"
:
true
"
>
=
"
:
true
instanceof
:
true
in
:
true
"
=
=
"
:
true
"
!
=
"
:
true
"
=
=
=
"
:
true
"
!
=
=
"
:
true
"
&
"
:
true
"
^
"
:
true
"
|
"
:
true
"
&
&
"
:
true
"
|
|
"
:
true
"
"
:
true
"
.
"
:
true
"
=
"
:
true
"
*
=
"
:
true
"
/
=
"
:
true
"
%
=
"
:
true
"
+
=
"
:
true
"
-
=
"
:
true
"
<
<
=
"
:
true
"
>
>
=
"
:
true
"
>
>
>
=
"
:
true
"
&
=
"
:
true
"
^
=
"
:
true
"
|
=
"
:
true
delete
:
true
void
:
true
typeof
:
true
"
~
"
:
true
"
!
"
:
true
new
:
true
"
(
"
:
true
}
;
const
PREVENT_ASI_BEFORE_TOKENS
=
{
"
*
"
:
true
"
/
"
:
true
"
%
"
:
true
"
<
<
"
:
true
"
>
>
"
:
true
"
>
>
>
"
:
true
"
<
"
:
true
"
>
"
:
true
"
<
=
"
:
true
"
>
=
"
:
true
instanceof
:
true
in
:
true
"
=
=
"
:
true
"
!
=
"
:
true
"
=
=
=
"
:
true
"
!
=
=
"
:
true
"
&
"
:
true
"
^
"
:
true
"
|
"
:
true
"
&
&
"
:
true
"
|
|
"
:
true
"
"
:
true
"
.
"
:
true
"
=
"
:
true
"
*
=
"
:
true
"
/
=
"
:
true
"
%
=
"
:
true
"
+
=
"
:
true
"
-
=
"
:
true
"
<
<
=
"
:
true
"
>
>
=
"
:
true
"
>
>
>
=
"
:
true
"
&
=
"
:
true
"
^
=
"
:
true
"
|
=
"
:
true
"
(
"
:
true
}
;
function
isIdentifierLike
(
token
)
{
const
ttl
=
token
.
type
.
label
;
return
(
ttl
=
=
"
name
"
|
|
ttl
=
=
"
num
"
|
|
ttl
=
=
"
privateId
"
|
|
!
!
token
.
type
.
keyword
)
;
}
function
isASI
(
token
lastToken
)
{
if
(
!
lastToken
)
{
return
false
;
}
if
(
token
.
loc
.
start
.
line
=
=
=
lastToken
.
loc
.
start
.
line
)
{
return
false
;
}
if
(
lastToken
.
type
.
keyword
=
=
"
return
"
|
|
lastToken
.
type
.
keyword
=
=
"
yield
"
|
|
(
lastToken
.
type
.
label
=
=
"
name
"
&
&
lastToken
.
value
=
=
"
yield
"
)
)
{
return
true
;
}
if
(
PREVENT_ASI_AFTER_TOKENS
[
lastToken
.
type
.
label
|
|
lastToken
.
type
.
keyword
]
)
{
return
false
;
}
if
(
PREVENT_ASI_BEFORE_TOKENS
[
token
.
type
.
label
|
|
token
.
type
.
keyword
]
)
{
return
false
;
}
return
true
;
}
function
isLineDelimiter
(
token
stack
)
{
if
(
token
.
isArrayLiteral
)
{
return
true
;
}
const
ttl
=
token
.
type
.
label
;
const
top
=
stack
[
stack
.
length
-
1
]
;
return
(
(
ttl
=
=
"
;
"
&
&
top
!
=
"
(
"
)
|
|
ttl
=
=
"
{
"
|
|
(
ttl
=
=
"
"
&
&
top
!
=
"
(
"
)
|
|
(
ttl
=
=
"
:
"
&
&
(
top
=
=
"
case
"
|
|
top
=
=
"
default
"
)
)
)
;
}
function
appendNewline
(
token
write
stack
)
{
if
(
isLineDelimiter
(
token
stack
)
)
{
write
(
"
\
n
"
token
.
loc
.
start
.
line
token
.
loc
.
start
.
column
)
;
return
true
;
}
return
false
;
}
function
needsSpaceAfter
(
token
lastToken
)
{
if
(
lastToken
)
{
if
(
lastToken
.
type
.
isLoop
)
{
return
true
;
}
if
(
lastToken
.
type
.
isAssign
)
{
return
true
;
}
if
(
lastToken
.
type
.
binop
!
=
null
)
{
return
true
;
}
const
ltt
=
lastToken
.
type
.
label
;
if
(
ltt
=
=
"
?
"
)
{
return
true
;
}
if
(
ltt
=
=
"
:
"
)
{
return
true
;
}
if
(
ltt
=
=
"
"
)
{
return
true
;
}
if
(
ltt
=
=
"
;
"
)
{
return
true
;
}
if
(
ltt
=
=
"
{
"
)
{
return
true
;
}
if
(
ltt
=
=
"
num
"
&
&
token
.
type
.
label
=
=
"
.
"
)
{
return
true
;
}
const
ltk
=
lastToken
.
type
.
keyword
;
const
ttl
=
token
.
type
.
label
;
if
(
ltk
!
=
null
&
&
ttl
!
=
"
.
"
)
{
if
(
ltk
=
=
"
break
"
|
|
ltk
=
=
"
continue
"
|
|
ltk
=
=
"
return
"
)
{
return
token
.
type
.
label
!
=
"
;
"
;
}
if
(
ltk
!
=
"
debugger
"
&
&
ltk
!
=
"
null
"
&
&
ltk
!
=
"
true
"
&
&
ltk
!
=
"
false
"
&
&
ltk
!
=
"
this
"
&
&
ltk
!
=
"
default
"
)
{
return
true
;
}
}
if
(
ltt
=
=
"
)
"
&
&
token
.
type
.
label
!
=
"
)
"
&
&
token
.
type
.
label
!
=
"
]
"
&
&
token
.
type
.
label
!
=
"
;
"
&
&
token
.
type
.
label
!
=
"
"
&
&
token
.
type
.
label
!
=
"
.
"
)
{
return
true
;
}
if
(
isIdentifierLike
(
token
)
&
&
isIdentifierLike
(
lastToken
)
)
{
return
true
;
}
if
(
token
.
type
.
label
=
=
"
{
"
&
&
lastToken
.
type
.
label
=
=
"
name
"
)
{
return
true
;
}
}
if
(
token
.
type
.
isAssign
)
{
return
true
;
}
if
(
token
.
type
.
binop
!
=
null
&
&
lastToken
)
{
return
true
;
}
if
(
token
.
type
.
label
=
=
"
?
"
)
{
return
true
;
}
return
false
;
}
function
prependWhiteSpace
(
token
lastToken
addedNewline
addedSpace
write
options
indentLevel
stack
)
{
const
ttk
=
token
.
type
.
keyword
;
const
ttl
=
token
.
type
.
label
;
let
newlineAdded
=
addedNewline
;
let
spaceAdded
=
addedSpace
;
const
ltt
=
lastToken
?
lastToken
.
type
.
label
:
null
;
if
(
lastToken
&
&
ltt
=
=
"
}
"
)
{
if
(
ttk
=
=
"
while
"
&
&
stack
[
stack
.
length
-
1
]
=
=
"
do
"
)
{
write
(
"
"
lastToken
.
loc
.
start
.
line
lastToken
.
loc
.
start
.
column
)
;
spaceAdded
=
true
;
}
else
if
(
ttk
=
=
"
else
"
|
|
ttk
=
=
"
catch
"
|
|
ttk
=
=
"
finally
"
)
{
write
(
"
"
lastToken
.
loc
.
start
.
line
lastToken
.
loc
.
start
.
column
)
;
spaceAdded
=
true
;
}
else
if
(
ttl
!
=
"
(
"
&
&
ttl
!
=
"
;
"
&
&
ttl
!
=
"
"
&
&
ttl
!
=
"
)
"
&
&
ttl
!
=
"
.
"
&
&
ttl
!
=
"
template
"
&
&
ttl
!
=
"
"
)
{
write
(
"
\
n
"
lastToken
.
loc
.
start
.
line
lastToken
.
loc
.
start
.
column
)
;
newlineAdded
=
true
;
}
}
if
(
(
ttl
=
=
"
:
"
&
&
stack
[
stack
.
length
-
1
]
=
=
"
?
"
)
|
|
(
ttl
=
=
"
}
"
&
&
stack
[
stack
.
length
-
1
]
=
=
"
{
"
)
)
{
write
(
"
"
lastToken
.
loc
.
start
.
line
lastToken
.
loc
.
start
.
column
)
;
spaceAdded
=
true
;
}
if
(
lastToken
&
&
ltt
!
=
"
}
"
&
&
ltt
!
=
"
.
"
&
&
ttk
=
=
"
else
"
)
{
write
(
"
"
lastToken
.
loc
.
start
.
line
lastToken
.
loc
.
start
.
column
)
;
spaceAdded
=
true
;
}
function
ensureNewline
(
)
{
if
(
!
newlineAdded
)
{
write
(
"
\
n
"
lastToken
.
loc
.
start
.
line
lastToken
.
loc
.
start
.
column
)
;
newlineAdded
=
true
;
}
}
if
(
isASI
(
token
lastToken
)
)
{
ensureNewline
(
)
;
}
if
(
decrementsIndent
(
ttl
stack
)
)
{
ensureNewline
(
)
;
}
if
(
newlineAdded
)
{
if
(
ttk
=
=
"
case
"
|
|
ttk
=
=
"
default
"
)
{
write
(
repeat
(
options
.
indent
indentLevel
-
1
)
token
.
loc
.
start
.
line
token
.
loc
.
start
.
column
)
;
}
else
{
write
(
repeat
(
options
.
indent
indentLevel
)
token
.
loc
.
start
.
line
token
.
loc
.
start
.
column
)
;
}
}
else
if
(
!
spaceAdded
&
&
needsSpaceAfter
(
token
lastToken
)
)
{
write
(
"
"
lastToken
.
loc
.
start
.
line
lastToken
.
loc
.
start
.
column
)
;
spaceAdded
=
true
;
}
}
function
repeat
(
str
n
)
{
let
result
=
"
"
;
while
(
n
>
0
)
{
if
(
n
&
1
)
{
result
+
=
str
;
}
n
>
>
=
1
;
str
+
=
str
;
}
return
result
;
}
const
sanitize
=
(
function
(
)
{
const
escapeCharacters
=
{
"
\
\
"
:
"
\
\
\
\
"
"
\
n
"
:
"
\
\
n
"
"
\
r
"
:
"
\
\
r
"
"
\
t
"
:
"
\
\
t
"
"
\
v
"
:
"
\
\
v
"
"
\
f
"
:
"
\
\
f
"
"
\
0
"
:
"
\
\
x00
"
"
\
u2028
"
:
"
\
\
u2028
"
"
\
u2029
"
:
"
\
\
u2029
"
"
'
"
:
"
\
\
'
"
}
;
const
regExpString
=
"
(
"
+
Object
.
values
(
escapeCharacters
)
.
join
(
"
|
"
)
+
"
)
"
;
const
escapeCharactersRegExp
=
new
RegExp
(
regExpString
"
g
"
)
;
return
function
(
str
)
{
return
str
.
replace
(
escapeCharactersRegExp
function
(
_
c
)
{
return
escapeCharacters
[
c
]
;
}
)
;
}
;
}
)
(
)
;
function
addToken
(
token
write
)
{
if
(
token
.
type
.
label
=
=
"
string
"
)
{
write
(
'
{
sanitize
(
token
.
value
)
}
'
token
.
loc
.
start
.
line
token
.
loc
.
start
.
column
)
;
}
else
if
(
token
.
type
.
label
=
=
"
regexp
"
)
{
write
(
String
(
token
.
value
.
value
)
token
.
loc
.
start
.
line
token
.
loc
.
start
.
column
)
;
}
else
{
let
value
;
if
(
token
.
value
!
=
null
)
{
value
=
token
.
value
;
if
(
token
.
type
.
label
=
=
=
"
privateId
"
)
{
value
=
#
{
value
}
;
}
}
else
{
value
=
token
.
type
.
label
;
}
write
(
String
(
value
)
token
.
loc
.
start
.
line
token
.
loc
.
start
.
column
)
;
}
}
function
belongsOnStack
(
token
)
{
const
ttl
=
token
.
type
.
label
;
const
ttk
=
token
.
type
.
keyword
;
return
(
ttl
=
=
"
{
"
|
|
ttl
=
=
"
(
"
|
|
ttl
=
=
"
[
"
|
|
ttl
=
=
"
?
"
|
|
ttl
=
=
"
{
"
|
|
ttk
=
=
"
do
"
|
|
ttk
=
=
"
switch
"
|
|
ttk
=
=
"
case
"
|
|
ttk
=
=
"
default
"
)
;
}
function
shouldStackPop
(
token
stack
)
{
const
ttl
=
token
.
type
.
label
;
const
ttk
=
token
.
type
.
keyword
;
const
top
=
stack
[
stack
.
length
-
1
]
;
return
(
ttl
=
=
"
]
"
|
|
ttl
=
=
"
)
"
|
|
ttl
=
=
"
}
"
|
|
(
ttl
=
=
"
:
"
&
&
(
top
=
=
"
case
"
|
|
top
=
=
"
default
"
|
|
top
=
=
"
?
"
)
)
|
|
(
ttk
=
=
"
while
"
&
&
top
=
=
"
do
"
)
)
;
}
function
decrementsIndent
(
tokenType
stack
)
{
return
(
(
tokenType
=
=
"
}
"
&
&
stack
[
stack
.
length
-
1
]
!
=
"
{
"
)
|
|
(
tokenType
=
=
"
]
"
&
&
stack
[
stack
.
length
-
1
]
=
=
"
[
\
n
"
)
)
;
}
function
incrementsIndent
(
token
)
{
return
(
token
.
type
.
label
=
=
"
{
"
|
|
token
.
isArrayLiteral
|
|
token
.
type
.
keyword
=
=
"
switch
"
)
;
}
function
addComment
(
write
indentLevel
options
block
text
line
column
nextToken
)
{
const
indentString
=
repeat
(
options
.
indent
indentLevel
)
;
let
needNewline
=
true
;
write
(
indentString
line
column
)
;
if
(
block
)
{
write
(
"
/
*
"
)
;
write
(
text
.
split
(
new
RegExp
(
/
\
n
{
indentString
}
/
"
g
"
)
)
.
join
(
\
n
{
indentString
}
)
null
null
true
)
;
write
(
"
*
/
"
)
;
needNewline
=
!
(
nextToken
&
&
nextToken
.
loc
.
start
.
line
=
=
line
)
;
}
else
{
write
(
"
/
/
"
)
;
write
(
text
)
;
}
if
(
needNewline
)
{
write
(
"
\
n
"
)
;
}
else
{
write
(
"
"
)
;
}
return
needNewline
;
}
export
function
prettyFast
(
input
options
)
{
let
indentLevel
=
0
;
const
result
=
new
SourceNode
(
)
;
const
write
=
(
function
(
)
{
const
buffer
=
[
]
;
let
bufferLine
=
-
1
;
let
bufferColumn
=
-
1
;
return
function
innerWrite
(
str
line
column
ignoreNewline
)
{
if
(
line
!
=
null
&
&
bufferLine
=
=
=
-
1
)
{
bufferLine
=
line
;
}
if
(
column
!
=
null
&
&
bufferColumn
=
=
=
-
1
)
{
bufferColumn
=
column
;
}
buffer
.
push
(
str
)
;
if
(
str
=
=
"
\
n
"
&
&
!
ignoreNewline
)
{
let
lineStr
=
"
"
;
for
(
let
i
=
0
len
=
buffer
.
length
;
i
<
len
;
i
+
+
)
{
lineStr
+
=
buffer
[
i
]
;
}
result
.
add
(
new
SourceNode
(
bufferLine
bufferColumn
options
.
url
lineStr
)
)
;
buffer
.
splice
(
0
buffer
.
length
)
;
bufferLine
=
-
1
;
bufferColumn
=
-
1
;
}
}
;
}
)
(
)
;
let
addedNewline
=
false
;
let
addedSpace
=
false
;
let
token
;
let
ttl
;
let
ttk
;
let
lastToken
;
const
stack
=
[
]
;
const
tokenQueue
=
[
]
;
const
tokens
=
acorn
.
tokenizer
(
input
{
locations
:
true
sourceFile
:
options
.
url
ecmaVersion
:
options
.
ecmaVersion
|
|
"
latest
"
onComment
(
block
text
start
end
startLoc
endLoc
)
{
tokenQueue
.
push
(
{
type
:
{
}
comment
:
true
block
text
loc
:
{
start
:
startLoc
end
:
endLoc
}
}
)
;
}
}
)
;
for
(
;
;
)
{
token
=
tokens
.
getToken
(
)
;
tokenQueue
.
push
(
token
)
;
if
(
token
.
type
.
label
=
=
"
eof
"
)
{
break
;
}
}
for
(
let
i
=
0
;
i
<
tokenQueue
.
length
;
i
+
+
)
{
token
=
tokenQueue
[
i
]
;
const
nextToken
=
tokenQueue
[
i
+
1
]
;
if
(
token
.
comment
)
{
let
commentIndentLevel
=
indentLevel
;
if
(
lastToken
&
&
lastToken
.
loc
.
end
.
line
=
=
token
.
loc
.
start
.
line
)
{
commentIndentLevel
=
0
;
write
(
"
"
)
;
}
addedNewline
=
addComment
(
write
commentIndentLevel
options
token
.
block
token
.
text
token
.
loc
.
start
.
line
token
.
loc
.
start
.
column
nextToken
)
;
addedSpace
=
!
addedNewline
;
continue
;
}
ttk
=
token
.
type
.
keyword
;
if
(
ttk
&
&
lastToken
&
&
lastToken
.
type
.
label
=
=
"
.
"
)
{
token
.
type
=
acorn
.
tokTypes
.
name
;
}
ttl
=
token
.
type
.
label
;
if
(
ttl
=
=
"
eof
"
)
{
if
(
!
addedNewline
)
{
write
(
"
\
n
"
)
;
}
break
;
}
token
.
isArrayLiteral
=
isArrayLiteral
(
token
lastToken
)
;
if
(
belongsOnStack
(
token
)
)
{
if
(
token
.
isArrayLiteral
)
{
stack
.
push
(
"
[
\
n
"
)
;
}
else
{
stack
.
push
(
ttl
|
|
ttk
)
;
}
}
if
(
decrementsIndent
(
ttl
stack
)
)
{
indentLevel
-
-
;
if
(
ttl
=
=
"
}
"
&
&
stack
.
length
>
1
&
&
stack
[
stack
.
length
-
2
]
=
=
"
switch
"
)
{
indentLevel
-
-
;
}
}
prependWhiteSpace
(
token
lastToken
addedNewline
addedSpace
write
options
indentLevel
stack
)
;
addToken
(
token
write
)
;
addedSpace
=
false
;
if
(
!
nextToken
|
|
!
nextToken
.
comment
|
|
token
.
loc
.
end
.
line
!
=
nextToken
.
loc
.
start
.
line
)
{
addedNewline
=
appendNewline
(
token
write
stack
)
;
}
if
(
shouldStackPop
(
token
stack
)
)
{
stack
.
pop
(
)
;
if
(
ttl
=
=
"
}
"
&
&
stack
.
length
&
&
stack
[
stack
.
length
-
1
]
=
=
"
switch
"
)
{
stack
.
pop
(
)
;
}
}
if
(
incrementsIndent
(
token
)
)
{
indentLevel
+
+
;
}
if
(
!
lastToken
)
{
lastToken
=
{
loc
:
{
start
:
{
}
end
:
{
}
}
}
;
}
lastToken
.
start
=
token
.
start
;
lastToken
.
end
=
token
.
end
;
lastToken
.
loc
.
start
.
line
=
token
.
loc
.
start
.
line
;
lastToken
.
loc
.
start
.
column
=
token
.
loc
.
start
.
column
;
lastToken
.
loc
.
end
.
line
=
token
.
loc
.
end
.
line
;
lastToken
.
loc
.
end
.
column
=
token
.
loc
.
end
.
column
;
lastToken
.
type
=
token
.
type
;
lastToken
.
value
=
token
.
value
;
lastToken
.
isArrayLiteral
=
token
.
isArrayLiteral
;
}
return
result
.
toStringWithSourceMap
(
{
file
:
options
.
url
}
)
;
}
