"
use
strict
"
;
const
jsLexer
=
require
(
"
devtools
/
shared
/
css
/
lexer
"
)
;
const
InspectorUtils
=
require
(
"
InspectorUtils
"
)
;
function
DoubleLexer
(
input
)
{
info
(
"
DoubleLexer
input
:
"
+
input
)
;
this
.
domLexer
=
InspectorUtils
.
getCSSLexer
(
input
)
;
this
.
jsLexer
=
jsLexer
.
getCSSLexer
(
input
)
;
}
DoubleLexer
.
prototype
=
{
checkState
:
function
(
)
{
equal
(
this
.
domLexer
.
lineNumber
this
.
jsLexer
.
lineNumber
"
check
line
number
"
)
;
equal
(
this
.
domLexer
.
columnNumber
this
.
jsLexer
.
columnNumber
"
check
column
number
"
)
;
}
get
lineNumber
(
)
{
return
this
.
domLexer
.
lineNumber
;
}
get
columnNumber
(
)
{
return
this
.
domLexer
.
columnNumber
;
}
performEOFFixup
:
function
(
inputString
preserveBackslash
)
{
const
d
=
this
.
domLexer
.
performEOFFixup
(
inputString
preserveBackslash
)
;
const
j
=
this
.
jsLexer
.
performEOFFixup
(
inputString
preserveBackslash
)
;
equal
(
d
j
)
;
return
d
;
}
mungeNumber
:
function
(
token
)
{
if
(
token
&
&
(
token
.
tokenType
=
=
=
"
number
"
|
|
token
.
tokenType
=
=
=
"
percentage
"
)
&
&
!
token
.
isInteger
)
{
token
.
number
=
parseFloat
(
token
.
number
.
toPrecision
(
8
)
)
;
}
}
nextToken
:
function
(
)
{
this
.
checkState
(
)
;
const
d
=
this
.
domLexer
.
nextToken
(
)
;
const
j
=
this
.
jsLexer
.
nextToken
(
)
;
this
.
mungeNumber
(
d
)
;
this
.
mungeNumber
(
j
)
;
deepEqual
(
d
j
)
;
this
.
checkState
(
)
;
return
d
;
}
}
;
function
test_lexer
(
cssText
tokenTypes
)
{
const
lexer
=
new
DoubleLexer
(
cssText
)
;
let
reconstructed
=
"
"
;
let
lastTokenEnd
=
0
;
let
i
=
0
;
while
(
true
)
{
const
token
=
lexer
.
nextToken
(
)
;
if
(
!
token
)
{
break
;
}
let
combined
=
token
.
tokenType
;
if
(
token
.
text
)
{
combined
+
=
"
:
"
+
token
.
text
;
}
equal
(
combined
tokenTypes
[
i
]
)
;
ok
(
token
.
endOffset
>
token
.
startOffset
)
;
equal
(
token
.
startOffset
lastTokenEnd
)
;
lastTokenEnd
=
token
.
endOffset
;
reconstructed
+
=
cssText
.
substring
(
token
.
startOffset
token
.
endOffset
)
;
+
+
i
;
}
equal
(
i
tokenTypes
.
length
)
;
equal
(
reconstructed
cssText
)
;
}
var
LEX_TESTS
=
[
[
"
simple
"
[
"
ident
:
simple
"
]
]
[
"
simple
:
{
hi
;
}
"
[
"
ident
:
simple
"
"
symbol
:
:
"
"
whitespace
"
"
symbol
:
{
"
"
whitespace
"
"
ident
:
hi
"
"
symbol
:
;
"
"
whitespace
"
"
symbol
:
}
"
]
]
[
"
/
*
whatever
*
/
"
[
"
comment
"
]
]
[
"
'
string
'
"
[
"
string
:
string
"
]
]
[
'
"
string
"
'
[
"
string
:
string
"
]
]
[
"
rgb
(
1
2
3
)
"
[
"
function
:
rgb
"
"
number
"
"
symbol
:
"
"
number
"
"
symbol
:
"
"
number
"
"
symbol
:
)
"
]
]
[
"
media
"
[
"
at
:
media
"
]
]
[
"
#
hibob
"
[
"
id
:
hibob
"
]
]
[
"
#
123
"
[
"
hash
:
123
"
]
]
[
"
23px
"
[
"
dimension
:
px
"
]
]
[
"
23
%
"
[
"
percentage
"
]
]
[
"
url
(
http
:
/
/
example
.
com
)
"
[
"
url
:
http
:
/
/
example
.
com
"
]
]
[
"
url
(
'
http
:
/
/
example
.
com
'
)
"
[
"
url
:
http
:
/
/
example
.
com
"
]
]
[
"
url
(
'
http
:
/
/
example
.
com
'
)
"
[
"
url
:
http
:
/
/
example
.
com
"
]
]
[
"
url
(
http
:
/
/
example
.
com
"
[
"
url
:
http
:
/
/
example
.
com
"
]
]
[
"
url
(
http
:
/
/
example
.
com
"
[
"
bad_url
:
http
:
/
/
example
.
com
"
]
]
[
"
quo
\
\
ting
"
[
"
ident
:
quoting
"
]
]
[
"
'
bad
string
\
n
"
[
"
bad_string
:
bad
string
"
"
whitespace
"
]
]
[
"
~
=
"
[
"
includes
"
]
]
[
"
|
=
"
[
"
dashmatch
"
]
]
[
"
^
=
"
[
"
beginsmatch
"
]
]
[
"
=
"
[
"
endsmatch
"
]
]
[
"
*
=
"
[
"
containsmatch
"
]
]
[
"
<
!
-
-
html
comment
-
-
>
"
[
"
htmlcomment
"
"
whitespace
"
"
ident
:
html
"
"
whitespace
"
"
ident
:
comment
"
"
whitespace
"
"
htmlcomment
"
]
]
[
"
/
*
bad
comment
"
[
"
comment
"
]
]
]
;
function
test_lexer_linecol
(
cssText
locations
)
{
const
lexer
=
new
DoubleLexer
(
cssText
)
;
let
i
=
0
;
while
(
true
)
{
const
token
=
lexer
.
nextToken
(
)
;
const
startLine
=
lexer
.
lineNumber
;
const
startColumn
=
lexer
.
columnNumber
;
let
combined
=
"
:
"
+
startLine
+
"
:
"
+
startColumn
;
if
(
token
)
{
combined
=
token
.
tokenType
+
combined
;
}
equal
(
combined
locations
[
i
]
)
;
+
+
i
;
if
(
!
token
)
{
break
;
}
}
equal
(
i
locations
.
length
)
;
}
function
test_lexer_eofchar
(
cssText
argText
expectedAppend
expectedNoAppend
)
{
const
lexer
=
new
DoubleLexer
(
cssText
)
;
while
(
lexer
.
nextToken
(
)
)
{
}
info
(
"
EOF
char
test
input
=
"
+
cssText
)
;
let
result
=
lexer
.
performEOFFixup
(
argText
true
)
;
equal
(
result
expectedAppend
)
;
result
=
lexer
.
performEOFFixup
(
argText
false
)
;
equal
(
result
expectedNoAppend
)
;
}
var
LINECOL_TESTS
=
[
[
"
simple
"
[
"
ident
:
0
:
0
"
"
:
0
:
6
"
]
]
[
"
\
n
stuff
"
[
"
whitespace
:
0
:
0
"
"
ident
:
1
:
4
"
"
:
1
:
9
"
]
]
[
'
"
string
with
\
\
\
nnewline
"
\
r
\
n
'
[
"
string
:
0
:
0
"
"
whitespace
:
1
:
8
"
"
:
2
:
0
"
]
]
]
;
var
EOFCHAR_TESTS
=
[
[
"
hello
"
"
hello
"
]
[
"
hello
\
\
"
"
hello
\
\
\
\
"
"
hello
\
\
\
uFFFD
"
]
[
"
'
hello
"
"
'
hello
'
"
]
[
"
\
"
hello
"
"
\
"
hello
\
"
"
]
[
"
'
hello
\
\
"
"
'
hello
\
\
\
\
'
"
"
'
hello
'
"
]
[
"
\
"
hello
\
\
"
"
\
"
hello
\
\
\
\
\
"
"
"
\
"
hello
\
"
"
]
[
"
/
*
hello
"
"
/
*
hello
*
/
"
]
[
"
/
*
hello
*
"
"
/
*
hello
*
/
"
]
[
"
/
*
hello
\
\
"
"
/
*
hello
\
\
*
/
"
]
[
"
url
(
hello
"
"
url
(
hello
)
"
]
[
"
url
(
'
hello
"
"
url
(
'
hello
'
)
"
]
[
"
url
(
\
"
hello
"
"
url
(
\
"
hello
\
"
)
"
]
[
"
url
(
hello
\
\
"
"
url
(
hello
\
\
\
\
)
"
"
url
(
hello
\
\
\
uFFFD
)
"
]
[
"
url
(
'
hello
\
\
"
"
url
(
'
hello
\
\
\
\
'
)
"
"
url
(
'
hello
'
)
"
]
[
"
url
(
\
"
hello
\
\
"
"
url
(
\
"
hello
\
\
\
\
\
"
)
"
"
url
(
\
"
hello
\
"
)
"
]
]
;
function
run_test
(
)
{
let
text
result
;
for
(
[
text
result
]
of
LEX_TESTS
)
{
test_lexer
(
text
result
)
;
}
for
(
[
text
result
]
of
LINECOL_TESTS
)
{
test_lexer_linecol
(
text
result
)
;
}
let
expectedAppend
expectedNoAppend
;
for
(
[
text
expectedAppend
expectedNoAppend
]
of
EOFCHAR_TESTS
)
{
if
(
!
expectedNoAppend
)
{
expectedNoAppend
=
expectedAppend
;
}
test_lexer_eofchar
(
text
text
expectedAppend
expectedNoAppend
)
;
}
test_lexer_eofchar
(
"
'
\
\
"
"
"
"
\
\
'
"
"
'
"
)
;
}
