"
use
strict
"
;
const
{
BaseStorageActor
MAX_STORE_OBJECT_COUNT
SEPARATOR_GUID
}
=
require
(
"
resource
:
/
/
devtools
/
server
/
actors
/
resources
/
storage
/
index
.
js
"
)
;
const
{
LongStringActor
}
=
require
(
"
resource
:
/
/
devtools
/
server
/
actors
/
string
.
js
"
)
;
loader
.
lazyGetter
(
this
"
indexedDBForStorage
"
(
)
=
>
{
try
{
const
sandbox
=
Cu
.
Sandbox
(
Components
.
Constructor
(
"
mozilla
.
org
/
systemprincipal
;
1
"
"
nsIPrincipal
"
)
(
)
{
wantGlobalProperties
:
[
"
indexedDB
"
]
}
)
;
return
sandbox
.
indexedDB
;
}
catch
(
e
)
{
return
{
}
;
}
}
)
;
const
lazy
=
{
}
;
ChromeUtils
.
defineESModuleGetters
(
lazy
{
Sqlite
:
"
resource
:
/
/
gre
/
modules
/
Sqlite
.
sys
.
mjs
"
}
{
global
:
"
contextual
"
}
)
;
function
sleep
(
time
)
{
return
new
Promise
(
resolve
=
>
{
setTimeout
(
(
)
=
>
{
resolve
(
null
)
;
}
time
)
;
}
)
;
}
const
SAFE_HOSTS_PREFIXES_REGEX
=
/
^
(
about
\
+
|
https
?
\
+
|
file
\
+
|
moz
-
extension
\
+
)
/
;
const
illegalFileNameCharacters
=
[
"
[
"
"
\
\
x00
-
\
\
x24
"
'
/
:
*
?
\
\
"
<
>
|
\
\
\
\
'
"
]
"
]
.
join
(
"
"
)
;
const
ILLEGAL_CHAR_REGEX
=
new
RegExp
(
illegalFileNameCharacters
"
g
"
)
;
class
IndexMetadata
{
constructor
(
index
)
{
this
.
_name
=
index
.
name
;
this
.
_keyPath
=
index
.
keyPath
;
this
.
_unique
=
index
.
unique
;
this
.
_multiEntry
=
index
.
multiEntry
;
}
toObject
(
)
{
return
{
name
:
this
.
_name
keyPath
:
this
.
_keyPath
unique
:
this
.
_unique
multiEntry
:
this
.
_multiEntry
}
;
}
}
class
ObjectStoreMetadata
{
constructor
(
objectStore
)
{
this
.
_name
=
objectStore
.
name
;
this
.
_keyPath
=
objectStore
.
keyPath
;
this
.
_autoIncrement
=
objectStore
.
autoIncrement
;
this
.
_indexes
=
[
]
;
for
(
let
i
=
0
;
i
<
objectStore
.
indexNames
.
length
;
i
+
+
)
{
const
index
=
objectStore
.
index
(
objectStore
.
indexNames
[
i
]
)
;
const
newIndex
=
{
keypath
:
index
.
keyPath
multiEntry
:
index
.
multiEntry
name
:
index
.
name
objectStore
:
{
autoIncrement
:
index
.
objectStore
.
autoIncrement
indexNames
:
[
.
.
.
index
.
objectStore
.
indexNames
]
keyPath
:
index
.
objectStore
.
keyPath
name
:
index
.
objectStore
.
name
}
}
;
this
.
_indexes
.
push
(
[
newIndex
new
IndexMetadata
(
index
)
]
)
;
}
}
toObject
(
)
{
return
{
name
:
this
.
_name
keyPath
:
this
.
_keyPath
autoIncrement
:
this
.
_autoIncrement
indexes
:
JSON
.
stringify
(
[
.
.
.
this
.
_indexes
.
values
(
)
]
.
map
(
index
=
>
index
.
toObject
(
)
)
)
}
;
}
}
class
DatabaseMetadata
{
constructor
(
origin
db
storage
)
{
this
.
_origin
=
origin
;
this
.
_name
=
db
.
name
;
this
.
_version
=
db
.
version
;
this
.
_objectStores
=
[
]
;
this
.
storage
=
storage
;
if
(
db
.
objectStoreNames
.
length
)
{
const
transaction
=
db
.
transaction
(
db
.
objectStoreNames
"
readonly
"
)
;
for
(
let
i
=
0
;
i
<
transaction
.
objectStoreNames
.
length
;
i
+
+
)
{
const
objectStore
=
transaction
.
objectStore
(
transaction
.
objectStoreNames
[
i
]
)
;
this
.
_objectStores
.
push
(
[
transaction
.
objectStoreNames
[
i
]
new
ObjectStoreMetadata
(
objectStore
)
]
)
;
}
}
}
get
objectStores
(
)
{
return
this
.
_objectStores
;
}
toObject
(
)
{
return
{
uniqueKey
:
{
this
.
_name
}
{
SEPARATOR_GUID
}
{
this
.
storage
}
name
:
this
.
_name
storage
:
this
.
storage
origin
:
this
.
_origin
version
:
this
.
_version
objectStores
:
this
.
_objectStores
.
size
}
;
}
}
class
IndexedDBStorageActor
extends
BaseStorageActor
{
constructor
(
storageActor
)
{
super
(
storageActor
"
indexedDB
"
)
;
this
.
objectsSize
=
{
}
;
this
.
storageActor
=
storageActor
;
}
destroy
(
)
{
this
.
objectsSize
=
null
;
super
.
destroy
(
)
;
}
async
populateStoresForHosts
(
)
{
for
(
const
host
of
await
this
.
getHosts
(
)
)
{
await
this
.
populateStoresForHost
(
host
)
;
}
}
async
populateStoresForHost
(
host
)
{
const
storeMap
=
new
Map
(
)
;
const
win
=
this
.
storageActor
.
getWindowFromHost
(
host
)
;
const
principal
=
this
.
getPrincipal
(
win
)
;
const
{
names
}
=
await
this
.
getDBNamesForHost
(
host
principal
)
;
for
(
const
{
name
storage
}
of
names
)
{
let
metadata
=
await
this
.
getDBMetaData
(
host
principal
name
storage
)
;
metadata
=
this
.
patchMetadataMapsAndProtos
(
metadata
)
;
storeMap
.
set
(
{
name
}
(
{
storage
}
)
metadata
)
;
}
this
.
hostVsStores
.
set
(
host
storeMap
)
;
}
async
getHosts
(
)
{
const
isBrowserToolbox
=
this
.
storageActor
.
parentActor
.
isRootActor
;
this
.
_internalHosts
=
isBrowserToolbox
?
await
this
.
getInternalHosts
(
)
:
[
]
;
return
this
.
hosts
;
}
async
removeDatabase
(
host
name
)
{
const
win
=
this
.
storageActor
.
getWindowFromHost
(
host
)
;
if
(
!
win
)
{
return
{
error
:
Window
for
host
{
host
}
not
found
}
;
}
const
principal
=
win
.
document
.
effectiveStoragePrincipal
;
return
this
.
removeDB
(
host
principal
name
)
;
}
async
removeAll
(
host
name
)
{
const
[
db
store
]
=
JSON
.
parse
(
name
)
;
const
win
=
this
.
storageActor
.
getWindowFromHost
(
host
)
;
if
(
!
win
)
{
return
;
}
const
principal
=
win
.
document
.
effectiveStoragePrincipal
;
this
.
clearDBStore
(
host
principal
db
store
)
;
}
async
removeItem
(
host
name
)
{
const
[
db
store
id
]
=
JSON
.
parse
(
name
)
;
const
win
=
this
.
storageActor
.
getWindowFromHost
(
host
)
;
if
(
!
win
)
{
return
;
}
const
principal
=
win
.
document
.
effectiveStoragePrincipal
;
this
.
removeDBRecord
(
host
principal
db
store
id
)
;
}
getNamesForHost
(
host
)
{
const
storesForHost
=
this
.
hostVsStores
.
get
(
host
)
;
if
(
!
storesForHost
)
{
return
[
]
;
}
const
names
=
[
]
;
for
(
const
[
dbName
{
objectStores
}
]
of
storesForHost
)
{
if
(
objectStores
.
size
)
{
for
(
const
objectStore
of
objectStores
.
keys
(
)
)
{
names
.
push
(
JSON
.
stringify
(
[
dbName
objectStore
]
)
)
;
}
}
else
{
names
.
push
(
JSON
.
stringify
(
[
dbName
]
)
)
;
}
}
return
names
;
}
getObjectsSize
(
host
names
options
)
{
const
name
=
names
[
0
]
;
const
parsedName
=
JSON
.
parse
(
name
)
;
if
(
parsedName
.
length
=
=
3
)
{
return
names
.
length
;
}
else
if
(
parsedName
.
length
=
=
2
)
{
const
index
=
options
.
index
;
const
[
db
objectStore
]
=
parsedName
;
if
(
this
.
objectsSize
[
host
+
db
+
objectStore
+
index
]
)
{
return
this
.
objectsSize
[
host
+
db
+
objectStore
+
index
]
;
}
}
else
if
(
parsedName
.
length
=
=
1
)
{
if
(
this
.
hostVsStores
.
has
(
host
)
&
&
this
.
hostVsStores
.
get
(
host
)
.
has
(
parsedName
[
0
]
)
)
{
return
this
.
hostVsStores
.
get
(
host
)
.
get
(
parsedName
[
0
]
)
.
objectStores
.
size
;
}
}
else
if
(
!
parsedName
|
|
!
parsedName
.
length
)
{
if
(
this
.
hostVsStores
.
has
(
host
)
)
{
return
this
.
hostVsStores
.
get
(
host
)
.
size
;
}
}
return
0
;
}
toStoreObject
(
item
)
{
if
(
!
item
)
{
return
null
;
}
if
(
"
indexes
"
in
item
)
{
return
{
objectStore
:
item
.
name
keyPath
:
item
.
keyPath
autoIncrement
:
item
.
autoIncrement
indexes
:
item
.
indexes
}
;
}
if
(
"
objectStores
"
in
item
)
{
return
{
uniqueKey
:
{
item
.
name
}
(
{
item
.
storage
}
)
db
:
item
.
name
storage
:
item
.
storage
origin
:
item
.
origin
version
:
item
.
version
objectStores
:
item
.
objectStores
}
;
}
const
value
=
JSON
.
stringify
(
item
.
value
)
;
return
{
name
:
item
.
name
value
:
new
LongStringActor
(
this
.
conn
value
)
}
;
}
form
(
)
{
const
hosts
=
{
}
;
for
(
const
host
of
this
.
hosts
)
{
hosts
[
host
]
=
this
.
getNamesForHost
(
host
)
;
}
return
{
actor
:
this
.
actorID
hosts
traits
:
this
.
_getTraits
(
)
}
;
}
onItemUpdated
(
action
host
path
)
{
dump
(
"
IDX
.
onItemUpdated
(
"
+
action
+
"
-
"
+
host
+
"
-
"
+
path
+
"
\
n
"
)
;
if
(
action
=
=
=
"
deleted
"
&
&
path
.
length
=
=
=
1
)
{
if
(
this
.
hostVsStores
.
has
(
host
)
)
{
this
.
hostVsStores
.
get
(
host
)
.
delete
(
path
[
0
]
)
;
}
}
this
.
storageActor
.
update
(
action
"
indexedDB
"
{
[
host
]
:
[
JSON
.
stringify
(
path
)
]
}
)
;
}
async
getFields
(
subType
)
{
switch
(
subType
)
{
case
"
database
"
:
return
[
{
name
:
"
objectStore
"
editable
:
false
}
{
name
:
"
keyPath
"
editable
:
false
}
{
name
:
"
autoIncrement
"
editable
:
false
}
{
name
:
"
indexes
"
editable
:
false
}
]
;
case
"
object
store
"
:
return
[
{
name
:
"
name
"
editable
:
false
}
{
name
:
"
value
"
editable
:
false
}
]
;
default
:
return
[
{
name
:
"
uniqueKey
"
editable
:
false
private
:
true
}
{
name
:
"
db
"
editable
:
false
}
{
name
:
"
storage
"
editable
:
false
}
{
name
:
"
origin
"
editable
:
false
}
{
name
:
"
version
"
editable
:
false
}
{
name
:
"
objectStores
"
editable
:
false
}
]
;
}
}
async
getDBMetaData
(
host
principal
name
storage
)
{
const
request
=
this
.
openWithPrincipal
(
principal
name
storage
)
;
return
new
Promise
(
resolve
=
>
{
request
.
onsuccess
=
event
=
>
{
const
db
=
event
.
target
.
result
;
const
dbData
=
new
DatabaseMetadata
(
host
db
storage
)
;
db
.
close
(
)
;
resolve
(
dbData
)
;
}
;
request
.
onerror
=
(
{
target
}
)
=
>
{
console
.
error
(
Error
opening
indexeddb
database
{
name
}
for
host
{
host
}
target
.
error
)
;
resolve
(
null
)
;
}
;
}
)
;
}
splitNameAndStorage
(
name
)
{
const
lastOpenBracketIndex
=
name
.
lastIndexOf
(
"
(
"
)
;
const
lastCloseBracketIndex
=
name
.
lastIndexOf
(
"
)
"
)
;
const
delta
=
lastCloseBracketIndex
-
lastOpenBracketIndex
-
1
;
const
storage
=
name
.
substr
(
lastOpenBracketIndex
+
1
delta
)
;
name
=
name
.
substr
(
0
lastOpenBracketIndex
-
1
)
;
return
{
storage
name
}
;
}
async
getInternalHosts
(
)
{
const
profileDir
=
PathUtils
.
profileDir
;
const
storagePath
=
PathUtils
.
join
(
profileDir
"
storage
"
"
permanent
"
)
;
const
children
=
await
IOUtils
.
getChildren
(
storagePath
)
;
const
hosts
=
[
]
;
for
(
const
path
of
children
)
{
const
exists
=
await
IOUtils
.
exists
(
path
)
;
if
(
!
exists
)
{
continue
;
}
const
stats
=
await
IOUtils
.
stat
(
path
)
;
if
(
stats
.
type
=
=
=
"
directory
"
&
&
!
SAFE_HOSTS_PREFIXES_REGEX
.
test
(
stats
.
path
)
)
{
const
basename
=
PathUtils
.
filename
(
path
)
;
hosts
.
push
(
basename
)
;
}
}
return
hosts
;
}
openWithPrincipal
(
principal
name
storage
)
{
return
indexedDBForStorage
.
openForPrincipal
(
principal
name
{
storage
}
)
;
}
async
removeDB
(
host
principal
dbName
)
{
const
result
=
new
Promise
(
resolve
=
>
{
const
{
name
storage
}
=
this
.
splitNameAndStorage
(
dbName
)
;
const
request
=
indexedDBForStorage
.
deleteForPrincipal
(
principal
name
{
storage
}
)
;
request
.
onsuccess
=
(
)
=
>
{
resolve
(
{
}
)
;
this
.
onItemUpdated
(
"
deleted
"
host
[
dbName
]
)
;
}
;
request
.
onblocked
=
(
)
=
>
{
console
.
warn
(
Deleting
indexedDB
database
{
name
}
for
host
{
host
}
is
blocked
)
;
resolve
(
{
blocked
:
true
}
)
;
}
;
request
.
onerror
=
(
)
=
>
{
const
{
error
}
=
request
;
console
.
warn
(
Error
deleting
indexedDB
database
{
name
}
for
host
{
host
}
:
{
error
}
)
;
resolve
(
{
error
:
error
.
message
}
)
;
}
;
setTimeout
(
(
)
=
>
resolve
(
{
blocked
:
true
}
)
3000
)
;
}
)
;
return
result
;
}
async
removeDBRecord
(
host
principal
dbName
storeName
id
)
{
let
db
;
const
{
name
storage
}
=
this
.
splitNameAndStorage
(
dbName
)
;
try
{
db
=
await
new
Promise
(
(
resolve
reject
)
=
>
{
const
request
=
this
.
openWithPrincipal
(
principal
name
storage
)
;
request
.
onsuccess
=
ev
=
>
resolve
(
ev
.
target
.
result
)
;
request
.
onerror
=
ev
=
>
reject
(
ev
.
target
.
error
)
;
}
)
;
const
transaction
=
db
.
transaction
(
storeName
"
readwrite
"
)
;
const
store
=
transaction
.
objectStore
(
storeName
)
;
await
new
Promise
(
(
resolve
reject
)
=
>
{
const
request
=
store
.
delete
(
id
)
;
request
.
onsuccess
=
(
)
=
>
resolve
(
)
;
request
.
onerror
=
ev
=
>
reject
(
ev
.
target
.
error
)
;
}
)
;
this
.
onItemUpdated
(
"
deleted
"
host
[
dbName
storeName
id
]
)
;
}
catch
(
error
)
{
const
recordPath
=
[
dbName
storeName
id
]
.
join
(
"
/
"
)
;
console
.
error
(
Failed
to
delete
indexedDB
record
:
{
recordPath
}
:
{
error
}
)
;
}
if
(
db
)
{
db
.
close
(
)
;
}
return
null
;
}
async
clearDBStore
(
host
principal
dbName
storeName
)
{
let
db
;
const
{
name
storage
}
=
this
.
splitNameAndStorage
(
dbName
)
;
try
{
db
=
await
new
Promise
(
(
resolve
reject
)
=
>
{
const
request
=
this
.
openWithPrincipal
(
principal
name
storage
)
;
request
.
onsuccess
=
ev
=
>
resolve
(
ev
.
target
.
result
)
;
request
.
onerror
=
ev
=
>
reject
(
ev
.
target
.
error
)
;
}
)
;
const
transaction
=
db
.
transaction
(
storeName
"
readwrite
"
)
;
const
store
=
transaction
.
objectStore
(
storeName
)
;
await
new
Promise
(
(
resolve
reject
)
=
>
{
const
request
=
store
.
clear
(
)
;
request
.
onsuccess
=
(
)
=
>
resolve
(
)
;
request
.
onerror
=
ev
=
>
reject
(
ev
.
target
.
error
)
;
}
)
;
this
.
onItemUpdated
(
"
cleared
"
host
[
dbName
storeName
]
)
;
}
catch
(
error
)
{
const
storePath
=
[
dbName
storeName
]
.
join
(
"
/
"
)
;
console
.
error
(
Failed
to
clear
indexedDB
store
:
{
storePath
}
:
{
error
}
)
;
}
if
(
db
)
{
db
.
close
(
)
;
}
return
null
;
}
async
getDBNamesForHost
(
host
principal
)
{
const
sanitizedHost
=
this
.
getSanitizedHost
(
host
)
+
principal
.
originSuffix
;
const
profileDir
=
PathUtils
.
profileDir
;
const
storagePath
=
PathUtils
.
join
(
profileDir
"
storage
"
)
;
const
files
=
[
]
;
const
names
=
[
]
;
const
sqliteFiles
=
await
this
.
findSqlitePathsForHost
(
storagePath
sanitizedHost
)
;
for
(
const
file
of
sqliteFiles
)
{
const
splitPath
=
PathUtils
.
split
(
file
)
;
const
idbIndex
=
splitPath
.
indexOf
(
"
idb
"
)
;
const
storage
=
splitPath
[
idbIndex
-
2
]
;
const
relative
=
file
.
substr
(
profileDir
.
length
+
1
)
;
files
.
push
(
{
file
:
relative
storage
:
storage
=
=
=
"
permanent
"
?
"
persistent
"
:
storage
}
)
;
}
if
(
files
.
length
)
{
for
(
const
{
file
storage
}
of
files
)
{
const
name
=
await
this
.
getNameFromDatabaseFile
(
file
)
;
if
(
name
)
{
names
.
push
(
{
name
storage
}
)
;
}
}
}
return
{
names
}
;
}
async
findSqlitePathsForHost
(
storagePath
sanitizedHost
)
{
const
sqlitePaths
=
[
]
;
const
idbPaths
=
await
this
.
findIDBPathsForHost
(
storagePath
sanitizedHost
)
;
for
(
const
idbPath
of
idbPaths
)
{
const
children
=
await
IOUtils
.
getChildren
(
idbPath
)
;
for
(
const
path
of
children
)
{
const
exists
=
await
IOUtils
.
exists
(
path
)
;
if
(
!
exists
)
{
continue
;
}
const
stats
=
await
IOUtils
.
stat
(
path
)
;
if
(
stats
.
type
!
=
=
"
directory
"
&
&
stats
.
path
.
endsWith
(
"
.
sqlite
"
)
)
{
sqlitePaths
.
push
(
path
)
;
}
}
}
return
sqlitePaths
;
}
async
findIDBPathsForHost
(
storagePath
sanitizedHost
)
{
const
idbPaths
=
[
]
;
const
typePaths
=
await
this
.
findStorageTypePaths
(
storagePath
)
;
for
(
const
typePath
of
typePaths
)
{
const
idbPath
=
PathUtils
.
join
(
typePath
sanitizedHost
"
idb
"
)
;
if
(
await
IOUtils
.
exists
(
idbPath
)
)
{
idbPaths
.
push
(
idbPath
)
;
}
}
return
idbPaths
;
}
async
findStorageTypePaths
(
storagePath
)
{
const
children
=
await
IOUtils
.
getChildren
(
storagePath
)
;
const
typePaths
=
[
]
;
for
(
const
path
of
children
)
{
const
exists
=
await
IOUtils
.
exists
(
path
)
;
if
(
!
exists
)
{
continue
;
}
const
stats
=
await
IOUtils
.
stat
(
path
)
;
if
(
stats
.
type
=
=
=
"
directory
"
)
{
typePaths
.
push
(
path
)
;
}
}
return
typePaths
;
}
getSanitizedHost
(
host
)
{
if
(
host
.
startsWith
(
"
about
:
"
)
)
{
host
=
"
moz
-
safe
-
"
+
host
;
}
return
host
.
replace
(
ILLEGAL_CHAR_REGEX
"
+
"
)
;
}
async
getNameFromDatabaseFile
(
path
)
{
let
connection
=
null
;
for
(
let
retries
=
0
;
!
connection
&
&
retries
<
25
;
retries
+
+
)
{
try
{
connection
=
await
lazy
.
Sqlite
.
openConnection
(
{
path
}
)
;
}
catch
(
ex
)
{
await
sleep
(
100
)
;
}
}
if
(
connection
=
=
=
null
)
{
console
.
error
(
"
Unable
to
open
Sqlite
connection
to
path
:
"
+
path
)
;
return
null
;
}
let
name
=
undefined
;
for
(
let
retries
=
0
;
name
=
=
=
undefined
&
&
retries
<
25
;
retries
+
+
)
{
try
{
const
rows
=
await
connection
.
execute
(
"
SELECT
name
FROM
database
"
)
;
name
=
rows
[
0
]
.
getResultByName
(
"
name
"
)
;
}
catch
{
await
sleep
(
100
)
;
}
}
if
(
!
name
)
{
console
.
error
(
"
Unable
to
get
the
database
name
for
path
:
"
+
path
)
;
}
await
connection
.
close
(
)
;
return
name
;
}
async
getValuesForHost
(
host
name
=
"
null
"
options
hostVsStores
principal
)
{
name
=
JSON
.
parse
(
name
)
;
if
(
!
name
|
|
!
name
.
length
)
{
const
dbs
=
[
]
;
if
(
hostVsStores
.
has
(
host
)
)
{
for
(
let
[
db
]
of
hostVsStores
.
get
(
host
)
)
{
db
=
this
.
patchMetadataMapsAndProtos
(
db
)
;
dbs
.
push
(
db
.
toObject
(
)
)
;
}
}
return
{
dbs
}
;
}
const
[
db2
objectStore
id
]
=
name
;
if
(
!
objectStore
)
{
const
objectStores
=
[
]
;
if
(
hostVsStores
.
has
(
host
)
&
&
hostVsStores
.
get
(
host
)
.
has
(
db2
)
)
{
let
db
=
hostVsStores
.
get
(
host
)
.
get
(
db2
)
;
db
=
this
.
patchMetadataMapsAndProtos
(
db
)
;
const
objectStores2
=
db
.
objectStores
;
for
(
const
objectStore2
of
objectStores2
)
{
objectStores
.
push
(
objectStore2
[
1
]
.
toObject
(
)
)
;
}
}
return
{
objectStores
}
;
}
const
storage
=
hostVsStores
.
get
(
host
)
.
get
(
db2
)
.
storage
;
const
result
=
await
this
.
getObjectStoreData
(
host
principal
db2
storage
{
objectStore
id
index
:
options
.
index
offset
:
options
.
offset
size
:
options
.
size
}
)
;
return
{
result
}
;
}
getObjectStoreData
(
host
principal
dbName
storage
requestOptions
)
{
const
{
name
}
=
this
.
splitNameAndStorage
(
dbName
)
;
const
request
=
this
.
openWithPrincipal
(
principal
name
storage
)
;
return
new
Promise
(
resolve
=
>
{
let
{
objectStore
id
index
offset
size
}
=
requestOptions
;
const
data
=
[
]
;
let
db
;
if
(
!
size
|
|
size
>
MAX_STORE_OBJECT_COUNT
)
{
size
=
MAX_STORE_OBJECT_COUNT
;
}
request
.
onsuccess
=
event
=
>
{
db
=
event
.
target
.
result
;
const
transaction
=
db
.
transaction
(
objectStore
"
readonly
"
)
;
let
source
=
transaction
.
objectStore
(
objectStore
)
;
if
(
index
&
&
index
!
=
"
name
"
)
{
source
=
source
.
index
(
index
)
;
}
source
.
count
(
)
.
onsuccess
=
event2
=
>
{
const
objectsSize
=
[
]
;
const
count
=
event2
.
target
.
result
;
objectsSize
.
push
(
{
key
:
host
+
dbName
+
objectStore
+
index
count
}
)
;
if
(
!
offset
)
{
offset
=
0
;
}
else
if
(
offset
>
count
)
{
db
.
close
(
)
;
resolve
(
[
]
)
;
return
;
}
if
(
id
)
{
source
.
get
(
id
)
.
onsuccess
=
event3
=
>
{
db
.
close
(
)
;
resolve
(
[
{
name
:
id
value
:
event3
.
target
.
result
}
]
)
;
}
;
}
else
{
source
.
openCursor
(
)
.
onsuccess
=
event4
=
>
{
const
cursor
=
event4
.
target
.
result
;
if
(
!
cursor
|
|
data
.
length
>
=
size
)
{
db
.
close
(
)
;
resolve
(
{
data
objectsSize
}
)
;
return
;
}
if
(
offset
-
-
<
=
0
)
{
data
.
push
(
{
name
:
cursor
.
key
value
:
cursor
.
value
}
)
;
}
cursor
.
continue
(
)
;
}
;
}
}
;
}
;
request
.
onerror
=
(
)
=
>
{
db
.
close
(
)
;
resolve
(
[
]
)
;
}
;
}
)
;
}
patchMetadataMapsAndProtos
(
metadata
)
{
const
md
=
Object
.
create
(
DatabaseMetadata
.
prototype
)
;
Object
.
assign
(
md
metadata
)
;
md
.
_objectStores
=
new
Map
(
metadata
.
_objectStores
)
;
for
(
const
[
name
store
]
of
md
.
_objectStores
)
{
const
obj
=
Object
.
create
(
ObjectStoreMetadata
.
prototype
)
;
Object
.
assign
(
obj
store
)
;
md
.
_objectStores
.
set
(
name
obj
)
;
if
(
typeof
store
.
_indexes
.
length
!
=
=
"
undefined
"
)
{
obj
.
_indexes
=
new
Map
(
store
.
_indexes
)
;
}
for
(
const
[
name2
value
]
of
obj
.
_indexes
)
{
const
obj2
=
Object
.
create
(
IndexMetadata
.
prototype
)
;
Object
.
assign
(
obj2
value
)
;
obj
.
_indexes
.
set
(
name2
obj2
)
;
}
}
return
md
;
}
}
exports
.
IndexedDBStorageActor
=
IndexedDBStorageActor
;
