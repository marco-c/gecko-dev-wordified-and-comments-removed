#
include
"
MediaEngineDefault
.
h
"
#
include
"
nsCOMPtr
.
h
"
#
include
"
mozilla
/
dom
/
File
.
h
"
#
include
"
mozilla
/
UniquePtr
.
h
"
#
include
"
nsILocalFile
.
h
"
#
include
"
Layers
.
h
"
#
include
"
ImageContainer
.
h
"
#
include
"
ImageTypes
.
h
"
#
include
"
prmem
.
h
"
#
include
"
nsContentUtils
.
h
"
#
include
"
nsIFilePicker
.
h
"
#
include
"
nsIPrefService
.
h
"
#
include
"
nsIPrefBranch
.
h
"
#
ifdef
MOZ_WIDGET_ANDROID
#
include
"
nsISupportsUtils
.
h
"
#
endif
#
ifdef
MOZ_WEBRTC
#
include
"
YuvStamper
.
h
"
#
endif
#
define
AUDIO_RATE
mozilla
:
:
MediaEngine
:
:
DEFAULT_SAMPLE_RATE
#
define
DEFAULT_AUDIO_TIMER_MS
10
namespace
mozilla
{
using
namespace
mozilla
:
:
gfx
;
NS_IMPL_ISUPPORTS
(
MediaEngineDefaultVideoSource
nsITimerCallback
)
MediaEngineDefaultVideoSource
:
:
MediaEngineDefaultVideoSource
(
)
#
ifdef
MOZ_WEBRTC
:
MediaEngineCameraVideoSource
(
"
FakeVideo
.
Monitor
"
)
#
else
:
MediaEngineVideoSource
(
)
#
endif
mTimer
(
nullptr
)
mMonitor
(
"
Fake
video
"
)
mCb
(
16
)
mCr
(
16
)
{
mImageContainer
=
layers
:
:
LayerManager
:
:
CreateImageContainer
(
layers
:
:
ImageContainer
:
:
ASYNCHRONOUS
)
;
}
MediaEngineDefaultVideoSource
:
:
~
MediaEngineDefaultVideoSource
(
)
{
}
void
MediaEngineDefaultVideoSource
:
:
GetName
(
nsAString
&
aName
)
const
{
aName
.
AssignLiteral
(
u
"
Default
Video
Device
"
)
;
return
;
}
void
MediaEngineDefaultVideoSource
:
:
GetUUID
(
nsACString
&
aUUID
)
const
{
aUUID
.
AssignLiteral
(
"
1041FCBD
-
3F12
-
4F7B
-
9E9B
-
1EC556DD5676
"
)
;
return
;
}
uint32_t
MediaEngineDefaultVideoSource
:
:
GetBestFitnessDistance
(
const
nsTArray
<
const
NormalizedConstraintSet
*
>
&
aConstraintSets
const
nsString
&
aDeviceId
)
const
{
uint32_t
distance
=
0
;
#
ifdef
MOZ_WEBRTC
for
(
const
auto
*
cs
:
aConstraintSets
)
{
distance
=
GetMinimumFitnessDistance
(
*
cs
aDeviceId
)
;
break
;
}
#
endif
return
distance
;
}
nsresult
MediaEngineDefaultVideoSource
:
:
Allocate
(
const
dom
:
:
MediaTrackConstraints
&
aConstraints
const
MediaEnginePrefs
&
aPrefs
const
nsString
&
aDeviceId
const
nsACString
&
aOrigin
AllocationHandle
*
*
aOutHandle
const
char
*
*
aOutBadConstraint
)
{
if
(
mState
!
=
kReleased
)
{
return
NS_ERROR_FAILURE
;
}
FlattenedConstraints
c
(
aConstraints
)
;
if
(
c
.
mDeviceId
.
mIdeal
.
find
(
NS_LITERAL_STRING
(
"
bad
device
"
)
)
!
=
c
.
mDeviceId
.
mIdeal
.
end
(
)
)
{
return
NS_ERROR_FAILURE
;
}
mOpts
=
aPrefs
;
mOpts
.
mWidth
=
c
.
mWidth
.
Get
(
aPrefs
.
mWidth
?
aPrefs
.
mWidth
:
#
ifdef
DEBUG
MediaEngine
:
:
DEFAULT_43_VIDEO_WIDTH
/
2
#
else
MediaEngine
:
:
DEFAULT_43_VIDEO_WIDTH
#
endif
)
;
mOpts
.
mHeight
=
c
.
mHeight
.
Get
(
aPrefs
.
mHeight
?
aPrefs
.
mHeight
:
#
ifdef
DEBUG
MediaEngine
:
:
DEFAULT_43_VIDEO_HEIGHT
/
2
#
else
MediaEngine
:
:
DEFAULT_43_VIDEO_HEIGHT
#
endif
)
;
mState
=
kAllocated
;
*
aOutHandle
=
nullptr
;
return
NS_OK
;
}
nsresult
MediaEngineDefaultVideoSource
:
:
Deallocate
(
AllocationHandle
*
aHandle
)
{
MOZ_ASSERT
(
!
aHandle
)
;
if
(
mState
!
=
kStopped
&
&
mState
!
=
kAllocated
)
{
return
NS_ERROR_FAILURE
;
}
mState
=
kReleased
;
mImage
=
nullptr
;
return
NS_OK
;
}
static
void
AllocateSolidColorFrame
(
layers
:
:
PlanarYCbCrData
&
aData
int
aWidth
int
aHeight
int
aY
int
aCb
int
aCr
)
{
MOZ_ASSERT
(
!
(
aWidth
&
1
)
)
;
MOZ_ASSERT
(
!
(
aHeight
&
1
)
)
;
int
yLen
=
aWidth
*
aHeight
;
int
cbLen
=
yLen
>
>
2
;
int
crLen
=
cbLen
;
uint8_t
*
frame
=
(
uint8_t
*
)
PR_Malloc
(
yLen
+
cbLen
+
crLen
)
;
memset
(
frame
aY
yLen
)
;
memset
(
frame
+
yLen
aCb
cbLen
)
;
memset
(
frame
+
yLen
+
cbLen
aCr
crLen
)
;
aData
.
mYChannel
=
frame
;
aData
.
mYSize
=
IntSize
(
aWidth
aHeight
)
;
aData
.
mYStride
=
aWidth
;
aData
.
mCbCrStride
=
aWidth
>
>
1
;
aData
.
mCbChannel
=
frame
+
yLen
;
aData
.
mCrChannel
=
aData
.
mCbChannel
+
cbLen
;
aData
.
mCbCrSize
=
IntSize
(
aWidth
>
>
1
aHeight
>
>
1
)
;
aData
.
mPicX
=
0
;
aData
.
mPicY
=
0
;
aData
.
mPicSize
=
IntSize
(
aWidth
aHeight
)
;
aData
.
mStereoMode
=
StereoMode
:
:
MONO
;
}
static
void
ReleaseFrame
(
layers
:
:
PlanarYCbCrData
&
aData
)
{
PR_Free
(
aData
.
mYChannel
)
;
}
nsresult
MediaEngineDefaultVideoSource
:
:
Start
(
SourceMediaStream
*
aStream
TrackID
aID
const
PrincipalHandle
&
aPrincipalHandle
)
{
if
(
mState
!
=
kAllocated
)
{
return
NS_ERROR_FAILURE
;
}
mTimer
=
do_CreateInstance
(
NS_TIMER_CONTRACTID
)
;
if
(
!
mTimer
)
{
return
NS_ERROR_FAILURE
;
}
aStream
-
>
AddTrack
(
aID
0
new
VideoSegment
(
)
SourceMediaStream
:
:
ADDTRACK_QUEUED
)
;
mTrackID
=
aID
;
#
if
(
defined
(
MOZ_WIDGET_GONK
)
|
|
defined
(
MOZ_WIDGET_ANDROID
)
)
&
&
defined
(
DEBUG
)
mTimer
-
>
InitWithCallback
(
this
(
1000
/
mOpts
.
mFPS
)
*
10
nsITimer
:
:
TYPE_REPEATING_SLACK
)
;
#
else
mTimer
-
>
InitWithCallback
(
this
1000
/
mOpts
.
mFPS
nsITimer
:
:
TYPE_REPEATING_SLACK
)
;
#
endif
mState
=
kStarted
;
return
NS_OK
;
}
nsresult
MediaEngineDefaultVideoSource
:
:
Stop
(
SourceMediaStream
*
aSource
TrackID
aID
)
{
if
(
mState
!
=
kStarted
)
{
return
NS_ERROR_FAILURE
;
}
if
(
!
mTimer
)
{
return
NS_ERROR_FAILURE
;
}
mTimer
-
>
Cancel
(
)
;
mTimer
=
nullptr
;
aSource
-
>
EndTrack
(
aID
)
;
mState
=
kStopped
;
mImage
=
nullptr
;
return
NS_OK
;
}
nsresult
MediaEngineDefaultVideoSource
:
:
Restart
(
AllocationHandle
*
aHandle
const
dom
:
:
MediaTrackConstraints
&
aConstraints
const
MediaEnginePrefs
&
aPrefs
const
nsString
&
aDeviceId
const
char
*
*
aOutBadConstraint
)
{
return
NS_OK
;
}
NS_IMETHODIMP
MediaEngineDefaultVideoSource
:
:
Notify
(
nsITimer
*
aTimer
)
{
if
(
mCr
<
=
16
)
{
if
(
mCb
<
240
)
{
mCb
+
+
;
}
else
{
mCr
+
+
;
}
}
else
if
(
mCb
>
=
240
)
{
if
(
mCr
<
240
)
{
mCr
+
+
;
}
else
{
mCb
-
-
;
}
}
else
if
(
mCr
>
=
240
)
{
if
(
mCb
>
16
)
{
mCb
-
-
;
}
else
{
mCr
-
-
;
}
}
else
{
mCr
-
-
;
}
RefPtr
<
layers
:
:
PlanarYCbCrImage
>
ycbcr_image
=
mImageContainer
-
>
CreatePlanarYCbCrImage
(
)
;
layers
:
:
PlanarYCbCrData
data
;
AllocateSolidColorFrame
(
data
mOpts
.
mWidth
mOpts
.
mHeight
0x80
mCb
mCr
)
;
#
ifdef
MOZ_WEBRTC
uint64_t
timestamp
=
PR_Now
(
)
;
YuvStamper
:
:
Encode
(
mOpts
.
mWidth
mOpts
.
mHeight
mOpts
.
mWidth
data
.
mYChannel
reinterpret_cast
<
unsigned
char
*
>
(
&
timestamp
)
sizeof
(
timestamp
)
0
0
)
;
#
endif
bool
setData
=
ycbcr_image
-
>
CopyData
(
data
)
;
MOZ_ASSERT
(
setData
)
;
ReleaseFrame
(
data
)
;
if
(
!
setData
)
{
return
NS_ERROR_FAILURE
;
}
MonitorAutoLock
lock
(
mMonitor
)
;
mImage
=
ycbcr_image
.
forget
(
)
;
return
NS_OK
;
}
void
MediaEngineDefaultVideoSource
:
:
NotifyPull
(
MediaStreamGraph
*
aGraph
SourceMediaStream
*
aSource
TrackID
aID
StreamTime
aDesiredTime
const
PrincipalHandle
&
aPrincipalHandle
)
{
VideoSegment
segment
;
MonitorAutoLock
lock
(
mMonitor
)
;
if
(
mState
!
=
kStarted
)
{
return
;
}
RefPtr
<
layers
:
:
Image
>
image
=
mImage
;
StreamTime
delta
=
aDesiredTime
-
aSource
-
>
GetEndOfAppendedData
(
aID
)
;
if
(
delta
>
0
)
{
IntSize
size
(
image
?
mOpts
.
mWidth
:
0
image
?
mOpts
.
mHeight
:
0
)
;
segment
.
AppendFrame
(
image
.
forget
(
)
delta
size
aPrincipalHandle
)
;
aSource
-
>
AppendToTrack
(
aID
&
segment
)
;
}
}
class
SineWaveGenerator
{
public
:
static
const
int
bytesPerSample
=
2
;
static
const
int
millisecondsPerSecond
=
PR_MSEC_PER_SEC
;
explicit
SineWaveGenerator
(
uint32_t
aSampleRate
uint32_t
aFrequency
)
:
mTotalLength
(
aSampleRate
/
aFrequency
)
mReadLength
(
0
)
{
mAudioBuffer
=
MakeUnique
<
int16_t
[
]
>
(
mTotalLength
)
;
for
(
int
i
=
0
;
i
<
mTotalLength
;
i
+
+
)
{
mAudioBuffer
[
i
]
=
(
3276
.
8f
*
sin
(
2
*
M_PI
*
i
/
mTotalLength
)
)
;
}
}
void
generate
(
int16_t
*
aBuffer
int16_t
aLengthInSamples
)
{
int16_t
remaining
=
aLengthInSamples
;
while
(
remaining
)
{
int16_t
processSamples
=
0
;
if
(
mTotalLength
-
mReadLength
>
=
remaining
)
{
processSamples
=
remaining
;
}
else
{
processSamples
=
mTotalLength
-
mReadLength
;
}
memcpy
(
aBuffer
&
mAudioBuffer
[
mReadLength
]
processSamples
*
bytesPerSample
)
;
aBuffer
+
=
processSamples
;
mReadLength
+
=
processSamples
;
remaining
-
=
processSamples
;
if
(
mReadLength
=
=
mTotalLength
)
{
mReadLength
=
0
;
}
}
}
private
:
UniquePtr
<
int16_t
[
]
>
mAudioBuffer
;
int16_t
mTotalLength
;
int16_t
mReadLength
;
}
;
NS_IMPL_ISUPPORTS
(
MediaEngineDefaultAudioSource
nsITimerCallback
)
MediaEngineDefaultAudioSource
:
:
MediaEngineDefaultAudioSource
(
)
:
MediaEngineAudioSource
(
kReleased
)
mPrincipalHandle
(
PRINCIPAL_HANDLE_NONE
)
mTimer
(
nullptr
)
{
}
MediaEngineDefaultAudioSource
:
:
~
MediaEngineDefaultAudioSource
(
)
{
}
void
MediaEngineDefaultAudioSource
:
:
GetName
(
nsAString
&
aName
)
const
{
aName
.
AssignLiteral
(
u
"
Default
Audio
Device
"
)
;
return
;
}
void
MediaEngineDefaultAudioSource
:
:
GetUUID
(
nsACString
&
aUUID
)
const
{
aUUID
.
AssignLiteral
(
"
B7CBD7C1
-
53EF
-
42F9
-
8353
-
73F61C70C092
"
)
;
return
;
}
uint32_t
MediaEngineDefaultAudioSource
:
:
GetBestFitnessDistance
(
const
nsTArray
<
const
NormalizedConstraintSet
*
>
&
aConstraintSets
const
nsString
&
aDeviceId
)
const
{
uint32_t
distance
=
0
;
#
ifdef
MOZ_WEBRTC
for
(
const
auto
*
cs
:
aConstraintSets
)
{
distance
=
GetMinimumFitnessDistance
(
*
cs
aDeviceId
)
;
break
;
}
#
endif
return
distance
;
}
nsresult
MediaEngineDefaultAudioSource
:
:
Allocate
(
const
dom
:
:
MediaTrackConstraints
&
aConstraints
const
MediaEnginePrefs
&
aPrefs
const
nsString
&
aDeviceId
const
nsACString
&
aOrigin
AllocationHandle
*
*
aOutHandle
const
char
*
*
aOutBadConstraint
)
{
if
(
mState
!
=
kReleased
)
{
return
NS_ERROR_FAILURE
;
}
if
(
aConstraints
.
mDeviceId
.
IsString
(
)
&
&
aConstraints
.
mDeviceId
.
GetAsString
(
)
.
EqualsASCII
(
"
bad
device
"
)
)
{
return
NS_ERROR_FAILURE
;
}
mState
=
kAllocated
;
mSineGenerator
=
new
SineWaveGenerator
(
AUDIO_RATE
static_cast
<
uint32_t
>
(
aPrefs
.
mFreq
?
aPrefs
.
mFreq
:
1000
)
)
;
*
aOutHandle
=
nullptr
;
return
NS_OK
;
}
nsresult
MediaEngineDefaultAudioSource
:
:
Deallocate
(
AllocationHandle
*
aHandle
)
{
MOZ_ASSERT
(
!
aHandle
)
;
if
(
mState
!
=
kStopped
&
&
mState
!
=
kAllocated
)
{
return
NS_ERROR_FAILURE
;
}
mState
=
kReleased
;
return
NS_OK
;
}
nsresult
MediaEngineDefaultAudioSource
:
:
Start
(
SourceMediaStream
*
aStream
TrackID
aID
const
PrincipalHandle
&
aPrincipalHandle
)
{
if
(
mState
!
=
kAllocated
)
{
return
NS_ERROR_FAILURE
;
}
mTimer
=
do_CreateInstance
(
NS_TIMER_CONTRACTID
)
;
if
(
!
mTimer
)
{
return
NS_ERROR_FAILURE
;
}
mSource
=
aStream
;
mBufferSize
=
2
*
(
AUDIO_RATE
*
DEFAULT_AUDIO_TIMER_MS
)
/
1000
;
AudioSegment
*
segment
=
new
AudioSegment
(
)
;
AppendToSegment
(
*
segment
mBufferSize
)
;
mSource
-
>
AddAudioTrack
(
aID
AUDIO_RATE
0
segment
SourceMediaStream
:
:
ADDTRACK_QUEUED
)
;
mTrackID
=
aID
;
mPrincipalHandle
=
aPrincipalHandle
;
mLastNotify
=
TimeStamp
:
:
Now
(
)
;
#
if
defined
(
MOZ_WIDGET_GONK
)
&
&
defined
(
DEBUG
)
mTimer
-
>
InitWithCallback
(
this
DEFAULT_AUDIO_TIMER_MS
*
10
nsITimer
:
:
TYPE_REPEATING_PRECISE_CAN_SKIP
)
;
#
else
mTimer
-
>
InitWithCallback
(
this
DEFAULT_AUDIO_TIMER_MS
nsITimer
:
:
TYPE_REPEATING_PRECISE_CAN_SKIP
)
;
#
endif
mState
=
kStarted
;
return
NS_OK
;
}
nsresult
MediaEngineDefaultAudioSource
:
:
Stop
(
SourceMediaStream
*
aSource
TrackID
aID
)
{
if
(
mState
!
=
kStarted
)
{
return
NS_ERROR_FAILURE
;
}
if
(
!
mTimer
)
{
return
NS_ERROR_FAILURE
;
}
mTimer
-
>
Cancel
(
)
;
mTimer
=
nullptr
;
aSource
-
>
EndTrack
(
aID
)
;
mState
=
kStopped
;
return
NS_OK
;
}
nsresult
MediaEngineDefaultAudioSource
:
:
Restart
(
AllocationHandle
*
aHandle
const
dom
:
:
MediaTrackConstraints
&
aConstraints
const
MediaEnginePrefs
&
aPrefs
const
nsString
&
aDeviceId
const
char
*
*
aOutBadConstraint
)
{
return
NS_OK
;
}
void
MediaEngineDefaultAudioSource
:
:
AppendToSegment
(
AudioSegment
&
aSegment
TrackTicks
aSamples
)
{
RefPtr
<
SharedBuffer
>
buffer
=
SharedBuffer
:
:
Create
(
aSamples
*
sizeof
(
int16_t
)
)
;
int16_t
*
dest
=
static_cast
<
int16_t
*
>
(
buffer
-
>
Data
(
)
)
;
mSineGenerator
-
>
generate
(
dest
aSamples
)
;
AutoTArray
<
const
int16_t
*
1
>
channels
;
channels
.
AppendElement
(
dest
)
;
aSegment
.
AppendFrames
(
buffer
.
forget
(
)
channels
aSamples
mPrincipalHandle
)
;
}
NS_IMETHODIMP
MediaEngineDefaultAudioSource
:
:
Notify
(
nsITimer
*
aTimer
)
{
TimeStamp
now
=
TimeStamp
:
:
Now
(
)
;
TimeDuration
timeSinceLastNotify
=
now
-
mLastNotify
;
mLastNotify
=
now
;
TrackTicks
samplesSinceLastNotify
=
RateConvertTicksRoundUp
(
AUDIO_RATE
1000000
timeSinceLastNotify
.
ToMicroseconds
(
)
)
;
TrackTicks
samplesToAppend
=
std
:
:
min
(
samplesSinceLastNotify
mBufferSize
)
;
AudioSegment
segment
;
AppendToSegment
(
segment
samplesToAppend
)
;
mSource
-
>
AppendToTrack
(
mTrackID
&
segment
)
;
return
NS_OK
;
}
void
MediaEngineDefault
:
:
EnumerateVideoDevices
(
dom
:
:
MediaSourceEnum
aMediaSource
nsTArray
<
RefPtr
<
MediaEngineVideoSource
>
>
*
aVSources
)
{
MutexAutoLock
lock
(
mMutex
)
;
if
(
aMediaSource
!
=
dom
:
:
MediaSourceEnum
:
:
Camera
)
{
return
;
}
RefPtr
<
MediaEngineVideoSource
>
newSource
=
new
MediaEngineDefaultVideoSource
(
)
;
mVSources
.
AppendElement
(
newSource
)
;
aVSources
-
>
AppendElement
(
newSource
)
;
return
;
}
void
MediaEngineDefault
:
:
EnumerateAudioDevices
(
dom
:
:
MediaSourceEnum
aMediaSource
nsTArray
<
RefPtr
<
MediaEngineAudioSource
>
>
*
aASources
)
{
MutexAutoLock
lock
(
mMutex
)
;
int32_t
len
=
mASources
.
Length
(
)
;
for
(
int32_t
i
=
0
;
i
<
len
;
i
+
+
)
{
RefPtr
<
MediaEngineAudioSource
>
source
=
mASources
.
ElementAt
(
i
)
;
if
(
source
-
>
IsAvailable
(
)
)
{
aASources
-
>
AppendElement
(
source
)
;
}
}
if
(
aASources
-
>
Length
(
)
=
=
0
)
{
RefPtr
<
MediaEngineAudioSource
>
newSource
=
new
MediaEngineDefaultAudioSource
(
)
;
mASources
.
AppendElement
(
newSource
)
;
aASources
-
>
AppendElement
(
newSource
)
;
}
return
;
}
}
