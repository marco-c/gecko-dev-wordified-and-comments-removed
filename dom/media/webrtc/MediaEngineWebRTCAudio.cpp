#
include
"
MediaEngineWebRTCAudio
.
h
"
#
include
<
stdio
.
h
>
#
include
<
algorithm
>
#
include
"
AudioConverter
.
h
"
#
include
"
MediaManager
.
h
"
#
include
"
MediaStreamGraphImpl
.
h
"
#
include
"
MediaTrackConstraints
.
h
"
#
include
"
mozilla
/
Assertions
.
h
"
#
include
"
mozilla
/
ErrorNames
.
h
"
#
include
"
mtransport
/
runnable_utils
.
h
"
#
include
"
nsAutoPtr
.
h
"
#
include
"
Tracing
.
h
"
#
ifdef
FF
#
undef
FF
#
endif
#
include
"
webrtc
/
voice_engine
/
voice_engine_defines
.
h
"
#
include
"
webrtc
/
modules
/
audio_processing
/
include
/
audio_processing
.
h
"
#
include
"
webrtc
/
common_audio
/
include
/
audio_util
.
h
"
using
namespace
webrtc
;
#
define
MAX_CHANNELS
2
#
define
MAX_SAMPLING_FREQ
48000
/
/
Hz
-
multiple
of
100
namespace
mozilla
{
extern
LazyLogModule
gMediaManagerLog
;
#
define
LOG
(
.
.
.
)
MOZ_LOG
(
gMediaManagerLog
LogLevel
:
:
Debug
(
__VA_ARGS__
)
)
#
define
LOG_FRAME
(
.
.
.
)
\
MOZ_LOG
(
gMediaManagerLog
LogLevel
:
:
Verbose
(
__VA_ARGS__
)
)
#
define
LOG_ERROR
(
.
.
.
)
MOZ_LOG
(
gMediaManagerLog
LogLevel
:
:
Error
(
__VA_ARGS__
)
)
MediaEngineWebRTCMicrophoneSource
:
:
MediaEngineWebRTCMicrophoneSource
(
RefPtr
<
AudioDeviceInfo
>
aInfo
const
nsString
&
aDeviceName
const
nsCString
&
aDeviceUUID
uint32_t
aMaxChannelCount
bool
aDelayAgnostic
bool
aExtendedFilter
)
:
mTrackID
(
TRACK_NONE
)
mPrincipal
(
PRINCIPAL_HANDLE_NONE
)
mDeviceInfo
(
std
:
:
move
(
aInfo
)
)
mDelayAgnostic
(
aDelayAgnostic
)
mExtendedFilter
(
aExtendedFilter
)
mDeviceName
(
aDeviceName
)
mDeviceUUID
(
aDeviceUUID
)
mDeviceMaxChannelCount
(
aMaxChannelCount
)
mSettings
(
new
nsMainThreadPtrHolder
<
media
:
:
Refcountable
<
dom
:
:
MediaTrackSettings
>
>
(
"
MediaEngineWebRTCMicrophoneSource
:
:
mSettings
"
new
media
:
:
Refcountable
<
dom
:
:
MediaTrackSettings
>
(
)
false
)
)
{
#
ifndef
ANDROID
MOZ_ASSERT
(
mDeviceInfo
-
>
DeviceID
(
)
)
;
#
endif
mSettings
-
>
mEchoCancellation
.
Construct
(
0
)
;
mSettings
-
>
mAutoGainControl
.
Construct
(
0
)
;
mSettings
-
>
mNoiseSuppression
.
Construct
(
0
)
;
mSettings
-
>
mChannelCount
.
Construct
(
0
)
;
mState
=
kReleased
;
}
nsString
MediaEngineWebRTCMicrophoneSource
:
:
GetName
(
)
const
{
return
mDeviceName
;
}
nsCString
MediaEngineWebRTCMicrophoneSource
:
:
GetUUID
(
)
const
{
return
mDeviceUUID
;
}
uint32_t
MediaEngineWebRTCMicrophoneSource
:
:
GetBestFitnessDistance
(
const
nsTArray
<
const
NormalizedConstraintSet
*
>
&
aConstraintSets
const
nsString
&
aDeviceId
)
const
{
uint32_t
distance
=
0
;
for
(
const
auto
*
cs
:
aConstraintSets
)
{
distance
=
MediaConstraintsHelper
:
:
GetMinimumFitnessDistance
(
*
cs
aDeviceId
)
;
break
;
}
return
distance
;
}
nsresult
MediaEngineWebRTCMicrophoneSource
:
:
EvaluateSettings
(
const
NormalizedConstraints
&
aConstraintsUpdate
const
MediaEnginePrefs
&
aInPrefs
MediaEnginePrefs
*
aOutPrefs
const
char
*
*
aOutBadConstraint
)
{
AssertIsOnOwningThread
(
)
;
FlattenedConstraints
c
(
aConstraintsUpdate
)
;
MediaEnginePrefs
prefs
=
aInPrefs
;
prefs
.
mAecOn
=
c
.
mEchoCancellation
.
Get
(
aInPrefs
.
mAecOn
)
;
prefs
.
mAgcOn
=
c
.
mAutoGainControl
.
Get
(
aInPrefs
.
mAgcOn
&
&
prefs
.
mAecOn
)
;
prefs
.
mNoiseOn
=
c
.
mNoiseSuppression
.
Get
(
aInPrefs
.
mNoiseOn
&
&
prefs
.
mAecOn
)
;
int32_t
maxChannels
=
mDeviceInfo
-
>
MaxChannels
(
)
;
if
(
c
.
mChannelCount
.
mMin
>
maxChannels
)
{
*
aOutBadConstraint
=
"
channelCount
"
;
return
NS_ERROR_FAILURE
;
}
if
(
aInPrefs
.
mChannels
<
=
0
)
{
prefs
.
mChannels
=
maxChannels
;
}
prefs
.
mChannels
=
c
.
mChannelCount
.
Get
(
std
:
:
min
(
aInPrefs
.
mChannels
maxChannels
)
)
;
prefs
.
mChannels
=
std
:
:
max
(
1
std
:
:
min
(
prefs
.
mChannels
maxChannels
)
)
;
LOG
(
"
Audio
config
:
aec
:
%
d
agc
:
%
d
noise
:
%
d
channels
:
%
d
"
prefs
.
mAecOn
?
prefs
.
mAec
:
-
1
prefs
.
mAgcOn
?
prefs
.
mAgc
:
-
1
prefs
.
mNoiseOn
?
prefs
.
mNoise
:
-
1
prefs
.
mChannels
)
;
*
aOutPrefs
=
prefs
;
return
NS_OK
;
}
nsresult
MediaEngineWebRTCMicrophoneSource
:
:
Reconfigure
(
const
RefPtr
<
AllocationHandle
>
&
const
dom
:
:
MediaTrackConstraints
&
aConstraints
const
MediaEnginePrefs
&
aPrefs
const
nsString
&
const
char
*
*
aOutBadConstraint
)
{
AssertIsOnOwningThread
(
)
;
MOZ_ASSERT
(
mStream
)
;
LOG
(
"
Mic
source
%
p
Reconfigure
"
this
)
;
NormalizedConstraints
constraints
(
aConstraints
)
;
MediaEnginePrefs
outputPrefs
;
nsresult
rv
=
EvaluateSettings
(
constraints
aPrefs
&
outputPrefs
aOutBadConstraint
)
;
if
(
NS_FAILED
(
rv
)
)
{
if
(
aOutBadConstraint
)
{
return
NS_ERROR_INVALID_ARG
;
}
nsAutoCString
name
;
GetErrorName
(
rv
name
)
;
LOG
(
"
Mic
source
%
p
Reconfigure
(
)
failed
unexpectedly
.
rv
=
%
s
"
this
name
.
Data
(
)
)
;
Stop
(
nullptr
)
;
return
NS_ERROR_UNEXPECTED
;
}
ApplySettings
(
outputPrefs
)
;
mCurrentPrefs
=
outputPrefs
;
return
NS_OK
;
}
void
MediaEngineWebRTCMicrophoneSource
:
:
Pull
(
const
RefPtr
<
const
AllocationHandle
>
&
const
RefPtr
<
SourceMediaStream
>
&
aStream
TrackID
aTrackID
StreamTime
aEndOfAppendedData
StreamTime
aDesiredTime
const
PrincipalHandle
&
aPrincipalHandle
)
{
mInputProcessing
-
>
Pull
(
aStream
aTrackID
aEndOfAppendedData
aDesiredTime
aPrincipalHandle
)
;
}
void
MediaEngineWebRTCMicrophoneSource
:
:
UpdateAECSettings
(
bool
aEnable
bool
aUseAecMobile
EchoCancellation
:
:
SuppressionLevel
aLevel
)
{
AssertIsOnOwningThread
(
)
;
RefPtr
<
MediaEngineWebRTCMicrophoneSource
>
that
=
this
;
RefPtr
<
MediaStreamGraphImpl
>
gripGraph
=
mStream
-
>
GraphImpl
(
)
;
NS_DispatchToMainThread
(
media
:
:
NewRunnableFrom
(
[
that
graph
=
std
:
:
move
(
gripGraph
)
aEnable
aUseAecMobile
aLevel
]
(
)
{
class
Message
:
public
ControlMessage
{
public
:
Message
(
AudioInputProcessing
*
aInputProcessing
bool
aEnable
bool
aUseAecMobile
EchoCancellation
:
:
SuppressionLevel
aLevel
)
:
ControlMessage
(
nullptr
)
mInputProcessing
(
aInputProcessing
)
mEnable
(
aEnable
)
mUseAecMobile
(
aUseAecMobile
)
mLevel
(
aLevel
)
{
}
void
Run
(
)
override
{
mInputProcessing
-
>
UpdateAECSettings
(
mEnable
mUseAecMobile
mLevel
)
;
}
protected
:
RefPtr
<
AudioInputProcessing
>
mInputProcessing
;
bool
mEnable
;
bool
mUseAecMobile
;
EchoCancellation
:
:
SuppressionLevel
mLevel
;
}
;
if
(
graph
)
{
graph
-
>
AppendMessage
(
MakeUnique
<
Message
>
(
that
-
>
mInputProcessing
aEnable
aUseAecMobile
aLevel
)
)
;
}
return
NS_OK
;
}
)
)
;
}
void
MediaEngineWebRTCMicrophoneSource
:
:
UpdateAGCSettings
(
bool
aEnable
GainControl
:
:
Mode
aMode
)
{
AssertIsOnOwningThread
(
)
;
RefPtr
<
MediaEngineWebRTCMicrophoneSource
>
that
=
this
;
RefPtr
<
MediaStreamGraphImpl
>
gripGraph
=
mStream
-
>
GraphImpl
(
)
;
NS_DispatchToMainThread
(
media
:
:
NewRunnableFrom
(
[
that
graph
=
std
:
:
move
(
gripGraph
)
aEnable
aMode
]
(
)
{
class
Message
:
public
ControlMessage
{
public
:
Message
(
AudioInputProcessing
*
aInputProcessing
bool
aEnable
GainControl
:
:
Mode
aMode
)
:
ControlMessage
(
nullptr
)
mInputProcessing
(
aInputProcessing
)
mEnable
(
aEnable
)
mMode
(
aMode
)
{
}
void
Run
(
)
override
{
mInputProcessing
-
>
UpdateAGCSettings
(
mEnable
mMode
)
;
}
protected
:
RefPtr
<
AudioInputProcessing
>
mInputProcessing
;
bool
mEnable
;
GainControl
:
:
Mode
mMode
;
}
;
if
(
graph
)
{
graph
-
>
AppendMessage
(
MakeUnique
<
Message
>
(
that
-
>
mInputProcessing
aEnable
aMode
)
)
;
}
return
NS_OK
;
}
)
)
;
}
void
MediaEngineWebRTCMicrophoneSource
:
:
UpdateNSSettings
(
bool
aEnable
webrtc
:
:
NoiseSuppression
:
:
Level
aLevel
)
{
AssertIsOnOwningThread
(
)
;
RefPtr
<
MediaEngineWebRTCMicrophoneSource
>
that
=
this
;
RefPtr
<
MediaStreamGraphImpl
>
gripGraph
=
mStream
-
>
GraphImpl
(
)
;
NS_DispatchToMainThread
(
media
:
:
NewRunnableFrom
(
[
that
graph
=
std
:
:
move
(
gripGraph
)
aEnable
aLevel
]
(
)
{
class
Message
:
public
ControlMessage
{
public
:
Message
(
AudioInputProcessing
*
aInputProcessing
bool
aEnable
webrtc
:
:
NoiseSuppression
:
:
Level
aLevel
)
:
ControlMessage
(
nullptr
)
mInputProcessing
(
aInputProcessing
)
mEnable
(
aEnable
)
mLevel
(
aLevel
)
{
}
void
Run
(
)
override
{
mInputProcessing
-
>
UpdateNSSettings
(
mEnable
mLevel
)
;
}
protected
:
RefPtr
<
AudioInputProcessing
>
mInputProcessing
;
bool
mEnable
;
webrtc
:
:
NoiseSuppression
:
:
Level
mLevel
;
}
;
if
(
graph
)
{
graph
-
>
AppendMessage
(
MakeUnique
<
Message
>
(
that
-
>
mInputProcessing
aEnable
aLevel
)
)
;
}
return
NS_OK
;
}
)
)
;
}
void
MediaEngineWebRTCMicrophoneSource
:
:
UpdateAPMExtraOptions
(
bool
aExtendedFilter
bool
aDelayAgnostic
)
{
AssertIsOnOwningThread
(
)
;
RefPtr
<
MediaEngineWebRTCMicrophoneSource
>
that
=
this
;
RefPtr
<
MediaStreamGraphImpl
>
gripGraph
=
mStream
-
>
GraphImpl
(
)
;
NS_DispatchToMainThread
(
media
:
:
NewRunnableFrom
(
[
that
graph
=
std
:
:
move
(
gripGraph
)
aExtendedFilter
aDelayAgnostic
]
(
)
{
class
Message
:
public
ControlMessage
{
public
:
Message
(
AudioInputProcessing
*
aInputProcessing
bool
aExtendedFilter
bool
aDelayAgnostic
)
:
ControlMessage
(
nullptr
)
mInputProcessing
(
aInputProcessing
)
mExtendedFilter
(
aExtendedFilter
)
mDelayAgnostic
(
aDelayAgnostic
)
{
}
void
Run
(
)
override
{
mInputProcessing
-
>
UpdateAPMExtraOptions
(
mExtendedFilter
mDelayAgnostic
)
;
}
protected
:
RefPtr
<
AudioInputProcessing
>
mInputProcessing
;
bool
mExtendedFilter
;
bool
mDelayAgnostic
;
}
;
if
(
graph
)
{
graph
-
>
AppendMessage
(
MakeUnique
<
Message
>
(
that
-
>
mInputProcessing
aExtendedFilter
aDelayAgnostic
)
)
;
}
return
NS_OK
;
}
)
)
;
}
void
MediaEngineWebRTCMicrophoneSource
:
:
ApplySettings
(
const
MediaEnginePrefs
&
aPrefs
)
{
AssertIsOnOwningThread
(
)
;
MOZ_ASSERT
(
mStream
"
ApplySetting
is
to
be
called
only
after
SetTrack
has
been
called
"
)
;
if
(
mStream
)
{
UpdateAGCSettings
(
aPrefs
.
mAgcOn
static_cast
<
webrtc
:
:
GainControl
:
:
Mode
>
(
aPrefs
.
mAgc
)
)
;
UpdateNSSettings
(
aPrefs
.
mNoiseOn
static_cast
<
webrtc
:
:
NoiseSuppression
:
:
Level
>
(
aPrefs
.
mNoise
)
)
;
UpdateAECSettings
(
aPrefs
.
mAecOn
aPrefs
.
mUseAecMobile
static_cast
<
webrtc
:
:
EchoCancellation
:
:
SuppressionLevel
>
(
aPrefs
.
mAec
)
)
;
UpdateAPMExtraOptions
(
mExtendedFilter
mDelayAgnostic
)
;
}
RefPtr
<
MediaEngineWebRTCMicrophoneSource
>
that
=
this
;
RefPtr
<
MediaStreamGraphImpl
>
graphImpl
=
mStream
-
>
GraphImpl
(
)
;
NS_DispatchToMainThread
(
media
:
:
NewRunnableFrom
(
[
that
graph
=
std
:
:
move
(
graphImpl
)
prefs
=
aPrefs
]
(
)
{
that
-
>
mSettings
-
>
mEchoCancellation
.
Value
(
)
=
prefs
.
mAecOn
;
that
-
>
mSettings
-
>
mAutoGainControl
.
Value
(
)
=
prefs
.
mAgcOn
;
that
-
>
mSettings
-
>
mNoiseSuppression
.
Value
(
)
=
prefs
.
mNoiseOn
;
that
-
>
mSettings
-
>
mChannelCount
.
Value
(
)
=
prefs
.
mChannels
;
class
Message
:
public
ControlMessage
{
public
:
Message
(
AudioInputProcessing
*
aInputProcessing
bool
aPassThrough
uint32_t
aRequestedInputChannelCount
)
:
ControlMessage
(
nullptr
)
mInputProcessing
(
aInputProcessing
)
mPassThrough
(
aPassThrough
)
mRequestedInputChannelCount
(
aRequestedInputChannelCount
)
{
}
void
Run
(
)
override
{
mInputProcessing
-
>
SetPassThrough
(
mPassThrough
)
;
mInputProcessing
-
>
SetRequestedInputChannelCount
(
mRequestedInputChannelCount
)
;
}
protected
:
RefPtr
<
AudioInputProcessing
>
mInputProcessing
;
bool
mPassThrough
;
uint32_t
mRequestedInputChannelCount
;
}
;
bool
passThrough
=
!
(
prefs
.
mAecOn
|
|
prefs
.
mAgcOn
|
|
prefs
.
mNoiseOn
)
;
if
(
graph
)
{
graph
-
>
AppendMessage
(
MakeUnique
<
Message
>
(
that
-
>
mInputProcessing
passThrough
prefs
.
mChannels
)
)
;
}
return
NS_OK
;
}
)
)
;
}
nsresult
MediaEngineWebRTCMicrophoneSource
:
:
Allocate
(
const
dom
:
:
MediaTrackConstraints
&
aConstraints
const
MediaEnginePrefs
&
aPrefs
const
nsString
&
aDeviceId
const
ipc
:
:
PrincipalInfo
&
aPrincipalInfo
AllocationHandle
*
*
aOutHandle
const
char
*
*
aOutBadConstraint
)
{
AssertIsOnOwningThread
(
)
;
MOZ_ASSERT
(
aOutHandle
)
;
*
aOutHandle
=
nullptr
;
mState
=
kAllocated
;
NormalizedConstraints
normalized
(
aConstraints
)
;
MediaEnginePrefs
outputPrefs
;
nsresult
rv
=
EvaluateSettings
(
normalized
aPrefs
&
outputPrefs
aOutBadConstraint
)
;
if
(
NS_FAILED
(
rv
)
)
{
return
rv
;
}
RefPtr
<
MediaEngineWebRTCMicrophoneSource
>
that
=
this
;
NS_DispatchToMainThread
(
media
:
:
NewRunnableFrom
(
[
that
prefs
=
outputPrefs
]
(
)
{
that
-
>
mSettings
-
>
mEchoCancellation
.
Value
(
)
=
prefs
.
mAecOn
;
that
-
>
mSettings
-
>
mAutoGainControl
.
Value
(
)
=
prefs
.
mAgcOn
;
that
-
>
mSettings
-
>
mNoiseSuppression
.
Value
(
)
=
prefs
.
mNoiseOn
;
that
-
>
mSettings
-
>
mChannelCount
.
Value
(
)
=
prefs
.
mChannels
;
return
NS_OK
;
}
)
)
;
mCurrentPrefs
=
outputPrefs
;
return
rv
;
}
nsresult
MediaEngineWebRTCMicrophoneSource
:
:
Deallocate
(
const
RefPtr
<
const
AllocationHandle
>
&
)
{
AssertIsOnOwningThread
(
)
;
MOZ_ASSERT
(
mState
=
=
kStopped
|
|
mState
=
=
kAllocated
)
;
class
EndTrackMessage
:
public
ControlMessage
{
public
:
EndTrackMessage
(
MediaStream
*
aStream
AudioInputProcessing
*
aAudioInputProcessing
TrackID
aTrackID
)
:
ControlMessage
(
aStream
)
mInputProcessing
(
aAudioInputProcessing
)
mTrackID
(
aTrackID
)
{
}
void
Run
(
)
override
{
mInputProcessing
-
>
End
(
)
;
mStream
-
>
AsSourceStream
(
)
-
>
EndTrack
(
mTrackID
)
;
}
protected
:
RefPtr
<
AudioInputProcessing
>
mInputProcessing
;
TrackID
mTrackID
;
}
;
if
(
mStream
&
&
IsTrackIDExplicit
(
mTrackID
)
)
{
RefPtr
<
MediaStream
>
sourceStream
=
mStream
;
RefPtr
<
AudioInputProcessing
>
inputProcessing
=
mInputProcessing
;
NS_DispatchToMainThread
(
media
:
:
NewRunnableFrom
(
[
stream
=
std
:
:
move
(
sourceStream
)
audioInputProcessing
=
std
:
:
move
(
inputProcessing
)
trackID
=
mTrackID
]
(
)
{
if
(
stream
-
>
IsDestroyed
(
)
)
{
return
NS_OK
;
}
MOZ_ASSERT
(
stream
-
>
GraphImpl
(
)
)
;
stream
-
>
GraphImpl
(
)
-
>
AppendMessage
(
MakeUnique
<
EndTrackMessage
>
(
stream
audioInputProcessing
trackID
)
)
;
return
NS_OK
;
}
)
)
;
}
MOZ_ASSERT
(
mTrackID
!
=
TRACK_NONE
"
Only
deallocate
once
"
)
;
mStream
=
nullptr
;
mTrackID
=
TRACK_NONE
;
mPrincipal
=
PRINCIPAL_HANDLE_NONE
;
MOZ_ASSERT
(
mState
!
=
kReleased
"
Source
not
allocated
"
)
;
MOZ_ASSERT
(
mState
!
=
kStarted
"
Source
not
stopped
"
)
;
mState
=
kReleased
;
LOG
(
"
Audio
device
%
s
deallocated
"
NS_ConvertUTF16toUTF8
(
mDeviceName
)
.
get
(
)
)
;
return
NS_OK
;
}
void
MediaEngineWebRTCMicrophoneSource
:
:
SetTrack
(
const
RefPtr
<
const
AllocationHandle
>
&
const
RefPtr
<
SourceMediaStream
>
&
aStream
TrackID
aTrackID
const
PrincipalHandle
&
aPrincipal
)
{
AssertIsOnOwningThread
(
)
;
MOZ_ASSERT
(
aStream
)
;
MOZ_ASSERT
(
IsTrackIDExplicit
(
aTrackID
)
)
;
MOZ_ASSERT
(
!
mStream
)
;
MOZ_ASSERT
(
mTrackID
=
=
TRACK_NONE
)
;
MOZ_ASSERT
(
mPrincipal
=
=
PRINCIPAL_HANDLE_NONE
)
;
mStream
=
aStream
;
mTrackID
=
aTrackID
;
mPrincipal
=
aPrincipal
;
AudioSegment
*
segment
=
new
AudioSegment
(
)
;
aStream
-
>
AddAudioTrack
(
aTrackID
aStream
-
>
GraphRate
(
)
segment
SourceMediaStream
:
:
ADDTRACK_QUEUED
)
;
mInputProcessing
=
new
AudioInputProcessing
(
mDeviceMaxChannelCount
mStream
mTrackID
mPrincipal
)
;
LOG
(
"
Stream
%
p
registered
for
microphone
capture
"
aStream
.
get
(
)
)
;
}
class
StartStopMessage
:
public
ControlMessage
{
public
:
enum
StartStop
{
Start
Stop
}
;
StartStopMessage
(
AudioInputProcessing
*
aInputProcessing
StartStop
aAction
)
:
ControlMessage
(
nullptr
)
mInputProcessing
(
aInputProcessing
)
mAction
(
aAction
)
{
}
void
Run
(
)
override
{
if
(
mAction
=
=
StartStopMessage
:
:
Start
)
{
mInputProcessing
-
>
Start
(
)
;
}
else
if
(
mAction
=
=
StartStopMessage
:
:
Stop
)
{
mInputProcessing
-
>
Stop
(
)
;
}
else
{
MOZ_CRASH
(
"
Invalid
enum
value
"
)
;
}
}
protected
:
RefPtr
<
AudioInputProcessing
>
mInputProcessing
;
StartStop
mAction
;
}
;
nsresult
MediaEngineWebRTCMicrophoneSource
:
:
Start
(
const
RefPtr
<
const
AllocationHandle
>
&
)
{
AssertIsOnOwningThread
(
)
;
if
(
mState
=
=
kStarted
)
{
return
NS_OK
;
}
MOZ_ASSERT
(
mState
=
=
kAllocated
|
|
mState
=
=
kStopped
)
;
CubebUtils
:
:
AudioDeviceID
deviceID
=
mDeviceInfo
-
>
DeviceID
(
)
;
if
(
mStream
-
>
GraphImpl
(
)
-
>
InputDeviceID
(
)
&
&
mStream
-
>
GraphImpl
(
)
-
>
InputDeviceID
(
)
!
=
deviceID
)
{
return
NS_ERROR_FAILURE
;
}
RefPtr
<
MediaEngineWebRTCMicrophoneSource
>
that
=
this
;
NS_DispatchToMainThread
(
media
:
:
NewRunnableFrom
(
[
that
deviceID
stream
=
mStream
track
=
mTrackID
]
(
)
{
if
(
stream
-
>
IsDestroyed
(
)
)
{
return
NS_OK
;
}
stream
-
>
GraphImpl
(
)
-
>
AppendMessage
(
MakeUnique
<
StartStopMessage
>
(
that
-
>
mInputProcessing
StartStopMessage
:
:
Start
)
)
;
stream
-
>
SetPullingEnabled
(
track
true
)
;
stream
-
>
OpenAudioInput
(
deviceID
that
-
>
mInputProcessing
)
;
return
NS_OK
;
}
)
)
;
ApplySettings
(
mCurrentPrefs
)
;
MOZ_ASSERT
(
mState
!
=
kReleased
)
;
mState
=
kStarted
;
return
NS_OK
;
}
nsresult
MediaEngineWebRTCMicrophoneSource
:
:
Stop
(
const
RefPtr
<
const
AllocationHandle
>
&
)
{
AssertIsOnOwningThread
(
)
;
LOG
(
"
Mic
source
%
p
Stop
(
)
"
this
)
;
MOZ_ASSERT
(
mStream
"
SetTrack
must
have
been
called
before
:
:
Stop
"
)
;
if
(
mState
=
=
kStopped
)
{
return
NS_OK
;
}
RefPtr
<
MediaEngineWebRTCMicrophoneSource
>
that
=
this
;
NS_DispatchToMainThread
(
media
:
:
NewRunnableFrom
(
[
that
stream
=
mStream
]
(
)
{
if
(
stream
-
>
IsDestroyed
(
)
)
{
return
NS_OK
;
}
stream
-
>
GraphImpl
(
)
-
>
AppendMessage
(
MakeUnique
<
StartStopMessage
>
(
that
-
>
mInputProcessing
StartStopMessage
:
:
Stop
)
)
;
CubebUtils
:
:
AudioDeviceID
deviceID
=
that
-
>
mDeviceInfo
-
>
DeviceID
(
)
;
Maybe
<
CubebUtils
:
:
AudioDeviceID
>
id
=
Some
(
deviceID
)
;
stream
-
>
CloseAudioInput
(
id
that
-
>
mInputProcessing
)
;
return
NS_OK
;
}
)
)
;
MOZ_ASSERT
(
mState
=
=
kStarted
"
Should
be
started
when
stopping
"
)
;
mState
=
kStopped
;
return
NS_OK
;
}
void
MediaEngineWebRTCMicrophoneSource
:
:
GetSettings
(
dom
:
:
MediaTrackSettings
&
aOutSettings
)
const
{
MOZ_ASSERT
(
NS_IsMainThread
(
)
)
;
aOutSettings
=
*
mSettings
;
}
AudioInputProcessing
:
:
AudioInputProcessing
(
uint32_t
aMaxChannelCount
RefPtr
<
SourceMediaStream
>
aStream
TrackID
aTrackID
const
PrincipalHandle
&
aPrincipalHandle
)
:
mStream
(
std
:
:
move
(
aStream
)
)
mAudioProcessing
(
AudioProcessing
:
:
Create
(
)
)
mRequestedInputChannelCount
(
aMaxChannelCount
)
mSkipProcessing
(
false
)
mInputDownmixBuffer
(
MAX_SAMPLING_FREQ
*
MAX_CHANNELS
/
100
)
#
ifdef
DEBUG
mLastCallbackAppendTime
(
0
)
#
endif
mLiveFramesAppended
(
false
)
mLiveSilenceAppended
(
false
)
mTrackID
(
aTrackID
)
mPrincipal
(
aPrincipalHandle
)
mEnabled
(
false
)
mEnded
(
false
)
{
}
void
AudioInputProcessing
:
:
Disconnect
(
MediaStreamGraphImpl
*
aGraph
)
{
MOZ_ASSERT
(
aGraph
-
>
CurrentDriver
(
)
-
>
OnThread
(
)
)
;
}
void
MediaEngineWebRTCMicrophoneSource
:
:
Shutdown
(
)
{
AssertIsOnOwningThread
(
)
;
if
(
mState
=
=
kStarted
)
{
Stop
(
nullptr
)
;
MOZ_ASSERT
(
mState
=
=
kStopped
)
;
}
MOZ_ASSERT
(
mState
=
=
kAllocated
|
|
mState
=
=
kStopped
)
;
Deallocate
(
nullptr
)
;
MOZ_ASSERT
(
mState
=
=
kReleased
)
;
}
bool
AudioInputProcessing
:
:
PassThrough
(
MediaStreamGraphImpl
*
aGraph
)
const
{
MOZ_ASSERT
(
aGraph
-
>
CurrentDriver
(
)
-
>
OnThread
(
)
)
;
return
mSkipProcessing
;
}
void
AudioInputProcessing
:
:
SetPassThrough
(
bool
aPassThrough
)
{
mSkipProcessing
=
aPassThrough
;
}
uint32_t
AudioInputProcessing
:
:
GetRequestedInputChannelCount
(
MediaStreamGraphImpl
*
aGraphImpl
)
{
return
mRequestedInputChannelCount
;
}
void
AudioInputProcessing
:
:
SetRequestedInputChannelCount
(
uint32_t
aRequestedInputChannelCount
)
{
mRequestedInputChannelCount
=
aRequestedInputChannelCount
;
mStream
-
>
GraphImpl
(
)
-
>
ReevaluateInputDevice
(
)
;
}
#
define
HANDLE_APM_ERROR
(
fn
)
\
do
{
\
int
rv
=
fn
;
\
if
(
rv
!
=
AudioProcessing
:
:
kNoError
)
{
\
MOZ_ASSERT_UNREACHABLE
(
"
APM
error
in
"
#
fn
)
;
\
return
;
\
}
\
}
while
(
0
)
;
void
AudioInputProcessing
:
:
UpdateAECSettings
(
bool
aEnable
bool
aUseAecMobile
EchoCancellation
:
:
SuppressionLevel
aLevel
)
{
if
(
aUseAecMobile
)
{
HANDLE_APM_ERROR
(
mAudioProcessing
-
>
echo_control_mobile
(
)
-
>
Enable
(
aEnable
)
)
;
HANDLE_APM_ERROR
(
mAudioProcessing
-
>
echo_cancellation
(
)
-
>
Enable
(
false
)
)
;
}
else
{
if
(
aLevel
!
=
EchoCancellation
:
:
SuppressionLevel
:
:
kLowSuppression
&
&
aLevel
!
=
EchoCancellation
:
:
SuppressionLevel
:
:
kModerateSuppression
&
&
aLevel
!
=
EchoCancellation
:
:
SuppressionLevel
:
:
kHighSuppression
)
{
LOG_ERROR
(
"
Attempt
to
set
invalid
AEC
suppression
level
%
d
"
static_cast
<
int
>
(
aLevel
)
)
;
aLevel
=
EchoCancellation
:
:
SuppressionLevel
:
:
kModerateSuppression
;
}
HANDLE_APM_ERROR
(
mAudioProcessing
-
>
echo_control_mobile
(
)
-
>
Enable
(
false
)
)
;
HANDLE_APM_ERROR
(
mAudioProcessing
-
>
echo_cancellation
(
)
-
>
Enable
(
aEnable
)
)
;
HANDLE_APM_ERROR
(
mAudioProcessing
-
>
echo_cancellation
(
)
-
>
set_suppression_level
(
aLevel
)
)
;
}
}
void
AudioInputProcessing
:
:
UpdateAGCSettings
(
bool
aEnable
GainControl
:
:
Mode
aMode
)
{
if
(
aMode
!
=
GainControl
:
:
Mode
:
:
kAdaptiveAnalog
&
&
aMode
!
=
GainControl
:
:
Mode
:
:
kAdaptiveDigital
&
&
aMode
!
=
GainControl
:
:
Mode
:
:
kFixedDigital
)
{
LOG_ERROR
(
"
Attempt
to
set
invalid
AGC
mode
%
d
"
static_cast
<
int
>
(
aMode
)
)
;
aMode
=
GainControl
:
:
Mode
:
:
kAdaptiveDigital
;
}
#
if
defined
(
WEBRTC_IOS
)
|
|
defined
(
ATA
)
|
|
defined
(
WEBRTC_ANDROID
)
if
(
aMode
=
=
GainControl
:
:
Mode
:
:
kAdaptiveAnalog
)
{
LOG_ERROR
(
"
Invalid
AGC
mode
kAgcAdaptiveAnalog
on
mobile
"
)
;
MOZ_ASSERT_UNREACHABLE
(
"
Bad
pref
set
in
all
.
js
or
in
about
:
config
"
"
for
the
auto
gain
on
mobile
.
"
)
;
aMode
=
GainControl
:
:
Mode
:
:
kFixedDigital
;
}
#
endif
HANDLE_APM_ERROR
(
mAudioProcessing
-
>
gain_control
(
)
-
>
set_mode
(
aMode
)
)
;
HANDLE_APM_ERROR
(
mAudioProcessing
-
>
gain_control
(
)
-
>
Enable
(
aEnable
)
)
;
}
void
AudioInputProcessing
:
:
UpdateNSSettings
(
bool
aEnable
webrtc
:
:
NoiseSuppression
:
:
Level
aLevel
)
{
if
(
aLevel
!
=
NoiseSuppression
:
:
Level
:
:
kLow
&
&
aLevel
!
=
NoiseSuppression
:
:
Level
:
:
kModerate
&
&
aLevel
!
=
NoiseSuppression
:
:
Level
:
:
kHigh
&
&
aLevel
!
=
NoiseSuppression
:
:
Level
:
:
kVeryHigh
)
{
LOG_ERROR
(
"
Attempt
to
set
invalid
noise
suppression
level
%
d
"
static_cast
<
int
>
(
aLevel
)
)
;
aLevel
=
NoiseSuppression
:
:
Level
:
:
kModerate
;
}
HANDLE_APM_ERROR
(
mAudioProcessing
-
>
noise_suppression
(
)
-
>
set_level
(
aLevel
)
)
;
HANDLE_APM_ERROR
(
mAudioProcessing
-
>
noise_suppression
(
)
-
>
Enable
(
aEnable
)
)
;
}
#
undef
HANDLE_APM_ERROR
void
AudioInputProcessing
:
:
UpdateAPMExtraOptions
(
bool
aExtendedFilter
bool
aDelayAgnostic
)
{
webrtc
:
:
Config
config
;
config
.
Set
<
webrtc
:
:
ExtendedFilter
>
(
new
webrtc
:
:
ExtendedFilter
(
aExtendedFilter
)
)
;
config
.
Set
<
webrtc
:
:
DelayAgnostic
>
(
new
webrtc
:
:
DelayAgnostic
(
aDelayAgnostic
)
)
;
mAudioProcessing
-
>
SetExtraOptions
(
config
)
;
}
void
AudioInputProcessing
:
:
Start
(
)
{
mEnabled
=
true
;
mLiveFramesAppended
=
false
;
mLiveSilenceAppended
=
false
;
#
ifdef
DEBUG
mLastCallbackAppendTime
=
0
;
#
endif
}
void
AudioInputProcessing
:
:
Stop
(
)
{
mEnabled
=
false
;
}
void
AudioInputProcessing
:
:
Pull
(
const
RefPtr
<
SourceMediaStream
>
&
aStream
TrackID
aTrackID
StreamTime
aEndOfAppendedData
StreamTime
aDesiredTime
const
PrincipalHandle
&
aPrincipalHandle
)
{
TRACE_AUDIO_CALLBACK_COMMENT
(
"
SourceMediaStream
%
p
track
%
i
"
aStream
.
get
(
)
aTrackID
)
;
if
(
mEnded
)
{
return
;
}
StreamTime
delta
=
aDesiredTime
-
aEndOfAppendedData
;
MOZ_ASSERT
(
delta
>
0
)
;
if
(
!
mLiveFramesAppended
|
|
!
mLiveSilenceAppended
)
{
delta
+
=
WEBAUDIO_BLOCK_SIZE
;
MOZ_ASSERT_IF
(
!
PassThrough
(
aStream
-
>
GraphImpl
(
)
)
&
&
!
mPacketizerInput
!
mLiveFramesAppended
)
;
if
(
!
PassThrough
(
aStream
-
>
GraphImpl
(
)
)
&
&
mPacketizerInput
)
{
delta
+
=
mPacketizerInput
-
>
PacketSize
(
)
;
}
}
LOG_FRAME
(
"
Pulling
%
"
PRId64
"
frames
of
silence
.
"
delta
)
;
MOZ_ASSERT_IF
(
mEnabled
&
&
mLiveFramesAppended
&
&
mLiveSilenceAppended
aStream
-
>
GraphImpl
(
)
-
>
IterationEnd
(
)
>
mLastCallbackAppendTime
)
;
if
(
mLiveFramesAppended
)
{
mLiveSilenceAppended
=
true
;
}
AudioSegment
audio
;
audio
.
AppendNullData
(
delta
)
;
aStream
-
>
AppendToTrack
(
aTrackID
&
audio
)
;
}
void
AudioInputProcessing
:
:
NotifyOutputData
(
MediaStreamGraphImpl
*
aGraph
AudioDataValue
*
aBuffer
size_t
aFrames
TrackRate
aRate
uint32_t
aChannels
)
{
MOZ_ASSERT
(
aGraph
-
>
CurrentDriver
(
)
-
>
OnThread
(
)
)
;
MOZ_ASSERT
(
mEnabled
)
;
if
(
!
mPacketizerOutput
|
|
mPacketizerOutput
-
>
PacketSize
(
)
!
=
aRate
/
100u
|
|
mPacketizerOutput
-
>
Channels
(
)
!
=
aChannels
)
{
mPacketizerOutput
=
new
AudioPacketizer
<
AudioDataValue
float
>
(
aRate
/
100
aChannels
)
;
}
mPacketizerOutput
-
>
Input
(
aBuffer
aFrames
)
;
while
(
mPacketizerOutput
-
>
PacketsAvailable
(
)
)
{
uint32_t
samplesPerPacket
=
mPacketizerOutput
-
>
PacketSize
(
)
*
mPacketizerOutput
-
>
Channels
(
)
;
if
(
mOutputBuffer
.
Length
(
)
<
samplesPerPacket
)
{
mOutputBuffer
.
SetLength
(
samplesPerPacket
)
;
}
if
(
mDeinterleavedBuffer
.
Length
(
)
<
samplesPerPacket
)
{
mDeinterleavedBuffer
.
SetLength
(
samplesPerPacket
)
;
}
float
*
packet
=
mOutputBuffer
.
Data
(
)
;
mPacketizerOutput
-
>
Output
(
packet
)
;
AutoTArray
<
float
*
MAX_CHANNELS
>
deinterleavedPacketDataChannelPointers
;
float
*
interleavedFarend
=
nullptr
;
uint32_t
channelCountFarend
=
0
;
uint32_t
framesPerPacketFarend
=
0
;
if
(
aChannels
>
MAX_CHANNELS
)
{
AudioConverter
converter
(
AudioConfig
(
aChannels
0
AudioConfig
:
:
FORMAT_FLT
)
AudioConfig
(
MAX_CHANNELS
0
AudioConfig
:
:
FORMAT_FLT
)
)
;
framesPerPacketFarend
=
mPacketizerOutput
-
>
PacketSize
(
)
;
framesPerPacketFarend
=
converter
.
Process
(
mInputDownmixBuffer
packet
framesPerPacketFarend
)
;
interleavedFarend
=
mInputDownmixBuffer
.
Data
(
)
;
channelCountFarend
=
MAX_CHANNELS
;
deinterleavedPacketDataChannelPointers
.
SetLength
(
MAX_CHANNELS
)
;
}
else
{
interleavedFarend
=
packet
;
channelCountFarend
=
aChannels
;
framesPerPacketFarend
=
mPacketizerOutput
-
>
PacketSize
(
)
;
deinterleavedPacketDataChannelPointers
.
SetLength
(
aChannels
)
;
}
MOZ_ASSERT
(
interleavedFarend
&
&
(
channelCountFarend
=
=
1
|
|
channelCountFarend
=
=
2
)
&
&
framesPerPacketFarend
)
;
if
(
mInputBuffer
.
Length
(
)
<
framesPerPacketFarend
*
channelCountFarend
)
{
mInputBuffer
.
SetLength
(
framesPerPacketFarend
*
channelCountFarend
)
;
}
size_t
offset
=
0
;
for
(
size_t
i
=
0
;
i
<
deinterleavedPacketDataChannelPointers
.
Length
(
)
;
+
+
i
)
{
deinterleavedPacketDataChannelPointers
[
i
]
=
mInputBuffer
.
Data
(
)
+
offset
;
offset
+
=
framesPerPacketFarend
;
}
DeinterleaveAndConvertBuffer
(
interleavedFarend
framesPerPacketFarend
channelCountFarend
deinterleavedPacketDataChannelPointers
.
Elements
(
)
)
;
StreamConfig
inputConfig
(
aRate
channelCountFarend
false
)
;
StreamConfig
outputConfig
=
inputConfig
;
DebugOnly
<
int
>
err
=
mAudioProcessing
-
>
ProcessReverseStream
(
deinterleavedPacketDataChannelPointers
.
Elements
(
)
inputConfig
outputConfig
deinterleavedPacketDataChannelPointers
.
Elements
(
)
)
;
MOZ_ASSERT
(
!
err
"
Could
not
process
the
reverse
stream
.
"
)
;
}
}
void
AudioInputProcessing
:
:
PacketizeAndProcess
(
MediaStreamGraphImpl
*
aGraph
const
AudioDataValue
*
aBuffer
size_t
aFrames
TrackRate
aRate
uint32_t
aChannels
)
{
MOZ_ASSERT
(
!
PassThrough
(
aGraph
)
"
This
should
be
bypassed
when
in
PassThrough
mode
.
"
)
;
MOZ_ASSERT
(
mEnabled
)
;
size_t
offset
=
0
;
if
(
!
mPacketizerInput
|
|
mPacketizerInput
-
>
PacketSize
(
)
!
=
aRate
/
100u
|
|
mPacketizerInput
-
>
Channels
(
)
!
=
aChannels
)
{
mPacketizerInput
=
new
AudioPacketizer
<
AudioDataValue
float
>
(
aRate
/
100
aChannels
)
;
}
mPacketizerInput
-
>
Input
(
aBuffer
static_cast
<
uint32_t
>
(
aFrames
)
)
;
while
(
mPacketizerInput
-
>
PacketsAvailable
(
)
)
{
uint32_t
samplesPerPacket
=
mPacketizerInput
-
>
PacketSize
(
)
*
mPacketizerInput
-
>
Channels
(
)
;
if
(
mInputBuffer
.
Length
(
)
<
samplesPerPacket
)
{
mInputBuffer
.
SetLength
(
samplesPerPacket
)
;
}
if
(
mDeinterleavedBuffer
.
Length
(
)
<
samplesPerPacket
)
{
mDeinterleavedBuffer
.
SetLength
(
samplesPerPacket
)
;
}
float
*
packet
=
mInputBuffer
.
Data
(
)
;
mPacketizerInput
-
>
Output
(
packet
)
;
AutoTArray
<
float
*
8
>
deinterleavedPacketizedInputDataChannelPointers
;
deinterleavedPacketizedInputDataChannelPointers
.
SetLength
(
aChannels
)
;
offset
=
0
;
for
(
size_t
i
=
0
;
i
<
deinterleavedPacketizedInputDataChannelPointers
.
Length
(
)
;
+
+
i
)
{
deinterleavedPacketizedInputDataChannelPointers
[
i
]
=
mDeinterleavedBuffer
.
Data
(
)
+
offset
;
offset
+
=
mPacketizerInput
-
>
PacketSize
(
)
;
}
Deinterleave
(
packet
mPacketizerInput
-
>
PacketSize
(
)
aChannels
deinterleavedPacketizedInputDataChannelPointers
.
Elements
(
)
)
;
StreamConfig
inputConfig
(
aRate
aChannels
false
)
;
StreamConfig
outputConfig
=
inputConfig
;
mAudioProcessing
-
>
set_stream_delay_ms
(
0
)
;
RefPtr
<
SharedBuffer
>
buffer
=
SharedBuffer
:
:
Create
(
mPacketizerInput
-
>
PacketSize
(
)
*
aChannels
*
sizeof
(
float
)
)
;
AutoTArray
<
float
*
8
>
processedOutputChannelPointers
;
AutoTArray
<
const
float
*
8
>
processedOutputChannelPointersConst
;
processedOutputChannelPointers
.
SetLength
(
aChannels
)
;
processedOutputChannelPointersConst
.
SetLength
(
aChannels
)
;
offset
=
0
;
for
(
size_t
i
=
0
;
i
<
processedOutputChannelPointers
.
Length
(
)
;
+
+
i
)
{
processedOutputChannelPointers
[
i
]
=
static_cast
<
float
*
>
(
buffer
-
>
Data
(
)
)
+
offset
;
processedOutputChannelPointersConst
[
i
]
=
static_cast
<
float
*
>
(
buffer
-
>
Data
(
)
)
+
offset
;
offset
+
=
mPacketizerInput
-
>
PacketSize
(
)
;
}
mAudioProcessing
-
>
ProcessStream
(
deinterleavedPacketizedInputDataChannelPointers
.
Elements
(
)
inputConfig
outputConfig
processedOutputChannelPointers
.
Elements
(
)
)
;
AudioSegment
segment
;
if
(
!
mStream
-
>
GraphImpl
(
)
)
{
continue
;
}
LOG_FRAME
(
"
Appending
%
"
PRIu32
"
frames
of
packetized
audio
"
mPacketizerInput
-
>
PacketSize
(
)
)
;
#
ifdef
DEBUG
mLastCallbackAppendTime
=
mStream
-
>
GraphImpl
(
)
-
>
IterationEnd
(
)
;
#
endif
mLiveFramesAppended
=
true
;
MOZ_ASSERT
(
processedOutputChannelPointers
.
Length
(
)
=
=
aChannels
)
;
RefPtr
<
SharedBuffer
>
other
=
buffer
;
segment
.
AppendFrames
(
other
.
forget
(
)
processedOutputChannelPointersConst
mPacketizerInput
-
>
PacketSize
(
)
mPrincipal
)
;
mStream
-
>
AppendToTrack
(
mTrackID
&
segment
)
;
}
}
template
<
typename
T
>
void
AudioInputProcessing
:
:
InsertInGraph
(
const
T
*
aBuffer
size_t
aFrames
uint32_t
aChannels
)
{
if
(
!
mStream
-
>
GraphImpl
(
)
)
{
return
;
}
#
ifdef
DEBUG
mLastCallbackAppendTime
=
mStream
-
>
GraphImpl
(
)
-
>
IterationEnd
(
)
;
#
endif
mLiveFramesAppended
=
true
;
MOZ_ASSERT
(
aChannels
>
=
1
&
&
aChannels
<
=
8
"
Support
up
to
8
channels
"
)
;
AudioSegment
segment
;
RefPtr
<
SharedBuffer
>
buffer
=
SharedBuffer
:
:
Create
(
aFrames
*
aChannels
*
sizeof
(
T
)
)
;
AutoTArray
<
const
T
*
8
>
channels
;
if
(
aChannels
=
=
1
)
{
PodCopy
(
static_cast
<
T
*
>
(
buffer
-
>
Data
(
)
)
aBuffer
aFrames
)
;
channels
.
AppendElement
(
static_cast
<
T
*
>
(
buffer
-
>
Data
(
)
)
)
;
}
else
{
channels
.
SetLength
(
aChannels
)
;
AutoTArray
<
T
*
8
>
write_channels
;
write_channels
.
SetLength
(
aChannels
)
;
T
*
samples
=
static_cast
<
T
*
>
(
buffer
-
>
Data
(
)
)
;
size_t
offset
=
0
;
for
(
uint32_t
i
=
0
;
i
<
aChannels
;
+
+
i
)
{
channels
[
i
]
=
write_channels
[
i
]
=
samples
+
offset
;
offset
+
=
aFrames
;
}
DeinterleaveAndConvertBuffer
(
aBuffer
aFrames
aChannels
write_channels
.
Elements
(
)
)
;
}
LOG_FRAME
(
"
Appending
%
zu
frames
of
raw
audio
"
aFrames
)
;
MOZ_ASSERT
(
aChannels
=
=
channels
.
Length
(
)
)
;
segment
.
AppendFrames
(
buffer
.
forget
(
)
channels
aFrames
mPrincipal
)
;
mStream
-
>
AppendToTrack
(
mTrackID
&
segment
)
;
}
void
AudioInputProcessing
:
:
NotifyInputData
(
MediaStreamGraphImpl
*
aGraph
const
AudioDataValue
*
aBuffer
size_t
aFrames
TrackRate
aRate
uint32_t
aChannels
)
{
MOZ_ASSERT
(
aGraph
-
>
CurrentDriver
(
)
-
>
OnThread
(
)
)
;
TRACE_AUDIO_CALLBACK
(
)
;
MOZ_ASSERT
(
mEnabled
)
;
if
(
PassThrough
(
aGraph
)
)
{
InsertInGraph
<
AudioDataValue
>
(
aBuffer
aFrames
aChannels
)
;
}
else
{
PacketizeAndProcess
(
aGraph
aBuffer
aFrames
aRate
aChannels
)
;
}
}
#
define
ResetProcessingIfNeeded
(
_processing
)
\
do
{
\
bool
enabled
=
mAudioProcessing
-
>
_processing
(
)
-
>
is_enabled
(
)
;
\
\
if
(
enabled
)
{
\
int
rv
=
mAudioProcessing
-
>
_processing
(
)
-
>
Enable
(
!
enabled
)
;
\
if
(
rv
)
{
\
NS_WARNING
(
"
Could
not
reset
the
status
of
the
"
#
_processing
\
"
on
device
change
.
"
)
;
\
return
;
\
}
\
rv
=
mAudioProcessing
-
>
_processing
(
)
-
>
Enable
(
enabled
)
;
\
if
(
rv
)
{
\
NS_WARNING
(
"
Could
not
reset
the
status
of
the
"
#
_processing
\
"
on
device
change
.
"
)
;
\
return
;
\
}
\
}
\
}
while
(
0
)
void
AudioInputProcessing
:
:
DeviceChanged
(
MediaStreamGraphImpl
*
aGraph
)
{
MOZ_ASSERT
(
aGraph
-
>
CurrentDriver
(
)
-
>
OnThread
(
)
)
;
ResetProcessingIfNeeded
(
gain_control
)
;
ResetProcessingIfNeeded
(
echo_cancellation
)
;
ResetProcessingIfNeeded
(
noise_suppression
)
;
}
void
AudioInputProcessing
:
:
End
(
)
{
mEnded
=
true
;
}
nsString
MediaEngineWebRTCAudioCaptureSource
:
:
GetName
(
)
const
{
return
NS_LITERAL_STRING
(
u
"
AudioCapture
"
)
;
}
nsCString
MediaEngineWebRTCAudioCaptureSource
:
:
GetUUID
(
)
const
{
nsID
uuid
;
char
uuidBuffer
[
NSID_LENGTH
]
;
nsCString
asciiString
;
ErrorResult
rv
;
rv
=
nsContentUtils
:
:
GenerateUUIDInPlace
(
uuid
)
;
if
(
rv
.
Failed
(
)
)
{
return
NS_LITERAL_CSTRING
(
"
"
)
;
}
uuid
.
ToProvidedString
(
uuidBuffer
)
;
asciiString
.
AssignASCII
(
uuidBuffer
)
;
return
nsCString
(
Substring
(
asciiString
1
NSID_LENGTH
-
3
)
)
;
}
void
MediaEngineWebRTCAudioCaptureSource
:
:
SetTrack
(
const
RefPtr
<
const
AllocationHandle
>
&
const
RefPtr
<
SourceMediaStream
>
&
aStream
TrackID
aTrackID
const
PrincipalHandle
&
aPrincipalHandle
)
{
AssertIsOnOwningThread
(
)
;
}
nsresult
MediaEngineWebRTCAudioCaptureSource
:
:
Start
(
const
RefPtr
<
const
AllocationHandle
>
&
)
{
AssertIsOnOwningThread
(
)
;
return
NS_OK
;
}
nsresult
MediaEngineWebRTCAudioCaptureSource
:
:
Stop
(
const
RefPtr
<
const
AllocationHandle
>
&
)
{
AssertIsOnOwningThread
(
)
;
return
NS_OK
;
}
nsresult
MediaEngineWebRTCAudioCaptureSource
:
:
Reconfigure
(
const
RefPtr
<
AllocationHandle
>
&
const
dom
:
:
MediaTrackConstraints
&
aConstraints
const
MediaEnginePrefs
&
aPrefs
const
nsString
&
aDeviceId
const
char
*
*
aOutBadConstraint
)
{
return
NS_OK
;
}
uint32_t
MediaEngineWebRTCAudioCaptureSource
:
:
GetBestFitnessDistance
(
const
nsTArray
<
const
NormalizedConstraintSet
*
>
&
aConstraintSets
const
nsString
&
aDeviceId
)
const
{
return
0
;
}
}
