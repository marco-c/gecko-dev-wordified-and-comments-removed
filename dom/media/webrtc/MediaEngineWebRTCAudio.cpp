#
include
"
MediaEngineWebRTCAudio
.
h
"
#
include
<
stdio
.
h
>
#
include
<
algorithm
>
#
include
"
AudioConverter
.
h
"
#
include
"
MediaManager
.
h
"
#
include
"
MediaTrackGraph
.
h
"
#
include
"
MediaTrackConstraints
.
h
"
#
include
"
mozilla
/
Assertions
.
h
"
#
include
"
mozilla
/
ErrorNames
.
h
"
#
include
"
nsIDUtils
.
h
"
#
include
"
transport
/
runnable_utils
.
h
"
#
include
"
Tracing
.
h
"
#
include
"
mozilla
/
Sprintf
.
h
"
#
include
"
mozilla
/
Logging
.
h
"
#
include
"
api
/
audio
/
echo_canceller3_factory
.
h
"
#
include
"
common_audio
/
include
/
audio_util
.
h
"
#
include
"
modules
/
audio_processing
/
include
/
audio_processing
.
h
"
using
namespace
webrtc
;
#
define
MAX_CHANNELS
2
#
define
MONO
1
#
define
MAX_SAMPLING_FREQ
48000
/
/
Hz
-
multiple
of
100
namespace
mozilla
{
using
dom
:
:
MediaSourceEnum
;
extern
LazyLogModule
gMediaManagerLog
;
#
define
LOG
(
.
.
.
)
MOZ_LOG
(
gMediaManagerLog
LogLevel
:
:
Debug
(
__VA_ARGS__
)
)
#
define
LOG_FRAME
(
.
.
.
)
\
MOZ_LOG
(
gMediaManagerLog
LogLevel
:
:
Verbose
(
__VA_ARGS__
)
)
#
define
LOG_ERROR
(
.
.
.
)
MOZ_LOG
(
gMediaManagerLog
LogLevel
:
:
Error
(
__VA_ARGS__
)
)
MediaEngineWebRTCMicrophoneSource
:
:
MediaEngineWebRTCMicrophoneSource
(
const
MediaDevice
*
aMediaDevice
)
:
mPrincipal
(
PRINCIPAL_HANDLE_NONE
)
mDeviceInfo
(
aMediaDevice
-
>
mAudioDeviceInfo
)
mDeviceMaxChannelCount
(
mDeviceInfo
-
>
MaxChannels
(
)
)
mSettings
(
new
nsMainThreadPtrHolder
<
media
:
:
Refcountable
<
dom
:
:
MediaTrackSettings
>
>
(
"
MediaEngineWebRTCMicrophoneSource
:
:
mSettings
"
new
media
:
:
Refcountable
<
dom
:
:
MediaTrackSettings
>
(
)
false
)
)
mCapabilities
(
new
nsMainThreadPtrHolder
<
media
:
:
Refcountable
<
dom
:
:
MediaTrackCapabilities
>
>
(
"
MediaEngineWebRTCMicrophoneSource
:
:
mCapabilities
"
new
media
:
:
Refcountable
<
dom
:
:
MediaTrackCapabilities
>
(
)
false
)
)
{
MOZ_ASSERT
(
aMediaDevice
-
>
mMediaSource
=
=
MediaSourceEnum
:
:
Microphone
)
;
#
ifndef
ANDROID
MOZ_ASSERT
(
mDeviceInfo
-
>
DeviceID
(
)
)
;
#
endif
mSettings
-
>
mEchoCancellation
.
Construct
(
0
)
;
mSettings
-
>
mAutoGainControl
.
Construct
(
0
)
;
mSettings
-
>
mNoiseSuppression
.
Construct
(
0
)
;
mSettings
-
>
mChannelCount
.
Construct
(
0
)
;
mState
=
kReleased
;
NS_DispatchToMainThread
(
NS_NewRunnableFunction
(
__func__
[
capabilities
=
mCapabilities
deviceMaxChannelCount
=
mDeviceMaxChannelCount
]
{
nsTArray
<
bool
>
echoCancellation
;
echoCancellation
.
AppendElement
(
true
)
;
echoCancellation
.
AppendElement
(
false
)
;
capabilities
-
>
mEchoCancellation
.
Reset
(
)
;
capabilities
-
>
mEchoCancellation
.
Construct
(
std
:
:
move
(
echoCancellation
)
)
;
nsTArray
<
bool
>
autoGainControl
;
autoGainControl
.
AppendElement
(
true
)
;
autoGainControl
.
AppendElement
(
false
)
;
capabilities
-
>
mAutoGainControl
.
Reset
(
)
;
capabilities
-
>
mAutoGainControl
.
Construct
(
std
:
:
move
(
autoGainControl
)
)
;
nsTArray
<
bool
>
noiseSuppression
;
noiseSuppression
.
AppendElement
(
true
)
;
noiseSuppression
.
AppendElement
(
false
)
;
capabilities
-
>
mNoiseSuppression
.
Reset
(
)
;
capabilities
-
>
mNoiseSuppression
.
Construct
(
std
:
:
move
(
noiseSuppression
)
)
;
if
(
deviceMaxChannelCount
)
{
dom
:
:
ULongRange
channelCountRange
;
channelCountRange
.
mMax
.
Construct
(
deviceMaxChannelCount
)
;
channelCountRange
.
mMin
.
Construct
(
1
)
;
capabilities
-
>
mChannelCount
.
Reset
(
)
;
capabilities
-
>
mChannelCount
.
Construct
(
channelCountRange
)
;
}
}
)
)
;
}
nsresult
MediaEngineWebRTCMicrophoneSource
:
:
EvaluateSettings
(
const
NormalizedConstraints
&
aConstraintsUpdate
const
MediaEnginePrefs
&
aInPrefs
MediaEnginePrefs
*
aOutPrefs
const
char
*
*
aOutBadConstraint
)
{
AssertIsOnOwningThread
(
)
;
FlattenedConstraints
c
(
aConstraintsUpdate
)
;
MediaEnginePrefs
prefs
=
aInPrefs
;
prefs
.
mAecOn
=
c
.
mEchoCancellation
.
Get
(
aInPrefs
.
mAecOn
)
;
prefs
.
mAgcOn
=
c
.
mAutoGainControl
.
Get
(
aInPrefs
.
mAgcOn
&
&
prefs
.
mAecOn
)
;
prefs
.
mNoiseOn
=
c
.
mNoiseSuppression
.
Get
(
aInPrefs
.
mNoiseOn
&
&
prefs
.
mAecOn
)
;
int32_t
maxChannels
=
static_cast
<
int32_t
>
(
mDeviceInfo
-
>
MaxChannels
(
)
)
;
if
(
c
.
mChannelCount
.
mMin
>
maxChannels
)
{
*
aOutBadConstraint
=
"
channelCount
"
;
return
NS_ERROR_FAILURE
;
}
if
(
aInPrefs
.
mChannels
<
=
0
)
{
prefs
.
mChannels
=
maxChannels
;
}
prefs
.
mChannels
=
c
.
mChannelCount
.
Get
(
std
:
:
min
(
prefs
.
mChannels
maxChannels
)
)
;
prefs
.
mChannels
=
std
:
:
max
(
1
std
:
:
min
(
prefs
.
mChannels
maxChannels
)
)
;
LOG
(
"
Mic
source
%
p
Audio
config
:
aec
:
%
s
agc
:
%
s
noise
:
%
s
channels
:
%
d
"
this
prefs
.
mAecOn
?
"
on
"
:
"
off
"
prefs
.
mAgcOn
?
"
on
"
:
"
off
"
prefs
.
mNoiseOn
?
"
on
"
:
"
off
"
prefs
.
mChannels
)
;
*
aOutPrefs
=
prefs
;
return
NS_OK
;
}
nsresult
MediaEngineWebRTCMicrophoneSource
:
:
Reconfigure
(
const
dom
:
:
MediaTrackConstraints
&
aConstraints
const
MediaEnginePrefs
&
aPrefs
const
char
*
*
aOutBadConstraint
)
{
AssertIsOnOwningThread
(
)
;
MOZ_ASSERT
(
mTrack
)
;
LOG
(
"
Mic
source
%
p
Reconfigure
"
this
)
;
NormalizedConstraints
constraints
(
aConstraints
)
;
MediaEnginePrefs
outputPrefs
;
nsresult
rv
=
EvaluateSettings
(
constraints
aPrefs
&
outputPrefs
aOutBadConstraint
)
;
if
(
NS_FAILED
(
rv
)
)
{
if
(
aOutBadConstraint
)
{
return
NS_ERROR_INVALID_ARG
;
}
nsAutoCString
name
;
GetErrorName
(
rv
name
)
;
LOG
(
"
Mic
source
%
p
Reconfigure
(
)
failed
unexpectedly
.
rv
=
%
s
"
this
name
.
Data
(
)
)
;
Stop
(
)
;
return
NS_ERROR_UNEXPECTED
;
}
ApplySettings
(
outputPrefs
)
;
mCurrentPrefs
=
outputPrefs
;
return
NS_OK
;
}
AudioProcessing
:
:
Config
AudioInputProcessing
:
:
ConfigForPrefs
(
const
MediaEnginePrefs
&
aPrefs
)
const
{
AudioProcessing
:
:
Config
config
;
config
.
pipeline
.
multi_channel_render
=
true
;
config
.
pipeline
.
multi_channel_capture
=
true
;
config
.
echo_canceller
.
enabled
=
aPrefs
.
mAecOn
;
config
.
echo_canceller
.
mobile_mode
=
aPrefs
.
mUseAecMobile
;
if
(
(
config
.
gain_controller1
.
enabled
=
aPrefs
.
mAgcOn
&
&
!
aPrefs
.
mAgc2Forced
)
)
{
auto
mode
=
static_cast
<
AudioProcessing
:
:
Config
:
:
GainController1
:
:
Mode
>
(
aPrefs
.
mAgc
)
;
if
(
mode
!
=
AudioProcessing
:
:
Config
:
:
GainController1
:
:
kAdaptiveAnalog
&
&
mode
!
=
AudioProcessing
:
:
Config
:
:
GainController1
:
:
kAdaptiveDigital
&
&
mode
!
=
AudioProcessing
:
:
Config
:
:
GainController1
:
:
kFixedDigital
)
{
LOG_ERROR
(
"
AudioInputProcessing
%
p
Attempt
to
set
invalid
AGC
mode
%
d
"
this
static_cast
<
int
>
(
mode
)
)
;
mode
=
AudioProcessing
:
:
Config
:
:
GainController1
:
:
kAdaptiveDigital
;
}
#
if
defined
(
WEBRTC_IOS
)
|
|
defined
(
ATA
)
|
|
defined
(
WEBRTC_ANDROID
)
if
(
mode
=
=
AudioProcessing
:
:
Config
:
:
GainController1
:
:
kAdaptiveAnalog
)
{
LOG_ERROR
(
"
AudioInputProcessing
%
p
Invalid
AGC
mode
kAdaptiveAnalog
on
"
"
mobile
"
this
)
;
MOZ_ASSERT_UNREACHABLE
(
"
Bad
pref
set
in
all
.
js
or
in
about
:
config
"
"
for
the
auto
gain
on
mobile
.
"
)
;
mode
=
AudioProcessing
:
:
Config
:
:
GainController1
:
:
kFixedDigital
;
}
#
endif
config
.
gain_controller1
.
mode
=
mode
;
}
config
.
gain_controller2
.
enabled
=
config
.
gain_controller2
.
adaptive_digital
.
enabled
=
aPrefs
.
mAgcOn
&
&
aPrefs
.
mAgc2Forced
;
if
(
(
config
.
noise_suppression
.
enabled
=
aPrefs
.
mNoiseOn
)
)
{
auto
level
=
static_cast
<
AudioProcessing
:
:
Config
:
:
NoiseSuppression
:
:
Level
>
(
aPrefs
.
mNoise
)
;
if
(
level
!
=
AudioProcessing
:
:
Config
:
:
NoiseSuppression
:
:
kLow
&
&
level
!
=
AudioProcessing
:
:
Config
:
:
NoiseSuppression
:
:
kModerate
&
&
level
!
=
AudioProcessing
:
:
Config
:
:
NoiseSuppression
:
:
kHigh
&
&
level
!
=
AudioProcessing
:
:
Config
:
:
NoiseSuppression
:
:
kVeryHigh
)
{
LOG_ERROR
(
"
AudioInputProcessing
%
p
Attempt
to
set
invalid
noise
suppression
"
"
level
%
d
"
this
static_cast
<
int
>
(
level
)
)
;
level
=
AudioProcessing
:
:
Config
:
:
NoiseSuppression
:
:
kModerate
;
}
config
.
noise_suppression
.
level
=
level
;
}
config
.
transient_suppression
.
enabled
=
aPrefs
.
mTransientOn
;
config
.
high_pass_filter
.
enabled
=
aPrefs
.
mHPFOn
;
if
(
mPlatformProcessingSetParams
&
CUBEB_INPUT_PROCESSING_PARAM_ECHO_CANCELLATION
)
{
config
.
echo_canceller
.
enabled
=
false
;
}
if
(
mPlatformProcessingSetParams
&
CUBEB_INPUT_PROCESSING_PARAM_AUTOMATIC_GAIN_CONTROL
)
{
config
.
gain_controller1
.
enabled
=
config
.
gain_controller2
.
enabled
=
false
;
}
if
(
mPlatformProcessingSetParams
&
CUBEB_INPUT_PROCESSING_PARAM_NOISE_SUPPRESSION
)
{
config
.
noise_suppression
.
enabled
=
false
;
}
return
config
;
}
void
MediaEngineWebRTCMicrophoneSource
:
:
ApplySettings
(
const
MediaEnginePrefs
&
aPrefs
)
{
AssertIsOnOwningThread
(
)
;
TRACE
(
"
ApplySettings
"
)
;
MOZ_ASSERT
(
mTrack
"
ApplySetting
is
to
be
called
only
after
SetTrack
has
been
called
"
)
;
RefPtr
<
MediaEngineWebRTCMicrophoneSource
>
that
=
this
;
CubebUtils
:
:
AudioDeviceID
deviceID
=
mDeviceInfo
-
>
DeviceID
(
)
;
NS_DispatchToMainThread
(
NS_NewRunnableFunction
(
__func__
[
this
that
deviceID
track
=
mTrack
prefs
=
aPrefs
]
{
mSettings
-
>
mEchoCancellation
.
Value
(
)
=
prefs
.
mAecOn
;
mSettings
-
>
mAutoGainControl
.
Value
(
)
=
prefs
.
mAgcOn
;
mSettings
-
>
mNoiseSuppression
.
Value
(
)
=
prefs
.
mNoiseOn
;
mSettings
-
>
mChannelCount
.
Value
(
)
=
prefs
.
mChannels
;
if
(
track
-
>
IsDestroyed
(
)
)
{
return
;
}
track
-
>
QueueControlMessageWithNoShutdown
(
[
track
deviceID
prefs
inputProcessing
=
mInputProcessing
]
{
inputProcessing
-
>
ApplySettings
(
track
-
>
Graph
(
)
deviceID
prefs
)
;
}
)
;
}
)
)
;
}
nsresult
MediaEngineWebRTCMicrophoneSource
:
:
Allocate
(
const
dom
:
:
MediaTrackConstraints
&
aConstraints
const
MediaEnginePrefs
&
aPrefs
uint64_t
aWindowID
const
char
*
*
aOutBadConstraint
)
{
AssertIsOnOwningThread
(
)
;
mState
=
kAllocated
;
NormalizedConstraints
normalized
(
aConstraints
)
;
MediaEnginePrefs
outputPrefs
;
nsresult
rv
=
EvaluateSettings
(
normalized
aPrefs
&
outputPrefs
aOutBadConstraint
)
;
if
(
NS_FAILED
(
rv
)
)
{
return
rv
;
}
NS_DispatchToMainThread
(
NS_NewRunnableFunction
(
__func__
[
settings
=
mSettings
prefs
=
outputPrefs
]
{
settings
-
>
mEchoCancellation
.
Value
(
)
=
prefs
.
mAecOn
;
settings
-
>
mAutoGainControl
.
Value
(
)
=
prefs
.
mAgcOn
;
settings
-
>
mNoiseSuppression
.
Value
(
)
=
prefs
.
mNoiseOn
;
settings
-
>
mChannelCount
.
Value
(
)
=
prefs
.
mChannels
;
}
)
)
;
mCurrentPrefs
=
outputPrefs
;
return
rv
;
}
nsresult
MediaEngineWebRTCMicrophoneSource
:
:
Deallocate
(
)
{
AssertIsOnOwningThread
(
)
;
MOZ_ASSERT
(
mState
=
=
kStopped
|
|
mState
=
=
kAllocated
)
;
if
(
mTrack
)
{
NS_DispatchToMainThread
(
NS_NewRunnableFunction
(
__func__
[
track
=
std
:
:
move
(
mTrack
)
inputProcessing
=
mInputProcessing
]
{
if
(
track
-
>
IsDestroyed
(
)
)
{
return
;
}
track
-
>
QueueControlMessageWithNoShutdown
(
[
inputProcessing
]
{
TRACE
(
"
mInputProcessing
:
:
End
"
)
;
inputProcessing
-
>
End
(
)
;
}
)
;
}
)
)
;
}
mTrack
=
nullptr
;
mPrincipal
=
PRINCIPAL_HANDLE_NONE
;
MOZ_ASSERT
(
mState
!
=
kReleased
"
Source
not
allocated
"
)
;
MOZ_ASSERT
(
mState
!
=
kStarted
"
Source
not
stopped
"
)
;
mState
=
kReleased
;
LOG
(
"
Mic
source
%
p
Audio
device
%
s
deallocated
"
this
NS_ConvertUTF16toUTF8
(
mDeviceInfo
-
>
Name
(
)
)
.
get
(
)
)
;
return
NS_OK
;
}
void
MediaEngineWebRTCMicrophoneSource
:
:
SetTrack
(
const
RefPtr
<
MediaTrack
>
&
aTrack
const
PrincipalHandle
&
aPrincipal
)
{
AssertIsOnOwningThread
(
)
;
MOZ_ASSERT
(
aTrack
)
;
MOZ_ASSERT
(
aTrack
-
>
AsAudioProcessingTrack
(
)
)
;
MOZ_ASSERT
(
!
mTrack
)
;
MOZ_ASSERT
(
mPrincipal
=
=
PRINCIPAL_HANDLE_NONE
)
;
mTrack
=
aTrack
-
>
AsAudioProcessingTrack
(
)
;
mPrincipal
=
aPrincipal
;
mInputProcessing
=
MakeAndAddRef
<
AudioInputProcessing
>
(
mDeviceMaxChannelCount
)
;
NS_DispatchToMainThread
(
NS_NewRunnableFunction
(
__func__
[
track
=
mTrack
processing
=
mInputProcessing
]
(
)
mutable
{
track
-
>
SetInputProcessing
(
std
:
:
move
(
processing
)
)
;
track
-
>
Resume
(
)
;
}
)
)
;
LOG
(
"
Mic
source
%
p
Track
%
p
registered
for
microphone
capture
"
this
aTrack
.
get
(
)
)
;
}
nsresult
MediaEngineWebRTCMicrophoneSource
:
:
Start
(
)
{
AssertIsOnOwningThread
(
)
;
if
(
mState
=
=
kStarted
)
{
return
NS_OK
;
}
MOZ_ASSERT
(
mState
=
=
kAllocated
|
|
mState
=
=
kStopped
)
;
ApplySettings
(
mCurrentPrefs
)
;
CubebUtils
:
:
AudioDeviceID
deviceID
=
mDeviceInfo
-
>
DeviceID
(
)
;
NS_DispatchToMainThread
(
NS_NewRunnableFunction
(
__func__
[
inputProcessing
=
mInputProcessing
deviceID
track
=
mTrack
principal
=
mPrincipal
]
{
if
(
track
-
>
IsDestroyed
(
)
)
{
return
;
}
track
-
>
QueueControlMessageWithNoShutdown
(
[
track
inputProcessing
]
{
TRACE
(
"
mInputProcessing
:
:
Start
"
)
;
inputProcessing
-
>
Start
(
track
-
>
Graph
(
)
)
;
}
)
;
track
-
>
ConnectDeviceInput
(
deviceID
inputProcessing
.
get
(
)
principal
)
;
}
)
)
;
MOZ_ASSERT
(
mState
!
=
kReleased
)
;
mState
=
kStarted
;
return
NS_OK
;
}
nsresult
MediaEngineWebRTCMicrophoneSource
:
:
Stop
(
)
{
AssertIsOnOwningThread
(
)
;
LOG
(
"
Mic
source
%
p
Stop
(
)
"
this
)
;
MOZ_ASSERT
(
mTrack
"
SetTrack
must
have
been
called
before
:
:
Stop
"
)
;
if
(
mState
=
=
kStopped
)
{
return
NS_OK
;
}
NS_DispatchToMainThread
(
NS_NewRunnableFunction
(
__func__
[
inputProcessing
=
mInputProcessing
deviceInfo
=
mDeviceInfo
track
=
mTrack
]
{
if
(
track
-
>
IsDestroyed
(
)
)
{
return
;
}
MOZ_ASSERT
(
track
-
>
DeviceId
(
)
.
value
(
)
=
=
deviceInfo
-
>
DeviceID
(
)
)
;
track
-
>
DisconnectDeviceInput
(
)
;
track
-
>
QueueControlMessageWithNoShutdown
(
[
track
inputProcessing
]
{
TRACE
(
"
mInputProcessing
:
:
Stop
"
)
;
inputProcessing
-
>
Stop
(
track
-
>
Graph
(
)
)
;
}
)
;
}
)
)
;
MOZ_ASSERT
(
mState
=
=
kStarted
"
Should
be
started
when
stopping
"
)
;
mState
=
kStopped
;
return
NS_OK
;
}
void
MediaEngineWebRTCMicrophoneSource
:
:
GetSettings
(
dom
:
:
MediaTrackSettings
&
aOutSettings
)
const
{
MOZ_ASSERT
(
NS_IsMainThread
(
)
)
;
aOutSettings
=
*
mSettings
;
}
void
MediaEngineWebRTCMicrophoneSource
:
:
GetCapabilities
(
dom
:
:
MediaTrackCapabilities
&
aOutCapabilities
)
const
{
MOZ_ASSERT
(
NS_IsMainThread
(
)
)
;
aOutCapabilities
=
*
mCapabilities
;
}
AudioInputProcessing
:
:
AudioInputProcessing
(
uint32_t
aMaxChannelCount
)
:
mInputDownmixBuffer
(
MAX_SAMPLING_FREQ
*
MAX_CHANNELS
/
100
)
mEnabled
(
false
)
mEnded
(
false
)
mPacketCount
(
0
)
{
mSettings
.
mChannels
=
static_cast
<
int32_t
>
(
std
:
:
min
<
uint32_t
>
(
std
:
:
numeric_limits
<
int32_t
>
:
:
max
(
)
aMaxChannelCount
)
)
;
}
void
AudioInputProcessing
:
:
Disconnect
(
MediaTrackGraph
*
aGraph
)
{
aGraph
-
>
AssertOnGraphThread
(
)
;
mPlatformProcessingSetGeneration
=
0
;
mPlatformProcessingSetParams
=
CUBEB_INPUT_PROCESSING_PARAM_NONE
;
ApplySettingsInternal
(
aGraph
mSettings
)
;
}
void
AudioInputProcessing
:
:
NotifySetRequestedInputProcessingParams
(
MediaTrackGraph
*
aGraph
int
aGeneration
cubeb_input_processing_params
aRequestedParams
)
{
aGraph
-
>
AssertOnGraphThread
(
)
;
MOZ_ASSERT
(
aGeneration
>
=
mPlatformProcessingSetGeneration
)
;
if
(
aGeneration
<
=
mPlatformProcessingSetGeneration
)
{
return
;
}
mPlatformProcessingSetGeneration
=
aGeneration
;
cubeb_input_processing_params
intersection
=
mPlatformProcessingSetParams
&
aRequestedParams
;
LOG
(
"
AudioInputProcessing
%
p
platform
processing
params
being
applied
are
"
"
now
%
s
(
Gen
%
d
)
.
Assuming
%
s
while
waiting
for
the
result
.
"
this
CubebUtils
:
:
ProcessingParamsToString
(
aRequestedParams
)
.
get
(
)
aGeneration
CubebUtils
:
:
ProcessingParamsToString
(
intersection
)
.
get
(
)
)
;
if
(
mPlatformProcessingSetParams
=
=
intersection
)
{
LOG
(
"
AudioInputProcessing
%
p
intersection
%
s
of
platform
processing
params
"
"
already
applied
.
Doing
nothing
.
"
this
CubebUtils
:
:
ProcessingParamsToString
(
intersection
)
.
get
(
)
)
;
return
;
}
mPlatformProcessingSetParams
=
intersection
;
ApplySettingsInternal
(
aGraph
mSettings
)
;
}
void
AudioInputProcessing
:
:
NotifySetRequestedInputProcessingParamsResult
(
MediaTrackGraph
*
aGraph
int
aGeneration
const
Result
<
cubeb_input_processing_params
int
>
&
aResult
)
{
aGraph
-
>
AssertOnGraphThread
(
)
;
if
(
aGeneration
!
=
mPlatformProcessingSetGeneration
)
{
return
;
}
if
(
aResult
.
isOk
(
)
)
{
if
(
mPlatformProcessingSetParams
=
=
aResult
.
inspect
(
)
)
{
return
;
}
mPlatformProcessingSetError
=
Nothing
(
)
;
mPlatformProcessingSetParams
=
aResult
.
inspect
(
)
;
LOG
(
"
AudioInputProcessing
%
p
platform
processing
params
are
now
%
s
.
"
this
CubebUtils
:
:
ProcessingParamsToString
(
mPlatformProcessingSetParams
)
.
get
(
)
)
;
}
else
{
mPlatformProcessingSetError
=
Some
(
aResult
.
inspectErr
(
)
)
;
mPlatformProcessingSetParams
=
CUBEB_INPUT_PROCESSING_PARAM_NONE
;
LOG
(
"
AudioInputProcessing
%
p
platform
processing
params
failed
to
apply
.
"
"
Applying
input
processing
config
in
libwebrtc
.
"
this
)
;
}
ApplySettingsInternal
(
aGraph
mSettings
)
;
}
bool
AudioInputProcessing
:
:
IsPassThrough
(
MediaTrackGraph
*
aGraph
)
const
{
aGraph
-
>
AssertOnGraphThread
(
)
;
auto
config
=
AppliedConfig
(
aGraph
)
;
auto
aec
=
[
]
(
const
auto
&
config
)
{
return
config
.
echo_canceller
.
enabled
;
}
;
auto
agc
=
[
]
(
const
auto
&
config
)
{
return
config
.
gain_controller1
.
enabled
|
|
config
.
gain_controller2
.
enabled
;
}
;
auto
ns
=
[
]
(
const
auto
&
config
)
{
return
config
.
noise_suppression
.
enabled
;
}
;
return
!
(
aec
(
config
)
|
|
agc
(
config
)
|
|
ns
(
config
)
)
;
}
void
AudioInputProcessing
:
:
PassThroughChanged
(
MediaTrackGraph
*
aGraph
)
{
aGraph
-
>
AssertOnGraphThread
(
)
;
if
(
!
mEnabled
)
{
MOZ_ASSERT
(
!
mPacketizerInput
)
;
return
;
}
if
(
IsPassThrough
(
aGraph
)
)
{
ResetAudioProcessing
(
aGraph
)
;
}
else
{
MOZ_ASSERT
(
!
mPacketizerInput
)
;
}
}
uint32_t
AudioInputProcessing
:
:
GetRequestedInputChannelCount
(
)
const
{
return
mSettings
.
mChannels
;
}
void
AudioInputProcessing
:
:
RequestedInputChannelCountChanged
(
MediaTrackGraph
*
aGraph
CubebUtils
:
:
AudioDeviceID
aDeviceId
)
{
aGraph
-
>
ReevaluateInputDevice
(
aDeviceId
)
;
}
void
AudioInputProcessing
:
:
Start
(
MediaTrackGraph
*
aGraph
)
{
aGraph
-
>
AssertOnGraphThread
(
)
;
if
(
mEnabled
)
{
return
;
}
mEnabled
=
true
;
MOZ_ASSERT
(
!
mPacketizerInput
)
;
}
void
AudioInputProcessing
:
:
Stop
(
MediaTrackGraph
*
aGraph
)
{
aGraph
-
>
AssertOnGraphThread
(
)
;
if
(
!
mEnabled
)
{
return
;
}
mEnabled
=
false
;
if
(
IsPassThrough
(
aGraph
)
)
{
return
;
}
ResetAudioProcessing
(
aGraph
)
;
}
void
AudioInputProcessing
:
:
Process
(
AudioProcessingTrack
*
aTrack
GraphTime
aFrom
GraphTime
aTo
AudioSegment
*
aInput
AudioSegment
*
aOutput
)
{
aTrack
-
>
AssertOnGraphThread
(
)
;
MOZ_ASSERT
(
aFrom
<
=
aTo
)
;
MOZ_ASSERT
(
!
mEnded
)
;
TrackTime
need
=
aTo
-
aFrom
;
if
(
need
=
=
0
)
{
return
;
}
MediaTrackGraph
*
graph
=
aTrack
-
>
Graph
(
)
;
if
(
!
mEnabled
)
{
LOG_FRAME
(
"
(
Graph
%
p
Driver
%
p
)
AudioInputProcessing
%
p
Filling
%
"
PRId64
"
frames
of
silence
to
output
(
disabled
)
"
graph
graph
-
>
CurrentDriver
(
)
this
need
)
;
aOutput
-
>
AppendNullData
(
need
)
;
return
;
}
MOZ_ASSERT
(
aInput
-
>
GetDuration
(
)
=
=
need
"
Wrong
data
length
from
input
port
source
"
)
;
if
(
IsPassThrough
(
graph
)
)
{
LOG_FRAME
(
"
(
Graph
%
p
Driver
%
p
)
AudioInputProcessing
%
p
Forwarding
%
"
PRId64
"
frames
of
input
data
to
output
directly
(
PassThrough
)
"
graph
graph
-
>
CurrentDriver
(
)
this
aInput
-
>
GetDuration
(
)
)
;
aOutput
-
>
AppendSegment
(
aInput
)
;
return
;
}
EnsurePacketizer
(
aTrack
)
;
MOZ_ASSERT
(
static_cast
<
uint32_t
>
(
mSegment
.
GetDuration
(
)
)
+
mPacketizerInput
-
>
FramesAvailable
(
)
=
=
mPacketizerInput
-
>
mPacketSize
)
;
MOZ_ASSERT
(
mSegment
.
GetDuration
(
)
>
=
1
)
;
MOZ_ASSERT
(
mSegment
.
GetDuration
(
)
<
=
mPacketizerInput
-
>
mPacketSize
)
;
PacketizeAndProcess
(
aTrack
*
aInput
)
;
LOG_FRAME
(
"
(
Graph
%
p
Driver
%
p
)
AudioInputProcessing
%
p
Buffer
has
%
"
PRId64
"
frames
of
data
now
after
packetizing
and
processing
"
graph
graph
-
>
CurrentDriver
(
)
this
mSegment
.
GetDuration
(
)
)
;
MOZ_ASSERT
(
mSegment
.
GetDuration
(
)
>
need
)
;
aOutput
-
>
AppendSlice
(
mSegment
0
need
)
;
mSegment
.
RemoveLeading
(
need
)
;
LOG_FRAME
(
"
(
Graph
%
p
Driver
%
p
)
AudioInputProcessing
%
p
moving
%
"
PRId64
"
frames
of
data
to
output
leaving
%
"
PRId64
"
frames
in
buffer
"
graph
graph
-
>
CurrentDriver
(
)
this
need
mSegment
.
GetDuration
(
)
)
;
MOZ_ASSERT
(
static_cast
<
uint32_t
>
(
mSegment
.
GetDuration
(
)
)
+
mPacketizerInput
-
>
FramesAvailable
(
)
=
=
mPacketizerInput
-
>
mPacketSize
)
;
MOZ_ASSERT
(
mSegment
.
GetDuration
(
)
>
=
1
)
;
MOZ_ASSERT
(
mSegment
.
GetDuration
(
)
<
=
mPacketizerInput
-
>
mPacketSize
)
;
}
void
AudioInputProcessing
:
:
ProcessOutputData
(
AudioProcessingTrack
*
aTrack
const
AudioChunk
&
aChunk
)
{
MOZ_ASSERT
(
aChunk
.
ChannelCount
(
)
>
0
)
;
aTrack
-
>
AssertOnGraphThread
(
)
;
if
(
!
mEnabled
|
|
IsPassThrough
(
aTrack
-
>
Graph
(
)
)
)
{
return
;
}
if
(
aChunk
.
mDuration
=
=
0
)
{
return
;
}
TrackRate
sampleRate
=
aTrack
-
>
mSampleRate
;
uint32_t
framesPerPacket
=
GetPacketSize
(
sampleRate
)
;
uint32_t
channelCount
=
std
:
:
min
<
uint32_t
>
(
aChunk
.
ChannelCount
(
)
MAX_CHANNELS
)
;
if
(
channelCount
!
=
mOutputBufferChannelCount
|
|
channelCount
*
framesPerPacket
!
=
mOutputBuffer
.
Length
(
)
)
{
mOutputBuffer
.
SetLength
(
channelCount
*
framesPerPacket
)
;
mOutputBufferChannelCount
=
channelCount
;
mOutputBufferFrameCount
=
0
;
}
TrackTime
chunkOffset
=
0
;
AutoTArray
<
float
*
MAX_CHANNELS
>
channelPtrs
;
channelPtrs
.
SetLength
(
channelCount
)
;
do
{
MOZ_ASSERT
(
mOutputBufferFrameCount
<
framesPerPacket
)
;
uint32_t
packetRemainder
=
framesPerPacket
-
mOutputBufferFrameCount
;
mSubChunk
=
aChunk
;
mSubChunk
.
SliceTo
(
chunkOffset
std
:
:
min
(
chunkOffset
+
packetRemainder
aChunk
.
mDuration
)
)
;
MOZ_ASSERT
(
mSubChunk
.
mDuration
<
=
packetRemainder
)
;
for
(
uint32_t
channel
=
0
;
channel
<
channelCount
;
channel
+
+
)
{
channelPtrs
[
channel
]
=
&
mOutputBuffer
[
channel
*
framesPerPacket
+
mOutputBufferFrameCount
]
;
}
mSubChunk
.
DownMixTo
(
channelPtrs
)
;
chunkOffset
+
=
mSubChunk
.
mDuration
;
MOZ_ASSERT
(
chunkOffset
<
=
aChunk
.
mDuration
)
;
mOutputBufferFrameCount
+
=
mSubChunk
.
mDuration
;
MOZ_ASSERT
(
mOutputBufferFrameCount
<
=
framesPerPacket
)
;
if
(
mOutputBufferFrameCount
=
=
framesPerPacket
)
{
EnsureAudioProcessing
(
aTrack
)
;
for
(
uint32_t
channel
=
0
;
channel
<
channelCount
;
channel
+
+
)
{
channelPtrs
[
channel
]
=
&
mOutputBuffer
[
channel
*
framesPerPacket
]
;
}
StreamConfig
reverseConfig
(
sampleRate
channelCount
)
;
DebugOnly
<
int
>
err
=
mAudioProcessing
-
>
AnalyzeReverseStream
(
channelPtrs
.
Elements
(
)
reverseConfig
)
;
MOZ_ASSERT
(
!
err
"
Could
not
process
the
reverse
stream
.
"
)
;
mOutputBufferFrameCount
=
0
;
}
}
while
(
chunkOffset
<
aChunk
.
mDuration
)
;
mSubChunk
.
SetNull
(
0
)
;
}
void
AudioInputProcessing
:
:
PacketizeAndProcess
(
AudioProcessingTrack
*
aTrack
const
AudioSegment
&
aSegment
)
{
MediaTrackGraph
*
graph
=
aTrack
-
>
Graph
(
)
;
MOZ_ASSERT
(
!
IsPassThrough
(
graph
)
"
This
should
be
bypassed
when
in
PassThrough
mode
.
"
)
;
MOZ_ASSERT
(
mEnabled
)
;
MOZ_ASSERT
(
mPacketizerInput
)
;
MOZ_ASSERT
(
mPacketizerInput
-
>
mPacketSize
=
=
GetPacketSize
(
aTrack
-
>
mSampleRate
)
)
;
auto
pendingFrames
=
[
&
]
(
)
{
TrackTime
frames
=
0
;
for
(
const
auto
&
p
:
mChunksInPacketizer
)
{
frames
+
=
p
.
first
;
}
return
frames
;
}
;
MOZ_ASSERT
(
mPacketizerInput
-
>
FramesAvailable
(
)
=
=
static_cast
<
uint32_t
>
(
pendingFrames
(
)
)
)
;
size_t
sampleCount
=
aSegment
.
WriteToInterleavedBuffer
(
mInterleavedBuffer
mPacketizerInput
-
>
mChannels
)
;
size_t
frameCount
=
sampleCount
/
static_cast
<
size_t
>
(
mPacketizerInput
-
>
mChannels
)
;
mPacketizerInput
-
>
Input
(
mInterleavedBuffer
.
Elements
(
)
static_cast
<
uint32_t
>
(
frameCount
)
)
;
for
(
AudioSegment
:
:
ConstChunkIterator
iter
(
aSegment
)
;
!
iter
.
IsEnded
(
)
;
iter
.
Next
(
)
)
{
MOZ_ASSERT
(
iter
-
>
mDuration
>
0
)
;
mChunksInPacketizer
.
emplace_back
(
std
:
:
make_pair
(
iter
-
>
mDuration
iter
-
>
mPrincipalHandle
)
)
;
}
MOZ_ASSERT
(
mPacketizerInput
-
>
FramesAvailable
(
)
=
=
static_cast
<
uint32_t
>
(
pendingFrames
(
)
)
)
;
LOG_FRAME
(
"
(
Graph
%
p
Driver
%
p
)
AudioInputProcessing
%
p
Packetizing
%
zu
frames
.
"
"
Packetizer
has
%
u
frames
(
enough
for
%
u
packets
)
now
"
graph
graph
-
>
CurrentDriver
(
)
this
frameCount
mPacketizerInput
-
>
FramesAvailable
(
)
mPacketizerInput
-
>
PacketsAvailable
(
)
)
;
size_t
offset
=
0
;
while
(
mPacketizerInput
-
>
PacketsAvailable
(
)
)
{
mPacketCount
+
+
;
uint32_t
samplesPerPacket
=
mPacketizerInput
-
>
mPacketSize
*
mPacketizerInput
-
>
mChannels
;
if
(
mInputBuffer
.
Length
(
)
<
samplesPerPacket
)
{
mInputBuffer
.
SetLength
(
samplesPerPacket
)
;
}
if
(
mDeinterleavedBuffer
.
Length
(
)
<
samplesPerPacket
)
{
mDeinterleavedBuffer
.
SetLength
(
samplesPerPacket
)
;
}
float
*
packet
=
mInputBuffer
.
Data
(
)
;
mPacketizerInput
-
>
Output
(
packet
)
;
AutoTArray
<
float
*
8
>
deinterleavedPacketizedInputDataChannelPointers
;
uint32_t
channelCountInput
=
0
;
if
(
mPacketizerInput
-
>
mChannels
>
MAX_CHANNELS
)
{
channelCountInput
=
MONO
;
deinterleavedPacketizedInputDataChannelPointers
.
SetLength
(
channelCountInput
)
;
deinterleavedPacketizedInputDataChannelPointers
[
0
]
=
mDeinterleavedBuffer
.
Data
(
)
;
float
gain
=
1
.
f
/
mPacketizerInput
-
>
mChannels
;
size_t
readIndex
=
0
;
for
(
size_t
i
=
0
;
i
<
mPacketizerInput
-
>
mPacketSize
;
i
+
+
)
{
mDeinterleavedBuffer
.
Data
(
)
[
i
]
=
0
.
;
for
(
size_t
j
=
0
;
j
<
mPacketizerInput
-
>
mChannels
;
j
+
+
)
{
mDeinterleavedBuffer
.
Data
(
)
[
i
]
+
=
gain
*
packet
[
readIndex
+
+
]
;
}
}
}
else
{
channelCountInput
=
mPacketizerInput
-
>
mChannels
;
webrtc
:
:
InterleavedView
<
const
float
>
interleaved
(
packet
mPacketizerInput
-
>
mPacketSize
channelCountInput
)
;
webrtc
:
:
DeinterleavedView
<
float
>
deinterleaved
(
mDeinterleavedBuffer
.
Data
(
)
mPacketizerInput
-
>
mPacketSize
channelCountInput
)
;
Deinterleave
(
interleaved
deinterleaved
)
;
deinterleavedPacketizedInputDataChannelPointers
.
SetLength
(
channelCountInput
)
;
for
(
size_t
i
=
0
;
i
<
deinterleavedPacketizedInputDataChannelPointers
.
Length
(
)
;
+
+
i
)
{
deinterleavedPacketizedInputDataChannelPointers
[
i
]
=
deinterleaved
[
i
]
.
data
(
)
;
}
}
StreamConfig
inputConfig
(
aTrack
-
>
mSampleRate
channelCountInput
)
;
StreamConfig
outputConfig
=
inputConfig
;
EnsureAudioProcessing
(
aTrack
)
;
mAudioProcessing
-
>
set_stream_delay_ms
(
0
)
;
CheckedInt
<
size_t
>
bufferSize
(
sizeof
(
float
)
)
;
bufferSize
*
=
mPacketizerInput
-
>
mPacketSize
;
bufferSize
*
=
channelCountInput
;
RefPtr
<
SharedBuffer
>
buffer
=
SharedBuffer
:
:
Create
(
bufferSize
)
;
AutoTArray
<
float
*
8
>
processedOutputChannelPointers
;
AutoTArray
<
const
float
*
8
>
processedOutputChannelPointersConst
;
processedOutputChannelPointers
.
SetLength
(
channelCountInput
)
;
processedOutputChannelPointersConst
.
SetLength
(
channelCountInput
)
;
offset
=
0
;
for
(
size_t
i
=
0
;
i
<
processedOutputChannelPointers
.
Length
(
)
;
+
+
i
)
{
processedOutputChannelPointers
[
i
]
=
static_cast
<
float
*
>
(
buffer
-
>
Data
(
)
)
+
offset
;
processedOutputChannelPointersConst
[
i
]
=
static_cast
<
float
*
>
(
buffer
-
>
Data
(
)
)
+
offset
;
offset
+
=
mPacketizerInput
-
>
mPacketSize
;
}
mAudioProcessing
-
>
ProcessStream
(
deinterleavedPacketizedInputDataChannelPointers
.
Elements
(
)
inputConfig
outputConfig
processedOutputChannelPointers
.
Elements
(
)
)
;
if
(
MOZ_LOG_TEST
(
gMediaManagerLog
LogLevel
:
:
Debug
)
&
&
!
(
mPacketCount
%
50
)
)
{
AudioProcessingStats
stats
=
mAudioProcessing
-
>
GetStatistics
(
)
;
char
msg
[
1024
]
;
msg
[
0
]
=
'
\
0
'
;
size_t
offset
=
0
;
#
define
AddIfValue
(
format
member
)
\
if
(
stats
.
member
.
has_value
(
)
)
{
\
offset
+
=
SprintfBuf
(
msg
+
offset
sizeof
(
msg
)
-
offset
\
#
member
"
:
"
format
"
"
stats
.
member
.
value
(
)
)
;
\
}
AddIfValue
(
"
%
d
"
voice_detected
)
;
AddIfValue
(
"
%
lf
"
echo_return_loss
)
;
AddIfValue
(
"
%
lf
"
echo_return_loss_enhancement
)
;
AddIfValue
(
"
%
lf
"
divergent_filter_fraction
)
;
AddIfValue
(
"
%
d
"
delay_median_ms
)
;
AddIfValue
(
"
%
d
"
delay_standard_deviation_ms
)
;
AddIfValue
(
"
%
d
"
delay_ms
)
;
#
undef
AddIfValue
LOG
(
"
AudioProcessing
statistics
:
%
s
"
msg
)
;
}
if
(
mEnded
)
{
continue
;
}
MOZ_ASSERT
(
processedOutputChannelPointers
.
Length
(
)
=
=
channelCountInput
)
;
auto
getAudioChunk
=
[
&
]
(
TrackTime
aStart
TrackTime
aEnd
const
PrincipalHandle
&
aPrincipalHandle
)
{
if
(
aStart
=
=
aEnd
)
{
return
AudioChunk
(
)
;
}
RefPtr
<
SharedBuffer
>
other
=
buffer
;
AudioChunk
c
=
AudioChunk
(
other
.
forget
(
)
processedOutputChannelPointersConst
static_cast
<
TrackTime
>
(
mPacketizerInput
-
>
mPacketSize
)
aPrincipalHandle
)
;
c
.
SliceTo
(
aStart
aEnd
)
;
return
c
;
}
;
TrackTime
len
=
static_cast
<
TrackTime
>
(
mPacketizerInput
-
>
mPacketSize
)
;
TrackTime
start
=
0
;
while
(
!
mChunksInPacketizer
.
empty
(
)
)
{
auto
&
[
frames
principal
]
=
mChunksInPacketizer
.
front
(
)
;
const
TrackTime
end
=
start
+
frames
;
if
(
end
>
len
)
{
if
(
len
>
start
)
{
mSegment
.
AppendAndConsumeChunk
(
getAudioChunk
(
start
len
principal
)
)
;
frames
-
=
len
-
start
;
}
break
;
}
mSegment
.
AppendAndConsumeChunk
(
getAudioChunk
(
start
end
principal
)
)
;
start
=
end
;
mChunksInPacketizer
.
pop_front
(
)
;
}
LOG_FRAME
(
"
(
Graph
%
p
Driver
%
p
)
AudioInputProcessing
%
p
Appending
%
u
frames
of
"
"
packetized
audio
leaving
%
u
frames
in
packetizer
(
%
"
PRId64
"
frames
in
mChunksInPacketizer
)
"
graph
graph
-
>
CurrentDriver
(
)
this
mPacketizerInput
-
>
mPacketSize
mPacketizerInput
-
>
FramesAvailable
(
)
pendingFrames
(
)
)
;
MOZ_ASSERT
(
mPacketizerInput
-
>
FramesAvailable
(
)
=
=
static_cast
<
uint32_t
>
(
pendingFrames
(
)
)
)
;
}
}
void
AudioInputProcessing
:
:
DeviceChanged
(
MediaTrackGraph
*
aGraph
)
{
aGraph
-
>
AssertOnGraphThread
(
)
;
if
(
mAudioProcessing
)
{
mAudioProcessing
-
>
Initialize
(
)
;
}
LOG_FRAME
(
"
(
Graph
%
p
Driver
%
p
)
AudioInputProcessing
%
p
Reinitializing
audio
"
"
processing
"
aGraph
aGraph
-
>
CurrentDriver
(
)
this
)
;
}
cubeb_input_processing_params
AudioInputProcessing
:
:
RequestedInputProcessingParams
(
MediaTrackGraph
*
aGraph
)
const
{
aGraph
-
>
AssertOnGraphThread
(
)
;
if
(
!
mPlatformProcessingEnabled
)
{
return
CUBEB_INPUT_PROCESSING_PARAM_NONE
;
}
if
(
mPlatformProcessingSetError
)
{
return
CUBEB_INPUT_PROCESSING_PARAM_NONE
;
}
cubeb_input_processing_params
params
=
CUBEB_INPUT_PROCESSING_PARAM_NONE
;
if
(
mSettings
.
mAecOn
)
{
params
|
=
CUBEB_INPUT_PROCESSING_PARAM_ECHO_CANCELLATION
;
}
if
(
mSettings
.
mAgcOn
)
{
params
|
=
CUBEB_INPUT_PROCESSING_PARAM_AUTOMATIC_GAIN_CONTROL
;
}
if
(
mSettings
.
mNoiseOn
)
{
params
|
=
CUBEB_INPUT_PROCESSING_PARAM_NOISE_SUPPRESSION
;
}
return
params
;
}
void
AudioInputProcessing
:
:
ApplySettings
(
MediaTrackGraph
*
aGraph
CubebUtils
:
:
AudioDeviceID
aDeviceID
const
MediaEnginePrefs
&
aSettings
)
{
TRACE
(
"
AudioInputProcessing
:
:
ApplySettings
"
)
;
aGraph
-
>
AssertOnGraphThread
(
)
;
if
(
mPlatformProcessingSetError
.
valueOr
(
CUBEB_OK
)
!
=
CUBEB_ERROR_NOT_SUPPORTED
)
{
mPlatformProcessingSetError
=
Nothing
(
)
;
}
uint32_t
oldChannelCount
=
GetRequestedInputChannelCount
(
)
;
ApplySettingsInternal
(
aGraph
aSettings
)
;
if
(
oldChannelCount
!
=
GetRequestedInputChannelCount
(
)
)
{
RequestedInputChannelCountChanged
(
aGraph
aDeviceID
)
;
}
}
void
AudioInputProcessing
:
:
ApplySettingsInternal
(
MediaTrackGraph
*
aGraph
const
MediaEnginePrefs
&
aSettings
)
{
TRACE
(
"
AudioInputProcessing
:
:
ApplySettingsInternal
"
)
;
aGraph
-
>
AssertOnGraphThread
(
)
;
mPlatformProcessingEnabled
=
aSettings
.
mUsePlatformProcessing
;
bool
wasPassThrough
=
IsPassThrough
(
aGraph
)
;
mSettings
=
aSettings
;
if
(
mAudioProcessing
)
{
mAudioProcessing
-
>
ApplyConfig
(
ConfigForPrefs
(
aSettings
)
)
;
}
if
(
wasPassThrough
!
=
IsPassThrough
(
aGraph
)
)
{
PassThroughChanged
(
aGraph
)
;
}
}
webrtc
:
:
AudioProcessing
:
:
Config
AudioInputProcessing
:
:
AppliedConfig
(
MediaTrackGraph
*
aGraph
)
const
{
aGraph
-
>
AssertOnGraphThread
(
)
;
if
(
mAudioProcessing
)
{
return
mAudioProcessing
-
>
GetConfig
(
)
;
}
return
ConfigForPrefs
(
mSettings
)
;
}
void
AudioInputProcessing
:
:
End
(
)
{
mEnded
=
true
;
mSegment
.
Clear
(
)
;
}
TrackTime
AudioInputProcessing
:
:
NumBufferedFrames
(
MediaTrackGraph
*
aGraph
)
const
{
aGraph
-
>
AssertOnGraphThread
(
)
;
return
mSegment
.
GetDuration
(
)
;
}
void
AudioInputProcessing
:
:
EnsurePacketizer
(
AudioProcessingTrack
*
aTrack
)
{
aTrack
-
>
AssertOnGraphThread
(
)
;
MOZ_ASSERT
(
mEnabled
)
;
MediaTrackGraph
*
graph
=
aTrack
-
>
Graph
(
)
;
MOZ_ASSERT
(
!
IsPassThrough
(
graph
)
)
;
uint32_t
channelCount
=
GetRequestedInputChannelCount
(
)
;
MOZ_ASSERT
(
channelCount
>
0
)
;
if
(
mPacketizerInput
&
&
mPacketizerInput
-
>
mChannels
=
=
channelCount
)
{
return
;
}
MOZ_ASSERT_IF
(
mPacketizerInput
mPacketizerInput
-
>
mPacketSize
=
=
GetPacketSize
(
aTrack
-
>
mSampleRate
)
)
;
bool
needPreBuffering
=
!
mPacketizerInput
;
if
(
mPacketizerInput
)
{
const
TrackTime
numBufferedFrames
=
static_cast
<
TrackTime
>
(
mPacketizerInput
-
>
FramesAvailable
(
)
)
;
mSegment
.
AppendNullData
(
numBufferedFrames
)
;
mPacketizerInput
=
Nothing
(
)
;
mChunksInPacketizer
.
clear
(
)
;
}
mPacketizerInput
.
emplace
(
GetPacketSize
(
aTrack
-
>
mSampleRate
)
channelCount
)
;
if
(
needPreBuffering
)
{
LOG_FRAME
(
"
(
Graph
%
p
Driver
%
p
)
AudioInputProcessing
%
p
:
Adding
%
u
frames
of
"
"
silence
as
pre
-
buffering
"
graph
graph
-
>
CurrentDriver
(
)
this
mPacketizerInput
-
>
mPacketSize
)
;
AudioSegment
buffering
;
buffering
.
AppendNullData
(
static_cast
<
TrackTime
>
(
mPacketizerInput
-
>
mPacketSize
)
)
;
PacketizeAndProcess
(
aTrack
buffering
)
;
}
}
void
AudioInputProcessing
:
:
EnsureAudioProcessing
(
AudioProcessingTrack
*
aTrack
)
{
aTrack
-
>
AssertOnGraphThread
(
)
;
MediaTrackGraph
*
graph
=
aTrack
-
>
Graph
(
)
;
bool
haveAECAndDrift
=
mSettings
.
mAecOn
;
if
(
haveAECAndDrift
)
{
if
(
mSettings
.
mExpectDrift
<
0
)
{
haveAECAndDrift
=
graph
-
>
OutputForAECMightDrift
(
)
|
|
aTrack
-
>
GetDeviceInputTrackGraphThread
(
)
-
>
AsNonNativeInputTrack
(
)
;
}
else
{
haveAECAndDrift
=
mSettings
.
mExpectDrift
>
0
;
}
}
if
(
!
mAudioProcessing
|
|
haveAECAndDrift
!
=
mHadAECAndDrift
)
{
TRACE
(
"
AudioProcessing
creation
"
)
;
LOG
(
"
Track
%
p
AudioInputProcessing
%
p
creating
AudioProcessing
.
"
"
aec
+
drift
:
%
s
"
aTrack
this
haveAECAndDrift
?
"
Y
"
:
"
N
"
)
;
mHadAECAndDrift
=
haveAECAndDrift
;
AudioProcessingBuilder
builder
;
builder
.
SetConfig
(
ConfigForPrefs
(
mSettings
)
)
;
if
(
haveAECAndDrift
)
{
EchoCanceller3Config
aec3Config
;
aec3Config
.
echo_removal_control
.
has_clock_drift
=
true
;
builder
.
SetEchoControlFactory
(
std
:
:
make_unique
<
EchoCanceller3Factory
>
(
aec3Config
)
)
;
}
mAudioProcessing
.
reset
(
builder
.
Create
(
)
.
release
(
)
)
;
}
}
void
AudioInputProcessing
:
:
ResetAudioProcessing
(
MediaTrackGraph
*
aGraph
)
{
aGraph
-
>
AssertOnGraphThread
(
)
;
MOZ_ASSERT
(
IsPassThrough
(
aGraph
)
|
|
!
mEnabled
)
;
LOG_FRAME
(
"
(
Graph
%
p
Driver
%
p
)
AudioInputProcessing
%
p
Resetting
audio
"
"
processing
"
aGraph
aGraph
-
>
CurrentDriver
(
)
this
)
;
if
(
mAudioProcessing
)
{
mAudioProcessing
-
>
Initialize
(
)
;
}
MOZ_ASSERT_IF
(
mPacketizerInput
static_cast
<
uint32_t
>
(
mSegment
.
GetDuration
(
)
)
+
mPacketizerInput
-
>
FramesAvailable
(
)
=
=
mPacketizerInput
-
>
mPacketSize
)
;
LOG_FRAME
(
"
(
Graph
%
p
Driver
%
p
)
AudioInputProcessing
%
p
Emptying
out
%
"
PRId64
"
frames
of
data
"
aGraph
aGraph
-
>
CurrentDriver
(
)
this
mSegment
.
GetDuration
(
)
)
;
mSegment
.
Clear
(
)
;
mPacketizerInput
=
Nothing
(
)
;
mChunksInPacketizer
.
clear
(
)
;
}
void
AudioProcessingTrack
:
:
Destroy
(
)
{
MOZ_ASSERT
(
NS_IsMainThread
(
)
)
;
DisconnectDeviceInput
(
)
;
MediaTrack
:
:
Destroy
(
)
;
}
void
AudioProcessingTrack
:
:
SetInputProcessing
(
RefPtr
<
AudioInputProcessing
>
aInputProcessing
)
{
if
(
IsDestroyed
(
)
)
{
return
;
}
QueueControlMessageWithNoShutdown
(
[
self
=
RefPtr
{
this
}
this
inputProcessing
=
std
:
:
move
(
aInputProcessing
)
]
(
)
mutable
{
TRACE
(
"
AudioProcessingTrack
:
:
SetInputProcessingImpl
"
)
;
SetInputProcessingImpl
(
std
:
:
move
(
inputProcessing
)
)
;
}
)
;
}
AudioProcessingTrack
*
AudioProcessingTrack
:
:
Create
(
MediaTrackGraph
*
aGraph
)
{
MOZ_ASSERT
(
NS_IsMainThread
(
)
)
;
AudioProcessingTrack
*
track
=
new
AudioProcessingTrack
(
aGraph
-
>
GraphRate
(
)
)
;
aGraph
-
>
AddTrack
(
track
)
;
return
track
;
}
void
AudioProcessingTrack
:
:
DestroyImpl
(
)
{
ProcessedMediaTrack
:
:
DestroyImpl
(
)
;
if
(
mInputProcessing
)
{
mInputProcessing
-
>
End
(
)
;
}
}
void
AudioProcessingTrack
:
:
ProcessInput
(
GraphTime
aFrom
GraphTime
aTo
uint32_t
aFlags
)
{
TRACE_COMMENT
(
"
AudioProcessingTrack
:
:
ProcessInput
"
"
AudioProcessingTrack
%
p
"
this
)
;
MOZ_ASSERT
(
mInputProcessing
)
;
MOZ_ASSERT
(
aFrom
<
aTo
)
;
LOG_FRAME
(
"
(
Graph
%
p
Driver
%
p
)
AudioProcessingTrack
%
p
ProcessInput
from
%
"
PRId64
"
to
%
"
PRId64
"
needs
%
"
PRId64
"
frames
"
mGraph
mGraph
-
>
CurrentDriver
(
)
this
aFrom
aTo
aTo
-
aFrom
)
;
if
(
!
mInputProcessing
-
>
IsEnded
(
)
)
{
MOZ_ASSERT
(
TrackTimeToGraphTime
(
GetEnd
(
)
)
=
=
aFrom
)
;
if
(
mInputs
.
IsEmpty
(
)
)
{
GetData
<
AudioSegment
>
(
)
-
>
AppendNullData
(
aTo
-
aFrom
)
;
LOG_FRAME
(
"
(
Graph
%
p
Driver
%
p
)
AudioProcessingTrack
%
p
Filling
%
"
PRId64
"
frames
of
null
data
(
no
input
source
)
"
mGraph
mGraph
-
>
CurrentDriver
(
)
this
aTo
-
aFrom
)
;
}
else
{
MOZ_ASSERT
(
mInputs
.
Length
(
)
=
=
1
)
;
AudioSegment
data
;
DeviceInputConsumerTrack
:
:
GetInputSourceData
(
data
aFrom
aTo
)
;
mInputProcessing
-
>
Process
(
this
aFrom
aTo
&
data
GetData
<
AudioSegment
>
(
)
)
;
}
MOZ_ASSERT
(
TrackTimeToGraphTime
(
GetEnd
(
)
)
=
=
aTo
)
;
ApplyTrackDisabling
(
mSegment
.
get
(
)
)
;
}
else
if
(
aFlags
&
ALLOW_END
)
{
mEnded
=
true
;
}
}
void
AudioProcessingTrack
:
:
NotifyOutputData
(
MediaTrackGraph
*
aGraph
const
AudioChunk
&
aChunk
)
{
MOZ_ASSERT
(
mGraph
=
=
aGraph
"
Cannot
feed
audio
output
to
another
graph
"
)
;
AssertOnGraphThread
(
)
;
if
(
mInputProcessing
)
{
mInputProcessing
-
>
ProcessOutputData
(
this
aChunk
)
;
}
}
void
AudioProcessingTrack
:
:
SetInputProcessingImpl
(
RefPtr
<
AudioInputProcessing
>
aInputProcessing
)
{
AssertOnGraphThread
(
)
;
mInputProcessing
=
std
:
:
move
(
aInputProcessing
)
;
}
MediaEngineWebRTCAudioCaptureSource
:
:
MediaEngineWebRTCAudioCaptureSource
(
const
MediaDevice
*
aMediaDevice
)
{
MOZ_ASSERT
(
aMediaDevice
-
>
mMediaSource
=
=
MediaSourceEnum
:
:
AudioCapture
)
;
}
nsString
MediaEngineWebRTCAudioCaptureSource
:
:
GetUUID
(
)
{
nsID
uuid
{
}
;
char
uuidBuffer
[
NSID_LENGTH
]
;
nsCString
asciiString
;
ErrorResult
rv
;
rv
=
nsID
:
:
GenerateUUIDInPlace
(
uuid
)
;
if
(
rv
.
Failed
(
)
)
{
return
u
"
"
_ns
;
}
uuid
.
ToProvidedString
(
uuidBuffer
)
;
asciiString
.
AssignASCII
(
uuidBuffer
)
;
return
NS_ConvertASCIItoUTF16
(
Substring
(
asciiString
1
NSID_LENGTH
-
3
)
)
;
}
nsString
MediaEngineWebRTCAudioCaptureSource
:
:
GetGroupId
(
)
{
return
u
"
AudioCaptureGroup
"
_ns
;
}
void
MediaEngineWebRTCAudioCaptureSource
:
:
SetTrack
(
const
RefPtr
<
MediaTrack
>
&
aTrack
const
PrincipalHandle
&
aPrincipalHandle
)
{
AssertIsOnOwningThread
(
)
;
}
nsresult
MediaEngineWebRTCAudioCaptureSource
:
:
Start
(
)
{
AssertIsOnOwningThread
(
)
;
return
NS_OK
;
}
nsresult
MediaEngineWebRTCAudioCaptureSource
:
:
Stop
(
)
{
AssertIsOnOwningThread
(
)
;
return
NS_OK
;
}
nsresult
MediaEngineWebRTCAudioCaptureSource
:
:
Reconfigure
(
const
dom
:
:
MediaTrackConstraints
&
aConstraints
const
MediaEnginePrefs
&
aPrefs
const
char
*
*
aOutBadConstraint
)
{
return
NS_OK
;
}
void
MediaEngineWebRTCAudioCaptureSource
:
:
GetSettings
(
dom
:
:
MediaTrackSettings
&
aOutSettings
)
const
{
aOutSettings
.
mAutoGainControl
.
Construct
(
false
)
;
aOutSettings
.
mEchoCancellation
.
Construct
(
false
)
;
aOutSettings
.
mNoiseSuppression
.
Construct
(
false
)
;
aOutSettings
.
mChannelCount
.
Construct
(
1
)
;
}
}
#
undef
MAX_CHANNELS
#
undef
MONO
#
undef
MAX_SAMPLING_FREQ
