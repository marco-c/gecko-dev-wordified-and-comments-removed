#
include
"
MediaEngineWebRTCAudio
.
h
"
#
include
<
stdio
.
h
>
#
include
<
algorithm
>
#
include
"
AudioConverter
.
h
"
#
include
"
MediaManager
.
h
"
#
include
"
MediaTrackGraphImpl
.
h
"
#
include
"
MediaTrackConstraints
.
h
"
#
include
"
mozilla
/
Assertions
.
h
"
#
include
"
mozilla
/
ErrorNames
.
h
"
#
include
"
nsContentUtils
.
h
"
#
include
"
nsIDUtils
.
h
"
#
include
"
transport
/
runnable_utils
.
h
"
#
include
"
Tracing
.
h
"
#
ifdef
FF
#
undef
FF
#
endif
#
include
"
webrtc
/
voice_engine
/
voice_engine_defines
.
h
"
#
include
"
webrtc
/
modules
/
audio_processing
/
include
/
audio_processing
.
h
"
#
include
"
webrtc
/
common_audio
/
include
/
audio_util
.
h
"
using
namespace
webrtc
;
#
define
MAX_CHANNELS
2
#
define
MONO
1
#
define
MAX_SAMPLING_FREQ
48000
/
/
Hz
-
multiple
of
100
namespace
mozilla
{
extern
LazyLogModule
gMediaManagerLog
;
#
define
LOG
(
.
.
.
)
MOZ_LOG
(
gMediaManagerLog
LogLevel
:
:
Debug
(
__VA_ARGS__
)
)
#
define
LOG_FRAME
(
.
.
.
)
\
MOZ_LOG
(
gMediaManagerLog
LogLevel
:
:
Verbose
(
__VA_ARGS__
)
)
#
define
LOG_ERROR
(
.
.
.
)
MOZ_LOG
(
gMediaManagerLog
LogLevel
:
:
Error
(
__VA_ARGS__
)
)
MediaEngineWebRTCMicrophoneSource
:
:
MediaEngineWebRTCMicrophoneSource
(
RefPtr
<
AudioDeviceInfo
>
aInfo
const
nsString
&
aDeviceName
const
nsCString
&
aDeviceUUID
const
nsString
&
aDeviceGroup
uint32_t
aMaxChannelCount
bool
aDelayAgnostic
bool
aExtendedFilter
)
:
mPrincipal
(
PRINCIPAL_HANDLE_NONE
)
mDeviceInfo
(
std
:
:
move
(
aInfo
)
)
mDelayAgnostic
(
aDelayAgnostic
)
mExtendedFilter
(
aExtendedFilter
)
mDeviceName
(
aDeviceName
)
mDeviceUUID
(
aDeviceUUID
)
mDeviceGroup
(
aDeviceGroup
)
mDeviceMaxChannelCount
(
aMaxChannelCount
)
mSettings
(
new
nsMainThreadPtrHolder
<
media
:
:
Refcountable
<
dom
:
:
MediaTrackSettings
>
>
(
"
MediaEngineWebRTCMicrophoneSource
:
:
mSettings
"
new
media
:
:
Refcountable
<
dom
:
:
MediaTrackSettings
>
(
)
false
)
)
{
#
ifndef
ANDROID
MOZ_ASSERT
(
mDeviceInfo
-
>
DeviceID
(
)
)
;
#
endif
mSettings
-
>
mEchoCancellation
.
Construct
(
0
)
;
mSettings
-
>
mAutoGainControl
.
Construct
(
0
)
;
mSettings
-
>
mNoiseSuppression
.
Construct
(
0
)
;
mSettings
-
>
mChannelCount
.
Construct
(
0
)
;
mState
=
kReleased
;
}
nsString
MediaEngineWebRTCMicrophoneSource
:
:
GetName
(
)
const
{
return
mDeviceName
;
}
nsCString
MediaEngineWebRTCMicrophoneSource
:
:
GetUUID
(
)
const
{
return
mDeviceUUID
;
}
nsString
MediaEngineWebRTCMicrophoneSource
:
:
GetGroupId
(
)
const
{
return
mDeviceGroup
;
}
nsresult
MediaEngineWebRTCMicrophoneSource
:
:
EvaluateSettings
(
const
NormalizedConstraints
&
aConstraintsUpdate
const
MediaEnginePrefs
&
aInPrefs
MediaEnginePrefs
*
aOutPrefs
const
char
*
*
aOutBadConstraint
)
{
AssertIsOnOwningThread
(
)
;
FlattenedConstraints
c
(
aConstraintsUpdate
)
;
MediaEnginePrefs
prefs
=
aInPrefs
;
prefs
.
mAecOn
=
c
.
mEchoCancellation
.
Get
(
aInPrefs
.
mAecOn
)
;
prefs
.
mAgcOn
=
c
.
mAutoGainControl
.
Get
(
aInPrefs
.
mAgcOn
&
&
prefs
.
mAecOn
)
;
prefs
.
mNoiseOn
=
c
.
mNoiseSuppression
.
Get
(
aInPrefs
.
mNoiseOn
&
&
prefs
.
mAecOn
)
;
int32_t
maxChannels
=
mDeviceInfo
-
>
MaxChannels
(
)
;
if
(
c
.
mChannelCount
.
mMin
>
maxChannels
)
{
*
aOutBadConstraint
=
"
channelCount
"
;
return
NS_ERROR_FAILURE
;
}
if
(
aInPrefs
.
mChannels
<
=
0
)
{
prefs
.
mChannels
=
maxChannels
;
}
prefs
.
mChannels
=
c
.
mChannelCount
.
Get
(
std
:
:
min
(
prefs
.
mChannels
maxChannels
)
)
;
prefs
.
mChannels
=
std
:
:
max
(
1
std
:
:
min
(
prefs
.
mChannels
maxChannels
)
)
;
LOG
(
"
Mic
source
%
p
Audio
config
:
aec
:
%
d
agc
:
%
d
noise
:
%
d
channels
:
%
d
"
this
prefs
.
mAecOn
?
prefs
.
mAec
:
-
1
prefs
.
mAgcOn
?
prefs
.
mAgc
:
-
1
prefs
.
mNoiseOn
?
prefs
.
mNoise
:
-
1
prefs
.
mChannels
)
;
*
aOutPrefs
=
prefs
;
return
NS_OK
;
}
nsresult
MediaEngineWebRTCMicrophoneSource
:
:
Reconfigure
(
const
dom
:
:
MediaTrackConstraints
&
aConstraints
const
MediaEnginePrefs
&
aPrefs
const
char
*
*
aOutBadConstraint
)
{
AssertIsOnOwningThread
(
)
;
MOZ_ASSERT
(
mTrack
)
;
LOG
(
"
Mic
source
%
p
Reconfigure
"
this
)
;
NormalizedConstraints
constraints
(
aConstraints
)
;
MediaEnginePrefs
outputPrefs
;
nsresult
rv
=
EvaluateSettings
(
constraints
aPrefs
&
outputPrefs
aOutBadConstraint
)
;
if
(
NS_FAILED
(
rv
)
)
{
if
(
aOutBadConstraint
)
{
return
NS_ERROR_INVALID_ARG
;
}
nsAutoCString
name
;
GetErrorName
(
rv
name
)
;
LOG
(
"
Mic
source
%
p
Reconfigure
(
)
failed
unexpectedly
.
rv
=
%
s
"
this
name
.
Data
(
)
)
;
Stop
(
)
;
return
NS_ERROR_UNEXPECTED
;
}
ApplySettings
(
outputPrefs
)
;
mCurrentPrefs
=
outputPrefs
;
return
NS_OK
;
}
void
MediaEngineWebRTCMicrophoneSource
:
:
UpdateAECSettings
(
bool
aEnable
bool
aUseAecMobile
EchoCancellation
:
:
SuppressionLevel
aLevel
EchoControlMobile
:
:
RoutingMode
aRoutingMode
)
{
AssertIsOnOwningThread
(
)
;
RefPtr
<
MediaEngineWebRTCMicrophoneSource
>
that
=
this
;
NS_DispatchToMainThread
(
NS_NewRunnableFunction
(
__func__
[
that
track
=
mTrack
aEnable
aUseAecMobile
aLevel
aRoutingMode
]
{
class
Message
:
public
ControlMessage
{
public
:
Message
(
AudioInputProcessing
*
aInputProcessing
bool
aEnable
bool
aUseAecMobile
EchoCancellation
:
:
SuppressionLevel
aLevel
EchoControlMobile
:
:
RoutingMode
aRoutingMode
)
:
ControlMessage
(
nullptr
)
mInputProcessing
(
aInputProcessing
)
mEnable
(
aEnable
)
mUseAecMobile
(
aUseAecMobile
)
mLevel
(
aLevel
)
mRoutingMode
(
aRoutingMode
)
{
}
void
Run
(
)
override
{
TRACE
(
"
UpdateAECSettings
"
)
;
mInputProcessing
-
>
UpdateAECSettings
(
mEnable
mUseAecMobile
mLevel
mRoutingMode
)
;
}
protected
:
RefPtr
<
AudioInputProcessing
>
mInputProcessing
;
bool
mEnable
;
bool
mUseAecMobile
;
EchoCancellation
:
:
SuppressionLevel
mLevel
;
EchoControlMobile
:
:
RoutingMode
mRoutingMode
;
}
;
if
(
track
-
>
IsDestroyed
(
)
)
{
return
;
}
track
-
>
GraphImpl
(
)
-
>
AppendMessage
(
MakeUnique
<
Message
>
(
that
-
>
mInputProcessing
aEnable
aUseAecMobile
aLevel
aRoutingMode
)
)
;
}
)
)
;
}
void
MediaEngineWebRTCMicrophoneSource
:
:
UpdateAGCSettings
(
bool
aEnable
GainControl
:
:
Mode
aMode
)
{
AssertIsOnOwningThread
(
)
;
RefPtr
<
MediaEngineWebRTCMicrophoneSource
>
that
=
this
;
NS_DispatchToMainThread
(
NS_NewRunnableFunction
(
__func__
[
that
track
=
mTrack
aEnable
aMode
]
{
class
Message
:
public
ControlMessage
{
public
:
Message
(
AudioInputProcessing
*
aInputProcessing
bool
aEnable
GainControl
:
:
Mode
aMode
)
:
ControlMessage
(
nullptr
)
mInputProcessing
(
aInputProcessing
)
mEnable
(
aEnable
)
mMode
(
aMode
)
{
}
void
Run
(
)
override
{
TRACE
(
"
UpdateAGCSettings
"
)
;
mInputProcessing
-
>
UpdateAGCSettings
(
mEnable
mMode
)
;
}
protected
:
RefPtr
<
AudioInputProcessing
>
mInputProcessing
;
bool
mEnable
;
GainControl
:
:
Mode
mMode
;
}
;
if
(
track
-
>
IsDestroyed
(
)
)
{
return
;
}
track
-
>
GraphImpl
(
)
-
>
AppendMessage
(
MakeUnique
<
Message
>
(
that
-
>
mInputProcessing
aEnable
aMode
)
)
;
}
)
)
;
}
void
MediaEngineWebRTCMicrophoneSource
:
:
UpdateHPFSettings
(
bool
aEnable
)
{
AssertIsOnOwningThread
(
)
;
RefPtr
<
MediaEngineWebRTCMicrophoneSource
>
that
=
this
;
NS_DispatchToMainThread
(
NS_NewRunnableFunction
(
__func__
[
that
track
=
mTrack
aEnable
]
{
class
Message
:
public
ControlMessage
{
public
:
Message
(
AudioInputProcessing
*
aInputProcessing
bool
aEnable
)
:
ControlMessage
(
nullptr
)
mInputProcessing
(
aInputProcessing
)
mEnable
(
aEnable
)
{
}
void
Run
(
)
override
{
TRACE
(
"
UpdateHPFSettings
"
)
;
mInputProcessing
-
>
UpdateHPFSettings
(
mEnable
)
;
}
protected
:
RefPtr
<
AudioInputProcessing
>
mInputProcessing
;
bool
mEnable
;
}
;
if
(
track
-
>
IsDestroyed
(
)
)
{
return
;
}
track
-
>
GraphImpl
(
)
-
>
AppendMessage
(
MakeUnique
<
Message
>
(
that
-
>
mInputProcessing
aEnable
)
)
;
}
)
)
;
}
void
MediaEngineWebRTCMicrophoneSource
:
:
UpdateNSSettings
(
bool
aEnable
webrtc
:
:
NoiseSuppression
:
:
Level
aLevel
)
{
AssertIsOnOwningThread
(
)
;
RefPtr
<
MediaEngineWebRTCMicrophoneSource
>
that
=
this
;
NS_DispatchToMainThread
(
NS_NewRunnableFunction
(
__func__
[
that
track
=
mTrack
aEnable
aLevel
]
{
class
Message
:
public
ControlMessage
{
public
:
Message
(
AudioInputProcessing
*
aInputProcessing
bool
aEnable
webrtc
:
:
NoiseSuppression
:
:
Level
aLevel
)
:
ControlMessage
(
nullptr
)
mInputProcessing
(
aInputProcessing
)
mEnable
(
aEnable
)
mLevel
(
aLevel
)
{
}
void
Run
(
)
override
{
TRACE
(
"
UpdateHPFSettings
"
)
;
mInputProcessing
-
>
UpdateNSSettings
(
mEnable
mLevel
)
;
}
protected
:
RefPtr
<
AudioInputProcessing
>
mInputProcessing
;
bool
mEnable
;
webrtc
:
:
NoiseSuppression
:
:
Level
mLevel
;
}
;
if
(
track
-
>
IsDestroyed
(
)
)
{
return
;
}
track
-
>
GraphImpl
(
)
-
>
AppendMessage
(
MakeUnique
<
Message
>
(
that
-
>
mInputProcessing
aEnable
aLevel
)
)
;
}
)
)
;
}
void
MediaEngineWebRTCMicrophoneSource
:
:
UpdateAPMExtraOptions
(
bool
aExtendedFilter
bool
aDelayAgnostic
)
{
AssertIsOnOwningThread
(
)
;
RefPtr
<
MediaEngineWebRTCMicrophoneSource
>
that
=
this
;
NS_DispatchToMainThread
(
NS_NewRunnableFunction
(
__func__
[
that
track
=
mTrack
aExtendedFilter
aDelayAgnostic
]
{
class
Message
:
public
ControlMessage
{
public
:
Message
(
AudioInputProcessing
*
aInputProcessing
bool
aExtendedFilter
bool
aDelayAgnostic
)
:
ControlMessage
(
nullptr
)
mInputProcessing
(
aInputProcessing
)
mExtendedFilter
(
aExtendedFilter
)
mDelayAgnostic
(
aDelayAgnostic
)
{
}
void
Run
(
)
override
{
TRACE
(
"
UpdateAPMExtraOptions
"
)
;
mInputProcessing
-
>
UpdateAPMExtraOptions
(
mExtendedFilter
mDelayAgnostic
)
;
}
protected
:
RefPtr
<
AudioInputProcessing
>
mInputProcessing
;
bool
mExtendedFilter
;
bool
mDelayAgnostic
;
}
;
if
(
track
-
>
IsDestroyed
(
)
)
{
return
;
}
track
-
>
GraphImpl
(
)
-
>
AppendMessage
(
MakeUnique
<
Message
>
(
that
-
>
mInputProcessing
aExtendedFilter
aDelayAgnostic
)
)
;
}
)
)
;
}
void
MediaEngineWebRTCMicrophoneSource
:
:
ApplySettings
(
const
MediaEnginePrefs
&
aPrefs
)
{
AssertIsOnOwningThread
(
)
;
MOZ_ASSERT
(
mTrack
"
ApplySetting
is
to
be
called
only
after
SetTrack
has
been
called
"
)
;
if
(
mTrack
)
{
UpdateAGCSettings
(
aPrefs
.
mAgcOn
static_cast
<
webrtc
:
:
GainControl
:
:
Mode
>
(
aPrefs
.
mAgc
)
)
;
UpdateNSSettings
(
aPrefs
.
mNoiseOn
static_cast
<
webrtc
:
:
NoiseSuppression
:
:
Level
>
(
aPrefs
.
mNoise
)
)
;
UpdateAECSettings
(
aPrefs
.
mAecOn
aPrefs
.
mUseAecMobile
static_cast
<
webrtc
:
:
EchoCancellation
:
:
SuppressionLevel
>
(
aPrefs
.
mAec
)
static_cast
<
webrtc
:
:
EchoControlMobile
:
:
RoutingMode
>
(
aPrefs
.
mRoutingMode
)
)
;
UpdateHPFSettings
(
aPrefs
.
mHPFOn
)
;
UpdateAPMExtraOptions
(
mExtendedFilter
mDelayAgnostic
)
;
}
RefPtr
<
MediaEngineWebRTCMicrophoneSource
>
that
=
this
;
NS_DispatchToMainThread
(
NS_NewRunnableFunction
(
__func__
[
that
track
=
mTrack
prefs
=
aPrefs
]
{
that
-
>
mSettings
-
>
mEchoCancellation
.
Value
(
)
=
prefs
.
mAecOn
;
that
-
>
mSettings
-
>
mAutoGainControl
.
Value
(
)
=
prefs
.
mAgcOn
;
that
-
>
mSettings
-
>
mNoiseSuppression
.
Value
(
)
=
prefs
.
mNoiseOn
;
that
-
>
mSettings
-
>
mChannelCount
.
Value
(
)
=
prefs
.
mChannels
;
class
Message
:
public
ControlMessage
{
public
:
Message
(
MediaTrack
*
aTrack
AudioInputProcessing
*
aInputProcessing
bool
aPassThrough
uint32_t
aRequestedInputChannelCount
)
:
ControlMessage
(
aTrack
)
mInputProcessing
(
aInputProcessing
)
mPassThrough
(
aPassThrough
)
mRequestedInputChannelCount
(
aRequestedInputChannelCount
)
{
}
void
Run
(
)
override
{
{
TRACE
(
"
SetPassThrough
"
)
mInputProcessing
-
>
SetPassThrough
(
mTrack
-
>
GraphImpl
(
)
mPassThrough
)
;
}
{
TRACE
(
"
SetRequestedInputChannelCount
"
)
;
mInputProcessing
-
>
SetRequestedInputChannelCount
(
mTrack
-
>
GraphImpl
(
)
mRequestedInputChannelCount
)
;
}
}
protected
:
RefPtr
<
AudioInputProcessing
>
mInputProcessing
;
bool
mPassThrough
;
uint32_t
mRequestedInputChannelCount
;
}
;
bool
passThrough
=
!
(
prefs
.
mAecOn
|
|
prefs
.
mAgcOn
|
|
prefs
.
mNoiseOn
)
;
if
(
track
-
>
IsDestroyed
(
)
)
{
return
;
}
track
-
>
GraphImpl
(
)
-
>
AppendMessage
(
MakeUnique
<
Message
>
(
track
that
-
>
mInputProcessing
passThrough
prefs
.
mChannels
)
)
;
}
)
)
;
}
nsresult
MediaEngineWebRTCMicrophoneSource
:
:
Allocate
(
const
dom
:
:
MediaTrackConstraints
&
aConstraints
const
MediaEnginePrefs
&
aPrefs
uint64_t
aWindowID
const
char
*
*
aOutBadConstraint
)
{
AssertIsOnOwningThread
(
)
;
mState
=
kAllocated
;
NormalizedConstraints
normalized
(
aConstraints
)
;
MediaEnginePrefs
outputPrefs
;
nsresult
rv
=
EvaluateSettings
(
normalized
aPrefs
&
outputPrefs
aOutBadConstraint
)
;
if
(
NS_FAILED
(
rv
)
)
{
return
rv
;
}
RefPtr
<
MediaEngineWebRTCMicrophoneSource
>
that
=
this
;
NS_DispatchToMainThread
(
NS_NewRunnableFunction
(
__func__
[
that
prefs
=
outputPrefs
]
{
that
-
>
mSettings
-
>
mEchoCancellation
.
Value
(
)
=
prefs
.
mAecOn
;
that
-
>
mSettings
-
>
mAutoGainControl
.
Value
(
)
=
prefs
.
mAgcOn
;
that
-
>
mSettings
-
>
mNoiseSuppression
.
Value
(
)
=
prefs
.
mNoiseOn
;
that
-
>
mSettings
-
>
mChannelCount
.
Value
(
)
=
prefs
.
mChannels
;
}
)
)
;
mCurrentPrefs
=
outputPrefs
;
return
rv
;
}
nsresult
MediaEngineWebRTCMicrophoneSource
:
:
Deallocate
(
)
{
AssertIsOnOwningThread
(
)
;
MOZ_ASSERT
(
mState
=
=
kStopped
|
|
mState
=
=
kAllocated
)
;
class
EndTrackMessage
:
public
ControlMessage
{
public
:
EndTrackMessage
(
AudioInputTrack
*
aTrack
AudioInputProcessing
*
aAudioInputProcessing
)
:
ControlMessage
(
aTrack
)
mInputProcessing
(
aAudioInputProcessing
)
mInputTrack
(
aTrack
)
{
}
void
Run
(
)
override
{
TRACE
(
"
mInputProcessing
:
:
End
"
)
;
mInputProcessing
-
>
End
(
)
;
}
protected
:
const
RefPtr
<
AudioInputProcessing
>
mInputProcessing
;
AudioInputTrack
const
*
mInputTrack
;
}
;
if
(
mTrack
)
{
RefPtr
<
AudioInputProcessing
>
inputProcessing
=
mInputProcessing
;
NS_DispatchToMainThread
(
NS_NewRunnableFunction
(
__func__
[
track
=
std
:
:
move
(
mTrack
)
audioInputProcessing
=
std
:
:
move
(
inputProcessing
)
]
{
if
(
track
-
>
IsDestroyed
(
)
)
{
return
;
}
track
-
>
GraphImpl
(
)
-
>
AppendMessage
(
MakeUnique
<
EndTrackMessage
>
(
track
audioInputProcessing
)
)
;
}
)
)
;
}
mTrack
=
nullptr
;
mPrincipal
=
PRINCIPAL_HANDLE_NONE
;
MOZ_ASSERT
(
mState
!
=
kReleased
"
Source
not
allocated
"
)
;
MOZ_ASSERT
(
mState
!
=
kStarted
"
Source
not
stopped
"
)
;
mState
=
kReleased
;
LOG
(
"
Mic
source
%
p
Audio
device
%
s
deallocated
"
this
NS_ConvertUTF16toUTF8
(
mDeviceName
)
.
get
(
)
)
;
return
NS_OK
;
}
void
MediaEngineWebRTCMicrophoneSource
:
:
SetTrack
(
const
RefPtr
<
MediaTrack
>
&
aTrack
const
PrincipalHandle
&
aPrincipal
)
{
AssertIsOnOwningThread
(
)
;
MOZ_ASSERT
(
aTrack
)
;
MOZ_ASSERT
(
aTrack
-
>
AsAudioInputTrack
(
)
)
;
MOZ_ASSERT
(
!
mTrack
)
;
MOZ_ASSERT
(
mPrincipal
=
=
PRINCIPAL_HANDLE_NONE
)
;
mTrack
=
aTrack
-
>
AsAudioInputTrack
(
)
;
mPrincipal
=
aPrincipal
;
mInputProcessing
=
MakeAndAddRef
<
AudioInputProcessing
>
(
mDeviceMaxChannelCount
mPrincipal
)
;
NS_DispatchToMainThread
(
NS_NewRunnableFunction
(
__func__
[
track
=
mTrack
processing
=
mInputProcessing
]
(
)
mutable
{
track
-
>
SetInputProcessing
(
std
:
:
move
(
processing
)
)
;
track
-
>
Resume
(
)
;
}
)
)
;
LOG
(
"
Mic
source
%
p
Track
%
p
registered
for
microphone
capture
"
this
aTrack
.
get
(
)
)
;
}
class
StartStopMessage
:
public
ControlMessage
{
public
:
enum
StartStop
{
Start
Stop
}
;
StartStopMessage
(
AudioInputProcessing
*
aInputProcessing
StartStop
aAction
)
:
ControlMessage
(
nullptr
)
mInputProcessing
(
aInputProcessing
)
mAction
(
aAction
)
{
}
void
Run
(
)
override
{
if
(
mAction
=
=
StartStopMessage
:
:
Start
)
{
TRACE
(
"
InputProcessing
:
:
Start
"
)
mInputProcessing
-
>
Start
(
)
;
}
else
if
(
mAction
=
=
StartStopMessage
:
:
Stop
)
{
TRACE
(
"
InputProcessing
:
:
Stop
"
)
mInputProcessing
-
>
Stop
(
)
;
}
else
{
MOZ_CRASH
(
"
Invalid
enum
value
"
)
;
}
}
protected
:
RefPtr
<
AudioInputProcessing
>
mInputProcessing
;
StartStop
mAction
;
}
;
nsresult
MediaEngineWebRTCMicrophoneSource
:
:
Start
(
)
{
AssertIsOnOwningThread
(
)
;
if
(
mState
=
=
kStarted
)
{
return
NS_OK
;
}
MOZ_ASSERT
(
mState
=
=
kAllocated
|
|
mState
=
=
kStopped
)
;
CubebUtils
:
:
AudioDeviceID
deviceID
=
mDeviceInfo
-
>
DeviceID
(
)
;
if
(
mTrack
-
>
GraphImpl
(
)
-
>
InputDeviceID
(
)
&
&
mTrack
-
>
GraphImpl
(
)
-
>
InputDeviceID
(
)
!
=
deviceID
)
{
return
NS_ERROR_NOT_AVAILABLE
;
}
RefPtr
<
MediaEngineWebRTCMicrophoneSource
>
that
=
this
;
NS_DispatchToMainThread
(
NS_NewRunnableFunction
(
__func__
[
that
deviceID
track
=
mTrack
]
{
if
(
track
-
>
IsDestroyed
(
)
)
{
return
;
}
track
-
>
GraphImpl
(
)
-
>
AppendMessage
(
MakeUnique
<
StartStopMessage
>
(
that
-
>
mInputProcessing
StartStopMessage
:
:
Start
)
)
;
track
-
>
OpenAudioInput
(
deviceID
that
-
>
mInputProcessing
)
;
}
)
)
;
ApplySettings
(
mCurrentPrefs
)
;
MOZ_ASSERT
(
mState
!
=
kReleased
)
;
mState
=
kStarted
;
return
NS_OK
;
}
nsresult
MediaEngineWebRTCMicrophoneSource
:
:
Stop
(
)
{
AssertIsOnOwningThread
(
)
;
LOG
(
"
Mic
source
%
p
Stop
(
)
"
this
)
;
MOZ_ASSERT
(
mTrack
"
SetTrack
must
have
been
called
before
:
:
Stop
"
)
;
if
(
mState
=
=
kStopped
)
{
return
NS_OK
;
}
RefPtr
<
MediaEngineWebRTCMicrophoneSource
>
that
=
this
;
NS_DispatchToMainThread
(
NS_NewRunnableFunction
(
__func__
[
that
track
=
mTrack
]
{
if
(
track
-
>
IsDestroyed
(
)
)
{
return
;
}
track
-
>
GraphImpl
(
)
-
>
AppendMessage
(
MakeUnique
<
StartStopMessage
>
(
that
-
>
mInputProcessing
StartStopMessage
:
:
Stop
)
)
;
MOZ_ASSERT
(
track
-
>
DeviceId
(
)
.
value
(
)
=
=
that
-
>
mDeviceInfo
-
>
DeviceID
(
)
)
;
track
-
>
CloseAudioInput
(
)
;
}
)
)
;
MOZ_ASSERT
(
mState
=
=
kStarted
"
Should
be
started
when
stopping
"
)
;
mState
=
kStopped
;
return
NS_OK
;
}
void
MediaEngineWebRTCMicrophoneSource
:
:
GetSettings
(
dom
:
:
MediaTrackSettings
&
aOutSettings
)
const
{
MOZ_ASSERT
(
NS_IsMainThread
(
)
)
;
aOutSettings
=
*
mSettings
;
}
AudioInputProcessing
:
:
AudioInputProcessing
(
uint32_t
aMaxChannelCount
const
PrincipalHandle
&
aPrincipalHandle
)
:
mAudioProcessing
(
AudioProcessing
:
:
Create
(
)
)
mRequestedInputChannelCount
(
aMaxChannelCount
)
mSkipProcessing
(
false
)
mInputDownmixBuffer
(
MAX_SAMPLING_FREQ
*
MAX_CHANNELS
/
100
)
mLiveBufferingAppended
(
Nothing
(
)
)
mPrincipal
(
aPrincipalHandle
)
mEnabled
(
false
)
mEnded
(
false
)
{
}
void
AudioInputProcessing
:
:
Disconnect
(
MediaTrackGraphImpl
*
aGraph
)
{
MOZ_ASSERT
(
aGraph
-
>
OnGraphThread
(
)
)
;
}
bool
AudioInputProcessing
:
:
PassThrough
(
MediaTrackGraphImpl
*
aGraph
)
const
{
MOZ_ASSERT
(
aGraph
-
>
OnGraphThread
(
)
)
;
return
mSkipProcessing
;
}
void
AudioInputProcessing
:
:
SetPassThrough
(
MediaTrackGraphImpl
*
aGraph
bool
aPassThrough
)
{
MOZ_ASSERT
(
aGraph
-
>
OnGraphThread
(
)
)
;
if
(
!
mSkipProcessing
&
&
aPassThrough
&
&
mPacketizerInput
)
{
MOZ_ASSERT
(
mPacketizerInput
-
>
PacketsAvailable
(
)
=
=
0
)
;
LOG_FRAME
(
"
AudioInputProcessing
%
p
Appending
%
u
frames
of
null
data
for
data
"
"
discarded
in
the
packetizer
"
this
mPacketizerInput
-
>
FramesAvailable
(
)
)
;
mSegment
.
AppendNullData
(
mPacketizerInput
-
>
FramesAvailable
(
)
)
;
mPacketizerInput
-
>
Clear
(
)
;
}
mSkipProcessing
=
aPassThrough
;
}
uint32_t
AudioInputProcessing
:
:
GetRequestedInputChannelCount
(
)
{
return
mRequestedInputChannelCount
;
}
void
AudioInputProcessing
:
:
SetRequestedInputChannelCount
(
MediaTrackGraphImpl
*
aGraph
uint32_t
aRequestedInputChannelCount
)
{
mRequestedInputChannelCount
=
aRequestedInputChannelCount
;
aGraph
-
>
ReevaluateInputDevice
(
)
;
}
#
define
HANDLE_APM_ERROR
(
fn
)
\
do
{
\
int
rv
=
fn
;
\
if
(
rv
!
=
AudioProcessing
:
:
kNoError
)
{
\
MOZ_ASSERT_UNREACHABLE
(
"
APM
error
in
"
#
fn
)
;
\
return
;
\
}
\
}
while
(
0
)
;
void
AudioInputProcessing
:
:
UpdateAECSettings
(
bool
aEnable
bool
aUseAecMobile
EchoCancellation
:
:
SuppressionLevel
aLevel
EchoControlMobile
:
:
RoutingMode
aRoutingMode
)
{
if
(
aUseAecMobile
)
{
HANDLE_APM_ERROR
(
mAudioProcessing
-
>
echo_control_mobile
(
)
-
>
Enable
(
aEnable
)
)
;
HANDLE_APM_ERROR
(
mAudioProcessing
-
>
echo_control_mobile
(
)
-
>
set_routing_mode
(
aRoutingMode
)
)
;
HANDLE_APM_ERROR
(
mAudioProcessing
-
>
echo_cancellation
(
)
-
>
Enable
(
false
)
)
;
}
else
{
if
(
aLevel
!
=
EchoCancellation
:
:
SuppressionLevel
:
:
kLowSuppression
&
&
aLevel
!
=
EchoCancellation
:
:
SuppressionLevel
:
:
kModerateSuppression
&
&
aLevel
!
=
EchoCancellation
:
:
SuppressionLevel
:
:
kHighSuppression
)
{
LOG_ERROR
(
"
AudioInputProcessing
%
p
Attempt
to
set
invalid
AEC
suppression
"
"
level
%
d
"
this
static_cast
<
int
>
(
aLevel
)
)
;
aLevel
=
EchoCancellation
:
:
SuppressionLevel
:
:
kModerateSuppression
;
}
HANDLE_APM_ERROR
(
mAudioProcessing
-
>
echo_control_mobile
(
)
-
>
Enable
(
false
)
)
;
HANDLE_APM_ERROR
(
mAudioProcessing
-
>
echo_cancellation
(
)
-
>
Enable
(
aEnable
)
)
;
HANDLE_APM_ERROR
(
mAudioProcessing
-
>
echo_cancellation
(
)
-
>
set_suppression_level
(
aLevel
)
)
;
}
}
void
AudioInputProcessing
:
:
UpdateAGCSettings
(
bool
aEnable
GainControl
:
:
Mode
aMode
)
{
if
(
aMode
!
=
GainControl
:
:
Mode
:
:
kAdaptiveAnalog
&
&
aMode
!
=
GainControl
:
:
Mode
:
:
kAdaptiveDigital
&
&
aMode
!
=
GainControl
:
:
Mode
:
:
kFixedDigital
)
{
LOG_ERROR
(
"
AudioInputProcessing
%
p
Attempt
to
set
invalid
AGC
mode
%
d
"
this
static_cast
<
int
>
(
aMode
)
)
;
aMode
=
GainControl
:
:
Mode
:
:
kAdaptiveDigital
;
}
#
if
defined
(
WEBRTC_IOS
)
|
|
defined
(
ATA
)
|
|
defined
(
WEBRTC_ANDROID
)
if
(
aMode
=
=
GainControl
:
:
Mode
:
:
kAdaptiveAnalog
)
{
LOG_ERROR
(
"
AudioInputProcessing
%
p
Invalid
AGC
mode
kAgcAdaptiveAnalog
on
"
"
mobile
"
this
)
;
MOZ_ASSERT_UNREACHABLE
(
"
Bad
pref
set
in
all
.
js
or
in
about
:
config
"
"
for
the
auto
gain
on
mobile
.
"
)
;
aMode
=
GainControl
:
:
Mode
:
:
kFixedDigital
;
}
#
endif
HANDLE_APM_ERROR
(
mAudioProcessing
-
>
gain_control
(
)
-
>
set_mode
(
aMode
)
)
;
HANDLE_APM_ERROR
(
mAudioProcessing
-
>
gain_control
(
)
-
>
Enable
(
aEnable
)
)
;
}
void
AudioInputProcessing
:
:
UpdateHPFSettings
(
bool
aEnable
)
{
HANDLE_APM_ERROR
(
mAudioProcessing
-
>
high_pass_filter
(
)
-
>
Enable
(
aEnable
)
)
;
}
void
AudioInputProcessing
:
:
UpdateNSSettings
(
bool
aEnable
webrtc
:
:
NoiseSuppression
:
:
Level
aLevel
)
{
if
(
aLevel
!
=
NoiseSuppression
:
:
Level
:
:
kLow
&
&
aLevel
!
=
NoiseSuppression
:
:
Level
:
:
kModerate
&
&
aLevel
!
=
NoiseSuppression
:
:
Level
:
:
kHigh
&
&
aLevel
!
=
NoiseSuppression
:
:
Level
:
:
kVeryHigh
)
{
LOG_ERROR
(
"
AudioInputProcessing
%
p
Attempt
to
set
invalid
noise
suppression
"
"
level
%
d
"
this
static_cast
<
int
>
(
aLevel
)
)
;
aLevel
=
NoiseSuppression
:
:
Level
:
:
kModerate
;
}
HANDLE_APM_ERROR
(
mAudioProcessing
-
>
noise_suppression
(
)
-
>
set_level
(
aLevel
)
)
;
HANDLE_APM_ERROR
(
mAudioProcessing
-
>
noise_suppression
(
)
-
>
Enable
(
aEnable
)
)
;
}
#
undef
HANDLE_APM_ERROR
void
AudioInputProcessing
:
:
UpdateAPMExtraOptions
(
bool
aExtendedFilter
bool
aDelayAgnostic
)
{
webrtc
:
:
Config
config
;
config
.
Set
<
webrtc
:
:
ExtendedFilter
>
(
new
webrtc
:
:
ExtendedFilter
(
aExtendedFilter
)
)
;
config
.
Set
<
webrtc
:
:
DelayAgnostic
>
(
new
webrtc
:
:
DelayAgnostic
(
aDelayAgnostic
)
)
;
mAudioProcessing
-
>
SetExtraOptions
(
config
)
;
}
void
AudioInputProcessing
:
:
Start
(
)
{
mEnabled
=
true
;
mLiveBufferingAppended
=
Nothing
(
)
;
}
void
AudioInputProcessing
:
:
Stop
(
)
{
mEnabled
=
false
;
}
void
AudioInputProcessing
:
:
Pull
(
MediaTrackGraphImpl
*
aGraph
GraphTime
aFrom
GraphTime
aTo
GraphTime
aTrackEnd
AudioSegment
*
aSegment
bool
aLastPullThisIteration
bool
*
aEnded
)
{
MOZ_ASSERT
(
aGraph
-
>
OnGraphThread
(
)
)
;
if
(
mEnded
)
{
*
aEnded
=
true
;
return
;
}
TrackTime
delta
=
aTo
-
aTrackEnd
;
MOZ_ASSERT
(
delta
>
=
0
"
We
shouldn
'
t
append
more
than
requested
"
)
;
TrackTime
buffering
=
0
;
buffering
+
=
WEBAUDIO_BLOCK_SIZE
;
MOZ_ASSERT_IF
(
!
PassThrough
(
aGraph
)
&
&
!
mPacketizerInput
mSegment
.
GetDuration
(
)
=
=
0
)
;
if
(
!
PassThrough
(
aGraph
)
&
&
mPacketizerInput
)
{
buffering
+
=
mPacketizerInput
-
>
mPacketSize
;
}
if
(
delta
<
=
0
)
{
return
;
}
if
(
MOZ_LIKELY
(
mLiveBufferingAppended
)
)
{
if
(
MOZ_UNLIKELY
(
buffering
>
*
mLiveBufferingAppended
)
)
{
TrackTime
silence
=
buffering
-
*
mLiveBufferingAppended
;
LOG_FRAME
(
"
AudioInputProcessing
%
p
Inserting
%
"
PRId64
"
frames
of
silence
due
to
buffer
increase
"
this
silence
)
;
mSegment
.
InsertNullDataAtStart
(
silence
)
;
mLiveBufferingAppended
=
Some
(
buffering
)
;
}
else
if
(
MOZ_UNLIKELY
(
buffering
<
*
mLiveBufferingAppended
)
)
{
MOZ_ASSERT
(
PassThrough
(
aGraph
)
"
Must
have
turned
on
passthrough
"
)
;
TrackTime
removal
=
*
mLiveBufferingAppended
-
buffering
;
MOZ_ASSERT
(
mSegment
.
GetDuration
(
)
>
=
removal
)
;
TrackTime
frames
=
std
:
:
min
(
mSegment
.
GetDuration
(
)
removal
)
;
LOG_FRAME
(
"
AudioInputProcessing
%
p
Removing
%
"
PRId64
"
frames
of
silence
due
to
buffer
decrease
"
this
frames
)
;
*
mLiveBufferingAppended
-
=
frames
;
mSegment
.
RemoveLeading
(
frames
)
;
}
}
if
(
mSegment
.
GetDuration
(
)
>
0
)
{
MOZ_ASSERT
(
buffering
=
=
*
mLiveBufferingAppended
)
;
TrackTime
frames
=
std
:
:
min
(
mSegment
.
GetDuration
(
)
delta
)
;
LOG_FRAME
(
"
AudioInputProcessing
%
p
Appending
%
"
PRId64
"
frames
of
real
data
for
%
u
channels
.
"
this
frames
mRequestedInputChannelCount
)
;
aSegment
-
>
AppendSlice
(
mSegment
0
frames
)
;
mSegment
.
RemoveLeading
(
frames
)
;
delta
-
=
frames
;
MOZ_ASSERT_IF
(
aLastPullThisIteration
mSegment
.
GetDuration
(
)
<
=
buffering
)
;
}
if
(
delta
<
=
0
)
{
if
(
mSegment
.
GetDuration
(
)
=
=
0
)
{
mLiveBufferingAppended
=
Some
(
-
delta
)
;
}
return
;
}
LOG_FRAME
(
"
AudioInputProcessing
%
p
Pulling
%
"
PRId64
"
frames
of
silence
for
%
u
channels
.
"
this
delta
mRequestedInputChannelCount
)
;
MOZ_ASSERT_IF
(
mEnabled
!
mLiveBufferingAppended
)
;
mLiveBufferingAppended
=
Nothing
(
)
;
aSegment
-
>
AppendNullData
(
delta
)
;
}
void
AudioInputProcessing
:
:
NotifyOutputData
(
MediaTrackGraphImpl
*
aGraph
AudioDataValue
*
aBuffer
size_t
aFrames
TrackRate
aRate
uint32_t
aChannels
)
{
MOZ_ASSERT
(
aGraph
-
>
OnGraphThread
(
)
)
;
MOZ_ASSERT
(
mEnabled
)
;
if
(
!
mPacketizerOutput
|
|
mPacketizerOutput
-
>
mPacketSize
!
=
aRate
/
100u
|
|
mPacketizerOutput
-
>
mChannels
!
=
aChannels
)
{
mPacketizerOutput
=
MakeUnique
<
AudioPacketizer
<
AudioDataValue
float
>
>
(
aRate
/
100
aChannels
)
;
}
mPacketizerOutput
-
>
Input
(
aBuffer
aFrames
)
;
while
(
mPacketizerOutput
-
>
PacketsAvailable
(
)
)
{
uint32_t
samplesPerPacket
=
mPacketizerOutput
-
>
mPacketSize
*
mPacketizerOutput
-
>
mChannels
;
if
(
mOutputBuffer
.
Length
(
)
<
samplesPerPacket
)
{
mOutputBuffer
.
SetLength
(
samplesPerPacket
)
;
}
if
(
mDeinterleavedBuffer
.
Length
(
)
<
samplesPerPacket
)
{
mDeinterleavedBuffer
.
SetLength
(
samplesPerPacket
)
;
}
float
*
packet
=
mOutputBuffer
.
Data
(
)
;
mPacketizerOutput
-
>
Output
(
packet
)
;
AutoTArray
<
float
*
MAX_CHANNELS
>
deinterleavedPacketDataChannelPointers
;
float
*
interleavedFarend
=
nullptr
;
uint32_t
channelCountFarend
=
0
;
uint32_t
framesPerPacketFarend
=
0
;
if
(
aChannels
>
MAX_CHANNELS
)
{
AudioConverter
converter
(
AudioConfig
(
aChannels
0
AudioConfig
:
:
FORMAT_FLT
)
AudioConfig
(
MAX_CHANNELS
0
AudioConfig
:
:
FORMAT_FLT
)
)
;
framesPerPacketFarend
=
mPacketizerOutput
-
>
mPacketSize
;
framesPerPacketFarend
=
converter
.
Process
(
mInputDownmixBuffer
packet
framesPerPacketFarend
)
;
interleavedFarend
=
mInputDownmixBuffer
.
Data
(
)
;
channelCountFarend
=
MAX_CHANNELS
;
deinterleavedPacketDataChannelPointers
.
SetLength
(
MAX_CHANNELS
)
;
}
else
{
interleavedFarend
=
packet
;
channelCountFarend
=
aChannels
;
framesPerPacketFarend
=
mPacketizerOutput
-
>
mPacketSize
;
deinterleavedPacketDataChannelPointers
.
SetLength
(
aChannels
)
;
}
MOZ_ASSERT
(
interleavedFarend
&
&
(
channelCountFarend
=
=
1
|
|
channelCountFarend
=
=
2
)
&
&
framesPerPacketFarend
)
;
if
(
mInputBuffer
.
Length
(
)
<
framesPerPacketFarend
*
channelCountFarend
)
{
mInputBuffer
.
SetLength
(
framesPerPacketFarend
*
channelCountFarend
)
;
}
size_t
offset
=
0
;
for
(
size_t
i
=
0
;
i
<
deinterleavedPacketDataChannelPointers
.
Length
(
)
;
+
+
i
)
{
deinterleavedPacketDataChannelPointers
[
i
]
=
mInputBuffer
.
Data
(
)
+
offset
;
offset
+
=
framesPerPacketFarend
;
}
DeinterleaveAndConvertBuffer
(
interleavedFarend
framesPerPacketFarend
channelCountFarend
deinterleavedPacketDataChannelPointers
.
Elements
(
)
)
;
StreamConfig
inputConfig
(
aRate
channelCountFarend
false
)
;
StreamConfig
outputConfig
=
inputConfig
;
DebugOnly
<
int
>
err
=
mAudioProcessing
-
>
ProcessReverseStream
(
deinterleavedPacketDataChannelPointers
.
Elements
(
)
inputConfig
outputConfig
deinterleavedPacketDataChannelPointers
.
Elements
(
)
)
;
MOZ_ASSERT
(
!
err
"
Could
not
process
the
reverse
stream
.
"
)
;
}
}
void
AudioInputProcessing
:
:
PacketizeAndProcess
(
MediaTrackGraphImpl
*
aGraph
const
AudioDataValue
*
aBuffer
size_t
aFrames
TrackRate
aRate
uint32_t
aChannels
)
{
MOZ_ASSERT
(
!
PassThrough
(
aGraph
)
"
This
should
be
bypassed
when
in
PassThrough
mode
.
"
)
;
MOZ_ASSERT
(
mEnabled
)
;
size_t
offset
=
0
;
if
(
!
mPacketizerInput
|
|
mPacketizerInput
-
>
mPacketSize
!
=
aRate
/
100u
|
|
mPacketizerInput
-
>
mChannels
!
=
aChannels
)
{
mPacketizerInput
=
MakeUnique
<
AudioPacketizer
<
AudioDataValue
float
>
>
(
aRate
/
100
aChannels
)
;
}
LOG_FRAME
(
"
AudioInputProcessing
%
p
Appending
%
zu
frames
to
packetizer
"
this
aFrames
)
;
mPacketizerInput
-
>
Input
(
aBuffer
static_cast
<
uint32_t
>
(
aFrames
)
)
;
while
(
mPacketizerInput
-
>
PacketsAvailable
(
)
)
{
uint32_t
samplesPerPacket
=
mPacketizerInput
-
>
mPacketSize
*
mPacketizerInput
-
>
mChannels
;
if
(
mInputBuffer
.
Length
(
)
<
samplesPerPacket
)
{
mInputBuffer
.
SetLength
(
samplesPerPacket
)
;
}
if
(
mDeinterleavedBuffer
.
Length
(
)
<
samplesPerPacket
)
{
mDeinterleavedBuffer
.
SetLength
(
samplesPerPacket
)
;
}
float
*
packet
=
mInputBuffer
.
Data
(
)
;
mPacketizerInput
-
>
Output
(
packet
)
;
AutoTArray
<
float
*
8
>
deinterleavedPacketizedInputDataChannelPointers
;
uint32_t
channelCountInput
=
0
;
if
(
aChannels
>
MAX_CHANNELS
)
{
channelCountInput
=
MONO
;
deinterleavedPacketizedInputDataChannelPointers
.
SetLength
(
channelCountInput
)
;
deinterleavedPacketizedInputDataChannelPointers
[
0
]
=
mDeinterleavedBuffer
.
Data
(
)
;
size_t
readIndex
=
0
;
for
(
size_t
i
=
0
;
i
<
mPacketizerInput
-
>
mPacketSize
;
i
+
+
)
{
mDeinterleavedBuffer
.
Data
(
)
[
i
]
=
0
.
;
for
(
size_t
j
=
0
;
j
<
aChannels
;
j
+
+
)
{
mDeinterleavedBuffer
.
Data
(
)
[
i
]
+
=
packet
[
readIndex
+
+
]
;
}
}
}
else
{
channelCountInput
=
aChannels
;
deinterleavedPacketizedInputDataChannelPointers
.
SetLength
(
channelCountInput
)
;
offset
=
0
;
for
(
size_t
i
=
0
;
i
<
deinterleavedPacketizedInputDataChannelPointers
.
Length
(
)
;
+
+
i
)
{
deinterleavedPacketizedInputDataChannelPointers
[
i
]
=
mDeinterleavedBuffer
.
Data
(
)
+
offset
;
offset
+
=
mPacketizerInput
-
>
mPacketSize
;
}
Deinterleave
(
packet
mPacketizerInput
-
>
mPacketSize
channelCountInput
deinterleavedPacketizedInputDataChannelPointers
.
Elements
(
)
)
;
}
StreamConfig
inputConfig
(
aRate
channelCountInput
false
)
;
StreamConfig
outputConfig
=
inputConfig
;
mAudioProcessing
-
>
set_stream_delay_ms
(
0
)
;
CheckedInt
<
size_t
>
bufferSize
(
sizeof
(
float
)
)
;
bufferSize
*
=
mPacketizerInput
-
>
mPacketSize
;
bufferSize
*
=
channelCountInput
;
RefPtr
<
SharedBuffer
>
buffer
=
SharedBuffer
:
:
Create
(
bufferSize
)
;
AutoTArray
<
float
*
8
>
processedOutputChannelPointers
;
AutoTArray
<
const
float
*
8
>
processedOutputChannelPointersConst
;
processedOutputChannelPointers
.
SetLength
(
channelCountInput
)
;
processedOutputChannelPointersConst
.
SetLength
(
channelCountInput
)
;
offset
=
0
;
for
(
size_t
i
=
0
;
i
<
processedOutputChannelPointers
.
Length
(
)
;
+
+
i
)
{
processedOutputChannelPointers
[
i
]
=
static_cast
<
float
*
>
(
buffer
-
>
Data
(
)
)
+
offset
;
processedOutputChannelPointersConst
[
i
]
=
static_cast
<
float
*
>
(
buffer
-
>
Data
(
)
)
+
offset
;
offset
+
=
mPacketizerInput
-
>
mPacketSize
;
}
mAudioProcessing
-
>
ProcessStream
(
deinterleavedPacketizedInputDataChannelPointers
.
Elements
(
)
inputConfig
outputConfig
processedOutputChannelPointers
.
Elements
(
)
)
;
if
(
mEnded
)
{
continue
;
}
LOG_FRAME
(
"
AudioInputProcessing
%
p
Appending
%
u
frames
of
packetized
audio
"
this
mPacketizerInput
-
>
mPacketSize
)
;
MOZ_ASSERT
(
processedOutputChannelPointers
.
Length
(
)
=
=
channelCountInput
)
;
RefPtr
<
SharedBuffer
>
other
=
buffer
;
mSegment
.
AppendFrames
(
other
.
forget
(
)
processedOutputChannelPointersConst
mPacketizerInput
-
>
mPacketSize
mPrincipal
)
;
}
}
void
AudioInputProcessing
:
:
ProcessInput
(
MediaTrackGraphImpl
*
aGraph
const
AudioSegment
*
aSegment
)
{
MOZ_ASSERT
(
aGraph
)
;
MOZ_ASSERT
(
aGraph
-
>
OnGraphThread
(
)
)
;
if
(
mEnded
|
|
!
mEnabled
|
|
!
mLiveBufferingAppended
|
|
mPendingData
.
IsEmpty
(
)
)
{
return
;
}
if
(
PassThrough
(
aGraph
)
)
{
if
(
aSegment
&
&
!
aSegment
-
>
IsEmpty
(
)
)
{
mSegment
.
AppendSegment
(
aSegment
mPrincipal
)
;
}
else
{
mSegment
.
AppendFromInterleavedBuffer
(
mPendingData
.
Data
(
)
mPendingData
.
FrameCount
(
)
mPendingData
.
Channels
(
)
mPrincipal
)
;
}
}
else
{
MOZ_ASSERT
(
aGraph
-
>
GraphRate
(
)
=
=
mPendingData
.
Rate
(
)
)
;
PacketizeAndProcess
(
aGraph
mPendingData
.
Data
(
)
mPendingData
.
FrameCount
(
)
mPendingData
.
Rate
(
)
mPendingData
.
Channels
(
)
)
;
}
mPendingData
.
Clear
(
)
;
}
void
AudioInputProcessing
:
:
NotifyInputStopped
(
MediaTrackGraphImpl
*
aGraph
)
{
MOZ_ASSERT
(
aGraph
-
>
OnGraphThread
(
)
)
;
mLiveBufferingAppended
=
Nothing
(
)
;
mSegment
.
Clear
(
)
;
if
(
mPacketizerInput
)
{
mPacketizerInput
-
>
Clear
(
)
;
}
mPendingData
.
Clear
(
)
;
}
void
AudioInputProcessing
:
:
NotifyInputData
(
MediaTrackGraphImpl
*
aGraph
const
AudioDataValue
*
aBuffer
size_t
aFrames
TrackRate
aRate
uint32_t
aChannels
uint32_t
aAlreadyBuffered
)
{
MOZ_ASSERT
(
aGraph
-
>
OnGraphThread
(
)
)
;
TRACE
(
"
AudioInputProcessing
:
:
NotifyInputData
"
)
;
MOZ_ASSERT
(
mEnabled
)
;
if
(
!
mLiveBufferingAppended
)
{
mLiveBufferingAppended
=
Some
(
aAlreadyBuffered
)
;
}
mPendingData
.
Push
(
aBuffer
aFrames
aRate
aChannels
)
;
}
#
define
ResetProcessingIfNeeded
(
_processing
)
\
do
{
\
bool
enabled
=
mAudioProcessing
-
>
_processing
(
)
-
>
is_enabled
(
)
;
\
\
if
(
enabled
)
{
\
int
rv
=
mAudioProcessing
-
>
_processing
(
)
-
>
Enable
(
!
enabled
)
;
\
if
(
rv
)
{
\
NS_WARNING
(
"
Could
not
reset
the
status
of
the
"
#
_processing
\
"
on
device
change
.
"
)
;
\
return
;
\
}
\
rv
=
mAudioProcessing
-
>
_processing
(
)
-
>
Enable
(
enabled
)
;
\
if
(
rv
)
{
\
NS_WARNING
(
"
Could
not
reset
the
status
of
the
"
#
_processing
\
"
on
device
change
.
"
)
;
\
return
;
\
}
\
}
\
}
while
(
0
)
void
AudioInputProcessing
:
:
DeviceChanged
(
MediaTrackGraphImpl
*
aGraph
)
{
MOZ_ASSERT
(
aGraph
-
>
OnGraphThread
(
)
)
;
ResetProcessingIfNeeded
(
gain_control
)
;
ResetProcessingIfNeeded
(
echo_cancellation
)
;
ResetProcessingIfNeeded
(
noise_suppression
)
;
}
void
AudioInputProcessing
:
:
End
(
)
{
mEnded
=
true
;
mSegment
.
Clear
(
)
;
mPendingData
.
Clear
(
)
;
}
TrackTime
AudioInputProcessing
:
:
NumBufferedFrames
(
MediaTrackGraphImpl
*
aGraph
)
const
{
MOZ_ASSERT
(
aGraph
-
>
OnGraphThread
(
)
)
;
return
mSegment
.
GetDuration
(
)
;
}
void
AudioInputTrack
:
:
Destroy
(
)
{
MOZ_ASSERT
(
NS_IsMainThread
(
)
)
;
CloseAudioInput
(
)
;
MediaTrack
:
:
Destroy
(
)
;
}
void
AudioInputTrack
:
:
SetInputProcessing
(
RefPtr
<
AudioInputProcessing
>
aInputProcessing
)
{
class
Message
:
public
ControlMessage
{
RefPtr
<
AudioInputTrack
>
mTrack
;
RefPtr
<
AudioInputProcessing
>
mProcessing
;
public
:
Message
(
RefPtr
<
AudioInputTrack
>
aTrack
RefPtr
<
AudioInputProcessing
>
aProcessing
)
:
ControlMessage
(
aTrack
)
mTrack
(
std
:
:
move
(
aTrack
)
)
mProcessing
(
std
:
:
move
(
aProcessing
)
)
{
}
void
Run
(
)
override
{
TRACE
(
"
AudioInputTrack
:
:
SetInputProcessingImpl
"
)
;
mTrack
-
>
SetInputProcessingImpl
(
std
:
:
move
(
mProcessing
)
)
;
}
}
;
if
(
IsDestroyed
(
)
)
{
return
;
}
GraphImpl
(
)
-
>
AppendMessage
(
MakeUnique
<
Message
>
(
std
:
:
move
(
this
)
std
:
:
move
(
aInputProcessing
)
)
)
;
}
AudioInputTrack
*
AudioInputTrack
:
:
Create
(
MediaTrackGraph
*
aGraph
)
{
MOZ_ASSERT
(
NS_IsMainThread
(
)
)
;
AudioInputTrack
*
track
=
new
AudioInputTrack
(
aGraph
-
>
GraphRate
(
)
)
;
aGraph
-
>
AddTrack
(
track
)
;
return
track
;
}
void
AudioInputTrack
:
:
DestroyImpl
(
)
{
ProcessedMediaTrack
:
:
DestroyImpl
(
)
;
if
(
mInputProcessing
)
{
mInputProcessing
-
>
End
(
)
;
}
}
void
AudioInputTrack
:
:
ProcessInput
(
GraphTime
aFrom
GraphTime
aTo
uint32_t
aFlags
)
{
TRACE_COMMENT
(
"
AudioInputTrack
:
:
ProcessInput
"
"
AudioInputTrack
%
p
"
this
)
;
NativeInputTrack
*
source
=
nullptr
;
if
(
!
mInputs
.
IsEmpty
(
)
)
{
for
(
const
MediaInputPort
*
input
:
mInputs
)
{
MOZ_ASSERT
(
input
-
>
GetSource
(
)
)
;
if
(
input
-
>
GetSource
(
)
-
>
AsNativeInputTrack
(
)
)
{
source
=
input
-
>
GetSource
(
)
-
>
AsNativeInputTrack
(
)
;
break
;
}
}
}
if
(
source
)
{
MOZ_ASSERT
(
source
-
>
GraphImpl
(
)
=
=
GraphImpl
(
)
)
;
MOZ_ASSERT
(
source
-
>
mSampleRate
=
=
mSampleRate
)
;
MOZ_ASSERT
(
GraphImpl
(
)
-
>
GraphRate
(
)
=
=
mSampleRate
)
;
mInputProcessing
-
>
ProcessInput
(
GraphImpl
(
)
source
-
>
GetData
<
AudioSegment
>
(
)
)
;
}
bool
ended
=
false
;
mInputProcessing
-
>
Pull
(
GraphImpl
(
)
aFrom
aTo
TrackTimeToGraphTime
(
GetEnd
(
)
)
GetData
<
AudioSegment
>
(
)
aTo
=
=
GraphImpl
(
)
-
>
mStateComputedTime
&
ended
)
;
ApplyTrackDisabling
(
mSegment
.
get
(
)
)
;
if
(
ended
&
&
(
aFlags
&
ALLOW_END
)
)
{
mEnded
=
true
;
}
}
void
AudioInputTrack
:
:
SetInputProcessingImpl
(
RefPtr
<
AudioInputProcessing
>
aInputProcessing
)
{
MOZ_ASSERT
(
GraphImpl
(
)
-
>
OnGraphThread
(
)
)
;
mInputProcessing
=
std
:
:
move
(
aInputProcessing
)
;
}
nsresult
AudioInputTrack
:
:
OpenAudioInput
(
CubebUtils
:
:
AudioDeviceID
aId
AudioDataListener
*
aListener
)
{
MOZ_ASSERT
(
NS_IsMainThread
(
)
)
;
MOZ_ASSERT
(
GraphImpl
(
)
)
;
MOZ_ASSERT
(
!
mInputListener
)
;
MOZ_ASSERT
(
mDeviceId
.
isNothing
(
)
)
;
mInputListener
=
aListener
;
ProcessedMediaTrack
*
input
=
GraphImpl
(
)
-
>
GetDeviceTrack
(
aId
)
;
MOZ_ASSERT
(
input
)
;
LOG
(
"
Open
device
%
p
(
InputTrack
=
%
p
)
for
Mic
source
%
p
"
aId
input
this
)
;
mPort
=
AllocateInputPort
(
input
)
;
mDeviceId
.
emplace
(
aId
)
;
return
GraphImpl
(
)
-
>
OpenAudioInput
(
aId
aListener
)
;
}
void
AudioInputTrack
:
:
CloseAudioInput
(
)
{
MOZ_ASSERT
(
NS_IsMainThread
(
)
)
;
MOZ_ASSERT
(
GraphImpl
(
)
)
;
if
(
!
mInputListener
)
{
return
;
}
MOZ_ASSERT
(
mPort
)
;
MOZ_ASSERT
(
mDeviceId
.
isSome
(
)
)
;
LOG
(
"
Close
device
%
p
(
InputTrack
=
%
p
)
for
Mic
source
%
p
"
mDeviceId
.
value
(
)
mPort
-
>
GetSource
(
)
this
)
;
mPort
-
>
Destroy
(
)
;
GraphImpl
(
)
-
>
CloseAudioInput
(
mDeviceId
.
extract
(
)
mInputListener
)
;
mInputListener
=
nullptr
;
}
Maybe
<
CubebUtils
:
:
AudioDeviceID
>
AudioInputTrack
:
:
DeviceId
(
)
const
{
MOZ_ASSERT
(
NS_IsMainThread
(
)
)
;
return
mDeviceId
;
}
nsString
MediaEngineWebRTCAudioCaptureSource
:
:
GetName
(
)
const
{
return
u
"
AudioCapture
"
_ns
;
}
nsCString
MediaEngineWebRTCAudioCaptureSource
:
:
GetUUID
(
)
const
{
nsID
uuid
;
ErrorResult
rv
;
rv
=
nsContentUtils
:
:
GenerateUUIDInPlace
(
uuid
)
;
if
(
rv
.
Failed
(
)
)
{
return
"
"
_ns
;
}
return
NSID_TrimBracketsASCII
(
uuid
)
;
}
nsString
MediaEngineWebRTCAudioCaptureSource
:
:
GetGroupId
(
)
const
{
return
u
"
AudioCaptureGroup
"
_ns
;
}
void
MediaEngineWebRTCAudioCaptureSource
:
:
SetTrack
(
const
RefPtr
<
MediaTrack
>
&
aTrack
const
PrincipalHandle
&
aPrincipalHandle
)
{
AssertIsOnOwningThread
(
)
;
}
nsresult
MediaEngineWebRTCAudioCaptureSource
:
:
Start
(
)
{
AssertIsOnOwningThread
(
)
;
return
NS_OK
;
}
nsresult
MediaEngineWebRTCAudioCaptureSource
:
:
Stop
(
)
{
AssertIsOnOwningThread
(
)
;
return
NS_OK
;
}
nsresult
MediaEngineWebRTCAudioCaptureSource
:
:
Reconfigure
(
const
dom
:
:
MediaTrackConstraints
&
aConstraints
const
MediaEnginePrefs
&
aPrefs
const
char
*
*
aOutBadConstraint
)
{
return
NS_OK
;
}
void
MediaEngineWebRTCAudioCaptureSource
:
:
GetSettings
(
dom
:
:
MediaTrackSettings
&
aOutSettings
)
const
{
aOutSettings
.
mAutoGainControl
.
Construct
(
false
)
;
aOutSettings
.
mEchoCancellation
.
Construct
(
false
)
;
aOutSettings
.
mNoiseSuppression
.
Construct
(
false
)
;
aOutSettings
.
mChannelCount
.
Construct
(
1
)
;
}
}
