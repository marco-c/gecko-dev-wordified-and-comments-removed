#
include
"
MediaEngineWebRTC
.
h
"
#
include
<
stdio
.
h
>
#
include
<
algorithm
>
#
include
"
mozilla
/
Assertions
.
h
"
#
include
"
MediaTrackConstraints
.
h
"
#
include
"
mtransport
/
runnable_utils
.
h
"
#
include
"
nsAutoPtr
.
h
"
#
include
"
AudioConverter
.
h
"
#
ifdef
FF
#
undef
FF
#
endif
#
include
"
webrtc
/
modules
/
audio_device
/
opensl
/
single_rw_fifo
.
h
"
#
include
"
webrtc
/
voice_engine
/
voice_engine_defines
.
h
"
#
include
"
webrtc
/
modules
/
audio_processing
/
include
/
audio_processing
.
h
"
#
include
"
webrtc
/
common_audio
/
include
/
audio_util
.
h
"
using
namespace
webrtc
;
#
define
MAX_CHANNELS
2
#
define
MAX_SAMPLING_FREQ
48000
/
/
Hz
-
multiple
of
100
#
define
MAX_AEC_FIFO_DEPTH
200
/
/
ms
-
multiple
of
10
static_assert
(
!
(
MAX_AEC_FIFO_DEPTH
%
10
)
"
Invalid
MAX_AEC_FIFO_DEPTH
"
)
;
namespace
mozilla
{
#
ifdef
LOG
#
undef
LOG
#
endif
extern
LogModule
*
GetMediaManagerLog
(
)
;
#
define
LOG
(
msg
)
MOZ_LOG
(
GetMediaManagerLog
(
)
mozilla
:
:
LogLevel
:
:
Debug
msg
)
#
define
LOG_FRAMES
(
msg
)
MOZ_LOG
(
GetMediaManagerLog
(
)
mozilla
:
:
LogLevel
:
:
Verbose
msg
)
LogModule
*
AudioLogModule
(
)
{
static
mozilla
:
:
LazyLogModule
log
(
"
AudioLatency
"
)
;
return
static_cast
<
LogModule
*
>
(
log
)
;
}
NS_IMPL_ISUPPORTS0
(
MediaEngineWebRTCMicrophoneSource
)
NS_IMPL_ISUPPORTS0
(
MediaEngineWebRTCAudioCaptureSource
)
int
MediaEngineWebRTCMicrophoneSource
:
:
sChannelsOpen
=
0
;
AudioOutputObserver
:
:
AudioOutputObserver
(
)
:
mPlayoutFreq
(
0
)
mPlayoutChannels
(
0
)
mChunkSize
(
0
)
mSaved
(
nullptr
)
mSamplesSaved
(
0
)
mDownmixBuffer
(
MAX_SAMPLING_FREQ
*
MAX_CHANNELS
/
100
)
{
mPlayoutFifo
=
new
SingleRwFifo
(
MAX_AEC_FIFO_DEPTH
/
10
)
;
}
AudioOutputObserver
:
:
~
AudioOutputObserver
(
)
{
Clear
(
)
;
free
(
mSaved
)
;
mSaved
=
nullptr
;
}
void
AudioOutputObserver
:
:
Clear
(
)
{
while
(
mPlayoutFifo
-
>
size
(
)
>
0
)
{
free
(
mPlayoutFifo
-
>
Pop
(
)
)
;
}
}
FarEndAudioChunk
*
AudioOutputObserver
:
:
Pop
(
)
{
return
(
FarEndAudioChunk
*
)
mPlayoutFifo
-
>
Pop
(
)
;
}
uint32_t
AudioOutputObserver
:
:
Size
(
)
{
return
mPlayoutFifo
-
>
size
(
)
;
}
void
AudioOutputObserver
:
:
InsertFarEnd
(
const
AudioDataValue
*
aBuffer
uint32_t
aFrames
bool
aOverran
int
aFreq
int
aChannels
)
{
int
channels
=
aChannels
;
if
(
aChannels
>
MAX_CHANNELS
)
{
channels
=
MAX_CHANNELS
;
}
if
(
mPlayoutChannels
!
=
0
)
{
if
(
mPlayoutChannels
!
=
static_cast
<
uint32_t
>
(
channels
)
)
{
MOZ_CRASH
(
)
;
}
}
else
{
MOZ_ASSERT
(
channels
<
=
MAX_CHANNELS
)
;
mPlayoutChannels
=
static_cast
<
uint32_t
>
(
channels
)
;
}
if
(
mPlayoutFreq
!
=
0
)
{
if
(
mPlayoutFreq
!
=
static_cast
<
uint32_t
>
(
aFreq
)
)
{
MOZ_CRASH
(
)
;
}
}
else
{
MOZ_ASSERT
(
aFreq
<
=
MAX_SAMPLING_FREQ
)
;
MOZ_ASSERT
(
!
(
aFreq
%
100
)
"
Sampling
rate
for
far
end
data
should
be
multiple
of
100
.
"
)
;
mPlayoutFreq
=
aFreq
;
mChunkSize
=
aFreq
/
100
;
}
#
ifdef
LOG_FAREND_INSERTION
static
FILE
*
fp
=
fopen
(
"
insertfarend
.
pcm
"
"
wb
"
)
;
#
endif
if
(
mSaved
)
{
mSaved
-
>
mOverrun
=
aOverran
;
aOverran
=
false
;
}
while
(
aFrames
)
{
if
(
!
mSaved
)
{
mSaved
=
(
FarEndAudioChunk
*
)
moz_xmalloc
(
sizeof
(
FarEndAudioChunk
)
+
(
mChunkSize
*
channels
-
1
)
*
sizeof
(
AudioDataValue
)
)
;
mSaved
-
>
mSamples
=
mChunkSize
;
mSaved
-
>
mOverrun
=
aOverran
;
aOverran
=
false
;
}
uint32_t
to_copy
=
mChunkSize
-
mSamplesSaved
;
if
(
to_copy
>
aFrames
)
{
to_copy
=
aFrames
;
}
AudioDataValue
*
dest
=
&
(
mSaved
-
>
mData
[
mSamplesSaved
*
channels
]
)
;
if
(
aChannels
>
MAX_CHANNELS
)
{
AudioConverter
converter
(
AudioConfig
(
aChannels
0
)
AudioConfig
(
channels
0
)
)
;
converter
.
Process
(
mDownmixBuffer
aBuffer
to_copy
)
;
ConvertAudioSamples
(
mDownmixBuffer
.
Data
(
)
dest
to_copy
*
channels
)
;
}
else
{
ConvertAudioSamples
(
aBuffer
dest
to_copy
*
channels
)
;
}
#
ifdef
LOG_FAREND_INSERTION
if
(
fp
)
{
fwrite
(
&
(
mSaved
-
>
mData
[
mSamplesSaved
*
aChannels
]
)
to_copy
*
aChannels
sizeof
(
AudioDataValue
)
fp
)
;
}
#
endif
aFrames
-
=
to_copy
;
mSamplesSaved
+
=
to_copy
;
aBuffer
+
=
to_copy
*
aChannels
;
if
(
mSamplesSaved
>
=
mChunkSize
)
{
int
free_slots
=
mPlayoutFifo
-
>
capacity
(
)
-
mPlayoutFifo
-
>
size
(
)
;
if
(
free_slots
<
=
0
)
{
break
;
}
else
{
mPlayoutFifo
-
>
Push
(
(
int8_t
*
)
mSaved
)
;
mSaved
=
nullptr
;
mSamplesSaved
=
0
;
}
}
}
}
MediaEngineWebRTCMicrophoneSource
:
:
MediaEngineWebRTCMicrophoneSource
(
mozilla
:
:
AudioInput
*
aAudioInput
int
aIndex
const
char
*
name
const
char
*
uuid
bool
aDelayAgnostic
bool
aExtendedFilter
)
:
MediaEngineAudioSource
(
kReleased
)
mAudioInput
(
aAudioInput
)
mAudioProcessing
(
AudioProcessing
:
:
Create
(
)
)
mMonitor
(
"
WebRTCMic
.
Monitor
"
)
mCapIndex
(
aIndex
)
mDelayAgnostic
(
aDelayAgnostic
)
mExtendedFilter
(
aExtendedFilter
)
mTrackID
(
TRACK_NONE
)
mStarted
(
false
)
mSampleFrequency
(
MediaEngine
:
:
USE_GRAPH_RATE
)
mTotalFrames
(
0
)
mLastLogFrames
(
0
)
mSkipProcessing
(
false
)
mInputDownmixBuffer
(
MAX_SAMPLING_FREQ
*
MAX_CHANNELS
/
100
)
{
MOZ_ASSERT
(
aAudioInput
)
;
mDeviceName
.
Assign
(
NS_ConvertUTF8toUTF16
(
name
)
)
;
mDeviceUUID
.
Assign
(
uuid
)
;
mListener
=
new
mozilla
:
:
WebRTCAudioDataListener
(
this
)
;
mSettings
-
>
mEchoCancellation
.
Construct
(
0
)
;
mSettings
-
>
mAutoGainControl
.
Construct
(
0
)
;
mSettings
-
>
mNoiseSuppression
.
Construct
(
0
)
;
mSettings
-
>
mChannelCount
.
Construct
(
0
)
;
}
void
MediaEngineWebRTCMicrophoneSource
:
:
GetName
(
nsAString
&
aName
)
const
{
aName
.
Assign
(
mDeviceName
)
;
}
void
MediaEngineWebRTCMicrophoneSource
:
:
GetUUID
(
nsACString
&
aUUID
)
const
{
aUUID
.
Assign
(
mDeviceUUID
)
;
}
uint32_t
MediaEngineWebRTCMicrophoneSource
:
:
GetBestFitnessDistance
(
const
nsTArray
<
const
NormalizedConstraintSet
*
>
&
aConstraintSets
const
nsString
&
aDeviceId
)
const
{
uint32_t
distance
=
0
;
for
(
const
auto
*
cs
:
aConstraintSets
)
{
distance
=
GetMinimumFitnessDistance
(
*
cs
aDeviceId
)
;
break
;
}
return
distance
;
}
nsresult
MediaEngineWebRTCMicrophoneSource
:
:
Restart
(
AllocationHandle
*
aHandle
const
dom
:
:
MediaTrackConstraints
&
aConstraints
const
MediaEnginePrefs
&
aPrefs
const
nsString
&
aDeviceId
const
char
*
*
aOutBadConstraint
)
{
AssertIsOnOwningThread
(
)
;
MOZ_ASSERT
(
aHandle
)
;
NormalizedConstraints
constraints
(
aConstraints
)
;
return
ReevaluateAllocation
(
aHandle
&
constraints
aPrefs
aDeviceId
aOutBadConstraint
)
;
}
bool
operator
=
=
(
const
MediaEnginePrefs
&
a
const
MediaEnginePrefs
&
b
)
{
return
!
memcmp
(
&
a
&
b
sizeof
(
MediaEnginePrefs
)
)
;
}
;
#
define
HANDLE_APM_ERROR
(
fn
)
\
do
{
\
int
rv
=
fn
;
\
if
(
rv
!
=
AudioProcessing
:
:
kNoError
)
{
\
MOZ_ASSERT_UNREACHABLE
(
"
APM
error
in
"
#
fn
)
;
\
return
;
\
}
\
}
while
(
0
)
;
void
MediaEngineWebRTCMicrophoneSource
:
:
UpdateAECSettingsIfNeeded
(
bool
aEnable
EcModes
aMode
)
{
using
webrtc
:
:
EcModes
;
EchoCancellation
:
:
SuppressionLevel
level
;
switch
(
aMode
)
{
case
EcModes
:
:
kEcUnchanged
:
level
=
mAudioProcessing
-
>
echo_cancellation
(
)
-
>
suppression_level
(
)
;
break
;
case
EcModes
:
:
kEcConference
:
level
=
EchoCancellation
:
:
kHighSuppression
;
break
;
case
EcModes
:
:
kEcDefault
:
level
=
EchoCancellation
:
:
kModerateSuppression
;
break
;
case
EcModes
:
:
kEcAec
:
level
=
EchoCancellation
:
:
kModerateSuppression
;
break
;
case
EcModes
:
:
kEcAecm
:
break
;
default
:
MOZ_LOG
(
GetMediaManagerLog
(
)
LogLevel
:
:
Error
(
"
Bad
EcMode
value
"
)
)
;
MOZ_ASSERT_UNREACHABLE
(
"
Bad
pref
set
in
all
.
js
or
in
about
:
config
"
"
for
the
echo
cancelation
mode
.
"
)
;
level
=
EchoCancellation
:
:
kModerateSuppression
;
break
;
}
if
(
aMode
=
=
EcModes
:
:
kEcAecm
)
{
HANDLE_APM_ERROR
(
mAudioProcessing
-
>
echo_cancellation
(
)
-
>
Enable
(
false
)
)
;
HANDLE_APM_ERROR
(
mAudioProcessing
-
>
echo_control_mobile
(
)
-
>
Enable
(
aEnable
)
)
;
}
else
{
HANDLE_APM_ERROR
(
mAudioProcessing
-
>
echo_control_mobile
(
)
-
>
Enable
(
false
)
)
;
HANDLE_APM_ERROR
(
mAudioProcessing
-
>
echo_cancellation
(
)
-
>
Enable
(
aEnable
)
)
;
HANDLE_APM_ERROR
(
mAudioProcessing
-
>
echo_cancellation
(
)
-
>
set_suppression_level
(
level
)
)
;
}
}
void
MediaEngineWebRTCMicrophoneSource
:
:
UpdateAGCSettingsIfNeeded
(
bool
aEnable
AgcModes
aMode
)
{
#
if
defined
(
WEBRTC_IOS
)
|
|
defined
(
ATA
)
|
|
defined
(
WEBRTC_ANDROID
)
if
(
aMode
=
=
kAgcAdaptiveAnalog
)
{
MOZ_LOG
(
GetMediaManagerLog
(
)
LogLevel
:
:
Error
(
"
Invalid
AGC
mode
kAgcAdaptiveAnalog
on
mobile
"
)
)
;
MOZ_ASSERT_UNREACHABLE
(
"
Bad
pref
set
in
all
.
js
or
in
about
:
config
"
"
for
the
auto
gain
on
mobile
.
"
)
;
aMode
=
kAgcDefault
;
}
#
endif
GainControl
:
:
Mode
mode
=
kDefaultAgcMode
;
switch
(
aMode
)
{
case
AgcModes
:
:
kAgcDefault
:
mode
=
kDefaultAgcMode
;
break
;
case
AgcModes
:
:
kAgcUnchanged
:
mode
=
mAudioProcessing
-
>
gain_control
(
)
-
>
mode
(
)
;
break
;
case
AgcModes
:
:
kAgcFixedDigital
:
mode
=
GainControl
:
:
Mode
:
:
kFixedDigital
;
break
;
case
AgcModes
:
:
kAgcAdaptiveAnalog
:
mode
=
GainControl
:
:
Mode
:
:
kAdaptiveAnalog
;
break
;
case
AgcModes
:
:
kAgcAdaptiveDigital
:
mode
=
GainControl
:
:
Mode
:
:
kAdaptiveDigital
;
break
;
default
:
MOZ_ASSERT_UNREACHABLE
(
"
Bad
pref
set
in
all
.
js
or
in
about
:
config
"
"
for
the
auto
gain
.
"
)
;
mode
=
GainControl
:
:
Mode
:
:
kAdaptiveDigital
;
break
;
}
HANDLE_APM_ERROR
(
mAudioProcessing
-
>
gain_control
(
)
-
>
set_mode
(
mode
)
)
;
HANDLE_APM_ERROR
(
mAudioProcessing
-
>
gain_control
(
)
-
>
Enable
(
aEnable
)
)
;
}
void
MediaEngineWebRTCMicrophoneSource
:
:
UpdateNSSettingsIfNeeded
(
bool
aEnable
NsModes
aMode
)
{
NoiseSuppression
:
:
Level
nsLevel
;
switch
(
aMode
)
{
case
NsModes
:
:
kNsDefault
:
nsLevel
=
kDefaultNsMode
;
break
;
case
NsModes
:
:
kNsUnchanged
:
nsLevel
=
mAudioProcessing
-
>
noise_suppression
(
)
-
>
level
(
)
;
break
;
case
NsModes
:
:
kNsConference
:
nsLevel
=
NoiseSuppression
:
:
kHigh
;
break
;
case
NsModes
:
:
kNsLowSuppression
:
nsLevel
=
NoiseSuppression
:
:
kLow
;
break
;
case
NsModes
:
:
kNsModerateSuppression
:
nsLevel
=
NoiseSuppression
:
:
kModerate
;
break
;
case
NsModes
:
:
kNsHighSuppression
:
nsLevel
=
NoiseSuppression
:
:
kHigh
;
break
;
case
NsModes
:
:
kNsVeryHighSuppression
:
nsLevel
=
NoiseSuppression
:
:
kVeryHigh
;
break
;
default
:
MOZ_ASSERT_UNREACHABLE
(
"
Bad
pref
set
in
all
.
js
or
in
about
:
config
"
"
for
the
noise
suppression
.
"
)
;
nsLevel
=
NoiseSuppression
:
:
kModerate
;
}
HANDLE_APM_ERROR
(
mAudioProcessing
-
>
noise_suppression
(
)
-
>
set_level
(
nsLevel
)
)
;
HANDLE_APM_ERROR
(
mAudioProcessing
-
>
noise_suppression
(
)
-
>
Enable
(
aEnable
)
)
;
}
#
undef
HANDLE_APM_ERROR
nsresult
MediaEngineWebRTCMicrophoneSource
:
:
UpdateSingleSource
(
const
AllocationHandle
*
aHandle
const
NormalizedConstraints
&
aNetConstraints
const
NormalizedConstraints
&
aNewConstraint
const
MediaEnginePrefs
&
aPrefs
const
nsString
&
aDeviceId
const
char
*
*
aOutBadConstraint
)
{
FlattenedConstraints
c
(
aNetConstraints
)
;
MediaEnginePrefs
prefs
=
aPrefs
;
prefs
.
mAecOn
=
c
.
mEchoCancellation
.
Get
(
prefs
.
mAecOn
)
;
prefs
.
mAgcOn
=
c
.
mAutoGainControl
.
Get
(
prefs
.
mAgcOn
)
;
prefs
.
mNoiseOn
=
c
.
mNoiseSuppression
.
Get
(
prefs
.
mNoiseOn
)
;
uint32_t
maxChannels
=
1
;
if
(
mAudioInput
-
>
GetMaxAvailableChannels
(
maxChannels
)
!
=
0
)
{
return
NS_ERROR_FAILURE
;
}
if
(
static_cast
<
int32_t
>
(
maxChannels
)
<
c
.
mChannelCount
.
mMin
|
|
static_cast
<
int32_t
>
(
maxChannels
)
>
c
.
mChannelCount
.
mMax
)
{
*
aOutBadConstraint
=
"
channelCount
"
;
return
NS_ERROR_FAILURE
;
}
if
(
prefs
.
mChannels
<
=
0
)
{
prefs
.
mChannels
=
static_cast
<
int32_t
>
(
maxChannels
)
;
}
prefs
.
mChannels
=
c
.
mChannelCount
.
Get
(
std
:
:
min
(
prefs
.
mChannels
static_cast
<
int32_t
>
(
maxChannels
)
)
)
;
prefs
.
mChannels
=
std
:
:
max
(
1
std
:
:
min
(
prefs
.
mChannels
static_cast
<
int32_t
>
(
maxChannels
)
)
)
;
LOG
(
(
"
Audio
config
:
aec
:
%
d
agc
:
%
d
noise
:
%
d
channels
:
%
d
"
prefs
.
mAecOn
?
prefs
.
mAec
:
-
1
prefs
.
mAgcOn
?
prefs
.
mAgc
:
-
1
prefs
.
mNoiseOn
?
prefs
.
mNoise
:
-
1
prefs
.
mChannels
)
)
;
switch
(
mState
)
{
case
kReleased
:
MOZ_ASSERT
(
aHandle
)
;
if
(
sChannelsOpen
!
=
0
)
{
return
NS_ERROR_FAILURE
;
}
if
(
mAudioInput
-
>
SetRecordingDevice
(
mCapIndex
)
)
{
return
NS_ERROR_FAILURE
;
}
mAudioInput
-
>
SetUserChannelCount
(
prefs
.
mChannels
)
;
if
(
!
AllocChannel
(
)
)
{
FreeChannel
(
)
;
LOG
(
(
"
Audio
device
is
not
initalized
"
)
)
;
return
NS_ERROR_FAILURE
;
}
LOG
(
(
"
Audio
device
%
d
allocated
"
mCapIndex
)
)
;
{
uint32_t
channelCount
=
0
;
mAudioInput
-
>
GetChannelCount
(
channelCount
)
;
MOZ_ASSERT
(
channelCount
>
0
)
;
prefs
.
mChannels
=
channelCount
;
}
break
;
case
kStarted
:
if
(
prefs
=
=
mLastPrefs
)
{
return
NS_OK
;
}
if
(
prefs
.
mChannels
!
=
mLastPrefs
.
mChannels
)
{
MOZ_ASSERT
(
mSources
.
Length
(
)
>
0
)
;
auto
&
source
=
mSources
.
LastElement
(
)
;
mAudioInput
-
>
SetUserChannelCount
(
prefs
.
mChannels
)
;
uint32_t
channelCount
=
0
;
mAudioInput
-
>
GetChannelCount
(
channelCount
)
;
MOZ_ASSERT
(
channelCount
>
0
&
&
mLastPrefs
.
mChannels
>
0
)
;
if
(
mLastPrefs
.
mChannels
!
=
prefs
.
mChannels
&
&
!
source
-
>
OpenNewAudioCallbackDriver
(
mListener
)
)
{
MOZ_LOG
(
GetMediaManagerLog
(
)
LogLevel
:
:
Error
(
"
Could
not
open
a
new
AudioCallbackDriver
for
input
"
)
)
;
return
NS_ERROR_FAILURE
;
}
}
if
(
MOZ_LOG_TEST
(
GetMediaManagerLog
(
)
LogLevel
:
:
Debug
)
)
{
MonitorAutoLock
lock
(
mMonitor
)
;
if
(
mSources
.
IsEmpty
(
)
)
{
LOG
(
(
"
Audio
device
%
d
reallocated
"
mCapIndex
)
)
;
}
else
{
LOG
(
(
"
Audio
device
%
d
allocated
shared
"
mCapIndex
)
)
;
}
}
break
;
default
:
LOG
(
(
"
Audio
device
%
d
in
ignored
state
%
d
"
mCapIndex
mState
)
)
;
break
;
}
if
(
sChannelsOpen
>
0
)
{
UpdateAGCSettingsIfNeeded
(
prefs
.
mAgcOn
static_cast
<
AgcModes
>
(
prefs
.
mAgc
)
)
;
UpdateNSSettingsIfNeeded
(
prefs
.
mNoiseOn
static_cast
<
NsModes
>
(
prefs
.
mNoise
)
)
;
UpdateAECSettingsIfNeeded
(
prefs
.
mAecOn
static_cast
<
EcModes
>
(
prefs
.
mAec
)
)
;
webrtc
:
:
Config
config
;
config
.
Set
<
webrtc
:
:
ExtendedFilter
>
(
new
webrtc
:
:
ExtendedFilter
(
mExtendedFilter
)
)
;
config
.
Set
<
webrtc
:
:
DelayAgnostic
>
(
new
webrtc
:
:
DelayAgnostic
(
mDelayAgnostic
)
)
;
mAudioProcessing
-
>
SetExtraOptions
(
config
)
;
}
SetLastPrefs
(
prefs
)
;
return
NS_OK
;
}
#
undef
HANDLE_APM_ERROR
void
MediaEngineWebRTCMicrophoneSource
:
:
SetLastPrefs
(
const
MediaEnginePrefs
&
aPrefs
)
{
mLastPrefs
=
aPrefs
;
RefPtr
<
MediaEngineWebRTCMicrophoneSource
>
that
=
this
;
NS_DispatchToMainThread
(
media
:
:
NewRunnableFrom
(
[
that
aPrefs
]
(
)
mutable
{
that
-
>
mSettings
-
>
mEchoCancellation
.
Value
(
)
=
aPrefs
.
mAecOn
;
that
-
>
mSettings
-
>
mAutoGainControl
.
Value
(
)
=
aPrefs
.
mAgcOn
;
that
-
>
mSettings
-
>
mNoiseSuppression
.
Value
(
)
=
aPrefs
.
mNoiseOn
;
that
-
>
mSettings
-
>
mChannelCount
.
Value
(
)
=
aPrefs
.
mChannels
;
return
NS_OK
;
}
)
)
;
}
nsresult
MediaEngineWebRTCMicrophoneSource
:
:
Deallocate
(
AllocationHandle
*
aHandle
)
{
AssertIsOnOwningThread
(
)
;
Super
:
:
Deallocate
(
aHandle
)
;
if
(
!
mRegisteredHandles
.
Length
(
)
)
{
if
(
mState
!
=
kStopped
&
&
mState
!
=
kAllocated
)
{
return
NS_ERROR_FAILURE
;
}
FreeChannel
(
)
;
LOG
(
(
"
Audio
device
%
d
deallocated
"
mCapIndex
)
)
;
}
else
{
LOG
(
(
"
Audio
device
%
d
deallocated
but
still
in
use
"
mCapIndex
)
)
;
}
return
NS_OK
;
}
nsresult
MediaEngineWebRTCMicrophoneSource
:
:
Start
(
SourceMediaStream
*
aStream
TrackID
aID
const
PrincipalHandle
&
aPrincipalHandle
)
{
AssertIsOnOwningThread
(
)
;
if
(
sChannelsOpen
=
=
0
|
|
!
aStream
)
{
return
NS_ERROR_FAILURE
;
}
if
(
!
mSources
.
IsEmpty
(
)
&
&
aStream
-
>
Graph
(
)
!
=
mSources
[
0
]
-
>
Graph
(
)
)
{
return
NS_ERROR_NOT_AVAILABLE
;
}
{
MonitorAutoLock
lock
(
mMonitor
)
;
mSources
.
AppendElement
(
aStream
)
;
mPrincipalHandles
.
AppendElement
(
aPrincipalHandle
)
;
MOZ_ASSERT
(
mSources
.
Length
(
)
=
=
mPrincipalHandles
.
Length
(
)
)
;
}
AudioSegment
*
segment
=
new
AudioSegment
(
)
;
if
(
mSampleFrequency
=
=
MediaEngine
:
:
USE_GRAPH_RATE
)
{
mSampleFrequency
=
aStream
-
>
GraphRate
(
)
;
}
aStream
-
>
AddAudioTrack
(
aID
mSampleFrequency
0
segment
SourceMediaStream
:
:
ADDTRACK_QUEUED
)
;
aStream
-
>
RegisterForAudioMixing
(
)
;
LOG
(
(
"
Start
audio
for
stream
%
p
"
aStream
)
)
;
if
(
!
mListener
)
{
mListener
=
new
mozilla
:
:
WebRTCAudioDataListener
(
this
)
;
}
if
(
mState
=
=
kStarted
)
{
MOZ_ASSERT
(
aID
=
=
mTrackID
)
;
mAudioInput
-
>
StartRecording
(
aStream
mListener
)
;
return
NS_OK
;
}
mState
=
kStarted
;
mTrackID
=
aID
;
AsyncLatencyLogger
:
:
Get
(
true
)
;
if
(
mAudioOutputObserver
)
{
mAudioOutputObserver
-
>
Clear
(
)
;
}
mAudioInput
-
>
StartRecording
(
aStream
mListener
)
;
return
NS_OK
;
}
nsresult
MediaEngineWebRTCMicrophoneSource
:
:
Stop
(
SourceMediaStream
*
aSource
TrackID
aID
)
{
AssertIsOnOwningThread
(
)
;
{
MonitorAutoLock
lock
(
mMonitor
)
;
size_t
sourceIndex
=
mSources
.
IndexOf
(
aSource
)
;
if
(
sourceIndex
=
=
mSources
.
NoIndex
)
{
return
NS_OK
;
}
mSources
.
RemoveElementAt
(
sourceIndex
)
;
mPrincipalHandles
.
RemoveElementAt
(
sourceIndex
)
;
MOZ_ASSERT
(
mSources
.
Length
(
)
=
=
mPrincipalHandles
.
Length
(
)
)
;
aSource
-
>
EndTrack
(
aID
)
;
if
(
!
mSources
.
IsEmpty
(
)
)
{
mAudioInput
-
>
StopRecording
(
aSource
)
;
return
NS_OK
;
}
if
(
mState
!
=
kStarted
)
{
return
NS_ERROR_FAILURE
;
}
mState
=
kStopped
;
}
if
(
mListener
)
{
mListener
-
>
Shutdown
(
)
;
mListener
=
nullptr
;
}
mAudioInput
-
>
StopRecording
(
aSource
)
;
return
NS_OK
;
}
void
MediaEngineWebRTCMicrophoneSource
:
:
NotifyPull
(
MediaStreamGraph
*
aGraph
SourceMediaStream
*
aSource
TrackID
aID
StreamTime
aDesiredTime
const
PrincipalHandle
&
aPrincipalHandle
)
{
LOG_FRAMES
(
(
"
NotifyPull
desired
=
%
"
PRId64
(
int64_t
)
aDesiredTime
)
)
;
}
void
MediaEngineWebRTCMicrophoneSource
:
:
NotifyOutputData
(
MediaStreamGraph
*
aGraph
AudioDataValue
*
aBuffer
size_t
aFrames
TrackRate
aRate
uint32_t
aChannels
)
{
if
(
mAudioOutputObserver
)
{
mAudioOutputObserver
-
>
InsertFarEnd
(
aBuffer
aFrames
false
aRate
aChannels
)
;
}
}
void
MediaEngineWebRTCMicrophoneSource
:
:
PacketizeAndProcess
(
MediaStreamGraph
*
aGraph
const
AudioDataValue
*
aBuffer
size_t
aFrames
TrackRate
aRate
uint32_t
aChannels
)
{
MOZ_ASSERT
(
!
PassThrough
(
)
"
This
should
be
bypassed
when
in
PassThrough
mode
.
"
)
;
size_t
offset
=
0
;
if
(
!
mPacketizer
|
|
mPacketizer
-
>
PacketSize
(
)
!
=
aRate
/
100u
|
|
mPacketizer
-
>
Channels
(
)
!
=
aChannels
)
{
mPacketizer
=
new
AudioPacketizer
<
AudioDataValue
float
>
(
aRate
/
100
aChannels
)
;
}
if
(
!
mStarted
)
{
mStarted
=
true
;
while
(
mAudioOutputObserver
-
>
Size
(
)
>
1
)
{
free
(
mAudioOutputObserver
-
>
Pop
(
)
)
;
}
}
while
(
mAudioOutputObserver
-
>
Size
(
)
>
0
)
{
UniquePtr
<
FarEndAudioChunk
>
buffer
(
mAudioOutputObserver
-
>
Pop
(
)
)
;
if
(
!
buffer
)
{
continue
;
}
AudioDataValue
*
packetDataPointer
=
buffer
-
>
mData
;
AutoTArray
<
AudioDataValue
*
MAX_CHANNELS
>
deinterleavedPacketDataChannelPointers
;
AudioDataValue
*
interleavedFarend
=
nullptr
;
uint32_t
channelCountFarend
=
0
;
uint32_t
framesPerPacketFarend
=
0
;
if
(
mAudioOutputObserver
-
>
PlayoutChannels
(
)
>
MAX_CHANNELS
)
{
AudioConverter
converter
(
AudioConfig
(
aChannels
0
AudioConfig
:
:
FORMAT_DEFAULT
)
AudioConfig
(
MAX_CHANNELS
0
AudioConfig
:
:
FORMAT_DEFAULT
)
)
;
framesPerPacketFarend
=
buffer
-
>
mSamples
;
framesPerPacketFarend
=
converter
.
Process
(
mInputDownmixBuffer
packetDataPointer
framesPerPacketFarend
)
;
interleavedFarend
=
mInputDownmixBuffer
.
Data
(
)
;
channelCountFarend
=
MAX_CHANNELS
;
deinterleavedPacketDataChannelPointers
.
SetLength
(
MAX_CHANNELS
)
;
}
else
{
uint32_t
outputChannels
=
mAudioOutputObserver
-
>
PlayoutChannels
(
)
;
interleavedFarend
=
packetDataPointer
;
channelCountFarend
=
outputChannels
;
framesPerPacketFarend
=
buffer
-
>
mSamples
;
deinterleavedPacketDataChannelPointers
.
SetLength
(
outputChannels
)
;
}
MOZ_ASSERT
(
interleavedFarend
&
&
(
channelCountFarend
=
=
1
|
|
channelCountFarend
=
=
2
)
&
&
framesPerPacketFarend
)
;
offset
=
0
;
for
(
size_t
i
=
0
;
i
<
deinterleavedPacketDataChannelPointers
.
Length
(
)
;
+
+
i
)
{
deinterleavedPacketDataChannelPointers
[
i
]
=
packetDataPointer
+
offset
;
offset
+
=
framesPerPacketFarend
;
}
Deinterleave
(
interleavedFarend
framesPerPacketFarend
channelCountFarend
deinterleavedPacketDataChannelPointers
.
Elements
(
)
)
;
StreamConfig
inputConfig
(
mAudioOutputObserver
-
>
PlayoutFrequency
(
)
channelCountFarend
false
)
;
StreamConfig
outputConfig
=
inputConfig
;
float
*
inputData
=
nullptr
;
#
ifdef
MOZ_SAMPLE_TYPE_S16
size_t
sampleCount
=
framesPerPacketFarend
*
channelCountFarend
;
if
(
mInputBuffer
.
Length
(
)
<
sampleCount
)
{
mInputBuffer
.
SetLength
(
sampleCount
)
;
}
ConvertAudioSamples
(
buffer
-
>
mData
mInputBuffer
.
Data
(
)
sampleCount
)
;
inputData
=
mInputBuffer
.
Data
(
)
;
#
else
inputData
=
buffer
-
>
mData
;
#
endif
AutoTArray
<
float
*
MAX_CHANNELS
>
channelsPointers
;
channelsPointers
.
SetLength
(
channelCountFarend
)
;
offset
=
0
;
for
(
size_t
i
=
0
;
i
<
channelsPointers
.
Length
(
)
;
+
+
i
)
{
channelsPointers
[
i
]
=
inputData
+
offset
;
offset
+
=
framesPerPacketFarend
;
}
int
err
=
mAudioProcessing
-
>
ProcessReverseStream
(
channelsPointers
.
Elements
(
)
inputConfig
outputConfig
channelsPointers
.
Elements
(
)
)
;
if
(
err
)
{
MOZ_LOG
(
GetMediaManagerLog
(
)
LogLevel
:
:
Error
(
"
error
in
audio
ProcessReverseStream
(
)
:
%
d
"
err
)
)
;
return
;
}
}
mPacketizer
-
>
Input
(
aBuffer
static_cast
<
uint32_t
>
(
aFrames
)
)
;
while
(
mPacketizer
-
>
PacketsAvailable
(
)
)
{
uint32_t
samplesPerPacket
=
mPacketizer
-
>
PacketSize
(
)
*
mPacketizer
-
>
Channels
(
)
;
if
(
mInputBuffer
.
Length
(
)
<
samplesPerPacket
)
{
mInputBuffer
.
SetLength
(
samplesPerPacket
)
;
mDeinterleavedBuffer
.
SetLength
(
samplesPerPacket
)
;
}
float
*
packet
=
mInputBuffer
.
Data
(
)
;
mPacketizer
-
>
Output
(
packet
)
;
AutoTArray
<
float
*
8
>
deinterleavedPacketizedInputDataChannelPointers
;
deinterleavedPacketizedInputDataChannelPointers
.
SetLength
(
aChannels
)
;
offset
=
0
;
for
(
size_t
i
=
0
;
i
<
deinterleavedPacketizedInputDataChannelPointers
.
Length
(
)
;
+
+
i
)
{
deinterleavedPacketizedInputDataChannelPointers
[
i
]
=
mDeinterleavedBuffer
.
Data
(
)
+
offset
;
offset
+
=
aFrames
;
}
Deinterleave
(
packet
mPacketizer
-
>
PacketSize
(
)
aChannels
deinterleavedPacketizedInputDataChannelPointers
.
Elements
(
)
)
;
StreamConfig
inputConfig
(
aRate
aChannels
false
)
;
StreamConfig
outputConfig
=
inputConfig
;
mAudioProcessing
-
>
set_stream_delay_ms
(
0
)
;
RefPtr
<
SharedBuffer
>
buffer
=
SharedBuffer
:
:
Create
(
mPacketizer
-
>
PacketSize
(
)
*
aChannels
*
sizeof
(
float
)
)
;
AudioSegment
segment
;
AutoTArray
<
float
*
8
>
processedOutputChannelPointers
;
AutoTArray
<
const
float
*
8
>
processedOutputChannelPointersConst
;
processedOutputChannelPointers
.
SetLength
(
aChannels
)
;
processedOutputChannelPointersConst
.
SetLength
(
aChannels
)
;
offset
=
0
;
for
(
size_t
i
=
0
;
i
<
processedOutputChannelPointers
.
Length
(
)
;
+
+
i
)
{
processedOutputChannelPointers
[
i
]
=
static_cast
<
float
*
>
(
buffer
-
>
Data
(
)
)
+
offset
;
processedOutputChannelPointersConst
[
i
]
=
static_cast
<
float
*
>
(
buffer
-
>
Data
(
)
)
+
offset
;
offset
+
=
aFrames
;
}
mAudioProcessing
-
>
ProcessStream
(
deinterleavedPacketizedInputDataChannelPointers
.
Elements
(
)
inputConfig
outputConfig
processedOutputChannelPointers
.
Elements
(
)
)
;
MonitorAutoLock
lock
(
mMonitor
)
;
if
(
mState
!
=
kStarted
)
return
;
for
(
size_t
i
=
0
;
i
<
mSources
.
Length
(
)
;
+
+
i
)
{
if
(
!
mSources
[
i
]
)
{
continue
;
}
MOZ_ASSERT
(
processedOutputChannelPointers
.
Length
(
)
=
=
aChannels
)
;
segment
.
AppendFrames
(
buffer
.
forget
(
)
processedOutputChannelPointersConst
mPacketizer
-
>
PacketSize
(
)
mPrincipalHandles
[
i
]
)
;
mSources
[
i
]
-
>
AppendToTrack
(
mTrackID
&
segment
)
;
}
}
}
template
<
typename
T
>
void
MediaEngineWebRTCMicrophoneSource
:
:
InsertInGraph
(
const
T
*
aBuffer
size_t
aFrames
uint32_t
aChannels
)
{
MonitorAutoLock
lock
(
mMonitor
)
;
if
(
mState
!
=
kStarted
)
{
return
;
}
if
(
MOZ_LOG_TEST
(
AudioLogModule
(
)
LogLevel
:
:
Debug
)
)
{
mTotalFrames
+
=
aFrames
;
if
(
mTotalFrames
>
mLastLogFrames
+
mSampleFrequency
)
{
MOZ_LOG
(
AudioLogModule
(
)
LogLevel
:
:
Debug
(
"
%
p
:
Inserting
%
zu
samples
into
graph
total
frames
=
%
"
PRIu64
(
void
*
)
this
aFrames
mTotalFrames
)
)
;
mLastLogFrames
=
mTotalFrames
;
}
}
size_t
len
=
mSources
.
Length
(
)
;
for
(
size_t
i
=
0
;
i
<
len
;
+
+
i
)
{
if
(
!
mSources
[
i
]
)
{
continue
;
}
TimeStamp
insertTime
;
LogTime
(
AsyncLatencyLogger
:
:
AudioTrackInsertion
LATENCY_STREAM_ID
(
mSources
[
i
]
.
get
(
)
mTrackID
)
(
i
+
1
<
len
)
?
0
:
1
insertTime
)
;
MOZ_ASSERT
(
aChannels
>
=
1
&
&
aChannels
<
=
8
"
Support
up
to
8
channels
"
)
;
AudioSegment
segment
;
RefPtr
<
SharedBuffer
>
buffer
=
SharedBuffer
:
:
Create
(
aFrames
*
aChannels
*
sizeof
(
T
)
)
;
AutoTArray
<
const
T
*
8
>
channels
;
if
(
aChannels
=
=
1
)
{
PodCopy
(
static_cast
<
T
*
>
(
buffer
-
>
Data
(
)
)
aBuffer
aFrames
)
;
channels
.
AppendElement
(
static_cast
<
T
*
>
(
buffer
-
>
Data
(
)
)
)
;
}
else
{
channels
.
SetLength
(
aChannels
)
;
AutoTArray
<
T
*
8
>
write_channels
;
write_channels
.
SetLength
(
aChannels
)
;
T
*
samples
=
static_cast
<
T
*
>
(
buffer
-
>
Data
(
)
)
;
size_t
offset
=
0
;
for
(
uint32_t
i
=
0
;
i
<
aChannels
;
+
+
i
)
{
channels
[
i
]
=
write_channels
[
i
]
=
samples
+
offset
;
offset
+
=
aFrames
;
}
DeinterleaveAndConvertBuffer
(
aBuffer
aFrames
aChannels
write_channels
.
Elements
(
)
)
;
}
MOZ_ASSERT
(
aChannels
=
=
channels
.
Length
(
)
)
;
segment
.
AppendFrames
(
buffer
.
forget
(
)
channels
aFrames
mPrincipalHandles
[
i
]
)
;
segment
.
GetStartTime
(
insertTime
)
;
mSources
[
i
]
-
>
AppendToTrack
(
mTrackID
&
segment
)
;
}
}
void
MediaEngineWebRTCMicrophoneSource
:
:
NotifyInputData
(
MediaStreamGraph
*
aGraph
const
AudioDataValue
*
aBuffer
size_t
aFrames
TrackRate
aRate
uint32_t
aChannels
)
{
if
(
PassThrough
(
)
)
{
InsertInGraph
<
AudioDataValue
>
(
aBuffer
aFrames
aChannels
)
;
}
else
{
PacketizeAndProcess
(
aGraph
aBuffer
aFrames
aRate
aChannels
)
;
}
}
#
define
ResetProcessingIfNeeded
(
_processing
)
\
do
{
\
bool
enabled
=
mAudioProcessing
-
>
_processing
(
)
-
>
is_enabled
(
)
;
\
\
if
(
enabled
)
{
\
int
rv
=
mAudioProcessing
-
>
_processing
(
)
-
>
Enable
(
!
enabled
)
;
\
if
(
rv
)
{
\
NS_WARNING
(
"
Could
not
reset
the
status
of
the
"
\
#
_processing
"
on
device
change
.
"
)
;
\
return
;
\
}
\
rv
=
mAudioProcessing
-
>
_processing
(
)
-
>
Enable
(
enabled
)
;
\
if
(
rv
)
{
\
NS_WARNING
(
"
Could
not
reset
the
status
of
the
"
\
#
_processing
"
on
device
change
.
"
)
;
\
return
;
\
}
\
\
}
\
}
while
(
0
)
void
MediaEngineWebRTCMicrophoneSource
:
:
DeviceChanged
(
)
{
ResetProcessingIfNeeded
(
gain_control
)
;
ResetProcessingIfNeeded
(
echo_cancellation
)
;
ResetProcessingIfNeeded
(
noise_suppression
)
;
}
void
MediaEngineWebRTCMicrophoneSource
:
:
FreeChannel
(
)
{
if
(
mState
!
=
kReleased
)
{
mState
=
kReleased
;
MOZ_ASSERT
(
sChannelsOpen
>
0
)
;
-
-
sChannelsOpen
;
}
}
bool
MediaEngineWebRTCMicrophoneSource
:
:
AllocChannel
(
)
{
mSampleFrequency
=
MediaEngine
:
:
USE_GRAPH_RATE
;
LOG
(
(
"
%
s
:
sampling
rate
%
u
"
__FUNCTION__
mSampleFrequency
)
)
;
mState
=
kAllocated
;
sChannelsOpen
+
+
;
return
true
;
}
void
MediaEngineWebRTCMicrophoneSource
:
:
Shutdown
(
)
{
Super
:
:
Shutdown
(
)
;
if
(
mListener
)
{
mListener
-
>
Shutdown
(
)
;
mListener
=
nullptr
;
}
if
(
mState
=
=
kStarted
)
{
SourceMediaStream
*
source
;
bool
empty
;
while
(
1
)
{
{
MonitorAutoLock
lock
(
mMonitor
)
;
empty
=
mSources
.
IsEmpty
(
)
;
if
(
empty
)
{
break
;
}
source
=
mSources
[
0
]
;
}
Stop
(
source
kAudioTrack
)
;
}
MOZ_ASSERT
(
mState
=
=
kStopped
)
;
}
while
(
mRegisteredHandles
.
Length
(
)
)
{
MOZ_ASSERT
(
mState
=
=
kAllocated
|
|
mState
=
=
kStopped
)
;
Deallocate
(
mRegisteredHandles
[
0
]
.
get
(
)
)
;
}
MOZ_ASSERT
(
mState
=
=
kReleased
)
;
}
void
MediaEngineWebRTCAudioCaptureSource
:
:
GetName
(
nsAString
&
aName
)
const
{
aName
.
AssignLiteral
(
"
AudioCapture
"
)
;
}
void
MediaEngineWebRTCAudioCaptureSource
:
:
GetUUID
(
nsACString
&
aUUID
)
const
{
nsID
uuid
;
char
uuidBuffer
[
NSID_LENGTH
]
;
nsCString
asciiString
;
ErrorResult
rv
;
rv
=
nsContentUtils
:
:
GenerateUUIDInPlace
(
uuid
)
;
if
(
rv
.
Failed
(
)
)
{
aUUID
.
AssignLiteral
(
"
"
)
;
return
;
}
uuid
.
ToProvidedString
(
uuidBuffer
)
;
asciiString
.
AssignASCII
(
uuidBuffer
)
;
aUUID
.
Assign
(
Substring
(
asciiString
1
NSID_LENGTH
-
3
)
)
;
}
nsresult
MediaEngineWebRTCAudioCaptureSource
:
:
Start
(
SourceMediaStream
*
aMediaStream
TrackID
aId
const
PrincipalHandle
&
aPrincipalHandle
)
{
AssertIsOnOwningThread
(
)
;
aMediaStream
-
>
AddTrack
(
aId
0
new
AudioSegment
(
)
)
;
return
NS_OK
;
}
nsresult
MediaEngineWebRTCAudioCaptureSource
:
:
Stop
(
SourceMediaStream
*
aMediaStream
TrackID
aId
)
{
AssertIsOnOwningThread
(
)
;
aMediaStream
-
>
EndAllTrackAndFinish
(
)
;
return
NS_OK
;
}
nsresult
MediaEngineWebRTCAudioCaptureSource
:
:
Restart
(
AllocationHandle
*
aHandle
const
dom
:
:
MediaTrackConstraints
&
aConstraints
const
MediaEnginePrefs
&
aPrefs
const
nsString
&
aDeviceId
const
char
*
*
aOutBadConstraint
)
{
MOZ_ASSERT
(
!
aHandle
)
;
return
NS_OK
;
}
uint32_t
MediaEngineWebRTCAudioCaptureSource
:
:
GetBestFitnessDistance
(
const
nsTArray
<
const
NormalizedConstraintSet
*
>
&
aConstraintSets
const
nsString
&
aDeviceId
)
const
{
return
0
;
}
}
