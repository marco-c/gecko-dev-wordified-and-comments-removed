#
include
"
MediaEngineWebRTCAudio
.
h
"
#
include
<
stdio
.
h
>
#
include
<
algorithm
>
#
include
"
AudioConverter
.
h
"
#
include
"
MediaManager
.
h
"
#
include
"
MediaTrackGraphImpl
.
h
"
#
include
"
MediaTrackConstraints
.
h
"
#
include
"
mozilla
/
Assertions
.
h
"
#
include
"
mozilla
/
ErrorNames
.
h
"
#
include
"
nsContentUtils
.
h
"
#
include
"
nsIDUtils
.
h
"
#
include
"
transport
/
runnable_utils
.
h
"
#
include
"
Tracing
.
h
"
#
include
"
mozilla
/
Sprintf
.
h
"
#
include
"
mozilla
/
Logging
.
h
"
#
include
"
common_audio
/
include
/
audio_util
.
h
"
#
include
"
modules
/
audio_processing
/
include
/
audio_processing
.
h
"
using
namespace
webrtc
;
#
define
MAX_CHANNELS
2
#
define
MONO
1
#
define
MAX_SAMPLING_FREQ
48000
/
/
Hz
-
multiple
of
100
namespace
mozilla
{
extern
LazyLogModule
gMediaManagerLog
;
#
define
LOG
(
.
.
.
)
MOZ_LOG
(
gMediaManagerLog
LogLevel
:
:
Debug
(
__VA_ARGS__
)
)
#
define
LOG_FRAME
(
.
.
.
)
\
MOZ_LOG
(
gMediaManagerLog
LogLevel
:
:
Verbose
(
__VA_ARGS__
)
)
#
define
LOG_ERROR
(
.
.
.
)
MOZ_LOG
(
gMediaManagerLog
LogLevel
:
:
Error
(
__VA_ARGS__
)
)
MediaEngineWebRTCMicrophoneSource
:
:
MediaEngineWebRTCMicrophoneSource
(
RefPtr
<
AudioDeviceInfo
>
aInfo
const
nsString
&
aDeviceName
const
nsCString
&
aDeviceUUID
const
nsString
&
aDeviceGroup
uint32_t
aMaxChannelCount
)
:
mPrincipal
(
PRINCIPAL_HANDLE_NONE
)
mDeviceInfo
(
std
:
:
move
(
aInfo
)
)
mDeviceName
(
aDeviceName
)
mDeviceUUID
(
aDeviceUUID
)
mDeviceGroup
(
aDeviceGroup
)
mDeviceMaxChannelCount
(
aMaxChannelCount
)
mSettings
(
new
nsMainThreadPtrHolder
<
media
:
:
Refcountable
<
dom
:
:
MediaTrackSettings
>
>
(
"
MediaEngineWebRTCMicrophoneSource
:
:
mSettings
"
new
media
:
:
Refcountable
<
dom
:
:
MediaTrackSettings
>
(
)
false
)
)
{
#
ifndef
ANDROID
MOZ_ASSERT
(
mDeviceInfo
-
>
DeviceID
(
)
)
;
#
endif
mSettings
-
>
mEchoCancellation
.
Construct
(
0
)
;
mSettings
-
>
mAutoGainControl
.
Construct
(
0
)
;
mSettings
-
>
mNoiseSuppression
.
Construct
(
0
)
;
mSettings
-
>
mChannelCount
.
Construct
(
0
)
;
mState
=
kReleased
;
}
nsString
MediaEngineWebRTCMicrophoneSource
:
:
GetName
(
)
const
{
return
mDeviceName
;
}
nsCString
MediaEngineWebRTCMicrophoneSource
:
:
GetUUID
(
)
const
{
return
mDeviceUUID
;
}
nsString
MediaEngineWebRTCMicrophoneSource
:
:
GetGroupId
(
)
const
{
return
mDeviceGroup
;
}
nsresult
MediaEngineWebRTCMicrophoneSource
:
:
EvaluateSettings
(
const
NormalizedConstraints
&
aConstraintsUpdate
const
MediaEnginePrefs
&
aInPrefs
MediaEnginePrefs
*
aOutPrefs
const
char
*
*
aOutBadConstraint
)
{
AssertIsOnOwningThread
(
)
;
FlattenedConstraints
c
(
aConstraintsUpdate
)
;
MediaEnginePrefs
prefs
=
aInPrefs
;
prefs
.
mAecOn
=
c
.
mEchoCancellation
.
Get
(
aInPrefs
.
mAecOn
)
;
prefs
.
mAgcOn
=
c
.
mAutoGainControl
.
Get
(
aInPrefs
.
mAgcOn
&
&
prefs
.
mAecOn
)
;
prefs
.
mNoiseOn
=
c
.
mNoiseSuppression
.
Get
(
aInPrefs
.
mNoiseOn
&
&
prefs
.
mAecOn
)
;
int32_t
maxChannels
=
static_cast
<
int32_t
>
(
mDeviceInfo
-
>
MaxChannels
(
)
)
;
if
(
c
.
mChannelCount
.
mMin
>
maxChannels
)
{
*
aOutBadConstraint
=
"
channelCount
"
;
return
NS_ERROR_FAILURE
;
}
if
(
aInPrefs
.
mChannels
<
=
0
)
{
prefs
.
mChannels
=
maxChannels
;
}
prefs
.
mChannels
=
c
.
mChannelCount
.
Get
(
std
:
:
min
(
prefs
.
mChannels
maxChannels
)
)
;
prefs
.
mChannels
=
std
:
:
max
(
1
std
:
:
min
(
prefs
.
mChannels
maxChannels
)
)
;
LOG
(
"
Audio
config
:
agc
:
%
d
noise
:
%
d
channels
:
%
d
"
prefs
.
mAgcOn
?
prefs
.
mAgc
:
-
1
prefs
.
mNoiseOn
?
prefs
.
mNoise
:
-
1
prefs
.
mChannels
)
;
*
aOutPrefs
=
prefs
;
return
NS_OK
;
}
nsresult
MediaEngineWebRTCMicrophoneSource
:
:
Reconfigure
(
const
dom
:
:
MediaTrackConstraints
&
aConstraints
const
MediaEnginePrefs
&
aPrefs
const
char
*
*
aOutBadConstraint
)
{
AssertIsOnOwningThread
(
)
;
MOZ_ASSERT
(
mTrack
)
;
LOG
(
"
Mic
source
%
p
Reconfigure
"
this
)
;
NormalizedConstraints
constraints
(
aConstraints
)
;
MediaEnginePrefs
outputPrefs
;
nsresult
rv
=
EvaluateSettings
(
constraints
aPrefs
&
outputPrefs
aOutBadConstraint
)
;
if
(
NS_FAILED
(
rv
)
)
{
if
(
aOutBadConstraint
)
{
return
NS_ERROR_INVALID_ARG
;
}
nsAutoCString
name
;
GetErrorName
(
rv
name
)
;
LOG
(
"
Mic
source
%
p
Reconfigure
(
)
failed
unexpectedly
.
rv
=
%
s
"
this
name
.
Data
(
)
)
;
Stop
(
)
;
return
NS_ERROR_UNEXPECTED
;
}
ApplySettings
(
outputPrefs
)
;
mCurrentPrefs
=
outputPrefs
;
return
NS_OK
;
}
void
MediaEngineWebRTCMicrophoneSource
:
:
ApplySettings
(
const
MediaEnginePrefs
&
aPrefs
)
{
AssertIsOnOwningThread
(
)
;
TRACE
(
"
ApplySettings
"
)
;
MOZ_ASSERT
(
mTrack
"
ApplySetting
is
to
be
called
only
after
SetTrack
has
been
called
"
)
;
mAudioProcessingConfig
.
pipeline
.
multi_channel_render
=
true
;
mAudioProcessingConfig
.
pipeline
.
multi_channel_capture
=
true
;
mAudioProcessingConfig
.
echo_canceller
.
enabled
=
aPrefs
.
mAecOn
;
mAudioProcessingConfig
.
echo_canceller
.
mobile_mode
=
aPrefs
.
mUseAecMobile
;
if
(
(
mAudioProcessingConfig
.
gain_controller1
.
enabled
=
aPrefs
.
mAgcOn
&
&
!
aPrefs
.
mAgc2Forced
)
)
{
auto
mode
=
static_cast
<
AudioProcessing
:
:
Config
:
:
GainController1
:
:
Mode
>
(
aPrefs
.
mAgc
)
;
if
(
mode
!
=
AudioProcessing
:
:
Config
:
:
GainController1
:
:
kAdaptiveAnalog
&
&
mode
!
=
AudioProcessing
:
:
Config
:
:
GainController1
:
:
kAdaptiveDigital
&
&
mode
!
=
AudioProcessing
:
:
Config
:
:
GainController1
:
:
kFixedDigital
)
{
LOG_ERROR
(
"
AudioInputProcessing
%
p
Attempt
to
set
invalid
AGC
mode
%
d
"
mInputProcessing
.
get
(
)
static_cast
<
int
>
(
mode
)
)
;
mode
=
AudioProcessing
:
:
Config
:
:
GainController1
:
:
kAdaptiveDigital
;
}
#
if
defined
(
WEBRTC_IOS
)
|
|
defined
(
ATA
)
|
|
defined
(
WEBRTC_ANDROID
)
if
(
mode
=
=
AudioProcessing
:
:
Config
:
:
GainController1
:
:
kAdaptiveAnalog
)
{
LOG_ERROR
(
"
AudioInputProcessing
%
p
Invalid
AGC
mode
kAdaptiveAnalog
on
"
"
mobile
"
mInputProcessing
.
get
(
)
)
;
MOZ_ASSERT_UNREACHABLE
(
"
Bad
pref
set
in
all
.
js
or
in
about
:
config
"
"
for
the
auto
gain
on
mobile
.
"
)
;
mode
=
AudioProcessing
:
:
Config
:
:
GainController1
:
:
kFixedDigital
;
}
#
endif
mAudioProcessingConfig
.
gain_controller1
.
mode
=
mode
;
}
mAudioProcessingConfig
.
gain_controller2
.
enabled
=
mAudioProcessingConfig
.
gain_controller2
.
adaptive_digital
.
enabled
=
aPrefs
.
mAgcOn
&
&
aPrefs
.
mAgc2Forced
;
if
(
(
mAudioProcessingConfig
.
noise_suppression
.
enabled
=
aPrefs
.
mNoiseOn
)
)
{
auto
level
=
static_cast
<
AudioProcessing
:
:
Config
:
:
NoiseSuppression
:
:
Level
>
(
aPrefs
.
mNoise
)
;
if
(
level
!
=
AudioProcessing
:
:
Config
:
:
NoiseSuppression
:
:
kLow
&
&
level
!
=
AudioProcessing
:
:
Config
:
:
NoiseSuppression
:
:
kModerate
&
&
level
!
=
AudioProcessing
:
:
Config
:
:
NoiseSuppression
:
:
kHigh
&
&
level
!
=
AudioProcessing
:
:
Config
:
:
NoiseSuppression
:
:
kVeryHigh
)
{
LOG_ERROR
(
"
AudioInputProcessing
%
p
Attempt
to
set
invalid
noise
suppression
"
"
level
%
d
"
mInputProcessing
.
get
(
)
static_cast
<
int
>
(
level
)
)
;
level
=
AudioProcessing
:
:
Config
:
:
NoiseSuppression
:
:
kModerate
;
}
mAudioProcessingConfig
.
noise_suppression
.
level
=
level
;
}
mAudioProcessingConfig
.
transient_suppression
.
enabled
=
aPrefs
.
mTransientOn
;
mAudioProcessingConfig
.
high_pass_filter
.
enabled
=
aPrefs
.
mHPFOn
;
mAudioProcessingConfig
.
residual_echo_detector
.
enabled
=
aPrefs
.
mResidualEchoOn
;
RefPtr
<
MediaEngineWebRTCMicrophoneSource
>
that
=
this
;
NS_DispatchToMainThread
(
NS_NewRunnableFunction
(
__func__
[
this
that
track
=
mTrack
prefs
=
aPrefs
audioProcessingConfig
=
mAudioProcessingConfig
]
{
mSettings
-
>
mEchoCancellation
.
Value
(
)
=
prefs
.
mAecOn
;
mSettings
-
>
mAutoGainControl
.
Value
(
)
=
prefs
.
mAgcOn
;
mSettings
-
>
mNoiseSuppression
.
Value
(
)
=
prefs
.
mNoiseOn
;
mSettings
-
>
mChannelCount
.
Value
(
)
=
prefs
.
mChannels
;
class
Message
:
public
ControlMessage
{
const
RefPtr
<
AudioInputProcessing
>
mInputProcessing
;
const
AudioProcessing
:
:
Config
mAudioProcessingConfig
;
const
bool
mPassThrough
;
const
uint32_t
mRequestedInputChannelCount
;
public
:
Message
(
MediaTrack
*
aTrack
AudioInputProcessing
*
aInputProcessing
const
AudioProcessing
:
:
Config
&
aAudioProcessingConfig
bool
aPassThrough
uint32_t
aRequestedInputChannelCount
)
:
ControlMessage
(
aTrack
)
mInputProcessing
(
aInputProcessing
)
mAudioProcessingConfig
(
aAudioProcessingConfig
)
mPassThrough
(
aPassThrough
)
mRequestedInputChannelCount
(
aRequestedInputChannelCount
)
{
}
void
Run
(
)
override
{
mInputProcessing
-
>
ApplyConfig
(
mTrack
-
>
GraphImpl
(
)
mAudioProcessingConfig
)
;
{
TRACE
(
"
SetPassThrough
"
)
mInputProcessing
-
>
SetPassThrough
(
mTrack
-
>
GraphImpl
(
)
mPassThrough
)
;
}
{
TRACE
(
"
SetRequestedInputChannelCount
"
)
;
mInputProcessing
-
>
SetRequestedInputChannelCount
(
mTrack
-
>
GraphImpl
(
)
mRequestedInputChannelCount
)
;
}
}
}
;
bool
passThrough
=
!
(
prefs
.
mAecOn
|
|
prefs
.
mAgcOn
|
|
prefs
.
mNoiseOn
)
;
if
(
track
-
>
IsDestroyed
(
)
)
{
return
;
}
track
-
>
GraphImpl
(
)
-
>
AppendMessage
(
MakeUnique
<
Message
>
(
track
mInputProcessing
audioProcessingConfig
passThrough
prefs
.
mChannels
)
)
;
}
)
)
;
}
nsresult
MediaEngineWebRTCMicrophoneSource
:
:
Allocate
(
const
dom
:
:
MediaTrackConstraints
&
aConstraints
const
MediaEnginePrefs
&
aPrefs
uint64_t
aWindowID
const
char
*
*
aOutBadConstraint
)
{
AssertIsOnOwningThread
(
)
;
mState
=
kAllocated
;
NormalizedConstraints
normalized
(
aConstraints
)
;
MediaEnginePrefs
outputPrefs
;
nsresult
rv
=
EvaluateSettings
(
normalized
aPrefs
&
outputPrefs
aOutBadConstraint
)
;
if
(
NS_FAILED
(
rv
)
)
{
return
rv
;
}
NS_DispatchToMainThread
(
NS_NewRunnableFunction
(
__func__
[
settings
=
mSettings
prefs
=
outputPrefs
]
{
settings
-
>
mEchoCancellation
.
Value
(
)
=
prefs
.
mAecOn
;
settings
-
>
mAutoGainControl
.
Value
(
)
=
prefs
.
mAgcOn
;
settings
-
>
mNoiseSuppression
.
Value
(
)
=
prefs
.
mNoiseOn
;
settings
-
>
mChannelCount
.
Value
(
)
=
prefs
.
mChannels
;
}
)
)
;
mCurrentPrefs
=
outputPrefs
;
return
rv
;
}
nsresult
MediaEngineWebRTCMicrophoneSource
:
:
Deallocate
(
)
{
AssertIsOnOwningThread
(
)
;
MOZ_ASSERT
(
mState
=
=
kStopped
|
|
mState
=
=
kAllocated
)
;
class
EndTrackMessage
:
public
ControlMessage
{
const
RefPtr
<
AudioInputProcessing
>
mInputProcessing
;
public
:
explicit
EndTrackMessage
(
AudioInputProcessing
*
aAudioInputProcessing
)
:
ControlMessage
(
nullptr
)
mInputProcessing
(
aAudioInputProcessing
)
{
}
void
Run
(
)
override
{
TRACE
(
"
mInputProcessing
:
:
End
"
)
;
mInputProcessing
-
>
End
(
)
;
}
}
;
if
(
mTrack
)
{
NS_DispatchToMainThread
(
NS_NewRunnableFunction
(
__func__
[
track
=
std
:
:
move
(
mTrack
)
inputProcessing
=
mInputProcessing
]
{
if
(
track
-
>
IsDestroyed
(
)
)
{
return
;
}
track
-
>
GraphImpl
(
)
-
>
AppendMessage
(
MakeUnique
<
EndTrackMessage
>
(
inputProcessing
)
)
;
}
)
)
;
}
mTrack
=
nullptr
;
mPrincipal
=
PRINCIPAL_HANDLE_NONE
;
MOZ_ASSERT
(
mState
!
=
kReleased
"
Source
not
allocated
"
)
;
MOZ_ASSERT
(
mState
!
=
kStarted
"
Source
not
stopped
"
)
;
mState
=
kReleased
;
LOG
(
"
Mic
source
%
p
Audio
device
%
s
deallocated
"
this
NS_ConvertUTF16toUTF8
(
mDeviceName
)
.
get
(
)
)
;
return
NS_OK
;
}
void
MediaEngineWebRTCMicrophoneSource
:
:
SetTrack
(
const
RefPtr
<
MediaTrack
>
&
aTrack
const
PrincipalHandle
&
aPrincipal
)
{
AssertIsOnOwningThread
(
)
;
MOZ_ASSERT
(
aTrack
)
;
MOZ_ASSERT
(
aTrack
-
>
AsAudioInputTrack
(
)
)
;
MOZ_ASSERT
(
!
mTrack
)
;
MOZ_ASSERT
(
mPrincipal
=
=
PRINCIPAL_HANDLE_NONE
)
;
mTrack
=
aTrack
-
>
AsAudioInputTrack
(
)
;
mPrincipal
=
aPrincipal
;
mInputProcessing
=
MakeAndAddRef
<
AudioInputProcessing
>
(
mDeviceMaxChannelCount
mPrincipal
)
;
NS_DispatchToMainThread
(
NS_NewRunnableFunction
(
__func__
[
track
=
mTrack
processing
=
mInputProcessing
]
(
)
mutable
{
track
-
>
SetInputProcessing
(
std
:
:
move
(
processing
)
)
;
track
-
>
Resume
(
)
;
}
)
)
;
LOG
(
"
Mic
source
%
p
Track
%
p
registered
for
microphone
capture
"
this
aTrack
.
get
(
)
)
;
}
class
StartStopMessage
:
public
ControlMessage
{
public
:
enum
StartStop
{
Start
Stop
}
;
StartStopMessage
(
AudioInputProcessing
*
aInputProcessing
StartStop
aAction
)
:
ControlMessage
(
nullptr
)
mInputProcessing
(
aInputProcessing
)
mAction
(
aAction
)
{
}
void
Run
(
)
override
{
if
(
mAction
=
=
StartStopMessage
:
:
Start
)
{
TRACE
(
"
InputProcessing
:
:
Start
"
)
mInputProcessing
-
>
Start
(
)
;
}
else
if
(
mAction
=
=
StartStopMessage
:
:
Stop
)
{
TRACE
(
"
InputProcessing
:
:
Stop
"
)
mInputProcessing
-
>
Stop
(
)
;
}
else
{
MOZ_CRASH
(
"
Invalid
enum
value
"
)
;
}
}
protected
:
const
RefPtr
<
AudioInputProcessing
>
mInputProcessing
;
const
StartStop
mAction
;
}
;
nsresult
MediaEngineWebRTCMicrophoneSource
:
:
Start
(
)
{
AssertIsOnOwningThread
(
)
;
if
(
mState
=
=
kStarted
)
{
return
NS_OK
;
}
MOZ_ASSERT
(
mState
=
=
kAllocated
|
|
mState
=
=
kStopped
)
;
CubebUtils
:
:
AudioDeviceID
deviceID
=
mDeviceInfo
-
>
DeviceID
(
)
;
if
(
mTrack
-
>
GraphImpl
(
)
-
>
InputDeviceID
(
)
&
&
mTrack
-
>
GraphImpl
(
)
-
>
InputDeviceID
(
)
!
=
deviceID
)
{
return
NS_ERROR_NOT_AVAILABLE
;
}
NS_DispatchToMainThread
(
NS_NewRunnableFunction
(
__func__
[
inputProcessing
=
mInputProcessing
deviceID
track
=
mTrack
]
{
if
(
track
-
>
IsDestroyed
(
)
)
{
return
;
}
track
-
>
GraphImpl
(
)
-
>
AppendMessage
(
MakeUnique
<
StartStopMessage
>
(
inputProcessing
StartStopMessage
:
:
Start
)
)
;
track
-
>
OpenAudioInput
(
deviceID
inputProcessing
)
;
}
)
)
;
ApplySettings
(
mCurrentPrefs
)
;
MOZ_ASSERT
(
mState
!
=
kReleased
)
;
mState
=
kStarted
;
return
NS_OK
;
}
nsresult
MediaEngineWebRTCMicrophoneSource
:
:
Stop
(
)
{
AssertIsOnOwningThread
(
)
;
LOG
(
"
Mic
source
%
p
Stop
(
)
"
this
)
;
MOZ_ASSERT
(
mTrack
"
SetTrack
must
have
been
called
before
:
:
Stop
"
)
;
if
(
mState
=
=
kStopped
)
{
return
NS_OK
;
}
NS_DispatchToMainThread
(
NS_NewRunnableFunction
(
__func__
[
inputProcessing
=
mInputProcessing
deviceInfo
=
mDeviceInfo
track
=
mTrack
]
{
if
(
track
-
>
IsDestroyed
(
)
)
{
return
;
}
track
-
>
GraphImpl
(
)
-
>
AppendMessage
(
MakeUnique
<
StartStopMessage
>
(
inputProcessing
StartStopMessage
:
:
Stop
)
)
;
MOZ_ASSERT
(
track
-
>
DeviceId
(
)
.
value
(
)
=
=
deviceInfo
-
>
DeviceID
(
)
)
;
track
-
>
CloseAudioInput
(
)
;
}
)
)
;
MOZ_ASSERT
(
mState
=
=
kStarted
"
Should
be
started
when
stopping
"
)
;
mState
=
kStopped
;
return
NS_OK
;
}
void
MediaEngineWebRTCMicrophoneSource
:
:
GetSettings
(
dom
:
:
MediaTrackSettings
&
aOutSettings
)
const
{
MOZ_ASSERT
(
NS_IsMainThread
(
)
)
;
aOutSettings
=
*
mSettings
;
}
AudioInputProcessing
:
:
AudioInputProcessing
(
uint32_t
aMaxChannelCount
const
PrincipalHandle
&
aPrincipalHandle
)
:
mAudioProcessing
(
AudioProcessingBuilder
(
)
.
Create
(
)
)
mRequestedInputChannelCount
(
aMaxChannelCount
)
mSkipProcessing
(
false
)
mInputDownmixBuffer
(
MAX_SAMPLING_FREQ
*
MAX_CHANNELS
/
100
)
mLiveBufferingAppended
(
Nothing
(
)
)
mPrincipal
(
aPrincipalHandle
)
mEnabled
(
false
)
mEnded
(
false
)
mPacketCount
(
0
)
{
}
void
AudioInputProcessing
:
:
Disconnect
(
MediaTrackGraphImpl
*
aGraph
)
{
MOZ_ASSERT
(
aGraph
-
>
OnGraphThread
(
)
)
;
}
bool
AudioInputProcessing
:
:
PassThrough
(
MediaTrackGraphImpl
*
aGraph
)
const
{
MOZ_ASSERT
(
aGraph
-
>
OnGraphThread
(
)
)
;
return
mSkipProcessing
;
}
void
AudioInputProcessing
:
:
SetPassThrough
(
MediaTrackGraphImpl
*
aGraph
bool
aPassThrough
)
{
MOZ_ASSERT
(
aGraph
-
>
OnGraphThread
(
)
)
;
if
(
!
mSkipProcessing
&
&
aPassThrough
)
{
mAudioProcessing
-
>
Initialize
(
)
;
if
(
mPacketizerInput
)
{
MOZ_ASSERT
(
mPacketizerInput
-
>
PacketsAvailable
(
)
=
=
0
)
;
LOG_FRAME
(
"
AudioInputProcessing
%
p
Appending
%
u
frames
of
null
data
for
data
"
"
discarded
in
the
packetizer
"
this
mPacketizerInput
-
>
FramesAvailable
(
)
)
;
mSegment
.
AppendNullData
(
mPacketizerInput
-
>
FramesAvailable
(
)
)
;
mPacketizerInput
-
>
Clear
(
)
;
}
}
mSkipProcessing
=
aPassThrough
;
}
uint32_t
AudioInputProcessing
:
:
GetRequestedInputChannelCount
(
)
{
return
mRequestedInputChannelCount
;
}
void
AudioInputProcessing
:
:
SetRequestedInputChannelCount
(
MediaTrackGraphImpl
*
aGraph
uint32_t
aRequestedInputChannelCount
)
{
mRequestedInputChannelCount
=
aRequestedInputChannelCount
;
aGraph
-
>
ReevaluateInputDevice
(
)
;
}
void
AudioInputProcessing
:
:
Start
(
)
{
mEnabled
=
true
;
mLiveBufferingAppended
=
Nothing
(
)
;
}
void
AudioInputProcessing
:
:
Stop
(
)
{
mEnabled
=
false
;
}
void
AudioInputProcessing
:
:
Pull
(
MediaTrackGraphImpl
*
aGraph
GraphTime
aFrom
GraphTime
aTo
GraphTime
aTrackEnd
AudioSegment
*
aSegment
bool
aLastPullThisIteration
bool
*
aEnded
)
{
MOZ_ASSERT
(
aGraph
-
>
OnGraphThread
(
)
)
;
if
(
mEnded
)
{
*
aEnded
=
true
;
return
;
}
TrackTime
delta
=
aTo
-
aTrackEnd
;
MOZ_ASSERT
(
delta
>
=
0
"
We
shouldn
'
t
append
more
than
requested
"
)
;
TrackTime
buffering
=
0
;
buffering
+
=
WEBAUDIO_BLOCK_SIZE
;
if
(
!
PassThrough
(
aGraph
)
&
&
mPacketizerInput
)
{
buffering
+
=
mPacketizerInput
-
>
mPacketSize
;
}
if
(
delta
<
=
0
)
{
return
;
}
if
(
MOZ_LIKELY
(
mLiveBufferingAppended
)
)
{
if
(
MOZ_UNLIKELY
(
buffering
>
*
mLiveBufferingAppended
)
)
{
TrackTime
silence
=
buffering
-
*
mLiveBufferingAppended
;
LOG_FRAME
(
"
AudioInputProcessing
%
p
Inserting
%
"
PRId64
"
frames
of
silence
due
to
buffer
increase
"
this
silence
)
;
mSegment
.
InsertNullDataAtStart
(
silence
)
;
mLiveBufferingAppended
=
Some
(
buffering
)
;
}
else
if
(
MOZ_UNLIKELY
(
buffering
<
*
mLiveBufferingAppended
)
)
{
MOZ_ASSERT
(
PassThrough
(
aGraph
)
"
Must
have
turned
on
passthrough
"
)
;
TrackTime
removal
=
*
mLiveBufferingAppended
-
buffering
;
MOZ_ASSERT
(
mSegment
.
GetDuration
(
)
>
=
removal
)
;
TrackTime
frames
=
std
:
:
min
(
mSegment
.
GetDuration
(
)
removal
)
;
LOG_FRAME
(
"
AudioInputProcessing
%
p
Removing
%
"
PRId64
"
frames
of
silence
due
to
buffer
decrease
"
this
frames
)
;
*
mLiveBufferingAppended
-
=
frames
;
mSegment
.
RemoveLeading
(
frames
)
;
}
}
if
(
mSegment
.
GetDuration
(
)
>
0
)
{
MOZ_ASSERT
(
buffering
=
=
*
mLiveBufferingAppended
)
;
TrackTime
frames
=
std
:
:
min
(
mSegment
.
GetDuration
(
)
delta
)
;
LOG_FRAME
(
"
AudioInputProcessing
%
p
Appending
%
"
PRId64
"
frames
of
real
data
for
%
u
channels
.
"
this
frames
mRequestedInputChannelCount
)
;
aSegment
-
>
AppendSlice
(
mSegment
0
frames
)
;
mSegment
.
RemoveLeading
(
frames
)
;
delta
-
=
frames
;
MOZ_ASSERT_IF
(
aLastPullThisIteration
mSegment
.
GetDuration
(
)
<
=
buffering
)
;
}
if
(
delta
<
=
0
)
{
if
(
mSegment
.
GetDuration
(
)
=
=
0
)
{
mLiveBufferingAppended
=
Some
(
-
delta
)
;
}
return
;
}
LOG_FRAME
(
"
AudioInputProcessing
%
p
Pulling
%
"
PRId64
"
frames
of
silence
for
%
u
channels
.
"
this
delta
mRequestedInputChannelCount
)
;
MOZ_ASSERT_IF
(
mEnabled
!
mLiveBufferingAppended
)
;
mLiveBufferingAppended
=
Nothing
(
)
;
aSegment
-
>
AppendNullData
(
delta
)
;
}
void
AudioInputProcessing
:
:
NotifyOutputData
(
MediaTrackGraphImpl
*
aGraph
AudioDataValue
*
aBuffer
size_t
aFrames
TrackRate
aRate
uint32_t
aChannels
)
{
MOZ_ASSERT
(
aGraph
-
>
OnGraphThread
(
)
)
;
MOZ_ASSERT
(
mEnabled
)
;
if
(
PassThrough
(
aGraph
)
)
{
return
;
}
if
(
!
mPacketizerOutput
|
|
mPacketizerOutput
-
>
mPacketSize
!
=
aRate
/
100u
|
|
mPacketizerOutput
-
>
mChannels
!
=
aChannels
)
{
mPacketizerOutput
=
MakeUnique
<
AudioPacketizer
<
AudioDataValue
float
>
>
(
aRate
/
100
aChannels
)
;
}
mPacketizerOutput
-
>
Input
(
aBuffer
aFrames
)
;
while
(
mPacketizerOutput
-
>
PacketsAvailable
(
)
)
{
uint32_t
samplesPerPacket
=
mPacketizerOutput
-
>
mPacketSize
*
mPacketizerOutput
-
>
mChannels
;
if
(
mOutputBuffer
.
Length
(
)
<
samplesPerPacket
)
{
mOutputBuffer
.
SetLength
(
samplesPerPacket
)
;
}
if
(
mDeinterleavedBuffer
.
Length
(
)
<
samplesPerPacket
)
{
mDeinterleavedBuffer
.
SetLength
(
samplesPerPacket
)
;
}
float
*
packet
=
mOutputBuffer
.
Data
(
)
;
mPacketizerOutput
-
>
Output
(
packet
)
;
AutoTArray
<
float
*
MAX_CHANNELS
>
deinterleavedPacketDataChannelPointers
;
float
*
interleavedFarend
=
nullptr
;
uint32_t
channelCountFarend
=
0
;
uint32_t
framesPerPacketFarend
=
0
;
if
(
aChannels
>
MAX_CHANNELS
)
{
AudioConverter
converter
(
AudioConfig
(
aChannels
0
AudioConfig
:
:
FORMAT_FLT
)
AudioConfig
(
MAX_CHANNELS
0
AudioConfig
:
:
FORMAT_FLT
)
)
;
framesPerPacketFarend
=
mPacketizerOutput
-
>
mPacketSize
;
framesPerPacketFarend
=
converter
.
Process
(
mInputDownmixBuffer
packet
framesPerPacketFarend
)
;
interleavedFarend
=
mInputDownmixBuffer
.
Data
(
)
;
channelCountFarend
=
MAX_CHANNELS
;
deinterleavedPacketDataChannelPointers
.
SetLength
(
MAX_CHANNELS
)
;
}
else
{
interleavedFarend
=
packet
;
channelCountFarend
=
aChannels
;
framesPerPacketFarend
=
mPacketizerOutput
-
>
mPacketSize
;
deinterleavedPacketDataChannelPointers
.
SetLength
(
aChannels
)
;
}
MOZ_ASSERT
(
interleavedFarend
&
&
(
channelCountFarend
=
=
1
|
|
channelCountFarend
=
=
2
)
&
&
framesPerPacketFarend
)
;
if
(
mInputBuffer
.
Length
(
)
<
framesPerPacketFarend
*
channelCountFarend
)
{
mInputBuffer
.
SetLength
(
framesPerPacketFarend
*
channelCountFarend
)
;
}
size_t
offset
=
0
;
for
(
size_t
i
=
0
;
i
<
deinterleavedPacketDataChannelPointers
.
Length
(
)
;
+
+
i
)
{
deinterleavedPacketDataChannelPointers
[
i
]
=
mInputBuffer
.
Data
(
)
+
offset
;
offset
+
=
framesPerPacketFarend
;
}
DeinterleaveAndConvertBuffer
(
interleavedFarend
framesPerPacketFarend
channelCountFarend
deinterleavedPacketDataChannelPointers
.
Elements
(
)
)
;
StreamConfig
inputConfig
(
aRate
channelCountFarend
false
)
;
StreamConfig
outputConfig
=
inputConfig
;
DebugOnly
<
int
>
err
=
mAudioProcessing
-
>
ProcessReverseStream
(
deinterleavedPacketDataChannelPointers
.
Elements
(
)
inputConfig
outputConfig
deinterleavedPacketDataChannelPointers
.
Elements
(
)
)
;
MOZ_ASSERT
(
!
err
"
Could
not
process
the
reverse
stream
.
"
)
;
}
}
void
AudioInputProcessing
:
:
PacketizeAndProcess
(
MediaTrackGraphImpl
*
aGraph
const
AudioDataValue
*
aBuffer
size_t
aFrames
TrackRate
aRate
uint32_t
aChannels
)
{
MOZ_ASSERT
(
!
PassThrough
(
aGraph
)
"
This
should
be
bypassed
when
in
PassThrough
mode
.
"
)
;
MOZ_ASSERT
(
mEnabled
)
;
size_t
offset
=
0
;
if
(
!
mPacketizerInput
|
|
mPacketizerInput
-
>
mPacketSize
!
=
aRate
/
100u
|
|
mPacketizerInput
-
>
mChannels
!
=
aChannels
)
{
mPacketizerInput
=
MakeUnique
<
AudioPacketizer
<
AudioDataValue
float
>
>
(
aRate
/
100
aChannels
)
;
}
LOG_FRAME
(
"
AudioInputProcessing
%
p
Appending
%
zu
frames
to
packetizer
"
this
aFrames
)
;
mPacketizerInput
-
>
Input
(
aBuffer
static_cast
<
uint32_t
>
(
aFrames
)
)
;
while
(
mPacketizerInput
-
>
PacketsAvailable
(
)
)
{
mPacketCount
+
+
;
uint32_t
samplesPerPacket
=
mPacketizerInput
-
>
mPacketSize
*
mPacketizerInput
-
>
mChannels
;
if
(
mInputBuffer
.
Length
(
)
<
samplesPerPacket
)
{
mInputBuffer
.
SetLength
(
samplesPerPacket
)
;
}
if
(
mDeinterleavedBuffer
.
Length
(
)
<
samplesPerPacket
)
{
mDeinterleavedBuffer
.
SetLength
(
samplesPerPacket
)
;
}
float
*
packet
=
mInputBuffer
.
Data
(
)
;
mPacketizerInput
-
>
Output
(
packet
)
;
AutoTArray
<
float
*
8
>
deinterleavedPacketizedInputDataChannelPointers
;
uint32_t
channelCountInput
=
0
;
if
(
aChannels
>
MAX_CHANNELS
)
{
channelCountInput
=
MONO
;
deinterleavedPacketizedInputDataChannelPointers
.
SetLength
(
channelCountInput
)
;
deinterleavedPacketizedInputDataChannelPointers
[
0
]
=
mDeinterleavedBuffer
.
Data
(
)
;
size_t
readIndex
=
0
;
for
(
size_t
i
=
0
;
i
<
mPacketizerInput
-
>
mPacketSize
;
i
+
+
)
{
mDeinterleavedBuffer
.
Data
(
)
[
i
]
=
0
.
;
for
(
size_t
j
=
0
;
j
<
aChannels
;
j
+
+
)
{
mDeinterleavedBuffer
.
Data
(
)
[
i
]
+
=
packet
[
readIndex
+
+
]
;
}
}
}
else
{
channelCountInput
=
aChannels
;
deinterleavedPacketizedInputDataChannelPointers
.
SetLength
(
channelCountInput
)
;
offset
=
0
;
for
(
size_t
i
=
0
;
i
<
deinterleavedPacketizedInputDataChannelPointers
.
Length
(
)
;
+
+
i
)
{
deinterleavedPacketizedInputDataChannelPointers
[
i
]
=
mDeinterleavedBuffer
.
Data
(
)
+
offset
;
offset
+
=
mPacketizerInput
-
>
mPacketSize
;
}
Deinterleave
(
packet
mPacketizerInput
-
>
mPacketSize
channelCountInput
deinterleavedPacketizedInputDataChannelPointers
.
Elements
(
)
)
;
}
StreamConfig
inputConfig
(
aRate
channelCountInput
false
)
;
StreamConfig
outputConfig
=
inputConfig
;
mAudioProcessing
-
>
set_stream_delay_ms
(
0
)
;
CheckedInt
<
size_t
>
bufferSize
(
sizeof
(
float
)
)
;
bufferSize
*
=
mPacketizerInput
-
>
mPacketSize
;
bufferSize
*
=
channelCountInput
;
RefPtr
<
SharedBuffer
>
buffer
=
SharedBuffer
:
:
Create
(
bufferSize
)
;
AutoTArray
<
float
*
8
>
processedOutputChannelPointers
;
AutoTArray
<
const
float
*
8
>
processedOutputChannelPointersConst
;
processedOutputChannelPointers
.
SetLength
(
channelCountInput
)
;
processedOutputChannelPointersConst
.
SetLength
(
channelCountInput
)
;
offset
=
0
;
for
(
size_t
i
=
0
;
i
<
processedOutputChannelPointers
.
Length
(
)
;
+
+
i
)
{
processedOutputChannelPointers
[
i
]
=
static_cast
<
float
*
>
(
buffer
-
>
Data
(
)
)
+
offset
;
processedOutputChannelPointersConst
[
i
]
=
static_cast
<
float
*
>
(
buffer
-
>
Data
(
)
)
+
offset
;
offset
+
=
mPacketizerInput
-
>
mPacketSize
;
}
mAudioProcessing
-
>
ProcessStream
(
deinterleavedPacketizedInputDataChannelPointers
.
Elements
(
)
inputConfig
outputConfig
processedOutputChannelPointers
.
Elements
(
)
)
;
if
(
MOZ_LOG_TEST
(
gMediaManagerLog
LogLevel
:
:
Debug
)
&
&
!
(
mPacketCount
%
50
)
)
{
AudioProcessingStats
stats
=
mAudioProcessing
-
>
GetStatistics
(
)
;
char
msg
[
1024
]
;
size_t
offset
=
0
;
#
define
AddIfValue
(
format
member
)
\
if
(
stats
.
member
.
has_value
(
)
)
{
\
offset
+
=
SprintfBuf
(
msg
+
offset
sizeof
(
msg
)
-
offset
\
#
member
"
:
"
format
"
"
stats
.
member
.
value
(
)
)
;
\
}
AddIfValue
(
"
%
d
"
output_rms_dbfs
)
;
AddIfValue
(
"
%
d
"
voice_detected
)
;
AddIfValue
(
"
%
lf
"
echo_return_loss
)
;
AddIfValue
(
"
%
lf
"
echo_return_loss_enhancement
)
;
AddIfValue
(
"
%
lf
"
divergent_filter_fraction
)
;
AddIfValue
(
"
%
d
"
delay_median_ms
)
;
AddIfValue
(
"
%
d
"
delay_standard_deviation_ms
)
;
AddIfValue
(
"
%
lf
"
residual_echo_likelihood
)
;
AddIfValue
(
"
%
lf
"
residual_echo_likelihood_recent_max
)
;
AddIfValue
(
"
%
d
"
delay_ms
)
;
#
undef
AddIfValue
LOG
(
"
AudioProcessing
statistics
:
%
s
"
msg
)
;
}
if
(
mEnded
)
{
continue
;
}
LOG_FRAME
(
"
AudioInputProcessing
%
p
Appending
%
u
frames
of
packetized
audio
"
this
mPacketizerInput
-
>
mPacketSize
)
;
MOZ_ASSERT
(
processedOutputChannelPointers
.
Length
(
)
=
=
channelCountInput
)
;
RefPtr
<
SharedBuffer
>
other
=
buffer
;
mSegment
.
AppendFrames
(
other
.
forget
(
)
processedOutputChannelPointersConst
static_cast
<
int32_t
>
(
mPacketizerInput
-
>
mPacketSize
)
mPrincipal
)
;
}
}
void
AudioInputProcessing
:
:
ProcessInput
(
MediaTrackGraphImpl
*
aGraph
const
AudioSegment
*
aSegment
)
{
MOZ_ASSERT
(
aGraph
)
;
MOZ_ASSERT
(
aGraph
-
>
OnGraphThread
(
)
)
;
if
(
mEnded
|
|
!
mEnabled
|
|
!
mLiveBufferingAppended
|
|
mPendingData
.
IsEmpty
(
)
)
{
return
;
}
if
(
PassThrough
(
aGraph
)
)
{
if
(
aSegment
&
&
!
aSegment
-
>
IsEmpty
(
)
)
{
mSegment
.
AppendSegment
(
aSegment
mPrincipal
)
;
}
else
{
mSegment
.
AppendFromInterleavedBuffer
(
mPendingData
.
Data
(
)
mPendingData
.
FrameCount
(
)
mPendingData
.
Channels
(
)
mPrincipal
)
;
}
}
else
{
MOZ_ASSERT
(
aGraph
-
>
GraphRate
(
)
=
=
mPendingData
.
Rate
(
)
)
;
PacketizeAndProcess
(
aGraph
mPendingData
.
Data
(
)
mPendingData
.
FrameCount
(
)
mPendingData
.
Rate
(
)
mPendingData
.
Channels
(
)
)
;
}
mPendingData
.
Clear
(
)
;
}
void
AudioInputProcessing
:
:
NotifyInputStopped
(
MediaTrackGraphImpl
*
aGraph
)
{
MOZ_ASSERT
(
aGraph
-
>
OnGraphThread
(
)
)
;
mLiveBufferingAppended
=
Nothing
(
)
;
mSegment
.
Clear
(
)
;
if
(
mPacketizerInput
)
{
mPacketizerInput
-
>
Clear
(
)
;
}
mPendingData
.
Clear
(
)
;
}
void
AudioInputProcessing
:
:
NotifyInputData
(
MediaTrackGraphImpl
*
aGraph
const
AudioDataValue
*
aBuffer
size_t
aFrames
TrackRate
aRate
uint32_t
aChannels
uint32_t
aAlreadyBuffered
)
{
MOZ_ASSERT
(
aGraph
-
>
OnGraphThread
(
)
)
;
TRACE
(
"
AudioInputProcessing
:
:
NotifyInputData
"
)
;
MOZ_ASSERT
(
mEnabled
)
;
if
(
!
mLiveBufferingAppended
)
{
mLiveBufferingAppended
=
Some
(
aAlreadyBuffered
)
;
}
mPendingData
.
Push
(
aBuffer
aFrames
aRate
aChannels
)
;
}
void
AudioInputProcessing
:
:
DeviceChanged
(
MediaTrackGraphImpl
*
aGraph
)
{
MOZ_ASSERT
(
aGraph
-
>
OnGraphThread
(
)
)
;
mAudioProcessing
-
>
Initialize
(
)
;
}
void
AudioInputProcessing
:
:
ApplyConfig
(
MediaTrackGraphImpl
*
aGraph
const
AudioProcessing
:
:
Config
&
aConfig
)
{
MOZ_ASSERT
(
aGraph
-
>
OnGraphThread
(
)
)
;
mAudioProcessing
-
>
ApplyConfig
(
aConfig
)
;
}
void
AudioInputProcessing
:
:
End
(
)
{
mEnded
=
true
;
mSegment
.
Clear
(
)
;
mPendingData
.
Clear
(
)
;
}
TrackTime
AudioInputProcessing
:
:
NumBufferedFrames
(
MediaTrackGraphImpl
*
aGraph
)
const
{
MOZ_ASSERT
(
aGraph
-
>
OnGraphThread
(
)
)
;
return
mSegment
.
GetDuration
(
)
;
}
void
AudioInputTrack
:
:
Destroy
(
)
{
MOZ_ASSERT
(
NS_IsMainThread
(
)
)
;
CloseAudioInput
(
)
;
MediaTrack
:
:
Destroy
(
)
;
}
void
AudioInputTrack
:
:
SetInputProcessing
(
RefPtr
<
AudioInputProcessing
>
aInputProcessing
)
{
class
Message
:
public
ControlMessage
{
const
RefPtr
<
AudioInputTrack
>
mTrack
;
const
RefPtr
<
AudioInputProcessing
>
mProcessing
;
public
:
Message
(
RefPtr
<
AudioInputTrack
>
aTrack
RefPtr
<
AudioInputProcessing
>
aProcessing
)
:
ControlMessage
(
aTrack
)
mTrack
(
std
:
:
move
(
aTrack
)
)
mProcessing
(
std
:
:
move
(
aProcessing
)
)
{
}
void
Run
(
)
override
{
TRACE
(
"
AudioInputTrack
:
:
SetInputProcessingImpl
"
)
;
mTrack
-
>
SetInputProcessingImpl
(
mProcessing
)
;
}
}
;
if
(
IsDestroyed
(
)
)
{
return
;
}
GraphImpl
(
)
-
>
AppendMessage
(
MakeUnique
<
Message
>
(
std
:
:
move
(
this
)
std
:
:
move
(
aInputProcessing
)
)
)
;
}
AudioInputTrack
*
AudioInputTrack
:
:
Create
(
MediaTrackGraph
*
aGraph
)
{
MOZ_ASSERT
(
NS_IsMainThread
(
)
)
;
AudioInputTrack
*
track
=
new
AudioInputTrack
(
aGraph
-
>
GraphRate
(
)
)
;
aGraph
-
>
AddTrack
(
track
)
;
return
track
;
}
void
AudioInputTrack
:
:
DestroyImpl
(
)
{
ProcessedMediaTrack
:
:
DestroyImpl
(
)
;
if
(
mInputProcessing
)
{
mInputProcessing
-
>
End
(
)
;
}
}
void
AudioInputTrack
:
:
ProcessInput
(
GraphTime
aFrom
GraphTime
aTo
uint32_t
aFlags
)
{
TRACE_COMMENT
(
"
AudioInputTrack
:
:
ProcessInput
"
"
AudioInputTrack
%
p
"
this
)
;
NativeInputTrack
*
source
=
nullptr
;
if
(
!
mInputs
.
IsEmpty
(
)
)
{
for
(
const
MediaInputPort
*
input
:
mInputs
)
{
MOZ_ASSERT
(
input
-
>
GetSource
(
)
)
;
if
(
input
-
>
GetSource
(
)
-
>
AsNativeInputTrack
(
)
)
{
source
=
input
-
>
GetSource
(
)
-
>
AsNativeInputTrack
(
)
;
break
;
}
}
}
if
(
source
)
{
MOZ_ASSERT
(
source
-
>
GraphImpl
(
)
=
=
GraphImpl
(
)
)
;
MOZ_ASSERT
(
source
-
>
mSampleRate
=
=
mSampleRate
)
;
MOZ_ASSERT
(
GraphImpl
(
)
-
>
GraphRate
(
)
=
=
mSampleRate
)
;
mInputProcessing
-
>
ProcessInput
(
GraphImpl
(
)
source
-
>
GetData
<
AudioSegment
>
(
)
)
;
}
bool
ended
=
false
;
mInputProcessing
-
>
Pull
(
GraphImpl
(
)
aFrom
aTo
TrackTimeToGraphTime
(
GetEnd
(
)
)
GetData
<
AudioSegment
>
(
)
aTo
=
=
GraphImpl
(
)
-
>
mStateComputedTime
&
ended
)
;
ApplyTrackDisabling
(
mSegment
.
get
(
)
)
;
if
(
ended
&
&
(
aFlags
&
ALLOW_END
)
)
{
mEnded
=
true
;
}
}
void
AudioInputTrack
:
:
SetInputProcessingImpl
(
RefPtr
<
AudioInputProcessing
>
aInputProcessing
)
{
MOZ_ASSERT
(
GraphImpl
(
)
-
>
OnGraphThread
(
)
)
;
mInputProcessing
=
std
:
:
move
(
aInputProcessing
)
;
}
nsresult
AudioInputTrack
:
:
OpenAudioInput
(
CubebUtils
:
:
AudioDeviceID
aId
AudioDataListener
*
aListener
)
{
MOZ_ASSERT
(
NS_IsMainThread
(
)
)
;
MOZ_ASSERT
(
GraphImpl
(
)
)
;
MOZ_ASSERT
(
!
mInputListener
)
;
MOZ_ASSERT
(
mDeviceId
.
isNothing
(
)
)
;
mInputListener
=
aListener
;
ProcessedMediaTrack
*
input
=
GraphImpl
(
)
-
>
GetDeviceTrack
(
aId
)
;
MOZ_ASSERT
(
input
)
;
LOG
(
"
Open
device
%
p
(
InputTrack
=
%
p
)
for
Mic
source
%
p
"
aId
input
this
)
;
mPort
=
AllocateInputPort
(
input
)
;
mDeviceId
.
emplace
(
aId
)
;
return
GraphImpl
(
)
-
>
OpenAudioInput
(
aId
aListener
)
;
}
void
AudioInputTrack
:
:
CloseAudioInput
(
)
{
MOZ_ASSERT
(
NS_IsMainThread
(
)
)
;
MOZ_ASSERT
(
GraphImpl
(
)
)
;
if
(
!
mInputListener
)
{
return
;
}
MOZ_ASSERT
(
mPort
)
;
MOZ_ASSERT
(
mDeviceId
.
isSome
(
)
)
;
LOG
(
"
Close
device
%
p
(
InputTrack
=
%
p
)
for
Mic
source
%
p
"
mDeviceId
.
value
(
)
mPort
-
>
GetSource
(
)
this
)
;
mPort
-
>
Destroy
(
)
;
GraphImpl
(
)
-
>
CloseAudioInput
(
mDeviceId
.
extract
(
)
mInputListener
)
;
mInputListener
=
nullptr
;
}
Maybe
<
CubebUtils
:
:
AudioDeviceID
>
AudioInputTrack
:
:
DeviceId
(
)
const
{
MOZ_ASSERT
(
NS_IsMainThread
(
)
)
;
return
mDeviceId
;
}
nsString
MediaEngineWebRTCAudioCaptureSource
:
:
GetName
(
)
const
{
return
u
"
AudioCapture
"
_ns
;
}
nsCString
MediaEngineWebRTCAudioCaptureSource
:
:
GetUUID
(
)
const
{
nsID
uuid
{
}
;
char
uuidBuffer
[
NSID_LENGTH
]
;
nsCString
asciiString
;
ErrorResult
rv
;
rv
=
nsContentUtils
:
:
GenerateUUIDInPlace
(
uuid
)
;
if
(
rv
.
Failed
(
)
)
{
return
"
"
_ns
;
}
uuid
.
ToProvidedString
(
uuidBuffer
)
;
asciiString
.
AssignASCII
(
uuidBuffer
)
;
return
nsCString
(
Substring
(
asciiString
1
NSID_LENGTH
-
3
)
)
;
}
nsString
MediaEngineWebRTCAudioCaptureSource
:
:
GetGroupId
(
)
const
{
return
u
"
AudioCaptureGroup
"
_ns
;
}
void
MediaEngineWebRTCAudioCaptureSource
:
:
SetTrack
(
const
RefPtr
<
MediaTrack
>
&
aTrack
const
PrincipalHandle
&
aPrincipalHandle
)
{
AssertIsOnOwningThread
(
)
;
}
nsresult
MediaEngineWebRTCAudioCaptureSource
:
:
Start
(
)
{
AssertIsOnOwningThread
(
)
;
return
NS_OK
;
}
nsresult
MediaEngineWebRTCAudioCaptureSource
:
:
Stop
(
)
{
AssertIsOnOwningThread
(
)
;
return
NS_OK
;
}
nsresult
MediaEngineWebRTCAudioCaptureSource
:
:
Reconfigure
(
const
dom
:
:
MediaTrackConstraints
&
aConstraints
const
MediaEnginePrefs
&
aPrefs
const
char
*
*
aOutBadConstraint
)
{
return
NS_OK
;
}
void
MediaEngineWebRTCAudioCaptureSource
:
:
GetSettings
(
dom
:
:
MediaTrackSettings
&
aOutSettings
)
const
{
aOutSettings
.
mAutoGainControl
.
Construct
(
false
)
;
aOutSettings
.
mEchoCancellation
.
Construct
(
false
)
;
aOutSettings
.
mNoiseSuppression
.
Construct
(
false
)
;
aOutSettings
.
mChannelCount
.
Construct
(
1
)
;
}
}
