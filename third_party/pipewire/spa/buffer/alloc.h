#
ifndef
SPA_BUFFER_ALLOC_H
#
define
SPA_BUFFER_ALLOC_H
#
ifdef
__cplusplus
extern
"
C
"
{
#
endif
#
include
<
spa
/
buffer
/
buffer
.
h
>
struct
spa_buffer_alloc_info
{
#
define
SPA_BUFFER_ALLOC_FLAG_INLINE_META
(
1
<
<
0
)
/
*
*
<
add
metadata
data
in
the
skeleton
*
/
#
define
SPA_BUFFER_ALLOC_FLAG_INLINE_CHUNK
(
1
<
<
1
)
/
*
*
<
add
chunk
data
in
the
skeleton
*
/
#
define
SPA_BUFFER_ALLOC_FLAG_INLINE_DATA
(
1
<
<
2
)
/
*
*
<
add
buffer
data
to
the
skeleton
*
/
#
define
SPA_BUFFER_ALLOC_FLAG_INLINE_ALL
0b111
#
define
SPA_BUFFER_ALLOC_FLAG_NO_DATA
(
1
<
<
3
)
/
*
*
<
don
'
t
set
data
pointers
*
/
uint32_t
flags
;
uint32_t
max_align
;
uint32_t
n_metas
;
uint32_t
n_datas
;
struct
spa_meta
*
metas
;
struct
spa_data
*
datas
;
uint32_t
*
data_aligns
;
size_t
skel_size
;
size_t
meta_size
;
size_t
chunk_size
;
size_t
data_size
;
size_t
mem_size
;
}
;
static
inline
int
spa_buffer_alloc_fill_info
(
struct
spa_buffer_alloc_info
*
info
uint32_t
n_metas
struct
spa_meta
metas
[
]
uint32_t
n_datas
struct
spa_data
datas
[
]
uint32_t
data_aligns
[
]
)
{
size_t
size
*
target
;
uint32_t
i
;
info
-
>
n_metas
=
n_metas
;
info
-
>
metas
=
metas
;
info
-
>
n_datas
=
n_datas
;
info
-
>
datas
=
datas
;
info
-
>
data_aligns
=
data_aligns
;
info
-
>
max_align
=
16
;
info
-
>
mem_size
=
0
;
info
-
>
skel_size
=
sizeof
(
struct
spa_buffer
)
;
info
-
>
skel_size
+
=
n_metas
*
sizeof
(
struct
spa_meta
)
;
info
-
>
skel_size
+
=
n_datas
*
sizeof
(
struct
spa_data
)
;
for
(
i
=
0
size
=
0
;
i
<
n_metas
;
i
+
+
)
size
+
=
SPA_ROUND_UP_N
(
metas
[
i
]
.
size
8
)
;
info
-
>
meta_size
=
size
;
if
(
SPA_FLAG_IS_SET
(
info
-
>
flags
SPA_BUFFER_ALLOC_FLAG_INLINE_META
)
)
target
=
&
info
-
>
skel_size
;
else
target
=
&
info
-
>
mem_size
;
*
target
+
=
info
-
>
meta_size
;
info
-
>
chunk_size
=
n_datas
*
sizeof
(
struct
spa_chunk
)
;
if
(
SPA_FLAG_IS_SET
(
info
-
>
flags
SPA_BUFFER_ALLOC_FLAG_INLINE_CHUNK
)
)
target
=
&
info
-
>
skel_size
;
else
target
=
&
info
-
>
mem_size
;
*
target
+
=
info
-
>
chunk_size
;
for
(
i
=
0
size
=
0
;
i
<
n_datas
;
i
+
+
)
{
info
-
>
max_align
=
SPA_MAX
(
info
-
>
max_align
data_aligns
[
i
]
)
;
size
=
SPA_ROUND_UP_N
(
size
data_aligns
[
i
]
)
;
size
+
=
datas
[
i
]
.
maxsize
;
}
info
-
>
data_size
=
size
;
if
(
!
SPA_FLAG_IS_SET
(
info
-
>
flags
SPA_BUFFER_ALLOC_FLAG_NO_DATA
)
&
&
SPA_FLAG_IS_SET
(
info
-
>
flags
SPA_BUFFER_ALLOC_FLAG_INLINE_DATA
)
)
target
=
&
info
-
>
skel_size
;
else
target
=
&
info
-
>
mem_size
;
*
target
=
SPA_ROUND_UP_N
(
*
target
n_datas
?
data_aligns
[
0
]
:
1
)
;
*
target
+
=
info
-
>
data_size
;
*
target
=
SPA_ROUND_UP_N
(
*
target
info
-
>
max_align
)
;
return
0
;
}
static
inline
struct
spa_buffer
*
spa_buffer_alloc_layout
(
struct
spa_buffer_alloc_info
*
info
void
*
skel_mem
void
*
data_mem
)
{
struct
spa_buffer
*
b
=
(
struct
spa_buffer
*
)
skel_mem
;
size_t
size
;
uint32_t
i
;
void
*
*
dp
*
skel
*
data
;
struct
spa_chunk
*
cp
;
b
-
>
n_metas
=
info
-
>
n_metas
;
b
-
>
metas
=
SPA_PTROFF
(
b
sizeof
(
struct
spa_buffer
)
struct
spa_meta
)
;
b
-
>
n_datas
=
info
-
>
n_datas
;
b
-
>
datas
=
SPA_PTROFF
(
b
-
>
metas
info
-
>
n_metas
*
sizeof
(
struct
spa_meta
)
struct
spa_data
)
;
skel
=
SPA_PTROFF
(
b
-
>
datas
info
-
>
n_datas
*
sizeof
(
struct
spa_data
)
void
)
;
data
=
data_mem
;
if
(
SPA_FLAG_IS_SET
(
info
-
>
flags
SPA_BUFFER_ALLOC_FLAG_INLINE_META
)
)
dp
=
&
skel
;
else
dp
=
&
data
;
for
(
i
=
0
;
i
<
info
-
>
n_metas
;
i
+
+
)
{
struct
spa_meta
*
m
=
&
b
-
>
metas
[
i
]
;
*
m
=
info
-
>
metas
[
i
]
;
m
-
>
data
=
*
dp
;
*
dp
=
SPA_PTROFF
(
*
dp
SPA_ROUND_UP_N
(
m
-
>
size
8
)
void
)
;
}
size
=
info
-
>
n_datas
*
sizeof
(
struct
spa_chunk
)
;
if
(
SPA_FLAG_IS_SET
(
info
-
>
flags
SPA_BUFFER_ALLOC_FLAG_INLINE_CHUNK
)
)
{
cp
=
(
struct
spa_chunk
*
)
skel
;
skel
=
SPA_PTROFF
(
skel
size
void
)
;
}
else
{
cp
=
(
struct
spa_chunk
*
)
data
;
data
=
SPA_PTROFF
(
data
size
void
)
;
}
if
(
SPA_FLAG_IS_SET
(
info
-
>
flags
SPA_BUFFER_ALLOC_FLAG_INLINE_DATA
)
)
dp
=
&
skel
;
else
dp
=
&
data
;
for
(
i
=
0
;
i
<
info
-
>
n_datas
;
i
+
+
)
{
struct
spa_data
*
d
=
&
b
-
>
datas
[
i
]
;
*
d
=
info
-
>
datas
[
i
]
;
d
-
>
chunk
=
&
cp
[
i
]
;
if
(
!
SPA_FLAG_IS_SET
(
info
-
>
flags
SPA_BUFFER_ALLOC_FLAG_NO_DATA
)
)
{
*
dp
=
SPA_PTR_ALIGN
(
*
dp
info
-
>
data_aligns
[
i
]
void
)
;
d
-
>
data
=
*
dp
;
*
dp
=
SPA_PTROFF
(
*
dp
d
-
>
maxsize
void
)
;
}
}
return
b
;
}
static
inline
int
spa_buffer_alloc_layout_array
(
struct
spa_buffer_alloc_info
*
info
uint32_t
n_buffers
struct
spa_buffer
*
buffers
[
]
void
*
skel_mem
void
*
data_mem
)
{
uint32_t
i
;
for
(
i
=
0
;
i
<
n_buffers
;
i
+
+
)
{
buffers
[
i
]
=
spa_buffer_alloc_layout
(
info
skel_mem
data_mem
)
;
skel_mem
=
SPA_PTROFF
(
skel_mem
info
-
>
skel_size
void
)
;
data_mem
=
SPA_PTROFF
(
data_mem
info
-
>
mem_size
void
)
;
}
return
0
;
}
static
inline
struct
spa_buffer
*
*
spa_buffer_alloc_array
(
uint32_t
n_buffers
uint32_t
flags
uint32_t
n_metas
struct
spa_meta
metas
[
]
uint32_t
n_datas
struct
spa_data
datas
[
]
uint32_t
data_aligns
[
]
)
{
struct
spa_buffer
*
*
buffers
;
struct
spa_buffer_alloc_info
info
=
{
flags
|
SPA_BUFFER_ALLOC_FLAG_INLINE_ALL
}
;
void
*
skel
;
spa_buffer_alloc_fill_info
(
&
info
n_metas
metas
n_datas
datas
data_aligns
)
;
buffers
=
(
struct
spa_buffer
*
*
)
calloc
(
1
info
.
max_align
+
n_buffers
*
(
sizeof
(
struct
spa_buffer
*
)
+
info
.
skel_size
)
)
;
if
(
buffers
=
=
NULL
)
return
NULL
;
skel
=
SPA_PTROFF
(
buffers
sizeof
(
struct
spa_buffer
*
)
*
n_buffers
void
)
;
skel
=
SPA_PTR_ALIGN
(
skel
info
.
max_align
void
)
;
spa_buffer_alloc_layout_array
(
&
info
n_buffers
buffers
skel
NULL
)
;
return
buffers
;
}
#
ifdef
__cplusplus
}
#
endif
#
endif
