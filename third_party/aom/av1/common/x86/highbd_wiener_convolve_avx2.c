#
include
<
immintrin
.
h
>
#
include
<
assert
.
h
>
#
include
"
config
/
aom_dsp_rtcd
.
h
"
#
include
"
av1
/
common
/
convolve
.
h
"
#
include
"
aom_dsp
/
aom_dsp_common
.
h
"
#
include
"
aom_dsp
/
aom_filter
.
h
"
#
include
"
aom_dsp
/
x86
/
synonyms
.
h
"
#
include
"
aom_dsp
/
x86
/
synonyms_avx2
.
h
"
void
av1_highbd_wiener_convolve_add_src_avx2
(
const
uint8_t
*
src8
ptrdiff_t
src_stride
uint8_t
*
dst8
ptrdiff_t
dst_stride
const
int16_t
*
filter_x
int
x_step_q4
const
int16_t
*
filter_y
int
y_step_q4
int
w
int
h
const
ConvolveParams
*
conv_params
int
bd
)
{
assert
(
x_step_q4
=
=
16
&
&
y_step_q4
=
=
16
)
;
assert
(
!
(
w
&
7
)
)
;
assert
(
bd
+
FILTER_BITS
-
conv_params
-
>
round_0
+
2
<
=
16
)
;
(
void
)
x_step_q4
;
(
void
)
y_step_q4
;
const
uint16_t
*
const
src
=
CONVERT_TO_SHORTPTR
(
src8
)
;
uint16_t
*
const
dst
=
CONVERT_TO_SHORTPTR
(
dst8
)
;
DECLARE_ALIGNED
(
32
uint16_t
temp
[
(
MAX_SB_SIZE
+
SUBPEL_TAPS
-
1
)
*
MAX_SB_SIZE
]
)
;
int
intermediate_height
=
h
+
SUBPEL_TAPS
-
1
;
const
int
center_tap
=
(
(
SUBPEL_TAPS
-
1
)
/
2
)
;
const
uint16_t
*
const
src_ptr
=
src
-
center_tap
*
src_stride
-
center_tap
;
const
__m128i
zero_128
=
_mm_setzero_si128
(
)
;
const
__m256i
zero_256
=
_mm256_setzero_si256
(
)
;
const
__m128i
offset
=
_mm_insert_epi16
(
zero_128
1
<
<
FILTER_BITS
3
)
;
const
__m256i
clamp_low
=
zero_256
;
{
const
__m256i
clamp_high_ep
=
_mm256_set1_epi16
(
WIENER_CLAMP_LIMIT
(
conv_params
-
>
round_0
bd
)
-
1
)
;
const
__m128i
coeffs_x
=
_mm_add_epi16
(
xx_loadu_128
(
filter_x
)
offset
)
;
const
__m128i
coeffs_0123
=
_mm_unpacklo_epi32
(
coeffs_x
coeffs_x
)
;
const
__m128i
coeffs_4567
=
_mm_unpackhi_epi32
(
coeffs_x
coeffs_x
)
;
const
__m128i
coeffs_01_128
=
_mm_unpacklo_epi64
(
coeffs_0123
coeffs_0123
)
;
const
__m128i
coeffs_23_128
=
_mm_unpackhi_epi64
(
coeffs_0123
coeffs_0123
)
;
const
__m128i
coeffs_45_128
=
_mm_unpacklo_epi64
(
coeffs_4567
coeffs_4567
)
;
const
__m128i
coeffs_67_128
=
_mm_unpackhi_epi64
(
coeffs_4567
coeffs_4567
)
;
const
__m256i
coeffs_01
=
yy_set_m128i
(
coeffs_01_128
coeffs_01_128
)
;
const
__m256i
coeffs_23
=
yy_set_m128i
(
coeffs_23_128
coeffs_23_128
)
;
const
__m256i
coeffs_45
=
yy_set_m128i
(
coeffs_45_128
coeffs_45_128
)
;
const
__m256i
coeffs_67
=
yy_set_m128i
(
coeffs_67_128
coeffs_67_128
)
;
const
__m256i
round_const
=
_mm256_set1_epi32
(
(
1
<
<
(
conv_params
-
>
round_0
-
1
)
)
+
(
1
<
<
(
bd
+
FILTER_BITS
-
1
)
)
)
;
for
(
int
i
=
0
;
i
<
intermediate_height
;
+
+
i
)
{
for
(
int
j
=
0
;
j
<
w
;
j
+
=
16
)
{
const
uint16_t
*
src_ij
=
src_ptr
+
i
*
src_stride
+
j
;
const
__m256i
src_0
=
yy_loadu_256
(
src_ij
+
0
)
;
const
__m256i
src_1
=
yy_loadu_256
(
src_ij
+
1
)
;
const
__m256i
src_2
=
yy_loadu_256
(
src_ij
+
2
)
;
const
__m256i
src_3
=
yy_loadu_256
(
src_ij
+
3
)
;
const
__m256i
src_4
=
yy_loadu_256
(
src_ij
+
4
)
;
const
__m256i
src_5
=
yy_loadu_256
(
src_ij
+
5
)
;
const
__m256i
src_6
=
yy_loadu_256
(
src_ij
+
6
)
;
const
__m256i
src_7
=
yy_loadu_256
(
src_ij
+
7
)
;
const
__m256i
res_0
=
_mm256_madd_epi16
(
src_0
coeffs_01
)
;
const
__m256i
res_1
=
_mm256_madd_epi16
(
src_1
coeffs_01
)
;
const
__m256i
res_2
=
_mm256_madd_epi16
(
src_2
coeffs_23
)
;
const
__m256i
res_3
=
_mm256_madd_epi16
(
src_3
coeffs_23
)
;
const
__m256i
res_4
=
_mm256_madd_epi16
(
src_4
coeffs_45
)
;
const
__m256i
res_5
=
_mm256_madd_epi16
(
src_5
coeffs_45
)
;
const
__m256i
res_6
=
_mm256_madd_epi16
(
src_6
coeffs_67
)
;
const
__m256i
res_7
=
_mm256_madd_epi16
(
src_7
coeffs_67
)
;
const
__m256i
res_even_sum
=
_mm256_add_epi32
(
_mm256_add_epi32
(
res_0
res_4
)
_mm256_add_epi32
(
res_2
res_6
)
)
;
const
__m256i
res_even
=
_mm256_srai_epi32
(
_mm256_add_epi32
(
res_even_sum
round_const
)
conv_params
-
>
round_0
)
;
const
__m256i
res_odd_sum
=
_mm256_add_epi32
(
_mm256_add_epi32
(
res_1
res_5
)
_mm256_add_epi32
(
res_3
res_7
)
)
;
const
__m256i
res_odd
=
_mm256_srai_epi32
(
_mm256_add_epi32
(
res_odd_sum
round_const
)
conv_params
-
>
round_0
)
;
const
__m256i
res
=
_mm256_packs_epi32
(
res_even
res_odd
)
;
const
__m256i
res_clamped
=
_mm256_min_epi16
(
_mm256_max_epi16
(
res
clamp_low
)
clamp_high_ep
)
;
yy_storeu_256
(
temp
+
i
*
MAX_SB_SIZE
+
j
res_clamped
)
;
}
}
}
{
const
__m256i
clamp_high
=
_mm256_set1_epi16
(
(
1
<
<
bd
)
-
1
)
;
const
__m128i
coeffs_y
=
_mm_add_epi16
(
xx_loadu_128
(
filter_y
)
offset
)
;
const
__m128i
coeffs_0123
=
_mm_unpacklo_epi32
(
coeffs_y
coeffs_y
)
;
const
__m128i
coeffs_4567
=
_mm_unpackhi_epi32
(
coeffs_y
coeffs_y
)
;
const
__m128i
coeffs_01_128
=
_mm_unpacklo_epi64
(
coeffs_0123
coeffs_0123
)
;
const
__m128i
coeffs_23_128
=
_mm_unpackhi_epi64
(
coeffs_0123
coeffs_0123
)
;
const
__m128i
coeffs_45_128
=
_mm_unpacklo_epi64
(
coeffs_4567
coeffs_4567
)
;
const
__m128i
coeffs_67_128
=
_mm_unpackhi_epi64
(
coeffs_4567
coeffs_4567
)
;
const
__m256i
coeffs_01
=
yy_set_m128i
(
coeffs_01_128
coeffs_01_128
)
;
const
__m256i
coeffs_23
=
yy_set_m128i
(
coeffs_23_128
coeffs_23_128
)
;
const
__m256i
coeffs_45
=
yy_set_m128i
(
coeffs_45_128
coeffs_45_128
)
;
const
__m256i
coeffs_67
=
yy_set_m128i
(
coeffs_67_128
coeffs_67_128
)
;
const
__m256i
round_const
=
_mm256_set1_epi32
(
(
1
<
<
(
conv_params
-
>
round_1
-
1
)
)
-
(
1
<
<
(
bd
+
conv_params
-
>
round_1
-
1
)
)
)
;
for
(
int
i
=
0
;
i
<
h
;
+
+
i
)
{
for
(
int
j
=
0
;
j
<
w
;
j
+
=
16
)
{
const
uint16_t
*
temp_ij
=
temp
+
i
*
MAX_SB_SIZE
+
j
;
const
__m256i
data_0
=
yy_loadu_256
(
temp_ij
+
0
*
MAX_SB_SIZE
)
;
const
__m256i
data_1
=
yy_loadu_256
(
temp_ij
+
1
*
MAX_SB_SIZE
)
;
const
__m256i
data_2
=
yy_loadu_256
(
temp_ij
+
2
*
MAX_SB_SIZE
)
;
const
__m256i
data_3
=
yy_loadu_256
(
temp_ij
+
3
*
MAX_SB_SIZE
)
;
const
__m256i
data_4
=
yy_loadu_256
(
temp_ij
+
4
*
MAX_SB_SIZE
)
;
const
__m256i
data_5
=
yy_loadu_256
(
temp_ij
+
5
*
MAX_SB_SIZE
)
;
const
__m256i
data_6
=
yy_loadu_256
(
temp_ij
+
6
*
MAX_SB_SIZE
)
;
const
__m256i
data_7
=
yy_loadu_256
(
temp_ij
+
7
*
MAX_SB_SIZE
)
;
const
__m256i
src_0
=
_mm256_unpacklo_epi16
(
data_0
data_1
)
;
const
__m256i
src_2
=
_mm256_unpacklo_epi16
(
data_2
data_3
)
;
const
__m256i
src_4
=
_mm256_unpacklo_epi16
(
data_4
data_5
)
;
const
__m256i
src_6
=
_mm256_unpacklo_epi16
(
data_6
data_7
)
;
const
__m256i
res_0
=
_mm256_madd_epi16
(
src_0
coeffs_01
)
;
const
__m256i
res_2
=
_mm256_madd_epi16
(
src_2
coeffs_23
)
;
const
__m256i
res_4
=
_mm256_madd_epi16
(
src_4
coeffs_45
)
;
const
__m256i
res_6
=
_mm256_madd_epi16
(
src_6
coeffs_67
)
;
const
__m256i
res_even
=
_mm256_add_epi32
(
_mm256_add_epi32
(
res_0
res_2
)
_mm256_add_epi32
(
res_4
res_6
)
)
;
const
__m256i
src_1
=
_mm256_unpackhi_epi16
(
data_0
data_1
)
;
const
__m256i
src_3
=
_mm256_unpackhi_epi16
(
data_2
data_3
)
;
const
__m256i
src_5
=
_mm256_unpackhi_epi16
(
data_4
data_5
)
;
const
__m256i
src_7
=
_mm256_unpackhi_epi16
(
data_6
data_7
)
;
const
__m256i
res_1
=
_mm256_madd_epi16
(
src_1
coeffs_01
)
;
const
__m256i
res_3
=
_mm256_madd_epi16
(
src_3
coeffs_23
)
;
const
__m256i
res_5
=
_mm256_madd_epi16
(
src_5
coeffs_45
)
;
const
__m256i
res_7
=
_mm256_madd_epi16
(
src_7
coeffs_67
)
;
const
__m256i
res_odd
=
_mm256_add_epi32
(
_mm256_add_epi32
(
res_1
res_3
)
_mm256_add_epi32
(
res_5
res_7
)
)
;
const
__m256i
res_lo
=
_mm256_unpacklo_epi32
(
res_even
res_odd
)
;
const
__m256i
res_hi
=
_mm256_unpackhi_epi32
(
res_even
res_odd
)
;
const
__m256i
res_lo_round
=
_mm256_srai_epi32
(
_mm256_add_epi32
(
res_lo
round_const
)
conv_params
-
>
round_1
)
;
const
__m256i
res_hi_round
=
_mm256_srai_epi32
(
_mm256_add_epi32
(
res_hi
round_const
)
conv_params
-
>
round_1
)
;
const
__m256i
res_16bit
=
_mm256_packs_epi32
(
res_lo_round
res_hi_round
)
;
const
__m256i
res_16bit_clamped
=
_mm256_min_epi16
(
_mm256_max_epi16
(
res_16bit
clamp_low
)
clamp_high
)
;
yy_storeu_256
(
dst
+
i
*
dst_stride
+
j
res_16bit_clamped
)
;
}
}
}
}
