#
include
<
tmmintrin
.
h
>
#
include
<
assert
.
h
>
#
include
"
.
/
aom_dsp_rtcd
.
h
"
#
include
"
aom_dsp
/
aom_convolve
.
h
"
#
include
"
aom_dsp
/
aom_dsp_common
.
h
"
#
include
"
aom_dsp
/
aom_filter
.
h
"
#
include
"
av1
/
common
/
convolve
.
h
"
#
if
CONFIG_COMPOUND_ROUND
void
av1_highbd_convolve_2d_ssse3
(
const
uint16_t
*
src
int
src_stride
CONV_BUF_TYPE
*
dst
int
dst_stride
int
w
int
h
InterpFilterParams
*
filter_params_x
InterpFilterParams
*
filter_params_y
const
int
subpel_x_q4
const
int
subpel_y_q4
ConvolveParams
*
conv_params
int
bd
)
{
DECLARE_ALIGNED
(
16
int16_t
im_block
[
(
MAX_SB_SIZE
+
MAX_FILTER_TAP
-
1
)
*
MAX_SB_SIZE
]
)
;
int
im_h
=
h
+
filter_params_y
-
>
taps
-
1
;
int
im_stride
=
MAX_SB_SIZE
;
int
i
j
;
const
int
fo_vert
=
filter_params_y
-
>
taps
/
2
-
1
;
const
int
fo_horiz
=
filter_params_x
-
>
taps
/
2
-
1
;
const
int
do_average
=
conv_params
-
>
do_average
;
const
uint16_t
*
const
src_ptr
=
src
-
fo_vert
*
src_stride
-
fo_horiz
;
{
const
int16_t
*
x_filter
=
av1_get_interp_filter_subpel_kernel
(
*
filter_params_x
subpel_x_q4
&
SUBPEL_MASK
)
;
const
__m128i
coeffs_x
=
_mm_loadu_si128
(
(
__m128i
*
)
x_filter
)
;
const
__m128i
tmp_0
=
_mm_unpacklo_epi32
(
coeffs_x
coeffs_x
)
;
const
__m128i
tmp_1
=
_mm_unpackhi_epi32
(
coeffs_x
coeffs_x
)
;
const
__m128i
coeff_01
=
_mm_unpacklo_epi64
(
tmp_0
tmp_0
)
;
const
__m128i
coeff_23
=
_mm_unpackhi_epi64
(
tmp_0
tmp_0
)
;
const
__m128i
coeff_45
=
_mm_unpacklo_epi64
(
tmp_1
tmp_1
)
;
const
__m128i
coeff_67
=
_mm_unpackhi_epi64
(
tmp_1
tmp_1
)
;
const
__m128i
round_const
=
_mm_set1_epi32
(
(
1
<
<
conv_params
-
>
round_0
)
>
>
1
)
;
const
__m128i
round_shift
=
_mm_cvtsi32_si128
(
conv_params
-
>
round_0
)
;
for
(
i
=
0
;
i
<
im_h
;
+
+
i
)
{
for
(
j
=
0
;
j
<
w
;
j
+
=
8
)
{
const
__m128i
data
=
_mm_loadu_si128
(
(
__m128i
*
)
&
src_ptr
[
i
*
src_stride
+
j
]
)
;
const
__m128i
data2
=
_mm_loadu_si128
(
(
__m128i
*
)
&
src_ptr
[
i
*
src_stride
+
j
+
8
]
)
;
const
__m128i
res_0
=
_mm_madd_epi16
(
data
coeff_01
)
;
const
__m128i
res_2
=
_mm_madd_epi16
(
_mm_alignr_epi8
(
data2
data
4
)
coeff_23
)
;
const
__m128i
res_4
=
_mm_madd_epi16
(
_mm_alignr_epi8
(
data2
data
8
)
coeff_45
)
;
const
__m128i
res_6
=
_mm_madd_epi16
(
_mm_alignr_epi8
(
data2
data
12
)
coeff_67
)
;
__m128i
res_even
=
_mm_add_epi32
(
_mm_add_epi32
(
res_0
res_4
)
_mm_add_epi32
(
res_2
res_6
)
)
;
res_even
=
_mm_sra_epi32
(
_mm_add_epi32
(
res_even
round_const
)
round_shift
)
;
const
__m128i
res_1
=
_mm_madd_epi16
(
_mm_alignr_epi8
(
data2
data
2
)
coeff_01
)
;
const
__m128i
res_3
=
_mm_madd_epi16
(
_mm_alignr_epi8
(
data2
data
6
)
coeff_23
)
;
const
__m128i
res_5
=
_mm_madd_epi16
(
_mm_alignr_epi8
(
data2
data
10
)
coeff_45
)
;
const
__m128i
res_7
=
_mm_madd_epi16
(
_mm_alignr_epi8
(
data2
data
14
)
coeff_67
)
;
__m128i
res_odd
=
_mm_add_epi32
(
_mm_add_epi32
(
res_1
res_5
)
_mm_add_epi32
(
res_3
res_7
)
)
;
res_odd
=
_mm_sra_epi32
(
_mm_add_epi32
(
res_odd
round_const
)
round_shift
)
;
const
__m128i
maxval
=
_mm_set1_epi16
(
(
1
<
<
bd
)
-
1
)
;
__m128i
res
=
_mm_packs_epi32
(
res_even
res_odd
)
;
res
=
_mm_max_epi16
(
_mm_min_epi16
(
res
maxval
)
_mm_setzero_si128
(
)
)
;
_mm_storeu_si128
(
(
__m128i
*
)
&
im_block
[
i
*
im_stride
+
j
]
res
)
;
}
}
}
{
const
int16_t
*
y_filter
=
av1_get_interp_filter_subpel_kernel
(
*
filter_params_y
subpel_y_q4
&
SUBPEL_MASK
)
;
const
__m128i
coeffs_y
=
_mm_loadu_si128
(
(
__m128i
*
)
y_filter
)
;
const
__m128i
tmp_0
=
_mm_unpacklo_epi32
(
coeffs_y
coeffs_y
)
;
const
__m128i
tmp_1
=
_mm_unpackhi_epi32
(
coeffs_y
coeffs_y
)
;
const
__m128i
coeff_01
=
_mm_unpacklo_epi64
(
tmp_0
tmp_0
)
;
const
__m128i
coeff_23
=
_mm_unpackhi_epi64
(
tmp_0
tmp_0
)
;
const
__m128i
coeff_45
=
_mm_unpacklo_epi64
(
tmp_1
tmp_1
)
;
const
__m128i
coeff_67
=
_mm_unpackhi_epi64
(
tmp_1
tmp_1
)
;
const
__m128i
round_const
=
_mm_set1_epi32
(
(
1
<
<
conv_params
-
>
round_1
)
>
>
1
)
;
const
__m128i
round_shift
=
_mm_cvtsi32_si128
(
conv_params
-
>
round_1
)
;
for
(
i
=
0
;
i
<
h
;
+
+
i
)
{
for
(
j
=
0
;
j
<
w
;
j
+
=
8
)
{
const
int16_t
*
data
=
&
im_block
[
i
*
im_stride
+
j
]
;
const
__m128i
src_0
=
_mm_unpacklo_epi16
(
*
(
__m128i
*
)
(
data
+
0
*
im_stride
)
*
(
__m128i
*
)
(
data
+
1
*
im_stride
)
)
;
const
__m128i
src_2
=
_mm_unpacklo_epi16
(
*
(
__m128i
*
)
(
data
+
2
*
im_stride
)
*
(
__m128i
*
)
(
data
+
3
*
im_stride
)
)
;
const
__m128i
src_4
=
_mm_unpacklo_epi16
(
*
(
__m128i
*
)
(
data
+
4
*
im_stride
)
*
(
__m128i
*
)
(
data
+
5
*
im_stride
)
)
;
const
__m128i
src_6
=
_mm_unpacklo_epi16
(
*
(
__m128i
*
)
(
data
+
6
*
im_stride
)
*
(
__m128i
*
)
(
data
+
7
*
im_stride
)
)
;
const
__m128i
res_0
=
_mm_madd_epi16
(
src_0
coeff_01
)
;
const
__m128i
res_2
=
_mm_madd_epi16
(
src_2
coeff_23
)
;
const
__m128i
res_4
=
_mm_madd_epi16
(
src_4
coeff_45
)
;
const
__m128i
res_6
=
_mm_madd_epi16
(
src_6
coeff_67
)
;
const
__m128i
res_even
=
_mm_add_epi32
(
_mm_add_epi32
(
res_0
res_2
)
_mm_add_epi32
(
res_4
res_6
)
)
;
const
__m128i
src_1
=
_mm_unpackhi_epi16
(
*
(
__m128i
*
)
(
data
+
0
*
im_stride
)
*
(
__m128i
*
)
(
data
+
1
*
im_stride
)
)
;
const
__m128i
src_3
=
_mm_unpackhi_epi16
(
*
(
__m128i
*
)
(
data
+
2
*
im_stride
)
*
(
__m128i
*
)
(
data
+
3
*
im_stride
)
)
;
const
__m128i
src_5
=
_mm_unpackhi_epi16
(
*
(
__m128i
*
)
(
data
+
4
*
im_stride
)
*
(
__m128i
*
)
(
data
+
5
*
im_stride
)
)
;
const
__m128i
src_7
=
_mm_unpackhi_epi16
(
*
(
__m128i
*
)
(
data
+
6
*
im_stride
)
*
(
__m128i
*
)
(
data
+
7
*
im_stride
)
)
;
const
__m128i
res_1
=
_mm_madd_epi16
(
src_1
coeff_01
)
;
const
__m128i
res_3
=
_mm_madd_epi16
(
src_3
coeff_23
)
;
const
__m128i
res_5
=
_mm_madd_epi16
(
src_5
coeff_45
)
;
const
__m128i
res_7
=
_mm_madd_epi16
(
src_7
coeff_67
)
;
const
__m128i
res_odd
=
_mm_add_epi32
(
_mm_add_epi32
(
res_1
res_3
)
_mm_add_epi32
(
res_5
res_7
)
)
;
const
__m128i
res_lo
=
_mm_unpacklo_epi32
(
res_even
res_odd
)
;
const
__m128i
res_hi
=
_mm_unpackhi_epi32
(
res_even
res_odd
)
;
const
__m128i
res_lo_round
=
_mm_sra_epi32
(
_mm_add_epi32
(
res_lo
round_const
)
round_shift
)
;
const
__m128i
res_hi_round
=
_mm_sra_epi32
(
_mm_add_epi32
(
res_hi
round_const
)
round_shift
)
;
__m128i
*
const
p
=
(
__m128i
*
)
&
dst
[
i
*
dst_stride
+
j
]
;
if
(
do_average
)
{
_mm_storeu_si128
(
p
+
0
_mm_add_epi32
(
_mm_loadu_si128
(
p
+
0
)
res_lo_round
)
)
;
_mm_storeu_si128
(
p
+
1
_mm_add_epi32
(
_mm_loadu_si128
(
p
+
1
)
res_hi_round
)
)
;
}
else
{
_mm_storeu_si128
(
p
+
0
res_lo_round
)
;
_mm_storeu_si128
(
p
+
1
res_hi_round
)
;
}
}
}
}
}
#
else
void
av1_highbd_convolve_2d_ssse3
(
const
uint16_t
*
src
int
src_stride
CONV_BUF_TYPE
*
dst
int
dst_stride
int
w
int
h
InterpFilterParams
*
filter_params_x
InterpFilterParams
*
filter_params_y
const
int
subpel_x_q4
const
int
subpel_y_q4
ConvolveParams
*
conv_params
int
bd
)
{
DECLARE_ALIGNED
(
16
int16_t
im_block
[
(
MAX_SB_SIZE
+
MAX_FILTER_TAP
-
1
)
*
MAX_SB_SIZE
]
)
;
int
im_h
=
h
+
filter_params_y
-
>
taps
-
1
;
int
im_stride
=
MAX_SB_SIZE
;
int
i
j
;
const
int
do_average
=
conv_params
-
>
do_average
;
const
int
fo_vert
=
filter_params_y
-
>
taps
/
2
-
1
;
const
int
fo_horiz
=
filter_params_x
-
>
taps
/
2
-
1
;
const
uint16_t
*
const
src_ptr
=
src
-
fo_vert
*
src_stride
-
fo_horiz
;
assert
(
conv_params
-
>
round_0
>
=
5
)
;
{
const
int16_t
*
x_filter
=
av1_get_interp_filter_subpel_kernel
(
*
filter_params_x
subpel_x_q4
&
SUBPEL_MASK
)
;
const
__m128i
coeffs_x
=
_mm_loadu_si128
(
(
__m128i
*
)
x_filter
)
;
const
__m128i
tmp_0
=
_mm_unpacklo_epi32
(
coeffs_x
coeffs_x
)
;
const
__m128i
tmp_1
=
_mm_unpackhi_epi32
(
coeffs_x
coeffs_x
)
;
const
__m128i
coeff_01
=
_mm_unpacklo_epi64
(
tmp_0
tmp_0
)
;
const
__m128i
coeff_23
=
_mm_unpackhi_epi64
(
tmp_0
tmp_0
)
;
const
__m128i
coeff_45
=
_mm_unpacklo_epi64
(
tmp_1
tmp_1
)
;
const
__m128i
coeff_67
=
_mm_unpackhi_epi64
(
tmp_1
tmp_1
)
;
const
__m128i
round_const
=
_mm_set1_epi32
(
(
(
1
<
<
conv_params
-
>
round_0
)
>
>
1
)
+
(
1
<
<
(
bd
+
FILTER_BITS
-
1
)
)
)
;
const
__m128i
round_shift
=
_mm_cvtsi32_si128
(
conv_params
-
>
round_0
)
;
for
(
i
=
0
;
i
<
im_h
;
+
+
i
)
{
for
(
j
=
0
;
j
<
w
;
j
+
=
8
)
{
const
__m128i
data
=
_mm_loadu_si128
(
(
__m128i
*
)
&
src_ptr
[
i
*
src_stride
+
j
]
)
;
const
__m128i
data2
=
_mm_loadu_si128
(
(
__m128i
*
)
&
src_ptr
[
i
*
src_stride
+
j
+
8
]
)
;
const
__m128i
res_0
=
_mm_madd_epi16
(
data
coeff_01
)
;
const
__m128i
res_2
=
_mm_madd_epi16
(
_mm_alignr_epi8
(
data2
data
4
)
coeff_23
)
;
const
__m128i
res_4
=
_mm_madd_epi16
(
_mm_alignr_epi8
(
data2
data
8
)
coeff_45
)
;
const
__m128i
res_6
=
_mm_madd_epi16
(
_mm_alignr_epi8
(
data2
data
12
)
coeff_67
)
;
__m128i
res_even
=
_mm_add_epi32
(
_mm_add_epi32
(
res_0
res_4
)
_mm_add_epi32
(
res_2
res_6
)
)
;
res_even
=
_mm_sra_epi32
(
_mm_add_epi32
(
res_even
round_const
)
round_shift
)
;
const
__m128i
res_1
=
_mm_madd_epi16
(
_mm_alignr_epi8
(
data2
data
2
)
coeff_01
)
;
const
__m128i
res_3
=
_mm_madd_epi16
(
_mm_alignr_epi8
(
data2
data
6
)
coeff_23
)
;
const
__m128i
res_5
=
_mm_madd_epi16
(
_mm_alignr_epi8
(
data2
data
10
)
coeff_45
)
;
const
__m128i
res_7
=
_mm_madd_epi16
(
_mm_alignr_epi8
(
data2
data
14
)
coeff_67
)
;
__m128i
res_odd
=
_mm_add_epi32
(
_mm_add_epi32
(
res_1
res_5
)
_mm_add_epi32
(
res_3
res_7
)
)
;
res_odd
=
_mm_sra_epi32
(
_mm_add_epi32
(
res_odd
round_const
)
round_shift
)
;
__m128i
res
=
_mm_packs_epi32
(
res_even
res_odd
)
;
_mm_storeu_si128
(
(
__m128i
*
)
&
im_block
[
i
*
im_stride
+
j
]
res
)
;
}
}
}
{
const
int16_t
*
y_filter
=
av1_get_interp_filter_subpel_kernel
(
*
filter_params_y
subpel_y_q4
&
SUBPEL_MASK
)
;
const
__m128i
coeffs_y
=
_mm_loadu_si128
(
(
__m128i
*
)
y_filter
)
;
const
__m128i
tmp_0
=
_mm_unpacklo_epi32
(
coeffs_y
coeffs_y
)
;
const
__m128i
tmp_1
=
_mm_unpackhi_epi32
(
coeffs_y
coeffs_y
)
;
const
__m128i
coeff_01
=
_mm_unpacklo_epi64
(
tmp_0
tmp_0
)
;
const
__m128i
coeff_23
=
_mm_unpackhi_epi64
(
tmp_0
tmp_0
)
;
const
__m128i
coeff_45
=
_mm_unpacklo_epi64
(
tmp_1
tmp_1
)
;
const
__m128i
coeff_67
=
_mm_unpackhi_epi64
(
tmp_1
tmp_1
)
;
const
__m128i
round_const
=
_mm_set1_epi32
(
(
(
1
<
<
conv_params
-
>
round_1
)
>
>
1
)
-
(
1
<
<
(
bd
+
2
*
FILTER_BITS
-
conv_params
-
>
round_0
-
1
)
)
)
;
const
__m128i
round_shift
=
_mm_cvtsi32_si128
(
conv_params
-
>
round_1
)
;
for
(
i
=
0
;
i
<
h
;
+
+
i
)
{
for
(
j
=
0
;
j
<
w
;
j
+
=
8
)
{
const
int16_t
*
data
=
&
im_block
[
i
*
im_stride
+
j
]
;
const
__m128i
src_0
=
_mm_unpacklo_epi16
(
*
(
__m128i
*
)
(
data
+
0
*
im_stride
)
*
(
__m128i
*
)
(
data
+
1
*
im_stride
)
)
;
const
__m128i
src_2
=
_mm_unpacklo_epi16
(
*
(
__m128i
*
)
(
data
+
2
*
im_stride
)
*
(
__m128i
*
)
(
data
+
3
*
im_stride
)
)
;
const
__m128i
src_4
=
_mm_unpacklo_epi16
(
*
(
__m128i
*
)
(
data
+
4
*
im_stride
)
*
(
__m128i
*
)
(
data
+
5
*
im_stride
)
)
;
const
__m128i
src_6
=
_mm_unpacklo_epi16
(
*
(
__m128i
*
)
(
data
+
6
*
im_stride
)
*
(
__m128i
*
)
(
data
+
7
*
im_stride
)
)
;
const
__m128i
res_0
=
_mm_madd_epi16
(
src_0
coeff_01
)
;
const
__m128i
res_2
=
_mm_madd_epi16
(
src_2
coeff_23
)
;
const
__m128i
res_4
=
_mm_madd_epi16
(
src_4
coeff_45
)
;
const
__m128i
res_6
=
_mm_madd_epi16
(
src_6
coeff_67
)
;
const
__m128i
res_even
=
_mm_add_epi32
(
_mm_add_epi32
(
res_0
res_2
)
_mm_add_epi32
(
res_4
res_6
)
)
;
const
__m128i
src_1
=
_mm_unpackhi_epi16
(
*
(
__m128i
*
)
(
data
+
0
*
im_stride
)
*
(
__m128i
*
)
(
data
+
1
*
im_stride
)
)
;
const
__m128i
src_3
=
_mm_unpackhi_epi16
(
*
(
__m128i
*
)
(
data
+
2
*
im_stride
)
*
(
__m128i
*
)
(
data
+
3
*
im_stride
)
)
;
const
__m128i
src_5
=
_mm_unpackhi_epi16
(
*
(
__m128i
*
)
(
data
+
4
*
im_stride
)
*
(
__m128i
*
)
(
data
+
5
*
im_stride
)
)
;
const
__m128i
src_7
=
_mm_unpackhi_epi16
(
*
(
__m128i
*
)
(
data
+
6
*
im_stride
)
*
(
__m128i
*
)
(
data
+
7
*
im_stride
)
)
;
const
__m128i
res_1
=
_mm_madd_epi16
(
src_1
coeff_01
)
;
const
__m128i
res_3
=
_mm_madd_epi16
(
src_3
coeff_23
)
;
const
__m128i
res_5
=
_mm_madd_epi16
(
src_5
coeff_45
)
;
const
__m128i
res_7
=
_mm_madd_epi16
(
src_7
coeff_67
)
;
const
__m128i
res_odd
=
_mm_add_epi32
(
_mm_add_epi32
(
res_1
res_3
)
_mm_add_epi32
(
res_5
res_7
)
)
;
const
__m128i
res_lo
=
_mm_unpacklo_epi32
(
res_even
res_odd
)
;
const
__m128i
res_hi
=
_mm_unpackhi_epi32
(
res_even
res_odd
)
;
const
__m128i
res_lo_round
=
_mm_sra_epi32
(
_mm_add_epi32
(
res_lo
round_const
)
round_shift
)
;
const
__m128i
res_hi_round
=
_mm_sra_epi32
(
_mm_add_epi32
(
res_hi
round_const
)
round_shift
)
;
__m128i
*
const
p
=
(
__m128i
*
)
&
dst
[
i
*
dst_stride
+
j
]
;
if
(
do_average
)
{
_mm_storeu_si128
(
p
+
0
_mm_add_epi32
(
_mm_loadu_si128
(
p
+
0
)
res_lo_round
)
)
;
_mm_storeu_si128
(
p
+
1
_mm_add_epi32
(
_mm_loadu_si128
(
p
+
1
)
res_hi_round
)
)
;
}
else
{
_mm_storeu_si128
(
p
+
0
res_lo_round
)
;
_mm_storeu_si128
(
p
+
1
res_hi_round
)
;
}
}
}
}
}
#
endif
