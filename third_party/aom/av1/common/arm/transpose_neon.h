#
ifndef
AV1_COMMON_ARM_TRANSPOSE_NEON_H_
#
define
AV1_COMMON_ARM_TRANSPOSE_NEON_H_
#
include
<
arm_neon
.
h
>
static
INLINE
void
transpose_u8_8x8
(
uint8x8_t
*
a0
uint8x8_t
*
a1
uint8x8_t
*
a2
uint8x8_t
*
a3
uint8x8_t
*
a4
uint8x8_t
*
a5
uint8x8_t
*
a6
uint8x8_t
*
a7
)
{
const
uint8x16x2_t
b0
=
vtrnq_u8
(
vcombine_u8
(
*
a0
*
a4
)
vcombine_u8
(
*
a1
*
a5
)
)
;
const
uint8x16x2_t
b1
=
vtrnq_u8
(
vcombine_u8
(
*
a2
*
a6
)
vcombine_u8
(
*
a3
*
a7
)
)
;
const
uint16x8x2_t
c0
=
vtrnq_u16
(
vreinterpretq_u16_u8
(
b0
.
val
[
0
]
)
vreinterpretq_u16_u8
(
b1
.
val
[
0
]
)
)
;
const
uint16x8x2_t
c1
=
vtrnq_u16
(
vreinterpretq_u16_u8
(
b0
.
val
[
1
]
)
vreinterpretq_u16_u8
(
b1
.
val
[
1
]
)
)
;
const
uint32x4x2_t
d0
=
vuzpq_u32
(
vreinterpretq_u32_u16
(
c0
.
val
[
0
]
)
vreinterpretq_u32_u16
(
c1
.
val
[
0
]
)
)
;
const
uint32x4x2_t
d1
=
vuzpq_u32
(
vreinterpretq_u32_u16
(
c0
.
val
[
1
]
)
vreinterpretq_u32_u16
(
c1
.
val
[
1
]
)
)
;
*
a0
=
vreinterpret_u8_u32
(
vget_low_u32
(
d0
.
val
[
0
]
)
)
;
*
a1
=
vreinterpret_u8_u32
(
vget_high_u32
(
d0
.
val
[
0
]
)
)
;
*
a2
=
vreinterpret_u8_u32
(
vget_low_u32
(
d1
.
val
[
0
]
)
)
;
*
a3
=
vreinterpret_u8_u32
(
vget_high_u32
(
d1
.
val
[
0
]
)
)
;
*
a4
=
vreinterpret_u8_u32
(
vget_low_u32
(
d0
.
val
[
1
]
)
)
;
*
a5
=
vreinterpret_u8_u32
(
vget_high_u32
(
d0
.
val
[
1
]
)
)
;
*
a6
=
vreinterpret_u8_u32
(
vget_low_u32
(
d1
.
val
[
1
]
)
)
;
*
a7
=
vreinterpret_u8_u32
(
vget_high_u32
(
d1
.
val
[
1
]
)
)
;
}
static
INLINE
void
transpose_u8_8x4
(
uint8x8_t
*
a0
uint8x8_t
*
a1
uint8x8_t
*
a2
uint8x8_t
*
a3
)
{
const
uint8x8x2_t
b0
=
vtrn_u8
(
*
a0
*
a1
)
;
const
uint8x8x2_t
b1
=
vtrn_u8
(
*
a2
*
a3
)
;
const
uint16x4x2_t
c0
=
vtrn_u16
(
vreinterpret_u16_u8
(
b0
.
val
[
0
]
)
vreinterpret_u16_u8
(
b1
.
val
[
0
]
)
)
;
const
uint16x4x2_t
c1
=
vtrn_u16
(
vreinterpret_u16_u8
(
b0
.
val
[
1
]
)
vreinterpret_u16_u8
(
b1
.
val
[
1
]
)
)
;
*
a0
=
vreinterpret_u8_u16
(
c0
.
val
[
0
]
)
;
*
a1
=
vreinterpret_u8_u16
(
c1
.
val
[
0
]
)
;
*
a2
=
vreinterpret_u8_u16
(
c0
.
val
[
1
]
)
;
*
a3
=
vreinterpret_u8_u16
(
c1
.
val
[
1
]
)
;
}
static
INLINE
void
transpose_u8_4x4
(
uint8x8_t
*
a0
uint8x8_t
*
a1
)
{
const
uint16x4x2_t
b0
=
vtrn_u16
(
vreinterpret_u16_u8
(
*
a0
)
vreinterpret_u16_u8
(
*
a1
)
)
;
const
uint32x2x2_t
c0
=
vtrn_u32
(
vreinterpret_u32_u16
(
b0
.
val
[
0
]
)
vreinterpret_u32_u16
(
b0
.
val
[
1
]
)
)
;
const
uint8x8x2_t
d0
=
vtrn_u8
(
vreinterpret_u8_u32
(
c0
.
val
[
0
]
)
vreinterpret_u8_u32
(
c0
.
val
[
1
]
)
)
;
*
a0
=
d0
.
val
[
0
]
;
*
a1
=
d0
.
val
[
1
]
;
}
static
INLINE
void
transpose_u8_4x8
(
uint8x8_t
*
a0
uint8x8_t
*
a1
uint8x8_t
*
a2
uint8x8_t
*
a3
const
uint8x8_t
a4
const
uint8x8_t
a5
const
uint8x8_t
a6
const
uint8x8_t
a7
)
{
const
uint32x2x2_t
b0
=
vtrn_u32
(
vreinterpret_u32_u8
(
*
a0
)
vreinterpret_u32_u8
(
a4
)
)
;
const
uint32x2x2_t
b1
=
vtrn_u32
(
vreinterpret_u32_u8
(
*
a1
)
vreinterpret_u32_u8
(
a5
)
)
;
const
uint32x2x2_t
b2
=
vtrn_u32
(
vreinterpret_u32_u8
(
*
a2
)
vreinterpret_u32_u8
(
a6
)
)
;
const
uint32x2x2_t
b3
=
vtrn_u32
(
vreinterpret_u32_u8
(
*
a3
)
vreinterpret_u32_u8
(
a7
)
)
;
const
uint16x4x2_t
c0
=
vtrn_u16
(
vreinterpret_u16_u32
(
b0
.
val
[
0
]
)
vreinterpret_u16_u32
(
b2
.
val
[
0
]
)
)
;
const
uint16x4x2_t
c1
=
vtrn_u16
(
vreinterpret_u16_u32
(
b1
.
val
[
0
]
)
vreinterpret_u16_u32
(
b3
.
val
[
0
]
)
)
;
const
uint8x8x2_t
d0
=
vtrn_u8
(
vreinterpret_u8_u16
(
c0
.
val
[
0
]
)
vreinterpret_u8_u16
(
c1
.
val
[
0
]
)
)
;
const
uint8x8x2_t
d1
=
vtrn_u8
(
vreinterpret_u8_u16
(
c0
.
val
[
1
]
)
vreinterpret_u8_u16
(
c1
.
val
[
1
]
)
)
;
*
a0
=
d0
.
val
[
0
]
;
*
a1
=
d0
.
val
[
1
]
;
*
a2
=
d1
.
val
[
0
]
;
*
a3
=
d1
.
val
[
1
]
;
}
static
INLINE
void
transpose_u16_4x8
(
uint16x4_t
*
a0
uint16x4_t
*
a1
uint16x4_t
*
a2
uint16x4_t
*
a3
uint16x4_t
*
a4
uint16x4_t
*
a5
uint16x4_t
*
a6
uint16x4_t
*
a7
uint16x8_t
*
o0
uint16x8_t
*
o1
uint16x8_t
*
o2
uint16x8_t
*
o3
)
{
uint16x4x2_t
b0
=
vtrn_u16
(
*
a0
*
a1
)
;
uint16x4x2_t
b1
=
vtrn_u16
(
*
a2
*
a3
)
;
uint16x4x2_t
b2
=
vtrn_u16
(
*
a4
*
a5
)
;
uint16x4x2_t
b3
=
vtrn_u16
(
*
a6
*
a7
)
;
uint32x2x2_t
c0
=
vtrn_u32
(
vreinterpret_u32_u16
(
b0
.
val
[
0
]
)
vreinterpret_u32_u16
(
b1
.
val
[
0
]
)
)
;
uint32x2x2_t
c1
=
vtrn_u32
(
vreinterpret_u32_u16
(
b0
.
val
[
1
]
)
vreinterpret_u32_u16
(
b1
.
val
[
1
]
)
)
;
uint32x2x2_t
c2
=
vtrn_u32
(
vreinterpret_u32_u16
(
b2
.
val
[
0
]
)
vreinterpret_u32_u16
(
b3
.
val
[
0
]
)
)
;
uint32x2x2_t
c3
=
vtrn_u32
(
vreinterpret_u32_u16
(
b2
.
val
[
1
]
)
vreinterpret_u32_u16
(
b3
.
val
[
1
]
)
)
;
*
o0
=
vcombine_u16
(
vreinterpret_u16_u32
(
c0
.
val
[
0
]
)
vreinterpret_u16_u32
(
c2
.
val
[
0
]
)
)
;
*
o1
=
vcombine_u16
(
vreinterpret_u16_u32
(
c1
.
val
[
0
]
)
vreinterpret_u16_u32
(
c3
.
val
[
0
]
)
)
;
*
o2
=
vcombine_u16
(
vreinterpret_u16_u32
(
c0
.
val
[
1
]
)
vreinterpret_u16_u32
(
c2
.
val
[
1
]
)
)
;
*
o3
=
vcombine_u16
(
vreinterpret_u16_u32
(
c1
.
val
[
1
]
)
vreinterpret_u16_u32
(
c3
.
val
[
1
]
)
)
;
}
static
INLINE
void
transpose_u16_8x8
(
uint16x8_t
*
a0
uint16x8_t
*
a1
uint16x8_t
*
a2
uint16x8_t
*
a3
uint16x8_t
*
a4
uint16x8_t
*
a5
uint16x8_t
*
a6
uint16x8_t
*
a7
)
{
const
uint16x8x2_t
b0
=
vtrnq_u16
(
*
a0
*
a1
)
;
const
uint16x8x2_t
b1
=
vtrnq_u16
(
*
a2
*
a3
)
;
const
uint16x8x2_t
b2
=
vtrnq_u16
(
*
a4
*
a5
)
;
const
uint16x8x2_t
b3
=
vtrnq_u16
(
*
a6
*
a7
)
;
const
uint32x4x2_t
c0
=
vtrnq_u32
(
vreinterpretq_u32_u16
(
b0
.
val
[
0
]
)
vreinterpretq_u32_u16
(
b1
.
val
[
0
]
)
)
;
const
uint32x4x2_t
c1
=
vtrnq_u32
(
vreinterpretq_u32_u16
(
b0
.
val
[
1
]
)
vreinterpretq_u32_u16
(
b1
.
val
[
1
]
)
)
;
const
uint32x4x2_t
c2
=
vtrnq_u32
(
vreinterpretq_u32_u16
(
b2
.
val
[
0
]
)
vreinterpretq_u32_u16
(
b3
.
val
[
0
]
)
)
;
const
uint32x4x2_t
c3
=
vtrnq_u32
(
vreinterpretq_u32_u16
(
b2
.
val
[
1
]
)
vreinterpretq_u32_u16
(
b3
.
val
[
1
]
)
)
;
*
a0
=
vcombine_u16
(
vget_low_u16
(
vreinterpretq_u16_u32
(
c0
.
val
[
0
]
)
)
vget_low_u16
(
vreinterpretq_u16_u32
(
c2
.
val
[
0
]
)
)
)
;
*
a4
=
vcombine_u16
(
vget_high_u16
(
vreinterpretq_u16_u32
(
c0
.
val
[
0
]
)
)
vget_high_u16
(
vreinterpretq_u16_u32
(
c2
.
val
[
0
]
)
)
)
;
*
a2
=
vcombine_u16
(
vget_low_u16
(
vreinterpretq_u16_u32
(
c0
.
val
[
1
]
)
)
vget_low_u16
(
vreinterpretq_u16_u32
(
c2
.
val
[
1
]
)
)
)
;
*
a6
=
vcombine_u16
(
vget_high_u16
(
vreinterpretq_u16_u32
(
c0
.
val
[
1
]
)
)
vget_high_u16
(
vreinterpretq_u16_u32
(
c2
.
val
[
1
]
)
)
)
;
*
a1
=
vcombine_u16
(
vget_low_u16
(
vreinterpretq_u16_u32
(
c1
.
val
[
0
]
)
)
vget_low_u16
(
vreinterpretq_u16_u32
(
c3
.
val
[
0
]
)
)
)
;
*
a5
=
vcombine_u16
(
vget_high_u16
(
vreinterpretq_u16_u32
(
c1
.
val
[
0
]
)
)
vget_high_u16
(
vreinterpretq_u16_u32
(
c3
.
val
[
0
]
)
)
)
;
*
a3
=
vcombine_u16
(
vget_low_u16
(
vreinterpretq_u16_u32
(
c1
.
val
[
1
]
)
)
vget_low_u16
(
vreinterpretq_u16_u32
(
c3
.
val
[
1
]
)
)
)
;
*
a7
=
vcombine_u16
(
vget_high_u16
(
vreinterpretq_u16_u32
(
c1
.
val
[
1
]
)
)
vget_high_u16
(
vreinterpretq_u16_u32
(
c3
.
val
[
1
]
)
)
)
;
}
static
INLINE
void
transpose_s16_8x8
(
int16x8_t
*
a0
int16x8_t
*
a1
int16x8_t
*
a2
int16x8_t
*
a3
int16x8_t
*
a4
int16x8_t
*
a5
int16x8_t
*
a6
int16x8_t
*
a7
)
{
const
int16x8x2_t
b0
=
vtrnq_s16
(
*
a0
*
a1
)
;
const
int16x8x2_t
b1
=
vtrnq_s16
(
*
a2
*
a3
)
;
const
int16x8x2_t
b2
=
vtrnq_s16
(
*
a4
*
a5
)
;
const
int16x8x2_t
b3
=
vtrnq_s16
(
*
a6
*
a7
)
;
const
int32x4x2_t
c0
=
vtrnq_s32
(
vreinterpretq_s32_s16
(
b0
.
val
[
0
]
)
vreinterpretq_s32_s16
(
b1
.
val
[
0
]
)
)
;
const
int32x4x2_t
c1
=
vtrnq_s32
(
vreinterpretq_s32_s16
(
b0
.
val
[
1
]
)
vreinterpretq_s32_s16
(
b1
.
val
[
1
]
)
)
;
const
int32x4x2_t
c2
=
vtrnq_s32
(
vreinterpretq_s32_s16
(
b2
.
val
[
0
]
)
vreinterpretq_s32_s16
(
b3
.
val
[
0
]
)
)
;
const
int32x4x2_t
c3
=
vtrnq_s32
(
vreinterpretq_s32_s16
(
b2
.
val
[
1
]
)
vreinterpretq_s32_s16
(
b3
.
val
[
1
]
)
)
;
*
a0
=
vcombine_s16
(
vget_low_s16
(
vreinterpretq_s16_s32
(
c0
.
val
[
0
]
)
)
vget_low_s16
(
vreinterpretq_s16_s32
(
c2
.
val
[
0
]
)
)
)
;
*
a4
=
vcombine_s16
(
vget_high_s16
(
vreinterpretq_s16_s32
(
c0
.
val
[
0
]
)
)
vget_high_s16
(
vreinterpretq_s16_s32
(
c2
.
val
[
0
]
)
)
)
;
*
a2
=
vcombine_s16
(
vget_low_s16
(
vreinterpretq_s16_s32
(
c0
.
val
[
1
]
)
)
vget_low_s16
(
vreinterpretq_s16_s32
(
c2
.
val
[
1
]
)
)
)
;
*
a6
=
vcombine_s16
(
vget_high_s16
(
vreinterpretq_s16_s32
(
c0
.
val
[
1
]
)
)
vget_high_s16
(
vreinterpretq_s16_s32
(
c2
.
val
[
1
]
)
)
)
;
*
a1
=
vcombine_s16
(
vget_low_s16
(
vreinterpretq_s16_s32
(
c1
.
val
[
0
]
)
)
vget_low_s16
(
vreinterpretq_s16_s32
(
c3
.
val
[
0
]
)
)
)
;
*
a5
=
vcombine_s16
(
vget_high_s16
(
vreinterpretq_s16_s32
(
c1
.
val
[
0
]
)
)
vget_high_s16
(
vreinterpretq_s16_s32
(
c3
.
val
[
0
]
)
)
)
;
*
a3
=
vcombine_s16
(
vget_low_s16
(
vreinterpretq_s16_s32
(
c1
.
val
[
1
]
)
)
vget_low_s16
(
vreinterpretq_s16_s32
(
c3
.
val
[
1
]
)
)
)
;
*
a7
=
vcombine_s16
(
vget_high_s16
(
vreinterpretq_s16_s32
(
c1
.
val
[
1
]
)
)
vget_high_s16
(
vreinterpretq_s16_s32
(
c3
.
val
[
1
]
)
)
)
;
}
static
INLINE
void
transpose_s16_4x4d
(
int16x4_t
*
a0
int16x4_t
*
a1
int16x4_t
*
a2
int16x4_t
*
a3
)
{
const
int16x4x2_t
b0
=
vtrn_s16
(
*
a0
*
a1
)
;
const
int16x4x2_t
b1
=
vtrn_s16
(
*
a2
*
a3
)
;
const
int32x2x2_t
c0
=
vtrn_s32
(
vreinterpret_s32_s16
(
b0
.
val
[
0
]
)
vreinterpret_s32_s16
(
b1
.
val
[
0
]
)
)
;
const
int32x2x2_t
c1
=
vtrn_s32
(
vreinterpret_s32_s16
(
b0
.
val
[
1
]
)
vreinterpret_s32_s16
(
b1
.
val
[
1
]
)
)
;
*
a0
=
vreinterpret_s16_s32
(
c0
.
val
[
0
]
)
;
*
a1
=
vreinterpret_s16_s32
(
c1
.
val
[
0
]
)
;
*
a2
=
vreinterpret_s16_s32
(
c0
.
val
[
1
]
)
;
*
a3
=
vreinterpret_s16_s32
(
c1
.
val
[
1
]
)
;
}
#
endif
