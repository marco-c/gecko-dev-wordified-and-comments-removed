#
ifndef
AOM_AOM_DSP_X86_LPF_COMMON_SSE2_H_
#
define
AOM_AOM_DSP_X86_LPF_COMMON_SSE2_H_
#
include
<
emmintrin
.
h
>
#
include
"
config
/
aom_config
.
h
"
#
define
mm_storelu
(
dst
v
)
memcpy
(
(
dst
)
(
const
char
*
)
&
(
v
)
8
)
#
define
mm_storehu
(
dst
v
)
memcpy
(
(
dst
)
(
const
char
*
)
&
(
v
)
+
8
8
)
static
INLINE
void
highbd_transpose6x6_sse2
(
__m128i
*
x0
__m128i
*
x1
__m128i
*
x2
__m128i
*
x3
__m128i
*
x4
__m128i
*
x5
__m128i
*
d0
__m128i
*
d1
__m128i
*
d2
__m128i
*
d3
__m128i
*
d4
__m128i
*
d5
)
{
__m128i
w0
w1
w2
w3
w4
w5
ww0
;
w0
=
_mm_unpacklo_epi16
(
*
x0
*
x1
)
;
w1
=
_mm_unpacklo_epi16
(
*
x2
*
x3
)
;
w2
=
_mm_unpacklo_epi16
(
*
x4
*
x5
)
;
ww0
=
_mm_unpacklo_epi32
(
w0
w1
)
;
*
d0
=
_mm_unpacklo_epi64
(
ww0
w2
)
;
*
d1
=
_mm_unpackhi_epi64
(
ww0
_mm_srli_si128
(
w2
4
)
)
;
ww0
=
_mm_unpackhi_epi32
(
w0
w1
)
;
*
d2
=
_mm_unpacklo_epi64
(
ww0
_mm_srli_si128
(
w2
8
)
)
;
w3
=
_mm_unpackhi_epi16
(
*
x0
*
x1
)
;
w4
=
_mm_unpackhi_epi16
(
*
x2
*
x3
)
;
w5
=
_mm_unpackhi_epi16
(
*
x4
*
x5
)
;
*
d3
=
_mm_unpackhi_epi64
(
ww0
_mm_srli_si128
(
w2
4
)
)
;
ww0
=
_mm_unpacklo_epi32
(
w3
w4
)
;
*
d4
=
_mm_unpacklo_epi64
(
ww0
w5
)
;
*
d5
=
_mm_unpackhi_epi64
(
ww0
_mm_slli_si128
(
w5
4
)
)
;
}
static
INLINE
void
highbd_transpose4x8_8x4_low_sse2
(
__m128i
*
x0
__m128i
*
x1
__m128i
*
x2
__m128i
*
x3
__m128i
*
d0
__m128i
*
d1
__m128i
*
d2
__m128i
*
d3
)
{
__m128i
zero
=
_mm_setzero_si128
(
)
;
__m128i
w0
w1
ww0
ww1
;
w0
=
_mm_unpacklo_epi16
(
*
x0
*
x1
)
;
w1
=
_mm_unpacklo_epi16
(
*
x2
*
x3
)
;
ww0
=
_mm_unpacklo_epi32
(
w0
w1
)
;
ww1
=
_mm_unpackhi_epi32
(
w0
w1
)
;
*
d0
=
_mm_unpacklo_epi64
(
ww0
zero
)
;
*
d1
=
_mm_unpackhi_epi64
(
ww0
zero
)
;
*
d2
=
_mm_unpacklo_epi64
(
ww1
zero
)
;
*
d3
=
_mm_unpackhi_epi64
(
ww1
zero
)
;
}
static
INLINE
void
highbd_transpose4x8_8x4_high_sse2
(
__m128i
*
x0
__m128i
*
x1
__m128i
*
x2
__m128i
*
x3
__m128i
*
d4
__m128i
*
d5
__m128i
*
d6
__m128i
*
d7
)
{
__m128i
w0
w1
ww2
ww3
;
__m128i
zero
=
_mm_setzero_si128
(
)
;
w0
=
_mm_unpackhi_epi16
(
*
x0
*
x1
)
;
w1
=
_mm_unpackhi_epi16
(
*
x2
*
x3
)
;
ww2
=
_mm_unpacklo_epi32
(
w0
w1
)
;
ww3
=
_mm_unpackhi_epi32
(
w0
w1
)
;
*
d4
=
_mm_unpacklo_epi64
(
ww2
zero
)
;
*
d5
=
_mm_unpackhi_epi64
(
ww2
zero
)
;
*
d6
=
_mm_unpacklo_epi64
(
ww3
zero
)
;
*
d7
=
_mm_unpackhi_epi64
(
ww3
zero
)
;
}
static
INLINE
void
highbd_transpose4x8_8x4_sse2
(
__m128i
*
x0
__m128i
*
x1
__m128i
*
x2
__m128i
*
x3
__m128i
*
d0
__m128i
*
d1
__m128i
*
d2
__m128i
*
d3
__m128i
*
d4
__m128i
*
d5
__m128i
*
d6
__m128i
*
d7
)
{
highbd_transpose4x8_8x4_low_sse2
(
x0
x1
x2
x3
d0
d1
d2
d3
)
;
highbd_transpose4x8_8x4_high_sse2
(
x0
x1
x2
x3
d4
d5
d6
d7
)
;
}
static
INLINE
void
highbd_transpose8x8_low_sse2
(
__m128i
*
x0
__m128i
*
x1
__m128i
*
x2
__m128i
*
x3
__m128i
*
x4
__m128i
*
x5
__m128i
*
x6
__m128i
*
x7
__m128i
*
d0
__m128i
*
d1
__m128i
*
d2
__m128i
*
d3
)
{
__m128i
w0
w1
w2
w3
ww0
ww1
;
w0
=
_mm_unpacklo_epi16
(
*
x0
*
x1
)
;
w1
=
_mm_unpacklo_epi16
(
*
x2
*
x3
)
;
w2
=
_mm_unpacklo_epi16
(
*
x4
*
x5
)
;
w3
=
_mm_unpacklo_epi16
(
*
x6
*
x7
)
;
ww0
=
_mm_unpacklo_epi32
(
w0
w1
)
;
ww1
=
_mm_unpacklo_epi32
(
w2
w3
)
;
*
d0
=
_mm_unpacklo_epi64
(
ww0
ww1
)
;
*
d1
=
_mm_unpackhi_epi64
(
ww0
ww1
)
;
ww0
=
_mm_unpackhi_epi32
(
w0
w1
)
;
ww1
=
_mm_unpackhi_epi32
(
w2
w3
)
;
*
d2
=
_mm_unpacklo_epi64
(
ww0
ww1
)
;
*
d3
=
_mm_unpackhi_epi64
(
ww0
ww1
)
;
}
static
INLINE
void
highbd_transpose8x8_high_sse2
(
__m128i
*
x0
__m128i
*
x1
__m128i
*
x2
__m128i
*
x3
__m128i
*
x4
__m128i
*
x5
__m128i
*
x6
__m128i
*
x7
__m128i
*
d4
__m128i
*
d5
__m128i
*
d6
__m128i
*
d7
)
{
__m128i
w0
w1
w2
w3
ww0
ww1
;
w0
=
_mm_unpackhi_epi16
(
*
x0
*
x1
)
;
w1
=
_mm_unpackhi_epi16
(
*
x2
*
x3
)
;
w2
=
_mm_unpackhi_epi16
(
*
x4
*
x5
)
;
w3
=
_mm_unpackhi_epi16
(
*
x6
*
x7
)
;
ww0
=
_mm_unpacklo_epi32
(
w0
w1
)
;
ww1
=
_mm_unpacklo_epi32
(
w2
w3
)
;
*
d4
=
_mm_unpacklo_epi64
(
ww0
ww1
)
;
*
d5
=
_mm_unpackhi_epi64
(
ww0
ww1
)
;
ww0
=
_mm_unpackhi_epi32
(
w0
w1
)
;
ww1
=
_mm_unpackhi_epi32
(
w2
w3
)
;
*
d6
=
_mm_unpacklo_epi64
(
ww0
ww1
)
;
*
d7
=
_mm_unpackhi_epi64
(
ww0
ww1
)
;
}
static
INLINE
void
highbd_transpose8x8_sse2
(
__m128i
*
x0
__m128i
*
x1
__m128i
*
x2
__m128i
*
x3
__m128i
*
x4
__m128i
*
x5
__m128i
*
x6
__m128i
*
x7
__m128i
*
d0
__m128i
*
d1
__m128i
*
d2
__m128i
*
d3
__m128i
*
d4
__m128i
*
d5
__m128i
*
d6
__m128i
*
d7
)
{
highbd_transpose8x8_low_sse2
(
x0
x1
x2
x3
x4
x5
x6
x7
d0
d1
d2
d3
)
;
highbd_transpose8x8_high_sse2
(
x0
x1
x2
x3
x4
x5
x6
x7
d4
d5
d6
d7
)
;
}
static
INLINE
void
highbd_transpose8x16_sse2
(
__m128i
*
x0
__m128i
*
x1
__m128i
*
x2
__m128i
*
x3
__m128i
*
x4
__m128i
*
x5
__m128i
*
x6
__m128i
*
x7
__m128i
*
d0
__m128i
*
d1
__m128i
*
d2
__m128i
*
d3
__m128i
*
d4
__m128i
*
d5
__m128i
*
d6
__m128i
*
d7
)
{
highbd_transpose8x8_sse2
(
x0
x1
x2
x3
x4
x5
x6
x7
d0
d1
d2
d3
d4
d5
d6
d7
)
;
highbd_transpose8x8_sse2
(
x0
+
1
x1
+
1
x2
+
1
x3
+
1
x4
+
1
x5
+
1
x6
+
1
x7
+
1
d0
+
1
d1
+
1
d2
+
1
d3
+
1
d4
+
1
d5
+
1
d6
+
1
d7
+
1
)
;
}
static
INLINE
void
transpose4x8_8x4_low_sse2
(
__m128i
*
x0
__m128i
*
x1
__m128i
*
x2
__m128i
*
x3
__m128i
*
d0
__m128i
*
d1
__m128i
*
d2
__m128i
*
d3
)
{
__m128i
w0
w1
;
w0
=
_mm_unpacklo_epi8
(
*
x0
*
x1
)
;
w1
=
_mm_unpacklo_epi8
(
*
x2
*
x3
)
;
*
d0
=
_mm_unpacklo_epi16
(
w0
w1
)
;
*
d1
=
_mm_srli_si128
(
*
d0
4
)
;
*
d2
=
_mm_srli_si128
(
*
d0
8
)
;
*
d3
=
_mm_srli_si128
(
*
d0
12
)
;
}
static
INLINE
void
transpose4x8_8x4_sse2
(
__m128i
*
x0
__m128i
*
x1
__m128i
*
x2
__m128i
*
x3
__m128i
*
d0
__m128i
*
d1
__m128i
*
d2
__m128i
*
d3
__m128i
*
d4
__m128i
*
d5
__m128i
*
d6
__m128i
*
d7
)
{
__m128i
w0
w1
ww0
ww1
;
w0
=
_mm_unpacklo_epi8
(
*
x0
*
x1
)
;
w1
=
_mm_unpacklo_epi8
(
*
x2
*
x3
)
;
ww0
=
_mm_unpacklo_epi16
(
w0
w1
)
;
ww1
=
_mm_unpackhi_epi16
(
w0
w1
)
;
*
d0
=
ww0
;
*
d1
=
_mm_srli_si128
(
ww0
4
)
;
*
d2
=
_mm_srli_si128
(
ww0
8
)
;
*
d3
=
_mm_srli_si128
(
ww0
12
)
;
*
d4
=
ww1
;
*
d5
=
_mm_srli_si128
(
ww1
4
)
;
*
d6
=
_mm_srli_si128
(
ww1
8
)
;
*
d7
=
_mm_srli_si128
(
ww1
12
)
;
}
static
INLINE
void
transpose8x8_low_sse2
(
__m128i
*
x0
__m128i
*
x1
__m128i
*
x2
__m128i
*
x3
__m128i
*
x4
__m128i
*
x5
__m128i
*
x6
__m128i
*
x7
__m128i
*
d0
__m128i
*
d1
__m128i
*
d2
__m128i
*
d3
)
{
__m128i
w0
w1
w2
w3
w4
w5
;
w0
=
_mm_unpacklo_epi8
(
*
x0
*
x1
)
;
w1
=
_mm_unpacklo_epi8
(
*
x2
*
x3
)
;
w2
=
_mm_unpacklo_epi8
(
*
x4
*
x5
)
;
w3
=
_mm_unpacklo_epi8
(
*
x6
*
x7
)
;
w4
=
_mm_unpacklo_epi16
(
w0
w1
)
;
w5
=
_mm_unpacklo_epi16
(
w2
w3
)
;
*
d0
=
_mm_unpacklo_epi32
(
w4
w5
)
;
*
d1
=
_mm_srli_si128
(
*
d0
8
)
;
*
d2
=
_mm_unpackhi_epi32
(
w4
w5
)
;
*
d3
=
_mm_srli_si128
(
*
d2
8
)
;
}
static
INLINE
void
transpose8x8_sse2
(
__m128i
*
x0
__m128i
*
x1
__m128i
*
x2
__m128i
*
x3
__m128i
*
x4
__m128i
*
x5
__m128i
*
x6
__m128i
*
x7
__m128i
*
d0d1
__m128i
*
d2d3
__m128i
*
d4d5
__m128i
*
d6d7
)
{
__m128i
w0
w1
w2
w3
w4
w5
w6
w7
;
w0
=
_mm_unpacklo_epi8
(
*
x0
*
x1
)
;
w1
=
_mm_unpacklo_epi8
(
*
x2
*
x3
)
;
w2
=
_mm_unpacklo_epi8
(
*
x4
*
x5
)
;
w3
=
_mm_unpacklo_epi8
(
*
x6
*
x7
)
;
w4
=
_mm_unpacklo_epi16
(
w0
w1
)
;
w5
=
_mm_unpacklo_epi16
(
w2
w3
)
;
*
d0d1
=
_mm_unpacklo_epi32
(
w4
w5
)
;
*
d2d3
=
_mm_unpackhi_epi32
(
w4
w5
)
;
w6
=
_mm_unpackhi_epi16
(
w0
w1
)
;
w7
=
_mm_unpackhi_epi16
(
w2
w3
)
;
*
d4d5
=
_mm_unpacklo_epi32
(
w6
w7
)
;
*
d6d7
=
_mm_unpackhi_epi32
(
w6
w7
)
;
}
static
INLINE
void
transpose16x8_8x16_sse2
(
__m128i
*
x0
__m128i
*
x1
__m128i
*
x2
__m128i
*
x3
__m128i
*
x4
__m128i
*
x5
__m128i
*
x6
__m128i
*
x7
__m128i
*
x8
__m128i
*
x9
__m128i
*
x10
__m128i
*
x11
__m128i
*
x12
__m128i
*
x13
__m128i
*
x14
__m128i
*
x15
__m128i
*
d0
__m128i
*
d1
__m128i
*
d2
__m128i
*
d3
__m128i
*
d4
__m128i
*
d5
__m128i
*
d6
__m128i
*
d7
)
{
__m128i
w0
w1
w2
w3
w4
w5
w6
w7
w8
w9
;
__m128i
w10
w11
w12
w13
w14
w15
;
w0
=
_mm_unpacklo_epi8
(
*
x0
*
x1
)
;
w1
=
_mm_unpacklo_epi8
(
*
x2
*
x3
)
;
w2
=
_mm_unpacklo_epi8
(
*
x4
*
x5
)
;
w3
=
_mm_unpacklo_epi8
(
*
x6
*
x7
)
;
w8
=
_mm_unpacklo_epi8
(
*
x8
*
x9
)
;
w9
=
_mm_unpacklo_epi8
(
*
x10
*
x11
)
;
w10
=
_mm_unpacklo_epi8
(
*
x12
*
x13
)
;
w11
=
_mm_unpacklo_epi8
(
*
x14
*
x15
)
;
w4
=
_mm_unpacklo_epi16
(
w0
w1
)
;
w5
=
_mm_unpacklo_epi16
(
w2
w3
)
;
w12
=
_mm_unpacklo_epi16
(
w8
w9
)
;
w13
=
_mm_unpacklo_epi16
(
w10
w11
)
;
w6
=
_mm_unpacklo_epi32
(
w4
w5
)
;
w7
=
_mm_unpackhi_epi32
(
w4
w5
)
;
w14
=
_mm_unpacklo_epi32
(
w12
w13
)
;
w15
=
_mm_unpackhi_epi32
(
w12
w13
)
;
*
d0
=
_mm_unpacklo_epi64
(
w6
w14
)
;
*
d1
=
_mm_unpackhi_epi64
(
w6
w14
)
;
*
d2
=
_mm_unpacklo_epi64
(
w7
w15
)
;
*
d3
=
_mm_unpackhi_epi64
(
w7
w15
)
;
w4
=
_mm_unpackhi_epi16
(
w0
w1
)
;
w5
=
_mm_unpackhi_epi16
(
w2
w3
)
;
w12
=
_mm_unpackhi_epi16
(
w8
w9
)
;
w13
=
_mm_unpackhi_epi16
(
w10
w11
)
;
w6
=
_mm_unpacklo_epi32
(
w4
w5
)
;
w7
=
_mm_unpackhi_epi32
(
w4
w5
)
;
w14
=
_mm_unpacklo_epi32
(
w12
w13
)
;
w15
=
_mm_unpackhi_epi32
(
w12
w13
)
;
*
d4
=
_mm_unpacklo_epi64
(
w6
w14
)
;
*
d5
=
_mm_unpackhi_epi64
(
w6
w14
)
;
*
d6
=
_mm_unpacklo_epi64
(
w7
w15
)
;
*
d7
=
_mm_unpackhi_epi64
(
w7
w15
)
;
}
static
INLINE
void
transpose8x16_16x8_sse2
(
__m128i
*
x0
__m128i
*
x1
__m128i
*
x2
__m128i
*
x3
__m128i
*
x4
__m128i
*
x5
__m128i
*
x6
__m128i
*
x7
__m128i
*
d0d1
__m128i
*
d2d3
__m128i
*
d4d5
__m128i
*
d6d7
__m128i
*
d8d9
__m128i
*
d10d11
__m128i
*
d12d13
__m128i
*
d14d15
)
{
__m128i
w0
w1
w2
w3
w4
w5
w6
w7
w8
w9
;
__m128i
w10
w11
w12
w13
w14
w15
;
w0
=
_mm_unpacklo_epi8
(
*
x0
*
x1
)
;
w1
=
_mm_unpacklo_epi8
(
*
x2
*
x3
)
;
w2
=
_mm_unpacklo_epi8
(
*
x4
*
x5
)
;
w3
=
_mm_unpacklo_epi8
(
*
x6
*
x7
)
;
w8
=
_mm_unpackhi_epi8
(
*
x0
*
x1
)
;
w9
=
_mm_unpackhi_epi8
(
*
x2
*
x3
)
;
w10
=
_mm_unpackhi_epi8
(
*
x4
*
x5
)
;
w11
=
_mm_unpackhi_epi8
(
*
x6
*
x7
)
;
w4
=
_mm_unpacklo_epi16
(
w0
w1
)
;
w5
=
_mm_unpacklo_epi16
(
w2
w3
)
;
w12
=
_mm_unpacklo_epi16
(
w8
w9
)
;
w13
=
_mm_unpacklo_epi16
(
w10
w11
)
;
w6
=
_mm_unpacklo_epi32
(
w4
w5
)
;
w7
=
_mm_unpackhi_epi32
(
w4
w5
)
;
w14
=
_mm_unpacklo_epi32
(
w12
w13
)
;
w15
=
_mm_unpackhi_epi32
(
w12
w13
)
;
*
d0d1
=
_mm_unpacklo_epi64
(
w6
w14
)
;
*
d2d3
=
_mm_unpackhi_epi64
(
w6
w14
)
;
*
d4d5
=
_mm_unpacklo_epi64
(
w7
w15
)
;
*
d6d7
=
_mm_unpackhi_epi64
(
w7
w15
)
;
w4
=
_mm_unpackhi_epi16
(
w0
w1
)
;
w5
=
_mm_unpackhi_epi16
(
w2
w3
)
;
w12
=
_mm_unpackhi_epi16
(
w8
w9
)
;
w13
=
_mm_unpackhi_epi16
(
w10
w11
)
;
w6
=
_mm_unpacklo_epi32
(
w4
w5
)
;
w7
=
_mm_unpackhi_epi32
(
w4
w5
)
;
w14
=
_mm_unpacklo_epi32
(
w12
w13
)
;
w15
=
_mm_unpackhi_epi32
(
w12
w13
)
;
*
d8d9
=
_mm_unpacklo_epi64
(
w6
w14
)
;
*
d10d11
=
_mm_unpackhi_epi64
(
w6
w14
)
;
*
d12d13
=
_mm_unpacklo_epi64
(
w7
w15
)
;
*
d14d15
=
_mm_unpackhi_epi64
(
w7
w15
)
;
}
static
INLINE
void
transpose_16x8
(
unsigned
char
*
in0
unsigned
char
*
in1
int
in_p
unsigned
char
*
out
int
out_p
)
{
__m128i
x0
x1
x2
x3
x4
x5
x6
x7
;
__m128i
x8
x9
x10
x11
x12
x13
x14
x15
;
x0
=
_mm_loadl_epi64
(
(
__m128i
*
)
in0
)
;
x1
=
_mm_loadl_epi64
(
(
__m128i
*
)
(
in0
+
in_p
)
)
;
x0
=
_mm_unpacklo_epi8
(
x0
x1
)
;
x2
=
_mm_loadl_epi64
(
(
__m128i
*
)
(
in0
+
2
*
in_p
)
)
;
x3
=
_mm_loadl_epi64
(
(
__m128i
*
)
(
in0
+
3
*
in_p
)
)
;
x1
=
_mm_unpacklo_epi8
(
x2
x3
)
;
x4
=
_mm_loadl_epi64
(
(
__m128i
*
)
(
in0
+
4
*
in_p
)
)
;
x5
=
_mm_loadl_epi64
(
(
__m128i
*
)
(
in0
+
5
*
in_p
)
)
;
x2
=
_mm_unpacklo_epi8
(
x4
x5
)
;
x6
=
_mm_loadl_epi64
(
(
__m128i
*
)
(
in0
+
6
*
in_p
)
)
;
x7
=
_mm_loadl_epi64
(
(
__m128i
*
)
(
in0
+
7
*
in_p
)
)
;
x3
=
_mm_unpacklo_epi8
(
x6
x7
)
;
x4
=
_mm_unpacklo_epi16
(
x0
x1
)
;
x8
=
_mm_loadl_epi64
(
(
__m128i
*
)
in1
)
;
x9
=
_mm_loadl_epi64
(
(
__m128i
*
)
(
in1
+
in_p
)
)
;
x8
=
_mm_unpacklo_epi8
(
x8
x9
)
;
x5
=
_mm_unpacklo_epi16
(
x2
x3
)
;
x10
=
_mm_loadl_epi64
(
(
__m128i
*
)
(
in1
+
2
*
in_p
)
)
;
x11
=
_mm_loadl_epi64
(
(
__m128i
*
)
(
in1
+
3
*
in_p
)
)
;
x9
=
_mm_unpacklo_epi8
(
x10
x11
)
;
x12
=
_mm_loadl_epi64
(
(
__m128i
*
)
(
in1
+
4
*
in_p
)
)
;
x13
=
_mm_loadl_epi64
(
(
__m128i
*
)
(
in1
+
5
*
in_p
)
)
;
x10
=
_mm_unpacklo_epi8
(
x12
x13
)
;
x12
=
_mm_unpacklo_epi16
(
x8
x9
)
;
x14
=
_mm_loadl_epi64
(
(
__m128i
*
)
(
in1
+
6
*
in_p
)
)
;
x15
=
_mm_loadl_epi64
(
(
__m128i
*
)
(
in1
+
7
*
in_p
)
)
;
x11
=
_mm_unpacklo_epi8
(
x14
x15
)
;
x13
=
_mm_unpacklo_epi16
(
x10
x11
)
;
x6
=
_mm_unpacklo_epi32
(
x4
x5
)
;
x7
=
_mm_unpackhi_epi32
(
x4
x5
)
;
x14
=
_mm_unpacklo_epi32
(
x12
x13
)
;
x15
=
_mm_unpackhi_epi32
(
x12
x13
)
;
_mm_storeu_si128
(
(
__m128i
*
)
out
_mm_unpacklo_epi64
(
x6
x14
)
)
;
_mm_storeu_si128
(
(
__m128i
*
)
(
out
+
out_p
)
_mm_unpackhi_epi64
(
x6
x14
)
)
;
_mm_storeu_si128
(
(
__m128i
*
)
(
out
+
2
*
out_p
)
_mm_unpacklo_epi64
(
x7
x15
)
)
;
_mm_storeu_si128
(
(
__m128i
*
)
(
out
+
3
*
out_p
)
_mm_unpackhi_epi64
(
x7
x15
)
)
;
x4
=
_mm_unpackhi_epi16
(
x0
x1
)
;
x5
=
_mm_unpackhi_epi16
(
x2
x3
)
;
x12
=
_mm_unpackhi_epi16
(
x8
x9
)
;
x13
=
_mm_unpackhi_epi16
(
x10
x11
)
;
x6
=
_mm_unpacklo_epi32
(
x4
x5
)
;
x7
=
_mm_unpackhi_epi32
(
x4
x5
)
;
x14
=
_mm_unpacklo_epi32
(
x12
x13
)
;
x15
=
_mm_unpackhi_epi32
(
x12
x13
)
;
_mm_storeu_si128
(
(
__m128i
*
)
(
out
+
4
*
out_p
)
_mm_unpacklo_epi64
(
x6
x14
)
)
;
_mm_storeu_si128
(
(
__m128i
*
)
(
out
+
5
*
out_p
)
_mm_unpackhi_epi64
(
x6
x14
)
)
;
_mm_storeu_si128
(
(
__m128i
*
)
(
out
+
6
*
out_p
)
_mm_unpacklo_epi64
(
x7
x15
)
)
;
_mm_storeu_si128
(
(
__m128i
*
)
(
out
+
7
*
out_p
)
_mm_unpackhi_epi64
(
x7
x15
)
)
;
}
static
INLINE
void
transpose_16x8_to_8x16
(
unsigned
char
*
src
int
in_p
unsigned
char
*
dst
int
out_p
)
{
const
__m128i
x0
=
_mm_loadu_si128
(
(
__m128i
*
)
(
src
)
)
;
const
__m128i
x1
=
_mm_loadu_si128
(
(
__m128i
*
)
(
src
+
(
1
*
in_p
)
)
)
;
const
__m128i
x2
=
_mm_loadu_si128
(
(
__m128i
*
)
(
src
+
(
2
*
in_p
)
)
)
;
const
__m128i
x3
=
_mm_loadu_si128
(
(
__m128i
*
)
(
src
+
(
3
*
in_p
)
)
)
;
const
__m128i
x4
=
_mm_loadu_si128
(
(
__m128i
*
)
(
src
+
(
4
*
in_p
)
)
)
;
const
__m128i
x5
=
_mm_loadu_si128
(
(
__m128i
*
)
(
src
+
(
5
*
in_p
)
)
)
;
const
__m128i
x6
=
_mm_loadu_si128
(
(
__m128i
*
)
(
src
+
(
6
*
in_p
)
)
)
;
const
__m128i
x7
=
_mm_loadu_si128
(
(
__m128i
*
)
(
src
+
(
7
*
in_p
)
)
)
;
const
__m128i
x_s10
=
_mm_unpacklo_epi8
(
x0
x1
)
;
const
__m128i
x_s11
=
_mm_unpackhi_epi8
(
x0
x1
)
;
const
__m128i
x_s12
=
_mm_unpacklo_epi8
(
x2
x3
)
;
const
__m128i
x_s13
=
_mm_unpackhi_epi8
(
x2
x3
)
;
const
__m128i
x_s14
=
_mm_unpacklo_epi8
(
x4
x5
)
;
const
__m128i
x_s15
=
_mm_unpackhi_epi8
(
x4
x5
)
;
const
__m128i
x_s16
=
_mm_unpacklo_epi8
(
x6
x7
)
;
const
__m128i
x_s17
=
_mm_unpackhi_epi8
(
x6
x7
)
;
const
__m128i
x_s20
=
_mm_unpacklo_epi16
(
x_s10
x_s12
)
;
const
__m128i
x_s21
=
_mm_unpackhi_epi16
(
x_s10
x_s12
)
;
const
__m128i
x_s22
=
_mm_unpacklo_epi16
(
x_s11
x_s13
)
;
const
__m128i
x_s23
=
_mm_unpackhi_epi16
(
x_s11
x_s13
)
;
const
__m128i
x_s24
=
_mm_unpacklo_epi16
(
x_s14
x_s16
)
;
const
__m128i
x_s25
=
_mm_unpackhi_epi16
(
x_s14
x_s16
)
;
const
__m128i
x_s26
=
_mm_unpacklo_epi16
(
x_s15
x_s17
)
;
const
__m128i
x_s27
=
_mm_unpackhi_epi16
(
x_s15
x_s17
)
;
const
__m128i
x_s30
=
_mm_unpacklo_epi32
(
x_s20
x_s24
)
;
const
__m128i
x_s31
=
_mm_unpackhi_epi32
(
x_s20
x_s24
)
;
const
__m128i
x_s32
=
_mm_unpacklo_epi32
(
x_s21
x_s25
)
;
const
__m128i
x_s33
=
_mm_unpackhi_epi32
(
x_s21
x_s25
)
;
const
__m128i
x_s34
=
_mm_unpacklo_epi32
(
x_s22
x_s26
)
;
const
__m128i
x_s35
=
_mm_unpackhi_epi32
(
x_s22
x_s26
)
;
const
__m128i
x_s36
=
_mm_unpacklo_epi32
(
x_s23
x_s27
)
;
const
__m128i
x_s37
=
_mm_unpackhi_epi32
(
x_s23
x_s27
)
;
mm_storelu
(
dst
x_s30
)
;
mm_storehu
(
dst
+
(
1
*
out_p
)
x_s30
)
;
mm_storelu
(
dst
+
(
2
*
out_p
)
x_s31
)
;
mm_storehu
(
dst
+
(
3
*
out_p
)
x_s31
)
;
mm_storelu
(
dst
+
(
4
*
out_p
)
x_s32
)
;
mm_storehu
(
dst
+
(
5
*
out_p
)
x_s32
)
;
mm_storelu
(
dst
+
(
6
*
out_p
)
x_s33
)
;
mm_storehu
(
dst
+
(
7
*
out_p
)
x_s33
)
;
mm_storelu
(
dst
+
(
8
*
out_p
)
x_s34
)
;
mm_storehu
(
dst
+
(
9
*
out_p
)
x_s34
)
;
mm_storelu
(
dst
+
(
10
*
out_p
)
x_s35
)
;
mm_storehu
(
dst
+
(
11
*
out_p
)
x_s35
)
;
mm_storelu
(
dst
+
(
12
*
out_p
)
x_s36
)
;
mm_storehu
(
dst
+
(
13
*
out_p
)
x_s36
)
;
mm_storelu
(
dst
+
(
14
*
out_p
)
x_s37
)
;
mm_storehu
(
dst
+
(
15
*
out_p
)
x_s37
)
;
}
static
INLINE
void
transpose_8xn
(
unsigned
char
*
src
[
]
int
in_p
unsigned
char
*
dst
[
]
int
out_p
int
num_8x8_to_transpose
)
{
int
idx8x8
=
0
;
__m128i
x0
x1
x2
x3
x4
x5
x6
x7
;
do
{
unsigned
char
*
in
=
src
[
idx8x8
]
;
unsigned
char
*
out
=
dst
[
idx8x8
]
;
x0
=
_mm_loadl_epi64
(
(
__m128i
*
)
(
in
+
0
*
in_p
)
)
;
x1
=
_mm_loadl_epi64
(
(
__m128i
*
)
(
in
+
1
*
in_p
)
)
;
x0
=
_mm_unpacklo_epi8
(
x0
x1
)
;
x2
=
_mm_loadl_epi64
(
(
__m128i
*
)
(
in
+
2
*
in_p
)
)
;
x3
=
_mm_loadl_epi64
(
(
__m128i
*
)
(
in
+
3
*
in_p
)
)
;
x1
=
_mm_unpacklo_epi8
(
x2
x3
)
;
x4
=
_mm_loadl_epi64
(
(
__m128i
*
)
(
in
+
4
*
in_p
)
)
;
x5
=
_mm_loadl_epi64
(
(
__m128i
*
)
(
in
+
5
*
in_p
)
)
;
x2
=
_mm_unpacklo_epi8
(
x4
x5
)
;
x6
=
_mm_loadl_epi64
(
(
__m128i
*
)
(
in
+
6
*
in_p
)
)
;
x7
=
_mm_loadl_epi64
(
(
__m128i
*
)
(
in
+
7
*
in_p
)
)
;
x3
=
_mm_unpacklo_epi8
(
x6
x7
)
;
x4
=
_mm_unpacklo_epi16
(
x0
x1
)
;
x5
=
_mm_unpacklo_epi16
(
x2
x3
)
;
x6
=
_mm_unpacklo_epi32
(
x4
x5
)
;
mm_storelu
(
out
+
0
*
out_p
x6
)
;
mm_storehu
(
out
+
1
*
out_p
x6
)
;
x7
=
_mm_unpackhi_epi32
(
x4
x5
)
;
mm_storelu
(
out
+
2
*
out_p
x7
)
;
mm_storehu
(
out
+
3
*
out_p
x7
)
;
x4
=
_mm_unpackhi_epi16
(
x0
x1
)
;
x5
=
_mm_unpackhi_epi16
(
x2
x3
)
;
x6
=
_mm_unpacklo_epi32
(
x4
x5
)
;
mm_storelu
(
out
+
4
*
out_p
x6
)
;
mm_storehu
(
out
+
5
*
out_p
x6
)
;
x7
=
_mm_unpackhi_epi32
(
x4
x5
)
;
mm_storelu
(
out
+
6
*
out_p
x7
)
;
mm_storehu
(
out
+
7
*
out_p
x7
)
;
}
while
(
+
+
idx8x8
<
num_8x8_to_transpose
)
;
}
#
endif
