#
include
"
absl
/
container
/
internal
/
raw_hash_set
.
h
"
#
include
<
atomic
>
#
include
<
cassert
>
#
include
<
cstddef
>
#
include
<
cstdint
>
#
include
<
cstring
>
#
include
"
absl
/
base
/
attributes
.
h
"
#
include
"
absl
/
base
/
config
.
h
"
#
include
"
absl
/
base
/
dynamic_annotations
.
h
"
#
include
"
absl
/
base
/
internal
/
endian
.
h
"
#
include
"
absl
/
base
/
internal
/
raw_logging
.
h
"
#
include
"
absl
/
base
/
optimization
.
h
"
#
include
"
absl
/
container
/
internal
/
container_memory
.
h
"
#
include
"
absl
/
container
/
internal
/
hashtable_control_bytes
.
h
"
#
include
"
absl
/
container
/
internal
/
hashtablez_sampler
.
h
"
#
include
"
absl
/
functional
/
function_ref
.
h
"
#
include
"
absl
/
hash
/
hash
.
h
"
#
include
"
absl
/
numeric
/
bits
.
h
"
namespace
absl
{
ABSL_NAMESPACE_BEGIN
namespace
container_internal
{
constexpr
ctrl_t
ZeroCtrlT
(
)
{
return
static_cast
<
ctrl_t
>
(
0
)
;
}
alignas
(
16
)
ABSL_CONST_INIT
ABSL_DLL
const
ctrl_t
kEmptyGroup
[
32
]
=
{
ZeroCtrlT
(
)
ZeroCtrlT
(
)
ZeroCtrlT
(
)
ZeroCtrlT
(
)
ZeroCtrlT
(
)
ZeroCtrlT
(
)
ZeroCtrlT
(
)
ZeroCtrlT
(
)
ZeroCtrlT
(
)
ZeroCtrlT
(
)
ZeroCtrlT
(
)
ZeroCtrlT
(
)
ZeroCtrlT
(
)
ZeroCtrlT
(
)
ZeroCtrlT
(
)
ZeroCtrlT
(
)
ctrl_t
:
:
kSentinel
ctrl_t
:
:
kEmpty
ctrl_t
:
:
kEmpty
ctrl_t
:
:
kEmpty
ctrl_t
:
:
kEmpty
ctrl_t
:
:
kEmpty
ctrl_t
:
:
kEmpty
ctrl_t
:
:
kEmpty
ctrl_t
:
:
kEmpty
ctrl_t
:
:
kEmpty
ctrl_t
:
:
kEmpty
ctrl_t
:
:
kEmpty
ctrl_t
:
:
kEmpty
ctrl_t
:
:
kEmpty
ctrl_t
:
:
kEmpty
ctrl_t
:
:
kEmpty
}
;
ABSL_CONST_INIT
ABSL_DLL
const
ctrl_t
kSooControl
[
17
]
=
{
ZeroCtrlT
(
)
ctrl_t
:
:
kSentinel
ZeroCtrlT
(
)
ctrl_t
:
:
kEmpty
ctrl_t
:
:
kEmpty
ctrl_t
:
:
kEmpty
ctrl_t
:
:
kEmpty
ctrl_t
:
:
kEmpty
ctrl_t
:
:
kEmpty
ctrl_t
:
:
kEmpty
ctrl_t
:
:
kEmpty
ctrl_t
:
:
kEmpty
ctrl_t
:
:
kEmpty
ctrl_t
:
:
kEmpty
ctrl_t
:
:
kEmpty
ctrl_t
:
:
kEmpty
ctrl_t
:
:
kEmpty
}
;
static_assert
(
NumControlBytes
(
SooCapacity
(
)
)
<
=
17
"
kSooControl
capacity
too
small
"
)
;
namespace
{
inline
size_t
RandomSeed
(
)
{
#
ifdef
ABSL_HAVE_THREAD_LOCAL
static
thread_local
size_t
counter
=
0
;
ABSL_ANNOTATE_MEMORY_IS_INITIALIZED
(
&
counter
sizeof
(
size_t
)
)
;
size_t
value
=
+
+
counter
;
#
else
static
std
:
:
atomic
<
size_t
>
counter
(
0
)
;
size_t
value
=
counter
.
fetch_add
(
1
std
:
:
memory_order_relaxed
)
;
#
endif
return
value
^
static_cast
<
size_t
>
(
reinterpret_cast
<
uintptr_t
>
(
&
counter
)
)
;
}
bool
ShouldRehashForBugDetection
(
const
ctrl_t
*
ctrl
size_t
capacity
)
{
return
probe
(
ctrl
capacity
absl
:
:
HashOf
(
RandomSeed
(
)
)
)
.
offset
(
)
<
RehashProbabilityConstant
(
)
;
}
size_t
SingleGroupTableH1
(
size_t
hash
ctrl_t
*
control
)
{
return
static_cast
<
size_t
>
(
absl
:
:
popcount
(
hash
^
static_cast
<
size_t
>
(
reinterpret_cast
<
uintptr_t
>
(
control
)
)
)
)
;
}
inline
void
*
NextSlot
(
void
*
slot
size_t
slot_size
size_t
i
=
1
)
{
return
reinterpret_cast
<
void
*
>
(
reinterpret_cast
<
uintptr_t
>
(
slot
)
+
slot_size
*
i
)
;
}
inline
void
*
PrevSlot
(
void
*
slot
size_t
slot_size
)
{
return
reinterpret_cast
<
void
*
>
(
reinterpret_cast
<
uintptr_t
>
(
slot
)
-
slot_size
)
;
}
}
GenerationType
*
EmptyGeneration
(
)
{
if
(
SwisstableGenerationsEnabled
(
)
)
{
constexpr
size_t
kNumEmptyGenerations
=
1024
;
static
constexpr
GenerationType
kEmptyGenerations
[
kNumEmptyGenerations
]
{
}
;
return
const_cast
<
GenerationType
*
>
(
&
kEmptyGenerations
[
RandomSeed
(
)
%
kNumEmptyGenerations
]
)
;
}
return
nullptr
;
}
bool
CommonFieldsGenerationInfoEnabled
:
:
should_rehash_for_bug_detection_on_insert
(
const
ctrl_t
*
ctrl
size_t
capacity
)
const
{
if
(
reserved_growth_
=
=
kReservedGrowthJustRanOut
)
return
true
;
if
(
reserved_growth_
>
0
)
return
false
;
return
ShouldRehashForBugDetection
(
ctrl
capacity
)
;
}
bool
CommonFieldsGenerationInfoEnabled
:
:
should_rehash_for_bug_detection_on_move
(
const
ctrl_t
*
ctrl
size_t
capacity
)
const
{
return
ShouldRehashForBugDetection
(
ctrl
capacity
)
;
}
bool
ShouldInsertBackwardsForDebug
(
size_t
capacity
size_t
hash
const
ctrl_t
*
ctrl
)
{
return
!
is_small
(
capacity
)
&
&
(
H1
(
hash
ctrl
)
^
RandomSeed
(
)
)
%
13
>
6
;
}
void
IterateOverFullSlots
(
const
CommonFields
&
c
size_t
slot_size
absl
:
:
FunctionRef
<
void
(
const
ctrl_t
*
void
*
)
>
cb
)
{
const
size_t
cap
=
c
.
capacity
(
)
;
const
ctrl_t
*
ctrl
=
c
.
control
(
)
;
void
*
slot
=
c
.
slot_array
(
)
;
if
(
is_small
(
cap
)
)
{
assert
(
cap
<
=
GroupPortableImpl
:
:
kWidth
&
&
"
unexpectedly
large
small
capacity
"
)
;
static_assert
(
Group
:
:
kWidth
>
=
GroupPortableImpl
:
:
kWidth
"
unexpected
group
width
"
)
;
const
auto
mask
=
GroupPortableImpl
(
ctrl
+
cap
)
.
MaskFull
(
)
;
-
-
ctrl
;
slot
=
PrevSlot
(
slot
slot_size
)
;
for
(
uint32_t
i
:
mask
)
{
cb
(
ctrl
+
i
SlotAddress
(
slot
i
slot_size
)
)
;
}
return
;
}
size_t
remaining
=
c
.
size
(
)
;
ABSL_ATTRIBUTE_UNUSED
const
size_t
original_size_for_assert
=
remaining
;
while
(
remaining
!
=
0
)
{
for
(
uint32_t
i
:
GroupFullEmptyOrDeleted
(
ctrl
)
.
MaskFull
(
)
)
{
assert
(
IsFull
(
ctrl
[
i
]
)
&
&
"
hash
table
was
modified
unexpectedly
"
)
;
cb
(
ctrl
+
i
SlotAddress
(
slot
i
slot_size
)
)
;
-
-
remaining
;
}
ctrl
+
=
Group
:
:
kWidth
;
slot
=
NextSlot
(
slot
slot_size
Group
:
:
kWidth
)
;
assert
(
(
remaining
=
=
0
|
|
*
(
ctrl
-
1
)
!
=
ctrl_t
:
:
kSentinel
)
&
&
"
hash
table
was
modified
unexpectedly
"
)
;
}
assert
(
original_size_for_assert
>
=
c
.
size
(
)
&
&
"
hash
table
was
modified
unexpectedly
"
)
;
}
size_t
PrepareInsertAfterSoo
(
size_t
hash
size_t
slot_size
CommonFields
&
common
)
{
assert
(
common
.
capacity
(
)
=
=
NextCapacity
(
SooCapacity
(
)
)
)
;
static_assert
(
SooSlotIndex
(
)
=
=
1
"
"
)
;
PrepareInsertCommon
(
common
)
;
const
size_t
offset
=
SingleGroupTableH1
(
hash
common
.
control
(
)
)
&
2
;
common
.
growth_info
(
)
.
OverwriteEmptyAsFull
(
)
;
SetCtrlInSingleGroupTable
(
common
offset
H2
(
hash
)
slot_size
)
;
common
.
infoz
(
)
.
RecordInsert
(
hash
0
)
;
return
offset
;
}
void
ConvertDeletedToEmptyAndFullToDeleted
(
ctrl_t
*
ctrl
size_t
capacity
)
{
assert
(
ctrl
[
capacity
]
=
=
ctrl_t
:
:
kSentinel
)
;
assert
(
IsValidCapacity
(
capacity
)
)
;
for
(
ctrl_t
*
pos
=
ctrl
;
pos
<
ctrl
+
capacity
;
pos
+
=
Group
:
:
kWidth
)
{
Group
{
pos
}
.
ConvertSpecialToEmptyAndFullToDeleted
(
pos
)
;
}
std
:
:
memcpy
(
ctrl
+
capacity
+
1
ctrl
NumClonedBytes
(
)
)
;
ctrl
[
capacity
]
=
ctrl_t
:
:
kSentinel
;
}
template
FindInfo
find_first_non_full
(
const
CommonFields
&
size_t
)
;
FindInfo
find_first_non_full_outofline
(
const
CommonFields
&
common
size_t
hash
)
{
return
find_first_non_full
(
common
hash
)
;
}
namespace
{
size_t
FindEmptySlot
(
size_t
start
size_t
end
const
ctrl_t
*
ctrl
)
{
for
(
size_t
i
=
start
;
i
<
end
;
+
+
i
)
{
if
(
IsEmpty
(
ctrl
[
i
]
)
)
{
return
i
;
}
}
ABSL_UNREACHABLE
(
)
;
}
size_t
FindFirstFullSlot
(
size_t
start
size_t
end
const
ctrl_t
*
ctrl
)
{
for
(
size_t
i
=
start
;
i
<
end
;
+
+
i
)
{
if
(
IsFull
(
ctrl
[
i
]
)
)
{
return
i
;
}
}
ABSL_UNREACHABLE
(
)
;
}
size_t
DropDeletesWithoutResizeAndPrepareInsert
(
CommonFields
&
common
size_t
new_hash
const
PolicyFunctions
&
policy
)
{
void
*
set
=
&
common
;
void
*
slot_array
=
common
.
slot_array
(
)
;
const
size_t
capacity
=
common
.
capacity
(
)
;
assert
(
IsValidCapacity
(
capacity
)
)
;
assert
(
!
is_small
(
capacity
)
)
;
ctrl_t
*
ctrl
=
common
.
control
(
)
;
ConvertDeletedToEmptyAndFullToDeleted
(
ctrl
capacity
)
;
const
void
*
hash_fn
=
policy
.
hash_fn
(
common
)
;
auto
hasher
=
policy
.
hash_slot
;
auto
transfer
=
policy
.
transfer
;
const
size_t
slot_size
=
policy
.
slot_size
;
size_t
total_probe_length
=
0
;
void
*
slot_ptr
=
SlotAddress
(
slot_array
0
slot_size
)
;
constexpr
size_t
kUnknownId
=
~
size_t
{
}
;
size_t
tmp_space_id
=
kUnknownId
;
for
(
size_t
i
=
0
;
i
!
=
capacity
;
+
+
i
slot_ptr
=
NextSlot
(
slot_ptr
slot_size
)
)
{
assert
(
slot_ptr
=
=
SlotAddress
(
slot_array
i
slot_size
)
)
;
if
(
IsEmpty
(
ctrl
[
i
]
)
)
{
tmp_space_id
=
i
;
continue
;
}
if
(
!
IsDeleted
(
ctrl
[
i
]
)
)
continue
;
const
size_t
hash
=
(
*
hasher
)
(
hash_fn
slot_ptr
)
;
const
FindInfo
target
=
find_first_non_full
(
common
hash
)
;
const
size_t
new_i
=
target
.
offset
;
total_probe_length
+
=
target
.
probe_length
;
const
size_t
probe_offset
=
probe
(
common
hash
)
.
offset
(
)
;
const
auto
probe_index
=
[
probe_offset
capacity
]
(
size_t
pos
)
{
return
(
(
pos
-
probe_offset
)
&
capacity
)
/
Group
:
:
kWidth
;
}
;
if
(
ABSL_PREDICT_TRUE
(
probe_index
(
new_i
)
=
=
probe_index
(
i
)
)
)
{
SetCtrlInLargeTable
(
common
i
H2
(
hash
)
slot_size
)
;
continue
;
}
void
*
new_slot_ptr
=
SlotAddress
(
slot_array
new_i
slot_size
)
;
if
(
IsEmpty
(
ctrl
[
new_i
]
)
)
{
SetCtrlInLargeTable
(
common
new_i
H2
(
hash
)
slot_size
)
;
(
*
transfer
)
(
set
new_slot_ptr
slot_ptr
1
)
;
SetCtrlInLargeTable
(
common
i
ctrl_t
:
:
kEmpty
slot_size
)
;
tmp_space_id
=
i
;
}
else
{
assert
(
IsDeleted
(
ctrl
[
new_i
]
)
)
;
SetCtrlInLargeTable
(
common
new_i
H2
(
hash
)
slot_size
)
;
if
(
tmp_space_id
=
=
kUnknownId
)
{
tmp_space_id
=
FindEmptySlot
(
i
+
1
capacity
ctrl
)
;
}
void
*
tmp_space
=
SlotAddress
(
slot_array
tmp_space_id
slot_size
)
;
SanitizerUnpoisonMemoryRegion
(
tmp_space
slot_size
)
;
(
*
transfer
)
(
set
tmp_space
new_slot_ptr
1
)
;
(
*
transfer
)
(
set
new_slot_ptr
slot_ptr
1
)
;
(
*
transfer
)
(
set
slot_ptr
tmp_space
1
)
;
SanitizerPoisonMemoryRegion
(
tmp_space
slot_size
)
;
-
-
i
;
slot_ptr
=
PrevSlot
(
slot_ptr
slot_size
)
;
}
}
PrepareInsertCommon
(
common
)
;
ResetGrowthLeft
(
common
)
;
FindInfo
find_info
=
find_first_non_full
(
common
new_hash
)
;
SetCtrlInLargeTable
(
common
find_info
.
offset
H2
(
new_hash
)
policy
.
slot_size
)
;
common
.
infoz
(
)
.
RecordInsert
(
new_hash
find_info
.
probe_length
)
;
common
.
infoz
(
)
.
RecordRehash
(
total_probe_length
)
;
return
find_info
.
offset
;
}
static
bool
WasNeverFull
(
CommonFields
&
c
size_t
index
)
{
if
(
is_single_group
(
c
.
capacity
(
)
)
)
{
return
true
;
}
const
size_t
index_before
=
(
index
-
Group
:
:
kWidth
)
&
c
.
capacity
(
)
;
const
auto
empty_after
=
Group
(
c
.
control
(
)
+
index
)
.
MaskEmpty
(
)
;
const
auto
empty_before
=
Group
(
c
.
control
(
)
+
index_before
)
.
MaskEmpty
(
)
;
return
empty_before
&
&
empty_after
&
&
static_cast
<
size_t
>
(
empty_after
.
TrailingZeros
(
)
)
+
empty_before
.
LeadingZeros
(
)
<
Group
:
:
kWidth
;
}
ABSL_ATTRIBUTE_ALWAYS_INLINE
inline
void
InitializeSingleElementControlBytes
(
uint64_t
h2
ctrl_t
*
new_ctrl
)
{
static
constexpr
uint64_t
kEmptyXorSentinel
=
static_cast
<
uint8_t
>
(
ctrl_t
:
:
kEmpty
)
^
static_cast
<
uint8_t
>
(
ctrl_t
:
:
kSentinel
)
;
static
constexpr
uint64_t
kEmpty64
=
static_cast
<
uint8_t
>
(
ctrl_t
:
:
kEmpty
)
;
static
constexpr
uint64_t
kFirstCtrlBytesWithZeroes
=
k8EmptyBytes
^
kEmpty64
^
(
kEmptyXorSentinel
<
<
8
)
^
(
kEmpty64
<
<
16
)
;
const
uint64_t
first_ctrl_bytes
=
(
h2
|
kFirstCtrlBytesWithZeroes
)
|
(
h2
<
<
16
)
;
std
:
:
memset
(
new_ctrl
+
1
static_cast
<
int8_t
>
(
ctrl_t
:
:
kEmpty
)
Group
:
:
kWidth
)
;
absl
:
:
little_endian
:
:
Store64
(
new_ctrl
first_ctrl_bytes
)
;
}
}
void
EraseMetaOnly
(
CommonFields
&
c
size_t
index
size_t
slot_size
)
{
assert
(
IsFull
(
c
.
control
(
)
[
index
]
)
&
&
"
erasing
a
dangling
iterator
"
)
;
c
.
decrement_size
(
)
;
c
.
infoz
(
)
.
RecordErase
(
)
;
if
(
WasNeverFull
(
c
index
)
)
{
SetCtrl
(
c
index
ctrl_t
:
:
kEmpty
slot_size
)
;
c
.
growth_info
(
)
.
OverwriteFullAsEmpty
(
)
;
return
;
}
c
.
growth_info
(
)
.
OverwriteFullAsDeleted
(
)
;
SetCtrlInLargeTable
(
c
index
ctrl_t
:
:
kDeleted
slot_size
)
;
}
void
ClearBackingArray
(
CommonFields
&
c
const
PolicyFunctions
&
policy
void
*
alloc
bool
reuse
bool
soo_enabled
)
{
c
.
set_size
(
0
)
;
if
(
reuse
)
{
assert
(
!
soo_enabled
|
|
c
.
capacity
(
)
>
SooCapacity
(
)
)
;
ResetCtrl
(
c
policy
.
slot_size
)
;
ResetGrowthLeft
(
c
)
;
c
.
infoz
(
)
.
RecordStorageChanged
(
0
c
.
capacity
(
)
)
;
}
else
{
c
.
infoz
(
)
.
RecordClearedReservation
(
)
;
c
.
infoz
(
)
.
RecordStorageChanged
(
0
soo_enabled
?
SooCapacity
(
)
:
0
)
;
c
.
infoz
(
)
.
Unregister
(
)
;
(
*
policy
.
dealloc
)
(
alloc
c
.
capacity
(
)
c
.
control
(
)
policy
.
slot_size
policy
.
slot_align
c
.
has_infoz
(
)
)
;
c
=
soo_enabled
?
CommonFields
{
soo_tag_t
{
}
}
:
CommonFields
{
non_soo_tag_t
{
}
}
;
}
}
namespace
{
void
PoisonEmptySlots
(
CommonFields
&
c
size_t
slot_size
)
{
for
(
size_t
i
=
0
;
i
<
c
.
capacity
(
)
;
+
+
i
)
{
if
(
!
IsFull
(
c
.
control
(
)
[
i
]
)
)
{
SanitizerPoisonMemoryRegion
(
SlotAddress
(
c
.
slot_array
(
)
i
slot_size
)
slot_size
)
;
}
}
}
template
<
bool
kGuaranteedEmpty
bool
kGuaranteedAllocated
>
void
ResizeNonSooImpl
(
CommonFields
&
common
size_t
new_capacity
HashtablezInfoHandle
infoz
const
PolicyFunctions
&
policy
)
{
static_assert
(
!
kGuaranteedEmpty
|
|
!
kGuaranteedAllocated
)
;
assert
(
IsValidCapacity
(
new_capacity
)
)
;
assert
(
new_capacity
>
policy
.
soo_capacity
)
;
const
size_t
old_capacity
=
common
.
capacity
(
)
;
[
[
maybe_unused
]
]
ctrl_t
*
old_ctrl
=
common
.
control
(
)
;
[
[
maybe_unused
]
]
void
*
old_slots
=
common
.
slot_array
(
)
;
const
size_t
slot_size
=
policy
.
slot_size
;
const
size_t
slot_align
=
policy
.
slot_align
;
const
bool
has_infoz
=
infoz
.
IsSampled
(
)
;
common
.
set_capacity
(
new_capacity
)
;
RawHashSetLayout
layout
(
new_capacity
slot_size
slot_align
has_infoz
)
;
void
*
alloc
=
policy
.
get_char_alloc
(
common
)
;
char
*
mem
=
static_cast
<
char
*
>
(
policy
.
alloc
(
alloc
layout
.
alloc_size
(
)
)
)
;
const
GenerationType
old_generation
=
common
.
generation
(
)
;
common
.
set_generation_ptr
(
reinterpret_cast
<
GenerationType
*
>
(
mem
+
layout
.
generation_offset
(
)
)
)
;
common
.
set_generation
(
NextGeneration
(
old_generation
)
)
;
common
.
set_control
(
reinterpret_cast
<
ctrl_t
*
>
(
mem
+
layout
.
control_offset
(
)
)
)
;
common
.
set_slots
(
mem
+
layout
.
slot_offset
(
)
)
;
size_t
total_probe_length
=
0
;
ResetCtrl
(
common
slot_size
)
;
assert
(
!
kGuaranteedEmpty
|
|
old_capacity
=
=
policy
.
soo_capacity
)
;
assert
(
!
kGuaranteedAllocated
|
|
old_capacity
>
0
)
;
if
constexpr
(
!
kGuaranteedEmpty
)
{
if
(
kGuaranteedAllocated
|
|
old_capacity
>
0
)
{
total_probe_length
=
policy
.
find_new_positions_and_transfer_slots
(
common
old_ctrl
old_slots
old_capacity
)
;
(
*
policy
.
dealloc
)
(
alloc
old_capacity
old_ctrl
slot_size
slot_align
has_infoz
)
;
}
}
ResetGrowthLeft
(
common
)
;
common
.
set_has_infoz
(
has_infoz
)
;
if
(
has_infoz
)
{
infoz
.
RecordStorageChanged
(
common
.
size
(
)
new_capacity
)
;
infoz
.
RecordRehash
(
total_probe_length
)
;
common
.
set_infoz
(
infoz
)
;
}
}
void
ResizeEmptyNonAllocatedTableImpl
(
CommonFields
&
common
size_t
new_capacity
bool
force_infoz
const
PolicyFunctions
&
policy
)
{
assert
(
IsValidCapacity
(
new_capacity
)
)
;
assert
(
new_capacity
>
policy
.
soo_capacity
)
;
assert
(
!
force_infoz
|
|
policy
.
soo_capacity
>
0
)
;
assert
(
common
.
capacity
(
)
<
=
policy
.
soo_capacity
)
;
assert
(
common
.
empty
(
)
)
;
const
size_t
slot_size
=
policy
.
slot_size
;
if
(
ABSL_PREDICT_FALSE
(
new_capacity
>
MaxValidCapacity
(
slot_size
)
)
)
{
HashTableSizeOverflow
(
)
;
}
HashtablezInfoHandle
infoz
;
const
bool
should_sample
=
policy
.
is_hashtablez_eligible
&
&
(
force_infoz
|
|
ShouldSampleNextTable
(
)
)
;
if
(
ABSL_PREDICT_FALSE
(
should_sample
)
)
{
infoz
=
ForcedTrySample
(
slot_size
policy
.
key_size
policy
.
value_size
policy
.
soo_capacity
)
;
}
ResizeNonSooImpl
<
true
false
>
(
common
new_capacity
infoz
policy
)
;
}
void
InsertOldSooSlotAndInitializeControlBytes
(
CommonFields
&
c
size_t
hash
ctrl_t
*
new_ctrl
void
*
new_slots
const
PolicyFunctions
&
policy
)
{
assert
(
c
.
size
(
)
=
=
policy
.
soo_capacity
)
;
assert
(
policy
.
soo_capacity
=
=
SooCapacity
(
)
)
;
size_t
new_capacity
=
c
.
capacity
(
)
;
size_t
offset
=
probe
(
new_ctrl
new_capacity
hash
)
.
offset
(
)
;
offset
=
offset
=
=
new_capacity
?
0
:
offset
;
SanitizerPoisonMemoryRegion
(
new_slots
policy
.
slot_size
*
new_capacity
)
;
void
*
target_slot
=
SlotAddress
(
new_slots
offset
policy
.
slot_size
)
;
SanitizerUnpoisonMemoryRegion
(
target_slot
policy
.
slot_size
)
;
policy
.
transfer
(
&
c
target_slot
c
.
soo_data
(
)
1
)
;
c
.
set_control
(
new_ctrl
)
;
c
.
set_slots
(
new_slots
)
;
ResetCtrl
(
c
policy
.
slot_size
)
;
SetCtrl
(
c
offset
H2
(
hash
)
policy
.
slot_size
)
;
}
enum
class
ResizeFullSooTableSamplingMode
{
kNoSampling
kForceSampleNoResizeIfUnsampled
}
;
void
ResizeFullSooTable
(
CommonFields
&
common
size_t
new_capacity
ResizeFullSooTableSamplingMode
sampling_mode
const
PolicyFunctions
&
policy
)
{
assert
(
common
.
capacity
(
)
=
=
policy
.
soo_capacity
)
;
assert
(
common
.
size
(
)
=
=
policy
.
soo_capacity
)
;
assert
(
policy
.
soo_capacity
=
=
SooCapacity
(
)
)
;
const
size_t
slot_size
=
policy
.
slot_size
;
const
size_t
slot_align
=
policy
.
slot_align
;
HashtablezInfoHandle
infoz
;
if
(
sampling_mode
=
=
ResizeFullSooTableSamplingMode
:
:
kForceSampleNoResizeIfUnsampled
)
{
if
(
ABSL_PREDICT_FALSE
(
policy
.
is_hashtablez_eligible
)
)
{
infoz
=
ForcedTrySample
(
slot_size
policy
.
key_size
policy
.
value_size
policy
.
soo_capacity
)
;
}
if
(
!
infoz
.
IsSampled
(
)
)
{
return
;
}
}
const
bool
has_infoz
=
infoz
.
IsSampled
(
)
;
common
.
set_capacity
(
new_capacity
)
;
RawHashSetLayout
layout
(
new_capacity
slot_size
slot_align
has_infoz
)
;
void
*
alloc
=
policy
.
get_char_alloc
(
common
)
;
char
*
mem
=
static_cast
<
char
*
>
(
policy
.
alloc
(
alloc
layout
.
alloc_size
(
)
)
)
;
const
GenerationType
old_generation
=
common
.
generation
(
)
;
common
.
set_generation_ptr
(
reinterpret_cast
<
GenerationType
*
>
(
mem
+
layout
.
generation_offset
(
)
)
)
;
common
.
set_generation
(
NextGeneration
(
old_generation
)
)
;
ctrl_t
*
new_ctrl
=
reinterpret_cast
<
ctrl_t
*
>
(
mem
+
layout
.
control_offset
(
)
)
;
void
*
new_slots
=
mem
+
layout
.
slot_offset
(
)
;
const
size_t
soo_slot_hash
=
policy
.
hash_slot
(
policy
.
hash_fn
(
common
)
common
.
soo_data
(
)
)
;
InsertOldSooSlotAndInitializeControlBytes
(
common
soo_slot_hash
new_ctrl
new_slots
policy
)
;
ResetGrowthLeft
(
common
)
;
if
(
has_infoz
)
{
common
.
set_has_infoz
(
has_infoz
)
;
common
.
set_infoz
(
infoz
)
;
}
}
void
GrowIntoSingleGroupShuffleControlBytes
(
ctrl_t
*
__restrict
old_ctrl
size_t
old_capacity
ctrl_t
*
__restrict
new_ctrl
size_t
new_capacity
)
{
assert
(
is_single_group
(
new_capacity
)
)
;
constexpr
size_t
kHalfWidth
=
Group
:
:
kWidth
/
2
;
ABSL_ASSUME
(
old_capacity
<
kHalfWidth
)
;
ABSL_ASSUME
(
old_capacity
>
0
)
;
static_assert
(
Group
:
:
kWidth
=
=
8
|
|
Group
:
:
kWidth
=
=
16
"
Group
size
is
not
supported
.
"
)
;
uint64_t
copied_bytes
=
absl
:
:
little_endian
:
:
Load64
(
old_ctrl
+
old_capacity
)
;
static
constexpr
uint64_t
kEmptyXorSentinel
=
static_cast
<
uint8_t
>
(
ctrl_t
:
:
kEmpty
)
^
static_cast
<
uint8_t
>
(
ctrl_t
:
:
kSentinel
)
;
copied_bytes
^
=
kEmptyXorSentinel
;
if
(
Group
:
:
kWidth
=
=
8
)
{
assert
(
old_capacity
<
8
&
&
"
old_capacity
is
too
large
for
group
size
8
"
)
;
absl
:
:
little_endian
:
:
Store64
(
new_ctrl
copied_bytes
)
;
static
constexpr
uint64_t
kSentinal64
=
static_cast
<
uint8_t
>
(
ctrl_t
:
:
kSentinel
)
;
copied_bytes
=
(
copied_bytes
<
<
8
)
^
kSentinal64
;
absl
:
:
little_endian
:
:
Store64
(
new_ctrl
+
new_capacity
copied_bytes
)
;
return
;
}
assert
(
Group
:
:
kWidth
=
=
16
)
;
std
:
:
memset
(
new_ctrl
+
kHalfWidth
static_cast
<
int8_t
>
(
ctrl_t
:
:
kEmpty
)
kHalfWidth
)
;
std
:
:
memset
(
new_ctrl
+
new_capacity
+
kHalfWidth
static_cast
<
int8_t
>
(
ctrl_t
:
:
kEmpty
)
kHalfWidth
)
;
absl
:
:
little_endian
:
:
Store64
(
new_ctrl
copied_bytes
)
;
new_ctrl
[
new_capacity
]
=
ctrl_t
:
:
kSentinel
;
absl
:
:
little_endian
:
:
Store64
(
new_ctrl
+
new_capacity
+
1
copied_bytes
)
;
}
size_t
GrowToNextCapacityAndPrepareInsert
(
CommonFields
&
common
size_t
new_hash
const
PolicyFunctions
&
policy
)
{
assert
(
common
.
growth_left
(
)
=
=
0
)
;
const
size_t
old_capacity
=
common
.
capacity
(
)
;
assert
(
old_capacity
=
=
0
|
|
old_capacity
>
policy
.
soo_capacity
)
;
const
size_t
new_capacity
=
NextCapacity
(
old_capacity
)
;
assert
(
IsValidCapacity
(
new_capacity
)
)
;
assert
(
new_capacity
>
policy
.
soo_capacity
)
;
ctrl_t
*
old_ctrl
=
common
.
control
(
)
;
void
*
old_slots
=
common
.
slot_array
(
)
;
common
.
set_capacity
(
new_capacity
)
;
const
size_t
slot_size
=
policy
.
slot_size
;
const
size_t
slot_align
=
policy
.
slot_align
;
HashtablezInfoHandle
infoz
;
if
(
old_capacity
>
0
)
{
infoz
=
common
.
infoz
(
)
;
}
else
{
const
bool
should_sample
=
policy
.
is_hashtablez_eligible
&
&
ShouldSampleNextTable
(
)
;
if
(
ABSL_PREDICT_FALSE
(
should_sample
)
)
{
infoz
=
ForcedTrySample
(
slot_size
policy
.
key_size
policy
.
value_size
policy
.
soo_capacity
)
;
}
}
const
bool
has_infoz
=
infoz
.
IsSampled
(
)
;
RawHashSetLayout
layout
(
new_capacity
slot_size
slot_align
has_infoz
)
;
void
*
alloc
=
policy
.
get_char_alloc
(
common
)
;
char
*
mem
=
static_cast
<
char
*
>
(
policy
.
alloc
(
alloc
layout
.
alloc_size
(
)
)
)
;
const
GenerationType
old_generation
=
common
.
generation
(
)
;
common
.
set_generation_ptr
(
reinterpret_cast
<
GenerationType
*
>
(
mem
+
layout
.
generation_offset
(
)
)
)
;
common
.
set_generation
(
NextGeneration
(
old_generation
)
)
;
ctrl_t
*
new_ctrl
=
reinterpret_cast
<
ctrl_t
*
>
(
mem
+
layout
.
control_offset
(
)
)
;
void
*
new_slots
=
mem
+
layout
.
slot_offset
(
)
;
common
.
set_control
(
new_ctrl
)
;
common
.
set_slots
(
new_slots
)
;
h2_t
new_h2
=
H2
(
new_hash
)
;
size_t
total_probe_length
=
0
;
FindInfo
find_info
;
if
(
old_capacity
=
=
0
)
{
static_assert
(
NextCapacity
(
0
)
=
=
1
)
;
InitializeSingleElementControlBytes
(
new_h2
new_ctrl
)
;
find_info
=
FindInfo
{
0
0
}
;
}
else
{
if
(
is_single_group
(
new_capacity
)
)
{
GrowIntoSingleGroupShuffleControlBytes
(
old_ctrl
old_capacity
new_ctrl
new_capacity
)
;
assert
(
common
.
size
(
)
=
=
old_capacity
)
;
policy
.
transfer
(
&
common
NextSlot
(
new_slots
slot_size
)
old_slots
old_capacity
)
;
PoisonEmptySlots
(
common
slot_size
)
;
size_t
offset
=
SingleGroupTableH1
(
new_hash
new_ctrl
)
&
1
?
0
:
new_capacity
-
1
;
assert
(
IsEmpty
(
new_ctrl
[
offset
]
)
)
;
SetCtrlInSingleGroupTable
(
common
offset
new_h2
policy
.
slot_size
)
;
find_info
=
FindInfo
{
offset
0
}
;
}
else
{
ResetCtrl
(
common
slot_size
)
;
total_probe_length
=
policy
.
find_new_positions_and_transfer_slots
(
common
old_ctrl
old_slots
old_capacity
)
;
find_info
=
find_first_non_full
(
common
new_hash
)
;
SetCtrlInLargeTable
(
common
find_info
.
offset
new_h2
policy
.
slot_size
)
;
}
assert
(
old_capacity
>
policy
.
soo_capacity
)
;
(
*
policy
.
dealloc
)
(
alloc
old_capacity
old_ctrl
slot_size
slot_align
has_infoz
)
;
}
PrepareInsertCommon
(
common
)
;
ResetGrowthLeft
(
common
)
;
common
.
set_has_infoz
(
has_infoz
)
;
if
(
has_infoz
)
{
infoz
.
RecordStorageChanged
(
common
.
size
(
)
-
1
new_capacity
)
;
infoz
.
RecordRehash
(
total_probe_length
)
;
infoz
.
RecordInsert
(
new_hash
find_info
.
probe_length
)
;
common
.
set_infoz
(
infoz
)
;
}
return
find_info
.
offset
;
}
ABSL_ATTRIBUTE_NOINLINE
size_t
RehashOrGrowToNextCapacityAndPrepareInsert
(
CommonFields
&
common
size_t
new_hash
const
PolicyFunctions
&
policy
)
{
const
size_t
cap
=
common
.
capacity
(
)
;
ABSL_ASSUME
(
cap
>
0
)
;
if
(
cap
>
Group
:
:
kWidth
&
&
common
.
size
(
)
*
uint64_t
{
32
}
<
=
cap
*
uint64_t
{
25
}
)
{
return
DropDeletesWithoutResizeAndPrepareInsert
(
common
new_hash
policy
)
;
}
else
{
return
GrowToNextCapacityAndPrepareInsert
(
common
new_hash
policy
)
;
}
}
size_t
PrepareInsertNonSooSlow
(
CommonFields
&
common
size_t
hash
const
PolicyFunctions
&
policy
)
{
const
GrowthInfo
growth_info
=
common
.
growth_info
(
)
;
assert
(
!
growth_info
.
HasNoDeletedAndGrowthLeft
(
)
)
;
if
(
ABSL_PREDICT_TRUE
(
growth_info
.
HasNoGrowthLeftAndNoDeleted
(
)
)
)
{
assert
(
growth_info
.
HasNoDeleted
(
)
&
&
growth_info
.
GetGrowthLeft
(
)
=
=
0
)
;
return
GrowToNextCapacityAndPrepareInsert
(
common
hash
policy
)
;
}
if
(
ABSL_PREDICT_FALSE
(
growth_info
.
HasNoGrowthLeftAssumingMayHaveDeleted
(
)
)
)
{
return
RehashOrGrowToNextCapacityAndPrepareInsert
(
common
hash
policy
)
;
}
FindInfo
target
=
find_first_non_full
(
common
hash
)
;
PrepareInsertCommon
(
common
)
;
common
.
growth_info
(
)
.
OverwriteControlAsFull
(
common
.
control
(
)
[
target
.
offset
]
)
;
SetCtrlInLargeTable
(
common
target
.
offset
H2
(
hash
)
policy
.
slot_size
)
;
common
.
infoz
(
)
.
RecordInsert
(
hash
target
.
probe_length
)
;
return
target
.
offset
;
}
}
void
*
GetRefForEmptyClass
(
CommonFields
&
common
)
{
return
&
common
;
}
void
ResizeAllocatedTable
(
CommonFields
&
common
size_t
new_capacity
const
PolicyFunctions
&
policy
)
{
ResizeNonSooImpl
<
false
true
>
(
common
new_capacity
common
.
infoz
(
)
policy
)
;
}
void
ResizeEmptyNonAllocatedTable
(
CommonFields
&
common
size_t
new_capacity
const
PolicyFunctions
&
policy
)
{
ResizeEmptyNonAllocatedTableImpl
(
common
new_capacity
false
policy
)
;
}
void
GrowEmptySooTableToNextCapacityForceSampling
(
CommonFields
&
common
const
PolicyFunctions
&
policy
)
{
ResizeEmptyNonAllocatedTableImpl
(
common
NextCapacity
(
SooCapacity
(
)
)
true
policy
)
;
}
void
GrowFullSooTableToNextCapacityForceSampling
(
CommonFields
&
common
const
PolicyFunctions
&
policy
)
{
assert
(
common
.
capacity
(
)
=
=
policy
.
soo_capacity
)
;
assert
(
common
.
size
(
)
=
=
policy
.
soo_capacity
)
;
assert
(
policy
.
soo_capacity
=
=
SooCapacity
(
)
)
;
ResizeFullSooTable
(
common
NextCapacity
(
SooCapacity
(
)
)
ResizeFullSooTableSamplingMode
:
:
kForceSampleNoResizeIfUnsampled
policy
)
;
}
void
Rehash
(
CommonFields
&
common
size_t
n
const
PolicyFunctions
&
policy
)
{
const
size_t
cap
=
common
.
capacity
(
)
;
auto
clear_backing_array
=
[
&
]
(
)
{
ClearBackingArray
(
common
policy
policy
.
get_char_alloc
(
common
)
false
policy
.
soo_capacity
>
0
)
;
}
;
const
size_t
slot_size
=
policy
.
slot_size
;
if
(
n
=
=
0
)
{
if
(
cap
<
=
policy
.
soo_capacity
)
return
;
if
(
common
.
empty
(
)
)
{
clear_backing_array
(
)
;
return
;
}
if
(
common
.
size
(
)
<
=
policy
.
soo_capacity
)
{
if
(
common
.
infoz
(
)
.
IsSampled
(
)
)
{
static
constexpr
size_t
kInitialSampledCapacity
=
NextCapacity
(
SooCapacity
(
)
)
;
if
(
cap
>
kInitialSampledCapacity
)
{
ResizeAllocatedTable
(
common
kInitialSampledCapacity
policy
)
;
}
assert
(
common
.
infoz
(
)
.
IsSampled
(
)
)
;
return
;
}
assert
(
slot_size
<
=
sizeof
(
HeapOrSoo
)
)
;
assert
(
policy
.
slot_align
<
=
alignof
(
HeapOrSoo
)
)
;
HeapOrSoo
tmp_slot
;
size_t
begin_offset
=
FindFirstFullSlot
(
0
cap
common
.
control
(
)
)
;
policy
.
transfer
(
&
common
&
tmp_slot
SlotAddress
(
common
.
slot_array
(
)
begin_offset
slot_size
)
1
)
;
clear_backing_array
(
)
;
policy
.
transfer
(
&
common
common
.
soo_data
(
)
&
tmp_slot
1
)
;
common
.
set_full_soo
(
)
;
return
;
}
}
const
size_t
new_capacity
=
NormalizeCapacity
(
n
|
GrowthToLowerboundCapacity
(
common
.
size
(
)
)
)
;
if
(
n
=
=
0
|
|
new_capacity
>
cap
)
{
if
(
ABSL_PREDICT_FALSE
(
new_capacity
>
MaxValidCapacity
(
slot_size
)
)
)
{
HashTableSizeOverflow
(
)
;
}
if
(
cap
=
=
policy
.
soo_capacity
)
{
if
(
common
.
empty
(
)
)
{
ResizeEmptyNonAllocatedTable
(
common
new_capacity
policy
)
;
}
else
{
ResizeFullSooTable
(
common
new_capacity
ResizeFullSooTableSamplingMode
:
:
kNoSampling
policy
)
;
}
}
else
{
ResizeAllocatedTable
(
common
new_capacity
policy
)
;
}
common
.
infoz
(
)
.
RecordReservation
(
n
)
;
}
}
void
ReserveAllocatedTable
(
CommonFields
&
common
size_t
n
const
PolicyFunctions
&
policy
)
{
const
size_t
cap
=
common
.
capacity
(
)
;
assert
(
!
common
.
empty
(
)
|
|
cap
>
policy
.
soo_capacity
)
;
assert
(
cap
>
0
)
;
const
size_t
max_size_before_growth
=
cap
<
=
policy
.
soo_capacity
?
policy
.
soo_capacity
:
common
.
size
(
)
+
common
.
growth_left
(
)
;
if
(
n
<
=
max_size_before_growth
)
{
return
;
}
const
size_t
new_capacity
=
NormalizeCapacity
(
GrowthToLowerboundCapacity
(
n
)
)
;
if
(
ABSL_PREDICT_FALSE
(
new_capacity
>
MaxValidCapacity
(
policy
.
slot_size
)
)
)
{
HashTableSizeOverflow
(
)
;
}
if
(
cap
=
=
policy
.
soo_capacity
)
{
assert
(
!
common
.
empty
(
)
)
;
ResizeFullSooTable
(
common
new_capacity
ResizeFullSooTableSamplingMode
:
:
kNoSampling
policy
)
;
}
else
{
assert
(
cap
>
policy
.
soo_capacity
)
;
ResizeAllocatedTable
(
common
new_capacity
policy
)
;
}
common
.
infoz
(
)
.
RecordReservation
(
n
)
;
}
size_t
PrepareInsertNonSoo
(
CommonFields
&
common
size_t
hash
const
PolicyFunctions
&
policy
FindInfo
target
)
{
const
bool
rehash_for_bug_detection
=
common
.
should_rehash_for_bug_detection_on_insert
(
)
&
&
common
.
capacity
(
)
>
0
;
if
(
rehash_for_bug_detection
)
{
const
size_t
cap
=
common
.
capacity
(
)
;
ResizeAllocatedTable
(
common
common
.
growth_left
(
)
>
0
?
cap
:
NextCapacity
(
cap
)
policy
)
;
target
=
find_first_non_full
(
common
hash
)
;
}
const
GrowthInfo
growth_info
=
common
.
growth_info
(
)
;
if
(
ABSL_PREDICT_FALSE
(
!
growth_info
.
HasNoDeletedAndGrowthLeft
(
)
)
)
{
return
PrepareInsertNonSooSlow
(
common
hash
policy
)
;
}
PrepareInsertCommon
(
common
)
;
common
.
growth_info
(
)
.
OverwriteEmptyAsFull
(
)
;
SetCtrl
(
common
target
.
offset
H2
(
hash
)
policy
.
slot_size
)
;
common
.
infoz
(
)
.
RecordInsert
(
hash
target
.
probe_length
)
;
return
target
.
offset
;
}
void
HashTableSizeOverflow
(
)
{
ABSL_RAW_LOG
(
FATAL
"
Hash
table
size
overflow
"
)
;
}
}
ABSL_NAMESPACE_END
}
