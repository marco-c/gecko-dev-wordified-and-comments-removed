#
ifndef
ABSL_CONTAINER_INTERNAL_RAW_HASH_SET_H_
#
define
ABSL_CONTAINER_INTERNAL_RAW_HASH_SET_H_
#
ifdef
__SSE2__
#
include
<
emmintrin
.
h
>
#
endif
#
ifdef
__SSSE3__
#
include
<
tmmintrin
.
h
>
#
endif
#
ifdef
_MSC_VER
#
include
<
intrin
.
h
>
#
endif
#
ifdef
__ARM_NEON
#
include
<
arm_neon
.
h
>
#
endif
#
include
<
algorithm
>
#
include
<
cmath
>
#
include
<
cstdint
>
#
include
<
cstring
>
#
include
<
iterator
>
#
include
<
limits
>
#
include
<
memory
>
#
include
<
tuple
>
#
include
<
type_traits
>
#
include
<
utility
>
#
include
"
absl
/
base
/
config
.
h
"
#
include
"
absl
/
base
/
internal
/
endian
.
h
"
#
include
"
absl
/
base
/
internal
/
prefetch
.
h
"
#
include
"
absl
/
base
/
optimization
.
h
"
#
include
"
absl
/
base
/
port
.
h
"
#
include
"
absl
/
container
/
internal
/
common
.
h
"
#
include
"
absl
/
container
/
internal
/
compressed_tuple
.
h
"
#
include
"
absl
/
container
/
internal
/
container_memory
.
h
"
#
include
"
absl
/
container
/
internal
/
hash_policy_traits
.
h
"
#
include
"
absl
/
container
/
internal
/
hashtable_debug_hooks
.
h
"
#
include
"
absl
/
container
/
internal
/
hashtablez_sampler
.
h
"
#
include
"
absl
/
memory
/
memory
.
h
"
#
include
"
absl
/
meta
/
type_traits
.
h
"
#
include
"
absl
/
numeric
/
bits
.
h
"
#
include
"
absl
/
utility
/
utility
.
h
"
namespace
absl
{
ABSL_NAMESPACE_BEGIN
namespace
container_internal
{
template
<
typename
AllocType
>
void
SwapAlloc
(
AllocType
&
lhs
AllocType
&
rhs
std
:
:
true_type
)
{
using
std
:
:
swap
;
swap
(
lhs
rhs
)
;
}
template
<
typename
AllocType
>
void
SwapAlloc
(
AllocType
&
AllocType
&
std
:
:
false_type
)
{
}
template
<
size_t
Width
>
class
probe_seq
{
public
:
probe_seq
(
size_t
hash
size_t
mask
)
{
assert
(
(
(
mask
+
1
)
&
mask
)
=
=
0
&
&
"
not
a
mask
"
)
;
mask_
=
mask
;
offset_
=
hash
&
mask_
;
}
size_t
offset
(
)
const
{
return
offset_
;
}
size_t
offset
(
size_t
i
)
const
{
return
(
offset_
+
i
)
&
mask_
;
}
void
next
(
)
{
index_
+
=
Width
;
offset_
+
=
index_
;
offset_
&
=
mask_
;
}
size_t
index
(
)
const
{
return
index_
;
}
private
:
size_t
mask_
;
size_t
offset_
;
size_t
index_
=
0
;
}
;
template
<
class
ContainerKey
class
Hash
class
Eq
>
struct
RequireUsableKey
{
template
<
class
PassedKey
class
.
.
.
Args
>
std
:
:
pair
<
decltype
(
std
:
:
declval
<
const
Hash
&
>
(
)
(
std
:
:
declval
<
const
PassedKey
&
>
(
)
)
)
decltype
(
std
:
:
declval
<
const
Eq
&
>
(
)
(
std
:
:
declval
<
const
ContainerKey
&
>
(
)
std
:
:
declval
<
const
PassedKey
&
>
(
)
)
)
>
*
operator
(
)
(
const
PassedKey
&
const
Args
&
.
.
.
)
const
;
}
;
template
<
class
E
class
Policy
class
Hash
class
Eq
class
.
.
.
Ts
>
struct
IsDecomposable
:
std
:
:
false_type
{
}
;
template
<
class
Policy
class
Hash
class
Eq
class
.
.
.
Ts
>
struct
IsDecomposable
<
absl
:
:
void_t
<
decltype
(
Policy
:
:
apply
(
RequireUsableKey
<
typename
Policy
:
:
key_type
Hash
Eq
>
(
)
std
:
:
declval
<
Ts
>
(
)
.
.
.
)
)
>
Policy
Hash
Eq
Ts
.
.
.
>
:
std
:
:
true_type
{
}
;
template
<
class
T
>
constexpr
bool
IsNoThrowSwappable
(
std
:
:
true_type
=
{
}
)
{
using
std
:
:
swap
;
return
noexcept
(
swap
(
std
:
:
declval
<
T
&
>
(
)
std
:
:
declval
<
T
&
>
(
)
)
)
;
}
template
<
class
T
>
constexpr
bool
IsNoThrowSwappable
(
std
:
:
false_type
)
{
return
false
;
}
template
<
typename
T
>
uint32_t
TrailingZeros
(
T
x
)
{
ABSL_ASSUME
(
x
!
=
0
)
;
return
static_cast
<
uint32_t
>
(
countr_zero
(
x
)
)
;
}
template
<
class
T
int
SignificantBits
int
Shift
=
0
>
class
NonIterableBitMask
{
public
:
explicit
NonIterableBitMask
(
T
mask
)
:
mask_
(
mask
)
{
}
explicit
operator
bool
(
)
const
{
return
this
-
>
mask_
!
=
0
;
}
uint32_t
LowestBitSet
(
)
const
{
return
container_internal
:
:
TrailingZeros
(
mask_
)
>
>
Shift
;
}
uint32_t
HighestBitSet
(
)
const
{
return
static_cast
<
uint32_t
>
(
(
bit_width
(
mask_
)
-
1
)
>
>
Shift
)
;
}
uint32_t
TrailingZeros
(
)
const
{
return
container_internal
:
:
TrailingZeros
(
mask_
)
>
>
Shift
;
}
uint32_t
LeadingZeros
(
)
const
{
constexpr
int
total_significant_bits
=
SignificantBits
<
<
Shift
;
constexpr
int
extra_bits
=
sizeof
(
T
)
*
8
-
total_significant_bits
;
return
static_cast
<
uint32_t
>
(
countl_zero
(
mask_
<
<
extra_bits
)
)
>
>
Shift
;
}
T
mask_
;
}
;
template
<
class
T
int
SignificantBits
int
Shift
=
0
>
class
BitMask
:
public
NonIterableBitMask
<
T
SignificantBits
Shift
>
{
using
Base
=
NonIterableBitMask
<
T
SignificantBits
Shift
>
;
static_assert
(
std
:
:
is_unsigned
<
T
>
:
:
value
"
"
)
;
static_assert
(
Shift
=
=
0
|
|
Shift
=
=
3
"
"
)
;
public
:
explicit
BitMask
(
T
mask
)
:
Base
(
mask
)
{
}
using
value_type
=
int
;
using
iterator
=
BitMask
;
using
const_iterator
=
BitMask
;
BitMask
&
operator
+
+
(
)
{
this
-
>
mask_
&
=
(
this
-
>
mask_
-
1
)
;
return
*
this
;
}
uint32_t
operator
*
(
)
const
{
return
Base
:
:
LowestBitSet
(
)
;
}
BitMask
begin
(
)
const
{
return
*
this
;
}
BitMask
end
(
)
const
{
return
BitMask
(
0
)
;
}
private
:
friend
bool
operator
=
=
(
const
BitMask
&
a
const
BitMask
&
b
)
{
return
a
.
mask_
=
=
b
.
mask_
;
}
friend
bool
operator
!
=
(
const
BitMask
&
a
const
BitMask
&
b
)
{
return
a
.
mask_
!
=
b
.
mask_
;
}
}
;
using
h2_t
=
uint8_t
;
enum
class
ctrl_t
:
int8_t
{
kEmpty
=
-
128
kDeleted
=
-
2
kSentinel
=
-
1
}
;
static_assert
(
(
static_cast
<
int8_t
>
(
ctrl_t
:
:
kEmpty
)
&
static_cast
<
int8_t
>
(
ctrl_t
:
:
kDeleted
)
&
static_cast
<
int8_t
>
(
ctrl_t
:
:
kSentinel
)
&
0x80
)
!
=
0
"
Special
markers
need
to
have
the
MSB
to
make
checking
for
them
efficient
"
)
;
static_assert
(
ctrl_t
:
:
kEmpty
<
ctrl_t
:
:
kSentinel
&
&
ctrl_t
:
:
kDeleted
<
ctrl_t
:
:
kSentinel
"
ctrl_t
:
:
kEmpty
and
ctrl_t
:
:
kDeleted
must
be
smaller
than
"
"
ctrl_t
:
:
kSentinel
to
make
the
SIMD
test
of
IsEmptyOrDeleted
(
)
efficient
"
)
;
static_assert
(
ctrl_t
:
:
kSentinel
=
=
static_cast
<
ctrl_t
>
(
-
1
)
"
ctrl_t
:
:
kSentinel
must
be
-
1
to
elide
loading
it
from
memory
into
SIMD
"
"
registers
(
pcmpeqd
xmm
xmm
)
"
)
;
static_assert
(
ctrl_t
:
:
kEmpty
=
=
static_cast
<
ctrl_t
>
(
-
128
)
"
ctrl_t
:
:
kEmpty
must
be
-
128
to
make
the
SIMD
check
for
its
"
"
existence
efficient
(
psignb
xmm
xmm
)
"
)
;
static_assert
(
(
~
static_cast
<
int8_t
>
(
ctrl_t
:
:
kEmpty
)
&
~
static_cast
<
int8_t
>
(
ctrl_t
:
:
kDeleted
)
&
static_cast
<
int8_t
>
(
ctrl_t
:
:
kSentinel
)
&
0x7F
)
!
=
0
"
ctrl_t
:
:
kEmpty
and
ctrl_t
:
:
kDeleted
must
share
an
unset
bit
that
is
not
"
"
shared
by
ctrl_t
:
:
kSentinel
to
make
the
scalar
test
for
"
"
MaskEmptyOrDeleted
(
)
efficient
"
)
;
static_assert
(
ctrl_t
:
:
kDeleted
=
=
static_cast
<
ctrl_t
>
(
-
2
)
"
ctrl_t
:
:
kDeleted
must
be
-
2
to
make
the
implementation
of
"
"
ConvertSpecialToEmptyAndFullToDeleted
efficient
"
)
;
ABSL_DLL
extern
const
ctrl_t
kEmptyGroup
[
16
]
;
inline
ctrl_t
*
EmptyGroup
(
)
{
return
const_cast
<
ctrl_t
*
>
(
kEmptyGroup
)
;
}
bool
ShouldInsertBackwards
(
size_t
hash
const
ctrl_t
*
ctrl
)
;
inline
size_t
PerTableSalt
(
const
ctrl_t
*
ctrl
)
{
return
reinterpret_cast
<
uintptr_t
>
(
ctrl
)
>
>
12
;
}
inline
size_t
H1
(
size_t
hash
const
ctrl_t
*
ctrl
)
{
return
(
hash
>
>
7
)
^
PerTableSalt
(
ctrl
)
;
}
inline
h2_t
H2
(
size_t
hash
)
{
return
hash
&
0x7F
;
}
inline
bool
IsEmpty
(
ctrl_t
c
)
{
return
c
=
=
ctrl_t
:
:
kEmpty
;
}
inline
bool
IsFull
(
ctrl_t
c
)
{
return
c
>
=
static_cast
<
ctrl_t
>
(
0
)
;
}
inline
bool
IsDeleted
(
ctrl_t
c
)
{
return
c
=
=
ctrl_t
:
:
kDeleted
;
}
inline
bool
IsEmptyOrDeleted
(
ctrl_t
c
)
{
return
c
<
ctrl_t
:
:
kSentinel
;
}
#
ifdef
ABSL_INTERNAL_HAVE_SSE2
inline
__m128i
_mm_cmpgt_epi8_fixed
(
__m128i
a
__m128i
b
)
{
#
if
defined
(
__GNUC__
)
&
&
!
defined
(
__clang__
)
if
(
std
:
:
is_unsigned
<
char
>
:
:
value
)
{
const
__m128i
mask
=
_mm_set1_epi8
(
0x80
)
;
const
__m128i
diff
=
_mm_subs_epi8
(
b
a
)
;
return
_mm_cmpeq_epi8
(
_mm_and_si128
(
diff
mask
)
mask
)
;
}
#
endif
return
_mm_cmpgt_epi8
(
a
b
)
;
}
struct
GroupSse2Impl
{
static
constexpr
size_t
kWidth
=
16
;
explicit
GroupSse2Impl
(
const
ctrl_t
*
pos
)
{
ctrl
=
_mm_loadu_si128
(
reinterpret_cast
<
const
__m128i
*
>
(
pos
)
)
;
}
BitMask
<
uint32_t
kWidth
>
Match
(
h2_t
hash
)
const
{
auto
match
=
_mm_set1_epi8
(
hash
)
;
return
BitMask
<
uint32_t
kWidth
>
(
static_cast
<
uint32_t
>
(
_mm_movemask_epi8
(
_mm_cmpeq_epi8
(
match
ctrl
)
)
)
)
;
}
NonIterableBitMask
<
uint32_t
kWidth
>
MaskEmpty
(
)
const
{
#
ifdef
ABSL_INTERNAL_HAVE_SSSE3
return
NonIterableBitMask
<
uint32_t
kWidth
>
(
static_cast
<
uint32_t
>
(
_mm_movemask_epi8
(
_mm_sign_epi8
(
ctrl
ctrl
)
)
)
)
;
#
else
auto
match
=
_mm_set1_epi8
(
static_cast
<
h2_t
>
(
ctrl_t
:
:
kEmpty
)
)
;
return
NonIterableBitMask
<
uint32_t
kWidth
>
(
static_cast
<
uint32_t
>
(
_mm_movemask_epi8
(
_mm_cmpeq_epi8
(
match
ctrl
)
)
)
)
;
#
endif
}
NonIterableBitMask
<
uint32_t
kWidth
>
MaskEmptyOrDeleted
(
)
const
{
auto
special
=
_mm_set1_epi8
(
static_cast
<
uint8_t
>
(
ctrl_t
:
:
kSentinel
)
)
;
return
NonIterableBitMask
<
uint32_t
kWidth
>
(
static_cast
<
uint32_t
>
(
_mm_movemask_epi8
(
_mm_cmpgt_epi8_fixed
(
special
ctrl
)
)
)
)
;
}
uint32_t
CountLeadingEmptyOrDeleted
(
)
const
{
auto
special
=
_mm_set1_epi8
(
static_cast
<
uint8_t
>
(
ctrl_t
:
:
kSentinel
)
)
;
return
TrailingZeros
(
static_cast
<
uint32_t
>
(
_mm_movemask_epi8
(
_mm_cmpgt_epi8_fixed
(
special
ctrl
)
)
+
1
)
)
;
}
void
ConvertSpecialToEmptyAndFullToDeleted
(
ctrl_t
*
dst
)
const
{
auto
msbs
=
_mm_set1_epi8
(
static_cast
<
char
>
(
-
128
)
)
;
auto
x126
=
_mm_set1_epi8
(
126
)
;
#
ifdef
ABSL_INTERNAL_HAVE_SSSE3
auto
res
=
_mm_or_si128
(
_mm_shuffle_epi8
(
x126
ctrl
)
msbs
)
;
#
else
auto
zero
=
_mm_setzero_si128
(
)
;
auto
special_mask
=
_mm_cmpgt_epi8_fixed
(
zero
ctrl
)
;
auto
res
=
_mm_or_si128
(
msbs
_mm_andnot_si128
(
special_mask
x126
)
)
;
#
endif
_mm_storeu_si128
(
reinterpret_cast
<
__m128i
*
>
(
dst
)
res
)
;
}
__m128i
ctrl
;
}
;
#
endif
#
if
defined
(
ABSL_INTERNAL_HAVE_ARM_NEON
)
&
&
defined
(
ABSL_IS_LITTLE_ENDIAN
)
struct
GroupAArch64Impl
{
static
constexpr
size_t
kWidth
=
8
;
explicit
GroupAArch64Impl
(
const
ctrl_t
*
pos
)
{
ctrl
=
vld1_u8
(
reinterpret_cast
<
const
uint8_t
*
>
(
pos
)
)
;
}
BitMask
<
uint64_t
kWidth
3
>
Match
(
h2_t
hash
)
const
{
uint8x8_t
dup
=
vdup_n_u8
(
hash
)
;
auto
mask
=
vceq_u8
(
ctrl
dup
)
;
constexpr
uint64_t
msbs
=
0x8080808080808080ULL
;
return
BitMask
<
uint64_t
kWidth
3
>
(
vget_lane_u64
(
vreinterpret_u64_u8
(
mask
)
0
)
&
msbs
)
;
}
NonIterableBitMask
<
uint64_t
kWidth
3
>
MaskEmpty
(
)
const
{
uint64_t
mask
=
vget_lane_u64
(
vreinterpret_u64_u8
(
vceq_s8
(
vdup_n_s8
(
static_cast
<
h2_t
>
(
ctrl_t
:
:
kEmpty
)
)
vreinterpret_s8_u8
(
ctrl
)
)
)
0
)
;
return
NonIterableBitMask
<
uint64_t
kWidth
3
>
(
mask
)
;
}
NonIterableBitMask
<
uint64_t
kWidth
3
>
MaskEmptyOrDeleted
(
)
const
{
uint64_t
mask
=
vget_lane_u64
(
vreinterpret_u64_u8
(
vcgt_s8
(
vdup_n_s8
(
static_cast
<
int8_t
>
(
ctrl_t
:
:
kSentinel
)
)
vreinterpret_s8_u8
(
ctrl
)
)
)
0
)
;
return
NonIterableBitMask
<
uint64_t
kWidth
3
>
(
mask
)
;
}
uint32_t
CountLeadingEmptyOrDeleted
(
)
const
{
uint64_t
mask
=
vget_lane_u64
(
vreinterpret_u64_u8
(
ctrl
)
0
)
;
constexpr
uint64_t
bits
=
0x0101010101010101ULL
;
return
countr_zero
(
(
mask
|
~
(
mask
>
>
7
)
)
&
bits
)
>
>
3
;
}
void
ConvertSpecialToEmptyAndFullToDeleted
(
ctrl_t
*
dst
)
const
{
uint64_t
mask
=
vget_lane_u64
(
vreinterpret_u64_u8
(
ctrl
)
0
)
;
constexpr
uint64_t
msbs
=
0x8080808080808080ULL
;
constexpr
uint64_t
lsbs
=
0x0101010101010101ULL
;
auto
x
=
mask
&
msbs
;
auto
res
=
(
~
x
+
(
x
>
>
7
)
)
&
~
lsbs
;
little_endian
:
:
Store64
(
dst
res
)
;
}
uint8x8_t
ctrl
;
}
;
#
endif
struct
GroupPortableImpl
{
static
constexpr
size_t
kWidth
=
8
;
explicit
GroupPortableImpl
(
const
ctrl_t
*
pos
)
:
ctrl
(
little_endian
:
:
Load64
(
pos
)
)
{
}
BitMask
<
uint64_t
kWidth
3
>
Match
(
h2_t
hash
)
const
{
constexpr
uint64_t
msbs
=
0x8080808080808080ULL
;
constexpr
uint64_t
lsbs
=
0x0101010101010101ULL
;
auto
x
=
ctrl
^
(
lsbs
*
hash
)
;
return
BitMask
<
uint64_t
kWidth
3
>
(
(
x
-
lsbs
)
&
~
x
&
msbs
)
;
}
NonIterableBitMask
<
uint64_t
kWidth
3
>
MaskEmpty
(
)
const
{
constexpr
uint64_t
msbs
=
0x8080808080808080ULL
;
return
NonIterableBitMask
<
uint64_t
kWidth
3
>
(
(
ctrl
&
(
~
ctrl
<
<
6
)
)
&
msbs
)
;
}
NonIterableBitMask
<
uint64_t
kWidth
3
>
MaskEmptyOrDeleted
(
)
const
{
constexpr
uint64_t
msbs
=
0x8080808080808080ULL
;
return
NonIterableBitMask
<
uint64_t
kWidth
3
>
(
(
ctrl
&
(
~
ctrl
<
<
7
)
)
&
msbs
)
;
}
uint32_t
CountLeadingEmptyOrDeleted
(
)
const
{
constexpr
uint64_t
bits
=
0x0101010101010101ULL
;
return
countr_zero
(
(
ctrl
|
~
(
ctrl
>
>
7
)
)
&
bits
)
>
>
3
;
}
void
ConvertSpecialToEmptyAndFullToDeleted
(
ctrl_t
*
dst
)
const
{
constexpr
uint64_t
msbs
=
0x8080808080808080ULL
;
constexpr
uint64_t
lsbs
=
0x0101010101010101ULL
;
auto
x
=
ctrl
&
msbs
;
auto
res
=
(
~
x
+
(
x
>
>
7
)
)
&
~
lsbs
;
little_endian
:
:
Store64
(
dst
res
)
;
}
uint64_t
ctrl
;
}
;
#
ifdef
ABSL_INTERNAL_HAVE_SSE2
using
Group
=
GroupSse2Impl
;
#
elif
defined
(
ABSL_INTERNAL_HAVE_ARM_NEON
)
&
&
defined
(
ABSL_IS_LITTLE_ENDIAN
)
using
Group
=
GroupAArch64Impl
;
#
else
using
Group
=
GroupPortableImpl
;
#
endif
constexpr
size_t
NumClonedBytes
(
)
{
return
Group
:
:
kWidth
-
1
;
}
template
<
class
Policy
class
Hash
class
Eq
class
Alloc
>
class
raw_hash_set
;
inline
bool
IsValidCapacity
(
size_t
n
)
{
return
(
(
n
+
1
)
&
n
)
=
=
0
&
&
n
>
0
;
}
void
ConvertDeletedToEmptyAndFullToDeleted
(
ctrl_t
*
ctrl
size_t
capacity
)
;
inline
size_t
NormalizeCapacity
(
size_t
n
)
{
return
n
?
~
size_t
{
}
>
>
countl_zero
(
n
)
:
1
;
}
inline
size_t
CapacityToGrowth
(
size_t
capacity
)
{
assert
(
IsValidCapacity
(
capacity
)
)
;
if
(
Group
:
:
kWidth
=
=
8
&
&
capacity
=
=
7
)
{
return
6
;
}
return
capacity
-
capacity
/
8
;
}
inline
size_t
GrowthToLowerboundCapacity
(
size_t
growth
)
{
if
(
Group
:
:
kWidth
=
=
8
&
&
growth
=
=
7
)
{
return
8
;
}
return
growth
+
static_cast
<
size_t
>
(
(
static_cast
<
int64_t
>
(
growth
)
-
1
)
/
7
)
;
}
template
<
class
InputIter
>
size_t
SelectBucketCountForIterRange
(
InputIter
first
InputIter
last
size_t
bucket_count
)
{
if
(
bucket_count
!
=
0
)
{
return
bucket_count
;
}
using
InputIterCategory
=
typename
std
:
:
iterator_traits
<
InputIter
>
:
:
iterator_category
;
if
(
std
:
:
is_base_of
<
std
:
:
random_access_iterator_tag
InputIterCategory
>
:
:
value
)
{
return
GrowthToLowerboundCapacity
(
static_cast
<
size_t
>
(
std
:
:
distance
(
first
last
)
)
)
;
}
return
0
;
}
#
define
ABSL_INTERNAL_ASSERT_IS_FULL
(
ctrl
msg
)
\
ABSL_HARDENING_ASSERT
(
(
ctrl
!
=
nullptr
&
&
IsFull
(
*
ctrl
)
)
&
&
msg
)
inline
void
AssertIsValid
(
ctrl_t
*
ctrl
)
{
ABSL_HARDENING_ASSERT
(
(
ctrl
=
=
nullptr
|
|
IsFull
(
*
ctrl
)
)
&
&
"
Invalid
operation
on
iterator
.
The
element
might
have
"
"
been
erased
the
table
might
have
rehashed
or
this
may
"
"
be
an
end
(
)
iterator
.
"
)
;
}
struct
FindInfo
{
size_t
offset
;
size_t
probe_length
;
}
;
inline
bool
is_small
(
size_t
capacity
)
{
return
capacity
<
Group
:
:
kWidth
-
1
;
}
inline
probe_seq
<
Group
:
:
kWidth
>
probe
(
const
ctrl_t
*
ctrl
size_t
hash
size_t
capacity
)
{
return
probe_seq
<
Group
:
:
kWidth
>
(
H1
(
hash
ctrl
)
capacity
)
;
}
template
<
typename
=
void
>
inline
FindInfo
find_first_non_full
(
const
ctrl_t
*
ctrl
size_t
hash
size_t
capacity
)
{
auto
seq
=
probe
(
ctrl
hash
capacity
)
;
while
(
true
)
{
Group
g
{
ctrl
+
seq
.
offset
(
)
}
;
auto
mask
=
g
.
MaskEmptyOrDeleted
(
)
;
if
(
mask
)
{
#
if
!
defined
(
NDEBUG
)
if
(
!
is_small
(
capacity
)
&
&
ShouldInsertBackwards
(
hash
ctrl
)
)
{
return
{
seq
.
offset
(
mask
.
HighestBitSet
(
)
)
seq
.
index
(
)
}
;
}
#
endif
return
{
seq
.
offset
(
mask
.
LowestBitSet
(
)
)
seq
.
index
(
)
}
;
}
seq
.
next
(
)
;
assert
(
seq
.
index
(
)
<
=
capacity
&
&
"
full
table
!
"
)
;
}
}
extern
template
FindInfo
find_first_non_full
(
const
ctrl_t
*
size_t
size_t
)
;
inline
void
ResetCtrl
(
size_t
capacity
ctrl_t
*
ctrl
const
void
*
slot
size_t
slot_size
)
{
std
:
:
memset
(
ctrl
static_cast
<
int8_t
>
(
ctrl_t
:
:
kEmpty
)
capacity
+
1
+
NumClonedBytes
(
)
)
;
ctrl
[
capacity
]
=
ctrl_t
:
:
kSentinel
;
SanitizerPoisonMemoryRegion
(
slot
slot_size
*
capacity
)
;
}
inline
void
SetCtrl
(
size_t
i
ctrl_t
h
size_t
capacity
ctrl_t
*
ctrl
const
void
*
slot
size_t
slot_size
)
{
assert
(
i
<
capacity
)
;
auto
*
slot_i
=
static_cast
<
const
char
*
>
(
slot
)
+
i
*
slot_size
;
if
(
IsFull
(
h
)
)
{
SanitizerUnpoisonMemoryRegion
(
slot_i
slot_size
)
;
}
else
{
SanitizerPoisonMemoryRegion
(
slot_i
slot_size
)
;
}
ctrl
[
i
]
=
h
;
ctrl
[
(
(
i
-
NumClonedBytes
(
)
)
&
capacity
)
+
(
NumClonedBytes
(
)
&
capacity
)
]
=
h
;
}
inline
void
SetCtrl
(
size_t
i
h2_t
h
size_t
capacity
ctrl_t
*
ctrl
const
void
*
slot
size_t
slot_size
)
{
SetCtrl
(
i
static_cast
<
ctrl_t
>
(
h
)
capacity
ctrl
slot
slot_size
)
;
}
inline
size_t
SlotOffset
(
size_t
capacity
size_t
slot_align
)
{
assert
(
IsValidCapacity
(
capacity
)
)
;
const
size_t
num_control_bytes
=
capacity
+
1
+
NumClonedBytes
(
)
;
return
(
num_control_bytes
+
slot_align
-
1
)
&
(
~
slot_align
+
1
)
;
}
inline
size_t
AllocSize
(
size_t
capacity
size_t
slot_size
size_t
slot_align
)
{
return
SlotOffset
(
capacity
slot_align
)
+
capacity
*
slot_size
;
}
template
<
class
Policy
class
Hash
class
Eq
class
Alloc
>
class
raw_hash_set
{
using
PolicyTraits
=
hash_policy_traits
<
Policy
>
;
using
KeyArgImpl
=
KeyArg
<
IsTransparent
<
Eq
>
:
:
value
&
&
IsTransparent
<
Hash
>
:
:
value
>
;
public
:
using
init_type
=
typename
PolicyTraits
:
:
init_type
;
using
key_type
=
typename
PolicyTraits
:
:
key_type
;
using
slot_type
=
typename
PolicyTraits
:
:
slot_type
;
using
allocator_type
=
Alloc
;
using
size_type
=
size_t
;
using
difference_type
=
ptrdiff_t
;
using
hasher
=
Hash
;
using
key_equal
=
Eq
;
using
policy_type
=
Policy
;
using
value_type
=
typename
PolicyTraits
:
:
value_type
;
using
reference
=
value_type
&
;
using
const_reference
=
const
value_type
&
;
using
pointer
=
typename
absl
:
:
allocator_traits
<
allocator_type
>
:
:
template
rebind_traits
<
value_type
>
:
:
pointer
;
using
const_pointer
=
typename
absl
:
:
allocator_traits
<
allocator_type
>
:
:
template
rebind_traits
<
value_type
>
:
:
const_pointer
;
template
<
class
K
>
using
key_arg
=
typename
KeyArgImpl
:
:
template
type
<
K
key_type
>
;
private
:
auto
KeyTypeCanBeHashed
(
const
Hash
&
h
const
key_type
&
k
)
-
>
decltype
(
h
(
k
)
)
;
auto
KeyTypeCanBeEq
(
const
Eq
&
eq
const
key_type
&
k
)
-
>
decltype
(
eq
(
k
k
)
)
;
using
AllocTraits
=
absl
:
:
allocator_traits
<
allocator_type
>
;
using
SlotAlloc
=
typename
absl
:
:
allocator_traits
<
allocator_type
>
:
:
template
rebind_alloc
<
slot_type
>
;
using
SlotAllocTraits
=
typename
absl
:
:
allocator_traits
<
allocator_type
>
:
:
template
rebind_traits
<
slot_type
>
;
static_assert
(
std
:
:
is_lvalue_reference
<
reference
>
:
:
value
"
Policy
:
:
element
(
)
must
return
a
reference
"
)
;
template
<
typename
T
>
struct
SameAsElementReference
:
std
:
:
is_same
<
typename
std
:
:
remove_cv
<
typename
std
:
:
remove_reference
<
reference
>
:
:
type
>
:
:
type
typename
std
:
:
remove_cv
<
typename
std
:
:
remove_reference
<
T
>
:
:
type
>
:
:
type
>
{
}
;
template
<
class
T
>
using
RequiresInsertable
=
typename
std
:
:
enable_if
<
absl
:
:
disjunction
<
std
:
:
is_convertible
<
T
init_type
>
SameAsElementReference
<
T
>
>
:
:
value
int
>
:
:
type
;
template
<
class
T
>
using
RequiresNotInit
=
typename
std
:
:
enable_if
<
!
std
:
:
is_same
<
T
init_type
>
:
:
value
int
>
:
:
type
;
template
<
class
.
.
.
Ts
>
using
IsDecomposable
=
IsDecomposable
<
void
PolicyTraits
Hash
Eq
Ts
.
.
.
>
;
public
:
static_assert
(
std
:
:
is_same
<
pointer
value_type
*
>
:
:
value
"
Allocators
with
custom
pointer
types
are
not
supported
"
)
;
static_assert
(
std
:
:
is_same
<
const_pointer
const
value_type
*
>
:
:
value
"
Allocators
with
custom
pointer
types
are
not
supported
"
)
;
class
iterator
{
friend
class
raw_hash_set
;
public
:
using
iterator_category
=
std
:
:
forward_iterator_tag
;
using
value_type
=
typename
raw_hash_set
:
:
value_type
;
using
reference
=
absl
:
:
conditional_t
<
PolicyTraits
:
:
constant_iterators
:
:
value
const
value_type
&
value_type
&
>
;
using
pointer
=
absl
:
:
remove_reference_t
<
reference
>
*
;
using
difference_type
=
typename
raw_hash_set
:
:
difference_type
;
iterator
(
)
{
}
reference
operator
*
(
)
const
{
ABSL_INTERNAL_ASSERT_IS_FULL
(
ctrl_
"
operator
*
(
)
called
on
invalid
iterator
.
"
)
;
return
PolicyTraits
:
:
element
(
slot_
)
;
}
pointer
operator
-
>
(
)
const
{
ABSL_INTERNAL_ASSERT_IS_FULL
(
ctrl_
"
operator
-
>
called
on
invalid
iterator
.
"
)
;
return
&
operator
*
(
)
;
}
iterator
&
operator
+
+
(
)
{
ABSL_INTERNAL_ASSERT_IS_FULL
(
ctrl_
"
operator
+
+
called
on
invalid
iterator
.
"
)
;
+
+
ctrl_
;
+
+
slot_
;
skip_empty_or_deleted
(
)
;
return
*
this
;
}
iterator
operator
+
+
(
int
)
{
auto
tmp
=
*
this
;
+
+
*
this
;
return
tmp
;
}
friend
bool
operator
=
=
(
const
iterator
&
a
const
iterator
&
b
)
{
AssertIsValid
(
a
.
ctrl_
)
;
AssertIsValid
(
b
.
ctrl_
)
;
return
a
.
ctrl_
=
=
b
.
ctrl_
;
}
friend
bool
operator
!
=
(
const
iterator
&
a
const
iterator
&
b
)
{
return
!
(
a
=
=
b
)
;
}
private
:
iterator
(
ctrl_t
*
ctrl
slot_type
*
slot
)
:
ctrl_
(
ctrl
)
slot_
(
slot
)
{
ABSL_ASSUME
(
ctrl
!
=
nullptr
)
;
}
void
skip_empty_or_deleted
(
)
{
while
(
IsEmptyOrDeleted
(
*
ctrl_
)
)
{
uint32_t
shift
=
Group
{
ctrl_
}
.
CountLeadingEmptyOrDeleted
(
)
;
ctrl_
+
=
shift
;
slot_
+
=
shift
;
}
if
(
ABSL_PREDICT_FALSE
(
*
ctrl_
=
=
ctrl_t
:
:
kSentinel
)
)
ctrl_
=
nullptr
;
}
ctrl_t
*
ctrl_
=
nullptr
;
union
{
slot_type
*
slot_
;
}
;
}
;
class
const_iterator
{
friend
class
raw_hash_set
;
public
:
using
iterator_category
=
typename
iterator
:
:
iterator_category
;
using
value_type
=
typename
raw_hash_set
:
:
value_type
;
using
reference
=
typename
raw_hash_set
:
:
const_reference
;
using
pointer
=
typename
raw_hash_set
:
:
const_pointer
;
using
difference_type
=
typename
raw_hash_set
:
:
difference_type
;
const_iterator
(
)
{
}
const_iterator
(
iterator
i
)
:
inner_
(
std
:
:
move
(
i
)
)
{
}
reference
operator
*
(
)
const
{
return
*
inner_
;
}
pointer
operator
-
>
(
)
const
{
return
inner_
.
operator
-
>
(
)
;
}
const_iterator
&
operator
+
+
(
)
{
+
+
inner_
;
return
*
this
;
}
const_iterator
operator
+
+
(
int
)
{
return
inner_
+
+
;
}
friend
bool
operator
=
=
(
const
const_iterator
&
a
const
const_iterator
&
b
)
{
return
a
.
inner_
=
=
b
.
inner_
;
}
friend
bool
operator
!
=
(
const
const_iterator
&
a
const
const_iterator
&
b
)
{
return
!
(
a
=
=
b
)
;
}
private
:
const_iterator
(
const
ctrl_t
*
ctrl
const
slot_type
*
slot
)
:
inner_
(
const_cast
<
ctrl_t
*
>
(
ctrl
)
const_cast
<
slot_type
*
>
(
slot
)
)
{
}
iterator
inner_
;
}
;
using
node_type
=
node_handle
<
Policy
hash_policy_traits
<
Policy
>
Alloc
>
;
using
insert_return_type
=
InsertReturnType
<
iterator
node_type
>
;
raw_hash_set
(
)
noexcept
(
std
:
:
is_nothrow_default_constructible
<
hasher
>
:
:
value
&
&
std
:
:
is_nothrow_default_constructible
<
key_equal
>
:
:
value
&
&
std
:
:
is_nothrow_default_constructible
<
allocator_type
>
:
:
value
)
{
}
explicit
raw_hash_set
(
size_t
bucket_count
const
hasher
&
hash
=
hasher
(
)
const
key_equal
&
eq
=
key_equal
(
)
const
allocator_type
&
alloc
=
allocator_type
(
)
)
:
ctrl_
(
EmptyGroup
(
)
)
settings_
(
0
HashtablezInfoHandle
(
)
hash
eq
alloc
)
{
if
(
bucket_count
)
{
capacity_
=
NormalizeCapacity
(
bucket_count
)
;
initialize_slots
(
)
;
}
}
raw_hash_set
(
size_t
bucket_count
const
hasher
&
hash
const
allocator_type
&
alloc
)
:
raw_hash_set
(
bucket_count
hash
key_equal
(
)
alloc
)
{
}
raw_hash_set
(
size_t
bucket_count
const
allocator_type
&
alloc
)
:
raw_hash_set
(
bucket_count
hasher
(
)
key_equal
(
)
alloc
)
{
}
explicit
raw_hash_set
(
const
allocator_type
&
alloc
)
:
raw_hash_set
(
0
hasher
(
)
key_equal
(
)
alloc
)
{
}
template
<
class
InputIter
>
raw_hash_set
(
InputIter
first
InputIter
last
size_t
bucket_count
=
0
const
hasher
&
hash
=
hasher
(
)
const
key_equal
&
eq
=
key_equal
(
)
const
allocator_type
&
alloc
=
allocator_type
(
)
)
:
raw_hash_set
(
SelectBucketCountForIterRange
(
first
last
bucket_count
)
hash
eq
alloc
)
{
insert
(
first
last
)
;
}
template
<
class
InputIter
>
raw_hash_set
(
InputIter
first
InputIter
last
size_t
bucket_count
const
hasher
&
hash
const
allocator_type
&
alloc
)
:
raw_hash_set
(
first
last
bucket_count
hash
key_equal
(
)
alloc
)
{
}
template
<
class
InputIter
>
raw_hash_set
(
InputIter
first
InputIter
last
size_t
bucket_count
const
allocator_type
&
alloc
)
:
raw_hash_set
(
first
last
bucket_count
hasher
(
)
key_equal
(
)
alloc
)
{
}
template
<
class
InputIter
>
raw_hash_set
(
InputIter
first
InputIter
last
const
allocator_type
&
alloc
)
:
raw_hash_set
(
first
last
0
hasher
(
)
key_equal
(
)
alloc
)
{
}
template
<
class
T
RequiresNotInit
<
T
>
=
0
RequiresInsertable
<
T
>
=
0
>
raw_hash_set
(
std
:
:
initializer_list
<
T
>
init
size_t
bucket_count
=
0
const
hasher
&
hash
=
hasher
(
)
const
key_equal
&
eq
=
key_equal
(
)
const
allocator_type
&
alloc
=
allocator_type
(
)
)
:
raw_hash_set
(
init
.
begin
(
)
init
.
end
(
)
bucket_count
hash
eq
alloc
)
{
}
raw_hash_set
(
std
:
:
initializer_list
<
init_type
>
init
size_t
bucket_count
=
0
const
hasher
&
hash
=
hasher
(
)
const
key_equal
&
eq
=
key_equal
(
)
const
allocator_type
&
alloc
=
allocator_type
(
)
)
:
raw_hash_set
(
init
.
begin
(
)
init
.
end
(
)
bucket_count
hash
eq
alloc
)
{
}
template
<
class
T
RequiresNotInit
<
T
>
=
0
RequiresInsertable
<
T
>
=
0
>
raw_hash_set
(
std
:
:
initializer_list
<
T
>
init
size_t
bucket_count
const
hasher
&
hash
const
allocator_type
&
alloc
)
:
raw_hash_set
(
init
bucket_count
hash
key_equal
(
)
alloc
)
{
}
raw_hash_set
(
std
:
:
initializer_list
<
init_type
>
init
size_t
bucket_count
const
hasher
&
hash
const
allocator_type
&
alloc
)
:
raw_hash_set
(
init
bucket_count
hash
key_equal
(
)
alloc
)
{
}
template
<
class
T
RequiresNotInit
<
T
>
=
0
RequiresInsertable
<
T
>
=
0
>
raw_hash_set
(
std
:
:
initializer_list
<
T
>
init
size_t
bucket_count
const
allocator_type
&
alloc
)
:
raw_hash_set
(
init
bucket_count
hasher
(
)
key_equal
(
)
alloc
)
{
}
raw_hash_set
(
std
:
:
initializer_list
<
init_type
>
init
size_t
bucket_count
const
allocator_type
&
alloc
)
:
raw_hash_set
(
init
bucket_count
hasher
(
)
key_equal
(
)
alloc
)
{
}
template
<
class
T
RequiresNotInit
<
T
>
=
0
RequiresInsertable
<
T
>
=
0
>
raw_hash_set
(
std
:
:
initializer_list
<
T
>
init
const
allocator_type
&
alloc
)
:
raw_hash_set
(
init
0
hasher
(
)
key_equal
(
)
alloc
)
{
}
raw_hash_set
(
std
:
:
initializer_list
<
init_type
>
init
const
allocator_type
&
alloc
)
:
raw_hash_set
(
init
0
hasher
(
)
key_equal
(
)
alloc
)
{
}
raw_hash_set
(
const
raw_hash_set
&
that
)
:
raw_hash_set
(
that
AllocTraits
:
:
select_on_container_copy_construction
(
that
.
alloc_ref
(
)
)
)
{
}
raw_hash_set
(
const
raw_hash_set
&
that
const
allocator_type
&
a
)
:
raw_hash_set
(
0
that
.
hash_ref
(
)
that
.
eq_ref
(
)
a
)
{
reserve
(
that
.
size
(
)
)
;
for
(
const
auto
&
v
:
that
)
{
const
size_t
hash
=
PolicyTraits
:
:
apply
(
HashElement
{
hash_ref
(
)
}
v
)
;
auto
target
=
find_first_non_full
(
ctrl_
hash
capacity_
)
;
SetCtrl
(
target
.
offset
H2
(
hash
)
capacity_
ctrl_
slots_
sizeof
(
slot_type
)
)
;
emplace_at
(
target
.
offset
v
)
;
infoz
(
)
.
RecordInsert
(
hash
target
.
probe_length
)
;
}
size_
=
that
.
size
(
)
;
growth_left
(
)
-
=
that
.
size
(
)
;
}
raw_hash_set
(
raw_hash_set
&
&
that
)
noexcept
(
std
:
:
is_nothrow_copy_constructible
<
hasher
>
:
:
value
&
&
std
:
:
is_nothrow_copy_constructible
<
key_equal
>
:
:
value
&
&
std
:
:
is_nothrow_copy_constructible
<
allocator_type
>
:
:
value
)
:
ctrl_
(
absl
:
:
exchange
(
that
.
ctrl_
EmptyGroup
(
)
)
)
slots_
(
absl
:
:
exchange
(
that
.
slots_
nullptr
)
)
size_
(
absl
:
:
exchange
(
that
.
size_
0
)
)
capacity_
(
absl
:
:
exchange
(
that
.
capacity_
0
)
)
settings_
(
absl
:
:
exchange
(
that
.
growth_left
(
)
0
)
absl
:
:
exchange
(
that
.
infoz
(
)
HashtablezInfoHandle
(
)
)
that
.
hash_ref
(
)
that
.
eq_ref
(
)
that
.
alloc_ref
(
)
)
{
}
raw_hash_set
(
raw_hash_set
&
&
that
const
allocator_type
&
a
)
:
ctrl_
(
EmptyGroup
(
)
)
slots_
(
nullptr
)
size_
(
0
)
capacity_
(
0
)
settings_
(
0
HashtablezInfoHandle
(
)
that
.
hash_ref
(
)
that
.
eq_ref
(
)
a
)
{
if
(
a
=
=
that
.
alloc_ref
(
)
)
{
std
:
:
swap
(
ctrl_
that
.
ctrl_
)
;
std
:
:
swap
(
slots_
that
.
slots_
)
;
std
:
:
swap
(
size_
that
.
size_
)
;
std
:
:
swap
(
capacity_
that
.
capacity_
)
;
std
:
:
swap
(
growth_left
(
)
that
.
growth_left
(
)
)
;
std
:
:
swap
(
infoz
(
)
that
.
infoz
(
)
)
;
}
else
{
reserve
(
that
.
size
(
)
)
;
for
(
auto
&
elem
:
that
)
insert
(
std
:
:
move
(
elem
)
)
;
}
}
raw_hash_set
&
operator
=
(
const
raw_hash_set
&
that
)
{
raw_hash_set
tmp
(
that
AllocTraits
:
:
propagate_on_container_copy_assignment
:
:
value
?
that
.
alloc_ref
(
)
:
alloc_ref
(
)
)
;
swap
(
tmp
)
;
return
*
this
;
}
raw_hash_set
&
operator
=
(
raw_hash_set
&
&
that
)
noexcept
(
absl
:
:
allocator_traits
<
allocator_type
>
:
:
is_always_equal
:
:
value
&
&
std
:
:
is_nothrow_move_assignable
<
hasher
>
:
:
value
&
&
std
:
:
is_nothrow_move_assignable
<
key_equal
>
:
:
value
)
{
return
move_assign
(
std
:
:
move
(
that
)
typename
AllocTraits
:
:
propagate_on_container_move_assignment
(
)
)
;
}
~
raw_hash_set
(
)
{
destroy_slots
(
)
;
}
iterator
begin
(
)
{
auto
it
=
iterator_at
(
0
)
;
it
.
skip_empty_or_deleted
(
)
;
return
it
;
}
iterator
end
(
)
{
return
{
}
;
}
const_iterator
begin
(
)
const
{
return
const_cast
<
raw_hash_set
*
>
(
this
)
-
>
begin
(
)
;
}
const_iterator
end
(
)
const
{
return
{
}
;
}
const_iterator
cbegin
(
)
const
{
return
begin
(
)
;
}
const_iterator
cend
(
)
const
{
return
end
(
)
;
}
bool
empty
(
)
const
{
return
!
size
(
)
;
}
size_t
size
(
)
const
{
return
size_
;
}
size_t
capacity
(
)
const
{
return
capacity_
;
}
size_t
max_size
(
)
const
{
return
(
std
:
:
numeric_limits
<
size_t
>
:
:
max
)
(
)
;
}
ABSL_ATTRIBUTE_REINITIALIZES
void
clear
(
)
{
if
(
capacity_
>
127
)
{
destroy_slots
(
)
;
infoz
(
)
.
RecordClearedReservation
(
)
;
}
else
if
(
capacity_
)
{
for
(
size_t
i
=
0
;
i
!
=
capacity_
;
+
+
i
)
{
if
(
IsFull
(
ctrl_
[
i
]
)
)
{
PolicyTraits
:
:
destroy
(
&
alloc_ref
(
)
slots_
+
i
)
;
}
}
size_
=
0
;
ResetCtrl
(
capacity_
ctrl_
slots_
sizeof
(
slot_type
)
)
;
reset_growth_left
(
)
;
}
assert
(
empty
(
)
)
;
infoz
(
)
.
RecordStorageChanged
(
0
capacity_
)
;
}
template
<
class
T
RequiresInsertable
<
T
>
=
0
class
T2
=
T
typename
std
:
:
enable_if
<
IsDecomposable
<
T2
>
:
:
value
int
>
:
:
type
=
0
T
*
=
nullptr
>
std
:
:
pair
<
iterator
bool
>
insert
(
T
&
&
value
)
{
return
emplace
(
std
:
:
forward
<
T
>
(
value
)
)
;
}
template
<
class
T
RequiresInsertable
<
T
>
=
0
typename
std
:
:
enable_if
<
IsDecomposable
<
const
T
&
>
:
:
value
int
>
:
:
type
=
0
>
std
:
:
pair
<
iterator
bool
>
insert
(
const
T
&
value
)
{
return
emplace
(
value
)
;
}
std
:
:
pair
<
iterator
bool
>
insert
(
init_type
&
&
value
)
{
return
emplace
(
std
:
:
move
(
value
)
)
;
}
template
<
class
T
RequiresInsertable
<
T
>
=
0
class
T2
=
T
typename
std
:
:
enable_if
<
IsDecomposable
<
T2
>
:
:
value
int
>
:
:
type
=
0
T
*
=
nullptr
>
iterator
insert
(
const_iterator
T
&
&
value
)
{
return
insert
(
std
:
:
forward
<
T
>
(
value
)
)
.
first
;
}
template
<
class
T
RequiresInsertable
<
T
>
=
0
typename
std
:
:
enable_if
<
IsDecomposable
<
const
T
&
>
:
:
value
int
>
:
:
type
=
0
>
iterator
insert
(
const_iterator
const
T
&
value
)
{
return
insert
(
value
)
.
first
;
}
iterator
insert
(
const_iterator
init_type
&
&
value
)
{
return
insert
(
std
:
:
move
(
value
)
)
.
first
;
}
template
<
class
InputIt
>
void
insert
(
InputIt
first
InputIt
last
)
{
for
(
;
first
!
=
last
;
+
+
first
)
emplace
(
*
first
)
;
}
template
<
class
T
RequiresNotInit
<
T
>
=
0
RequiresInsertable
<
const
T
&
>
=
0
>
void
insert
(
std
:
:
initializer_list
<
T
>
ilist
)
{
insert
(
ilist
.
begin
(
)
ilist
.
end
(
)
)
;
}
void
insert
(
std
:
:
initializer_list
<
init_type
>
ilist
)
{
insert
(
ilist
.
begin
(
)
ilist
.
end
(
)
)
;
}
insert_return_type
insert
(
node_type
&
&
node
)
{
if
(
!
node
)
return
{
end
(
)
false
node_type
(
)
}
;
const
auto
&
elem
=
PolicyTraits
:
:
element
(
CommonAccess
:
:
GetSlot
(
node
)
)
;
auto
res
=
PolicyTraits
:
:
apply
(
InsertSlot
<
false
>
{
*
this
std
:
:
move
(
*
CommonAccess
:
:
GetSlot
(
node
)
)
}
elem
)
;
if
(
res
.
second
)
{
CommonAccess
:
:
Reset
(
&
node
)
;
return
{
res
.
first
true
node_type
(
)
}
;
}
else
{
return
{
res
.
first
false
std
:
:
move
(
node
)
}
;
}
}
iterator
insert
(
const_iterator
node_type
&
&
node
)
{
auto
res
=
insert
(
std
:
:
move
(
node
)
)
;
node
=
std
:
:
move
(
res
.
node
)
;
return
res
.
position
;
}
template
<
class
.
.
.
Args
typename
std
:
:
enable_if
<
IsDecomposable
<
Args
.
.
.
>
:
:
value
int
>
:
:
type
=
0
>
std
:
:
pair
<
iterator
bool
>
emplace
(
Args
&
&
.
.
.
args
)
{
return
PolicyTraits
:
:
apply
(
EmplaceDecomposable
{
*
this
}
std
:
:
forward
<
Args
>
(
args
)
.
.
.
)
;
}
template
<
class
.
.
.
Args
typename
std
:
:
enable_if
<
!
IsDecomposable
<
Args
.
.
.
>
:
:
value
int
>
:
:
type
=
0
>
std
:
:
pair
<
iterator
bool
>
emplace
(
Args
&
&
.
.
.
args
)
{
alignas
(
slot_type
)
unsigned
char
raw
[
sizeof
(
slot_type
)
]
;
slot_type
*
slot
=
reinterpret_cast
<
slot_type
*
>
(
&
raw
)
;
PolicyTraits
:
:
construct
(
&
alloc_ref
(
)
slot
std
:
:
forward
<
Args
>
(
args
)
.
.
.
)
;
const
auto
&
elem
=
PolicyTraits
:
:
element
(
slot
)
;
return
PolicyTraits
:
:
apply
(
InsertSlot
<
true
>
{
*
this
std
:
:
move
(
*
slot
)
}
elem
)
;
}
template
<
class
.
.
.
Args
>
iterator
emplace_hint
(
const_iterator
Args
&
&
.
.
.
args
)
{
return
emplace
(
std
:
:
forward
<
Args
>
(
args
)
.
.
.
)
.
first
;
}
class
constructor
{
friend
class
raw_hash_set
;
public
:
template
<
class
.
.
.
Args
>
void
operator
(
)
(
Args
&
&
.
.
.
args
)
const
{
assert
(
*
slot_
)
;
PolicyTraits
:
:
construct
(
alloc_
*
slot_
std
:
:
forward
<
Args
>
(
args
)
.
.
.
)
;
*
slot_
=
nullptr
;
}
private
:
constructor
(
allocator_type
*
a
slot_type
*
*
slot
)
:
alloc_
(
a
)
slot_
(
slot
)
{
}
allocator_type
*
alloc_
;
slot_type
*
*
slot_
;
}
;
template
<
class
K
=
key_type
class
F
>
iterator
lazy_emplace
(
const
key_arg
<
K
>
&
key
F
&
&
f
)
{
auto
res
=
find_or_prepare_insert
(
key
)
;
if
(
res
.
second
)
{
slot_type
*
slot
=
slots_
+
res
.
first
;
std
:
:
forward
<
F
>
(
f
)
(
constructor
(
&
alloc_ref
(
)
&
slot
)
)
;
assert
(
!
slot
)
;
}
return
iterator_at
(
res
.
first
)
;
}
template
<
class
K
=
key_type
>
size_type
erase
(
const
key_arg
<
K
>
&
key
)
{
auto
it
=
find
(
key
)
;
if
(
it
=
=
end
(
)
)
return
0
;
erase
(
it
)
;
return
1
;
}
void
erase
(
const_iterator
cit
)
{
erase
(
cit
.
inner_
)
;
}
void
erase
(
iterator
it
)
{
ABSL_INTERNAL_ASSERT_IS_FULL
(
it
.
ctrl_
"
erase
(
)
called
on
invalid
iterator
.
"
)
;
PolicyTraits
:
:
destroy
(
&
alloc_ref
(
)
it
.
slot_
)
;
erase_meta_only
(
it
)
;
}
iterator
erase
(
const_iterator
first
const_iterator
last
)
{
while
(
first
!
=
last
)
{
erase
(
first
+
+
)
;
}
return
last
.
inner_
;
}
template
<
typename
H
typename
E
>
void
merge
(
raw_hash_set
<
Policy
H
E
Alloc
>
&
src
)
{
assert
(
this
!
=
&
src
)
;
for
(
auto
it
=
src
.
begin
(
)
e
=
src
.
end
(
)
;
it
!
=
e
;
)
{
auto
next
=
std
:
:
next
(
it
)
;
if
(
PolicyTraits
:
:
apply
(
InsertSlot
<
false
>
{
*
this
std
:
:
move
(
*
it
.
slot_
)
}
PolicyTraits
:
:
element
(
it
.
slot_
)
)
.
second
)
{
src
.
erase_meta_only
(
it
)
;
}
it
=
next
;
}
}
template
<
typename
H
typename
E
>
void
merge
(
raw_hash_set
<
Policy
H
E
Alloc
>
&
&
src
)
{
merge
(
src
)
;
}
node_type
extract
(
const_iterator
position
)
{
ABSL_INTERNAL_ASSERT_IS_FULL
(
position
.
inner_
.
ctrl_
"
extract
(
)
called
on
invalid
iterator
.
"
)
;
auto
node
=
CommonAccess
:
:
Transfer
<
node_type
>
(
alloc_ref
(
)
position
.
inner_
.
slot_
)
;
erase_meta_only
(
position
)
;
return
node
;
}
template
<
class
K
=
key_type
typename
std
:
:
enable_if
<
!
std
:
:
is_same
<
K
iterator
>
:
:
value
int
>
:
:
type
=
0
>
node_type
extract
(
const
key_arg
<
K
>
&
key
)
{
auto
it
=
find
(
key
)
;
return
it
=
=
end
(
)
?
node_type
(
)
:
extract
(
const_iterator
{
it
}
)
;
}
void
swap
(
raw_hash_set
&
that
)
noexcept
(
IsNoThrowSwappable
<
hasher
>
(
)
&
&
IsNoThrowSwappable
<
key_equal
>
(
)
&
&
IsNoThrowSwappable
<
allocator_type
>
(
typename
AllocTraits
:
:
propagate_on_container_swap
{
}
)
)
{
using
std
:
:
swap
;
swap
(
ctrl_
that
.
ctrl_
)
;
swap
(
slots_
that
.
slots_
)
;
swap
(
size_
that
.
size_
)
;
swap
(
capacity_
that
.
capacity_
)
;
swap
(
growth_left
(
)
that
.
growth_left
(
)
)
;
swap
(
hash_ref
(
)
that
.
hash_ref
(
)
)
;
swap
(
eq_ref
(
)
that
.
eq_ref
(
)
)
;
swap
(
infoz
(
)
that
.
infoz
(
)
)
;
SwapAlloc
(
alloc_ref
(
)
that
.
alloc_ref
(
)
typename
AllocTraits
:
:
propagate_on_container_swap
{
}
)
;
}
void
rehash
(
size_t
n
)
{
if
(
n
=
=
0
&
&
capacity_
=
=
0
)
return
;
if
(
n
=
=
0
&
&
size_
=
=
0
)
{
destroy_slots
(
)
;
infoz
(
)
.
RecordStorageChanged
(
0
0
)
;
infoz
(
)
.
RecordClearedReservation
(
)
;
return
;
}
auto
m
=
NormalizeCapacity
(
n
|
GrowthToLowerboundCapacity
(
size
(
)
)
)
;
if
(
n
=
=
0
|
|
m
>
capacity_
)
{
resize
(
m
)
;
infoz
(
)
.
RecordReservation
(
n
)
;
}
}
void
reserve
(
size_t
n
)
{
if
(
n
>
size
(
)
+
growth_left
(
)
)
{
size_t
m
=
GrowthToLowerboundCapacity
(
n
)
;
resize
(
NormalizeCapacity
(
m
)
)
;
infoz
(
)
.
RecordReservation
(
n
)
;
}
}
template
<
class
K
=
key_type
>
size_t
count
(
const
key_arg
<
K
>
&
key
)
const
{
return
find
(
key
)
=
=
end
(
)
?
0
:
1
;
}
template
<
class
K
=
key_type
>
void
prefetch
(
const
key_arg
<
K
>
&
key
)
const
{
(
void
)
key
;
#
ifdef
ABSL_INTERNAL_HAVE_PREFETCH
prefetch_heap_block
(
)
;
auto
seq
=
probe
(
ctrl_
hash_ref
(
)
(
key
)
capacity_
)
;
base_internal
:
:
PrefetchT0
(
ctrl_
+
seq
.
offset
(
)
)
;
base_internal
:
:
PrefetchT0
(
slots_
+
seq
.
offset
(
)
)
;
#
endif
}
template
<
class
K
=
key_type
>
iterator
find
(
const
key_arg
<
K
>
&
key
size_t
hash
)
{
auto
seq
=
probe
(
ctrl_
hash
capacity_
)
;
while
(
true
)
{
Group
g
{
ctrl_
+
seq
.
offset
(
)
}
;
for
(
uint32_t
i
:
g
.
Match
(
H2
(
hash
)
)
)
{
if
(
ABSL_PREDICT_TRUE
(
PolicyTraits
:
:
apply
(
EqualElement
<
K
>
{
key
eq_ref
(
)
}
PolicyTraits
:
:
element
(
slots_
+
seq
.
offset
(
i
)
)
)
)
)
return
iterator_at
(
seq
.
offset
(
i
)
)
;
}
if
(
ABSL_PREDICT_TRUE
(
g
.
MaskEmpty
(
)
)
)
return
end
(
)
;
seq
.
next
(
)
;
assert
(
seq
.
index
(
)
<
=
capacity_
&
&
"
full
table
!
"
)
;
}
}
template
<
class
K
=
key_type
>
iterator
find
(
const
key_arg
<
K
>
&
key
)
{
prefetch_heap_block
(
)
;
return
find
(
key
hash_ref
(
)
(
key
)
)
;
}
template
<
class
K
=
key_type
>
const_iterator
find
(
const
key_arg
<
K
>
&
key
size_t
hash
)
const
{
return
const_cast
<
raw_hash_set
*
>
(
this
)
-
>
find
(
key
hash
)
;
}
template
<
class
K
=
key_type
>
const_iterator
find
(
const
key_arg
<
K
>
&
key
)
const
{
prefetch_heap_block
(
)
;
return
find
(
key
hash_ref
(
)
(
key
)
)
;
}
template
<
class
K
=
key_type
>
bool
contains
(
const
key_arg
<
K
>
&
key
)
const
{
return
find
(
key
)
!
=
end
(
)
;
}
template
<
class
K
=
key_type
>
std
:
:
pair
<
iterator
iterator
>
equal_range
(
const
key_arg
<
K
>
&
key
)
{
auto
it
=
find
(
key
)
;
if
(
it
!
=
end
(
)
)
return
{
it
std
:
:
next
(
it
)
}
;
return
{
it
it
}
;
}
template
<
class
K
=
key_type
>
std
:
:
pair
<
const_iterator
const_iterator
>
equal_range
(
const
key_arg
<
K
>
&
key
)
const
{
auto
it
=
find
(
key
)
;
if
(
it
!
=
end
(
)
)
return
{
it
std
:
:
next
(
it
)
}
;
return
{
it
it
}
;
}
size_t
bucket_count
(
)
const
{
return
capacity_
;
}
float
load_factor
(
)
const
{
return
capacity_
?
static_cast
<
double
>
(
size
(
)
)
/
capacity_
:
0
.
0
;
}
float
max_load_factor
(
)
const
{
return
1
.
0f
;
}
void
max_load_factor
(
float
)
{
}
hasher
hash_function
(
)
const
{
return
hash_ref
(
)
;
}
key_equal
key_eq
(
)
const
{
return
eq_ref
(
)
;
}
allocator_type
get_allocator
(
)
const
{
return
alloc_ref
(
)
;
}
friend
bool
operator
=
=
(
const
raw_hash_set
&
a
const
raw_hash_set
&
b
)
{
if
(
a
.
size
(
)
!
=
b
.
size
(
)
)
return
false
;
const
raw_hash_set
*
outer
=
&
a
;
const
raw_hash_set
*
inner
=
&
b
;
if
(
outer
-
>
capacity
(
)
>
inner
-
>
capacity
(
)
)
std
:
:
swap
(
outer
inner
)
;
for
(
const
value_type
&
elem
:
*
outer
)
if
(
!
inner
-
>
has_element
(
elem
)
)
return
false
;
return
true
;
}
friend
bool
operator
!
=
(
const
raw_hash_set
&
a
const
raw_hash_set
&
b
)
{
return
!
(
a
=
=
b
)
;
}
template
<
typename
H
>
friend
typename
std
:
:
enable_if
<
H
:
:
template
is_hashable
<
value_type
>
:
:
value
H
>
:
:
type
AbslHashValue
(
H
h
const
raw_hash_set
&
s
)
{
return
H
:
:
combine
(
H
:
:
combine_unordered
(
std
:
:
move
(
h
)
s
.
begin
(
)
s
.
end
(
)
)
s
.
size
(
)
)
;
}
friend
void
swap
(
raw_hash_set
&
a
raw_hash_set
&
b
)
noexcept
(
noexcept
(
a
.
swap
(
b
)
)
)
{
a
.
swap
(
b
)
;
}
private
:
template
<
class
Container
typename
Enabler
>
friend
struct
absl
:
:
container_internal
:
:
hashtable_debug_internal
:
:
HashtableDebugAccess
;
struct
FindElement
{
template
<
class
K
class
.
.
.
Args
>
const_iterator
operator
(
)
(
const
K
&
key
Args
&
&
.
.
.
)
const
{
return
s
.
find
(
key
)
;
}
const
raw_hash_set
&
s
;
}
;
struct
HashElement
{
template
<
class
K
class
.
.
.
Args
>
size_t
operator
(
)
(
const
K
&
key
Args
&
&
.
.
.
)
const
{
return
h
(
key
)
;
}
const
hasher
&
h
;
}
;
template
<
class
K1
>
struct
EqualElement
{
template
<
class
K2
class
.
.
.
Args
>
bool
operator
(
)
(
const
K2
&
lhs
Args
&
&
.
.
.
)
const
{
return
eq
(
lhs
rhs
)
;
}
const
K1
&
rhs
;
const
key_equal
&
eq
;
}
;
struct
EmplaceDecomposable
{
template
<
class
K
class
.
.
.
Args
>
std
:
:
pair
<
iterator
bool
>
operator
(
)
(
const
K
&
key
Args
&
&
.
.
.
args
)
const
{
auto
res
=
s
.
find_or_prepare_insert
(
key
)
;
if
(
res
.
second
)
{
s
.
emplace_at
(
res
.
first
std
:
:
forward
<
Args
>
(
args
)
.
.
.
)
;
}
return
{
s
.
iterator_at
(
res
.
first
)
res
.
second
}
;
}
raw_hash_set
&
s
;
}
;
template
<
bool
do_destroy
>
struct
InsertSlot
{
template
<
class
K
class
.
.
.
Args
>
std
:
:
pair
<
iterator
bool
>
operator
(
)
(
const
K
&
key
Args
&
&
.
.
.
)
&
&
{
auto
res
=
s
.
find_or_prepare_insert
(
key
)
;
if
(
res
.
second
)
{
PolicyTraits
:
:
transfer
(
&
s
.
alloc_ref
(
)
s
.
slots_
+
res
.
first
&
slot
)
;
}
else
if
(
do_destroy
)
{
PolicyTraits
:
:
destroy
(
&
s
.
alloc_ref
(
)
&
slot
)
;
}
return
{
s
.
iterator_at
(
res
.
first
)
res
.
second
}
;
}
raw_hash_set
&
s
;
slot_type
&
&
slot
;
}
;
void
erase_meta_only
(
const_iterator
it
)
{
assert
(
IsFull
(
*
it
.
inner_
.
ctrl_
)
&
&
"
erasing
a
dangling
iterator
"
)
;
-
-
size_
;
const
size_t
index
=
static_cast
<
size_t
>
(
it
.
inner_
.
ctrl_
-
ctrl_
)
;
const
size_t
index_before
=
(
index
-
Group
:
:
kWidth
)
&
capacity_
;
const
auto
empty_after
=
Group
(
it
.
inner_
.
ctrl_
)
.
MaskEmpty
(
)
;
const
auto
empty_before
=
Group
(
ctrl_
+
index_before
)
.
MaskEmpty
(
)
;
bool
was_never_full
=
empty_before
&
&
empty_after
&
&
static_cast
<
size_t
>
(
empty_after
.
TrailingZeros
(
)
+
empty_before
.
LeadingZeros
(
)
)
<
Group
:
:
kWidth
;
SetCtrl
(
index
was_never_full
?
ctrl_t
:
:
kEmpty
:
ctrl_t
:
:
kDeleted
capacity_
ctrl_
slots_
sizeof
(
slot_type
)
)
;
growth_left
(
)
+
=
was_never_full
;
infoz
(
)
.
RecordErase
(
)
;
}
void
initialize_slots
(
)
{
assert
(
capacity_
)
;
if
(
std
:
:
is_same
<
SlotAlloc
std
:
:
allocator
<
slot_type
>
>
:
:
value
&
&
slots_
=
=
nullptr
)
{
infoz
(
)
=
Sample
(
sizeof
(
slot_type
)
)
;
}
char
*
mem
=
static_cast
<
char
*
>
(
Allocate
<
alignof
(
slot_type
)
>
(
&
alloc_ref
(
)
AllocSize
(
capacity_
sizeof
(
slot_type
)
alignof
(
slot_type
)
)
)
)
;
ctrl_
=
reinterpret_cast
<
ctrl_t
*
>
(
mem
)
;
slots_
=
reinterpret_cast
<
slot_type
*
>
(
mem
+
SlotOffset
(
capacity_
alignof
(
slot_type
)
)
)
;
ResetCtrl
(
capacity_
ctrl_
slots_
sizeof
(
slot_type
)
)
;
reset_growth_left
(
)
;
infoz
(
)
.
RecordStorageChanged
(
size_
capacity_
)
;
}
void
destroy_slots
(
)
{
if
(
!
capacity_
)
return
;
for
(
size_t
i
=
0
;
i
!
=
capacity_
;
+
+
i
)
{
if
(
IsFull
(
ctrl_
[
i
]
)
)
{
PolicyTraits
:
:
destroy
(
&
alloc_ref
(
)
slots_
+
i
)
;
}
}
SanitizerUnpoisonMemoryRegion
(
slots_
sizeof
(
slot_type
)
*
capacity_
)
;
Deallocate
<
alignof
(
slot_type
)
>
(
&
alloc_ref
(
)
ctrl_
AllocSize
(
capacity_
sizeof
(
slot_type
)
alignof
(
slot_type
)
)
)
;
ctrl_
=
EmptyGroup
(
)
;
slots_
=
nullptr
;
size_
=
0
;
capacity_
=
0
;
growth_left
(
)
=
0
;
}
void
resize
(
size_t
new_capacity
)
{
assert
(
IsValidCapacity
(
new_capacity
)
)
;
auto
*
old_ctrl
=
ctrl_
;
auto
*
old_slots
=
slots_
;
const
size_t
old_capacity
=
capacity_
;
capacity_
=
new_capacity
;
initialize_slots
(
)
;
size_t
total_probe_length
=
0
;
for
(
size_t
i
=
0
;
i
!
=
old_capacity
;
+
+
i
)
{
if
(
IsFull
(
old_ctrl
[
i
]
)
)
{
size_t
hash
=
PolicyTraits
:
:
apply
(
HashElement
{
hash_ref
(
)
}
PolicyTraits
:
:
element
(
old_slots
+
i
)
)
;
auto
target
=
find_first_non_full
(
ctrl_
hash
capacity_
)
;
size_t
new_i
=
target
.
offset
;
total_probe_length
+
=
target
.
probe_length
;
SetCtrl
(
new_i
H2
(
hash
)
capacity_
ctrl_
slots_
sizeof
(
slot_type
)
)
;
PolicyTraits
:
:
transfer
(
&
alloc_ref
(
)
slots_
+
new_i
old_slots
+
i
)
;
}
}
if
(
old_capacity
)
{
SanitizerUnpoisonMemoryRegion
(
old_slots
sizeof
(
slot_type
)
*
old_capacity
)
;
Deallocate
<
alignof
(
slot_type
)
>
(
&
alloc_ref
(
)
old_ctrl
AllocSize
(
old_capacity
sizeof
(
slot_type
)
alignof
(
slot_type
)
)
)
;
}
infoz
(
)
.
RecordRehash
(
total_probe_length
)
;
}
void
drop_deletes_without_resize
(
)
ABSL_ATTRIBUTE_NOINLINE
{
assert
(
IsValidCapacity
(
capacity_
)
)
;
assert
(
!
is_small
(
capacity_
)
)
;
ConvertDeletedToEmptyAndFullToDeleted
(
ctrl_
capacity_
)
;
alignas
(
slot_type
)
unsigned
char
raw
[
sizeof
(
slot_type
)
]
;
size_t
total_probe_length
=
0
;
slot_type
*
slot
=
reinterpret_cast
<
slot_type
*
>
(
&
raw
)
;
for
(
size_t
i
=
0
;
i
!
=
capacity_
;
+
+
i
)
{
if
(
!
IsDeleted
(
ctrl_
[
i
]
)
)
continue
;
const
size_t
hash
=
PolicyTraits
:
:
apply
(
HashElement
{
hash_ref
(
)
}
PolicyTraits
:
:
element
(
slots_
+
i
)
)
;
const
FindInfo
target
=
find_first_non_full
(
ctrl_
hash
capacity_
)
;
const
size_t
new_i
=
target
.
offset
;
total_probe_length
+
=
target
.
probe_length
;
const
size_t
probe_offset
=
probe
(
ctrl_
hash
capacity_
)
.
offset
(
)
;
const
auto
probe_index
=
[
probe_offset
this
]
(
size_t
pos
)
{
return
(
(
pos
-
probe_offset
)
&
capacity_
)
/
Group
:
:
kWidth
;
}
;
if
(
ABSL_PREDICT_TRUE
(
probe_index
(
new_i
)
=
=
probe_index
(
i
)
)
)
{
SetCtrl
(
i
H2
(
hash
)
capacity_
ctrl_
slots_
sizeof
(
slot_type
)
)
;
continue
;
}
if
(
IsEmpty
(
ctrl_
[
new_i
]
)
)
{
SetCtrl
(
new_i
H2
(
hash
)
capacity_
ctrl_
slots_
sizeof
(
slot_type
)
)
;
PolicyTraits
:
:
transfer
(
&
alloc_ref
(
)
slots_
+
new_i
slots_
+
i
)
;
SetCtrl
(
i
ctrl_t
:
:
kEmpty
capacity_
ctrl_
slots_
sizeof
(
slot_type
)
)
;
}
else
{
assert
(
IsDeleted
(
ctrl_
[
new_i
]
)
)
;
SetCtrl
(
new_i
H2
(
hash
)
capacity_
ctrl_
slots_
sizeof
(
slot_type
)
)
;
PolicyTraits
:
:
transfer
(
&
alloc_ref
(
)
slot
slots_
+
i
)
;
PolicyTraits
:
:
transfer
(
&
alloc_ref
(
)
slots_
+
i
slots_
+
new_i
)
;
PolicyTraits
:
:
transfer
(
&
alloc_ref
(
)
slots_
+
new_i
slot
)
;
-
-
i
;
}
}
reset_growth_left
(
)
;
infoz
(
)
.
RecordRehash
(
total_probe_length
)
;
}
void
rehash_and_grow_if_necessary
(
)
{
if
(
capacity_
=
=
0
)
{
resize
(
1
)
;
}
else
if
(
capacity_
>
Group
:
:
kWidth
&
&
size
(
)
*
uint64_t
{
32
}
<
=
capacity_
*
uint64_t
{
25
}
)
{
drop_deletes_without_resize
(
)
;
}
else
{
resize
(
capacity_
*
2
+
1
)
;
}
}
bool
has_element
(
const
value_type
&
elem
)
const
{
size_t
hash
=
PolicyTraits
:
:
apply
(
HashElement
{
hash_ref
(
)
}
elem
)
;
auto
seq
=
probe
(
ctrl_
hash
capacity_
)
;
while
(
true
)
{
Group
g
{
ctrl_
+
seq
.
offset
(
)
}
;
for
(
uint32_t
i
:
g
.
Match
(
H2
(
hash
)
)
)
{
if
(
ABSL_PREDICT_TRUE
(
PolicyTraits
:
:
element
(
slots_
+
seq
.
offset
(
i
)
)
=
=
elem
)
)
return
true
;
}
if
(
ABSL_PREDICT_TRUE
(
g
.
MaskEmpty
(
)
)
)
return
false
;
seq
.
next
(
)
;
assert
(
seq
.
index
(
)
<
=
capacity_
&
&
"
full
table
!
"
)
;
}
return
false
;
}
raw_hash_set
&
move_assign
(
raw_hash_set
&
&
that
std
:
:
true_type
)
{
raw_hash_set
tmp
(
std
:
:
move
(
that
)
)
;
swap
(
tmp
)
;
return
*
this
;
}
raw_hash_set
&
move_assign
(
raw_hash_set
&
&
that
std
:
:
false_type
)
{
raw_hash_set
tmp
(
std
:
:
move
(
that
)
alloc_ref
(
)
)
;
swap
(
tmp
)
;
return
*
this
;
}
protected
:
template
<
class
K
>
std
:
:
pair
<
size_t
bool
>
find_or_prepare_insert
(
const
K
&
key
)
{
prefetch_heap_block
(
)
;
auto
hash
=
hash_ref
(
)
(
key
)
;
auto
seq
=
probe
(
ctrl_
hash
capacity_
)
;
while
(
true
)
{
Group
g
{
ctrl_
+
seq
.
offset
(
)
}
;
for
(
uint32_t
i
:
g
.
Match
(
H2
(
hash
)
)
)
{
if
(
ABSL_PREDICT_TRUE
(
PolicyTraits
:
:
apply
(
EqualElement
<
K
>
{
key
eq_ref
(
)
}
PolicyTraits
:
:
element
(
slots_
+
seq
.
offset
(
i
)
)
)
)
)
return
{
seq
.
offset
(
i
)
false
}
;
}
if
(
ABSL_PREDICT_TRUE
(
g
.
MaskEmpty
(
)
)
)
break
;
seq
.
next
(
)
;
assert
(
seq
.
index
(
)
<
=
capacity_
&
&
"
full
table
!
"
)
;
}
return
{
prepare_insert
(
hash
)
true
}
;
}
size_t
prepare_insert
(
size_t
hash
)
ABSL_ATTRIBUTE_NOINLINE
{
auto
target
=
find_first_non_full
(
ctrl_
hash
capacity_
)
;
if
(
ABSL_PREDICT_FALSE
(
growth_left
(
)
=
=
0
&
&
!
IsDeleted
(
ctrl_
[
target
.
offset
]
)
)
)
{
rehash_and_grow_if_necessary
(
)
;
target
=
find_first_non_full
(
ctrl_
hash
capacity_
)
;
}
+
+
size_
;
growth_left
(
)
-
=
IsEmpty
(
ctrl_
[
target
.
offset
]
)
;
SetCtrl
(
target
.
offset
H2
(
hash
)
capacity_
ctrl_
slots_
sizeof
(
slot_type
)
)
;
infoz
(
)
.
RecordInsert
(
hash
target
.
probe_length
)
;
return
target
.
offset
;
}
template
<
class
.
.
.
Args
>
void
emplace_at
(
size_t
i
Args
&
&
.
.
.
args
)
{
PolicyTraits
:
:
construct
(
&
alloc_ref
(
)
slots_
+
i
std
:
:
forward
<
Args
>
(
args
)
.
.
.
)
;
assert
(
PolicyTraits
:
:
apply
(
FindElement
{
*
this
}
*
iterator_at
(
i
)
)
=
=
iterator_at
(
i
)
&
&
"
constructed
value
does
not
match
the
lookup
key
"
)
;
}
iterator
iterator_at
(
size_t
i
)
{
return
{
ctrl_
+
i
slots_
+
i
}
;
}
const_iterator
iterator_at
(
size_t
i
)
const
{
return
{
ctrl_
+
i
slots_
+
i
}
;
}
private
:
friend
struct
RawHashSetTestOnlyAccess
;
void
reset_growth_left
(
)
{
growth_left
(
)
=
CapacityToGrowth
(
capacity
(
)
)
-
size_
;
}
size_t
&
growth_left
(
)
{
return
settings_
.
template
get
<
0
>
(
)
;
}
void
prefetch_heap_block
(
)
const
{
base_internal
:
:
PrefetchT2
(
ctrl_
)
;
}
HashtablezInfoHandle
&
infoz
(
)
{
return
settings_
.
template
get
<
1
>
(
)
;
}
hasher
&
hash_ref
(
)
{
return
settings_
.
template
get
<
2
>
(
)
;
}
const
hasher
&
hash_ref
(
)
const
{
return
settings_
.
template
get
<
2
>
(
)
;
}
key_equal
&
eq_ref
(
)
{
return
settings_
.
template
get
<
3
>
(
)
;
}
const
key_equal
&
eq_ref
(
)
const
{
return
settings_
.
template
get
<
3
>
(
)
;
}
allocator_type
&
alloc_ref
(
)
{
return
settings_
.
template
get
<
4
>
(
)
;
}
const
allocator_type
&
alloc_ref
(
)
const
{
return
settings_
.
template
get
<
4
>
(
)
;
}
ctrl_t
*
ctrl_
=
EmptyGroup
(
)
;
slot_type
*
slots_
=
nullptr
;
size_t
size_
=
0
;
size_t
capacity_
=
0
;
absl
:
:
container_internal
:
:
CompressedTuple
<
size_t
HashtablezInfoHandle
hasher
key_equal
allocator_type
>
settings_
{
0u
HashtablezInfoHandle
{
}
hasher
{
}
key_equal
{
}
allocator_type
{
}
}
;
}
;
template
<
typename
P
typename
H
typename
E
typename
A
typename
Predicate
>
typename
raw_hash_set
<
P
H
E
A
>
:
:
size_type
EraseIf
(
Predicate
&
pred
raw_hash_set
<
P
H
E
A
>
*
c
)
{
const
auto
initial_size
=
c
-
>
size
(
)
;
for
(
auto
it
=
c
-
>
begin
(
)
last
=
c
-
>
end
(
)
;
it
!
=
last
;
)
{
if
(
pred
(
*
it
)
)
{
c
-
>
erase
(
it
+
+
)
;
}
else
{
+
+
it
;
}
}
return
initial_size
-
c
-
>
size
(
)
;
}
namespace
hashtable_debug_internal
{
template
<
typename
Set
>
struct
HashtableDebugAccess
<
Set
absl
:
:
void_t
<
typename
Set
:
:
raw_hash_set
>
>
{
using
Traits
=
typename
Set
:
:
PolicyTraits
;
using
Slot
=
typename
Traits
:
:
slot_type
;
static
size_t
GetNumProbes
(
const
Set
&
set
const
typename
Set
:
:
key_type
&
key
)
{
size_t
num_probes
=
0
;
size_t
hash
=
set
.
hash_ref
(
)
(
key
)
;
auto
seq
=
probe
(
set
.
ctrl_
hash
set
.
capacity_
)
;
while
(
true
)
{
container_internal
:
:
Group
g
{
set
.
ctrl_
+
seq
.
offset
(
)
}
;
for
(
uint32_t
i
:
g
.
Match
(
container_internal
:
:
H2
(
hash
)
)
)
{
if
(
Traits
:
:
apply
(
typename
Set
:
:
template
EqualElement
<
typename
Set
:
:
key_type
>
{
key
set
.
eq_ref
(
)
}
Traits
:
:
element
(
set
.
slots_
+
seq
.
offset
(
i
)
)
)
)
return
num_probes
;
+
+
num_probes
;
}
if
(
g
.
MaskEmpty
(
)
)
return
num_probes
;
seq
.
next
(
)
;
+
+
num_probes
;
}
}
static
size_t
AllocatedByteSize
(
const
Set
&
c
)
{
size_t
capacity
=
c
.
capacity_
;
if
(
capacity
=
=
0
)
return
0
;
size_t
m
=
AllocSize
(
capacity
sizeof
(
Slot
)
alignof
(
Slot
)
)
;
size_t
per_slot
=
Traits
:
:
space_used
(
static_cast
<
const
Slot
*
>
(
nullptr
)
)
;
if
(
per_slot
!
=
~
size_t
{
}
)
{
m
+
=
per_slot
*
c
.
size
(
)
;
}
else
{
for
(
size_t
i
=
0
;
i
!
=
capacity
;
+
+
i
)
{
if
(
container_internal
:
:
IsFull
(
c
.
ctrl_
[
i
]
)
)
{
m
+
=
Traits
:
:
space_used
(
c
.
slots_
+
i
)
;
}
}
}
return
m
;
}
static
size_t
LowerBoundAllocatedByteSize
(
size_t
size
)
{
size_t
capacity
=
GrowthToLowerboundCapacity
(
size
)
;
if
(
capacity
=
=
0
)
return
0
;
size_t
m
=
AllocSize
(
NormalizeCapacity
(
capacity
)
sizeof
(
Slot
)
alignof
(
Slot
)
)
;
size_t
per_slot
=
Traits
:
:
space_used
(
static_cast
<
const
Slot
*
>
(
nullptr
)
)
;
if
(
per_slot
!
=
~
size_t
{
}
)
{
m
+
=
per_slot
*
size
;
}
return
m
;
}
}
;
}
}
ABSL_NAMESPACE_END
}
#
undef
ABSL_INTERNAL_ASSERT_IS_FULL
#
endif
