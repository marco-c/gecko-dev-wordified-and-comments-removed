#
ifndef
AUDIO_UTILITY_AUDIO_FRAME_OPERATIONS_H_
#
define
AUDIO_UTILITY_AUDIO_FRAME_OPERATIONS_H_
#
include
<
stddef
.
h
>
#
include
"
typedefs
.
h
"
namespace
webrtc
{
class
AudioFrame
;
class
AudioFrameOperations
{
public
:
static
void
Add
(
const
AudioFrame
&
frame_to_add
AudioFrame
*
result_frame
)
;
static
void
MonoToStereo
(
const
int16_t
*
src_audio
size_t
samples_per_channel
int16_t
*
dst_audio
)
;
static
int
MonoToStereo
(
AudioFrame
*
frame
)
;
static
void
StereoToMono
(
const
int16_t
*
src_audio
size_t
samples_per_channel
int16_t
*
dst_audio
)
;
static
int
StereoToMono
(
AudioFrame
*
frame
)
;
static
void
QuadToStereo
(
const
int16_t
*
src_audio
size_t
samples_per_channel
int16_t
*
dst_audio
)
;
static
int
QuadToStereo
(
AudioFrame
*
frame
)
;
static
void
QuadToMono
(
const
int16_t
*
src_audio
size_t
samples_per_channel
int16_t
*
dst_audio
)
;
static
int
QuadToMono
(
AudioFrame
*
frame
)
;
static
void
DownmixChannels
(
const
int16_t
*
src_audio
size_t
src_channels
size_t
samples_per_channel
size_t
dst_channels
int16_t
*
dst_audio
)
;
static
int
DownmixChannels
(
size_t
dst_channels
AudioFrame
*
frame
)
;
static
void
SwapStereoChannels
(
AudioFrame
*
frame
)
;
static
void
Mute
(
AudioFrame
*
frame
bool
previous_frame_muted
bool
current_frame_muted
)
;
static
void
Mute
(
AudioFrame
*
frame
)
;
static
void
ApplyHalfGain
(
AudioFrame
*
frame
)
;
static
int
Scale
(
float
left
float
right
AudioFrame
*
frame
)
;
static
int
ScaleWithSat
(
float
scale
AudioFrame
*
frame
)
;
}
;
}
#
endif
