#
pragma
once
#
include
<
atomic
>
#
include
<
chrono
>
#
include
<
thread
>
#
include
"
opentelemetry
/
version
.
h
"
#
if
defined
(
_MSC_VER
)
#
define
_WINSOCKAPI_
#
include
<
windows
.
h
>
#
elif
defined
(
__i386__
)
|
|
defined
(
__x86_64__
)
#
if
defined
(
__clang__
)
#
include
<
emmintrin
.
h
>
#
elif
defined
(
__INTEL_COMPILER
)
#
include
<
immintrin
.
h
>
#
endif
#
endif
OPENTELEMETRY_BEGIN_NAMESPACE
namespace
common
{
constexpr
int
SPINLOCK_FAST_ITERATIONS
=
100
;
constexpr
int
SPINLOCK_SLEEP_MS
=
1
;
class
SpinLockMutex
{
public
:
SpinLockMutex
(
)
noexcept
{
}
~
SpinLockMutex
(
)
noexcept
=
default
;
SpinLockMutex
(
const
SpinLockMutex
&
)
=
delete
;
SpinLockMutex
&
operator
=
(
const
SpinLockMutex
&
)
=
delete
;
static
inline
void
fast_yield
(
)
noexcept
{
#
if
defined
(
_MSC_VER
)
YieldProcessor
(
)
;
#
elif
defined
(
__i386__
)
|
|
defined
(
__x86_64__
)
#
if
defined
(
__clang__
)
|
|
defined
(
__INTEL_COMPILER
)
_mm_pause
(
)
;
#
else
__builtin_ia32_pause
(
)
;
#
endif
#
elif
defined
(
__armel__
)
|
|
defined
(
__ARMEL__
)
asm
volatile
(
"
nop
"
:
:
:
"
memory
"
)
;
#
elif
defined
(
__arm__
)
|
|
defined
(
__aarch64__
)
__asm__
__volatile__
(
"
yield
"
:
:
:
"
memory
"
)
;
#
else
#
endif
}
bool
try_lock
(
)
noexcept
{
return
!
flag_
.
load
(
std
:
:
memory_order_relaxed
)
&
&
!
flag_
.
exchange
(
true
std
:
:
memory_order_acquire
)
;
}
void
lock
(
)
noexcept
{
for
(
;
;
)
{
if
(
!
flag_
.
exchange
(
true
std
:
:
memory_order_acquire
)
)
{
return
;
}
for
(
std
:
:
size_t
i
=
0
;
i
<
SPINLOCK_FAST_ITERATIONS
;
+
+
i
)
{
if
(
try_lock
(
)
)
{
return
;
}
fast_yield
(
)
;
}
std
:
:
this_thread
:
:
yield
(
)
;
if
(
try_lock
(
)
)
{
return
;
}
std
:
:
this_thread
:
:
sleep_for
(
std
:
:
chrono
:
:
milliseconds
(
SPINLOCK_SLEEP_MS
)
)
;
}
return
;
}
void
unlock
(
)
noexcept
{
flag_
.
store
(
false
std
:
:
memory_order_release
)
;
}
private
:
std
:
:
atomic
<
bool
>
flag_
{
false
}
;
}
;
}
OPENTELEMETRY_END_NAMESPACE
