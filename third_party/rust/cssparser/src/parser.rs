use
crate
:
:
cow_rc_str
:
:
CowRcStr
;
use
crate
:
:
tokenizer
:
:
{
SourceLocation
SourcePosition
Token
Tokenizer
}
;
use
smallvec
:
:
SmallVec
;
use
std
:
:
ops
:
:
BitOr
;
use
std
:
:
ops
:
:
Range
;
#
[
derive
(
Debug
Clone
)
]
pub
struct
ParserState
{
pub
(
crate
)
position
:
usize
pub
(
crate
)
current_line_start_position
:
usize
pub
(
crate
)
current_line_number
:
u32
pub
(
crate
)
at_start_of
:
Option
<
BlockType
>
}
impl
ParserState
{
#
[
inline
]
pub
fn
position
(
&
self
)
-
>
SourcePosition
{
SourcePosition
(
self
.
position
)
}
#
[
inline
]
pub
fn
source_location
(
&
self
)
-
>
SourceLocation
{
SourceLocation
{
line
:
self
.
current_line_number
column
:
(
self
.
position
-
self
.
current_line_start_position
+
1
)
as
u32
}
}
}
#
[
derive
(
Clone
Debug
PartialEq
)
]
pub
enum
BasicParseErrorKind
<
'
i
>
{
UnexpectedToken
(
Token
<
'
i
>
)
EndOfInput
AtRuleInvalid
(
CowRcStr
<
'
i
>
)
AtRuleBodyInvalid
QualifiedRuleInvalid
}
#
[
derive
(
Clone
Debug
PartialEq
)
]
pub
struct
BasicParseError
<
'
i
>
{
pub
kind
:
BasicParseErrorKind
<
'
i
>
pub
location
:
SourceLocation
}
impl
<
'
i
T
>
From
<
BasicParseError
<
'
i
>
>
for
ParseError
<
'
i
T
>
{
#
[
inline
]
fn
from
(
this
:
BasicParseError
<
'
i
>
)
-
>
ParseError
<
'
i
T
>
{
ParseError
{
kind
:
ParseErrorKind
:
:
Basic
(
this
.
kind
)
location
:
this
.
location
}
}
}
impl
SourceLocation
{
#
[
inline
]
pub
fn
new_basic_unexpected_token_error
<
'
i
>
(
self
token
:
Token
<
'
i
>
)
-
>
BasicParseError
<
'
i
>
{
BasicParseError
{
kind
:
BasicParseErrorKind
:
:
UnexpectedToken
(
token
)
location
:
self
}
}
#
[
inline
]
pub
fn
new_unexpected_token_error
<
'
i
E
>
(
self
token
:
Token
<
'
i
>
)
-
>
ParseError
<
'
i
E
>
{
ParseError
{
kind
:
ParseErrorKind
:
:
Basic
(
BasicParseErrorKind
:
:
UnexpectedToken
(
token
)
)
location
:
self
}
}
#
[
inline
]
pub
fn
new_custom_error
<
'
i
E1
:
Into
<
E2
>
E2
>
(
self
error
:
E1
)
-
>
ParseError
<
'
i
E2
>
{
ParseError
{
kind
:
ParseErrorKind
:
:
Custom
(
error
.
into
(
)
)
location
:
self
}
}
}
#
[
derive
(
Clone
Debug
PartialEq
)
]
pub
enum
ParseErrorKind
<
'
i
T
:
'
i
>
{
Basic
(
BasicParseErrorKind
<
'
i
>
)
Custom
(
T
)
}
impl
<
'
i
T
>
ParseErrorKind
<
'
i
T
>
{
pub
fn
into
<
U
>
(
self
)
-
>
ParseErrorKind
<
'
i
U
>
where
T
:
Into
<
U
>
{
match
self
{
ParseErrorKind
:
:
Basic
(
basic
)
=
>
ParseErrorKind
:
:
Basic
(
basic
)
ParseErrorKind
:
:
Custom
(
custom
)
=
>
ParseErrorKind
:
:
Custom
(
custom
.
into
(
)
)
}
}
}
#
[
derive
(
Clone
Debug
PartialEq
)
]
pub
struct
ParseError
<
'
i
E
>
{
pub
kind
:
ParseErrorKind
<
'
i
E
>
pub
location
:
SourceLocation
}
impl
<
'
i
T
>
ParseError
<
'
i
T
>
{
pub
fn
basic
(
self
)
-
>
BasicParseError
<
'
i
>
{
match
self
.
kind
{
ParseErrorKind
:
:
Basic
(
kind
)
=
>
BasicParseError
{
kind
:
kind
location
:
self
.
location
}
ParseErrorKind
:
:
Custom
(
_
)
=
>
panic
!
(
"
Not
a
basic
parse
error
"
)
}
}
pub
fn
into
<
U
>
(
self
)
-
>
ParseError
<
'
i
U
>
where
T
:
Into
<
U
>
{
ParseError
{
kind
:
self
.
kind
.
into
(
)
location
:
self
.
location
}
}
}
pub
struct
ParserInput
<
'
i
>
{
tokenizer
:
Tokenizer
<
'
i
>
cached_token
:
Option
<
CachedToken
<
'
i
>
>
}
struct
CachedToken
<
'
i
>
{
token
:
Token
<
'
i
>
start_position
:
SourcePosition
end_state
:
ParserState
}
impl
<
'
i
>
ParserInput
<
'
i
>
{
pub
fn
new
(
input
:
&
'
i
str
)
-
>
ParserInput
<
'
i
>
{
ParserInput
{
tokenizer
:
Tokenizer
:
:
new
(
input
)
cached_token
:
None
}
}
pub
fn
new_with_line_number_offset
(
input
:
&
'
i
str
first_line_number
:
u32
)
-
>
ParserInput
<
'
i
>
{
ParserInput
{
tokenizer
:
Tokenizer
:
:
with_first_line_number
(
input
first_line_number
)
cached_token
:
None
}
}
#
[
inline
]
fn
cached_token_ref
(
&
self
)
-
>
&
Token
<
'
i
>
{
&
self
.
cached_token
.
as_ref
(
)
.
unwrap
(
)
.
token
}
}
pub
struct
Parser
<
'
i
'
t
>
{
input
:
&
'
t
mut
ParserInput
<
'
i
>
at_start_of
:
Option
<
BlockType
>
stop_before
:
Delimiters
}
#
[
derive
(
Copy
Clone
PartialEq
Eq
Debug
)
]
pub
(
crate
)
enum
BlockType
{
Parenthesis
SquareBracket
CurlyBracket
}
impl
BlockType
{
fn
opening
(
token
:
&
Token
)
-
>
Option
<
BlockType
>
{
match
*
token
{
Token
:
:
Function
(
_
)
|
Token
:
:
ParenthesisBlock
=
>
Some
(
BlockType
:
:
Parenthesis
)
Token
:
:
SquareBracketBlock
=
>
Some
(
BlockType
:
:
SquareBracket
)
Token
:
:
CurlyBracketBlock
=
>
Some
(
BlockType
:
:
CurlyBracket
)
_
=
>
None
}
}
fn
closing
(
token
:
&
Token
)
-
>
Option
<
BlockType
>
{
match
*
token
{
Token
:
:
CloseParenthesis
=
>
Some
(
BlockType
:
:
Parenthesis
)
Token
:
:
CloseSquareBracket
=
>
Some
(
BlockType
:
:
SquareBracket
)
Token
:
:
CloseCurlyBracket
=
>
Some
(
BlockType
:
:
CurlyBracket
)
_
=
>
None
}
}
}
#
[
derive
(
Copy
Clone
PartialEq
Eq
Debug
)
]
pub
struct
Delimiters
{
bits
:
u8
}
#
[
allow
(
non_upper_case_globals
non_snake_case
)
]
pub
mod
Delimiter
{
use
super
:
:
Delimiters
;
pub
const
None
:
Delimiters
=
Delimiters
{
bits
:
0
}
;
pub
const
CurlyBracketBlock
:
Delimiters
=
Delimiters
{
bits
:
1
<
<
1
}
;
pub
const
Semicolon
:
Delimiters
=
Delimiters
{
bits
:
1
<
<
2
}
;
pub
const
Bang
:
Delimiters
=
Delimiters
{
bits
:
1
<
<
3
}
;
pub
const
Comma
:
Delimiters
=
Delimiters
{
bits
:
1
<
<
4
}
;
}
#
[
allow
(
non_upper_case_globals
non_snake_case
)
]
mod
ClosingDelimiter
{
use
super
:
:
Delimiters
;
pub
const
CloseCurlyBracket
:
Delimiters
=
Delimiters
{
bits
:
1
<
<
5
}
;
pub
const
CloseSquareBracket
:
Delimiters
=
Delimiters
{
bits
:
1
<
<
6
}
;
pub
const
CloseParenthesis
:
Delimiters
=
Delimiters
{
bits
:
1
<
<
7
}
;
}
impl
BitOr
<
Delimiters
>
for
Delimiters
{
type
Output
=
Delimiters
;
#
[
inline
]
fn
bitor
(
self
other
:
Delimiters
)
-
>
Delimiters
{
Delimiters
{
bits
:
self
.
bits
|
other
.
bits
}
}
}
impl
Delimiters
{
#
[
inline
]
fn
contains
(
self
other
:
Delimiters
)
-
>
bool
{
(
self
.
bits
&
other
.
bits
)
!
=
0
}
#
[
inline
]
fn
from_byte
(
byte
:
Option
<
u8
>
)
-
>
Delimiters
{
match
byte
{
Some
(
b
'
;
'
)
=
>
Delimiter
:
:
Semicolon
Some
(
b
'
!
'
)
=
>
Delimiter
:
:
Bang
Some
(
b
'
'
)
=
>
Delimiter
:
:
Comma
Some
(
b
'
{
'
)
=
>
Delimiter
:
:
CurlyBracketBlock
Some
(
b
'
}
'
)
=
>
ClosingDelimiter
:
:
CloseCurlyBracket
Some
(
b
'
]
'
)
=
>
ClosingDelimiter
:
:
CloseSquareBracket
Some
(
b
'
)
'
)
=
>
ClosingDelimiter
:
:
CloseParenthesis
_
=
>
Delimiter
:
:
None
}
}
}
macro_rules
!
expect
{
(
parser
:
ident
(
branches
:
tt
)
+
)
=
>
{
{
let
start_location
=
parser
.
current_source_location
(
)
;
match
*
parser
.
next
(
)
?
{
(
branches
)
+
ref
token
=
>
{
return
Err
(
start_location
.
new_basic_unexpected_token_error
(
token
.
clone
(
)
)
)
}
}
}
}
}
impl
<
'
i
:
'
t
'
t
>
Parser
<
'
i
'
t
>
{
#
[
inline
]
pub
fn
new
(
input
:
&
'
t
mut
ParserInput
<
'
i
>
)
-
>
Parser
<
'
i
'
t
>
{
Parser
{
input
:
input
at_start_of
:
None
stop_before
:
Delimiter
:
:
None
}
}
pub
fn
current_line
(
&
self
)
-
>
&
'
i
str
{
self
.
input
.
tokenizer
.
current_source_line
(
)
}
#
[
inline
]
pub
fn
is_exhausted
(
&
mut
self
)
-
>
bool
{
self
.
expect_exhausted
(
)
.
is_ok
(
)
}
#
[
inline
]
pub
fn
expect_exhausted
(
&
mut
self
)
-
>
Result
<
(
)
BasicParseError
<
'
i
>
>
{
let
start
=
self
.
state
(
)
;
let
result
=
match
self
.
next
(
)
{
Err
(
BasicParseError
{
kind
:
BasicParseErrorKind
:
:
EndOfInput
.
.
}
)
=
>
Ok
(
(
)
)
Err
(
e
)
=
>
unreachable
!
(
"
Unexpected
error
encountered
:
{
:
?
}
"
e
)
Ok
(
t
)
=
>
Err
(
start
.
source_location
(
)
.
new_basic_unexpected_token_error
(
t
.
clone
(
)
)
)
}
;
self
.
reset
(
&
start
)
;
result
}
#
[
inline
]
pub
fn
position
(
&
self
)
-
>
SourcePosition
{
self
.
input
.
tokenizer
.
position
(
)
}
#
[
inline
]
pub
fn
current_source_location
(
&
self
)
-
>
SourceLocation
{
self
.
input
.
tokenizer
.
current_source_location
(
)
}
pub
fn
current_source_map_url
(
&
self
)
-
>
Option
<
&
str
>
{
self
.
input
.
tokenizer
.
current_source_map_url
(
)
}
pub
fn
current_source_url
(
&
self
)
-
>
Option
<
&
str
>
{
self
.
input
.
tokenizer
.
current_source_url
(
)
}
#
[
inline
]
pub
fn
new_basic_error
(
&
self
kind
:
BasicParseErrorKind
<
'
i
>
)
-
>
BasicParseError
<
'
i
>
{
BasicParseError
{
kind
:
kind
location
:
self
.
current_source_location
(
)
}
}
#
[
inline
]
pub
fn
new_error
<
E
>
(
&
self
kind
:
BasicParseErrorKind
<
'
i
>
)
-
>
ParseError
<
'
i
E
>
{
ParseError
{
kind
:
ParseErrorKind
:
:
Basic
(
kind
)
location
:
self
.
current_source_location
(
)
}
}
#
[
inline
]
pub
fn
new_custom_error
<
E1
:
Into
<
E2
>
E2
>
(
&
self
error
:
E1
)
-
>
ParseError
<
'
i
E2
>
{
self
.
current_source_location
(
)
.
new_custom_error
(
error
)
}
#
[
inline
]
pub
fn
new_basic_unexpected_token_error
(
&
self
token
:
Token
<
'
i
>
)
-
>
BasicParseError
<
'
i
>
{
self
.
new_basic_error
(
BasicParseErrorKind
:
:
UnexpectedToken
(
token
)
)
}
#
[
inline
]
pub
fn
new_unexpected_token_error
<
E
>
(
&
self
token
:
Token
<
'
i
>
)
-
>
ParseError
<
'
i
E
>
{
self
.
new_error
(
BasicParseErrorKind
:
:
UnexpectedToken
(
token
)
)
}
#
[
inline
]
pub
fn
new_error_for_next_token
<
E
>
(
&
mut
self
)
-
>
ParseError
<
'
i
E
>
{
let
token
=
match
self
.
next
(
)
{
Ok
(
token
)
=
>
token
.
clone
(
)
Err
(
e
)
=
>
return
e
.
into
(
)
}
;
self
.
new_error
(
BasicParseErrorKind
:
:
UnexpectedToken
(
token
)
)
}
#
[
inline
]
pub
fn
state
(
&
self
)
-
>
ParserState
{
ParserState
{
at_start_of
:
self
.
at_start_of
.
.
self
.
input
.
tokenizer
.
state
(
)
}
}
#
[
inline
]
pub
fn
skip_whitespace
(
&
mut
self
)
{
if
let
Some
(
block_type
)
=
self
.
at_start_of
.
take
(
)
{
consume_until_end_of_block
(
block_type
&
mut
self
.
input
.
tokenizer
)
;
}
self
.
input
.
tokenizer
.
skip_whitespace
(
)
}
#
[
inline
]
pub
(
crate
)
fn
skip_cdc_and_cdo
(
&
mut
self
)
{
if
let
Some
(
block_type
)
=
self
.
at_start_of
.
take
(
)
{
consume_until_end_of_block
(
block_type
&
mut
self
.
input
.
tokenizer
)
;
}
self
.
input
.
tokenizer
.
skip_cdc_and_cdo
(
)
}
#
[
inline
]
pub
(
crate
)
fn
next_byte
(
&
self
)
-
>
Option
<
u8
>
{
let
byte
=
self
.
input
.
tokenizer
.
next_byte
(
)
;
if
self
.
stop_before
.
contains
(
Delimiters
:
:
from_byte
(
byte
)
)
{
return
None
;
}
byte
}
#
[
inline
]
pub
fn
reset
(
&
mut
self
state
:
&
ParserState
)
{
self
.
input
.
tokenizer
.
reset
(
state
)
;
self
.
at_start_of
=
state
.
at_start_of
;
}
#
[
inline
]
pub
fn
look_for_var_or_env_functions
(
&
mut
self
)
{
self
.
input
.
tokenizer
.
look_for_var_or_env_functions
(
)
}
#
[
inline
]
pub
fn
seen_var_or_env_functions
(
&
mut
self
)
-
>
bool
{
self
.
input
.
tokenizer
.
seen_var_or_env_functions
(
)
}
#
[
inline
]
pub
fn
r
#
try
<
F
T
E
>
(
&
mut
self
thing
:
F
)
-
>
Result
<
T
E
>
where
F
:
FnOnce
(
&
mut
Parser
<
'
i
'
t
>
)
-
>
Result
<
T
E
>
{
self
.
try_parse
(
thing
)
}
#
[
inline
]
pub
fn
try_parse
<
F
T
E
>
(
&
mut
self
thing
:
F
)
-
>
Result
<
T
E
>
where
F
:
FnOnce
(
&
mut
Parser
<
'
i
'
t
>
)
-
>
Result
<
T
E
>
{
let
start
=
self
.
state
(
)
;
let
result
=
thing
(
self
)
;
if
result
.
is_err
(
)
{
self
.
reset
(
&
start
)
}
result
}
#
[
inline
]
pub
fn
slice
(
&
self
range
:
Range
<
SourcePosition
>
)
-
>
&
'
i
str
{
self
.
input
.
tokenizer
.
slice
(
range
)
}
#
[
inline
]
pub
fn
slice_from
(
&
self
start_position
:
SourcePosition
)
-
>
&
'
i
str
{
self
.
input
.
tokenizer
.
slice_from
(
start_position
)
}
pub
fn
next
(
&
mut
self
)
-
>
Result
<
&
Token
<
'
i
>
BasicParseError
<
'
i
>
>
{
self
.
skip_whitespace
(
)
;
self
.
next_including_whitespace_and_comments
(
)
}
pub
fn
next_including_whitespace
(
&
mut
self
)
-
>
Result
<
&
Token
<
'
i
>
BasicParseError
<
'
i
>
>
{
loop
{
match
self
.
next_including_whitespace_and_comments
(
)
{
Err
(
e
)
=
>
return
Err
(
e
)
Ok
(
&
Token
:
:
Comment
(
_
)
)
=
>
{
}
_
=
>
break
}
}
Ok
(
self
.
input
.
cached_token_ref
(
)
)
}
pub
fn
next_including_whitespace_and_comments
(
&
mut
self
)
-
>
Result
<
&
Token
<
'
i
>
BasicParseError
<
'
i
>
>
{
if
let
Some
(
block_type
)
=
self
.
at_start_of
.
take
(
)
{
consume_until_end_of_block
(
block_type
&
mut
self
.
input
.
tokenizer
)
;
}
let
byte
=
self
.
input
.
tokenizer
.
next_byte
(
)
;
if
self
.
stop_before
.
contains
(
Delimiters
:
:
from_byte
(
byte
)
)
{
return
Err
(
self
.
new_basic_error
(
BasicParseErrorKind
:
:
EndOfInput
)
)
;
}
let
token_start_position
=
self
.
input
.
tokenizer
.
position
(
)
;
let
using_cached_token
=
self
.
input
.
cached_token
.
as_ref
(
)
.
map_or
(
false
|
cached_token
|
{
cached_token
.
start_position
=
=
token_start_position
}
)
;
let
token
=
if
using_cached_token
{
let
cached_token
=
self
.
input
.
cached_token
.
as_ref
(
)
.
unwrap
(
)
;
self
.
input
.
tokenizer
.
reset
(
&
cached_token
.
end_state
)
;
match
cached_token
.
token
{
Token
:
:
Function
(
ref
name
)
=
>
self
.
input
.
tokenizer
.
see_function
(
name
)
_
=
>
{
}
}
&
cached_token
.
token
}
else
{
let
new_token
=
self
.
input
.
tokenizer
.
next
(
)
.
map_err
(
|
(
)
|
self
.
new_basic_error
(
BasicParseErrorKind
:
:
EndOfInput
)
)
?
;
self
.
input
.
cached_token
=
Some
(
CachedToken
{
token
:
new_token
start_position
:
token_start_position
end_state
:
self
.
input
.
tokenizer
.
state
(
)
}
)
;
self
.
input
.
cached_token_ref
(
)
}
;
if
let
Some
(
block_type
)
=
BlockType
:
:
opening
(
token
)
{
self
.
at_start_of
=
Some
(
block_type
)
;
}
Ok
(
token
)
}
#
[
inline
]
pub
fn
parse_entirely
<
F
T
E
>
(
&
mut
self
parse
:
F
)
-
>
Result
<
T
ParseError
<
'
i
E
>
>
where
F
:
FnOnce
(
&
mut
Parser
<
'
i
'
t
>
)
-
>
Result
<
T
ParseError
<
'
i
E
>
>
{
let
result
=
parse
(
self
)
?
;
self
.
expect_exhausted
(
)
?
;
Ok
(
result
)
}
#
[
inline
]
pub
fn
parse_comma_separated
<
F
T
E
>
(
&
mut
self
mut
parse_one
:
F
)
-
>
Result
<
Vec
<
T
>
ParseError
<
'
i
E
>
>
where
F
:
for
<
'
tt
>
FnMut
(
&
mut
Parser
<
'
i
'
tt
>
)
-
>
Result
<
T
ParseError
<
'
i
E
>
>
{
let
mut
values
=
Vec
:
:
with_capacity
(
1
)
;
loop
{
self
.
skip_whitespace
(
)
;
values
.
push
(
self
.
parse_until_before
(
Delimiter
:
:
Comma
&
mut
parse_one
)
?
)
;
match
self
.
next
(
)
{
Err
(
_
)
=
>
return
Ok
(
values
)
Ok
(
&
Token
:
:
Comma
)
=
>
continue
Ok
(
_
)
=
>
unreachable
!
(
)
}
}
}
#
[
inline
]
pub
fn
parse_nested_block
<
F
T
E
>
(
&
mut
self
parse
:
F
)
-
>
Result
<
T
ParseError
<
'
i
E
>
>
where
F
:
for
<
'
tt
>
FnOnce
(
&
mut
Parser
<
'
i
'
tt
>
)
-
>
Result
<
T
ParseError
<
'
i
E
>
>
{
parse_nested_block
(
self
parse
)
}
#
[
inline
]
pub
fn
parse_until_before
<
F
T
E
>
(
&
mut
self
delimiters
:
Delimiters
parse
:
F
)
-
>
Result
<
T
ParseError
<
'
i
E
>
>
where
F
:
for
<
'
tt
>
FnOnce
(
&
mut
Parser
<
'
i
'
tt
>
)
-
>
Result
<
T
ParseError
<
'
i
E
>
>
{
parse_until_before
(
self
delimiters
parse
)
}
#
[
inline
]
pub
fn
parse_until_after
<
F
T
E
>
(
&
mut
self
delimiters
:
Delimiters
parse
:
F
)
-
>
Result
<
T
ParseError
<
'
i
E
>
>
where
F
:
for
<
'
tt
>
FnOnce
(
&
mut
Parser
<
'
i
'
tt
>
)
-
>
Result
<
T
ParseError
<
'
i
E
>
>
{
parse_until_after
(
self
delimiters
parse
)
}
#
[
inline
]
pub
fn
expect_whitespace
(
&
mut
self
)
-
>
Result
<
&
'
i
str
BasicParseError
<
'
i
>
>
{
let
start_location
=
self
.
current_source_location
(
)
;
match
*
self
.
next_including_whitespace
(
)
?
{
Token
:
:
WhiteSpace
(
value
)
=
>
Ok
(
value
)
ref
t
=
>
Err
(
start_location
.
new_basic_unexpected_token_error
(
t
.
clone
(
)
)
)
}
}
#
[
inline
]
pub
fn
expect_ident
(
&
mut
self
)
-
>
Result
<
&
CowRcStr
<
'
i
>
BasicParseError
<
'
i
>
>
{
expect
!
{
self
Token
:
:
Ident
(
ref
value
)
=
>
Ok
(
value
)
}
}
#
[
inline
]
pub
fn
expect_ident_cloned
(
&
mut
self
)
-
>
Result
<
CowRcStr
<
'
i
>
BasicParseError
<
'
i
>
>
{
self
.
expect_ident
(
)
.
map
(
|
s
|
s
.
clone
(
)
)
}
#
[
inline
]
pub
fn
expect_ident_matching
(
&
mut
self
expected_value
:
&
str
)
-
>
Result
<
(
)
BasicParseError
<
'
i
>
>
{
expect
!
{
self
Token
:
:
Ident
(
ref
value
)
if
value
.
eq_ignore_ascii_case
(
expected_value
)
=
>
Ok
(
(
)
)
}
}
#
[
inline
]
pub
fn
expect_string
(
&
mut
self
)
-
>
Result
<
&
CowRcStr
<
'
i
>
BasicParseError
<
'
i
>
>
{
expect
!
{
self
Token
:
:
QuotedString
(
ref
value
)
=
>
Ok
(
value
)
}
}
#
[
inline
]
pub
fn
expect_string_cloned
(
&
mut
self
)
-
>
Result
<
CowRcStr
<
'
i
>
BasicParseError
<
'
i
>
>
{
self
.
expect_string
(
)
.
map
(
|
s
|
s
.
clone
(
)
)
}
#
[
inline
]
pub
fn
expect_ident_or_string
(
&
mut
self
)
-
>
Result
<
&
CowRcStr
<
'
i
>
BasicParseError
<
'
i
>
>
{
expect
!
{
self
Token
:
:
Ident
(
ref
value
)
=
>
Ok
(
value
)
Token
:
:
QuotedString
(
ref
value
)
=
>
Ok
(
value
)
}
}
#
[
inline
]
pub
fn
expect_url
(
&
mut
self
)
-
>
Result
<
CowRcStr
<
'
i
>
BasicParseError
<
'
i
>
>
{
expect
!
{
self
Token
:
:
UnquotedUrl
(
ref
value
)
=
>
Ok
(
value
.
clone
(
)
)
Token
:
:
Function
(
ref
name
)
if
name
.
eq_ignore_ascii_case
(
"
url
"
)
=
>
{
self
.
parse_nested_block
(
|
input
|
{
input
.
expect_string
(
)
.
map_err
(
Into
:
:
into
)
.
map
(
|
s
|
s
.
clone
(
)
)
}
)
.
map_err
(
ParseError
:
:
<
(
)
>
:
:
basic
)
}
}
}
#
[
inline
]
pub
fn
expect_url_or_string
(
&
mut
self
)
-
>
Result
<
CowRcStr
<
'
i
>
BasicParseError
<
'
i
>
>
{
expect
!
{
self
Token
:
:
UnquotedUrl
(
ref
value
)
=
>
Ok
(
value
.
clone
(
)
)
Token
:
:
QuotedString
(
ref
value
)
=
>
Ok
(
value
.
clone
(
)
)
Token
:
:
Function
(
ref
name
)
if
name
.
eq_ignore_ascii_case
(
"
url
"
)
=
>
{
self
.
parse_nested_block
(
|
input
|
{
input
.
expect_string
(
)
.
map_err
(
Into
:
:
into
)
.
map
(
|
s
|
s
.
clone
(
)
)
}
)
.
map_err
(
ParseError
:
:
<
(
)
>
:
:
basic
)
}
}
}
#
[
inline
]
pub
fn
expect_number
(
&
mut
self
)
-
>
Result
<
f32
BasicParseError
<
'
i
>
>
{
expect
!
{
self
Token
:
:
Number
{
value
.
.
}
=
>
Ok
(
value
)
}
}
#
[
inline
]
pub
fn
expect_integer
(
&
mut
self
)
-
>
Result
<
i32
BasicParseError
<
'
i
>
>
{
expect
!
{
self
Token
:
:
Number
{
int_value
:
Some
(
int_value
)
.
.
}
=
>
Ok
(
int_value
)
}
}
#
[
inline
]
pub
fn
expect_percentage
(
&
mut
self
)
-
>
Result
<
f32
BasicParseError
<
'
i
>
>
{
expect
!
{
self
Token
:
:
Percentage
{
unit_value
.
.
}
=
>
Ok
(
unit_value
)
}
}
#
[
inline
]
pub
fn
expect_colon
(
&
mut
self
)
-
>
Result
<
(
)
BasicParseError
<
'
i
>
>
{
expect
!
{
self
Token
:
:
Colon
=
>
Ok
(
(
)
)
}
}
#
[
inline
]
pub
fn
expect_semicolon
(
&
mut
self
)
-
>
Result
<
(
)
BasicParseError
<
'
i
>
>
{
expect
!
{
self
Token
:
:
Semicolon
=
>
Ok
(
(
)
)
}
}
#
[
inline
]
pub
fn
expect_comma
(
&
mut
self
)
-
>
Result
<
(
)
BasicParseError
<
'
i
>
>
{
expect
!
{
self
Token
:
:
Comma
=
>
Ok
(
(
)
)
}
}
#
[
inline
]
pub
fn
expect_delim
(
&
mut
self
expected_value
:
char
)
-
>
Result
<
(
)
BasicParseError
<
'
i
>
>
{
expect
!
{
self
Token
:
:
Delim
(
value
)
if
value
=
=
expected_value
=
>
Ok
(
(
)
)
}
}
#
[
inline
]
pub
fn
expect_curly_bracket_block
(
&
mut
self
)
-
>
Result
<
(
)
BasicParseError
<
'
i
>
>
{
expect
!
{
self
Token
:
:
CurlyBracketBlock
=
>
Ok
(
(
)
)
}
}
#
[
inline
]
pub
fn
expect_square_bracket_block
(
&
mut
self
)
-
>
Result
<
(
)
BasicParseError
<
'
i
>
>
{
expect
!
{
self
Token
:
:
SquareBracketBlock
=
>
Ok
(
(
)
)
}
}
#
[
inline
]
pub
fn
expect_parenthesis_block
(
&
mut
self
)
-
>
Result
<
(
)
BasicParseError
<
'
i
>
>
{
expect
!
{
self
Token
:
:
ParenthesisBlock
=
>
Ok
(
(
)
)
}
}
#
[
inline
]
pub
fn
expect_function
(
&
mut
self
)
-
>
Result
<
&
CowRcStr
<
'
i
>
BasicParseError
<
'
i
>
>
{
expect
!
{
self
Token
:
:
Function
(
ref
name
)
=
>
Ok
(
name
)
}
}
#
[
inline
]
pub
fn
expect_function_matching
(
&
mut
self
expected_name
:
&
str
)
-
>
Result
<
(
)
BasicParseError
<
'
i
>
>
{
expect
!
{
self
Token
:
:
Function
(
ref
name
)
if
name
.
eq_ignore_ascii_case
(
expected_name
)
=
>
Ok
(
(
)
)
}
}
#
[
inline
]
pub
fn
expect_no_error_token
(
&
mut
self
)
-
>
Result
<
(
)
BasicParseError
<
'
i
>
>
{
loop
{
match
self
.
next_including_whitespace_and_comments
(
)
{
Ok
(
&
Token
:
:
Function
(
_
)
)
|
Ok
(
&
Token
:
:
ParenthesisBlock
)
|
Ok
(
&
Token
:
:
SquareBracketBlock
)
|
Ok
(
&
Token
:
:
CurlyBracketBlock
)
=
>
self
.
parse_nested_block
(
|
input
|
input
.
expect_no_error_token
(
)
.
map_err
(
Into
:
:
into
)
)
.
map_err
(
ParseError
:
:
<
(
)
>
:
:
basic
)
?
Ok
(
t
)
=
>
{
if
t
.
is_parse_error
(
)
{
let
token
=
t
.
clone
(
)
;
return
Err
(
self
.
new_basic_unexpected_token_error
(
token
)
)
;
}
}
Err
(
_
)
=
>
return
Ok
(
(
)
)
}
}
}
}
pub
fn
parse_until_before
<
'
i
:
'
t
'
t
F
T
E
>
(
parser
:
&
mut
Parser
<
'
i
'
t
>
delimiters
:
Delimiters
parse
:
F
)
-
>
Result
<
T
ParseError
<
'
i
E
>
>
where
F
:
for
<
'
tt
>
FnOnce
(
&
mut
Parser
<
'
i
'
tt
>
)
-
>
Result
<
T
ParseError
<
'
i
E
>
>
{
let
delimiters
=
parser
.
stop_before
|
delimiters
;
let
result
;
{
let
mut
delimited_parser
=
Parser
{
input
:
parser
.
input
at_start_of
:
parser
.
at_start_of
.
take
(
)
stop_before
:
delimiters
}
;
result
=
delimited_parser
.
parse_entirely
(
parse
)
;
if
let
Some
(
block_type
)
=
delimited_parser
.
at_start_of
{
consume_until_end_of_block
(
block_type
&
mut
delimited_parser
.
input
.
tokenizer
)
;
}
}
loop
{
if
delimiters
.
contains
(
Delimiters
:
:
from_byte
(
parser
.
input
.
tokenizer
.
next_byte
(
)
)
)
{
break
;
}
if
let
Ok
(
token
)
=
parser
.
input
.
tokenizer
.
next
(
)
{
if
let
Some
(
block_type
)
=
BlockType
:
:
opening
(
&
token
)
{
consume_until_end_of_block
(
block_type
&
mut
parser
.
input
.
tokenizer
)
;
}
}
else
{
break
;
}
}
result
}
pub
fn
parse_until_after
<
'
i
:
'
t
'
t
F
T
E
>
(
parser
:
&
mut
Parser
<
'
i
'
t
>
delimiters
:
Delimiters
parse
:
F
)
-
>
Result
<
T
ParseError
<
'
i
E
>
>
where
F
:
for
<
'
tt
>
FnOnce
(
&
mut
Parser
<
'
i
'
tt
>
)
-
>
Result
<
T
ParseError
<
'
i
E
>
>
{
let
result
=
parser
.
parse_until_before
(
delimiters
parse
)
;
let
next_byte
=
parser
.
input
.
tokenizer
.
next_byte
(
)
;
if
next_byte
.
is_some
(
)
&
&
!
parser
.
stop_before
.
contains
(
Delimiters
:
:
from_byte
(
next_byte
)
)
{
debug_assert
!
(
delimiters
.
contains
(
Delimiters
:
:
from_byte
(
next_byte
)
)
)
;
parser
.
input
.
tokenizer
.
advance
(
1
)
;
if
next_byte
=
=
Some
(
b
'
{
'
)
{
consume_until_end_of_block
(
BlockType
:
:
CurlyBracket
&
mut
parser
.
input
.
tokenizer
)
;
}
}
result
}
pub
fn
parse_nested_block
<
'
i
:
'
t
'
t
F
T
E
>
(
parser
:
&
mut
Parser
<
'
i
'
t
>
parse
:
F
)
-
>
Result
<
T
ParseError
<
'
i
E
>
>
where
F
:
for
<
'
tt
>
FnOnce
(
&
mut
Parser
<
'
i
'
tt
>
)
-
>
Result
<
T
ParseError
<
'
i
E
>
>
{
let
block_type
=
parser
.
at_start_of
.
take
(
)
.
expect
(
"
\
A
nested
parser
can
only
be
created
when
a
Function
\
ParenthesisBlock
SquareBracketBlock
or
CurlyBracketBlock
\
token
was
just
consumed
.
\
"
)
;
let
closing_delimiter
=
match
block_type
{
BlockType
:
:
CurlyBracket
=
>
ClosingDelimiter
:
:
CloseCurlyBracket
BlockType
:
:
SquareBracket
=
>
ClosingDelimiter
:
:
CloseSquareBracket
BlockType
:
:
Parenthesis
=
>
ClosingDelimiter
:
:
CloseParenthesis
}
;
let
result
;
{
let
mut
nested_parser
=
Parser
{
input
:
parser
.
input
at_start_of
:
None
stop_before
:
closing_delimiter
}
;
result
=
nested_parser
.
parse_entirely
(
parse
)
;
if
let
Some
(
block_type
)
=
nested_parser
.
at_start_of
{
consume_until_end_of_block
(
block_type
&
mut
nested_parser
.
input
.
tokenizer
)
;
}
}
consume_until_end_of_block
(
block_type
&
mut
parser
.
input
.
tokenizer
)
;
result
}
#
[
inline
(
never
)
]
#
[
cold
]
fn
consume_until_end_of_block
(
block_type
:
BlockType
tokenizer
:
&
mut
Tokenizer
)
{
let
mut
stack
=
SmallVec
:
:
<
[
BlockType
;
16
]
>
:
:
new
(
)
;
stack
.
push
(
block_type
)
;
while
let
Ok
(
ref
token
)
=
tokenizer
.
next
(
)
{
if
let
Some
(
b
)
=
BlockType
:
:
closing
(
token
)
{
if
*
stack
.
last
(
)
.
unwrap
(
)
=
=
b
{
stack
.
pop
(
)
;
if
stack
.
is_empty
(
)
{
return
;
}
}
}
if
let
Some
(
block_type
)
=
BlockType
:
:
opening
(
token
)
{
stack
.
push
(
block_type
)
;
}
}
}
