mod
db
;
mod
error
;
mod
ingest
;
mod
interest
;
mod
ranker
;
mod
rs
;
mod
schema
;
pub
mod
url_hash
;
use
rand_distr
:
:
{
Beta
Distribution
}
;
pub
use
db
:
:
RelevancyDb
;
pub
use
error
:
:
{
ApiResult
Error
RelevancyApiError
Result
}
;
pub
use
interest
:
:
{
Interest
InterestVector
}
;
use
parking_lot
:
:
Mutex
;
pub
use
ranker
:
:
score
;
use
error_support
:
:
handle_error
;
use
db
:
:
BanditData
;
use
std
:
:
{
collections
:
:
HashMap
sync
:
:
Arc
}
;
uniffi
:
:
setup_scaffolding
!
(
)
;
#
[
derive
(
uniffi
:
:
Object
)
]
pub
struct
RelevancyStore
{
db
:
RelevancyDb
cache
:
Mutex
<
BanditCache
>
}
#
[
uniffi
:
:
export
]
impl
RelevancyStore
{
#
[
uniffi
:
:
constructor
(
default
(
remote_settings_service
=
None
)
)
]
pub
fn
new
(
db_path
:
String
#
[
allow
(
unused
)
]
remote_settings_service
:
Option
<
Arc
<
remote_settings
:
:
RemoteSettingsService
>
>
)
-
>
Self
{
Self
{
db
:
RelevancyDb
:
:
new
(
db_path
)
cache
:
Mutex
:
:
new
(
BanditCache
:
:
new
(
)
)
}
}
pub
fn
close
(
&
self
)
{
self
.
db
.
close
(
)
}
pub
fn
interrupt
(
&
self
)
{
self
.
db
.
interrupt
(
)
}
#
[
handle_error
(
Error
)
]
pub
fn
ingest
(
&
self
top_urls_by_frecency
:
Vec
<
String
>
)
-
>
ApiResult
<
InterestVector
>
{
ingest
:
:
ensure_interest_data_populated
(
&
self
.
db
)
?
;
let
interest_vec
=
self
.
classify
(
top_urls_by_frecency
)
?
;
self
.
db
.
read_write
(
|
dao
|
dao
.
update_frecency_user_interest_vector
(
&
interest_vec
)
)
?
;
Ok
(
interest_vec
)
}
#
[
handle_error
(
Error
)
]
pub
fn
calculate_metrics
(
&
self
)
-
>
ApiResult
<
InterestMetrics
>
{
todo
!
(
)
}
#
[
handle_error
(
Error
)
]
pub
fn
user_interest_vector
(
&
self
)
-
>
ApiResult
<
InterestVector
>
{
self
.
db
.
read
(
|
dao
|
dao
.
get_frecency_user_interest_vector
(
)
)
}
#
[
handle_error
(
Error
)
]
pub
fn
bandit_init
(
&
self
bandit
:
String
arms
:
&
[
String
]
)
-
>
ApiResult
<
(
)
>
{
self
.
db
.
read_write
(
|
dao
|
{
for
arm
in
arms
{
dao
.
initialize_multi_armed_bandit
(
&
bandit
arm
)
?
;
}
Ok
(
(
)
)
}
)
?
;
Ok
(
(
)
)
}
#
[
handle_error
(
Error
)
]
pub
fn
bandit_select
(
&
self
bandit
:
String
arms
:
&
[
String
]
)
-
>
ApiResult
<
String
>
{
let
mut
cache
=
self
.
cache
.
lock
(
)
;
let
mut
best_sample
=
f64
:
:
MIN
;
let
mut
selected_arm
=
String
:
:
new
(
)
;
for
arm
in
arms
{
let
(
alpha
beta
)
=
cache
.
get_beta_distribution
(
&
bandit
arm
&
self
.
db
)
?
;
let
beta_dist
=
Beta
:
:
new
(
alpha
as
f64
beta
as
f64
)
.
expect
(
"
computing
betas
dist
unexpectedly
failed
"
)
;
let
sampled_prob
=
beta_dist
.
sample
(
&
mut
rand
:
:
thread_rng
(
)
)
;
if
sampled_prob
>
best_sample
{
best_sample
=
sampled_prob
;
selected_arm
.
clone_from
(
arm
)
;
}
}
return
Ok
(
selected_arm
)
;
}
#
[
handle_error
(
Error
)
]
pub
fn
bandit_update
(
&
self
bandit
:
String
arm
:
String
selected
:
bool
)
-
>
ApiResult
<
(
)
>
{
let
mut
cache
=
self
.
cache
.
lock
(
)
;
cache
.
clear
(
&
bandit
&
arm
)
;
self
.
db
.
read_write
(
|
dao
|
dao
.
update_bandit_arm_data
(
&
bandit
&
arm
selected
)
)
?
;
Ok
(
(
)
)
}
#
[
handle_error
(
Error
)
]
pub
fn
get_bandit_data
(
&
self
bandit
:
String
arm
:
String
)
-
>
ApiResult
<
BanditData
>
{
let
bandit_data
=
self
.
db
.
read
(
|
dao
|
dao
.
retrieve_bandit_data
(
&
bandit
&
arm
)
)
?
;
Ok
(
bandit_data
)
}
}
#
[
derive
(
Default
)
]
pub
struct
BanditCache
{
cache
:
HashMap
<
(
String
String
)
(
u64
u64
)
>
}
impl
BanditCache
{
pub
fn
new
(
)
-
>
Self
{
Self
:
:
default
(
)
}
pub
fn
get_beta_distribution
(
&
mut
self
bandit
:
&
str
arm
:
&
str
db
:
&
RelevancyDb
)
-
>
Result
<
(
u64
u64
)
>
{
let
key
=
(
bandit
.
to_string
(
)
arm
.
to_string
(
)
)
;
if
let
Some
(
&
params
)
=
self
.
cache
.
get
(
&
key
)
{
return
Ok
(
params
)
;
}
let
params
=
db
.
read
(
|
dao
|
dao
.
retrieve_bandit_arm_beta_distribution
(
bandit
arm
)
)
?
;
self
.
cache
.
insert
(
key
params
)
;
Ok
(
params
)
}
pub
fn
clear
(
&
mut
self
bandit
:
&
str
arm
:
&
str
)
{
let
key
=
(
bandit
.
to_string
(
)
arm
.
to_string
(
)
)
;
self
.
cache
.
remove
(
&
key
)
;
}
}
impl
RelevancyStore
{
#
[
handle_error
(
Error
)
]
pub
fn
ensure_interest_data_populated
(
&
self
)
-
>
ApiResult
<
(
)
>
{
ingest
:
:
ensure_interest_data_populated
(
&
self
.
db
)
?
;
Ok
(
(
)
)
}
pub
fn
classify
(
&
self
top_urls_by_frecency
:
Vec
<
String
>
)
-
>
Result
<
InterestVector
>
{
let
mut
interest_vector
=
InterestVector
:
:
default
(
)
;
for
url
in
top_urls_by_frecency
{
let
interest_count
=
self
.
db
.
read
(
|
dao
|
dao
.
get_url_interest_vector
(
&
url
)
)
?
;
log
:
:
trace
!
(
"
classified
:
{
url
}
{
}
"
interest_count
.
summary
(
)
)
;
interest_vector
=
interest_vector
+
interest_count
;
}
Ok
(
interest_vector
)
}
}
#
[
derive
(
uniffi
:
:
Record
)
]
pub
struct
InterestMetrics
{
pub
top_single_interest_similarity
:
u32
pub
top_2interest_similarity
:
u32
pub
top_3interest_similarity
:
u32
}
#
[
cfg
(
test
)
]
mod
test
{
use
crate
:
:
url_hash
:
:
hash_url
;
use
super
:
:
*
;
use
rand
:
:
Rng
;
use
std
:
:
collections
:
:
HashMap
;
fn
make_fixture
(
)
-
>
Vec
<
(
String
Interest
)
>
{
vec
!
[
(
"
https
:
/
/
food
.
com
/
"
.
to_string
(
)
Interest
:
:
Food
)
(
"
https
:
/
/
hello
.
com
"
.
to_string
(
)
Interest
:
:
Inconclusive
)
(
"
https
:
/
/
pasta
.
com
"
.
to_string
(
)
Interest
:
:
Food
)
(
"
https
:
/
/
dog
.
com
"
.
to_string
(
)
Interest
:
:
Animals
)
]
}
fn
expected_interest_vector
(
)
-
>
InterestVector
{
InterestVector
{
inconclusive
:
1
animals
:
1
food
:
2
.
.
InterestVector
:
:
default
(
)
}
}
fn
setup_store
(
test_id
:
&
'
static
str
)
-
>
RelevancyStore
{
let
relevancy_store
=
RelevancyStore
:
:
new
(
format
!
(
"
file
:
test_
{
test_id
}
_data
?
mode
=
memory
&
cache
=
shared
"
)
None
)
;
relevancy_store
.
db
.
read_write
(
|
dao
|
{
for
(
url
interest
)
in
make_fixture
(
)
{
dao
.
add_url_interest
(
hash_url
(
&
url
)
.
unwrap
(
)
interest
)
?
;
}
Ok
(
(
)
)
}
)
.
expect
(
"
Insert
should
succeed
"
)
;
relevancy_store
}
#
[
test
]
fn
test_ingest
(
)
{
let
relevancy_store
=
setup_store
(
"
ingest
"
)
;
let
(
top_urls
_
)
:
(
Vec
<
String
>
Vec
<
Interest
>
)
=
make_fixture
(
)
.
into_iter
(
)
.
unzip
(
)
;
assert_eq
!
(
relevancy_store
.
ingest
(
top_urls
)
.
unwrap
(
)
expected_interest_vector
(
)
)
;
}
#
[
test
]
fn
test_get_user_interest_vector
(
)
{
let
relevancy_store
=
setup_store
(
"
get_user_interest_vector
"
)
;
let
(
top_urls
_
)
:
(
Vec
<
String
>
Vec
<
Interest
>
)
=
make_fixture
(
)
.
into_iter
(
)
.
unzip
(
)
;
relevancy_store
.
ingest
(
top_urls
)
.
expect
(
"
Ingest
should
succeed
"
)
;
assert_eq
!
(
relevancy_store
.
user_interest_vector
(
)
.
unwrap
(
)
expected_interest_vector
(
)
)
;
}
#
[
test
]
fn
test_thompson_sampling_convergence
(
)
{
let
relevancy_store
=
setup_store
(
"
thompson_sampling_convergence
"
)
;
let
arms_to_ctr_map
:
HashMap
<
String
f64
>
=
[
(
"
wiki
"
.
to_string
(
)
0
.
1
)
(
"
geolocation
"
.
to_string
(
)
0
.
3
)
(
"
weather
"
.
to_string
(
)
0
.
8
)
]
.
into_iter
(
)
.
collect
(
)
;
let
arm_names
:
Vec
<
String
>
=
arms_to_ctr_map
.
keys
(
)
.
cloned
(
)
.
collect
(
)
;
let
bandit
=
"
provider
"
.
to_string
(
)
;
relevancy_store
.
bandit_init
(
bandit
.
clone
(
)
&
arm_names
)
.
unwrap
(
)
;
let
mut
rng
=
rand
:
:
thread_rng
(
)
;
let
mut
selection_counts
:
HashMap
<
String
usize
>
=
arm_names
.
iter
(
)
.
map
(
|
name
|
(
name
.
clone
(
)
0
)
)
.
collect
(
)
;
for
_
in
0
.
.
1000
{
let
selected_arm_name
=
relevancy_store
.
bandit_select
(
bandit
.
clone
(
)
&
arm_names
)
.
expect
(
"
Failed
to
select
arm
"
)
;
*
selection_counts
.
get_mut
(
&
selected_arm_name
)
.
unwrap
(
)
+
=
1
;
let
true_ctr
=
&
arms_to_ctr_map
[
&
selected_arm_name
]
;
let
clicked
=
rng
.
gen_bool
(
*
true_ctr
)
;
relevancy_store
.
bandit_update
(
bandit
.
clone
(
)
selected_arm_name
clicked
)
.
expect
(
"
Failed
to
update
beta
distribution
for
arm
"
)
;
}
let
most_selected_arm_name
=
selection_counts
.
iter
(
)
.
max_by_key
(
|
(
_
count
)
|
*
count
)
.
unwrap
(
)
.
0
;
assert_eq
!
(
most_selected_arm_name
"
weather
"
"
Thompson
Sampling
did
not
favor
the
best
-
performing
arm
"
)
;
}
#
[
test
]
fn
test_get_bandit_data
(
)
{
let
relevancy_store
=
setup_store
(
"
get_bandit_data
"
)
;
let
bandit
=
"
provider
"
.
to_string
(
)
;
let
arm
=
"
wiki
"
.
to_string
(
)
;
relevancy_store
.
bandit_init
(
"
provider
"
.
to_string
(
)
&
[
"
weather
"
.
to_string
(
)
"
fakespot
"
.
to_string
(
)
arm
.
clone
(
)
]
)
.
unwrap
(
)
;
relevancy_store
.
bandit_update
(
bandit
.
clone
(
)
arm
.
clone
(
)
true
)
.
expect
(
"
Failed
to
update
beta
distribution
for
arm
"
)
;
relevancy_store
.
bandit_update
(
bandit
.
clone
(
)
arm
.
clone
(
)
true
)
.
expect
(
"
Failed
to
update
beta
distribution
for
arm
"
)
;
let
bandit_data
=
relevancy_store
.
get_bandit_data
(
bandit
.
clone
(
)
arm
.
clone
(
)
)
.
unwrap
(
)
;
let
expected_bandit_data
=
BanditData
{
bandit
:
bandit
.
clone
(
)
arm
:
arm
.
clone
(
)
impressions
:
2
clicks
:
2
alpha
:
3
beta
:
1
}
;
assert_eq
!
(
bandit_data
expected_bandit_data
)
;
}
}
