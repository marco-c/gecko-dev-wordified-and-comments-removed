use
abi
:
:
{
self
Abi
}
;
use
ast
:
:
BareFnTy
;
use
ast
:
:
{
RegionTyParamBound
TraitTyParamBound
TraitBoundModifier
}
;
use
ast
:
:
Unsafety
;
use
ast
:
:
{
Mod
Arg
Arm
Attribute
BindingMode
TraitItemKind
}
;
use
ast
:
:
Block
;
use
ast
:
:
{
BlockCheckMode
CaptureBy
}
;
use
ast
:
:
{
Constness
Crate
}
;
use
ast
:
:
Defaultness
;
use
ast
:
:
EnumDef
;
use
ast
:
:
{
Expr
ExprKind
RangeLimits
}
;
use
ast
:
:
{
Field
FnDecl
}
;
use
ast
:
:
{
ForeignItem
ForeignItemKind
FunctionRetTy
}
;
use
ast
:
:
{
Ident
ImplItem
Item
ItemKind
}
;
use
ast
:
:
{
Lit
LitKind
UintTy
}
;
use
ast
:
:
Local
;
use
ast
:
:
MacStmtStyle
;
use
ast
:
:
Mac_
;
use
ast
:
:
{
MutTy
Mutability
}
;
use
ast
:
:
{
Pat
PatKind
}
;
use
ast
:
:
{
PolyTraitRef
QSelf
}
;
use
ast
:
:
{
Stmt
StmtKind
}
;
use
ast
:
:
{
VariantData
StructField
}
;
use
ast
:
:
StrStyle
;
use
ast
:
:
SelfKind
;
use
ast
:
:
{
TraitItem
TraitRef
}
;
use
ast
:
:
{
Ty
TyKind
TypeBinding
TyParam
TyParamBounds
}
;
use
ast
:
:
{
ViewPath
ViewPathGlob
ViewPathList
ViewPathSimple
}
;
use
ast
:
:
{
Visibility
WhereClause
}
;
use
ast
:
:
{
BinOpKind
UnOp
}
;
use
ast
;
use
codemap
:
:
{
self
CodeMap
Spanned
spanned
respan
}
;
use
syntax_pos
:
:
{
self
Span
BytePos
mk_sp
}
;
use
errors
:
:
{
self
DiagnosticBuilder
}
;
use
ext
:
:
tt
:
:
macro_parser
;
use
parse
;
use
parse
:
:
classify
;
use
parse
:
:
common
:
:
SeqSep
;
use
parse
:
:
lexer
:
:
{
Reader
TokenAndSpan
}
;
use
parse
:
:
obsolete
:
:
ObsoleteSyntax
;
use
parse
:
:
token
:
:
{
self
intern
keywords
MatchNt
SubstNt
InternedString
}
;
use
parse
:
:
{
new_sub_parser_from_file
ParseSess
}
;
use
util
:
:
parser
:
:
{
AssocOp
Fixity
}
;
use
print
:
:
pprust
;
use
ptr
:
:
P
;
use
parse
:
:
PResult
;
use
tokenstream
:
:
{
self
Delimited
SequenceRepetition
TokenTree
}
;
use
util
:
:
ThinVec
;
use
std
:
:
collections
:
:
HashSet
;
use
std
:
:
mem
;
use
std
:
:
path
:
:
{
Path
PathBuf
}
;
use
std
:
:
rc
:
:
Rc
;
use
std
:
:
slice
;
bitflags
!
{
pub
flags
Restrictions
:
u8
{
const
RESTRICTION_STMT_EXPR
=
1
<
<
0
const
RESTRICTION_NO_STRUCT_LITERAL
=
1
<
<
1
const
NO_NONINLINE_MOD
=
1
<
<
2
}
}
impl
Restrictions
{
pub
fn
restriction_stmt_expr
(
)
-
>
Self
{
RESTRICTION_STMT_EXPR
}
pub
fn
restriction_no_struct_literal
(
)
-
>
Self
{
RESTRICTION_NO_STRUCT_LITERAL
}
pub
fn
no_noninline_mod
(
)
-
>
Self
{
NO_NONINLINE_MOD
}
}
type
ItemInfo
=
(
Ident
ItemKind
Option
<
Vec
<
Attribute
>
>
)
;
#
[
derive
(
Copy
Clone
PartialEq
)
]
pub
enum
PathStyle
{
Mod
Type
Expr
}
#
[
derive
(
Copy
Clone
PartialEq
)
]
pub
enum
BoundParsingMode
{
Bare
Modified
}
#
[
derive
(
Clone
Copy
PartialEq
)
]
pub
enum
SemiColonMode
{
Break
Ignore
}
macro_rules
!
maybe_whole_expr
{
(
p
:
expr
)
=
>
{
if
let
token
:
:
Interpolated
(
nt
)
=
p
.
token
.
clone
(
)
{
match
*
nt
{
token
:
:
NtExpr
(
ref
e
)
=
>
{
p
.
bump
(
)
;
return
Ok
(
(
*
e
)
.
clone
(
)
)
;
}
token
:
:
NtPath
(
ref
path
)
=
>
{
p
.
bump
(
)
;
let
span
=
p
.
span
;
let
kind
=
ExprKind
:
:
Path
(
None
(
*
path
)
.
clone
(
)
)
;
return
Ok
(
p
.
mk_expr
(
span
.
lo
span
.
hi
kind
ThinVec
:
:
new
(
)
)
)
;
}
token
:
:
NtBlock
(
ref
block
)
=
>
{
p
.
bump
(
)
;
let
span
=
p
.
span
;
let
kind
=
ExprKind
:
:
Block
(
(
*
block
)
.
clone
(
)
)
;
return
Ok
(
p
.
mk_expr
(
span
.
lo
span
.
hi
kind
ThinVec
:
:
new
(
)
)
)
;
}
_
=
>
{
}
}
;
}
}
}
macro_rules
!
maybe_whole
{
(
p
:
expr
constructor
:
ident
|
x
:
ident
|
e
:
expr
)
=
>
{
if
let
token
:
:
Interpolated
(
nt
)
=
p
.
token
.
clone
(
)
{
if
let
token
:
:
constructor
(
x
)
=
(
*
nt
)
.
clone
(
)
{
p
.
bump
(
)
;
return
Ok
(
e
)
;
}
}
}
;
}
fn
maybe_append
(
mut
lhs
:
Vec
<
Attribute
>
rhs
:
Option
<
Vec
<
Attribute
>
>
)
-
>
Vec
<
Attribute
>
{
if
let
Some
(
ref
attrs
)
=
rhs
{
lhs
.
extend
(
attrs
.
iter
(
)
.
cloned
(
)
)
}
lhs
}
#
[
derive
(
PartialEq
)
]
enum
PrevTokenKind
{
DocComment
Comma
Interpolated
Eof
Other
}
#
[
derive
(
Default
)
]
struct
LookaheadBuffer
{
buffer
:
[
TokenAndSpan
;
LOOKAHEAD_BUFFER_CAPACITY
]
start
:
usize
end
:
usize
}
const
LOOKAHEAD_BUFFER_CAPACITY
:
usize
=
8
;
impl
LookaheadBuffer
{
fn
len
(
&
self
)
-
>
usize
{
(
LOOKAHEAD_BUFFER_CAPACITY
+
self
.
end
-
self
.
start
)
%
LOOKAHEAD_BUFFER_CAPACITY
}
}
pub
struct
Parser
<
'
a
>
{
pub
sess
:
&
'
a
ParseSess
pub
token
:
token
:
:
Token
pub
span
:
Span
pub
prev_span
:
Span
prev_token_kind
:
PrevTokenKind
lookahead_buffer
:
LookaheadBuffer
pub
tokens_consumed
:
usize
pub
restrictions
:
Restrictions
pub
quote_depth
:
usize
parsing_token_tree
:
bool
pub
reader
:
Box
<
Reader
+
'
a
>
pub
obsolete_set
:
HashSet
<
ObsoleteSyntax
>
pub
directory
:
PathBuf
pub
open_braces
:
Vec
<
(
token
:
:
DelimToken
Span
)
>
pub
owns_directory
:
bool
pub
root_module_name
:
Option
<
String
>
pub
expected_tokens
:
Vec
<
TokenType
>
pub
tts
:
Vec
<
(
TokenTree
usize
)
>
pub
desugar_doc_comments
:
bool
pub
allow_interpolated_tts
:
bool
}
#
[
derive
(
PartialEq
Eq
Clone
)
]
pub
enum
TokenType
{
Token
(
token
:
:
Token
)
Keyword
(
keywords
:
:
Keyword
)
Operator
}
impl
TokenType
{
fn
to_string
(
&
self
)
-
>
String
{
match
*
self
{
TokenType
:
:
Token
(
ref
t
)
=
>
format
!
(
"
{
}
"
Parser
:
:
token_to_string
(
t
)
)
TokenType
:
:
Operator
=
>
"
an
operator
"
.
to_string
(
)
TokenType
:
:
Keyword
(
kw
)
=
>
format
!
(
"
{
}
"
kw
.
name
(
)
)
}
}
}
fn
is_ident_or_underscore
(
t
:
&
token
:
:
Token
)
-
>
bool
{
t
.
is_ident
(
)
|
|
*
t
=
=
token
:
:
Underscore
}
pub
struct
ModulePath
{
pub
name
:
String
pub
path_exists
:
bool
pub
result
:
Result
<
ModulePathSuccess
ModulePathError
>
}
pub
struct
ModulePathSuccess
{
pub
path
:
:
:
std
:
:
path
:
:
PathBuf
pub
owns_directory
:
bool
}
pub
struct
ModulePathError
{
pub
err_msg
:
String
pub
help_msg
:
String
}
pub
enum
LhsExpr
{
NotYetParsed
AttributesParsed
(
ThinVec
<
Attribute
>
)
AlreadyParsed
(
P
<
Expr
>
)
}
impl
From
<
Option
<
ThinVec
<
Attribute
>
>
>
for
LhsExpr
{
fn
from
(
o
:
Option
<
ThinVec
<
Attribute
>
>
)
-
>
Self
{
if
let
Some
(
attrs
)
=
o
{
LhsExpr
:
:
AttributesParsed
(
attrs
)
}
else
{
LhsExpr
:
:
NotYetParsed
}
}
}
impl
From
<
P
<
Expr
>
>
for
LhsExpr
{
fn
from
(
expr
:
P
<
Expr
>
)
-
>
Self
{
LhsExpr
:
:
AlreadyParsed
(
expr
)
}
}
impl
<
'
a
>
Parser
<
'
a
>
{
pub
fn
new
(
sess
:
&
'
a
ParseSess
rdr
:
Box
<
Reader
+
'
a
>
)
-
>
Self
{
Parser
:
:
new_with_doc_flag
(
sess
rdr
false
)
}
pub
fn
new_with_doc_flag
(
sess
:
&
'
a
ParseSess
rdr
:
Box
<
Reader
+
'
a
>
desugar_doc_comments
:
bool
)
-
>
Self
{
let
mut
parser
=
Parser
{
reader
:
rdr
sess
:
sess
token
:
token
:
:
Underscore
span
:
syntax_pos
:
:
DUMMY_SP
prev_span
:
syntax_pos
:
:
DUMMY_SP
prev_token_kind
:
PrevTokenKind
:
:
Other
lookahead_buffer
:
Default
:
:
default
(
)
tokens_consumed
:
0
restrictions
:
Restrictions
:
:
empty
(
)
quote_depth
:
0
parsing_token_tree
:
false
obsolete_set
:
HashSet
:
:
new
(
)
directory
:
PathBuf
:
:
new
(
)
open_braces
:
Vec
:
:
new
(
)
owns_directory
:
true
root_module_name
:
None
expected_tokens
:
Vec
:
:
new
(
)
tts
:
Vec
:
:
new
(
)
desugar_doc_comments
:
desugar_doc_comments
allow_interpolated_tts
:
true
}
;
let
tok
=
parser
.
next_tok
(
)
;
parser
.
token
=
tok
.
tok
;
parser
.
span
=
tok
.
sp
;
if
parser
.
span
!
=
syntax_pos
:
:
DUMMY_SP
{
parser
.
directory
=
PathBuf
:
:
from
(
sess
.
codemap
(
)
.
span_to_filename
(
parser
.
span
)
)
;
parser
.
directory
.
pop
(
)
;
}
parser
}
fn
next_tok
(
&
mut
self
)
-
>
TokenAndSpan
{
'
outer
:
loop
{
let
mut
tok
=
if
let
Some
(
(
tts
i
)
)
=
self
.
tts
.
pop
(
)
{
let
tt
=
tts
.
get_tt
(
i
)
;
if
i
+
1
<
tts
.
len
(
)
{
self
.
tts
.
push
(
(
tts
i
+
1
)
)
;
}
if
let
TokenTree
:
:
Token
(
sp
tok
)
=
tt
{
TokenAndSpan
{
tok
:
tok
sp
:
sp
}
}
else
{
self
.
tts
.
push
(
(
tt
0
)
)
;
continue
}
}
else
{
self
.
reader
.
real_token
(
)
}
;
loop
{
let
nt
=
match
tok
.
tok
{
token
:
:
Interpolated
(
ref
nt
)
=
>
nt
.
clone
(
)
token
:
:
DocComment
(
name
)
if
self
.
desugar_doc_comments
=
>
{
self
.
tts
.
push
(
(
TokenTree
:
:
Token
(
tok
.
sp
token
:
:
DocComment
(
name
)
)
0
)
)
;
continue
'
outer
}
_
=
>
return
tok
}
;
match
*
nt
{
token
:
:
NtTT
(
TokenTree
:
:
Token
(
sp
ref
t
)
)
=
>
{
tok
=
TokenAndSpan
{
tok
:
t
.
clone
(
)
sp
:
sp
}
;
}
token
:
:
NtTT
(
ref
tt
)
=
>
{
self
.
tts
.
push
(
(
tt
.
clone
(
)
0
)
)
;
continue
'
outer
}
_
=
>
return
tok
}
}
}
}
pub
fn
token_to_string
(
token
:
&
token
:
:
Token
)
-
>
String
{
pprust
:
:
token_to_string
(
token
)
}
pub
fn
this_token_to_string
(
&
self
)
-
>
String
{
Parser
:
:
token_to_string
(
&
self
.
token
)
}
pub
fn
this_token_descr
(
&
self
)
-
>
String
{
let
s
=
self
.
this_token_to_string
(
)
;
if
self
.
token
.
is_strict_keyword
(
)
{
format
!
(
"
keyword
{
}
"
s
)
}
else
if
self
.
token
.
is_reserved_keyword
(
)
{
format
!
(
"
reserved
keyword
{
}
"
s
)
}
else
{
format
!
(
"
{
}
"
s
)
}
}
pub
fn
unexpected_last
<
T
>
(
&
self
t
:
&
token
:
:
Token
)
-
>
PResult
<
'
a
T
>
{
let
token_str
=
Parser
:
:
token_to_string
(
t
)
;
Err
(
self
.
span_fatal
(
self
.
prev_span
&
format
!
(
"
unexpected
token
:
{
}
"
token_str
)
)
)
}
pub
fn
unexpected
<
T
>
(
&
mut
self
)
-
>
PResult
<
'
a
T
>
{
match
self
.
expect_one_of
(
&
[
]
&
[
]
)
{
Err
(
e
)
=
>
Err
(
e
)
Ok
(
_
)
=
>
unreachable
!
(
)
}
}
pub
fn
expect
(
&
mut
self
t
:
&
token
:
:
Token
)
-
>
PResult
<
'
a
(
)
>
{
if
self
.
expected_tokens
.
is_empty
(
)
{
if
self
.
token
=
=
*
t
{
self
.
bump
(
)
;
Ok
(
(
)
)
}
else
{
let
token_str
=
Parser
:
:
token_to_string
(
t
)
;
let
this_token_str
=
self
.
this_token_to_string
(
)
;
Err
(
self
.
fatal
(
&
format
!
(
"
expected
{
}
found
{
}
"
token_str
this_token_str
)
)
)
}
}
else
{
self
.
expect_one_of
(
unsafe
{
slice
:
:
from_raw_parts
(
t
1
)
}
&
[
]
)
}
}
pub
fn
expect_one_of
(
&
mut
self
edible
:
&
[
token
:
:
Token
]
inedible
:
&
[
token
:
:
Token
]
)
-
>
PResult
<
'
a
(
)
>
{
fn
tokens_to_string
(
tokens
:
&
[
TokenType
]
)
-
>
String
{
let
mut
i
=
tokens
.
iter
(
)
;
let
b
=
i
.
next
(
)
.
map_or
(
"
"
.
to_string
(
)
|
t
|
t
.
to_string
(
)
)
;
i
.
enumerate
(
)
.
fold
(
b
|
mut
b
(
i
ref
a
)
|
{
if
tokens
.
len
(
)
>
2
&
&
i
=
=
tokens
.
len
(
)
-
2
{
b
.
push_str
(
"
or
"
)
;
}
else
if
tokens
.
len
(
)
=
=
2
&
&
i
=
=
tokens
.
len
(
)
-
2
{
b
.
push_str
(
"
or
"
)
;
}
else
{
b
.
push_str
(
"
"
)
;
}
b
.
push_str
(
&
a
.
to_string
(
)
)
;
b
}
)
}
if
edible
.
contains
(
&
self
.
token
)
{
self
.
bump
(
)
;
Ok
(
(
)
)
}
else
if
inedible
.
contains
(
&
self
.
token
)
{
Ok
(
(
)
)
}
else
{
let
mut
expected
=
edible
.
iter
(
)
.
map
(
|
x
|
TokenType
:
:
Token
(
x
.
clone
(
)
)
)
.
chain
(
inedible
.
iter
(
)
.
map
(
|
x
|
TokenType
:
:
Token
(
x
.
clone
(
)
)
)
)
.
chain
(
self
.
expected_tokens
.
iter
(
)
.
cloned
(
)
)
.
collect
:
:
<
Vec
<
_
>
>
(
)
;
expected
.
sort_by
(
|
a
b
|
a
.
to_string
(
)
.
cmp
(
&
b
.
to_string
(
)
)
)
;
expected
.
dedup
(
)
;
let
expect
=
tokens_to_string
(
&
expected
[
.
.
]
)
;
let
actual
=
self
.
this_token_to_string
(
)
;
Err
(
self
.
fatal
(
&
(
if
expected
.
len
(
)
>
1
{
(
format
!
(
"
expected
one
of
{
}
found
{
}
"
expect
actual
)
)
}
else
if
expected
.
is_empty
(
)
{
(
format
!
(
"
unexpected
token
:
{
}
"
actual
)
)
}
else
{
(
format
!
(
"
expected
{
}
found
{
}
"
expect
actual
)
)
}
)
[
.
.
]
)
)
}
}
fn
interpolated_or_expr_span
(
&
self
expr
:
PResult
<
'
a
P
<
Expr
>
>
)
-
>
PResult
<
'
a
(
Span
P
<
Expr
>
)
>
{
expr
.
map
(
|
e
|
{
if
self
.
prev_token_kind
=
=
PrevTokenKind
:
:
Interpolated
{
(
self
.
prev_span
e
)
}
else
{
(
e
.
span
e
)
}
}
)
}
pub
fn
parse_ident
(
&
mut
self
)
-
>
PResult
<
'
a
ast
:
:
Ident
>
{
self
.
check_strict_keywords
(
)
;
self
.
check_reserved_keywords
(
)
;
match
self
.
token
{
token
:
:
Ident
(
i
)
=
>
{
self
.
bump
(
)
;
Ok
(
i
)
}
_
=
>
{
Err
(
if
self
.
prev_token_kind
=
=
PrevTokenKind
:
:
DocComment
{
self
.
span_fatal_help
(
self
.
prev_span
"
found
a
documentation
comment
that
doesn
'
t
document
anything
"
"
doc
comments
must
come
before
what
they
document
maybe
a
comment
was
\
intended
with
/
/
?
"
)
}
else
{
let
mut
err
=
self
.
fatal
(
&
format
!
(
"
expected
identifier
found
{
}
"
self
.
this_token_to_string
(
)
)
)
;
if
self
.
token
=
=
token
:
:
Underscore
{
err
.
note
(
"
_
is
a
wildcard
pattern
not
an
identifier
"
)
;
}
err
}
)
}
}
}
pub
fn
check
(
&
mut
self
tok
:
&
token
:
:
Token
)
-
>
bool
{
let
is_present
=
self
.
token
=
=
*
tok
;
if
!
is_present
{
self
.
expected_tokens
.
push
(
TokenType
:
:
Token
(
tok
.
clone
(
)
)
)
;
}
is_present
}
pub
fn
eat
(
&
mut
self
tok
:
&
token
:
:
Token
)
-
>
bool
{
let
is_present
=
self
.
check
(
tok
)
;
if
is_present
{
self
.
bump
(
)
}
is_present
}
pub
fn
check_keyword
(
&
mut
self
kw
:
keywords
:
:
Keyword
)
-
>
bool
{
self
.
expected_tokens
.
push
(
TokenType
:
:
Keyword
(
kw
)
)
;
self
.
token
.
is_keyword
(
kw
)
}
pub
fn
eat_keyword
(
&
mut
self
kw
:
keywords
:
:
Keyword
)
-
>
bool
{
if
self
.
check_keyword
(
kw
)
{
self
.
bump
(
)
;
true
}
else
{
false
}
}
pub
fn
eat_keyword_noexpect
(
&
mut
self
kw
:
keywords
:
:
Keyword
)
-
>
bool
{
if
self
.
token
.
is_keyword
(
kw
)
{
self
.
bump
(
)
;
true
}
else
{
false
}
}
pub
fn
check_contextual_keyword
(
&
mut
self
ident
:
Ident
)
-
>
bool
{
self
.
expected_tokens
.
push
(
TokenType
:
:
Token
(
token
:
:
Ident
(
ident
)
)
)
;
if
let
token
:
:
Ident
(
ref
cur_ident
)
=
self
.
token
{
cur_ident
.
name
=
=
ident
.
name
}
else
{
false
}
}
pub
fn
eat_contextual_keyword
(
&
mut
self
ident
:
Ident
)
-
>
bool
{
if
self
.
check_contextual_keyword
(
ident
)
{
self
.
bump
(
)
;
true
}
else
{
false
}
}
pub
fn
expect_keyword
(
&
mut
self
kw
:
keywords
:
:
Keyword
)
-
>
PResult
<
'
a
(
)
>
{
if
!
self
.
eat_keyword
(
kw
)
{
self
.
unexpected
(
)
}
else
{
Ok
(
(
)
)
}
}
pub
fn
check_strict_keywords
(
&
mut
self
)
{
if
self
.
token
.
is_strict_keyword
(
)
{
let
token_str
=
self
.
this_token_to_string
(
)
;
let
span
=
self
.
span
;
self
.
span_err
(
span
&
format
!
(
"
expected
identifier
found
keyword
{
}
"
token_str
)
)
;
}
}
pub
fn
check_reserved_keywords
(
&
mut
self
)
{
if
self
.
token
.
is_reserved_keyword
(
)
{
let
token_str
=
self
.
this_token_to_string
(
)
;
self
.
fatal
(
&
format
!
(
"
{
}
is
a
reserved
keyword
"
token_str
)
)
.
emit
(
)
}
}
fn
expect_and
(
&
mut
self
)
-
>
PResult
<
'
a
(
)
>
{
self
.
expected_tokens
.
push
(
TokenType
:
:
Token
(
token
:
:
BinOp
(
token
:
:
And
)
)
)
;
match
self
.
token
{
token
:
:
BinOp
(
token
:
:
And
)
=
>
{
self
.
bump
(
)
;
Ok
(
(
)
)
}
token
:
:
AndAnd
=
>
{
let
span
=
self
.
span
;
let
lo
=
span
.
lo
+
BytePos
(
1
)
;
Ok
(
self
.
bump_with
(
token
:
:
BinOp
(
token
:
:
And
)
lo
span
.
hi
)
)
}
_
=
>
self
.
unexpected
(
)
}
}
pub
fn
expect_no_suffix
(
&
self
sp
:
Span
kind
:
&
str
suffix
:
Option
<
ast
:
:
Name
>
)
{
match
suffix
{
None
=
>
{
}
Some
(
suf
)
=
>
{
let
text
=
suf
.
as_str
(
)
;
if
text
.
is_empty
(
)
{
self
.
span_bug
(
sp
"
found
empty
literal
suffix
in
Some
"
)
}
self
.
span_err
(
sp
&
format
!
(
"
{
}
with
a
suffix
is
invalid
"
kind
)
)
;
}
}
}
fn
eat_lt
(
&
mut
self
)
-
>
bool
{
self
.
expected_tokens
.
push
(
TokenType
:
:
Token
(
token
:
:
Lt
)
)
;
match
self
.
token
{
token
:
:
Lt
=
>
{
self
.
bump
(
)
;
true
}
token
:
:
BinOp
(
token
:
:
Shl
)
=
>
{
let
span
=
self
.
span
;
let
lo
=
span
.
lo
+
BytePos
(
1
)
;
self
.
bump_with
(
token
:
:
Lt
lo
span
.
hi
)
;
true
}
_
=
>
false
}
}
fn
expect_lt
(
&
mut
self
)
-
>
PResult
<
'
a
(
)
>
{
if
!
self
.
eat_lt
(
)
{
self
.
unexpected
(
)
}
else
{
Ok
(
(
)
)
}
}
pub
fn
expect_gt
(
&
mut
self
)
-
>
PResult
<
'
a
(
)
>
{
self
.
expected_tokens
.
push
(
TokenType
:
:
Token
(
token
:
:
Gt
)
)
;
match
self
.
token
{
token
:
:
Gt
=
>
{
self
.
bump
(
)
;
Ok
(
(
)
)
}
token
:
:
BinOp
(
token
:
:
Shr
)
=
>
{
let
span
=
self
.
span
;
let
lo
=
span
.
lo
+
BytePos
(
1
)
;
Ok
(
self
.
bump_with
(
token
:
:
Gt
lo
span
.
hi
)
)
}
token
:
:
BinOpEq
(
token
:
:
Shr
)
=
>
{
let
span
=
self
.
span
;
let
lo
=
span
.
lo
+
BytePos
(
1
)
;
Ok
(
self
.
bump_with
(
token
:
:
Ge
lo
span
.
hi
)
)
}
token
:
:
Ge
=
>
{
let
span
=
self
.
span
;
let
lo
=
span
.
lo
+
BytePos
(
1
)
;
Ok
(
self
.
bump_with
(
token
:
:
Eq
lo
span
.
hi
)
)
}
_
=
>
{
let
gt_str
=
Parser
:
:
token_to_string
(
&
token
:
:
Gt
)
;
let
this_token_str
=
self
.
this_token_to_string
(
)
;
Err
(
self
.
fatal
(
&
format
!
(
"
expected
{
}
found
{
}
"
gt_str
this_token_str
)
)
)
}
}
}
pub
fn
parse_seq_to_before_gt_or_return
<
T
F
>
(
&
mut
self
sep
:
Option
<
token
:
:
Token
>
mut
f
:
F
)
-
>
PResult
<
'
a
(
P
<
[
T
]
>
bool
)
>
where
F
:
FnMut
(
&
mut
Parser
<
'
a
>
)
-
>
PResult
<
'
a
Option
<
T
>
>
{
let
mut
v
=
Vec
:
:
new
(
)
;
for
i
in
0
.
.
{
if
self
.
check
(
&
token
:
:
Gt
)
|
|
self
.
token
=
=
token
:
:
BinOp
(
token
:
:
Shr
)
|
|
self
.
token
=
=
token
:
:
Ge
|
|
self
.
token
=
=
token
:
:
BinOpEq
(
token
:
:
Shr
)
{
break
;
}
if
i
%
2
=
=
0
{
match
try
!
(
f
(
self
)
)
{
Some
(
result
)
=
>
v
.
push
(
result
)
None
=
>
return
Ok
(
(
P
:
:
from_vec
(
v
)
true
)
)
}
}
else
{
if
let
Some
(
t
)
=
sep
.
as_ref
(
)
{
try
!
(
self
.
expect
(
t
)
)
;
}
}
}
return
Ok
(
(
P
:
:
from_vec
(
v
)
false
)
)
;
}
pub
fn
parse_seq_to_before_gt
<
T
F
>
(
&
mut
self
sep
:
Option
<
token
:
:
Token
>
mut
f
:
F
)
-
>
PResult
<
'
a
P
<
[
T
]
>
>
where
F
:
FnMut
(
&
mut
Parser
<
'
a
>
)
-
>
PResult
<
'
a
T
>
{
let
(
result
returned
)
=
try
!
(
self
.
parse_seq_to_before_gt_or_return
(
sep
|
p
|
Ok
(
Some
(
try
!
(
f
(
p
)
)
)
)
)
)
;
assert
!
(
!
returned
)
;
return
Ok
(
result
)
;
}
pub
fn
parse_seq_to_gt
<
T
F
>
(
&
mut
self
sep
:
Option
<
token
:
:
Token
>
f
:
F
)
-
>
PResult
<
'
a
P
<
[
T
]
>
>
where
F
:
FnMut
(
&
mut
Parser
<
'
a
>
)
-
>
PResult
<
'
a
T
>
{
let
v
=
try
!
(
self
.
parse_seq_to_before_gt
(
sep
f
)
)
;
try
!
(
self
.
expect_gt
(
)
)
;
return
Ok
(
v
)
;
}
pub
fn
parse_seq_to_gt_or_return
<
T
F
>
(
&
mut
self
sep
:
Option
<
token
:
:
Token
>
f
:
F
)
-
>
PResult
<
'
a
(
P
<
[
T
]
>
bool
)
>
where
F
:
FnMut
(
&
mut
Parser
<
'
a
>
)
-
>
PResult
<
'
a
Option
<
T
>
>
{
let
(
v
returned
)
=
try
!
(
self
.
parse_seq_to_before_gt_or_return
(
sep
f
)
)
;
if
!
returned
{
try
!
(
self
.
expect_gt
(
)
)
;
}
return
Ok
(
(
v
returned
)
)
;
}
pub
fn
eat_to_tokens
(
&
mut
self
kets
:
&
[
&
token
:
:
Token
]
)
{
let
handler
=
self
.
diagnostic
(
)
;
self
.
parse_seq_to_before_tokens
(
kets
SeqSep
:
:
none
(
)
|
p
|
p
.
parse_token_tree
(
)
|
mut
e
|
handler
.
cancel
(
&
mut
e
)
)
;
}
pub
fn
parse_seq_to_end
<
T
F
>
(
&
mut
self
ket
:
&
token
:
:
Token
sep
:
SeqSep
f
:
F
)
-
>
PResult
<
'
a
Vec
<
T
>
>
where
F
:
FnMut
(
&
mut
Parser
<
'
a
>
)
-
>
PResult
<
'
a
T
>
{
let
val
=
self
.
parse_seq_to_before_end
(
ket
sep
f
)
;
self
.
bump
(
)
;
Ok
(
val
)
}
pub
fn
parse_seq_to_before_end
<
T
F
>
(
&
mut
self
ket
:
&
token
:
:
Token
sep
:
SeqSep
f
:
F
)
-
>
Vec
<
T
>
where
F
:
FnMut
(
&
mut
Parser
<
'
a
>
)
-
>
PResult
<
'
a
T
>
{
self
.
parse_seq_to_before_tokens
(
&
[
ket
]
sep
f
|
mut
e
|
e
.
emit
(
)
)
}
fn
parse_seq_to_before_tokens
<
T
F
Fe
>
(
&
mut
self
kets
:
&
[
&
token
:
:
Token
]
sep
:
SeqSep
mut
f
:
F
mut
fe
:
Fe
)
-
>
Vec
<
T
>
where
F
:
FnMut
(
&
mut
Parser
<
'
a
>
)
-
>
PResult
<
'
a
T
>
Fe
:
FnMut
(
DiagnosticBuilder
)
{
let
mut
first
:
bool
=
true
;
let
mut
v
=
vec
!
[
]
;
while
!
kets
.
contains
(
&
&
self
.
token
)
{
match
sep
.
sep
{
Some
(
ref
t
)
=
>
{
if
first
{
first
=
false
;
}
else
{
if
let
Err
(
e
)
=
self
.
expect
(
t
)
{
fe
(
e
)
;
break
;
}
}
}
_
=
>
(
)
}
if
sep
.
trailing_sep_allowed
&
&
kets
.
iter
(
)
.
any
(
|
k
|
self
.
check
(
k
)
)
{
break
;
}
match
f
(
self
)
{
Ok
(
t
)
=
>
v
.
push
(
t
)
Err
(
e
)
=
>
{
fe
(
e
)
;
break
;
}
}
}
v
}
pub
fn
parse_unspanned_seq
<
T
F
>
(
&
mut
self
bra
:
&
token
:
:
Token
ket
:
&
token
:
:
Token
sep
:
SeqSep
f
:
F
)
-
>
PResult
<
'
a
Vec
<
T
>
>
where
F
:
FnMut
(
&
mut
Parser
<
'
a
>
)
-
>
PResult
<
'
a
T
>
{
try
!
(
self
.
expect
(
bra
)
)
;
let
result
=
self
.
parse_seq_to_before_end
(
ket
sep
f
)
;
if
self
.
token
=
=
*
ket
{
self
.
bump
(
)
;
}
Ok
(
result
)
}
pub
fn
parse_seq
<
T
F
>
(
&
mut
self
bra
:
&
token
:
:
Token
ket
:
&
token
:
:
Token
sep
:
SeqSep
f
:
F
)
-
>
PResult
<
'
a
Spanned
<
Vec
<
T
>
>
>
where
F
:
FnMut
(
&
mut
Parser
<
'
a
>
)
-
>
PResult
<
'
a
T
>
{
let
lo
=
self
.
span
.
lo
;
try
!
(
self
.
expect
(
bra
)
)
;
let
result
=
self
.
parse_seq_to_before_end
(
ket
sep
f
)
;
let
hi
=
self
.
span
.
hi
;
self
.
bump
(
)
;
Ok
(
spanned
(
lo
hi
result
)
)
}
pub
fn
bump
(
&
mut
self
)
{
if
self
.
prev_token_kind
=
=
PrevTokenKind
:
:
Eof
{
self
.
bug
(
"
attempted
to
bump
the
parser
past
EOF
(
may
be
stuck
in
a
loop
)
"
)
;
}
self
.
prev_span
=
self
.
span
;
self
.
prev_token_kind
=
match
self
.
token
{
token
:
:
DocComment
(
.
.
)
=
>
PrevTokenKind
:
:
DocComment
token
:
:
Comma
=
>
PrevTokenKind
:
:
Comma
token
:
:
Interpolated
(
.
.
)
=
>
PrevTokenKind
:
:
Interpolated
token
:
:
Eof
=
>
PrevTokenKind
:
:
Eof
_
=
>
PrevTokenKind
:
:
Other
}
;
let
next
=
if
self
.
lookahead_buffer
.
start
=
=
self
.
lookahead_buffer
.
end
{
self
.
next_tok
(
)
}
else
{
let
old_start
=
self
.
lookahead_buffer
.
start
;
self
.
lookahead_buffer
.
start
=
(
old_start
+
1
)
%
LOOKAHEAD_BUFFER_CAPACITY
;
mem
:
:
replace
(
&
mut
self
.
lookahead_buffer
.
buffer
[
old_start
]
Default
:
:
default
(
)
)
}
;
self
.
span
=
next
.
sp
;
self
.
token
=
next
.
tok
;
self
.
tokens_consumed
+
=
1
;
self
.
expected_tokens
.
clear
(
)
;
self
.
check_unknown_macro_variable
(
)
;
}
pub
fn
bump_and_get
(
&
mut
self
)
-
>
token
:
:
Token
{
let
old_token
=
mem
:
:
replace
(
&
mut
self
.
token
token
:
:
Underscore
)
;
self
.
bump
(
)
;
old_token
}
pub
fn
bump_with
(
&
mut
self
next
:
token
:
:
Token
lo
:
BytePos
hi
:
BytePos
)
{
self
.
prev_span
=
mk_sp
(
self
.
span
.
lo
lo
)
;
self
.
prev_token_kind
=
PrevTokenKind
:
:
Other
;
self
.
span
=
mk_sp
(
lo
hi
)
;
self
.
token
=
next
;
self
.
expected_tokens
.
clear
(
)
;
}
pub
fn
look_ahead
<
R
F
>
(
&
mut
self
dist
:
usize
f
:
F
)
-
>
R
where
F
:
FnOnce
(
&
token
:
:
Token
)
-
>
R
{
if
dist
=
=
0
{
f
(
&
self
.
token
)
}
else
if
dist
<
LOOKAHEAD_BUFFER_CAPACITY
{
while
self
.
lookahead_buffer
.
len
(
)
<
dist
{
self
.
lookahead_buffer
.
buffer
[
self
.
lookahead_buffer
.
end
]
=
self
.
next_tok
(
)
;
self
.
lookahead_buffer
.
end
=
(
self
.
lookahead_buffer
.
end
+
1
)
%
LOOKAHEAD_BUFFER_CAPACITY
;
}
let
index
=
(
self
.
lookahead_buffer
.
start
+
dist
-
1
)
%
LOOKAHEAD_BUFFER_CAPACITY
;
f
(
&
self
.
lookahead_buffer
.
buffer
[
index
]
.
tok
)
}
else
{
self
.
bug
(
"
lookahead
distance
is
too
large
"
)
;
}
}
pub
fn
fatal
(
&
self
m
:
&
str
)
-
>
DiagnosticBuilder
<
'
a
>
{
self
.
sess
.
span_diagnostic
.
struct_span_fatal
(
self
.
span
m
)
}
pub
fn
span_fatal
(
&
self
sp
:
Span
m
:
&
str
)
-
>
DiagnosticBuilder
<
'
a
>
{
self
.
sess
.
span_diagnostic
.
struct_span_fatal
(
sp
m
)
}
pub
fn
span_fatal_help
(
&
self
sp
:
Span
m
:
&
str
help
:
&
str
)
-
>
DiagnosticBuilder
<
'
a
>
{
let
mut
err
=
self
.
sess
.
span_diagnostic
.
struct_span_fatal
(
sp
m
)
;
err
.
help
(
help
)
;
err
}
pub
fn
bug
(
&
self
m
:
&
str
)
-
>
!
{
self
.
sess
.
span_diagnostic
.
span_bug
(
self
.
span
m
)
}
pub
fn
warn
(
&
self
m
:
&
str
)
{
self
.
sess
.
span_diagnostic
.
span_warn
(
self
.
span
m
)
}
pub
fn
span_warn
(
&
self
sp
:
Span
m
:
&
str
)
{
self
.
sess
.
span_diagnostic
.
span_warn
(
sp
m
)
}
pub
fn
span_err
(
&
self
sp
:
Span
m
:
&
str
)
{
self
.
sess
.
span_diagnostic
.
span_err
(
sp
m
)
}
pub
fn
span_err_help
(
&
self
sp
:
Span
m
:
&
str
h
:
&
str
)
{
let
mut
err
=
self
.
sess
.
span_diagnostic
.
mut_span_err
(
sp
m
)
;
err
.
help
(
h
)
;
err
.
emit
(
)
;
}
pub
fn
span_bug
(
&
self
sp
:
Span
m
:
&
str
)
-
>
!
{
self
.
sess
.
span_diagnostic
.
span_bug
(
sp
m
)
}
pub
fn
abort_if_errors
(
&
self
)
{
self
.
sess
.
span_diagnostic
.
abort_if_errors
(
)
;
}
fn
cancel
(
&
self
err
:
&
mut
DiagnosticBuilder
)
{
self
.
sess
.
span_diagnostic
.
cancel
(
err
)
}
pub
fn
diagnostic
(
&
self
)
-
>
&
'
a
errors
:
:
Handler
{
&
self
.
sess
.
span_diagnostic
}
pub
fn
id_to_interned_str
(
&
mut
self
id
:
Ident
)
-
>
InternedString
{
id
.
name
.
as_str
(
)
}
pub
fn
token_is_bare_fn_keyword
(
&
mut
self
)
-
>
bool
{
self
.
check_keyword
(
keywords
:
:
Fn
)
|
|
self
.
check_keyword
(
keywords
:
:
Unsafe
)
|
|
self
.
check_keyword
(
keywords
:
:
Extern
)
}
pub
fn
get_lifetime
(
&
mut
self
)
-
>
ast
:
:
Ident
{
match
self
.
token
{
token
:
:
Lifetime
(
ref
ident
)
=
>
*
ident
_
=
>
self
.
bug
(
"
not
a
lifetime
"
)
}
}
pub
fn
parse_for_in_type
(
&
mut
self
)
-
>
PResult
<
'
a
TyKind
>
{
let
lo
=
self
.
span
.
lo
;
let
lifetime_defs
=
try
!
(
self
.
parse_late_bound_lifetime_defs
(
)
)
;
if
self
.
token_is_bare_fn_keyword
(
)
{
self
.
parse_ty_bare_fn
(
lifetime_defs
)
}
else
{
let
hi
=
self
.
span
.
hi
;
let
trait_ref
=
try
!
(
self
.
parse_trait_ref
(
)
)
;
let
poly_trait_ref
=
ast
:
:
PolyTraitRef
{
bound_lifetimes
:
lifetime_defs
trait_ref
:
trait_ref
span
:
mk_sp
(
lo
hi
)
}
;
let
other_bounds
=
if
self
.
eat
(
&
token
:
:
BinOp
(
token
:
:
Plus
)
)
{
try
!
(
self
.
parse_ty_param_bounds
(
BoundParsingMode
:
:
Bare
)
)
}
else
{
P
:
:
new
(
)
}
;
let
all_bounds
=
Some
(
TraitTyParamBound
(
poly_trait_ref
TraitBoundModifier
:
:
None
)
)
.
into_iter
(
)
.
chain
(
other_bounds
.
into_vec
(
)
)
.
collect
(
)
;
Ok
(
ast
:
:
TyKind
:
:
PolyTraitRef
(
all_bounds
)
)
}
}
pub
fn
parse_impl_trait_type
(
&
mut
self
)
-
>
PResult
<
'
a
TyKind
>
{
let
bounds
=
try
!
(
self
.
parse_ty_param_bounds
(
BoundParsingMode
:
:
Modified
)
)
;
if
!
bounds
.
iter
(
)
.
any
(
|
b
|
if
let
TraitTyParamBound
(
.
.
)
=
*
b
{
true
}
else
{
false
}
)
{
self
.
span_err
(
self
.
prev_span
"
at
least
one
trait
must
be
specified
"
)
;
}
Ok
(
ast
:
:
TyKind
:
:
ImplTrait
(
bounds
)
)
}
pub
fn
parse_ty_path
(
&
mut
self
)
-
>
PResult
<
'
a
TyKind
>
{
Ok
(
TyKind
:
:
Path
(
None
try
!
(
self
.
parse_path
(
PathStyle
:
:
Type
)
)
)
)
}
pub
fn
parse_ty_bare_fn
(
&
mut
self
lifetime_defs
:
Vec
<
ast
:
:
LifetimeDef
>
)
-
>
PResult
<
'
a
TyKind
>
{
let
unsafety
=
try
!
(
self
.
parse_unsafety
(
)
)
;
let
abi
=
if
self
.
eat_keyword
(
keywords
:
:
Extern
)
{
try
!
(
self
.
parse_opt_abi
(
)
)
.
unwrap_or
(
Abi
:
:
C
)
}
else
{
Abi
:
:
Rust
}
;
try
!
(
self
.
expect_keyword
(
keywords
:
:
Fn
)
)
;
let
(
inputs
variadic
)
=
try
!
(
self
.
parse_fn_args
(
false
true
)
)
;
let
ret_ty
=
try
!
(
self
.
parse_ret_ty
(
)
)
;
let
decl
=
P
(
FnDecl
{
inputs
:
inputs
output
:
ret_ty
variadic
:
variadic
}
)
;
Ok
(
TyKind
:
:
BareFn
(
P
(
BareFnTy
{
abi
:
abi
unsafety
:
unsafety
lifetimes
:
lifetime_defs
decl
:
decl
}
)
)
)
}
pub
fn
parse_unsafety
(
&
mut
self
)
-
>
PResult
<
'
a
Unsafety
>
{
if
self
.
eat_keyword
(
keywords
:
:
Unsafe
)
{
return
Ok
(
Unsafety
:
:
Unsafe
)
;
}
else
{
return
Ok
(
Unsafety
:
:
Normal
)
;
}
}
pub
fn
parse_trait_item
(
&
mut
self
)
-
>
PResult
<
'
a
TraitItem
>
{
maybe_whole
!
(
self
NtTraitItem
|
x
|
x
)
;
let
mut
attrs
=
try
!
(
self
.
parse_outer_attributes
(
)
)
;
let
lo
=
self
.
span
.
lo
;
let
(
name
node
)
=
if
self
.
eat_keyword
(
keywords
:
:
Type
)
{
let
TyParam
{
ident
bounds
default
.
.
}
=
try
!
(
self
.
parse_ty_param
(
vec
!
[
]
)
)
;
try
!
(
self
.
expect
(
&
token
:
:
Semi
)
)
;
(
ident
TraitItemKind
:
:
Type
(
bounds
default
)
)
}
else
if
self
.
is_const_item
(
)
{
try
!
(
self
.
expect_keyword
(
keywords
:
:
Const
)
)
;
let
ident
=
try
!
(
self
.
parse_ident
(
)
)
;
try
!
(
self
.
expect
(
&
token
:
:
Colon
)
)
;
let
ty
=
try
!
(
self
.
parse_ty_sum
(
)
)
;
let
default
=
if
self
.
check
(
&
token
:
:
Eq
)
{
self
.
bump
(
)
;
let
expr
=
try
!
(
self
.
parse_expr
(
)
)
;
try
!
(
self
.
expect
(
&
token
:
:
Semi
)
)
;
Some
(
expr
)
}
else
{
try
!
(
self
.
expect
(
&
token
:
:
Semi
)
)
;
None
}
;
(
ident
TraitItemKind
:
:
Const
(
ty
default
)
)
}
else
if
self
.
token
.
is_path_start
(
)
{
let
lo
=
self
.
span
.
lo
;
let
pth
=
try
!
(
self
.
parse_path
(
PathStyle
:
:
Mod
)
)
;
try
!
(
self
.
expect
(
&
token
:
:
Not
)
)
;
let
delim
=
try
!
(
self
.
expect_open_delim
(
)
)
;
let
tts
=
try
!
(
self
.
parse_seq_to_end
(
&
token
:
:
CloseDelim
(
delim
)
SeqSep
:
:
none
(
)
|
pp
|
pp
.
parse_token_tree
(
)
)
)
;
if
delim
!
=
token
:
:
Brace
{
try
!
(
self
.
expect
(
&
token
:
:
Semi
)
)
}
let
mac
=
spanned
(
lo
self
.
prev_span
.
hi
Mac_
{
path
:
pth
tts
:
tts
}
)
;
(
keywords
:
:
Invalid
.
ident
(
)
ast
:
:
TraitItemKind
:
:
Macro
(
mac
)
)
}
else
{
let
(
constness
unsafety
abi
)
=
match
self
.
parse_fn_front_matter
(
)
{
Ok
(
cua
)
=
>
cua
Err
(
e
)
=
>
{
loop
{
match
self
.
token
{
token
:
:
Eof
=
>
break
token
:
:
CloseDelim
(
token
:
:
Brace
)
|
token
:
:
Semi
=
>
{
self
.
bump
(
)
;
break
;
}
token
:
:
OpenDelim
(
token
:
:
Brace
)
=
>
{
try
!
(
self
.
parse_token_tree
(
)
)
;
break
;
}
_
=
>
self
.
bump
(
)
}
}
return
Err
(
e
)
;
}
}
;
let
ident
=
try
!
(
self
.
parse_ident
(
)
)
;
let
mut
generics
=
try
!
(
self
.
parse_generics
(
)
)
;
let
d
=
try
!
(
self
.
parse_fn_decl_with_self
(
|
p
:
&
mut
Parser
<
'
a
>
|
{
/
/
This
is
somewhat
dubious
;
We
don
'
t
want
to
allow
/
/
argument
names
to
be
left
off
if
there
is
a
/
/
definition
.
.
.
p
.
parse_arg_general
(
false
)
}
)
)
;
generics
.
where_clause
=
try
!
(
self
.
parse_where_clause
(
)
)
;
let
sig
=
ast
:
:
MethodSig
{
unsafety
:
unsafety
constness
:
constness
decl
:
d
generics
:
generics
abi
:
abi
}
;
let
body
=
match
self
.
token
{
token
:
:
Semi
=
>
{
self
.
bump
(
)
;
debug
!
(
"
parse_trait_methods
(
)
:
parsing
required
method
"
)
;
None
}
token
:
:
OpenDelim
(
token
:
:
Brace
)
=
>
{
debug
!
(
"
parse_trait_methods
(
)
:
parsing
provided
method
"
)
;
let
(
inner_attrs
body
)
=
try
!
(
self
.
parse_inner_attrs_and_block
(
)
)
;
attrs
.
extend
(
inner_attrs
.
iter
(
)
.
cloned
(
)
)
;
Some
(
body
)
}
_
=
>
{
let
token_str
=
self
.
this_token_to_string
(
)
;
return
Err
(
self
.
fatal
(
&
format
!
(
"
expected
;
or
{
{
found
{
}
"
token_str
)
)
)
;
}
}
;
(
ident
ast
:
:
TraitItemKind
:
:
Method
(
sig
body
)
)
}
;
Ok
(
TraitItem
{
id
:
ast
:
:
DUMMY_NODE_ID
ident
:
name
attrs
:
attrs
node
:
node
span
:
mk_sp
(
lo
self
.
prev_span
.
hi
)
}
)
}
pub
fn
parse_trait_items
(
&
mut
self
)
-
>
PResult
<
'
a
Vec
<
TraitItem
>
>
{
self
.
parse_unspanned_seq
(
&
token
:
:
OpenDelim
(
token
:
:
Brace
)
&
token
:
:
CloseDelim
(
token
:
:
Brace
)
SeqSep
:
:
none
(
)
|
p
|
-
>
PResult
<
'
a
TraitItem
>
{
p
.
parse_trait_item
(
)
}
)
}
pub
fn
parse_mt
(
&
mut
self
)
-
>
PResult
<
'
a
MutTy
>
{
let
mutbl
=
try
!
(
self
.
parse_mutability
(
)
)
;
let
t
=
try
!
(
self
.
parse_ty
(
)
)
;
Ok
(
MutTy
{
ty
:
t
mutbl
:
mutbl
}
)
}
pub
fn
parse_ret_ty
(
&
mut
self
)
-
>
PResult
<
'
a
FunctionRetTy
>
{
if
self
.
eat
(
&
token
:
:
RArrow
)
{
Ok
(
FunctionRetTy
:
:
Ty
(
try
!
(
self
.
parse_ty
(
)
)
)
)
}
else
{
let
pos
=
self
.
span
.
lo
;
Ok
(
FunctionRetTy
:
:
Default
(
mk_sp
(
pos
pos
)
)
)
}
}
pub
fn
parse_ty_sum
(
&
mut
self
)
-
>
PResult
<
'
a
P
<
Ty
>
>
{
let
lo
=
self
.
span
.
lo
;
let
lhs
=
try
!
(
self
.
parse_ty
(
)
)
;
if
!
self
.
eat
(
&
token
:
:
BinOp
(
token
:
:
Plus
)
)
{
return
Ok
(
lhs
)
;
}
let
bounds
=
try
!
(
self
.
parse_ty_param_bounds
(
BoundParsingMode
:
:
Bare
)
)
;
if
bounds
.
is_empty
(
)
{
let
prev_span
=
self
.
prev_span
;
self
.
span_err
(
prev_span
"
at
least
one
type
parameter
bound
\
must
be
specified
"
)
;
}
let
sp
=
mk_sp
(
lo
self
.
prev_span
.
hi
)
;
let
sum
=
ast
:
:
TyKind
:
:
ObjectSum
(
lhs
bounds
)
;
Ok
(
P
(
Ty
{
id
:
ast
:
:
DUMMY_NODE_ID
node
:
sum
span
:
sp
}
)
)
}
pub
fn
parse_ty
(
&
mut
self
)
-
>
PResult
<
'
a
P
<
Ty
>
>
{
maybe_whole
!
(
self
NtTy
|
x
|
x
)
;
let
lo
=
self
.
span
.
lo
;
let
t
=
if
self
.
check
(
&
token
:
:
OpenDelim
(
token
:
:
Paren
)
)
{
self
.
bump
(
)
;
let
mut
ts
=
vec
!
[
]
;
let
mut
last_comma
=
false
;
while
self
.
token
!
=
token
:
:
CloseDelim
(
token
:
:
Paren
)
{
ts
.
push
(
try
!
(
self
.
parse_ty_sum
(
)
)
)
;
if
self
.
check
(
&
token
:
:
Comma
)
{
last_comma
=
true
;
self
.
bump
(
)
;
}
else
{
last_comma
=
false
;
break
;
}
}
try
!
(
self
.
expect
(
&
token
:
:
CloseDelim
(
token
:
:
Paren
)
)
)
;
if
ts
.
len
(
)
=
=
1
&
&
!
last_comma
{
TyKind
:
:
Paren
(
ts
.
into_iter
(
)
.
nth
(
0
)
.
unwrap
(
)
)
}
else
{
TyKind
:
:
Tup
(
ts
)
}
}
else
if
self
.
eat
(
&
token
:
:
Not
)
{
TyKind
:
:
Never
}
else
if
self
.
check
(
&
token
:
:
BinOp
(
token
:
:
Star
)
)
{
self
.
bump
(
)
;
TyKind
:
:
Ptr
(
try
!
(
self
.
parse_ptr
(
)
)
)
}
else
if
self
.
check
(
&
token
:
:
OpenDelim
(
token
:
:
Bracket
)
)
{
try
!
(
self
.
expect
(
&
token
:
:
OpenDelim
(
token
:
:
Bracket
)
)
)
;
let
t
=
try
!
(
self
.
parse_ty_sum
(
)
)
;
let
t
=
match
try
!
(
self
.
maybe_parse_fixed_length_of_vec
(
)
)
{
None
=
>
TyKind
:
:
Slice
(
t
)
Some
(
suffix
)
=
>
TyKind
:
:
Array
(
t
suffix
)
}
;
try
!
(
self
.
expect
(
&
token
:
:
CloseDelim
(
token
:
:
Bracket
)
)
)
;
t
}
else
if
self
.
check
(
&
token
:
:
BinOp
(
token
:
:
And
)
)
|
|
self
.
token
=
=
token
:
:
AndAnd
{
try
!
(
self
.
expect_and
(
)
)
;
try
!
(
self
.
parse_borrowed_pointee
(
)
)
}
else
if
self
.
check_keyword
(
keywords
:
:
For
)
{
try
!
(
self
.
parse_for_in_type
(
)
)
}
else
if
self
.
eat_keyword
(
keywords
:
:
Impl
)
{
try
!
(
self
.
parse_impl_trait_type
(
)
)
}
else
if
self
.
token_is_bare_fn_keyword
(
)
{
try
!
(
self
.
parse_ty_bare_fn
(
Vec
:
:
new
(
)
)
)
}
else
if
self
.
eat_keyword_noexpect
(
keywords
:
:
Typeof
)
{
try
!
(
self
.
expect
(
&
token
:
:
OpenDelim
(
token
:
:
Paren
)
)
)
;
let
e
=
try
!
(
self
.
parse_expr
(
)
)
;
try
!
(
self
.
expect
(
&
token
:
:
CloseDelim
(
token
:
:
Paren
)
)
)
;
TyKind
:
:
Typeof
(
e
)
}
else
if
self
.
eat_lt
(
)
{
let
(
qself
path
)
=
try
!
(
self
.
parse_qualified_path
(
PathStyle
:
:
Type
)
)
;
TyKind
:
:
Path
(
Some
(
qself
)
path
)
}
else
if
self
.
token
.
is_path_start
(
)
{
let
path
=
try
!
(
self
.
parse_path
(
PathStyle
:
:
Type
)
)
;
if
self
.
eat
(
&
token
:
:
Not
)
{
let
delim
=
try
!
(
self
.
expect_open_delim
(
)
)
;
let
tts
=
try
!
(
self
.
parse_seq_to_end
(
&
token
:
:
CloseDelim
(
delim
)
SeqSep
:
:
none
(
)
|
p
|
p
.
parse_token_tree
(
)
)
)
;
let
hi
=
self
.
span
.
hi
;
TyKind
:
:
Mac
(
spanned
(
lo
hi
Mac_
{
path
:
path
tts
:
tts
}
)
)
}
else
{
TyKind
:
:
Path
(
None
path
)
}
}
else
if
self
.
eat
(
&
token
:
:
Underscore
)
{
TyKind
:
:
Infer
}
else
{
let
msg
=
format
!
(
"
expected
type
found
{
}
"
self
.
this_token_descr
(
)
)
;
return
Err
(
self
.
fatal
(
&
msg
)
)
;
}
;
let
sp
=
mk_sp
(
lo
self
.
prev_span
.
hi
)
;
Ok
(
P
(
Ty
{
id
:
ast
:
:
DUMMY_NODE_ID
node
:
t
span
:
sp
}
)
)
}
pub
fn
parse_borrowed_pointee
(
&
mut
self
)
-
>
PResult
<
'
a
TyKind
>
{
let
opt_lifetime
=
try
!
(
self
.
parse_opt_lifetime
(
)
)
;
let
mt
=
try
!
(
self
.
parse_mt
(
)
)
;
return
Ok
(
TyKind
:
:
Rptr
(
opt_lifetime
mt
)
)
;
}
pub
fn
parse_ptr
(
&
mut
self
)
-
>
PResult
<
'
a
MutTy
>
{
let
mutbl
=
if
self
.
eat_keyword
(
keywords
:
:
Mut
)
{
Mutability
:
:
Mutable
}
else
if
self
.
eat_keyword
(
keywords
:
:
Const
)
{
Mutability
:
:
Immutable
}
else
{
let
span
=
self
.
prev_span
;
self
.
span_err
(
span
"
expected
mut
or
const
in
raw
pointer
type
(
use
\
*
mut
T
or
*
const
T
as
appropriate
)
"
)
;
Mutability
:
:
Immutable
}
;
let
t
=
try
!
(
self
.
parse_ty
(
)
)
;
Ok
(
MutTy
{
ty
:
t
mutbl
:
mutbl
}
)
}
pub
fn
is_named_argument
(
&
mut
self
)
-
>
bool
{
let
offset
=
match
self
.
token
{
token
:
:
BinOp
(
token
:
:
And
)
=
>
1
token
:
:
AndAnd
=
>
1
_
if
self
.
token
.
is_keyword
(
keywords
:
:
Mut
)
=
>
1
_
=
>
0
}
;
debug
!
(
"
parser
is_named_argument
offset
:
{
}
"
offset
)
;
if
offset
=
=
0
{
is_ident_or_underscore
(
&
self
.
token
)
&
&
self
.
look_ahead
(
1
|
t
|
*
t
=
=
token
:
:
Colon
)
}
else
{
self
.
look_ahead
(
offset
|
t
|
is_ident_or_underscore
(
t
)
)
&
&
self
.
look_ahead
(
offset
+
1
|
t
|
*
t
=
=
token
:
:
Colon
)
}
}
pub
fn
parse_arg_general
(
&
mut
self
require_name
:
bool
)
-
>
PResult
<
'
a
Arg
>
{
maybe_whole
!
(
self
NtArg
|
x
|
x
)
;
let
pat
=
if
require_name
|
|
self
.
is_named_argument
(
)
{
debug
!
(
"
parse_arg_general
parse_pat
(
require_name
:
{
}
)
"
require_name
)
;
let
pat
=
try
!
(
self
.
parse_pat
(
)
)
;
try
!
(
self
.
expect
(
&
token
:
:
Colon
)
)
;
pat
}
else
{
debug
!
(
"
parse_arg_general
ident_to_pat
"
)
;
let
sp
=
self
.
prev_span
;
let
spanned
=
Spanned
{
span
:
sp
node
:
keywords
:
:
Invalid
.
ident
(
)
}
;
P
(
Pat
{
id
:
ast
:
:
DUMMY_NODE_ID
node
:
PatKind
:
:
Ident
(
BindingMode
:
:
ByValue
(
Mutability
:
:
Immutable
)
spanned
None
)
span
:
sp
}
)
}
;
let
t
=
try
!
(
self
.
parse_ty_sum
(
)
)
;
Ok
(
Arg
{
ty
:
t
pat
:
pat
id
:
ast
:
:
DUMMY_NODE_ID
}
)
}
pub
fn
parse_arg
(
&
mut
self
)
-
>
PResult
<
'
a
Arg
>
{
self
.
parse_arg_general
(
true
)
}
pub
fn
parse_fn_block_arg
(
&
mut
self
)
-
>
PResult
<
'
a
Arg
>
{
let
pat
=
try
!
(
self
.
parse_pat
(
)
)
;
let
t
=
if
self
.
eat
(
&
token
:
:
Colon
)
{
try
!
(
self
.
parse_ty_sum
(
)
)
}
else
{
P
(
Ty
{
id
:
ast
:
:
DUMMY_NODE_ID
node
:
TyKind
:
:
Infer
span
:
mk_sp
(
self
.
span
.
lo
self
.
span
.
hi
)
}
)
}
;
Ok
(
Arg
{
ty
:
t
pat
:
pat
id
:
ast
:
:
DUMMY_NODE_ID
}
)
}
pub
fn
maybe_parse_fixed_length_of_vec
(
&
mut
self
)
-
>
PResult
<
'
a
Option
<
P
<
ast
:
:
Expr
>
>
>
{
if
self
.
check
(
&
token
:
:
Semi
)
{
self
.
bump
(
)
;
Ok
(
Some
(
try
!
(
self
.
parse_expr
(
)
)
)
)
}
else
{
Ok
(
None
)
}
}
pub
fn
parse_lit_token
(
&
mut
self
)
-
>
PResult
<
'
a
LitKind
>
{
let
out
=
match
self
.
token
{
token
:
:
Interpolated
(
ref
nt
)
=
>
match
*
*
nt
{
token
:
:
NtExpr
(
ref
v
)
=
>
match
v
.
node
{
ExprKind
:
:
Lit
(
ref
lit
)
=
>
{
lit
.
node
.
clone
(
)
}
_
=
>
{
return
self
.
unexpected_last
(
&
self
.
token
)
;
}
}
_
=
>
{
return
self
.
unexpected_last
(
&
self
.
token
)
;
}
}
token
:
:
Literal
(
lit
suf
)
=
>
{
let
(
suffix_illegal
out
)
=
match
lit
{
token
:
:
Byte
(
i
)
=
>
(
true
LitKind
:
:
Byte
(
parse
:
:
byte_lit
(
&
i
.
as_str
(
)
)
.
0
)
)
token
:
:
Char
(
i
)
=
>
(
true
LitKind
:
:
Char
(
parse
:
:
char_lit
(
&
i
.
as_str
(
)
)
.
0
)
)
token
:
:
Integer
(
s
)
=
>
{
(
false
parse
:
:
integer_lit
(
&
s
.
as_str
(
)
suf
.
as_ref
(
)
.
map
(
|
s
|
s
.
as_str
(
)
)
&
self
.
sess
.
span_diagnostic
self
.
span
)
)
}
token
:
:
Float
(
s
)
=
>
{
(
false
parse
:
:
float_lit
(
&
s
.
as_str
(
)
suf
.
as_ref
(
)
.
map
(
|
s
|
s
.
as_str
(
)
)
&
self
.
sess
.
span_diagnostic
self
.
span
)
)
}
token
:
:
Str_
(
s
)
=
>
{
(
true
LitKind
:
:
Str
(
token
:
:
intern_and_get_ident
(
&
parse
:
:
str_lit
(
&
s
.
as_str
(
)
)
)
ast
:
:
StrStyle
:
:
Cooked
)
)
}
token
:
:
StrRaw
(
s
n
)
=
>
{
(
true
LitKind
:
:
Str
(
token
:
:
intern_and_get_ident
(
&
parse
:
:
raw_str_lit
(
&
s
.
as_str
(
)
)
)
ast
:
:
StrStyle
:
:
Raw
(
n
)
)
)
}
token
:
:
ByteStr
(
i
)
=
>
(
true
LitKind
:
:
ByteStr
(
parse
:
:
byte_str_lit
(
&
i
.
as_str
(
)
)
)
)
token
:
:
ByteStrRaw
(
i
_
)
=
>
(
true
LitKind
:
:
ByteStr
(
Rc
:
:
new
(
i
.
to_string
(
)
.
into_bytes
(
)
)
)
)
}
;
if
suffix_illegal
{
let
sp
=
self
.
span
;
self
.
expect_no_suffix
(
sp
&
format
!
(
"
{
}
literal
"
lit
.
short_name
(
)
)
suf
)
}
out
}
_
=
>
{
return
self
.
unexpected_last
(
&
self
.
token
)
;
}
}
;
self
.
bump
(
)
;
Ok
(
out
)
}
pub
fn
parse_lit
(
&
mut
self
)
-
>
PResult
<
'
a
Lit
>
{
let
lo
=
self
.
span
.
lo
;
let
lit
=
if
self
.
eat_keyword
(
keywords
:
:
True
)
{
LitKind
:
:
Bool
(
true
)
}
else
if
self
.
eat_keyword
(
keywords
:
:
False
)
{
LitKind
:
:
Bool
(
false
)
}
else
{
let
lit
=
try
!
(
self
.
parse_lit_token
(
)
)
;
lit
}
;
Ok
(
codemap
:
:
Spanned
{
node
:
lit
span
:
mk_sp
(
lo
self
.
prev_span
.
hi
)
}
)
}
pub
fn
parse_pat_literal_maybe_minus
(
&
mut
self
)
-
>
PResult
<
'
a
P
<
Expr
>
>
{
let
minus_lo
=
self
.
span
.
lo
;
let
minus_present
=
self
.
eat
(
&
token
:
:
BinOp
(
token
:
:
Minus
)
)
;
let
lo
=
self
.
span
.
lo
;
let
literal
=
P
(
try
!
(
self
.
parse_lit
(
)
)
)
;
let
hi
=
self
.
prev_span
.
hi
;
let
expr
=
self
.
mk_expr
(
lo
hi
ExprKind
:
:
Lit
(
literal
)
ThinVec
:
:
new
(
)
)
;
if
minus_present
{
let
minus_hi
=
self
.
prev_span
.
hi
;
let
unary
=
self
.
mk_unary
(
UnOp
:
:
Neg
expr
)
;
Ok
(
self
.
mk_expr
(
minus_lo
minus_hi
unary
ThinVec
:
:
new
(
)
)
)
}
else
{
Ok
(
expr
)
}
}
pub
fn
parse_path_segment_ident
(
&
mut
self
)
-
>
PResult
<
'
a
ast
:
:
Ident
>
{
match
self
.
token
{
token
:
:
Ident
(
sid
)
if
self
.
token
.
is_path_segment_keyword
(
)
=
>
{
self
.
bump
(
)
;
Ok
(
sid
)
}
_
=
>
self
.
parse_ident
(
)
}
}
pub
fn
parse_qualified_path
(
&
mut
self
mode
:
PathStyle
)
-
>
PResult
<
'
a
(
QSelf
ast
:
:
Path
)
>
{
let
span
=
self
.
prev_span
;
let
self_type
=
try
!
(
self
.
parse_ty_sum
(
)
)
;
let
mut
path
=
if
self
.
eat_keyword
(
keywords
:
:
As
)
{
try
!
(
self
.
parse_path
(
PathStyle
:
:
Type
)
)
}
else
{
ast
:
:
Path
{
span
:
span
global
:
false
segments
:
vec
!
[
]
}
}
;
let
qself
=
QSelf
{
ty
:
self_type
position
:
path
.
segments
.
len
(
)
}
;
try
!
(
self
.
expect
(
&
token
:
:
Gt
)
)
;
try
!
(
self
.
expect
(
&
token
:
:
ModSep
)
)
;
let
segments
=
match
mode
{
PathStyle
:
:
Type
=
>
{
try
!
(
self
.
parse_path_segments_without_colons
(
)
)
}
PathStyle
:
:
Expr
=
>
{
try
!
(
self
.
parse_path_segments_with_colons
(
)
)
}
PathStyle
:
:
Mod
=
>
{
try
!
(
self
.
parse_path_segments_without_types
(
)
)
}
}
;
path
.
segments
.
extend
(
segments
)
;
path
.
span
.
hi
=
self
.
prev_span
.
hi
;
Ok
(
(
qself
path
)
)
}
pub
fn
parse_path
(
&
mut
self
mode
:
PathStyle
)
-
>
PResult
<
'
a
ast
:
:
Path
>
{
maybe_whole
!
(
self
NtPath
|
x
|
x
)
;
let
lo
=
self
.
span
.
lo
;
let
is_global
=
self
.
eat
(
&
token
:
:
ModSep
)
;
let
segments
=
match
mode
{
PathStyle
:
:
Type
=
>
{
try
!
(
self
.
parse_path_segments_without_colons
(
)
)
}
PathStyle
:
:
Expr
=
>
{
try
!
(
self
.
parse_path_segments_with_colons
(
)
)
}
PathStyle
:
:
Mod
=
>
{
try
!
(
self
.
parse_path_segments_without_types
(
)
)
}
}
;
let
span
=
mk_sp
(
lo
self
.
prev_span
.
hi
)
;
Ok
(
ast
:
:
Path
{
span
:
span
global
:
is_global
segments
:
segments
}
)
}
pub
fn
parse_path_segments_without_colons
(
&
mut
self
)
-
>
PResult
<
'
a
Vec
<
ast
:
:
PathSegment
>
>
{
let
mut
segments
=
Vec
:
:
new
(
)
;
loop
{
let
identifier
=
try
!
(
self
.
parse_path_segment_ident
(
)
)
;
if
self
.
check
(
&
token
:
:
ModSep
)
&
&
self
.
look_ahead
(
1
|
t
|
*
t
=
=
token
:
:
Lt
)
{
self
.
bump
(
)
;
let
prev_span
=
self
.
prev_span
;
let
mut
err
=
self
.
diagnostic
(
)
.
struct_span_err
(
prev_span
"
unexpected
token
:
:
:
"
)
;
err
.
help
(
"
use
<
.
.
.
>
instead
of
:
:
<
.
.
.
>
if
you
meant
to
specify
type
arguments
"
)
;
err
.
emit
(
)
;
}
let
parameters
=
if
self
.
eat_lt
(
)
{
let
(
lifetimes
types
bindings
)
=
try
!
(
self
.
parse_generic_values_after_lt
(
)
)
;
ast
:
:
PathParameters
:
:
AngleBracketed
(
ast
:
:
AngleBracketedParameterData
{
lifetimes
:
lifetimes
types
:
P
:
:
from_vec
(
types
)
bindings
:
P
:
:
from_vec
(
bindings
)
}
)
}
else
if
self
.
eat
(
&
token
:
:
OpenDelim
(
token
:
:
Paren
)
)
{
let
lo
=
self
.
prev_span
.
lo
;
let
inputs
=
try
!
(
self
.
parse_seq_to_end
(
&
token
:
:
CloseDelim
(
token
:
:
Paren
)
SeqSep
:
:
trailing_allowed
(
token
:
:
Comma
)
|
p
|
p
.
parse_ty_sum
(
)
)
)
;
let
output_ty
=
if
self
.
eat
(
&
token
:
:
RArrow
)
{
Some
(
try
!
(
self
.
parse_ty
(
)
)
)
}
else
{
None
}
;
let
hi
=
self
.
prev_span
.
hi
;
ast
:
:
PathParameters
:
:
Parenthesized
(
ast
:
:
ParenthesizedParameterData
{
span
:
mk_sp
(
lo
hi
)
inputs
:
inputs
output
:
output_ty
}
)
}
else
{
ast
:
:
PathParameters
:
:
none
(
)
}
;
segments
.
push
(
ast
:
:
PathSegment
{
identifier
:
identifier
parameters
:
parameters
}
)
;
if
!
self
.
eat
(
&
token
:
:
ModSep
)
{
return
Ok
(
segments
)
;
}
}
}
pub
fn
parse_path_segments_with_colons
(
&
mut
self
)
-
>
PResult
<
'
a
Vec
<
ast
:
:
PathSegment
>
>
{
let
mut
segments
=
Vec
:
:
new
(
)
;
loop
{
let
identifier
=
try
!
(
self
.
parse_path_segment_ident
(
)
)
;
if
!
self
.
eat
(
&
token
:
:
ModSep
)
{
segments
.
push
(
ast
:
:
PathSegment
{
identifier
:
identifier
parameters
:
ast
:
:
PathParameters
:
:
none
(
)
}
)
;
return
Ok
(
segments
)
;
}
if
self
.
eat_lt
(
)
{
let
(
lifetimes
types
bindings
)
=
try
!
(
self
.
parse_generic_values_after_lt
(
)
)
;
let
parameters
=
ast
:
:
AngleBracketedParameterData
{
lifetimes
:
lifetimes
types
:
P
:
:
from_vec
(
types
)
bindings
:
P
:
:
from_vec
(
bindings
)
}
;
segments
.
push
(
ast
:
:
PathSegment
{
identifier
:
identifier
parameters
:
ast
:
:
PathParameters
:
:
AngleBracketed
(
parameters
)
}
)
;
if
!
self
.
eat
(
&
token
:
:
ModSep
)
{
return
Ok
(
segments
)
;
}
}
else
{
segments
.
push
(
ast
:
:
PathSegment
{
identifier
:
identifier
parameters
:
ast
:
:
PathParameters
:
:
none
(
)
}
)
;
}
}
}
pub
fn
parse_path_segments_without_types
(
&
mut
self
)
-
>
PResult
<
'
a
Vec
<
ast
:
:
PathSegment
>
>
{
let
mut
segments
=
Vec
:
:
new
(
)
;
loop
{
let
identifier
=
try
!
(
self
.
parse_path_segment_ident
(
)
)
;
segments
.
push
(
ast
:
:
PathSegment
{
identifier
:
identifier
parameters
:
ast
:
:
PathParameters
:
:
none
(
)
}
)
;
if
!
self
.
check
(
&
token
:
:
ModSep
)
|
|
self
.
is_import_coupler
(
)
{
return
Ok
(
segments
)
;
}
else
{
self
.
bump
(
)
;
}
}
}
pub
fn
parse_opt_lifetime
(
&
mut
self
)
-
>
PResult
<
'
a
Option
<
ast
:
:
Lifetime
>
>
{
match
self
.
token
{
token
:
:
Lifetime
(
.
.
)
=
>
{
Ok
(
Some
(
try
!
(
self
.
parse_lifetime
(
)
)
)
)
}
_
=
>
{
Ok
(
None
)
}
}
}
pub
fn
parse_lifetime
(
&
mut
self
)
-
>
PResult
<
'
a
ast
:
:
Lifetime
>
{
match
self
.
token
{
token
:
:
Lifetime
(
i
)
=
>
{
let
span
=
self
.
span
;
self
.
bump
(
)
;
return
Ok
(
ast
:
:
Lifetime
{
id
:
ast
:
:
DUMMY_NODE_ID
span
:
span
name
:
i
.
name
}
)
;
}
_
=
>
{
return
Err
(
self
.
fatal
(
"
expected
a
lifetime
name
"
)
)
;
}
}
}
pub
fn
parse_lifetime_defs
(
&
mut
self
followed_by_ty_params
:
Option
<
&
mut
Vec
<
ast
:
:
Attribute
>
>
)
-
>
PResult
<
'
a
Vec
<
ast
:
:
LifetimeDef
>
>
{
let
mut
res
=
Vec
:
:
new
(
)
;
loop
{
let
attrs
=
try
!
(
self
.
parse_outer_attributes
(
)
)
;
match
self
.
token
{
token
:
:
Lifetime
(
_
)
=
>
{
let
lifetime
=
try
!
(
self
.
parse_lifetime
(
)
)
;
let
bounds
=
if
self
.
eat
(
&
token
:
:
Colon
)
{
try
!
(
self
.
parse_lifetimes
(
token
:
:
BinOp
(
token
:
:
Plus
)
)
)
}
else
{
Vec
:
:
new
(
)
}
;
res
.
push
(
ast
:
:
LifetimeDef
{
attrs
:
attrs
.
into
(
)
lifetime
:
lifetime
bounds
:
bounds
}
)
;
}
_
=
>
{
if
let
Some
(
recv
)
=
followed_by_ty_params
{
assert
!
(
recv
.
is_empty
(
)
)
;
*
recv
=
attrs
;
debug
!
(
"
parse_lifetime_defs
ret
{
:
?
}
"
res
)
;
return
Ok
(
res
)
;
}
else
if
!
attrs
.
is_empty
(
)
{
let
msg
=
"
trailing
attribute
after
lifetime
parameters
"
;
return
Err
(
self
.
fatal
(
msg
)
)
;
}
}
}
match
self
.
token
{
token
:
:
Comma
=
>
{
self
.
bump
(
)
;
}
token
:
:
Gt
=
>
{
return
Ok
(
res
)
;
}
token
:
:
BinOp
(
token
:
:
Shr
)
=
>
{
return
Ok
(
res
)
;
}
_
=
>
{
let
this_token_str
=
self
.
this_token_to_string
(
)
;
let
msg
=
format
!
(
"
expected
or
>
after
lifetime
\
name
found
{
}
"
this_token_str
)
;
return
Err
(
self
.
fatal
(
&
msg
[
.
.
]
)
)
;
}
}
}
}
pub
fn
parse_lifetimes
(
&
mut
self
sep
:
token
:
:
Token
)
-
>
PResult
<
'
a
Vec
<
ast
:
:
Lifetime
>
>
{
let
mut
res
=
Vec
:
:
new
(
)
;
loop
{
match
self
.
token
{
token
:
:
Lifetime
(
_
)
=
>
{
res
.
push
(
try
!
(
self
.
parse_lifetime
(
)
)
)
;
}
_
=
>
{
return
Ok
(
res
)
;
}
}
if
self
.
token
!
=
sep
{
return
Ok
(
res
)
;
}
self
.
bump
(
)
;
}
}
pub
fn
parse_mutability
(
&
mut
self
)
-
>
PResult
<
'
a
Mutability
>
{
if
self
.
eat_keyword
(
keywords
:
:
Mut
)
{
Ok
(
Mutability
:
:
Mutable
)
}
else
{
Ok
(
Mutability
:
:
Immutable
)
}
}
pub
fn
parse_field_name
(
&
mut
self
)
-
>
PResult
<
'
a
Ident
>
{
if
let
token
:
:
Literal
(
token
:
:
Integer
(
name
)
None
)
=
self
.
token
{
self
.
bump
(
)
;
Ok
(
Ident
:
:
with_empty_ctxt
(
name
)
)
}
else
{
self
.
parse_ident
(
)
}
}
pub
fn
parse_field
(
&
mut
self
)
-
>
PResult
<
'
a
Field
>
{
let
lo
=
self
.
span
.
lo
;
let
hi
;
let
(
fieldname
expr
is_shorthand
)
=
if
self
.
look_ahead
(
1
|
t
|
t
=
=
&
token
:
:
Colon
)
{
let
fieldname
=
try
!
(
self
.
parse_field_name
(
)
)
;
self
.
bump
(
)
;
hi
=
self
.
prev_span
.
hi
;
(
fieldname
try
!
(
self
.
parse_expr
(
)
)
false
)
}
else
{
let
fieldname
=
try
!
(
self
.
parse_ident
(
)
)
;
hi
=
self
.
prev_span
.
hi
;
let
path
=
ast
:
:
Path
:
:
from_ident
(
mk_sp
(
lo
hi
)
fieldname
)
;
(
fieldname
self
.
mk_expr
(
lo
hi
ExprKind
:
:
Path
(
None
path
)
ThinVec
:
:
new
(
)
)
true
)
}
;
Ok
(
ast
:
:
Field
{
ident
:
spanned
(
lo
hi
fieldname
)
span
:
mk_sp
(
lo
expr
.
span
.
hi
)
expr
:
expr
is_shorthand
:
is_shorthand
}
)
}
pub
fn
mk_expr
(
&
mut
self
lo
:
BytePos
hi
:
BytePos
node
:
ExprKind
attrs
:
ThinVec
<
Attribute
>
)
-
>
P
<
Expr
>
{
P
(
Expr
{
id
:
ast
:
:
DUMMY_NODE_ID
node
:
node
span
:
mk_sp
(
lo
hi
)
attrs
:
attrs
.
into
(
)
}
)
}
pub
fn
mk_unary
(
&
mut
self
unop
:
ast
:
:
UnOp
expr
:
P
<
Expr
>
)
-
>
ast
:
:
ExprKind
{
ExprKind
:
:
Unary
(
unop
expr
)
}
pub
fn
mk_binary
(
&
mut
self
binop
:
ast
:
:
BinOp
lhs
:
P
<
Expr
>
rhs
:
P
<
Expr
>
)
-
>
ast
:
:
ExprKind
{
ExprKind
:
:
Binary
(
binop
lhs
rhs
)
}
pub
fn
mk_call
(
&
mut
self
f
:
P
<
Expr
>
args
:
Vec
<
P
<
Expr
>
>
)
-
>
ast
:
:
ExprKind
{
ExprKind
:
:
Call
(
f
args
)
}
fn
mk_method_call
(
&
mut
self
ident
:
ast
:
:
SpannedIdent
tps
:
Vec
<
P
<
Ty
>
>
args
:
Vec
<
P
<
Expr
>
>
)
-
>
ast
:
:
ExprKind
{
ExprKind
:
:
MethodCall
(
ident
tps
args
)
}
pub
fn
mk_index
(
&
mut
self
expr
:
P
<
Expr
>
idx
:
P
<
Expr
>
)
-
>
ast
:
:
ExprKind
{
ExprKind
:
:
Index
(
expr
idx
)
}
pub
fn
mk_range
(
&
mut
self
start
:
Option
<
P
<
Expr
>
>
end
:
Option
<
P
<
Expr
>
>
limits
:
RangeLimits
)
-
>
PResult
<
'
a
ast
:
:
ExprKind
>
{
if
end
.
is_none
(
)
&
&
limits
=
=
RangeLimits
:
:
Closed
{
Err
(
self
.
span_fatal_help
(
self
.
span
"
inclusive
range
with
no
end
"
"
inclusive
ranges
must
be
bounded
at
the
end
\
(
.
.
.
b
or
a
.
.
.
b
)
"
)
)
}
else
{
Ok
(
ExprKind
:
:
Range
(
start
end
limits
)
)
}
}
pub
fn
mk_field
(
&
mut
self
expr
:
P
<
Expr
>
ident
:
ast
:
:
SpannedIdent
)
-
>
ast
:
:
ExprKind
{
ExprKind
:
:
Field
(
expr
ident
)
}
pub
fn
mk_tup_field
(
&
mut
self
expr
:
P
<
Expr
>
idx
:
codemap
:
:
Spanned
<
usize
>
)
-
>
ast
:
:
ExprKind
{
ExprKind
:
:
TupField
(
expr
idx
)
}
pub
fn
mk_assign_op
(
&
mut
self
binop
:
ast
:
:
BinOp
lhs
:
P
<
Expr
>
rhs
:
P
<
Expr
>
)
-
>
ast
:
:
ExprKind
{
ExprKind
:
:
AssignOp
(
binop
lhs
rhs
)
}
pub
fn
mk_mac_expr
(
&
mut
self
lo
:
BytePos
hi
:
BytePos
m
:
Mac_
attrs
:
ThinVec
<
Attribute
>
)
-
>
P
<
Expr
>
{
P
(
Expr
{
id
:
ast
:
:
DUMMY_NODE_ID
node
:
ExprKind
:
:
Mac
(
codemap
:
:
Spanned
{
node
:
m
span
:
mk_sp
(
lo
hi
)
}
)
span
:
mk_sp
(
lo
hi
)
attrs
:
attrs
}
)
}
pub
fn
mk_lit_u32
(
&
mut
self
i
:
u32
attrs
:
ThinVec
<
Attribute
>
)
-
>
P
<
Expr
>
{
let
span
=
&
self
.
span
;
let
lv_lit
=
P
(
codemap
:
:
Spanned
{
node
:
LitKind
:
:
Int
(
i
as
u64
ast
:
:
LitIntType
:
:
Unsigned
(
UintTy
:
:
U32
)
)
span
:
*
span
}
)
;
P
(
Expr
{
id
:
ast
:
:
DUMMY_NODE_ID
node
:
ExprKind
:
:
Lit
(
lv_lit
)
span
:
*
span
attrs
:
attrs
}
)
}
fn
expect_open_delim
(
&
mut
self
)
-
>
PResult
<
'
a
token
:
:
DelimToken
>
{
self
.
expected_tokens
.
push
(
TokenType
:
:
Token
(
token
:
:
Gt
)
)
;
match
self
.
token
{
token
:
:
OpenDelim
(
delim
)
=
>
{
self
.
bump
(
)
;
Ok
(
delim
)
}
_
=
>
Err
(
self
.
fatal
(
"
expected
open
delimiter
"
)
)
}
}
fn
parse_bottom_expr
(
&
mut
self
)
-
>
PResult
<
'
a
P
<
Expr
>
>
{
maybe_whole_expr
!
(
self
)
;
let
mut
attrs
=
ThinVec
:
:
new
(
)
;
let
lo
=
self
.
span
.
lo
;
let
mut
hi
=
self
.
span
.
hi
;
let
ex
:
ExprKind
;
match
self
.
token
{
token
:
:
OpenDelim
(
token
:
:
Paren
)
=
>
{
self
.
bump
(
)
;
attrs
.
extend
(
try
!
(
self
.
parse_inner_attributes
(
)
)
)
;
let
mut
es
=
vec
!
[
]
;
let
mut
trailing_comma
=
false
;
while
self
.
token
!
=
token
:
:
CloseDelim
(
token
:
:
Paren
)
{
es
.
push
(
try
!
(
self
.
parse_expr
(
)
)
)
;
try
!
(
self
.
expect_one_of
(
&
[
]
&
[
token
:
:
Comma
token
:
:
CloseDelim
(
token
:
:
Paren
)
]
)
)
;
if
self
.
check
(
&
token
:
:
Comma
)
{
trailing_comma
=
true
;
self
.
bump
(
)
;
}
else
{
trailing_comma
=
false
;
break
;
}
}
self
.
bump
(
)
;
hi
=
self
.
prev_span
.
hi
;
return
if
es
.
len
(
)
=
=
1
&
&
!
trailing_comma
{
Ok
(
self
.
mk_expr
(
lo
hi
ExprKind
:
:
Paren
(
es
.
into_iter
(
)
.
nth
(
0
)
.
unwrap
(
)
)
attrs
)
)
}
else
{
Ok
(
self
.
mk_expr
(
lo
hi
ExprKind
:
:
Tup
(
es
)
attrs
)
)
}
}
token
:
:
OpenDelim
(
token
:
:
Brace
)
=
>
{
return
self
.
parse_block_expr
(
lo
BlockCheckMode
:
:
Default
attrs
)
;
}
token
:
:
BinOp
(
token
:
:
Or
)
|
token
:
:
OrOr
=
>
{
let
lo
=
self
.
span
.
lo
;
return
self
.
parse_lambda_expr
(
lo
CaptureBy
:
:
Ref
attrs
)
;
}
token
:
:
OpenDelim
(
token
:
:
Bracket
)
=
>
{
self
.
bump
(
)
;
attrs
.
extend
(
try
!
(
self
.
parse_inner_attributes
(
)
)
)
;
if
self
.
check
(
&
token
:
:
CloseDelim
(
token
:
:
Bracket
)
)
{
self
.
bump
(
)
;
ex
=
ExprKind
:
:
Vec
(
Vec
:
:
new
(
)
)
;
}
else
{
let
first_expr
=
try
!
(
self
.
parse_expr
(
)
)
;
if
self
.
check
(
&
token
:
:
Semi
)
{
self
.
bump
(
)
;
let
count
=
try
!
(
self
.
parse_expr
(
)
)
;
try
!
(
self
.
expect
(
&
token
:
:
CloseDelim
(
token
:
:
Bracket
)
)
)
;
ex
=
ExprKind
:
:
Repeat
(
first_expr
count
)
;
}
else
if
self
.
check
(
&
token
:
:
Comma
)
{
self
.
bump
(
)
;
let
remaining_exprs
=
try
!
(
self
.
parse_seq_to_end
(
&
token
:
:
CloseDelim
(
token
:
:
Bracket
)
SeqSep
:
:
trailing_allowed
(
token
:
:
Comma
)
|
p
|
Ok
(
try
!
(
p
.
parse_expr
(
)
)
)
)
)
;
let
mut
exprs
=
vec
!
[
first_expr
]
;
exprs
.
extend
(
remaining_exprs
)
;
ex
=
ExprKind
:
:
Vec
(
exprs
)
;
}
else
{
try
!
(
self
.
expect
(
&
token
:
:
CloseDelim
(
token
:
:
Bracket
)
)
)
;
ex
=
ExprKind
:
:
Vec
(
vec
!
[
first_expr
]
)
;
}
}
hi
=
self
.
prev_span
.
hi
;
}
_
=
>
{
if
self
.
eat_lt
(
)
{
let
(
qself
path
)
=
try
!
(
self
.
parse_qualified_path
(
PathStyle
:
:
Expr
)
)
;
hi
=
path
.
span
.
hi
;
return
Ok
(
self
.
mk_expr
(
lo
hi
ExprKind
:
:
Path
(
Some
(
qself
)
path
)
attrs
)
)
;
}
if
self
.
eat_keyword
(
keywords
:
:
Move
)
{
let
lo
=
self
.
prev_span
.
lo
;
return
self
.
parse_lambda_expr
(
lo
CaptureBy
:
:
Value
attrs
)
;
}
if
self
.
eat_keyword
(
keywords
:
:
If
)
{
return
self
.
parse_if_expr
(
attrs
)
;
}
if
self
.
eat_keyword
(
keywords
:
:
For
)
{
let
lo
=
self
.
prev_span
.
lo
;
return
self
.
parse_for_expr
(
None
lo
attrs
)
;
}
if
self
.
eat_keyword
(
keywords
:
:
While
)
{
let
lo
=
self
.
prev_span
.
lo
;
return
self
.
parse_while_expr
(
None
lo
attrs
)
;
}
if
self
.
token
.
is_lifetime
(
)
{
let
label
=
Spanned
{
node
:
self
.
get_lifetime
(
)
span
:
self
.
span
}
;
let
lo
=
self
.
span
.
lo
;
self
.
bump
(
)
;
try
!
(
self
.
expect
(
&
token
:
:
Colon
)
)
;
if
self
.
eat_keyword
(
keywords
:
:
While
)
{
return
self
.
parse_while_expr
(
Some
(
label
)
lo
attrs
)
}
if
self
.
eat_keyword
(
keywords
:
:
For
)
{
return
self
.
parse_for_expr
(
Some
(
label
)
lo
attrs
)
}
if
self
.
eat_keyword
(
keywords
:
:
Loop
)
{
return
self
.
parse_loop_expr
(
Some
(
label
)
lo
attrs
)
}
return
Err
(
self
.
fatal
(
"
expected
while
for
or
loop
after
a
label
"
)
)
}
if
self
.
eat_keyword
(
keywords
:
:
Loop
)
{
let
lo
=
self
.
prev_span
.
lo
;
return
self
.
parse_loop_expr
(
None
lo
attrs
)
;
}
if
self
.
eat_keyword
(
keywords
:
:
Continue
)
{
let
ex
=
if
self
.
token
.
is_lifetime
(
)
{
let
ex
=
ExprKind
:
:
Continue
(
Some
(
Spanned
{
node
:
self
.
get_lifetime
(
)
span
:
self
.
span
}
)
)
;
self
.
bump
(
)
;
ex
}
else
{
ExprKind
:
:
Continue
(
None
)
}
;
let
hi
=
self
.
prev_span
.
hi
;
return
Ok
(
self
.
mk_expr
(
lo
hi
ex
attrs
)
)
;
}
if
self
.
eat_keyword
(
keywords
:
:
Match
)
{
return
self
.
parse_match_expr
(
attrs
)
;
}
if
self
.
eat_keyword
(
keywords
:
:
Unsafe
)
{
return
self
.
parse_block_expr
(
lo
BlockCheckMode
:
:
Unsafe
(
ast
:
:
UserProvided
)
attrs
)
;
}
if
self
.
eat_keyword
(
keywords
:
:
Return
)
{
if
self
.
token
.
can_begin_expr
(
)
{
let
e
=
try
!
(
self
.
parse_expr
(
)
)
;
hi
=
e
.
span
.
hi
;
ex
=
ExprKind
:
:
Ret
(
Some
(
e
)
)
;
}
else
{
ex
=
ExprKind
:
:
Ret
(
None
)
;
}
}
else
if
self
.
eat_keyword
(
keywords
:
:
Break
)
{
if
self
.
token
.
is_lifetime
(
)
{
ex
=
ExprKind
:
:
Break
(
Some
(
Spanned
{
node
:
self
.
get_lifetime
(
)
span
:
self
.
span
}
)
)
;
self
.
bump
(
)
;
}
else
{
ex
=
ExprKind
:
:
Break
(
None
)
;
}
hi
=
self
.
prev_span
.
hi
;
}
else
if
self
.
token
.
is_keyword
(
keywords
:
:
Let
)
{
let
mut
db
=
self
.
fatal
(
"
expected
expression
found
statement
(
let
)
"
)
;
db
.
note
(
"
variable
declaration
using
let
is
a
statement
"
)
;
return
Err
(
db
)
;
}
else
if
self
.
token
.
is_path_start
(
)
{
let
pth
=
try
!
(
self
.
parse_path
(
PathStyle
:
:
Expr
)
)
;
if
self
.
eat
(
&
token
:
:
Not
)
{
let
delim
=
try
!
(
self
.
expect_open_delim
(
)
)
;
let
tts
=
try
!
(
self
.
parse_seq_to_end
(
&
token
:
:
CloseDelim
(
delim
)
SeqSep
:
:
none
(
)
|
p
|
p
.
parse_token_tree
(
)
)
)
;
let
hi
=
self
.
prev_span
.
hi
;
return
Ok
(
self
.
mk_mac_expr
(
lo
hi
Mac_
{
path
:
pth
tts
:
tts
}
attrs
)
)
;
}
if
self
.
check
(
&
token
:
:
OpenDelim
(
token
:
:
Brace
)
)
{
let
prohibited
=
self
.
restrictions
.
contains
(
RESTRICTION_NO_STRUCT_LITERAL
)
;
if
!
prohibited
{
return
self
.
parse_struct_expr
(
lo
pth
attrs
)
;
}
}
hi
=
pth
.
span
.
hi
;
ex
=
ExprKind
:
:
Path
(
None
pth
)
;
}
else
{
match
self
.
parse_lit
(
)
{
Ok
(
lit
)
=
>
{
hi
=
lit
.
span
.
hi
;
ex
=
ExprKind
:
:
Lit
(
P
(
lit
)
)
;
}
Err
(
mut
err
)
=
>
{
self
.
cancel
(
&
mut
err
)
;
let
msg
=
format
!
(
"
expected
expression
found
{
}
"
self
.
this_token_descr
(
)
)
;
return
Err
(
self
.
fatal
(
&
msg
)
)
;
}
}
}
}
}
return
Ok
(
self
.
mk_expr
(
lo
hi
ex
attrs
)
)
;
}
fn
parse_struct_expr
(
&
mut
self
lo
:
BytePos
pth
:
ast
:
:
Path
mut
attrs
:
ThinVec
<
Attribute
>
)
-
>
PResult
<
'
a
P
<
Expr
>
>
{
self
.
bump
(
)
;
let
mut
fields
=
Vec
:
:
new
(
)
;
let
mut
base
=
None
;
attrs
.
extend
(
try
!
(
self
.
parse_inner_attributes
(
)
)
)
;
while
self
.
token
!
=
token
:
:
CloseDelim
(
token
:
:
Brace
)
{
if
self
.
eat
(
&
token
:
:
DotDot
)
{
match
self
.
parse_expr
(
)
{
Ok
(
e
)
=
>
{
base
=
Some
(
e
)
;
}
Err
(
mut
e
)
=
>
{
e
.
emit
(
)
;
self
.
recover_stmt
(
)
;
}
}
break
;
}
match
self
.
parse_field
(
)
{
Ok
(
f
)
=
>
fields
.
push
(
f
)
Err
(
mut
e
)
=
>
{
e
.
emit
(
)
;
self
.
recover_stmt
(
)
;
break
;
}
}
match
self
.
expect_one_of
(
&
[
token
:
:
Comma
]
&
[
token
:
:
CloseDelim
(
token
:
:
Brace
)
]
)
{
Ok
(
(
)
)
=
>
{
}
Err
(
mut
e
)
=
>
{
e
.
emit
(
)
;
self
.
recover_stmt
(
)
;
break
;
}
}
}
let
hi
=
self
.
span
.
hi
;
try
!
(
self
.
expect
(
&
token
:
:
CloseDelim
(
token
:
:
Brace
)
)
)
;
return
Ok
(
self
.
mk_expr
(
lo
hi
ExprKind
:
:
Struct
(
pth
fields
base
)
attrs
)
)
;
}
fn
parse_or_use_outer_attributes
(
&
mut
self
already_parsed_attrs
:
Option
<
ThinVec
<
Attribute
>
>
)
-
>
PResult
<
'
a
ThinVec
<
Attribute
>
>
{
if
let
Some
(
attrs
)
=
already_parsed_attrs
{
Ok
(
attrs
)
}
else
{
self
.
parse_outer_attributes
(
)
.
map
(
|
a
|
a
.
into
(
)
)
}
}
pub
fn
parse_block_expr
(
&
mut
self
lo
:
BytePos
blk_mode
:
BlockCheckMode
outer_attrs
:
ThinVec
<
Attribute
>
)
-
>
PResult
<
'
a
P
<
Expr
>
>
{
try
!
(
self
.
expect
(
&
token
:
:
OpenDelim
(
token
:
:
Brace
)
)
)
;
let
mut
attrs
=
outer_attrs
;
attrs
.
extend
(
try
!
(
self
.
parse_inner_attributes
(
)
)
)
;
let
blk
=
try
!
(
self
.
parse_block_tail
(
lo
blk_mode
)
)
;
return
Ok
(
self
.
mk_expr
(
blk
.
span
.
lo
blk
.
span
.
hi
ExprKind
:
:
Block
(
blk
)
attrs
)
)
;
}
pub
fn
parse_dot_or_call_expr
(
&
mut
self
already_parsed_attrs
:
Option
<
ThinVec
<
Attribute
>
>
)
-
>
PResult
<
'
a
P
<
Expr
>
>
{
let
attrs
=
try
!
(
self
.
parse_or_use_outer_attributes
(
already_parsed_attrs
)
)
;
let
b
=
self
.
parse_bottom_expr
(
)
;
let
(
span
b
)
=
try
!
(
self
.
interpolated_or_expr_span
(
b
)
)
;
self
.
parse_dot_or_call_expr_with
(
b
span
.
lo
attrs
)
}
pub
fn
parse_dot_or_call_expr_with
(
&
mut
self
e0
:
P
<
Expr
>
lo
:
BytePos
mut
attrs
:
ThinVec
<
Attribute
>
)
-
>
PResult
<
'
a
P
<
Expr
>
>
{
self
.
parse_dot_or_call_expr_with_
(
e0
lo
)
.
map
(
|
expr
|
expr
.
map
(
|
mut
expr
|
{
attrs
.
extend
:
:
<
Vec
<
_
>
>
(
expr
.
attrs
.
into
(
)
)
;
expr
.
attrs
=
attrs
;
match
expr
.
node
{
ExprKind
:
:
If
(
.
.
)
|
ExprKind
:
:
IfLet
(
.
.
)
=
>
{
if
!
expr
.
attrs
.
is_empty
(
)
{
let
span
=
expr
.
attrs
[
0
]
.
span
;
self
.
span_err
(
span
"
attributes
are
not
yet
allowed
on
if
\
expressions
"
)
;
}
}
_
=
>
{
}
}
expr
}
)
)
}
fn
parse_dot_suffix
(
&
mut
self
ident
:
Ident
ident_span
:
Span
self_value
:
P
<
Expr
>
lo
:
BytePos
)
-
>
PResult
<
'
a
P
<
Expr
>
>
{
let
(
_
tys
bindings
)
=
if
self
.
eat
(
&
token
:
:
ModSep
)
{
try
!
(
self
.
expect_lt
(
)
)
;
try
!
(
self
.
parse_generic_values_after_lt
(
)
)
}
else
{
(
Vec
:
:
new
(
)
Vec
:
:
new
(
)
Vec
:
:
new
(
)
)
}
;
if
!
bindings
.
is_empty
(
)
{
let
prev_span
=
self
.
prev_span
;
self
.
span_err
(
prev_span
"
type
bindings
are
only
permitted
on
trait
paths
"
)
;
}
Ok
(
match
self
.
token
{
token
:
:
OpenDelim
(
token
:
:
Paren
)
=
>
{
let
mut
es
=
try
!
(
self
.
parse_unspanned_seq
(
&
token
:
:
OpenDelim
(
token
:
:
Paren
)
&
token
:
:
CloseDelim
(
token
:
:
Paren
)
SeqSep
:
:
trailing_allowed
(
token
:
:
Comma
)
|
p
|
Ok
(
try
!
(
p
.
parse_expr
(
)
)
)
)
)
;
let
hi
=
self
.
prev_span
.
hi
;
es
.
insert
(
0
self_value
)
;
let
id
=
spanned
(
ident_span
.
lo
ident_span
.
hi
ident
)
;
let
nd
=
self
.
mk_method_call
(
id
tys
es
)
;
self
.
mk_expr
(
lo
hi
nd
ThinVec
:
:
new
(
)
)
}
_
=
>
{
if
!
tys
.
is_empty
(
)
{
let
prev_span
=
self
.
prev_span
;
self
.
span_err
(
prev_span
"
field
expressions
may
not
\
have
type
parameters
"
)
;
}
let
id
=
spanned
(
ident_span
.
lo
ident_span
.
hi
ident
)
;
let
field
=
self
.
mk_field
(
self_value
id
)
;
self
.
mk_expr
(
lo
ident_span
.
hi
field
ThinVec
:
:
new
(
)
)
}
}
)
}
fn
parse_dot_or_call_expr_with_
(
&
mut
self
e0
:
P
<
Expr
>
lo
:
BytePos
)
-
>
PResult
<
'
a
P
<
Expr
>
>
{
let
mut
e
=
e0
;
let
mut
hi
;
loop
{
while
self
.
eat
(
&
token
:
:
Question
)
{
let
hi
=
self
.
prev_span
.
hi
;
e
=
self
.
mk_expr
(
lo
hi
ExprKind
:
:
Try
(
e
)
ThinVec
:
:
new
(
)
)
;
}
if
self
.
eat
(
&
token
:
:
Dot
)
{
match
self
.
token
{
token
:
:
Ident
(
i
)
=
>
{
let
dot_pos
=
self
.
prev_span
.
hi
;
hi
=
self
.
span
.
hi
;
self
.
bump
(
)
;
e
=
try
!
(
self
.
parse_dot_suffix
(
i
mk_sp
(
dot_pos
hi
)
e
lo
)
)
;
}
token
:
:
Literal
(
token
:
:
Integer
(
n
)
suf
)
=
>
{
let
sp
=
self
.
span
;
self
.
expect_no_suffix
(
sp
"
tuple
index
"
suf
)
;
let
dot
=
self
.
prev_span
.
hi
;
hi
=
self
.
span
.
hi
;
self
.
bump
(
)
;
let
index
=
n
.
as_str
(
)
.
parse
:
:
<
usize
>
(
)
.
ok
(
)
;
match
index
{
Some
(
n
)
=
>
{
let
id
=
spanned
(
dot
hi
n
)
;
let
field
=
self
.
mk_tup_field
(
e
id
)
;
e
=
self
.
mk_expr
(
lo
hi
field
ThinVec
:
:
new
(
)
)
;
}
None
=
>
{
let
prev_span
=
self
.
prev_span
;
self
.
span_err
(
prev_span
"
invalid
tuple
or
tuple
struct
index
"
)
;
}
}
}
token
:
:
Literal
(
token
:
:
Float
(
n
)
_suf
)
=
>
{
self
.
bump
(
)
;
let
prev_span
=
self
.
prev_span
;
let
fstr
=
n
.
as_str
(
)
;
let
mut
err
=
self
.
diagnostic
(
)
.
struct_span_err
(
prev_span
&
format
!
(
"
unexpected
token
:
{
}
"
n
.
as_str
(
)
)
)
;
if
fstr
.
chars
(
)
.
all
(
|
x
|
"
0123456789
.
"
.
contains
(
x
)
)
{
let
float
=
match
fstr
.
parse
:
:
<
f64
>
(
)
.
ok
(
)
{
Some
(
f
)
=
>
f
None
=
>
continue
}
;
err
.
help
(
&
format
!
(
"
try
parenthesizing
the
first
index
;
e
.
g
.
(
foo
.
{
}
)
{
}
"
float
.
trunc
(
)
as
usize
format
!
(
"
.
{
}
"
fstr
.
splitn
(
2
"
.
"
)
.
last
(
)
.
unwrap
(
)
)
)
)
;
}
return
Err
(
err
)
;
}
_
=
>
{
let
actual
=
self
.
this_token_to_string
(
)
;
self
.
span_err
(
self
.
span
&
format
!
(
"
unexpected
token
:
{
}
"
actual
)
)
;
let
dot_pos
=
self
.
prev_span
.
hi
;
e
=
try
!
(
self
.
parse_dot_suffix
(
keywords
:
:
Invalid
.
ident
(
)
mk_sp
(
dot_pos
dot_pos
)
e
lo
)
)
;
}
}
continue
;
}
if
self
.
expr_is_complete
(
&
e
)
{
break
;
}
match
self
.
token
{
token
:
:
OpenDelim
(
token
:
:
Paren
)
=
>
{
let
es
=
try
!
(
self
.
parse_unspanned_seq
(
&
token
:
:
OpenDelim
(
token
:
:
Paren
)
&
token
:
:
CloseDelim
(
token
:
:
Paren
)
SeqSep
:
:
trailing_allowed
(
token
:
:
Comma
)
|
p
|
Ok
(
try
!
(
p
.
parse_expr
(
)
)
)
)
)
;
hi
=
self
.
prev_span
.
hi
;
let
nd
=
self
.
mk_call
(
e
es
)
;
e
=
self
.
mk_expr
(
lo
hi
nd
ThinVec
:
:
new
(
)
)
;
}
token
:
:
OpenDelim
(
token
:
:
Bracket
)
=
>
{
self
.
bump
(
)
;
let
ix
=
try
!
(
self
.
parse_expr
(
)
)
;
hi
=
self
.
span
.
hi
;
try
!
(
self
.
expect
(
&
token
:
:
CloseDelim
(
token
:
:
Bracket
)
)
)
;
let
index
=
self
.
mk_index
(
e
ix
)
;
e
=
self
.
mk_expr
(
lo
hi
index
ThinVec
:
:
new
(
)
)
}
_
=
>
return
Ok
(
e
)
}
}
return
Ok
(
e
)
;
}
fn
parse_unquoted
(
&
mut
self
)
-
>
PResult
<
'
a
TokenTree
>
{
let
mut
sp
=
self
.
span
;
let
name
=
match
self
.
token
{
token
:
:
Dollar
=
>
{
self
.
bump
(
)
;
if
self
.
token
=
=
token
:
:
OpenDelim
(
token
:
:
Paren
)
{
let
Spanned
{
node
:
seq
span
:
seq_span
}
=
try
!
(
self
.
parse_seq
(
&
token
:
:
OpenDelim
(
token
:
:
Paren
)
&
token
:
:
CloseDelim
(
token
:
:
Paren
)
SeqSep
:
:
none
(
)
|
p
|
p
.
parse_token_tree
(
)
)
)
;
let
(
sep
repeat
)
=
try
!
(
self
.
parse_sep_and_kleene_op
(
)
)
;
let
name_num
=
macro_parser
:
:
count_names
(
&
seq
)
;
return
Ok
(
TokenTree
:
:
Sequence
(
mk_sp
(
sp
.
lo
seq_span
.
hi
)
Rc
:
:
new
(
SequenceRepetition
{
tts
:
seq
separator
:
sep
op
:
repeat
num_captures
:
name_num
}
)
)
)
;
}
else
if
self
.
token
.
is_keyword
(
keywords
:
:
Crate
)
{
let
ident
=
match
self
.
token
{
token
:
:
Ident
(
id
)
=
>
ast
:
:
Ident
{
name
:
token
:
:
intern
(
"
crate
"
)
.
.
id
}
_
=
>
unreachable
!
(
)
}
;
self
.
bump
(
)
;
return
Ok
(
TokenTree
:
:
Token
(
sp
token
:
:
Ident
(
ident
)
)
)
;
}
else
{
sp
=
mk_sp
(
sp
.
lo
self
.
span
.
hi
)
;
self
.
parse_ident
(
)
.
unwrap_or_else
(
|
mut
e
|
{
e
.
emit
(
)
;
keywords
:
:
Invalid
.
ident
(
)
}
)
}
}
token
:
:
SubstNt
(
name
)
=
>
{
self
.
bump
(
)
;
name
}
_
=
>
unreachable
!
(
)
}
;
if
self
.
token
=
=
token
:
:
Colon
&
&
self
.
look_ahead
(
1
|
t
|
t
.
is_ident
(
)
&
&
!
t
.
is_any_keyword
(
)
)
{
self
.
bump
(
)
;
sp
=
mk_sp
(
sp
.
lo
self
.
span
.
hi
)
;
let
nt_kind
=
try
!
(
self
.
parse_ident
(
)
)
;
Ok
(
TokenTree
:
:
Token
(
sp
MatchNt
(
name
nt_kind
)
)
)
}
else
{
Ok
(
TokenTree
:
:
Token
(
sp
SubstNt
(
name
)
)
)
}
}
pub
fn
check_unknown_macro_variable
(
&
mut
self
)
{
if
self
.
quote_depth
=
=
0
&
&
!
self
.
parsing_token_tree
{
match
self
.
token
{
token
:
:
SubstNt
(
name
)
=
>
self
.
fatal
(
&
format
!
(
"
unknown
macro
variable
{
}
"
name
)
)
.
emit
(
)
_
=
>
{
}
}
}
}
pub
fn
parse_sep_and_kleene_op
(
&
mut
self
)
-
>
PResult
<
'
a
(
Option
<
token
:
:
Token
>
tokenstream
:
:
KleeneOp
)
>
{
fn
parse_kleene_op
<
'
a
>
(
parser
:
&
mut
Parser
<
'
a
>
)
-
>
PResult
<
'
a
Option
<
tokenstream
:
:
KleeneOp
>
>
{
match
parser
.
token
{
token
:
:
BinOp
(
token
:
:
Star
)
=
>
{
parser
.
bump
(
)
;
Ok
(
Some
(
tokenstream
:
:
KleeneOp
:
:
ZeroOrMore
)
)
}
token
:
:
BinOp
(
token
:
:
Plus
)
=
>
{
parser
.
bump
(
)
;
Ok
(
Some
(
tokenstream
:
:
KleeneOp
:
:
OneOrMore
)
)
}
_
=
>
Ok
(
None
)
}
}
;
if
let
Some
(
kleene_op
)
=
try
!
(
parse_kleene_op
(
self
)
)
{
return
Ok
(
(
None
kleene_op
)
)
;
}
let
separator
=
self
.
bump_and_get
(
)
;
match
try
!
(
parse_kleene_op
(
self
)
)
{
Some
(
zerok
)
=
>
Ok
(
(
Some
(
separator
)
zerok
)
)
None
=
>
return
Err
(
self
.
fatal
(
"
expected
*
or
+
"
)
)
}
}
pub
fn
parse_token_tree
(
&
mut
self
)
-
>
PResult
<
'
a
TokenTree
>
{
match
self
.
token
{
token
:
:
Eof
=
>
{
let
mut
err
:
DiagnosticBuilder
<
'
a
>
=
self
.
diagnostic
(
)
.
struct_span_err
(
self
.
span
"
this
file
contains
an
un
-
closed
delimiter
"
)
;
for
&
(
_
sp
)
in
&
self
.
open_braces
{
err
.
span_help
(
sp
"
did
you
mean
to
close
this
delimiter
?
"
)
;
}
Err
(
err
)
}
token
:
:
OpenDelim
(
delim
)
=
>
{
if
self
.
tts
.
last
(
)
.
map
(
|
&
(
_
i
)
|
i
=
=
1
)
.
unwrap_or
(
false
)
{
let
tt
=
self
.
tts
.
pop
(
)
.
unwrap
(
)
.
0
;
self
.
bump
(
)
;
return
Ok
(
if
self
.
allow_interpolated_tts
{
TokenTree
:
:
Token
(
tt
.
span
(
)
token
:
:
Interpolated
(
Rc
:
:
new
(
token
:
:
NtTT
(
tt
)
)
)
)
}
else
{
tt
}
)
;
}
let
parsing_token_tree
=
:
:
std
:
:
mem
:
:
replace
(
&
mut
self
.
parsing_token_tree
true
)
;
let
pre_span
=
self
.
span
;
self
.
open_braces
.
push
(
(
delim
self
.
span
)
)
;
let
open_span
=
self
.
span
;
self
.
bump
(
)
;
let
tts
=
self
.
parse_seq_to_before_tokens
(
&
[
&
token
:
:
CloseDelim
(
token
:
:
Brace
)
&
token
:
:
CloseDelim
(
token
:
:
Paren
)
&
token
:
:
CloseDelim
(
token
:
:
Bracket
)
]
SeqSep
:
:
none
(
)
|
p
|
p
.
parse_token_tree
(
)
|
mut
e
|
e
.
emit
(
)
)
;
let
close_span
=
self
.
span
;
let
span
=
Span
{
hi
:
close_span
.
hi
.
.
pre_span
}
;
match
self
.
token
{
token
:
:
CloseDelim
(
d
)
if
d
=
=
delim
=
>
{
self
.
open_braces
.
pop
(
)
.
unwrap
(
)
;
self
.
bump
(
)
;
}
token
:
:
CloseDelim
(
other
)
=
>
{
let
token_str
=
self
.
this_token_to_string
(
)
;
let
mut
err
=
self
.
diagnostic
(
)
.
struct_span_err
(
self
.
span
&
format
!
(
"
incorrect
close
delimiter
:
{
}
"
token_str
)
)
;
if
let
Some
(
&
(
_
sp
)
)
=
self
.
open_braces
.
last
(
)
{
err
.
span_note
(
sp
"
unclosed
delimiter
"
)
;
}
;
err
.
emit
(
)
;
self
.
open_braces
.
pop
(
)
.
unwrap
(
)
;
if
!
self
.
open_braces
.
iter
(
)
.
any
(
|
&
(
b
_
)
|
b
=
=
other
)
{
self
.
bump
(
)
;
}
}
token
:
:
Eof
=
>
{
}
_
=
>
{
}
}
self
.
parsing_token_tree
=
parsing_token_tree
;
Ok
(
TokenTree
:
:
Delimited
(
span
Rc
:
:
new
(
Delimited
{
delim
:
delim
open_span
:
open_span
tts
:
tts
close_span
:
close_span
}
)
)
)
}
token
:
:
CloseDelim
(
_
)
=
>
{
let
token_str
=
self
.
this_token_to_string
(
)
;
let
err
=
self
.
diagnostic
(
)
.
struct_span_err
(
self
.
span
&
format
!
(
"
unexpected
close
delimiter
:
{
}
"
token_str
)
)
;
Err
(
err
)
}
token
:
:
Dollar
|
token
:
:
SubstNt
(
.
.
)
if
self
.
quote_depth
>
0
=
>
{
self
.
parse_unquoted
(
)
}
_
=
>
{
Ok
(
TokenTree
:
:
Token
(
self
.
span
self
.
bump_and_get
(
)
)
)
}
}
}
pub
fn
parse_all_token_trees
(
&
mut
self
)
-
>
PResult
<
'
a
Vec
<
TokenTree
>
>
{
let
mut
tts
=
Vec
:
:
new
(
)
;
while
self
.
token
!
=
token
:
:
Eof
{
tts
.
push
(
try
!
(
self
.
parse_token_tree
(
)
)
)
;
}
Ok
(
tts
)
}
pub
fn
parse_prefix_expr
(
&
mut
self
already_parsed_attrs
:
Option
<
ThinVec
<
Attribute
>
>
)
-
>
PResult
<
'
a
P
<
Expr
>
>
{
let
attrs
=
try
!
(
self
.
parse_or_use_outer_attributes
(
already_parsed_attrs
)
)
;
let
lo
=
self
.
span
.
lo
;
let
hi
;
let
ex
=
match
self
.
token
{
token
:
:
Not
=
>
{
self
.
bump
(
)
;
let
e
=
self
.
parse_prefix_expr
(
None
)
;
let
(
span
e
)
=
try
!
(
self
.
interpolated_or_expr_span
(
e
)
)
;
hi
=
span
.
hi
;
self
.
mk_unary
(
UnOp
:
:
Not
e
)
}
token
:
:
BinOp
(
token
:
:
Minus
)
=
>
{
self
.
bump
(
)
;
let
e
=
self
.
parse_prefix_expr
(
None
)
;
let
(
span
e
)
=
try
!
(
self
.
interpolated_or_expr_span
(
e
)
)
;
hi
=
span
.
hi
;
self
.
mk_unary
(
UnOp
:
:
Neg
e
)
}
token
:
:
BinOp
(
token
:
:
Star
)
=
>
{
self
.
bump
(
)
;
let
e
=
self
.
parse_prefix_expr
(
None
)
;
let
(
span
e
)
=
try
!
(
self
.
interpolated_or_expr_span
(
e
)
)
;
hi
=
span
.
hi
;
self
.
mk_unary
(
UnOp
:
:
Deref
e
)
}
token
:
:
BinOp
(
token
:
:
And
)
|
token
:
:
AndAnd
=
>
{
try
!
(
self
.
expect_and
(
)
)
;
let
m
=
try
!
(
self
.
parse_mutability
(
)
)
;
let
e
=
self
.
parse_prefix_expr
(
None
)
;
let
(
span
e
)
=
try
!
(
self
.
interpolated_or_expr_span
(
e
)
)
;
hi
=
span
.
hi
;
ExprKind
:
:
AddrOf
(
m
e
)
}
token
:
:
Ident
(
.
.
)
if
self
.
token
.
is_keyword
(
keywords
:
:
In
)
=
>
{
self
.
bump
(
)
;
let
place
=
try
!
(
self
.
parse_expr_res
(
RESTRICTION_NO_STRUCT_LITERAL
None
)
)
;
let
blk
=
try
!
(
self
.
parse_block
(
)
)
;
let
span
=
blk
.
span
;
hi
=
span
.
hi
;
let
blk_expr
=
self
.
mk_expr
(
span
.
lo
hi
ExprKind
:
:
Block
(
blk
)
ThinVec
:
:
new
(
)
)
;
ExprKind
:
:
InPlace
(
place
blk_expr
)
}
token
:
:
Ident
(
.
.
)
if
self
.
token
.
is_keyword
(
keywords
:
:
Box
)
=
>
{
self
.
bump
(
)
;
let
e
=
self
.
parse_prefix_expr
(
None
)
;
let
(
span
e
)
=
try
!
(
self
.
interpolated_or_expr_span
(
e
)
)
;
hi
=
span
.
hi
;
ExprKind
:
:
Box
(
e
)
}
_
=
>
return
self
.
parse_dot_or_call_expr
(
Some
(
attrs
)
)
}
;
return
Ok
(
self
.
mk_expr
(
lo
hi
ex
attrs
)
)
;
}
pub
fn
parse_assoc_expr
(
&
mut
self
already_parsed_attrs
:
Option
<
ThinVec
<
Attribute
>
>
)
-
>
PResult
<
'
a
P
<
Expr
>
>
{
self
.
parse_assoc_expr_with
(
0
already_parsed_attrs
.
into
(
)
)
}
pub
fn
parse_assoc_expr_with
(
&
mut
self
min_prec
:
usize
lhs
:
LhsExpr
)
-
>
PResult
<
'
a
P
<
Expr
>
>
{
let
mut
lhs
=
if
let
LhsExpr
:
:
AlreadyParsed
(
expr
)
=
lhs
{
expr
}
else
{
let
attrs
=
match
lhs
{
LhsExpr
:
:
AttributesParsed
(
attrs
)
=
>
Some
(
attrs
)
_
=
>
None
}
;
if
self
.
token
=
=
token
:
:
DotDot
|
|
self
.
token
=
=
token
:
:
DotDotDot
{
return
self
.
parse_prefix_range_expr
(
attrs
)
;
}
else
{
try
!
(
self
.
parse_prefix_expr
(
attrs
)
)
}
}
;
if
self
.
expr_is_complete
(
&
lhs
)
{
return
Ok
(
lhs
)
;
}
self
.
expected_tokens
.
push
(
TokenType
:
:
Operator
)
;
while
let
Some
(
op
)
=
AssocOp
:
:
from_token
(
&
self
.
token
)
{
let
lhs_span
=
if
self
.
prev_token_kind
=
=
PrevTokenKind
:
:
Interpolated
{
self
.
prev_span
}
else
{
lhs
.
span
}
;
let
cur_op_span
=
self
.
span
;
let
restrictions
=
if
op
.
is_assign_like
(
)
{
self
.
restrictions
&
RESTRICTION_NO_STRUCT_LITERAL
}
else
{
self
.
restrictions
}
;
if
op
.
precedence
(
)
<
min_prec
{
break
;
}
self
.
bump
(
)
;
if
op
.
is_comparison
(
)
{
self
.
check_no_chained_comparison
(
&
lhs
&
op
)
;
}
if
op
=
=
AssocOp
:
:
As
{
let
rhs
=
try
!
(
self
.
parse_ty
(
)
)
;
let
(
lo
hi
)
=
(
lhs_span
.
lo
rhs
.
span
.
hi
)
;
lhs
=
self
.
mk_expr
(
lo
hi
ExprKind
:
:
Cast
(
lhs
rhs
)
ThinVec
:
:
new
(
)
)
;
continue
}
else
if
op
=
=
AssocOp
:
:
Colon
{
let
rhs
=
try
!
(
self
.
parse_ty
(
)
)
;
let
(
lo
hi
)
=
(
lhs_span
.
lo
rhs
.
span
.
hi
)
;
lhs
=
self
.
mk_expr
(
lo
hi
ExprKind
:
:
Type
(
lhs
rhs
)
ThinVec
:
:
new
(
)
)
;
continue
}
else
if
op
=
=
AssocOp
:
:
DotDot
|
|
op
=
=
AssocOp
:
:
DotDotDot
{
let
rhs
=
if
self
.
is_at_start_of_range_notation_rhs
(
)
{
Some
(
try
!
(
self
.
parse_assoc_expr_with
(
op
.
precedence
(
)
+
1
LhsExpr
:
:
NotYetParsed
)
)
)
}
else
{
None
}
;
let
(
lhs_span
rhs_span
)
=
(
lhs
.
span
if
let
Some
(
ref
x
)
=
rhs
{
x
.
span
}
else
{
cur_op_span
}
)
;
let
limits
=
if
op
=
=
AssocOp
:
:
DotDot
{
RangeLimits
:
:
HalfOpen
}
else
{
RangeLimits
:
:
Closed
}
;
let
r
=
try
!
(
self
.
mk_range
(
Some
(
lhs
)
rhs
limits
)
)
;
lhs
=
self
.
mk_expr
(
lhs_span
.
lo
rhs_span
.
hi
r
ThinVec
:
:
new
(
)
)
;
break
}
let
rhs
=
try
!
(
match
op
.
fixity
(
)
{
Fixity
:
:
Right
=
>
self
.
with_res
(
restrictions
-
RESTRICTION_STMT_EXPR
|
this
|
{
this
.
parse_assoc_expr_with
(
op
.
precedence
(
)
LhsExpr
:
:
NotYetParsed
)
}
)
Fixity
:
:
Left
=
>
self
.
with_res
(
restrictions
-
RESTRICTION_STMT_EXPR
|
this
|
{
this
.
parse_assoc_expr_with
(
op
.
precedence
(
)
+
1
LhsExpr
:
:
NotYetParsed
)
}
)
/
/
We
currently
have
no
non
-
associative
operators
that
are
not
handled
above
by
/
/
the
special
cases
.
The
code
is
here
only
for
future
convenience
.
Fixity
:
:
None
=
>
self
.
with_res
(
restrictions
-
RESTRICTION_STMT_EXPR
|
this
|
{
this
.
parse_assoc_expr_with
(
op
.
precedence
(
)
+
1
LhsExpr
:
:
NotYetParsed
)
}
)
}
)
;
let
(
lo
hi
)
=
(
lhs_span
.
lo
rhs
.
span
.
hi
)
;
lhs
=
match
op
{
AssocOp
:
:
Add
|
AssocOp
:
:
Subtract
|
AssocOp
:
:
Multiply
|
AssocOp
:
:
Divide
|
AssocOp
:
:
Modulus
|
AssocOp
:
:
LAnd
|
AssocOp
:
:
LOr
|
AssocOp
:
:
BitXor
|
AssocOp
:
:
BitAnd
|
AssocOp
:
:
BitOr
|
AssocOp
:
:
ShiftLeft
|
AssocOp
:
:
ShiftRight
|
AssocOp
:
:
Equal
|
AssocOp
:
:
Less
|
AssocOp
:
:
LessEqual
|
AssocOp
:
:
NotEqual
|
AssocOp
:
:
Greater
|
AssocOp
:
:
GreaterEqual
=
>
{
let
ast_op
=
op
.
to_ast_binop
(
)
.
unwrap
(
)
;
let
binary
=
self
.
mk_binary
(
codemap
:
:
respan
(
cur_op_span
ast_op
)
lhs
rhs
)
;
self
.
mk_expr
(
lo
hi
binary
ThinVec
:
:
new
(
)
)
}
AssocOp
:
:
Assign
=
>
self
.
mk_expr
(
lo
hi
ExprKind
:
:
Assign
(
lhs
rhs
)
ThinVec
:
:
new
(
)
)
AssocOp
:
:
Inplace
=
>
self
.
mk_expr
(
lo
hi
ExprKind
:
:
InPlace
(
lhs
rhs
)
ThinVec
:
:
new
(
)
)
AssocOp
:
:
AssignOp
(
k
)
=
>
{
let
aop
=
match
k
{
token
:
:
Plus
=
>
BinOpKind
:
:
Add
token
:
:
Minus
=
>
BinOpKind
:
:
Sub
token
:
:
Star
=
>
BinOpKind
:
:
Mul
token
:
:
Slash
=
>
BinOpKind
:
:
Div
token
:
:
Percent
=
>
BinOpKind
:
:
Rem
token
:
:
Caret
=
>
BinOpKind
:
:
BitXor
token
:
:
And
=
>
BinOpKind
:
:
BitAnd
token
:
:
Or
=
>
BinOpKind
:
:
BitOr
token
:
:
Shl
=
>
BinOpKind
:
:
Shl
token
:
:
Shr
=
>
BinOpKind
:
:
Shr
}
;
let
aopexpr
=
self
.
mk_assign_op
(
codemap
:
:
respan
(
cur_op_span
aop
)
lhs
rhs
)
;
self
.
mk_expr
(
lo
hi
aopexpr
ThinVec
:
:
new
(
)
)
}
AssocOp
:
:
As
|
AssocOp
:
:
Colon
|
AssocOp
:
:
DotDot
|
AssocOp
:
:
DotDotDot
=
>
{
self
.
bug
(
"
As
Colon
DotDot
or
DotDotDot
branch
reached
"
)
}
}
;
if
op
.
fixity
(
)
=
=
Fixity
:
:
None
{
break
}
}
Ok
(
lhs
)
}
fn
check_no_chained_comparison
(
&
mut
self
lhs
:
&
Expr
outer_op
:
&
AssocOp
)
{
debug_assert
!
(
outer_op
.
is_comparison
(
)
)
;
match
lhs
.
node
{
ExprKind
:
:
Binary
(
op
_
_
)
if
op
.
node
.
is_comparison
(
)
=
>
{
let
op_span
=
mk_sp
(
op
.
span
.
lo
self
.
span
.
hi
)
;
let
mut
err
=
self
.
diagnostic
(
)
.
struct_span_err
(
op_span
"
chained
comparison
operators
require
parentheses
"
)
;
if
op
.
node
=
=
BinOpKind
:
:
Lt
&
&
*
outer_op
=
=
AssocOp
:
:
Greater
{
err
.
help
(
"
use
:
:
<
.
.
.
>
instead
of
<
.
.
.
>
if
you
meant
to
specify
type
arguments
"
)
;
}
err
.
emit
(
)
;
}
_
=
>
{
}
}
}
fn
parse_prefix_range_expr
(
&
mut
self
already_parsed_attrs
:
Option
<
ThinVec
<
Attribute
>
>
)
-
>
PResult
<
'
a
P
<
Expr
>
>
{
debug_assert
!
(
self
.
token
=
=
token
:
:
DotDot
|
|
self
.
token
=
=
token
:
:
DotDotDot
)
;
let
tok
=
self
.
token
.
clone
(
)
;
let
attrs
=
try
!
(
self
.
parse_or_use_outer_attributes
(
already_parsed_attrs
)
)
;
let
lo
=
self
.
span
.
lo
;
let
mut
hi
=
self
.
span
.
hi
;
self
.
bump
(
)
;
let
opt_end
=
if
self
.
is_at_start_of_range_notation_rhs
(
)
{
let
next_prec
=
AssocOp
:
:
from_token
(
&
tok
)
.
unwrap
(
)
.
precedence
(
)
+
1
;
Some
(
try
!
(
self
.
parse_assoc_expr_with
(
next_prec
LhsExpr
:
:
NotYetParsed
)
.
map
(
|
x
|
{
hi
=
x
.
span
.
hi
;
x
}
)
)
)
}
else
{
None
}
;
let
limits
=
if
tok
=
=
token
:
:
DotDot
{
RangeLimits
:
:
HalfOpen
}
else
{
RangeLimits
:
:
Closed
}
;
let
r
=
try
!
(
self
.
mk_range
(
None
opt_end
limits
)
)
;
Ok
(
self
.
mk_expr
(
lo
hi
r
attrs
)
)
}
fn
is_at_start_of_range_notation_rhs
(
&
self
)
-
>
bool
{
if
self
.
token
.
can_begin_expr
(
)
{
if
self
.
token
=
=
token
:
:
OpenDelim
(
token
:
:
Brace
)
{
return
!
self
.
restrictions
.
contains
(
RESTRICTION_NO_STRUCT_LITERAL
)
;
}
true
}
else
{
false
}
}
pub
fn
parse_if_expr
(
&
mut
self
attrs
:
ThinVec
<
Attribute
>
)
-
>
PResult
<
'
a
P
<
Expr
>
>
{
if
self
.
check_keyword
(
keywords
:
:
Let
)
{
return
self
.
parse_if_let_expr
(
attrs
)
;
}
let
lo
=
self
.
prev_span
.
lo
;
let
cond
=
try
!
(
self
.
parse_expr_res
(
RESTRICTION_NO_STRUCT_LITERAL
None
)
)
;
let
thn
=
try
!
(
self
.
parse_block
(
)
)
;
let
mut
els
:
Option
<
P
<
Expr
>
>
=
None
;
let
mut
hi
=
thn
.
span
.
hi
;
if
self
.
eat_keyword
(
keywords
:
:
Else
)
{
let
elexpr
=
try
!
(
self
.
parse_else_expr
(
)
)
;
hi
=
elexpr
.
span
.
hi
;
els
=
Some
(
elexpr
)
;
}
Ok
(
self
.
mk_expr
(
lo
hi
ExprKind
:
:
If
(
cond
thn
els
)
attrs
)
)
}
pub
fn
parse_if_let_expr
(
&
mut
self
attrs
:
ThinVec
<
Attribute
>
)
-
>
PResult
<
'
a
P
<
Expr
>
>
{
let
lo
=
self
.
prev_span
.
lo
;
try
!
(
self
.
expect_keyword
(
keywords
:
:
Let
)
)
;
let
pat
=
try
!
(
self
.
parse_pat
(
)
)
;
try
!
(
self
.
expect
(
&
token
:
:
Eq
)
)
;
let
expr
=
try
!
(
self
.
parse_expr_res
(
RESTRICTION_NO_STRUCT_LITERAL
None
)
)
;
let
thn
=
try
!
(
self
.
parse_block
(
)
)
;
let
(
hi
els
)
=
if
self
.
eat_keyword
(
keywords
:
:
Else
)
{
let
expr
=
try
!
(
self
.
parse_else_expr
(
)
)
;
(
expr
.
span
.
hi
Some
(
expr
)
)
}
else
{
(
thn
.
span
.
hi
None
)
}
;
Ok
(
self
.
mk_expr
(
lo
hi
ExprKind
:
:
IfLet
(
pat
expr
thn
els
)
attrs
)
)
}
pub
fn
parse_lambda_expr
(
&
mut
self
lo
:
BytePos
capture_clause
:
CaptureBy
attrs
:
ThinVec
<
Attribute
>
)
-
>
PResult
<
'
a
P
<
Expr
>
>
{
let
decl
=
try
!
(
self
.
parse_fn_block_decl
(
)
)
;
let
decl_hi
=
self
.
prev_span
.
hi
;
let
body
=
match
decl
.
output
{
FunctionRetTy
:
:
Default
(
_
)
=
>
try
!
(
self
.
parse_expr
(
)
)
_
=
>
{
let
body_lo
=
self
.
span
.
lo
;
try
!
(
self
.
parse_block_expr
(
body_lo
BlockCheckMode
:
:
Default
ThinVec
:
:
new
(
)
)
)
}
}
;
Ok
(
self
.
mk_expr
(
lo
body
.
span
.
hi
ExprKind
:
:
Closure
(
capture_clause
decl
body
mk_sp
(
lo
decl_hi
)
)
attrs
)
)
}
pub
fn
parse_else_expr
(
&
mut
self
)
-
>
PResult
<
'
a
P
<
Expr
>
>
{
if
self
.
eat_keyword
(
keywords
:
:
If
)
{
return
self
.
parse_if_expr
(
ThinVec
:
:
new
(
)
)
;
}
else
{
let
blk
=
try
!
(
self
.
parse_block
(
)
)
;
return
Ok
(
self
.
mk_expr
(
blk
.
span
.
lo
blk
.
span
.
hi
ExprKind
:
:
Block
(
blk
)
ThinVec
:
:
new
(
)
)
)
;
}
}
pub
fn
parse_for_expr
(
&
mut
self
opt_ident
:
Option
<
ast
:
:
SpannedIdent
>
span_lo
:
BytePos
mut
attrs
:
ThinVec
<
Attribute
>
)
-
>
PResult
<
'
a
P
<
Expr
>
>
{
let
pat
=
try
!
(
self
.
parse_pat
(
)
)
;
try
!
(
self
.
expect_keyword
(
keywords
:
:
In
)
)
;
let
expr
=
try
!
(
self
.
parse_expr_res
(
Restrictions
:
:
restriction_no_struct_literal
(
)
None
)
)
;
let
(
iattrs
loop_block
)
=
try
!
(
self
.
parse_inner_attrs_and_block
(
)
)
;
attrs
.
extend
(
iattrs
)
;
let
hi
=
self
.
prev_span
.
hi
;
Ok
(
self
.
mk_expr
(
span_lo
hi
ExprKind
:
:
ForLoop
(
pat
expr
loop_block
opt_ident
)
attrs
)
)
}
pub
fn
parse_while_expr
(
&
mut
self
opt_ident
:
Option
<
ast
:
:
SpannedIdent
>
span_lo
:
BytePos
mut
attrs
:
ThinVec
<
Attribute
>
)
-
>
PResult
<
'
a
P
<
Expr
>
>
{
if
self
.
token
.
is_keyword
(
keywords
:
:
Let
)
{
return
self
.
parse_while_let_expr
(
opt_ident
span_lo
attrs
)
;
}
let
cond
=
try
!
(
self
.
parse_expr_res
(
Restrictions
:
:
restriction_no_struct_literal
(
)
None
)
)
;
let
(
iattrs
body
)
=
try
!
(
self
.
parse_inner_attrs_and_block
(
)
)
;
attrs
.
extend
(
iattrs
)
;
let
hi
=
body
.
span
.
hi
;
return
Ok
(
self
.
mk_expr
(
span_lo
hi
ExprKind
:
:
While
(
cond
body
opt_ident
)
attrs
)
)
;
}
pub
fn
parse_while_let_expr
(
&
mut
self
opt_ident
:
Option
<
ast
:
:
SpannedIdent
>
span_lo
:
BytePos
mut
attrs
:
ThinVec
<
Attribute
>
)
-
>
PResult
<
'
a
P
<
Expr
>
>
{
try
!
(
self
.
expect_keyword
(
keywords
:
:
Let
)
)
;
let
pat
=
try
!
(
self
.
parse_pat
(
)
)
;
try
!
(
self
.
expect
(
&
token
:
:
Eq
)
)
;
let
expr
=
try
!
(
self
.
parse_expr_res
(
Restrictions
:
:
restriction_no_struct_literal
(
)
None
)
)
;
let
(
iattrs
body
)
=
try
!
(
self
.
parse_inner_attrs_and_block
(
)
)
;
attrs
.
extend
(
iattrs
)
;
let
hi
=
body
.
span
.
hi
;
return
Ok
(
self
.
mk_expr
(
span_lo
hi
ExprKind
:
:
WhileLet
(
pat
expr
body
opt_ident
)
attrs
)
)
;
}
pub
fn
parse_loop_expr
(
&
mut
self
opt_ident
:
Option
<
ast
:
:
SpannedIdent
>
span_lo
:
BytePos
mut
attrs
:
ThinVec
<
Attribute
>
)
-
>
PResult
<
'
a
P
<
Expr
>
>
{
let
(
iattrs
body
)
=
try
!
(
self
.
parse_inner_attrs_and_block
(
)
)
;
attrs
.
extend
(
iattrs
)
;
let
hi
=
body
.
span
.
hi
;
Ok
(
self
.
mk_expr
(
span_lo
hi
ExprKind
:
:
Loop
(
body
opt_ident
)
attrs
)
)
}
fn
parse_match_expr
(
&
mut
self
mut
attrs
:
ThinVec
<
Attribute
>
)
-
>
PResult
<
'
a
P
<
Expr
>
>
{
let
match_span
=
self
.
prev_span
;
let
lo
=
self
.
prev_span
.
lo
;
let
discriminant
=
try
!
(
self
.
parse_expr_res
(
RESTRICTION_NO_STRUCT_LITERAL
None
)
)
;
if
let
Err
(
mut
e
)
=
self
.
expect
(
&
token
:
:
OpenDelim
(
token
:
:
Brace
)
)
{
if
self
.
token
=
=
token
:
:
Token
:
:
Semi
{
e
.
span_note
(
match_span
"
did
you
mean
to
remove
this
match
keyword
?
"
)
;
}
return
Err
(
e
)
}
attrs
.
extend
(
try
!
(
self
.
parse_inner_attributes
(
)
)
)
;
let
mut
arms
:
Vec
<
Arm
>
=
Vec
:
:
new
(
)
;
while
self
.
token
!
=
token
:
:
CloseDelim
(
token
:
:
Brace
)
{
match
self
.
parse_arm
(
)
{
Ok
(
arm
)
=
>
arms
.
push
(
arm
)
Err
(
mut
e
)
=
>
{
e
.
emit
(
)
;
self
.
recover_stmt
(
)
;
let
hi
=
self
.
span
.
hi
;
if
self
.
token
=
=
token
:
:
CloseDelim
(
token
:
:
Brace
)
{
self
.
bump
(
)
;
}
return
Ok
(
self
.
mk_expr
(
lo
hi
ExprKind
:
:
Match
(
discriminant
arms
)
attrs
)
)
;
}
}
}
let
hi
=
self
.
span
.
hi
;
self
.
bump
(
)
;
return
Ok
(
self
.
mk_expr
(
lo
hi
ExprKind
:
:
Match
(
discriminant
arms
)
attrs
)
)
;
}
pub
fn
parse_arm
(
&
mut
self
)
-
>
PResult
<
'
a
Arm
>
{
maybe_whole
!
(
self
NtArm
|
x
|
x
)
;
let
attrs
=
try
!
(
self
.
parse_outer_attributes
(
)
)
;
let
pats
=
try
!
(
self
.
parse_pats
(
)
)
;
let
mut
guard
=
None
;
if
self
.
eat_keyword
(
keywords
:
:
If
)
{
guard
=
Some
(
try
!
(
self
.
parse_expr
(
)
)
)
;
}
try
!
(
self
.
expect
(
&
token
:
:
FatArrow
)
)
;
let
expr
=
try
!
(
self
.
parse_expr_res
(
RESTRICTION_STMT_EXPR
None
)
)
;
let
require_comma
=
!
classify
:
:
expr_is_simple_block
(
&
expr
)
&
&
self
.
token
!
=
token
:
:
CloseDelim
(
token
:
:
Brace
)
;
if
require_comma
{
try
!
(
self
.
expect_one_of
(
&
[
token
:
:
Comma
]
&
[
token
:
:
CloseDelim
(
token
:
:
Brace
)
]
)
)
;
}
else
{
self
.
eat
(
&
token
:
:
Comma
)
;
}
Ok
(
ast
:
:
Arm
{
attrs
:
attrs
pats
:
pats
guard
:
guard
body
:
expr
}
)
}
pub
fn
parse_expr
(
&
mut
self
)
-
>
PResult
<
'
a
P
<
Expr
>
>
{
self
.
parse_expr_res
(
Restrictions
:
:
empty
(
)
None
)
}
pub
fn
with_res
<
F
T
>
(
&
mut
self
r
:
Restrictions
f
:
F
)
-
>
T
where
F
:
FnOnce
(
&
mut
Self
)
-
>
T
{
let
old
=
self
.
restrictions
;
self
.
restrictions
=
r
;
let
r
=
f
(
self
)
;
self
.
restrictions
=
old
;
return
r
;
}
pub
fn
parse_expr_res
(
&
mut
self
r
:
Restrictions
already_parsed_attrs
:
Option
<
ThinVec
<
Attribute
>
>
)
-
>
PResult
<
'
a
P
<
Expr
>
>
{
self
.
with_res
(
r
|
this
|
this
.
parse_assoc_expr
(
already_parsed_attrs
)
)
}
fn
parse_initializer
(
&
mut
self
)
-
>
PResult
<
'
a
Option
<
P
<
Expr
>
>
>
{
if
self
.
check
(
&
token
:
:
Eq
)
{
self
.
bump
(
)
;
Ok
(
Some
(
try
!
(
self
.
parse_expr
(
)
)
)
)
}
else
{
Ok
(
None
)
}
}
fn
parse_pats
(
&
mut
self
)
-
>
PResult
<
'
a
Vec
<
P
<
Pat
>
>
>
{
let
mut
pats
=
Vec
:
:
new
(
)
;
loop
{
pats
.
push
(
try
!
(
self
.
parse_pat
(
)
)
)
;
if
self
.
check
(
&
token
:
:
BinOp
(
token
:
:
Or
)
)
{
self
.
bump
(
)
;
}
else
{
return
Ok
(
pats
)
;
}
}
;
}
fn
parse_pat_tuple_elements
(
&
mut
self
unary_needs_comma
:
bool
)
-
>
PResult
<
'
a
(
Vec
<
P
<
Pat
>
>
Option
<
usize
>
)
>
{
let
mut
fields
=
vec
!
[
]
;
let
mut
ddpos
=
None
;
while
!
self
.
check
(
&
token
:
:
CloseDelim
(
token
:
:
Paren
)
)
{
if
ddpos
.
is_none
(
)
&
&
self
.
eat
(
&
token
:
:
DotDot
)
{
ddpos
=
Some
(
fields
.
len
(
)
)
;
if
self
.
eat
(
&
token
:
:
Comma
)
{
fields
.
push
(
try
!
(
self
.
parse_pat
(
)
)
)
;
}
}
else
if
ddpos
.
is_some
(
)
&
&
self
.
eat
(
&
token
:
:
DotDot
)
{
self
.
span_err
(
self
.
prev_span
"
.
.
can
only
be
used
once
per
\
tuple
or
tuple
struct
pattern
"
)
;
}
else
{
fields
.
push
(
try
!
(
self
.
parse_pat
(
)
)
)
;
}
if
!
self
.
check
(
&
token
:
:
CloseDelim
(
token
:
:
Paren
)
)
|
|
(
unary_needs_comma
&
&
fields
.
len
(
)
=
=
1
&
&
ddpos
.
is_none
(
)
)
{
try
!
(
self
.
expect
(
&
token
:
:
Comma
)
)
;
}
}
Ok
(
(
fields
ddpos
)
)
}
fn
parse_pat_vec_elements
(
&
mut
self
)
-
>
PResult
<
'
a
(
Vec
<
P
<
Pat
>
>
Option
<
P
<
Pat
>
>
Vec
<
P
<
Pat
>
>
)
>
{
let
mut
before
=
Vec
:
:
new
(
)
;
let
mut
slice
=
None
;
let
mut
after
=
Vec
:
:
new
(
)
;
let
mut
first
=
true
;
let
mut
before_slice
=
true
;
while
self
.
token
!
=
token
:
:
CloseDelim
(
token
:
:
Bracket
)
{
if
first
{
first
=
false
;
}
else
{
try
!
(
self
.
expect
(
&
token
:
:
Comma
)
)
;
if
self
.
token
=
=
token
:
:
CloseDelim
(
token
:
:
Bracket
)
&
&
(
before_slice
|
|
!
after
.
is_empty
(
)
)
{
break
}
}
if
before_slice
{
if
self
.
check
(
&
token
:
:
DotDot
)
{
self
.
bump
(
)
;
if
self
.
check
(
&
token
:
:
Comma
)
|
|
self
.
check
(
&
token
:
:
CloseDelim
(
token
:
:
Bracket
)
)
{
slice
=
Some
(
P
(
ast
:
:
Pat
{
id
:
ast
:
:
DUMMY_NODE_ID
node
:
PatKind
:
:
Wild
span
:
self
.
span
}
)
)
;
before_slice
=
false
;
}
continue
}
}
let
subpat
=
try
!
(
self
.
parse_pat
(
)
)
;
if
before_slice
&
&
self
.
check
(
&
token
:
:
DotDot
)
{
self
.
bump
(
)
;
slice
=
Some
(
subpat
)
;
before_slice
=
false
;
}
else
if
before_slice
{
before
.
push
(
subpat
)
;
}
else
{
after
.
push
(
subpat
)
;
}
}
Ok
(
(
before
slice
after
)
)
}
fn
parse_pat_fields
(
&
mut
self
)
-
>
PResult
<
'
a
(
Vec
<
codemap
:
:
Spanned
<
ast
:
:
FieldPat
>
>
bool
)
>
{
let
mut
fields
=
Vec
:
:
new
(
)
;
let
mut
etc
=
false
;
let
mut
first
=
true
;
while
self
.
token
!
=
token
:
:
CloseDelim
(
token
:
:
Brace
)
{
if
first
{
first
=
false
;
}
else
{
try
!
(
self
.
expect
(
&
token
:
:
Comma
)
)
;
if
self
.
check
(
&
token
:
:
CloseDelim
(
token
:
:
Brace
)
)
{
break
}
}
let
lo
=
self
.
span
.
lo
;
let
hi
;
if
self
.
check
(
&
token
:
:
DotDot
)
{
self
.
bump
(
)
;
if
self
.
token
!
=
token
:
:
CloseDelim
(
token
:
:
Brace
)
{
let
token_str
=
self
.
this_token_to_string
(
)
;
return
Err
(
self
.
fatal
(
&
format
!
(
"
expected
{
}
found
{
}
"
"
}
"
token_str
)
)
)
}
etc
=
true
;
break
;
}
let
(
subpat
fieldname
is_shorthand
)
=
if
self
.
look_ahead
(
1
|
t
|
t
=
=
&
token
:
:
Colon
)
{
let
fieldname
=
try
!
(
self
.
parse_field_name
(
)
)
;
self
.
bump
(
)
;
let
pat
=
try
!
(
self
.
parse_pat
(
)
)
;
hi
=
pat
.
span
.
hi
;
(
pat
fieldname
false
)
}
else
{
let
is_box
=
self
.
eat_keyword
(
keywords
:
:
Box
)
;
let
boxed_span_lo
=
self
.
span
.
lo
;
let
is_ref
=
self
.
eat_keyword
(
keywords
:
:
Ref
)
;
let
is_mut
=
self
.
eat_keyword
(
keywords
:
:
Mut
)
;
let
fieldname
=
try
!
(
self
.
parse_ident
(
)
)
;
hi
=
self
.
prev_span
.
hi
;
let
bind_type
=
match
(
is_ref
is_mut
)
{
(
true
true
)
=
>
BindingMode
:
:
ByRef
(
Mutability
:
:
Mutable
)
(
true
false
)
=
>
BindingMode
:
:
ByRef
(
Mutability
:
:
Immutable
)
(
false
true
)
=
>
BindingMode
:
:
ByValue
(
Mutability
:
:
Mutable
)
(
false
false
)
=
>
BindingMode
:
:
ByValue
(
Mutability
:
:
Immutable
)
}
;
let
fieldpath
=
codemap
:
:
Spanned
{
span
:
self
.
prev_span
node
:
fieldname
}
;
let
fieldpat
=
P
(
ast
:
:
Pat
{
id
:
ast
:
:
DUMMY_NODE_ID
node
:
PatKind
:
:
Ident
(
bind_type
fieldpath
None
)
span
:
mk_sp
(
boxed_span_lo
hi
)
}
)
;
let
subpat
=
if
is_box
{
P
(
ast
:
:
Pat
{
id
:
ast
:
:
DUMMY_NODE_ID
node
:
PatKind
:
:
Box
(
fieldpat
)
span
:
mk_sp
(
lo
hi
)
}
)
}
else
{
fieldpat
}
;
(
subpat
fieldname
true
)
}
;
fields
.
push
(
codemap
:
:
Spanned
{
span
:
mk_sp
(
lo
hi
)
node
:
ast
:
:
FieldPat
{
ident
:
fieldname
pat
:
subpat
is_shorthand
:
is_shorthand
}
}
)
;
}
return
Ok
(
(
fields
etc
)
)
;
}
fn
parse_pat_range_end
(
&
mut
self
)
-
>
PResult
<
'
a
P
<
Expr
>
>
{
if
self
.
token
.
is_path_start
(
)
{
let
lo
=
self
.
span
.
lo
;
let
(
qself
path
)
=
if
self
.
eat_lt
(
)
{
let
(
qself
path
)
=
try
!
(
self
.
parse_qualified_path
(
PathStyle
:
:
Expr
)
)
;
(
Some
(
qself
)
path
)
}
else
{
(
None
try
!
(
self
.
parse_path
(
PathStyle
:
:
Expr
)
)
)
}
;
let
hi
=
self
.
prev_span
.
hi
;
Ok
(
self
.
mk_expr
(
lo
hi
ExprKind
:
:
Path
(
qself
path
)
ThinVec
:
:
new
(
)
)
)
}
else
{
self
.
parse_pat_literal_maybe_minus
(
)
}
}
pub
fn
parse_pat
(
&
mut
self
)
-
>
PResult
<
'
a
P
<
Pat
>
>
{
maybe_whole
!
(
self
NtPat
|
x
|
x
)
;
let
lo
=
self
.
span
.
lo
;
let
pat
;
match
self
.
token
{
token
:
:
Underscore
=
>
{
self
.
bump
(
)
;
pat
=
PatKind
:
:
Wild
;
}
token
:
:
BinOp
(
token
:
:
And
)
|
token
:
:
AndAnd
=
>
{
try
!
(
self
.
expect_and
(
)
)
;
let
mutbl
=
try
!
(
self
.
parse_mutability
(
)
)
;
if
let
token
:
:
Lifetime
(
ident
)
=
self
.
token
{
return
Err
(
self
.
fatal
(
&
format
!
(
"
unexpected
lifetime
{
}
in
pattern
"
ident
)
)
)
;
}
let
subpat
=
try
!
(
self
.
parse_pat
(
)
)
;
pat
=
PatKind
:
:
Ref
(
subpat
mutbl
)
;
}
token
:
:
OpenDelim
(
token
:
:
Paren
)
=
>
{
self
.
bump
(
)
;
let
(
fields
ddpos
)
=
try
!
(
self
.
parse_pat_tuple_elements
(
true
)
)
;
try
!
(
self
.
expect
(
&
token
:
:
CloseDelim
(
token
:
:
Paren
)
)
)
;
pat
=
PatKind
:
:
Tuple
(
fields
ddpos
)
;
}
token
:
:
OpenDelim
(
token
:
:
Bracket
)
=
>
{
self
.
bump
(
)
;
let
(
before
slice
after
)
=
try
!
(
self
.
parse_pat_vec_elements
(
)
)
;
try
!
(
self
.
expect
(
&
token
:
:
CloseDelim
(
token
:
:
Bracket
)
)
)
;
pat
=
PatKind
:
:
Slice
(
before
slice
after
)
;
}
_
=
>
if
self
.
eat_keyword
(
keywords
:
:
Mut
)
{
pat
=
try
!
(
self
.
parse_pat_ident
(
BindingMode
:
:
ByValue
(
Mutability
:
:
Mutable
)
)
)
;
}
else
if
self
.
eat_keyword
(
keywords
:
:
Ref
)
{
let
mutbl
=
try
!
(
self
.
parse_mutability
(
)
)
;
pat
=
try
!
(
self
.
parse_pat_ident
(
BindingMode
:
:
ByRef
(
mutbl
)
)
)
;
}
else
if
self
.
eat_keyword
(
keywords
:
:
Box
)
{
let
subpat
=
try
!
(
self
.
parse_pat
(
)
)
;
pat
=
PatKind
:
:
Box
(
subpat
)
;
}
else
if
self
.
token
.
is_ident
(
)
&
&
!
self
.
token
.
is_any_keyword
(
)
&
&
self
.
look_ahead
(
1
|
t
|
match
*
t
{
token
:
:
OpenDelim
(
token
:
:
Paren
)
|
token
:
:
OpenDelim
(
token
:
:
Brace
)
|
token
:
:
DotDotDot
|
token
:
:
ModSep
|
token
:
:
Not
=
>
false
_
=
>
true
}
)
{
let
binding_mode
=
BindingMode
:
:
ByValue
(
Mutability
:
:
Immutable
)
;
pat
=
try
!
(
self
.
parse_pat_ident
(
binding_mode
)
)
;
}
else
if
self
.
token
.
is_path_start
(
)
{
let
(
qself
path
)
=
if
self
.
eat_lt
(
)
{
let
(
qself
path
)
=
try
!
(
self
.
parse_qualified_path
(
PathStyle
:
:
Expr
)
)
;
(
Some
(
qself
)
path
)
}
else
{
(
None
try
!
(
self
.
parse_path
(
PathStyle
:
:
Expr
)
)
)
}
;
match
self
.
token
{
token
:
:
Not
if
qself
.
is_none
(
)
=
>
{
self
.
bump
(
)
;
let
delim
=
try
!
(
self
.
expect_open_delim
(
)
)
;
let
tts
=
try
!
(
self
.
parse_seq_to_end
(
&
token
:
:
CloseDelim
(
delim
)
SeqSep
:
:
none
(
)
|
p
|
p
.
parse_token_tree
(
)
)
)
;
let
mac
=
spanned
(
lo
self
.
prev_span
.
hi
Mac_
{
path
:
path
tts
:
tts
}
)
;
pat
=
PatKind
:
:
Mac
(
mac
)
;
}
token
:
:
DotDotDot
=
>
{
let
hi
=
self
.
prev_span
.
hi
;
let
begin
=
self
.
mk_expr
(
lo
hi
ExprKind
:
:
Path
(
qself
path
)
ThinVec
:
:
new
(
)
)
;
self
.
bump
(
)
;
let
end
=
try
!
(
self
.
parse_pat_range_end
(
)
)
;
pat
=
PatKind
:
:
Range
(
begin
end
)
;
}
token
:
:
OpenDelim
(
token
:
:
Brace
)
=
>
{
if
qself
.
is_some
(
)
{
return
Err
(
self
.
fatal
(
"
unexpected
{
after
qualified
path
"
)
)
;
}
self
.
bump
(
)
;
let
(
fields
etc
)
=
self
.
parse_pat_fields
(
)
.
unwrap_or_else
(
|
mut
e
|
{
e
.
emit
(
)
;
self
.
recover_stmt
(
)
;
(
vec
!
[
]
false
)
}
)
;
self
.
bump
(
)
;
pat
=
PatKind
:
:
Struct
(
path
fields
etc
)
;
}
token
:
:
OpenDelim
(
token
:
:
Paren
)
=
>
{
if
qself
.
is_some
(
)
{
return
Err
(
self
.
fatal
(
"
unexpected
(
after
qualified
path
"
)
)
;
}
self
.
bump
(
)
;
let
(
fields
ddpos
)
=
try
!
(
self
.
parse_pat_tuple_elements
(
false
)
)
;
try
!
(
self
.
expect
(
&
token
:
:
CloseDelim
(
token
:
:
Paren
)
)
)
;
pat
=
PatKind
:
:
TupleStruct
(
path
fields
ddpos
)
}
_
=
>
pat
=
PatKind
:
:
Path
(
qself
path
)
}
}
else
{
match
self
.
parse_pat_literal_maybe_minus
(
)
{
Ok
(
begin
)
=
>
{
if
self
.
eat
(
&
token
:
:
DotDotDot
)
{
let
end
=
try
!
(
self
.
parse_pat_range_end
(
)
)
;
pat
=
PatKind
:
:
Range
(
begin
end
)
;
}
else
{
pat
=
PatKind
:
:
Lit
(
begin
)
;
}
}
Err
(
mut
err
)
=
>
{
self
.
cancel
(
&
mut
err
)
;
let
msg
=
format
!
(
"
expected
pattern
found
{
}
"
self
.
this_token_descr
(
)
)
;
return
Err
(
self
.
fatal
(
&
msg
)
)
;
}
}
}
}
let
hi
=
self
.
prev_span
.
hi
;
Ok
(
P
(
ast
:
:
Pat
{
id
:
ast
:
:
DUMMY_NODE_ID
node
:
pat
span
:
mk_sp
(
lo
hi
)
}
)
)
}
fn
parse_pat_ident
(
&
mut
self
binding_mode
:
ast
:
:
BindingMode
)
-
>
PResult
<
'
a
PatKind
>
{
let
ident
=
try
!
(
self
.
parse_ident
(
)
)
;
let
prev_span
=
self
.
prev_span
;
let
name
=
codemap
:
:
Spanned
{
span
:
prev_span
node
:
ident
}
;
let
sub
=
if
self
.
eat
(
&
token
:
:
At
)
{
Some
(
try
!
(
self
.
parse_pat
(
)
)
)
}
else
{
None
}
;
if
self
.
token
=
=
token
:
:
OpenDelim
(
token
:
:
Paren
)
{
return
Err
(
self
.
span_fatal
(
self
.
prev_span
"
expected
identifier
found
enum
pattern
"
)
)
}
Ok
(
PatKind
:
:
Ident
(
binding_mode
name
sub
)
)
}
fn
parse_local
(
&
mut
self
attrs
:
ThinVec
<
Attribute
>
)
-
>
PResult
<
'
a
P
<
Local
>
>
{
let
lo
=
self
.
span
.
lo
;
let
pat
=
try
!
(
self
.
parse_pat
(
)
)
;
let
mut
ty
=
None
;
if
self
.
eat
(
&
token
:
:
Colon
)
{
ty
=
Some
(
try
!
(
self
.
parse_ty_sum
(
)
)
)
;
}
let
init
=
try
!
(
self
.
parse_initializer
(
)
)
;
Ok
(
P
(
ast
:
:
Local
{
ty
:
ty
pat
:
pat
init
:
init
id
:
ast
:
:
DUMMY_NODE_ID
span
:
mk_sp
(
lo
self
.
prev_span
.
hi
)
attrs
:
attrs
}
)
)
}
fn
parse_name_and_ty
(
&
mut
self
lo
:
BytePos
vis
:
Visibility
attrs
:
Vec
<
Attribute
>
)
-
>
PResult
<
'
a
StructField
>
{
let
name
=
try
!
(
self
.
parse_ident
(
)
)
;
try
!
(
self
.
expect
(
&
token
:
:
Colon
)
)
;
let
ty
=
try
!
(
self
.
parse_ty_sum
(
)
)
;
Ok
(
StructField
{
span
:
mk_sp
(
lo
self
.
prev_span
.
hi
)
ident
:
Some
(
name
)
vis
:
vis
id
:
ast
:
:
DUMMY_NODE_ID
ty
:
ty
attrs
:
attrs
}
)
}
fn
expected_item_err
(
&
self
attrs
:
&
[
Attribute
]
)
{
let
message
=
match
attrs
.
last
(
)
{
Some
(
&
Attribute
{
node
:
ast
:
:
Attribute_
{
is_sugared_doc
:
true
.
.
}
.
.
}
)
=
>
{
"
expected
item
after
doc
comment
"
}
_
=
>
"
expected
item
after
attributes
"
}
;
self
.
span_err
(
self
.
prev_span
message
)
;
}
pub
fn
parse_stmt
(
&
mut
self
)
-
>
PResult
<
'
a
Option
<
Stmt
>
>
{
Ok
(
self
.
parse_stmt_
(
true
)
)
}
fn
recover_stmt
(
&
mut
self
)
{
self
.
recover_stmt_
(
SemiColonMode
:
:
Ignore
)
}
fn
recover_stmt_
(
&
mut
self
break_on_semi
:
SemiColonMode
)
{
let
mut
brace_depth
=
0
;
let
mut
bracket_depth
=
0
;
debug
!
(
"
recover_stmt_
enter
loop
"
)
;
loop
{
debug
!
(
"
recover_stmt_
loop
{
:
?
}
"
self
.
token
)
;
match
self
.
token
{
token
:
:
OpenDelim
(
token
:
:
DelimToken
:
:
Brace
)
=
>
{
brace_depth
+
=
1
;
self
.
bump
(
)
;
}
token
:
:
OpenDelim
(
token
:
:
DelimToken
:
:
Bracket
)
=
>
{
bracket_depth
+
=
1
;
self
.
bump
(
)
;
}
token
:
:
CloseDelim
(
token
:
:
DelimToken
:
:
Brace
)
=
>
{
if
brace_depth
=
=
0
{
debug
!
(
"
recover_stmt_
return
-
close
delim
{
:
?
}
"
self
.
token
)
;
return
;
}
brace_depth
-
=
1
;
self
.
bump
(
)
;
}
token
:
:
CloseDelim
(
token
:
:
DelimToken
:
:
Bracket
)
=
>
{
bracket_depth
-
=
1
;
if
bracket_depth
<
0
{
bracket_depth
=
0
;
}
self
.
bump
(
)
;
}
token
:
:
Eof
=
>
{
debug
!
(
"
recover_stmt_
return
-
Eof
"
)
;
return
;
}
token
:
:
Semi
=
>
{
self
.
bump
(
)
;
if
break_on_semi
=
=
SemiColonMode
:
:
Break
&
&
brace_depth
=
=
0
&
&
bracket_depth
=
=
0
{
debug
!
(
"
recover_stmt_
return
-
Semi
"
)
;
return
;
}
}
_
=
>
{
self
.
bump
(
)
}
}
}
}
fn
parse_stmt_
(
&
mut
self
macro_legacy_warnings
:
bool
)
-
>
Option
<
Stmt
>
{
self
.
parse_stmt_without_recovery
(
macro_legacy_warnings
)
.
unwrap_or_else
(
|
mut
e
|
{
e
.
emit
(
)
;
self
.
recover_stmt_
(
SemiColonMode
:
:
Break
)
;
None
}
)
}
fn
is_union_item
(
&
mut
self
)
-
>
bool
{
self
.
token
.
is_keyword
(
keywords
:
:
Union
)
&
&
self
.
look_ahead
(
1
|
t
|
t
.
is_ident
(
)
&
&
!
t
.
is_any_keyword
(
)
)
}
fn
parse_stmt_without_recovery
(
&
mut
self
macro_legacy_warnings
:
bool
)
-
>
PResult
<
'
a
Option
<
Stmt
>
>
{
maybe_whole
!
(
self
NtStmt
|
x
|
Some
(
x
)
)
;
let
attrs
=
try
!
(
self
.
parse_outer_attributes
(
)
)
;
let
lo
=
self
.
span
.
lo
;
Ok
(
Some
(
if
self
.
eat_keyword
(
keywords
:
:
Let
)
{
Stmt
{
id
:
ast
:
:
DUMMY_NODE_ID
node
:
StmtKind
:
:
Local
(
try
!
(
self
.
parse_local
(
attrs
.
into
(
)
)
)
)
span
:
mk_sp
(
lo
self
.
prev_span
.
hi
)
}
}
else
if
self
.
token
.
is_path_start
(
)
&
&
!
self
.
token
.
is_qpath_start
(
)
&
&
!
self
.
is_union_item
(
)
{
let
pth
=
try
!
(
self
.
parse_path
(
PathStyle
:
:
Expr
)
)
;
if
!
self
.
eat
(
&
token
:
:
Not
)
{
let
expr
=
if
self
.
check
(
&
token
:
:
OpenDelim
(
token
:
:
Brace
)
)
{
try
!
(
self
.
parse_struct_expr
(
lo
pth
ThinVec
:
:
new
(
)
)
)
}
else
{
let
hi
=
self
.
prev_span
.
hi
;
self
.
mk_expr
(
lo
hi
ExprKind
:
:
Path
(
None
pth
)
ThinVec
:
:
new
(
)
)
}
;
let
expr
=
try
!
(
self
.
with_res
(
Restrictions
:
:
restriction_stmt_expr
(
)
|
this
|
{
let
expr
=
try
!
(
this
.
parse_dot_or_call_expr_with
(
expr
lo
attrs
.
into
(
)
)
)
;
this
.
parse_assoc_expr_with
(
0
LhsExpr
:
:
AlreadyParsed
(
expr
)
)
}
)
)
;
return
Ok
(
Some
(
Stmt
{
id
:
ast
:
:
DUMMY_NODE_ID
node
:
StmtKind
:
:
Expr
(
expr
)
span
:
mk_sp
(
lo
self
.
prev_span
.
hi
)
}
)
)
;
}
let
id
=
match
self
.
token
{
token
:
:
OpenDelim
(
_
)
=
>
keywords
:
:
Invalid
.
ident
(
)
_
=
>
try
!
(
self
.
parse_ident
(
)
)
}
;
let
delim
=
match
self
.
token
{
token
:
:
OpenDelim
(
delim
)
=
>
delim
_
=
>
{
let
ident_str
=
if
id
.
name
=
=
keywords
:
:
Invalid
.
name
(
)
{
"
identifier
"
}
else
{
"
"
}
;
let
tok_str
=
self
.
this_token_to_string
(
)
;
return
Err
(
self
.
fatal
(
&
format
!
(
"
expected
{
}
(
or
{
{
found
{
}
"
ident_str
tok_str
)
)
)
}
}
;
let
tts
=
try
!
(
self
.
parse_unspanned_seq
(
&
token
:
:
OpenDelim
(
delim
)
&
token
:
:
CloseDelim
(
delim
)
SeqSep
:
:
none
(
)
|
p
|
p
.
parse_token_tree
(
)
)
)
;
let
hi
=
self
.
prev_span
.
hi
;
let
style
=
if
delim
=
=
token
:
:
Brace
{
MacStmtStyle
:
:
Braces
}
else
{
MacStmtStyle
:
:
NoBraces
}
;
if
id
.
name
=
=
keywords
:
:
Invalid
.
name
(
)
{
let
mac
=
spanned
(
lo
hi
Mac_
{
path
:
pth
tts
:
tts
}
)
;
let
node
=
if
delim
=
=
token
:
:
Brace
|
|
self
.
token
=
=
token
:
:
Semi
|
|
self
.
token
=
=
token
:
:
Eof
{
StmtKind
:
:
Mac
(
P
(
(
mac
style
attrs
.
into
(
)
)
)
)
}
else
if
macro_legacy_warnings
&
&
self
.
token
.
can_begin_expr
(
)
&
&
match
self
.
token
{
token
:
:
OpenDelim
(
token
:
:
Paren
)
|
token
:
:
OpenDelim
(
token
:
:
Bracket
)
|
token
:
:
BinOp
(
token
:
:
Minus
)
|
token
:
:
BinOp
(
token
:
:
Star
)
|
token
:
:
BinOp
(
token
:
:
And
)
|
token
:
:
BinOp
(
token
:
:
Or
)
|
token
:
:
AndAnd
|
token
:
:
OrOr
|
token
:
:
DotDot
|
token
:
:
DotDotDot
=
>
false
_
=
>
true
}
{
self
.
warn_missing_semicolon
(
)
;
StmtKind
:
:
Mac
(
P
(
(
mac
style
attrs
.
into
(
)
)
)
)
}
else
{
let
e
=
self
.
mk_mac_expr
(
lo
hi
mac
.
node
ThinVec
:
:
new
(
)
)
;
let
e
=
try
!
(
self
.
parse_dot_or_call_expr_with
(
e
lo
attrs
.
into
(
)
)
)
;
let
e
=
try
!
(
self
.
parse_assoc_expr_with
(
0
LhsExpr
:
:
AlreadyParsed
(
e
)
)
)
;
StmtKind
:
:
Expr
(
e
)
}
;
Stmt
{
id
:
ast
:
:
DUMMY_NODE_ID
span
:
mk_sp
(
lo
hi
)
node
:
node
}
}
else
{
if
style
!
=
MacStmtStyle
:
:
Braces
{
if
!
self
.
eat
(
&
token
:
:
Semi
)
{
self
.
span_err
(
self
.
prev_span
"
macros
that
expand
to
items
must
\
either
be
surrounded
with
braces
or
\
followed
by
a
semicolon
"
)
;
}
}
Stmt
{
id
:
ast
:
:
DUMMY_NODE_ID
span
:
mk_sp
(
lo
hi
)
node
:
StmtKind
:
:
Item
(
{
self
.
mk_item
(
lo
hi
id
ItemKind
:
:
Mac
(
spanned
(
lo
hi
Mac_
{
path
:
pth
tts
:
tts
}
)
)
Visibility
:
:
Inherited
attrs
)
}
)
}
}
}
else
{
let
restrictions
=
self
.
restrictions
|
Restrictions
:
:
no_noninline_mod
(
)
;
match
try
!
(
self
.
with_res
(
restrictions
|
this
|
this
.
parse_item_
(
attrs
.
clone
(
)
false
true
)
)
)
{
Some
(
i
)
=
>
Stmt
{
id
:
ast
:
:
DUMMY_NODE_ID
span
:
mk_sp
(
lo
i
.
span
.
hi
)
node
:
StmtKind
:
:
Item
(
i
)
}
None
=
>
{
let
unused_attrs
=
|
attrs
:
&
[
_
]
s
:
&
mut
Self
|
{
if
attrs
.
len
(
)
>
0
{
if
s
.
prev_token_kind
=
=
PrevTokenKind
:
:
DocComment
{
s
.
span_err_help
(
s
.
prev_span
"
found
a
documentation
comment
that
doesn
'
t
document
anything
"
"
doc
comments
must
come
before
what
they
document
maybe
a
\
comment
was
intended
with
/
/
?
"
)
;
}
else
{
s
.
span_err
(
s
.
span
"
expected
statement
after
outer
attribute
"
)
;
}
}
}
;
if
self
.
token
=
=
token
:
:
Semi
{
unused_attrs
(
&
attrs
self
)
;
self
.
bump
(
)
;
return
Ok
(
None
)
;
}
if
self
.
token
=
=
token
:
:
CloseDelim
(
token
:
:
Brace
)
{
unused_attrs
(
&
attrs
self
)
;
return
Ok
(
None
)
;
}
let
e
=
try
!
(
self
.
parse_expr_res
(
Restrictions
:
:
restriction_stmt_expr
(
)
Some
(
attrs
.
into
(
)
)
)
)
;
Stmt
{
id
:
ast
:
:
DUMMY_NODE_ID
span
:
mk_sp
(
lo
e
.
span
.
hi
)
node
:
StmtKind
:
:
Expr
(
e
)
}
}
}
}
)
)
}
fn
expr_is_complete
(
&
mut
self
e
:
&
Expr
)
-
>
bool
{
self
.
restrictions
.
contains
(
RESTRICTION_STMT_EXPR
)
&
&
!
classify
:
:
expr_requires_semi_to_be_stmt
(
e
)
}
pub
fn
parse_block
(
&
mut
self
)
-
>
PResult
<
'
a
P
<
Block
>
>
{
maybe_whole
!
(
self
NtBlock
|
x
|
x
)
;
let
lo
=
self
.
span
.
lo
;
if
!
self
.
eat
(
&
token
:
:
OpenDelim
(
token
:
:
Brace
)
)
{
let
sp
=
self
.
span
;
let
tok
=
self
.
this_token_to_string
(
)
;
let
mut
e
=
self
.
span_fatal
(
sp
&
format
!
(
"
expected
{
{
found
{
}
"
tok
)
)
;
match
self
.
parse_stmt_without_recovery
(
false
)
{
Ok
(
Some
(
stmt
)
)
=
>
{
let
mut
stmt_span
=
stmt
.
span
;
if
self
.
eat
(
&
token
:
:
Semi
)
{
stmt_span
.
hi
=
self
.
prev_span
.
hi
;
}
e
.
span_help
(
stmt_span
"
try
placing
this
code
inside
a
block
"
)
;
}
Err
(
mut
e
)
=
>
{
self
.
recover_stmt_
(
SemiColonMode
:
:
Break
)
;
self
.
cancel
(
&
mut
e
)
;
}
_
=
>
(
)
}
return
Err
(
e
)
;
}
self
.
parse_block_tail
(
lo
BlockCheckMode
:
:
Default
)
}
fn
parse_inner_attrs_and_block
(
&
mut
self
)
-
>
PResult
<
'
a
(
Vec
<
Attribute
>
P
<
Block
>
)
>
{
maybe_whole
!
(
self
NtBlock
|
x
|
(
Vec
:
:
new
(
)
x
)
)
;
let
lo
=
self
.
span
.
lo
;
try
!
(
self
.
expect
(
&
token
:
:
OpenDelim
(
token
:
:
Brace
)
)
)
;
Ok
(
(
try
!
(
self
.
parse_inner_attributes
(
)
)
try
!
(
self
.
parse_block_tail
(
lo
BlockCheckMode
:
:
Default
)
)
)
)
}
fn
parse_block_tail
(
&
mut
self
lo
:
BytePos
s
:
BlockCheckMode
)
-
>
PResult
<
'
a
P
<
Block
>
>
{
let
mut
stmts
=
vec
!
[
]
;
while
!
self
.
eat
(
&
token
:
:
CloseDelim
(
token
:
:
Brace
)
)
{
if
let
Some
(
stmt
)
=
try
!
(
self
.
parse_full_stmt
(
false
)
)
{
stmts
.
push
(
stmt
)
;
}
else
if
self
.
token
=
=
token
:
:
Eof
{
break
;
}
else
{
continue
;
}
;
}
Ok
(
P
(
ast
:
:
Block
{
stmts
:
stmts
id
:
ast
:
:
DUMMY_NODE_ID
rules
:
s
span
:
mk_sp
(
lo
self
.
prev_span
.
hi
)
}
)
)
}
pub
fn
parse_full_stmt
(
&
mut
self
macro_legacy_warnings
:
bool
)
-
>
PResult
<
'
a
Option
<
Stmt
>
>
{
let
mut
stmt
=
match
self
.
parse_stmt_
(
macro_legacy_warnings
)
{
Some
(
stmt
)
=
>
stmt
None
=
>
return
Ok
(
None
)
}
;
match
stmt
.
node
{
StmtKind
:
:
Expr
(
ref
expr
)
if
self
.
token
!
=
token
:
:
Eof
=
>
{
if
classify
:
:
expr_requires_semi_to_be_stmt
(
expr
)
{
if
let
Err
(
mut
e
)
=
self
.
expect_one_of
(
&
[
]
&
[
token
:
:
Semi
token
:
:
CloseDelim
(
token
:
:
Brace
)
]
)
{
e
.
emit
(
)
;
self
.
recover_stmt
(
)
;
}
}
}
StmtKind
:
:
Local
(
.
.
)
=
>
{
if
macro_legacy_warnings
&
&
self
.
token
!
=
token
:
:
Semi
{
self
.
warn_missing_semicolon
(
)
;
}
else
{
try
!
(
self
.
expect_one_of
(
&
[
token
:
:
Semi
]
&
[
]
)
)
;
}
}
_
=
>
{
}
}
if
self
.
eat
(
&
token
:
:
Semi
)
{
stmt
=
stmt
.
add_trailing_semicolon
(
)
;
}
stmt
.
span
.
hi
=
self
.
prev_span
.
hi
;
Ok
(
Some
(
stmt
)
)
}
fn
warn_missing_semicolon
(
&
self
)
{
self
.
diagnostic
(
)
.
struct_span_warn
(
self
.
span
{
&
format
!
(
"
expected
;
found
{
}
"
self
.
this_token_to_string
(
)
)
}
)
.
note
(
{
"
This
was
erroneously
allowed
and
will
become
a
hard
error
in
a
future
release
"
}
)
.
emit
(
)
;
}
fn
parse_colon_then_ty_param_bounds
(
&
mut
self
mode
:
BoundParsingMode
)
-
>
PResult
<
'
a
TyParamBounds
>
{
if
!
self
.
eat
(
&
token
:
:
Colon
)
{
Ok
(
P
:
:
new
(
)
)
}
else
{
self
.
parse_ty_param_bounds
(
mode
)
}
}
fn
parse_ty_param_bounds
(
&
mut
self
mode
:
BoundParsingMode
)
-
>
PResult
<
'
a
TyParamBounds
>
{
let
mut
result
=
vec
!
[
]
;
loop
{
let
question_span
=
self
.
span
;
let
ate_question
=
self
.
eat
(
&
token
:
:
Question
)
;
match
self
.
token
{
token
:
:
Lifetime
(
lifetime
)
=
>
{
if
ate_question
{
self
.
span_err
(
question_span
"
?
may
only
modify
trait
bounds
not
lifetime
bounds
"
)
;
}
result
.
push
(
RegionTyParamBound
(
ast
:
:
Lifetime
{
id
:
ast
:
:
DUMMY_NODE_ID
span
:
self
.
span
name
:
lifetime
.
name
}
)
)
;
self
.
bump
(
)
;
}
token
:
:
ModSep
|
token
:
:
Ident
(
.
.
)
=
>
{
let
poly_trait_ref
=
try
!
(
self
.
parse_poly_trait_ref
(
)
)
;
let
modifier
=
if
ate_question
{
if
mode
=
=
BoundParsingMode
:
:
Modified
{
TraitBoundModifier
:
:
Maybe
}
else
{
self
.
span_err
(
question_span
"
unexpected
?
"
)
;
TraitBoundModifier
:
:
None
}
}
else
{
TraitBoundModifier
:
:
None
}
;
result
.
push
(
TraitTyParamBound
(
poly_trait_ref
modifier
)
)
}
_
=
>
break
}
if
!
self
.
eat
(
&
token
:
:
BinOp
(
token
:
:
Plus
)
)
{
break
;
}
}
return
Ok
(
P
:
:
from_vec
(
result
)
)
;
}
fn
parse_ty_param
(
&
mut
self
preceding_attrs
:
Vec
<
ast
:
:
Attribute
>
)
-
>
PResult
<
'
a
TyParam
>
{
let
span
=
self
.
span
;
let
ident
=
try
!
(
self
.
parse_ident
(
)
)
;
let
bounds
=
try
!
(
self
.
parse_colon_then_ty_param_bounds
(
BoundParsingMode
:
:
Modified
)
)
;
let
default
=
if
self
.
check
(
&
token
:
:
Eq
)
{
self
.
bump
(
)
;
Some
(
try
!
(
self
.
parse_ty_sum
(
)
)
)
}
else
{
None
}
;
Ok
(
TyParam
{
attrs
:
preceding_attrs
.
into
(
)
ident
:
ident
id
:
ast
:
:
DUMMY_NODE_ID
bounds
:
bounds
default
:
default
span
:
span
}
)
}
pub
fn
parse_generics
(
&
mut
self
)
-
>
PResult
<
'
a
ast
:
:
Generics
>
{
maybe_whole
!
(
self
NtGenerics
|
x
|
x
)
;
let
span_lo
=
self
.
span
.
lo
;
if
self
.
eat
(
&
token
:
:
Lt
)
{
let
mut
attrs
=
vec
!
[
]
;
let
lifetime_defs
=
try
!
(
self
.
parse_lifetime_defs
(
Some
(
&
mut
attrs
)
)
)
;
let
mut
seen_default
=
false
;
let
mut
post_lifetime_attrs
=
Some
(
attrs
)
;
let
ty_params
=
try
!
(
self
.
parse_seq_to_gt
(
Some
(
token
:
:
Comma
)
|
p
|
{
try
!
(
p
.
forbid_lifetime
(
)
)
;
/
/
Move
out
of
post_lifetime_attrs
if
present
.
O
/
w
/
/
not
first
type
param
:
parse
attributes
anew
.
let
attrs
=
match
post_lifetime_attrs
.
as_mut
(
)
{
None
=
>
try
!
(
p
.
parse_outer_attributes
(
)
)
Some
(
attrs
)
=
>
mem
:
:
replace
(
attrs
vec
!
[
]
)
}
;
post_lifetime_attrs
=
None
;
let
ty_param
=
try
!
(
p
.
parse_ty_param
(
attrs
)
)
;
if
ty_param
.
default
.
is_some
(
)
{
seen_default
=
true
;
}
else
if
seen_default
{
let
prev_span
=
p
.
prev_span
;
p
.
span_err
(
prev_span
"
type
parameters
with
a
default
must
be
trailing
"
)
;
}
Ok
(
ty_param
)
}
)
)
;
if
let
Some
(
attrs
)
=
post_lifetime_attrs
{
if
!
attrs
.
is_empty
(
)
{
self
.
span_err
(
attrs
[
0
]
.
span
"
trailing
attribute
after
lifetime
parameters
"
)
;
}
}
Ok
(
ast
:
:
Generics
{
lifetimes
:
lifetime_defs
ty_params
:
ty_params
where_clause
:
WhereClause
{
id
:
ast
:
:
DUMMY_NODE_ID
predicates
:
Vec
:
:
new
(
)
}
span
:
mk_sp
(
span_lo
self
.
prev_span
.
hi
)
}
)
}
else
{
Ok
(
ast
:
:
Generics
:
:
default
(
)
)
}
}
fn
parse_generic_values_after_lt
(
&
mut
self
)
-
>
PResult
<
'
a
(
Vec
<
ast
:
:
Lifetime
>
Vec
<
P
<
Ty
>
>
Vec
<
TypeBinding
>
)
>
{
let
span_lo
=
self
.
span
.
lo
;
let
lifetimes
=
try
!
(
self
.
parse_lifetimes
(
token
:
:
Comma
)
)
;
let
missing_comma
=
!
lifetimes
.
is_empty
(
)
&
&
!
self
.
token
.
is_like_gt
(
)
&
&
self
.
prev_token_kind
!
=
PrevTokenKind
:
:
Comma
;
if
missing_comma
{
let
msg
=
format
!
(
"
expected
or
>
after
lifetime
\
name
found
{
}
"
self
.
this_token_to_string
(
)
)
;
let
mut
err
=
self
.
diagnostic
(
)
.
struct_span_err
(
self
.
span
&
msg
)
;
let
span_hi
=
self
.
span
.
hi
;
let
span_hi
=
match
self
.
parse_ty
(
)
{
Ok
(
.
.
)
=
>
self
.
span
.
hi
Err
(
ref
mut
err
)
=
>
{
self
.
cancel
(
err
)
;
span_hi
}
}
;
let
msg
=
format
!
(
"
did
you
mean
a
single
argument
type
&
'
a
Type
\
or
did
you
mean
the
comma
-
separated
arguments
\
'
a
Type
?
"
)
;
err
.
span_note
(
mk_sp
(
span_lo
span_hi
)
&
msg
)
;
return
Err
(
err
)
;
}
let
(
types
returned
)
=
try
!
(
self
.
parse_seq_to_gt_or_return
(
Some
(
token
:
:
Comma
)
|
p
|
{
try
!
(
p
.
forbid_lifetime
(
)
)
;
if
p
.
look_ahead
(
1
|
t
|
t
=
=
&
token
:
:
Eq
)
{
Ok
(
None
)
}
else
{
Ok
(
Some
(
try
!
(
p
.
parse_ty_sum
(
)
)
)
)
}
}
)
)
;
if
!
returned
{
return
Ok
(
(
lifetimes
types
.
into_vec
(
)
Vec
:
:
new
(
)
)
)
;
}
let
bindings
=
try
!
(
self
.
parse_seq_to_gt
(
Some
(
token
:
:
Comma
)
|
p
|
{
try
!
(
p
.
forbid_lifetime
(
)
)
;
let
lo
=
p
.
span
.
lo
;
let
ident
=
try
!
(
p
.
parse_ident
(
)
)
;
try
!
(
p
.
expect
(
&
token
:
:
Eq
)
)
;
let
ty
=
try
!
(
p
.
parse_ty
(
)
)
;
let
hi
=
ty
.
span
.
hi
;
let
span
=
mk_sp
(
lo
hi
)
;
return
Ok
(
TypeBinding
{
id
:
ast
:
:
DUMMY_NODE_ID
ident
:
ident
ty
:
ty
span
:
span
}
)
;
}
)
)
;
Ok
(
(
lifetimes
types
.
into_vec
(
)
bindings
.
into_vec
(
)
)
)
}
fn
forbid_lifetime
(
&
mut
self
)
-
>
PResult
<
'
a
(
)
>
{
if
self
.
token
.
is_lifetime
(
)
{
let
span
=
self
.
span
;
return
Err
(
self
.
diagnostic
(
)
.
struct_span_err
(
span
"
lifetime
parameters
must
be
\
declared
prior
to
type
parameters
"
)
)
}
Ok
(
(
)
)
}
pub
fn
parse_where_clause
(
&
mut
self
)
-
>
PResult
<
'
a
ast
:
:
WhereClause
>
{
maybe_whole
!
(
self
NtWhereClause
|
x
|
x
)
;
let
mut
where_clause
=
WhereClause
{
id
:
ast
:
:
DUMMY_NODE_ID
predicates
:
Vec
:
:
new
(
)
}
;
if
!
self
.
eat_keyword
(
keywords
:
:
Where
)
{
return
Ok
(
where_clause
)
;
}
let
mut
parsed_something
=
false
;
loop
{
let
lo
=
self
.
span
.
lo
;
match
self
.
token
{
token
:
:
OpenDelim
(
token
:
:
Brace
)
=
>
{
break
}
token
:
:
Lifetime
(
.
.
)
=
>
{
let
bounded_lifetime
=
try
!
(
self
.
parse_lifetime
(
)
)
;
try
!
(
self
.
expect
(
&
token
:
:
Colon
)
)
;
let
bounds
=
try
!
(
self
.
parse_lifetimes
(
token
:
:
BinOp
(
token
:
:
Plus
)
)
)
;
let
hi
=
self
.
prev_span
.
hi
;
let
span
=
mk_sp
(
lo
hi
)
;
where_clause
.
predicates
.
push
(
ast
:
:
WherePredicate
:
:
RegionPredicate
(
ast
:
:
WhereRegionPredicate
{
span
:
span
lifetime
:
bounded_lifetime
bounds
:
bounds
}
)
)
;
parsed_something
=
true
;
}
_
=
>
{
let
bound_lifetimes
=
if
self
.
eat_keyword
(
keywords
:
:
For
)
{
try
!
(
self
.
expect
(
&
token
:
:
Lt
)
)
;
let
lifetime_defs
=
try
!
(
self
.
parse_lifetime_defs
(
None
)
)
;
try
!
(
self
.
expect_gt
(
)
)
;
lifetime_defs
}
else
{
vec
!
[
]
}
;
let
bounded_ty
=
try
!
(
self
.
parse_ty
(
)
)
;
if
self
.
eat
(
&
token
:
:
Colon
)
{
let
bounds
=
try
!
(
self
.
parse_ty_param_bounds
(
BoundParsingMode
:
:
Bare
)
)
;
let
hi
=
self
.
prev_span
.
hi
;
let
span
=
mk_sp
(
lo
hi
)
;
if
bounds
.
is_empty
(
)
{
self
.
span_err
(
span
"
each
predicate
in
a
where
clause
must
have
\
at
least
one
bound
in
it
"
)
;
}
where_clause
.
predicates
.
push
(
ast
:
:
WherePredicate
:
:
BoundPredicate
(
ast
:
:
WhereBoundPredicate
{
span
:
span
bound_lifetimes
:
bound_lifetimes
bounded_ty
:
bounded_ty
bounds
:
bounds
}
)
)
;
parsed_something
=
true
;
}
else
if
self
.
eat
(
&
token
:
:
Eq
)
{
let
hi
=
self
.
prev_span
.
hi
;
let
span
=
mk_sp
(
lo
hi
)
;
self
.
span_err
(
span
"
equality
constraints
are
not
yet
supported
\
in
where
clauses
(
#
20041
)
"
)
;
}
else
{
let
prev_span
=
self
.
prev_span
;
self
.
span_err
(
prev_span
"
unexpected
token
in
where
clause
"
)
;
}
}
}
;
if
!
self
.
eat
(
&
token
:
:
Comma
)
{
break
}
}
if
!
parsed_something
{
let
prev_span
=
self
.
prev_span
;
self
.
span_err
(
prev_span
"
a
where
clause
must
have
at
least
one
predicate
\
in
it
"
)
;
}
Ok
(
where_clause
)
}
fn
parse_fn_args
(
&
mut
self
named_args
:
bool
allow_variadic
:
bool
)
-
>
PResult
<
'
a
(
Vec
<
Arg
>
bool
)
>
{
let
sp
=
self
.
span
;
let
mut
variadic
=
false
;
let
args
:
Vec
<
Option
<
Arg
>
>
=
try
!
(
self
.
parse_unspanned_seq
(
&
token
:
:
OpenDelim
(
token
:
:
Paren
)
&
token
:
:
CloseDelim
(
token
:
:
Paren
)
SeqSep
:
:
trailing_allowed
(
token
:
:
Comma
)
|
p
|
{
if
p
.
token
=
=
token
:
:
DotDotDot
{
p
.
bump
(
)
;
if
allow_variadic
{
if
p
.
token
!
=
token
:
:
CloseDelim
(
token
:
:
Paren
)
{
let
span
=
p
.
span
;
p
.
span_err
(
span
"
.
.
.
must
be
last
in
argument
list
for
variadic
function
"
)
;
}
}
else
{
let
span
=
p
.
span
;
p
.
span_err
(
span
"
only
foreign
functions
are
allowed
to
be
variadic
"
)
;
}
variadic
=
true
;
Ok
(
None
)
}
else
{
match
p
.
parse_arg_general
(
named_args
)
{
Ok
(
arg
)
=
>
Ok
(
Some
(
arg
)
)
Err
(
mut
e
)
=
>
{
e
.
emit
(
)
;
p
.
eat_to_tokens
(
&
[
&
token
:
:
Comma
&
token
:
:
CloseDelim
(
token
:
:
Paren
)
]
)
;
Ok
(
None
)
}
}
}
}
)
)
;
let
args
:
Vec
<
_
>
=
args
.
into_iter
(
)
.
filter_map
(
|
x
|
x
)
.
collect
(
)
;
if
variadic
&
&
args
.
is_empty
(
)
{
self
.
span_err
(
sp
"
variadic
function
must
be
declared
with
at
least
one
named
argument
"
)
;
}
Ok
(
(
args
variadic
)
)
}
pub
fn
parse_fn_decl
(
&
mut
self
allow_variadic
:
bool
)
-
>
PResult
<
'
a
P
<
FnDecl
>
>
{
let
(
args
variadic
)
=
try
!
(
self
.
parse_fn_args
(
true
allow_variadic
)
)
;
let
ret_ty
=
try
!
(
self
.
parse_ret_ty
(
)
)
;
Ok
(
P
(
FnDecl
{
inputs
:
args
output
:
ret_ty
variadic
:
variadic
}
)
)
}
fn
parse_self_arg
(
&
mut
self
)
-
>
PResult
<
'
a
Option
<
Arg
>
>
{
let
expect_ident
=
|
this
:
&
mut
Self
|
match
this
.
token
{
token
:
:
Ident
(
ident
)
=
>
{
this
.
bump
(
)
;
codemap
:
:
respan
(
this
.
prev_span
ident
)
}
_
=
>
unreachable
!
(
)
}
;
let
isolated_self
=
|
this
:
&
mut
Self
n
|
{
this
.
look_ahead
(
n
|
t
|
t
.
is_keyword
(
keywords
:
:
SelfValue
)
)
&
&
this
.
look_ahead
(
n
+
1
|
t
|
t
!
=
&
token
:
:
ModSep
)
}
;
let
eself_lo
=
self
.
span
.
lo
;
let
(
eself
eself_ident
)
=
match
self
.
token
{
token
:
:
BinOp
(
token
:
:
And
)
=
>
{
if
isolated_self
(
self
1
)
{
self
.
bump
(
)
;
(
SelfKind
:
:
Region
(
None
Mutability
:
:
Immutable
)
expect_ident
(
self
)
)
}
else
if
self
.
look_ahead
(
1
|
t
|
t
.
is_keyword
(
keywords
:
:
Mut
)
)
&
&
isolated_self
(
self
2
)
{
self
.
bump
(
)
;
self
.
bump
(
)
;
(
SelfKind
:
:
Region
(
None
Mutability
:
:
Mutable
)
expect_ident
(
self
)
)
}
else
if
self
.
look_ahead
(
1
|
t
|
t
.
is_lifetime
(
)
)
&
&
isolated_self
(
self
2
)
{
self
.
bump
(
)
;
let
lt
=
try
!
(
self
.
parse_lifetime
(
)
)
;
(
SelfKind
:
:
Region
(
Some
(
lt
)
Mutability
:
:
Immutable
)
expect_ident
(
self
)
)
}
else
if
self
.
look_ahead
(
1
|
t
|
t
.
is_lifetime
(
)
)
&
&
self
.
look_ahead
(
2
|
t
|
t
.
is_keyword
(
keywords
:
:
Mut
)
)
&
&
isolated_self
(
self
3
)
{
self
.
bump
(
)
;
let
lt
=
try
!
(
self
.
parse_lifetime
(
)
)
;
self
.
bump
(
)
;
(
SelfKind
:
:
Region
(
Some
(
lt
)
Mutability
:
:
Mutable
)
expect_ident
(
self
)
)
}
else
{
return
Ok
(
None
)
;
}
}
token
:
:
BinOp
(
token
:
:
Star
)
=
>
{
if
isolated_self
(
self
1
)
{
self
.
bump
(
)
;
self
.
span_err
(
self
.
span
"
cannot
pass
self
by
raw
pointer
"
)
;
(
SelfKind
:
:
Value
(
Mutability
:
:
Immutable
)
expect_ident
(
self
)
)
}
else
if
self
.
look_ahead
(
1
|
t
|
t
.
is_mutability
(
)
)
&
&
isolated_self
(
self
2
)
{
self
.
bump
(
)
;
self
.
bump
(
)
;
self
.
span_err
(
self
.
span
"
cannot
pass
self
by
raw
pointer
"
)
;
(
SelfKind
:
:
Value
(
Mutability
:
:
Immutable
)
expect_ident
(
self
)
)
}
else
{
return
Ok
(
None
)
;
}
}
token
:
:
Ident
(
.
.
)
=
>
{
if
isolated_self
(
self
0
)
{
let
eself_ident
=
expect_ident
(
self
)
;
if
self
.
eat
(
&
token
:
:
Colon
)
{
let
ty
=
try
!
(
self
.
parse_ty_sum
(
)
)
;
(
SelfKind
:
:
Explicit
(
ty
Mutability
:
:
Immutable
)
eself_ident
)
}
else
{
(
SelfKind
:
:
Value
(
Mutability
:
:
Immutable
)
eself_ident
)
}
}
else
if
self
.
token
.
is_keyword
(
keywords
:
:
Mut
)
&
&
isolated_self
(
self
1
)
{
self
.
bump
(
)
;
let
eself_ident
=
expect_ident
(
self
)
;
if
self
.
eat
(
&
token
:
:
Colon
)
{
let
ty
=
try
!
(
self
.
parse_ty_sum
(
)
)
;
(
SelfKind
:
:
Explicit
(
ty
Mutability
:
:
Mutable
)
eself_ident
)
}
else
{
(
SelfKind
:
:
Value
(
Mutability
:
:
Mutable
)
eself_ident
)
}
}
else
{
return
Ok
(
None
)
;
}
}
_
=
>
return
Ok
(
None
)
}
;
let
eself
=
codemap
:
:
respan
(
mk_sp
(
eself_lo
self
.
prev_span
.
hi
)
eself
)
;
Ok
(
Some
(
Arg
:
:
from_self
(
eself
eself_ident
)
)
)
}
fn
parse_fn_decl_with_self
<
F
>
(
&
mut
self
parse_arg_fn
:
F
)
-
>
PResult
<
'
a
P
<
FnDecl
>
>
where
F
:
FnMut
(
&
mut
Parser
<
'
a
>
)
-
>
PResult
<
'
a
Arg
>
{
try
!
(
self
.
expect
(
&
token
:
:
OpenDelim
(
token
:
:
Paren
)
)
)
;
let
self_arg
=
try
!
(
self
.
parse_self_arg
(
)
)
;
let
sep
=
SeqSep
:
:
trailing_allowed
(
token
:
:
Comma
)
;
let
fn_inputs
=
if
let
Some
(
self_arg
)
=
self_arg
{
if
self
.
check
(
&
token
:
:
CloseDelim
(
token
:
:
Paren
)
)
{
vec
!
[
self_arg
]
}
else
if
self
.
eat
(
&
token
:
:
Comma
)
{
let
mut
fn_inputs
=
vec
!
[
self_arg
]
;
fn_inputs
.
append
(
&
mut
self
.
parse_seq_to_before_end
(
&
token
:
:
CloseDelim
(
token
:
:
Paren
)
sep
parse_arg_fn
)
)
;
fn_inputs
}
else
{
return
self
.
unexpected
(
)
;
}
}
else
{
self
.
parse_seq_to_before_end
(
&
token
:
:
CloseDelim
(
token
:
:
Paren
)
sep
parse_arg_fn
)
}
;
try
!
(
self
.
expect
(
&
token
:
:
CloseDelim
(
token
:
:
Paren
)
)
)
;
Ok
(
P
(
FnDecl
{
inputs
:
fn_inputs
output
:
try
!
(
self
.
parse_ret_ty
(
)
)
variadic
:
false
}
)
)
}
fn
parse_fn_block_decl
(
&
mut
self
)
-
>
PResult
<
'
a
P
<
FnDecl
>
>
{
let
inputs_captures
=
{
if
self
.
eat
(
&
token
:
:
OrOr
)
{
Vec
:
:
new
(
)
}
else
{
try
!
(
self
.
expect
(
&
token
:
:
BinOp
(
token
:
:
Or
)
)
)
;
let
args
=
self
.
parse_seq_to_before_end
(
&
token
:
:
BinOp
(
token
:
:
Or
)
SeqSep
:
:
trailing_allowed
(
token
:
:
Comma
)
|
p
|
p
.
parse_fn_block_arg
(
)
)
;
self
.
bump
(
)
;
args
}
}
;
let
output
=
try
!
(
self
.
parse_ret_ty
(
)
)
;
Ok
(
P
(
FnDecl
{
inputs
:
inputs_captures
output
:
output
variadic
:
false
}
)
)
}
fn
parse_fn_header
(
&
mut
self
)
-
>
PResult
<
'
a
(
Ident
ast
:
:
Generics
)
>
{
let
id
=
try
!
(
self
.
parse_ident
(
)
)
;
let
generics
=
try
!
(
self
.
parse_generics
(
)
)
;
Ok
(
(
id
generics
)
)
}
fn
mk_item
(
&
mut
self
lo
:
BytePos
hi
:
BytePos
ident
:
Ident
node
:
ItemKind
vis
:
Visibility
attrs
:
Vec
<
Attribute
>
)
-
>
P
<
Item
>
{
P
(
Item
{
ident
:
ident
attrs
:
attrs
id
:
ast
:
:
DUMMY_NODE_ID
node
:
node
vis
:
vis
span
:
mk_sp
(
lo
hi
)
}
)
}
fn
parse_item_fn
(
&
mut
self
unsafety
:
Unsafety
constness
:
Spanned
<
Constness
>
abi
:
abi
:
:
Abi
)
-
>
PResult
<
'
a
ItemInfo
>
{
let
(
ident
mut
generics
)
=
try
!
(
self
.
parse_fn_header
(
)
)
;
let
decl
=
try
!
(
self
.
parse_fn_decl
(
false
)
)
;
generics
.
where_clause
=
try
!
(
self
.
parse_where_clause
(
)
)
;
let
(
inner_attrs
body
)
=
try
!
(
self
.
parse_inner_attrs_and_block
(
)
)
;
Ok
(
(
ident
ItemKind
:
:
Fn
(
decl
unsafety
constness
abi
generics
body
)
Some
(
inner_attrs
)
)
)
}
pub
fn
is_const_item
(
&
mut
self
)
-
>
bool
{
self
.
token
.
is_keyword
(
keywords
:
:
Const
)
&
&
!
self
.
look_ahead
(
1
|
t
|
t
.
is_keyword
(
keywords
:
:
Fn
)
)
&
&
!
self
.
look_ahead
(
1
|
t
|
t
.
is_keyword
(
keywords
:
:
Unsafe
)
)
}
pub
fn
parse_fn_front_matter
(
&
mut
self
)
-
>
PResult
<
'
a
(
Spanned
<
ast
:
:
Constness
>
ast
:
:
Unsafety
abi
:
:
Abi
)
>
{
let
is_const_fn
=
self
.
eat_keyword
(
keywords
:
:
Const
)
;
let
const_span
=
self
.
prev_span
;
let
unsafety
=
try
!
(
self
.
parse_unsafety
(
)
)
;
let
(
constness
unsafety
abi
)
=
if
is_const_fn
{
(
respan
(
const_span
Constness
:
:
Const
)
unsafety
Abi
:
:
Rust
)
}
else
{
let
abi
=
if
self
.
eat_keyword
(
keywords
:
:
Extern
)
{
try
!
(
self
.
parse_opt_abi
(
)
)
.
unwrap_or
(
Abi
:
:
C
)
}
else
{
Abi
:
:
Rust
}
;
(
respan
(
self
.
prev_span
Constness
:
:
NotConst
)
unsafety
abi
)
}
;
try
!
(
self
.
expect_keyword
(
keywords
:
:
Fn
)
)
;
Ok
(
(
constness
unsafety
abi
)
)
}
pub
fn
parse_impl_item
(
&
mut
self
)
-
>
PResult
<
'
a
ImplItem
>
{
maybe_whole
!
(
self
NtImplItem
|
x
|
x
)
;
let
mut
attrs
=
try
!
(
self
.
parse_outer_attributes
(
)
)
;
let
lo
=
self
.
span
.
lo
;
let
vis
=
try
!
(
self
.
parse_visibility
(
true
)
)
;
let
defaultness
=
try
!
(
self
.
parse_defaultness
(
)
)
;
let
(
name
node
)
=
if
self
.
eat_keyword
(
keywords
:
:
Type
)
{
let
name
=
try
!
(
self
.
parse_ident
(
)
)
;
try
!
(
self
.
expect
(
&
token
:
:
Eq
)
)
;
let
typ
=
try
!
(
self
.
parse_ty_sum
(
)
)
;
try
!
(
self
.
expect
(
&
token
:
:
Semi
)
)
;
(
name
ast
:
:
ImplItemKind
:
:
Type
(
typ
)
)
}
else
if
self
.
is_const_item
(
)
{
try
!
(
self
.
expect_keyword
(
keywords
:
:
Const
)
)
;
let
name
=
try
!
(
self
.
parse_ident
(
)
)
;
try
!
(
self
.
expect
(
&
token
:
:
Colon
)
)
;
let
typ
=
try
!
(
self
.
parse_ty_sum
(
)
)
;
try
!
(
self
.
expect
(
&
token
:
:
Eq
)
)
;
let
expr
=
try
!
(
self
.
parse_expr
(
)
)
;
try
!
(
self
.
expect
(
&
token
:
:
Semi
)
)
;
(
name
ast
:
:
ImplItemKind
:
:
Const
(
typ
expr
)
)
}
else
{
let
(
name
inner_attrs
node
)
=
try
!
(
self
.
parse_impl_method
(
&
vis
)
)
;
attrs
.
extend
(
inner_attrs
)
;
(
name
node
)
}
;
Ok
(
ImplItem
{
id
:
ast
:
:
DUMMY_NODE_ID
span
:
mk_sp
(
lo
self
.
prev_span
.
hi
)
ident
:
name
vis
:
vis
defaultness
:
defaultness
attrs
:
attrs
node
:
node
}
)
}
fn
complain_if_pub_macro
(
&
mut
self
visa
:
&
Visibility
span
:
Span
)
{
match
*
visa
{
Visibility
:
:
Inherited
=
>
(
)
_
=
>
{
let
is_macro_rules
:
bool
=
match
self
.
token
{
token
:
:
Ident
(
sid
)
=
>
sid
.
name
=
=
intern
(
"
macro_rules
"
)
_
=
>
false
}
;
if
is_macro_rules
{
self
.
diagnostic
(
)
.
struct_span_err
(
span
"
can
'
t
qualify
macro_rules
\
invocation
with
pub
"
)
.
help
(
"
did
you
mean
#
[
macro_export
]
?
"
)
.
emit
(
)
;
}
else
{
self
.
diagnostic
(
)
.
struct_span_err
(
span
"
can
'
t
qualify
macro
\
invocation
with
pub
"
)
.
help
(
"
try
adjusting
the
macro
to
put
pub
\
inside
the
invocation
"
)
.
emit
(
)
;
}
}
}
}
fn
parse_impl_method
(
&
mut
self
vis
:
&
Visibility
)
-
>
PResult
<
'
a
(
Ident
Vec
<
ast
:
:
Attribute
>
ast
:
:
ImplItemKind
)
>
{
if
self
.
token
.
is_path_start
(
)
{
let
prev_span
=
self
.
prev_span
;
self
.
complain_if_pub_macro
(
&
vis
prev_span
)
;
let
lo
=
self
.
span
.
lo
;
let
pth
=
try
!
(
self
.
parse_path
(
PathStyle
:
:
Mod
)
)
;
try
!
(
self
.
expect
(
&
token
:
:
Not
)
)
;
let
delim
=
try
!
(
self
.
expect_open_delim
(
)
)
;
let
tts
=
try
!
(
self
.
parse_seq_to_end
(
&
token
:
:
CloseDelim
(
delim
)
SeqSep
:
:
none
(
)
|
p
|
p
.
parse_token_tree
(
)
)
)
;
if
delim
!
=
token
:
:
Brace
{
try
!
(
self
.
expect
(
&
token
:
:
Semi
)
)
}
let
mac
=
spanned
(
lo
self
.
prev_span
.
hi
Mac_
{
path
:
pth
tts
:
tts
}
)
;
Ok
(
(
keywords
:
:
Invalid
.
ident
(
)
vec
!
[
]
ast
:
:
ImplItemKind
:
:
Macro
(
mac
)
)
)
}
else
{
let
(
constness
unsafety
abi
)
=
try
!
(
self
.
parse_fn_front_matter
(
)
)
;
let
ident
=
try
!
(
self
.
parse_ident
(
)
)
;
let
mut
generics
=
try
!
(
self
.
parse_generics
(
)
)
;
let
decl
=
try
!
(
self
.
parse_fn_decl_with_self
(
|
p
|
p
.
parse_arg
(
)
)
)
;
generics
.
where_clause
=
try
!
(
self
.
parse_where_clause
(
)
)
;
let
(
inner_attrs
body
)
=
try
!
(
self
.
parse_inner_attrs_and_block
(
)
)
;
Ok
(
(
ident
inner_attrs
ast
:
:
ImplItemKind
:
:
Method
(
ast
:
:
MethodSig
{
generics
:
generics
abi
:
abi
unsafety
:
unsafety
constness
:
constness
decl
:
decl
}
body
)
)
)
}
}
fn
parse_item_trait
(
&
mut
self
unsafety
:
Unsafety
)
-
>
PResult
<
'
a
ItemInfo
>
{
let
ident
=
try
!
(
self
.
parse_ident
(
)
)
;
let
mut
tps
=
try
!
(
self
.
parse_generics
(
)
)
;
let
bounds
=
try
!
(
self
.
parse_colon_then_ty_param_bounds
(
BoundParsingMode
:
:
Bare
)
)
;
tps
.
where_clause
=
try
!
(
self
.
parse_where_clause
(
)
)
;
let
meths
=
try
!
(
self
.
parse_trait_items
(
)
)
;
Ok
(
(
ident
ItemKind
:
:
Trait
(
unsafety
tps
bounds
meths
)
None
)
)
}
fn
parse_item_impl
(
&
mut
self
unsafety
:
ast
:
:
Unsafety
)
-
>
PResult
<
'
a
ItemInfo
>
{
let
impl_span
=
self
.
span
;
let
mut
generics
=
try
!
(
self
.
parse_generics
(
)
)
;
let
could_be_trait
=
self
.
token
!
=
token
:
:
OpenDelim
(
token
:
:
Paren
)
;
let
neg_span
=
self
.
span
;
let
polarity
=
if
self
.
eat
(
&
token
:
:
Not
)
{
ast
:
:
ImplPolarity
:
:
Negative
}
else
{
ast
:
:
ImplPolarity
:
:
Positive
}
;
let
mut
ty
=
try
!
(
self
.
parse_ty_sum
(
)
)
;
let
opt_trait
=
if
could_be_trait
&
&
self
.
eat_keyword
(
keywords
:
:
For
)
{
match
ty
.
node
{
TyKind
:
:
Path
(
None
ref
path
)
=
>
{
Some
(
TraitRef
{
path
:
(
*
path
)
.
clone
(
)
ref_id
:
ty
.
id
}
)
}
_
=
>
{
self
.
span_err
(
ty
.
span
"
not
a
trait
"
)
;
None
}
}
}
else
{
match
polarity
{
ast
:
:
ImplPolarity
:
:
Negative
=
>
{
self
.
span_err
(
neg_span
"
inherent
implementation
can
'
t
be
negated
"
)
;
}
_
=
>
{
}
}
None
}
;
if
opt_trait
.
is_some
(
)
&
&
self
.
eat
(
&
token
:
:
DotDot
)
{
if
generics
.
is_parameterized
(
)
{
self
.
span_err
(
impl_span
"
default
trait
implementations
are
not
\
allowed
to
have
generics
"
)
;
}
try
!
(
self
.
expect
(
&
token
:
:
OpenDelim
(
token
:
:
Brace
)
)
)
;
try
!
(
self
.
expect
(
&
token
:
:
CloseDelim
(
token
:
:
Brace
)
)
)
;
Ok
(
(
keywords
:
:
Invalid
.
ident
(
)
ItemKind
:
:
DefaultImpl
(
unsafety
opt_trait
.
unwrap
(
)
)
None
)
)
}
else
{
if
opt_trait
.
is_some
(
)
{
ty
=
try
!
(
self
.
parse_ty_sum
(
)
)
;
}
generics
.
where_clause
=
try
!
(
self
.
parse_where_clause
(
)
)
;
try
!
(
self
.
expect
(
&
token
:
:
OpenDelim
(
token
:
:
Brace
)
)
)
;
let
attrs
=
try
!
(
self
.
parse_inner_attributes
(
)
)
;
let
mut
impl_items
=
vec
!
[
]
;
while
!
self
.
eat
(
&
token
:
:
CloseDelim
(
token
:
:
Brace
)
)
{
impl_items
.
push
(
try
!
(
self
.
parse_impl_item
(
)
)
)
;
}
Ok
(
(
keywords
:
:
Invalid
.
ident
(
)
ItemKind
:
:
Impl
(
unsafety
polarity
generics
opt_trait
ty
impl_items
)
Some
(
attrs
)
)
)
}
}
fn
parse_trait_ref
(
&
mut
self
)
-
>
PResult
<
'
a
TraitRef
>
{
Ok
(
ast
:
:
TraitRef
{
path
:
try
!
(
self
.
parse_path
(
PathStyle
:
:
Type
)
)
ref_id
:
ast
:
:
DUMMY_NODE_ID
}
)
}
fn
parse_late_bound_lifetime_defs
(
&
mut
self
)
-
>
PResult
<
'
a
Vec
<
ast
:
:
LifetimeDef
>
>
{
if
self
.
eat_keyword
(
keywords
:
:
For
)
{
try
!
(
self
.
expect
(
&
token
:
:
Lt
)
)
;
let
lifetime_defs
=
try
!
(
self
.
parse_lifetime_defs
(
None
)
)
;
try
!
(
self
.
expect_gt
(
)
)
;
Ok
(
lifetime_defs
)
}
else
{
Ok
(
Vec
:
:
new
(
)
)
}
}
fn
parse_poly_trait_ref
(
&
mut
self
)
-
>
PResult
<
'
a
PolyTraitRef
>
{
let
lo
=
self
.
span
.
lo
;
let
lifetime_defs
=
try
!
(
self
.
parse_late_bound_lifetime_defs
(
)
)
;
Ok
(
ast
:
:
PolyTraitRef
{
bound_lifetimes
:
lifetime_defs
trait_ref
:
try
!
(
self
.
parse_trait_ref
(
)
)
span
:
mk_sp
(
lo
self
.
prev_span
.
hi
)
}
)
}
fn
parse_item_struct
(
&
mut
self
)
-
>
PResult
<
'
a
ItemInfo
>
{
let
class_name
=
try
!
(
self
.
parse_ident
(
)
)
;
let
mut
generics
=
try
!
(
self
.
parse_generics
(
)
)
;
let
vdata
=
if
self
.
token
.
is_keyword
(
keywords
:
:
Where
)
{
generics
.
where_clause
=
try
!
(
self
.
parse_where_clause
(
)
)
;
if
self
.
eat
(
&
token
:
:
Semi
)
{
VariantData
:
:
Unit
(
ast
:
:
DUMMY_NODE_ID
)
}
else
{
VariantData
:
:
Struct
(
try
!
(
self
.
parse_record_struct_body
(
)
)
ast
:
:
DUMMY_NODE_ID
)
}
}
else
if
self
.
eat
(
&
token
:
:
Semi
)
{
VariantData
:
:
Unit
(
ast
:
:
DUMMY_NODE_ID
)
}
else
if
self
.
token
=
=
token
:
:
OpenDelim
(
token
:
:
Brace
)
{
VariantData
:
:
Struct
(
try
!
(
self
.
parse_record_struct_body
(
)
)
ast
:
:
DUMMY_NODE_ID
)
}
else
if
self
.
token
=
=
token
:
:
OpenDelim
(
token
:
:
Paren
)
{
let
body
=
VariantData
:
:
Tuple
(
try
!
(
self
.
parse_tuple_struct_body
(
)
)
ast
:
:
DUMMY_NODE_ID
)
;
generics
.
where_clause
=
try
!
(
self
.
parse_where_clause
(
)
)
;
try
!
(
self
.
expect
(
&
token
:
:
Semi
)
)
;
body
}
else
{
let
token_str
=
self
.
this_token_to_string
(
)
;
return
Err
(
self
.
fatal
(
&
format
!
(
"
expected
where
{
{
(
or
;
after
struct
\
name
found
{
}
"
token_str
)
)
)
}
;
Ok
(
(
class_name
ItemKind
:
:
Struct
(
vdata
generics
)
None
)
)
}
fn
parse_item_union
(
&
mut
self
)
-
>
PResult
<
'
a
ItemInfo
>
{
let
class_name
=
try
!
(
self
.
parse_ident
(
)
)
;
let
mut
generics
=
try
!
(
self
.
parse_generics
(
)
)
;
let
vdata
=
if
self
.
token
.
is_keyword
(
keywords
:
:
Where
)
{
generics
.
where_clause
=
try
!
(
self
.
parse_where_clause
(
)
)
;
VariantData
:
:
Struct
(
try
!
(
self
.
parse_record_struct_body
(
)
)
ast
:
:
DUMMY_NODE_ID
)
}
else
if
self
.
token
=
=
token
:
:
OpenDelim
(
token
:
:
Brace
)
{
VariantData
:
:
Struct
(
try
!
(
self
.
parse_record_struct_body
(
)
)
ast
:
:
DUMMY_NODE_ID
)
}
else
{
let
token_str
=
self
.
this_token_to_string
(
)
;
return
Err
(
self
.
fatal
(
&
format
!
(
"
expected
where
or
{
{
after
union
\
name
found
{
}
"
token_str
)
)
)
}
;
Ok
(
(
class_name
ItemKind
:
:
Union
(
vdata
generics
)
None
)
)
}
pub
fn
parse_record_struct_body
(
&
mut
self
)
-
>
PResult
<
'
a
Vec
<
StructField
>
>
{
let
mut
fields
=
Vec
:
:
new
(
)
;
if
self
.
eat
(
&
token
:
:
OpenDelim
(
token
:
:
Brace
)
)
{
while
self
.
token
!
=
token
:
:
CloseDelim
(
token
:
:
Brace
)
{
fields
.
push
(
try
!
(
self
.
parse_struct_decl_field
(
)
.
map_err
(
|
e
|
{
self
.
recover_stmt
(
)
;
self
.
eat
(
&
token
:
:
CloseDelim
(
token
:
:
Brace
)
)
;
e
}
)
)
)
;
}
self
.
bump
(
)
;
}
else
{
let
token_str
=
self
.
this_token_to_string
(
)
;
return
Err
(
self
.
fatal
(
&
format
!
(
"
expected
where
or
{
{
after
struct
\
name
found
{
}
"
token_str
)
)
)
;
}
Ok
(
fields
)
}
pub
fn
parse_tuple_struct_body
(
&
mut
self
)
-
>
PResult
<
'
a
Vec
<
StructField
>
>
{
let
fields
=
try
!
(
self
.
parse_unspanned_seq
(
&
token
:
:
OpenDelim
(
token
:
:
Paren
)
&
token
:
:
CloseDelim
(
token
:
:
Paren
)
SeqSep
:
:
trailing_allowed
(
token
:
:
Comma
)
|
p
|
{
let
attrs
=
try
!
(
p
.
parse_outer_attributes
(
)
)
;
let
lo
=
p
.
span
.
lo
;
let
mut
vis
=
try
!
(
p
.
parse_visibility
(
false
)
)
;
let
ty_is_interpolated
=
p
.
token
.
is_interpolated
(
)
|
|
p
.
look_ahead
(
1
|
t
|
t
.
is_interpolated
(
)
)
;
let
mut
ty
=
try
!
(
p
.
parse_ty_sum
(
)
)
;
/
/
Handle
pub
(
path
)
type
in
which
vis
will
be
pub
and
ty
will
be
(
path
)
.
if
vis
=
=
Visibility
:
:
Public
&
&
!
ty_is_interpolated
&
&
p
.
token
!
=
token
:
:
Comma
&
&
p
.
token
!
=
token
:
:
CloseDelim
(
token
:
:
Paren
)
{
ty
=
if
let
TyKind
:
:
Paren
(
ref
path_ty
)
=
ty
.
node
{
if
let
TyKind
:
:
Path
(
None
ref
path
)
=
path_ty
.
node
{
vis
=
Visibility
:
:
Restricted
{
path
:
P
(
path
.
clone
(
)
)
id
:
path_ty
.
id
}
;
Some
(
try
!
(
p
.
parse_ty_sum
(
)
)
)
}
else
{
None
}
}
else
{
None
}
.
unwrap_or
(
ty
)
;
}
Ok
(
StructField
{
span
:
mk_sp
(
lo
p
.
span
.
hi
)
vis
:
vis
ident
:
None
id
:
ast
:
:
DUMMY_NODE_ID
ty
:
ty
attrs
:
attrs
}
)
}
)
)
;
Ok
(
fields
)
}
pub
fn
parse_single_struct_field
(
&
mut
self
lo
:
BytePos
vis
:
Visibility
attrs
:
Vec
<
Attribute
>
)
-
>
PResult
<
'
a
StructField
>
{
let
a_var
=
try
!
(
self
.
parse_name_and_ty
(
lo
vis
attrs
)
)
;
match
self
.
token
{
token
:
:
Comma
=
>
{
self
.
bump
(
)
;
}
token
:
:
CloseDelim
(
token
:
:
Brace
)
=
>
{
}
token
:
:
DocComment
(
_
)
=
>
return
Err
(
self
.
span_fatal_help
(
self
.
span
"
found
a
documentation
comment
that
doesn
'
t
document
anything
"
"
doc
comments
must
come
before
what
they
document
maybe
a
comment
was
\
intended
with
/
/
?
"
)
)
_
=
>
return
Err
(
self
.
span_fatal_help
(
self
.
span
&
format
!
(
"
expected
or
}
}
found
{
}
"
self
.
this_token_to_string
(
)
)
"
struct
fields
should
be
separated
by
commas
"
)
)
}
Ok
(
a_var
)
}
fn
parse_struct_decl_field
(
&
mut
self
)
-
>
PResult
<
'
a
StructField
>
{
let
attrs
=
try
!
(
self
.
parse_outer_attributes
(
)
)
;
let
lo
=
self
.
span
.
lo
;
let
vis
=
try
!
(
self
.
parse_visibility
(
true
)
)
;
self
.
parse_single_struct_field
(
lo
vis
attrs
)
}
fn
parse_visibility
(
&
mut
self
allow_path
:
bool
)
-
>
PResult
<
'
a
Visibility
>
{
let
pub_crate
=
|
this
:
&
mut
Self
|
{
let
span
=
this
.
prev_span
;
try
!
(
this
.
expect
(
&
token
:
:
CloseDelim
(
token
:
:
Paren
)
)
)
;
Ok
(
Visibility
:
:
Crate
(
span
)
)
}
;
if
!
self
.
eat_keyword
(
keywords
:
:
Pub
)
{
Ok
(
Visibility
:
:
Inherited
)
}
else
if
!
allow_path
{
if
self
.
token
=
=
token
:
:
OpenDelim
(
token
:
:
Paren
)
&
&
self
.
look_ahead
(
1
|
t
|
t
.
is_keyword
(
keywords
:
:
Crate
)
)
{
self
.
bump
(
)
;
self
.
bump
(
)
;
pub_crate
(
self
)
}
else
{
Ok
(
Visibility
:
:
Public
)
}
}
else
if
!
self
.
eat
(
&
token
:
:
OpenDelim
(
token
:
:
Paren
)
)
{
Ok
(
Visibility
:
:
Public
)
}
else
if
self
.
eat_keyword
(
keywords
:
:
Crate
)
{
pub_crate
(
self
)
}
else
{
let
path
=
try
!
(
self
.
parse_path
(
PathStyle
:
:
Mod
)
)
;
try
!
(
self
.
expect
(
&
token
:
:
CloseDelim
(
token
:
:
Paren
)
)
)
;
Ok
(
Visibility
:
:
Restricted
{
path
:
P
(
path
)
id
:
ast
:
:
DUMMY_NODE_ID
}
)
}
}
fn
parse_defaultness
(
&
mut
self
)
-
>
PResult
<
'
a
Defaultness
>
{
if
self
.
eat_contextual_keyword
(
keywords
:
:
Default
.
ident
(
)
)
{
Ok
(
Defaultness
:
:
Default
)
}
else
{
Ok
(
Defaultness
:
:
Final
)
}
}
fn
parse_mod_items
(
&
mut
self
term
:
&
token
:
:
Token
inner_lo
:
BytePos
)
-
>
PResult
<
'
a
Mod
>
{
let
mut
items
=
vec
!
[
]
;
while
let
Some
(
item
)
=
try
!
(
self
.
parse_item
(
)
)
{
items
.
push
(
item
)
;
}
if
!
self
.
eat
(
term
)
{
let
token_str
=
self
.
this_token_to_string
(
)
;
return
Err
(
self
.
fatal
(
&
format
!
(
"
expected
item
found
{
}
"
token_str
)
)
)
;
}
let
hi
=
if
self
.
span
=
=
syntax_pos
:
:
DUMMY_SP
{
inner_lo
}
else
{
self
.
prev_span
.
hi
}
;
Ok
(
ast
:
:
Mod
{
inner
:
mk_sp
(
inner_lo
hi
)
items
:
items
}
)
}
fn
parse_item_const
(
&
mut
self
m
:
Option
<
Mutability
>
)
-
>
PResult
<
'
a
ItemInfo
>
{
let
id
=
try
!
(
self
.
parse_ident
(
)
)
;
try
!
(
self
.
expect
(
&
token
:
:
Colon
)
)
;
let
ty
=
try
!
(
self
.
parse_ty_sum
(
)
)
;
try
!
(
self
.
expect
(
&
token
:
:
Eq
)
)
;
let
e
=
try
!
(
self
.
parse_expr
(
)
)
;
try
!
(
self
.
expect
(
&
token
:
:
Semi
)
)
;
let
item
=
match
m
{
Some
(
m
)
=
>
ItemKind
:
:
Static
(
ty
m
e
)
None
=
>
ItemKind
:
:
Const
(
ty
e
)
}
;
Ok
(
(
id
item
None
)
)
}
fn
parse_item_mod
(
&
mut
self
outer_attrs
:
&
[
Attribute
]
)
-
>
PResult
<
'
a
ItemInfo
>
{
let
(
in_cfg
outer_attrs
)
=
{
let
mut
strip_unconfigured
=
:
:
config
:
:
StripUnconfigured
{
sess
:
self
.
sess
should_test
:
false
features
:
None
}
;
let
outer_attrs
=
strip_unconfigured
.
process_cfg_attrs
(
outer_attrs
.
to_owned
(
)
)
;
(
strip_unconfigured
.
in_cfg
(
&
outer_attrs
)
outer_attrs
)
}
;
let
id_span
=
self
.
span
;
let
id
=
try
!
(
self
.
parse_ident
(
)
)
;
if
self
.
check
(
&
token
:
:
Semi
)
{
self
.
bump
(
)
;
if
in_cfg
{
let
(
m
attrs
)
=
try
!
(
self
.
eval_src_mod
(
id
&
outer_attrs
id_span
)
)
;
Ok
(
(
id
m
Some
(
attrs
)
)
)
}
else
{
let
placeholder
=
ast
:
:
Mod
{
inner
:
syntax_pos
:
:
DUMMY_SP
items
:
Vec
:
:
new
(
)
}
;
Ok
(
(
id
ItemKind
:
:
Mod
(
placeholder
)
None
)
)
}
}
else
{
let
directory
=
self
.
directory
.
clone
(
)
;
let
restrictions
=
self
.
push_directory
(
id
&
outer_attrs
)
;
try
!
(
self
.
expect
(
&
token
:
:
OpenDelim
(
token
:
:
Brace
)
)
)
;
let
mod_inner_lo
=
self
.
span
.
lo
;
let
attrs
=
try
!
(
self
.
parse_inner_attributes
(
)
)
;
let
m
=
try
!
(
self
.
with_res
(
restrictions
|
this
|
{
this
.
parse_mod_items
(
&
token
:
:
CloseDelim
(
token
:
:
Brace
)
mod_inner_lo
)
}
)
)
;
self
.
directory
=
directory
;
Ok
(
(
id
ItemKind
:
:
Mod
(
m
)
Some
(
attrs
)
)
)
}
}
fn
push_directory
(
&
mut
self
id
:
Ident
attrs
:
&
[
Attribute
]
)
-
>
Restrictions
{
if
let
Some
(
path
)
=
:
:
attr
:
:
first_attr_value_str_by_name
(
attrs
"
path
"
)
{
self
.
directory
.
push
(
&
*
path
)
;
self
.
restrictions
-
Restrictions
:
:
no_noninline_mod
(
)
}
else
{
let
default_path
=
self
.
id_to_interned_str
(
id
)
;
self
.
directory
.
push
(
&
*
default_path
)
;
self
.
restrictions
}
}
pub
fn
submod_path_from_attr
(
attrs
:
&
[
ast
:
:
Attribute
]
dir_path
:
&
Path
)
-
>
Option
<
PathBuf
>
{
:
:
attr
:
:
first_attr_value_str_by_name
(
attrs
"
path
"
)
.
map
(
|
d
|
dir_path
.
join
(
&
*
d
)
)
}
pub
fn
default_submod_path
(
id
:
ast
:
:
Ident
dir_path
:
&
Path
codemap
:
&
CodeMap
)
-
>
ModulePath
{
let
mod_name
=
id
.
to_string
(
)
;
let
default_path_str
=
format
!
(
"
{
}
.
rs
"
mod_name
)
;
let
secondary_path_str
=
format
!
(
"
{
}
/
mod
.
rs
"
mod_name
)
;
let
default_path
=
dir_path
.
join
(
&
default_path_str
)
;
let
secondary_path
=
dir_path
.
join
(
&
secondary_path_str
)
;
let
default_exists
=
codemap
.
file_exists
(
&
default_path
)
;
let
secondary_exists
=
codemap
.
file_exists
(
&
secondary_path
)
;
let
result
=
match
(
default_exists
secondary_exists
)
{
(
true
false
)
=
>
Ok
(
ModulePathSuccess
{
path
:
default_path
owns_directory
:
false
}
)
(
false
true
)
=
>
Ok
(
ModulePathSuccess
{
path
:
secondary_path
owns_directory
:
true
}
)
(
false
false
)
=
>
Err
(
ModulePathError
{
err_msg
:
format
!
(
"
file
not
found
for
module
{
}
"
mod_name
)
help_msg
:
format
!
(
"
name
the
file
either
{
}
or
{
}
inside
the
directory
{
:
?
}
"
default_path_str
secondary_path_str
dir_path
.
display
(
)
)
}
)
(
true
true
)
=
>
Err
(
ModulePathError
{
err_msg
:
format
!
(
"
file
for
module
{
}
found
at
both
{
}
and
{
}
"
mod_name
default_path_str
secondary_path_str
)
help_msg
:
"
delete
or
rename
one
of
them
to
remove
the
ambiguity
"
.
to_owned
(
)
}
)
}
;
ModulePath
{
name
:
mod_name
path_exists
:
default_exists
|
|
secondary_exists
result
:
result
}
}
fn
submod_path
(
&
mut
self
id
:
ast
:
:
Ident
outer_attrs
:
&
[
ast
:
:
Attribute
]
id_sp
:
Span
)
-
>
PResult
<
'
a
ModulePathSuccess
>
{
if
let
Some
(
p
)
=
Parser
:
:
submod_path_from_attr
(
outer_attrs
&
self
.
directory
)
{
return
Ok
(
ModulePathSuccess
{
path
:
p
owns_directory
:
true
}
)
;
}
let
paths
=
Parser
:
:
default_submod_path
(
id
&
self
.
directory
self
.
sess
.
codemap
(
)
)
;
if
self
.
restrictions
.
contains
(
NO_NONINLINE_MOD
)
{
let
msg
=
"
Cannot
declare
a
non
-
inline
module
inside
a
block
unless
it
has
a
path
attribute
"
;
let
mut
err
=
self
.
diagnostic
(
)
.
struct_span_err
(
id_sp
msg
)
;
if
paths
.
path_exists
{
let
msg
=
format
!
(
"
Maybe
use
the
module
{
}
instead
of
redeclaring
it
"
paths
.
name
)
;
err
.
span_note
(
id_sp
&
msg
)
;
}
return
Err
(
err
)
;
}
else
if
!
self
.
owns_directory
{
let
mut
err
=
self
.
diagnostic
(
)
.
struct_span_err
(
id_sp
"
cannot
declare
a
new
module
at
this
location
"
)
;
let
this_module
=
match
self
.
directory
.
file_name
(
)
{
Some
(
file_name
)
=
>
file_name
.
to_str
(
)
.
unwrap
(
)
.
to_owned
(
)
None
=
>
self
.
root_module_name
.
as_ref
(
)
.
unwrap
(
)
.
clone
(
)
}
;
err
.
span_note
(
id_sp
&
format
!
(
"
maybe
move
this
module
{
0
}
to
its
own
directory
\
via
{
0
}
/
mod
.
rs
"
this_module
)
)
;
if
paths
.
path_exists
{
err
.
span_note
(
id_sp
&
format
!
(
"
.
.
.
or
maybe
use
the
module
{
}
instead
\
of
possibly
redeclaring
it
"
paths
.
name
)
)
;
}
return
Err
(
err
)
;
}
match
paths
.
result
{
Ok
(
succ
)
=
>
Ok
(
succ
)
Err
(
err
)
=
>
Err
(
self
.
span_fatal_help
(
id_sp
&
err
.
err_msg
&
err
.
help_msg
)
)
}
}
fn
eval_src_mod
(
&
mut
self
id
:
ast
:
:
Ident
outer_attrs
:
&
[
ast
:
:
Attribute
]
id_sp
:
Span
)
-
>
PResult
<
'
a
(
ast
:
:
ItemKind
Vec
<
ast
:
:
Attribute
>
)
>
{
let
ModulePathSuccess
{
path
owns_directory
}
=
try
!
(
self
.
submod_path
(
id
outer_attrs
id_sp
)
)
;
self
.
eval_src_mod_from_path
(
path
owns_directory
id
.
to_string
(
)
id_sp
)
}
fn
eval_src_mod_from_path
(
&
mut
self
path
:
PathBuf
owns_directory
:
bool
name
:
String
id_sp
:
Span
)
-
>
PResult
<
'
a
(
ast
:
:
ItemKind
Vec
<
ast
:
:
Attribute
>
)
>
{
let
mut
included_mod_stack
=
self
.
sess
.
included_mod_stack
.
borrow_mut
(
)
;
if
let
Some
(
i
)
=
included_mod_stack
.
iter
(
)
.
position
(
|
p
|
*
p
=
=
path
)
{
let
mut
err
=
String
:
:
from
(
"
circular
modules
:
"
)
;
let
len
=
included_mod_stack
.
len
(
)
;
for
p
in
&
included_mod_stack
[
i
.
.
len
]
{
err
.
push_str
(
&
p
.
to_string_lossy
(
)
)
;
err
.
push_str
(
"
-
>
"
)
;
}
err
.
push_str
(
&
path
.
to_string_lossy
(
)
)
;
return
Err
(
self
.
span_fatal
(
id_sp
&
err
[
.
.
]
)
)
;
}
included_mod_stack
.
push
(
path
.
clone
(
)
)
;
drop
(
included_mod_stack
)
;
let
mut
p0
=
new_sub_parser_from_file
(
self
.
sess
&
path
owns_directory
Some
(
name
)
id_sp
)
;
let
mod_inner_lo
=
p0
.
span
.
lo
;
let
mod_attrs
=
try
!
(
p0
.
parse_inner_attributes
(
)
)
;
let
m0
=
try
!
(
p0
.
parse_mod_items
(
&
token
:
:
Eof
mod_inner_lo
)
)
;
self
.
sess
.
included_mod_stack
.
borrow_mut
(
)
.
pop
(
)
;
Ok
(
(
ast
:
:
ItemKind
:
:
Mod
(
m0
)
mod_attrs
)
)
}
fn
parse_item_foreign_fn
(
&
mut
self
vis
:
ast
:
:
Visibility
lo
:
BytePos
attrs
:
Vec
<
Attribute
>
)
-
>
PResult
<
'
a
ForeignItem
>
{
try
!
(
self
.
expect_keyword
(
keywords
:
:
Fn
)
)
;
let
(
ident
mut
generics
)
=
try
!
(
self
.
parse_fn_header
(
)
)
;
let
decl
=
try
!
(
self
.
parse_fn_decl
(
true
)
)
;
generics
.
where_clause
=
try
!
(
self
.
parse_where_clause
(
)
)
;
let
hi
=
self
.
span
.
hi
;
try
!
(
self
.
expect
(
&
token
:
:
Semi
)
)
;
Ok
(
ast
:
:
ForeignItem
{
ident
:
ident
attrs
:
attrs
node
:
ForeignItemKind
:
:
Fn
(
decl
generics
)
id
:
ast
:
:
DUMMY_NODE_ID
span
:
mk_sp
(
lo
hi
)
vis
:
vis
}
)
}
fn
parse_item_foreign_static
(
&
mut
self
vis
:
ast
:
:
Visibility
lo
:
BytePos
attrs
:
Vec
<
Attribute
>
)
-
>
PResult
<
'
a
ForeignItem
>
{
try
!
(
self
.
expect_keyword
(
keywords
:
:
Static
)
)
;
let
mutbl
=
self
.
eat_keyword
(
keywords
:
:
Mut
)
;
let
ident
=
try
!
(
self
.
parse_ident
(
)
)
;
try
!
(
self
.
expect
(
&
token
:
:
Colon
)
)
;
let
ty
=
try
!
(
self
.
parse_ty_sum
(
)
)
;
let
hi
=
self
.
span
.
hi
;
try
!
(
self
.
expect
(
&
token
:
:
Semi
)
)
;
Ok
(
ForeignItem
{
ident
:
ident
attrs
:
attrs
node
:
ForeignItemKind
:
:
Static
(
ty
mutbl
)
id
:
ast
:
:
DUMMY_NODE_ID
span
:
mk_sp
(
lo
hi
)
vis
:
vis
}
)
}
fn
parse_item_extern_crate
(
&
mut
self
lo
:
BytePos
visibility
:
Visibility
attrs
:
Vec
<
Attribute
>
)
-
>
PResult
<
'
a
P
<
Item
>
>
{
let
crate_name
=
try
!
(
self
.
parse_ident
(
)
)
;
let
(
maybe_path
ident
)
=
if
let
Some
(
ident
)
=
try
!
(
self
.
parse_rename
(
)
)
{
(
Some
(
crate_name
.
name
)
ident
)
}
else
{
(
None
crate_name
)
}
;
try
!
(
self
.
expect
(
&
token
:
:
Semi
)
)
;
let
prev_span
=
self
.
prev_span
;
Ok
(
self
.
mk_item
(
lo
prev_span
.
hi
ident
ItemKind
:
:
ExternCrate
(
maybe_path
)
visibility
attrs
)
)
}
fn
parse_item_foreign_mod
(
&
mut
self
lo
:
BytePos
opt_abi
:
Option
<
abi
:
:
Abi
>
visibility
:
Visibility
mut
attrs
:
Vec
<
Attribute
>
)
-
>
PResult
<
'
a
P
<
Item
>
>
{
try
!
(
self
.
expect
(
&
token
:
:
OpenDelim
(
token
:
:
Brace
)
)
)
;
let
abi
=
opt_abi
.
unwrap_or
(
Abi
:
:
C
)
;
attrs
.
extend
(
try
!
(
self
.
parse_inner_attributes
(
)
)
)
;
let
mut
foreign_items
=
vec
!
[
]
;
while
let
Some
(
item
)
=
try
!
(
self
.
parse_foreign_item
(
)
)
{
foreign_items
.
push
(
item
)
;
}
try
!
(
self
.
expect
(
&
token
:
:
CloseDelim
(
token
:
:
Brace
)
)
)
;
let
prev_span
=
self
.
prev_span
;
let
m
=
ast
:
:
ForeignMod
{
abi
:
abi
items
:
foreign_items
}
;
Ok
(
self
.
mk_item
(
lo
prev_span
.
hi
keywords
:
:
Invalid
.
ident
(
)
ItemKind
:
:
ForeignMod
(
m
)
visibility
attrs
)
)
}
fn
parse_item_type
(
&
mut
self
)
-
>
PResult
<
'
a
ItemInfo
>
{
let
ident
=
try
!
(
self
.
parse_ident
(
)
)
;
let
mut
tps
=
try
!
(
self
.
parse_generics
(
)
)
;
tps
.
where_clause
=
try
!
(
self
.
parse_where_clause
(
)
)
;
try
!
(
self
.
expect
(
&
token
:
:
Eq
)
)
;
let
ty
=
try
!
(
self
.
parse_ty_sum
(
)
)
;
try
!
(
self
.
expect
(
&
token
:
:
Semi
)
)
;
Ok
(
(
ident
ItemKind
:
:
Ty
(
ty
tps
)
None
)
)
}
fn
parse_enum_def
(
&
mut
self
_generics
:
&
ast
:
:
Generics
)
-
>
PResult
<
'
a
EnumDef
>
{
let
mut
variants
=
Vec
:
:
new
(
)
;
let
mut
all_nullary
=
true
;
let
mut
any_disr
=
None
;
while
self
.
token
!
=
token
:
:
CloseDelim
(
token
:
:
Brace
)
{
let
variant_attrs
=
try
!
(
self
.
parse_outer_attributes
(
)
)
;
let
vlo
=
self
.
span
.
lo
;
let
struct_def
;
let
mut
disr_expr
=
None
;
let
ident
=
try
!
(
self
.
parse_ident
(
)
)
;
if
self
.
check
(
&
token
:
:
OpenDelim
(
token
:
:
Brace
)
)
{
all_nullary
=
false
;
struct_def
=
VariantData
:
:
Struct
(
try
!
(
self
.
parse_record_struct_body
(
)
)
ast
:
:
DUMMY_NODE_ID
)
;
}
else
if
self
.
check
(
&
token
:
:
OpenDelim
(
token
:
:
Paren
)
)
{
all_nullary
=
false
;
struct_def
=
VariantData
:
:
Tuple
(
try
!
(
self
.
parse_tuple_struct_body
(
)
)
ast
:
:
DUMMY_NODE_ID
)
;
}
else
if
self
.
eat
(
&
token
:
:
Eq
)
{
disr_expr
=
Some
(
try
!
(
self
.
parse_expr
(
)
)
)
;
any_disr
=
disr_expr
.
as_ref
(
)
.
map
(
|
expr
|
expr
.
span
)
;
struct_def
=
VariantData
:
:
Unit
(
ast
:
:
DUMMY_NODE_ID
)
;
}
else
{
struct_def
=
VariantData
:
:
Unit
(
ast
:
:
DUMMY_NODE_ID
)
;
}
let
vr
=
ast
:
:
Variant_
{
name
:
ident
attrs
:
variant_attrs
data
:
struct_def
disr_expr
:
disr_expr
}
;
variants
.
push
(
spanned
(
vlo
self
.
prev_span
.
hi
vr
)
)
;
if
!
self
.
eat
(
&
token
:
:
Comma
)
{
break
;
}
}
try
!
(
self
.
expect
(
&
token
:
:
CloseDelim
(
token
:
:
Brace
)
)
)
;
match
any_disr
{
Some
(
disr_span
)
if
!
all_nullary
=
>
self
.
span_err
(
disr_span
"
discriminator
values
can
only
be
used
with
a
c
-
like
enum
"
)
_
=
>
(
)
}
Ok
(
ast
:
:
EnumDef
{
variants
:
variants
}
)
}
fn
parse_item_enum
(
&
mut
self
)
-
>
PResult
<
'
a
ItemInfo
>
{
let
id
=
try
!
(
self
.
parse_ident
(
)
)
;
let
mut
generics
=
try
!
(
self
.
parse_generics
(
)
)
;
generics
.
where_clause
=
try
!
(
self
.
parse_where_clause
(
)
)
;
try
!
(
self
.
expect
(
&
token
:
:
OpenDelim
(
token
:
:
Brace
)
)
)
;
let
enum_definition
=
try
!
(
self
.
parse_enum_def
(
&
generics
)
.
map_err
(
|
e
|
{
self
.
recover_stmt
(
)
;
self
.
eat
(
&
token
:
:
CloseDelim
(
token
:
:
Brace
)
)
;
e
}
)
)
;
Ok
(
(
id
ItemKind
:
:
Enum
(
enum_definition
generics
)
None
)
)
}
fn
parse_opt_abi
(
&
mut
self
)
-
>
PResult
<
'
a
Option
<
abi
:
:
Abi
>
>
{
match
self
.
token
{
token
:
:
Literal
(
token
:
:
Str_
(
s
)
suf
)
|
token
:
:
Literal
(
token
:
:
StrRaw
(
s
_
)
suf
)
=
>
{
let
sp
=
self
.
span
;
self
.
expect_no_suffix
(
sp
"
ABI
spec
"
suf
)
;
self
.
bump
(
)
;
match
abi
:
:
lookup
(
&
s
.
as_str
(
)
)
{
Some
(
abi
)
=
>
Ok
(
Some
(
abi
)
)
None
=
>
{
let
prev_span
=
self
.
prev_span
;
self
.
span_err
(
prev_span
&
format
!
(
"
invalid
ABI
:
expected
one
of
[
{
}
]
\
found
{
}
"
abi
:
:
all_names
(
)
.
join
(
"
"
)
s
)
)
;
Ok
(
None
)
}
}
}
_
=
>
Ok
(
None
)
}
}
fn
parse_item_
(
&
mut
self
attrs
:
Vec
<
Attribute
>
macros_allowed
:
bool
attributes_allowed
:
bool
)
-
>
PResult
<
'
a
Option
<
P
<
Item
>
>
>
{
maybe_whole
!
(
self
NtItem
|
item
|
{
let
mut
item
=
item
.
unwrap
(
)
;
let
mut
attrs
=
attrs
;
mem
:
:
swap
(
&
mut
item
.
attrs
&
mut
attrs
)
;
item
.
attrs
.
extend
(
attrs
)
;
Some
(
P
(
item
)
)
}
)
;
let
lo
=
self
.
span
.
lo
;
let
visibility
=
try
!
(
self
.
parse_visibility
(
true
)
)
;
if
self
.
eat_keyword
(
keywords
:
:
Use
)
{
let
item_
=
ItemKind
:
:
Use
(
try
!
(
self
.
parse_view_path
(
)
)
)
;
try
!
(
self
.
expect
(
&
token
:
:
Semi
)
)
;
let
prev_span
=
self
.
prev_span
;
let
item
=
self
.
mk_item
(
lo
prev_span
.
hi
keywords
:
:
Invalid
.
ident
(
)
item_
visibility
attrs
)
;
return
Ok
(
Some
(
item
)
)
;
}
if
self
.
eat_keyword
(
keywords
:
:
Extern
)
{
if
self
.
eat_keyword
(
keywords
:
:
Crate
)
{
return
Ok
(
Some
(
try
!
(
self
.
parse_item_extern_crate
(
lo
visibility
attrs
)
)
)
)
;
}
let
opt_abi
=
try
!
(
self
.
parse_opt_abi
(
)
)
;
if
self
.
eat_keyword
(
keywords
:
:
Fn
)
{
let
fn_span
=
self
.
prev_span
;
let
abi
=
opt_abi
.
unwrap_or
(
Abi
:
:
C
)
;
let
(
ident
item_
extra_attrs
)
=
try
!
(
self
.
parse_item_fn
(
Unsafety
:
:
Normal
respan
(
fn_span
Constness
:
:
NotConst
)
abi
)
)
;
let
prev_span
=
self
.
prev_span
;
let
item
=
self
.
mk_item
(
lo
prev_span
.
hi
ident
item_
visibility
maybe_append
(
attrs
extra_attrs
)
)
;
return
Ok
(
Some
(
item
)
)
;
}
else
if
self
.
check
(
&
token
:
:
OpenDelim
(
token
:
:
Brace
)
)
{
return
Ok
(
Some
(
try
!
(
self
.
parse_item_foreign_mod
(
lo
opt_abi
visibility
attrs
)
)
)
)
;
}
try
!
(
self
.
unexpected
(
)
)
;
}
if
self
.
eat_keyword
(
keywords
:
:
Static
)
{
let
m
=
if
self
.
eat_keyword
(
keywords
:
:
Mut
)
{
Mutability
:
:
Mutable
}
else
{
Mutability
:
:
Immutable
}
;
let
(
ident
item_
extra_attrs
)
=
try
!
(
self
.
parse_item_const
(
Some
(
m
)
)
)
;
let
prev_span
=
self
.
prev_span
;
let
item
=
self
.
mk_item
(
lo
prev_span
.
hi
ident
item_
visibility
maybe_append
(
attrs
extra_attrs
)
)
;
return
Ok
(
Some
(
item
)
)
;
}
if
self
.
eat_keyword
(
keywords
:
:
Const
)
{
let
const_span
=
self
.
prev_span
;
if
self
.
check_keyword
(
keywords
:
:
Fn
)
|
|
(
self
.
check_keyword
(
keywords
:
:
Unsafe
)
&
&
self
.
look_ahead
(
1
|
t
|
t
.
is_keyword
(
keywords
:
:
Fn
)
)
)
{
let
unsafety
=
if
self
.
eat_keyword
(
keywords
:
:
Unsafe
)
{
Unsafety
:
:
Unsafe
}
else
{
Unsafety
:
:
Normal
}
;
self
.
bump
(
)
;
let
(
ident
item_
extra_attrs
)
=
try
!
(
self
.
parse_item_fn
(
unsafety
respan
(
const_span
Constness
:
:
Const
)
Abi
:
:
Rust
)
)
;
let
prev_span
=
self
.
prev_span
;
let
item
=
self
.
mk_item
(
lo
prev_span
.
hi
ident
item_
visibility
maybe_append
(
attrs
extra_attrs
)
)
;
return
Ok
(
Some
(
item
)
)
;
}
if
self
.
eat_keyword
(
keywords
:
:
Mut
)
{
let
prev_span
=
self
.
prev_span
;
self
.
diagnostic
(
)
.
struct_span_err
(
prev_span
"
const
globals
cannot
be
mutable
"
)
.
help
(
"
did
you
mean
to
declare
a
static
?
"
)
.
emit
(
)
;
}
let
(
ident
item_
extra_attrs
)
=
try
!
(
self
.
parse_item_const
(
None
)
)
;
let
prev_span
=
self
.
prev_span
;
let
item
=
self
.
mk_item
(
lo
prev_span
.
hi
ident
item_
visibility
maybe_append
(
attrs
extra_attrs
)
)
;
return
Ok
(
Some
(
item
)
)
;
}
if
self
.
check_keyword
(
keywords
:
:
Unsafe
)
&
&
self
.
look_ahead
(
1
|
t
|
t
.
is_keyword
(
keywords
:
:
Trait
)
)
{
try
!
(
self
.
expect_keyword
(
keywords
:
:
Unsafe
)
)
;
try
!
(
self
.
expect_keyword
(
keywords
:
:
Trait
)
)
;
let
(
ident
item_
extra_attrs
)
=
try
!
(
self
.
parse_item_trait
(
ast
:
:
Unsafety
:
:
Unsafe
)
)
;
let
prev_span
=
self
.
prev_span
;
let
item
=
self
.
mk_item
(
lo
prev_span
.
hi
ident
item_
visibility
maybe_append
(
attrs
extra_attrs
)
)
;
return
Ok
(
Some
(
item
)
)
;
}
if
self
.
check_keyword
(
keywords
:
:
Unsafe
)
&
&
self
.
look_ahead
(
1
|
t
|
t
.
is_keyword
(
keywords
:
:
Impl
)
)
{
try
!
(
self
.
expect_keyword
(
keywords
:
:
Unsafe
)
)
;
try
!
(
self
.
expect_keyword
(
keywords
:
:
Impl
)
)
;
let
(
ident
item_
extra_attrs
)
=
try
!
(
self
.
parse_item_impl
(
ast
:
:
Unsafety
:
:
Unsafe
)
)
;
let
prev_span
=
self
.
prev_span
;
let
item
=
self
.
mk_item
(
lo
prev_span
.
hi
ident
item_
visibility
maybe_append
(
attrs
extra_attrs
)
)
;
return
Ok
(
Some
(
item
)
)
;
}
if
self
.
check_keyword
(
keywords
:
:
Fn
)
{
self
.
bump
(
)
;
let
fn_span
=
self
.
prev_span
;
let
(
ident
item_
extra_attrs
)
=
try
!
(
self
.
parse_item_fn
(
Unsafety
:
:
Normal
respan
(
fn_span
Constness
:
:
NotConst
)
Abi
:
:
Rust
)
)
;
let
prev_span
=
self
.
prev_span
;
let
item
=
self
.
mk_item
(
lo
prev_span
.
hi
ident
item_
visibility
maybe_append
(
attrs
extra_attrs
)
)
;
return
Ok
(
Some
(
item
)
)
;
}
if
self
.
check_keyword
(
keywords
:
:
Unsafe
)
&
&
self
.
look_ahead
(
1
|
t
|
*
t
!
=
token
:
:
OpenDelim
(
token
:
:
Brace
)
)
{
self
.
bump
(
)
;
let
abi
=
if
self
.
eat_keyword
(
keywords
:
:
Extern
)
{
try
!
(
self
.
parse_opt_abi
(
)
)
.
unwrap_or
(
Abi
:
:
C
)
}
else
{
Abi
:
:
Rust
}
;
try
!
(
self
.
expect_keyword
(
keywords
:
:
Fn
)
)
;
let
fn_span
=
self
.
prev_span
;
let
(
ident
item_
extra_attrs
)
=
try
!
(
self
.
parse_item_fn
(
Unsafety
:
:
Unsafe
respan
(
fn_span
Constness
:
:
NotConst
)
abi
)
)
;
let
prev_span
=
self
.
prev_span
;
let
item
=
self
.
mk_item
(
lo
prev_span
.
hi
ident
item_
visibility
maybe_append
(
attrs
extra_attrs
)
)
;
return
Ok
(
Some
(
item
)
)
;
}
if
self
.
eat_keyword
(
keywords
:
:
Mod
)
{
let
(
ident
item_
extra_attrs
)
=
try
!
(
self
.
parse_item_mod
(
&
attrs
[
.
.
]
)
)
;
let
prev_span
=
self
.
prev_span
;
let
item
=
self
.
mk_item
(
lo
prev_span
.
hi
ident
item_
visibility
maybe_append
(
attrs
extra_attrs
)
)
;
return
Ok
(
Some
(
item
)
)
;
}
if
self
.
eat_keyword
(
keywords
:
:
Type
)
{
let
(
ident
item_
extra_attrs
)
=
try
!
(
self
.
parse_item_type
(
)
)
;
let
prev_span
=
self
.
prev_span
;
let
item
=
self
.
mk_item
(
lo
prev_span
.
hi
ident
item_
visibility
maybe_append
(
attrs
extra_attrs
)
)
;
return
Ok
(
Some
(
item
)
)
;
}
if
self
.
eat_keyword
(
keywords
:
:
Enum
)
{
let
(
ident
item_
extra_attrs
)
=
try
!
(
self
.
parse_item_enum
(
)
)
;
let
prev_span
=
self
.
prev_span
;
let
item
=
self
.
mk_item
(
lo
prev_span
.
hi
ident
item_
visibility
maybe_append
(
attrs
extra_attrs
)
)
;
return
Ok
(
Some
(
item
)
)
;
}
if
self
.
eat_keyword
(
keywords
:
:
Trait
)
{
let
(
ident
item_
extra_attrs
)
=
try
!
(
self
.
parse_item_trait
(
ast
:
:
Unsafety
:
:
Normal
)
)
;
let
prev_span
=
self
.
prev_span
;
let
item
=
self
.
mk_item
(
lo
prev_span
.
hi
ident
item_
visibility
maybe_append
(
attrs
extra_attrs
)
)
;
return
Ok
(
Some
(
item
)
)
;
}
if
self
.
eat_keyword
(
keywords
:
:
Impl
)
{
let
(
ident
item_
extra_attrs
)
=
try
!
(
self
.
parse_item_impl
(
ast
:
:
Unsafety
:
:
Normal
)
)
;
let
prev_span
=
self
.
prev_span
;
let
item
=
self
.
mk_item
(
lo
prev_span
.
hi
ident
item_
visibility
maybe_append
(
attrs
extra_attrs
)
)
;
return
Ok
(
Some
(
item
)
)
;
}
if
self
.
eat_keyword
(
keywords
:
:
Struct
)
{
let
(
ident
item_
extra_attrs
)
=
try
!
(
self
.
parse_item_struct
(
)
)
;
let
prev_span
=
self
.
prev_span
;
let
item
=
self
.
mk_item
(
lo
prev_span
.
hi
ident
item_
visibility
maybe_append
(
attrs
extra_attrs
)
)
;
return
Ok
(
Some
(
item
)
)
;
}
if
self
.
is_union_item
(
)
{
self
.
bump
(
)
;
let
(
ident
item_
extra_attrs
)
=
try
!
(
self
.
parse_item_union
(
)
)
;
let
prev_span
=
self
.
prev_span
;
let
item
=
self
.
mk_item
(
lo
prev_span
.
hi
ident
item_
visibility
maybe_append
(
attrs
extra_attrs
)
)
;
return
Ok
(
Some
(
item
)
)
;
}
self
.
parse_macro_use_or_failure
(
attrs
macros_allowed
attributes_allowed
lo
visibility
)
}
fn
parse_foreign_item
(
&
mut
self
)
-
>
PResult
<
'
a
Option
<
ForeignItem
>
>
{
let
attrs
=
try
!
(
self
.
parse_outer_attributes
(
)
)
;
let
lo
=
self
.
span
.
lo
;
let
visibility
=
try
!
(
self
.
parse_visibility
(
true
)
)
;
if
self
.
check_keyword
(
keywords
:
:
Static
)
{
return
Ok
(
Some
(
try
!
(
self
.
parse_item_foreign_static
(
visibility
lo
attrs
)
)
)
)
;
}
if
self
.
check_keyword
(
keywords
:
:
Fn
)
{
return
Ok
(
Some
(
try
!
(
self
.
parse_item_foreign_fn
(
visibility
lo
attrs
)
)
)
)
;
}
match
try
!
(
self
.
parse_macro_use_or_failure
(
attrs
true
false
lo
visibility
)
)
{
Some
(
item
)
=
>
{
return
Err
(
self
.
span_fatal
(
item
.
span
"
macros
cannot
expand
to
foreign
items
"
)
)
;
}
None
=
>
Ok
(
None
)
}
}
fn
parse_macro_use_or_failure
(
&
mut
self
attrs
:
Vec
<
Attribute
>
macros_allowed
:
bool
attributes_allowed
:
bool
lo
:
BytePos
visibility
:
Visibility
)
-
>
PResult
<
'
a
Option
<
P
<
Item
>
>
>
{
if
macros_allowed
&
&
self
.
token
.
is_path_start
(
)
{
let
prev_span
=
self
.
prev_span
;
self
.
complain_if_pub_macro
(
&
visibility
prev_span
)
;
let
mac_lo
=
self
.
span
.
lo
;
let
pth
=
try
!
(
self
.
parse_path
(
PathStyle
:
:
Mod
)
)
;
try
!
(
self
.
expect
(
&
token
:
:
Not
)
)
;
let
id
=
if
self
.
token
.
is_ident
(
)
{
try
!
(
self
.
parse_ident
(
)
)
}
else
{
keywords
:
:
Invalid
.
ident
(
)
}
;
let
delim
=
try
!
(
self
.
expect_open_delim
(
)
)
;
let
tts
=
try
!
(
self
.
parse_seq_to_end
(
&
token
:
:
CloseDelim
(
delim
)
SeqSep
:
:
none
(
)
|
p
|
p
.
parse_token_tree
(
)
)
)
;
if
delim
!
=
token
:
:
Brace
{
if
!
self
.
eat
(
&
token
:
:
Semi
)
{
let
prev_span
=
self
.
prev_span
;
self
.
span_err
(
prev_span
"
macros
that
expand
to
items
must
either
\
be
surrounded
with
braces
or
followed
by
\
a
semicolon
"
)
;
}
}
let
hi
=
self
.
prev_span
.
hi
;
let
mac
=
spanned
(
mac_lo
hi
Mac_
{
path
:
pth
tts
:
tts
}
)
;
let
item
=
self
.
mk_item
(
lo
hi
id
ItemKind
:
:
Mac
(
mac
)
visibility
attrs
)
;
return
Ok
(
Some
(
item
)
)
;
}
match
visibility
{
Visibility
:
:
Inherited
=
>
{
}
_
=
>
{
let
prev_span
=
self
.
prev_span
;
return
Err
(
self
.
span_fatal
(
prev_span
"
unmatched
visibility
pub
"
)
)
;
}
}
if
!
attributes_allowed
&
&
!
attrs
.
is_empty
(
)
{
self
.
expected_item_err
(
&
attrs
)
;
}
Ok
(
None
)
}
pub
fn
parse_item
(
&
mut
self
)
-
>
PResult
<
'
a
Option
<
P
<
Item
>
>
>
{
let
attrs
=
try
!
(
self
.
parse_outer_attributes
(
)
)
;
self
.
parse_item_
(
attrs
true
false
)
}
fn
parse_path_list_items
(
&
mut
self
)
-
>
PResult
<
'
a
Vec
<
ast
:
:
PathListItem
>
>
{
self
.
parse_unspanned_seq
(
&
token
:
:
OpenDelim
(
token
:
:
Brace
)
&
token
:
:
CloseDelim
(
token
:
:
Brace
)
SeqSep
:
:
trailing_allowed
(
token
:
:
Comma
)
|
this
|
{
let
lo
=
this
.
span
.
lo
;
let
ident
=
if
this
.
eat_keyword
(
keywords
:
:
SelfValue
)
{
keywords
:
:
SelfValue
.
ident
(
)
}
else
{
try
!
(
this
.
parse_ident
(
)
)
}
;
let
rename
=
try
!
(
this
.
parse_rename
(
)
)
;
let
node
=
ast
:
:
PathListItem_
{
name
:
ident
rename
:
rename
id
:
ast
:
:
DUMMY_NODE_ID
}
;
let
hi
=
this
.
prev_span
.
hi
;
Ok
(
spanned
(
lo
hi
node
)
)
}
)
}
fn
is_import_coupler
(
&
mut
self
)
-
>
bool
{
self
.
check
(
&
token
:
:
ModSep
)
&
&
self
.
look_ahead
(
1
|
t
|
*
t
=
=
token
:
:
OpenDelim
(
token
:
:
Brace
)
|
|
*
t
=
=
token
:
:
BinOp
(
token
:
:
Star
)
)
}
fn
parse_view_path
(
&
mut
self
)
-
>
PResult
<
'
a
P
<
ViewPath
>
>
{
let
lo
=
self
.
span
.
lo
;
if
self
.
check
(
&
token
:
:
OpenDelim
(
token
:
:
Brace
)
)
|
|
self
.
check
(
&
token
:
:
BinOp
(
token
:
:
Star
)
)
|
|
self
.
is_import_coupler
(
)
{
let
prefix
=
ast
:
:
Path
{
global
:
self
.
eat
(
&
token
:
:
ModSep
)
segments
:
Vec
:
:
new
(
)
span
:
mk_sp
(
lo
self
.
span
.
hi
)
}
;
let
view_path_kind
=
if
self
.
eat
(
&
token
:
:
BinOp
(
token
:
:
Star
)
)
{
ViewPathGlob
(
prefix
)
}
else
{
ViewPathList
(
prefix
try
!
(
self
.
parse_path_list_items
(
)
)
)
}
;
Ok
(
P
(
spanned
(
lo
self
.
span
.
hi
view_path_kind
)
)
)
}
else
{
let
prefix
=
try
!
(
self
.
parse_path
(
PathStyle
:
:
Mod
)
)
;
if
self
.
is_import_coupler
(
)
{
self
.
bump
(
)
;
if
self
.
check
(
&
token
:
:
BinOp
(
token
:
:
Star
)
)
{
self
.
bump
(
)
;
Ok
(
P
(
spanned
(
lo
self
.
span
.
hi
ViewPathGlob
(
prefix
)
)
)
)
}
else
{
let
items
=
try
!
(
self
.
parse_path_list_items
(
)
)
;
Ok
(
P
(
spanned
(
lo
self
.
span
.
hi
ViewPathList
(
prefix
items
)
)
)
)
}
}
else
{
let
rename
=
try
!
(
self
.
parse_rename
(
)
)
.
unwrap_or
(
prefix
.
segments
.
last
(
)
.
unwrap
(
)
.
identifier
)
;
Ok
(
P
(
spanned
(
lo
self
.
prev_span
.
hi
ViewPathSimple
(
rename
prefix
)
)
)
)
}
}
}
fn
parse_rename
(
&
mut
self
)
-
>
PResult
<
'
a
Option
<
Ident
>
>
{
if
self
.
eat_keyword
(
keywords
:
:
As
)
{
self
.
parse_ident
(
)
.
map
(
Some
)
}
else
{
Ok
(
None
)
}
}
pub
fn
parse_crate_mod
(
&
mut
self
)
-
>
PResult
<
'
a
Crate
>
{
let
lo
=
self
.
span
.
lo
;
Ok
(
ast
:
:
Crate
{
attrs
:
try
!
(
self
.
parse_inner_attributes
(
)
)
module
:
try
!
(
self
.
parse_mod_items
(
&
token
:
:
Eof
lo
)
)
span
:
mk_sp
(
lo
self
.
span
.
lo
)
exported_macros
:
Vec
:
:
new
(
)
}
)
}
pub
fn
parse_optional_str
(
&
mut
self
)
-
>
Option
<
(
InternedString
ast
:
:
StrStyle
Option
<
ast
:
:
Name
>
)
>
{
let
ret
=
match
self
.
token
{
token
:
:
Literal
(
token
:
:
Str_
(
s
)
suf
)
=
>
{
let
s
=
self
.
id_to_interned_str
(
ast
:
:
Ident
:
:
with_empty_ctxt
(
s
)
)
;
(
s
ast
:
:
StrStyle
:
:
Cooked
suf
)
}
token
:
:
Literal
(
token
:
:
StrRaw
(
s
n
)
suf
)
=
>
{
let
s
=
self
.
id_to_interned_str
(
ast
:
:
Ident
:
:
with_empty_ctxt
(
s
)
)
;
(
s
ast
:
:
StrStyle
:
:
Raw
(
n
)
suf
)
}
_
=
>
return
None
}
;
self
.
bump
(
)
;
Some
(
ret
)
}
pub
fn
parse_str
(
&
mut
self
)
-
>
PResult
<
'
a
(
InternedString
StrStyle
)
>
{
match
self
.
parse_optional_str
(
)
{
Some
(
(
s
style
suf
)
)
=
>
{
let
sp
=
self
.
prev_span
;
self
.
expect_no_suffix
(
sp
"
string
literal
"
suf
)
;
Ok
(
(
s
style
)
)
}
_
=
>
Err
(
self
.
fatal
(
"
expected
string
literal
"
)
)
}
}
}
