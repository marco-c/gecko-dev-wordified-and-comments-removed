pub
use
self
:
:
NamedMatch
:
:
*
;
pub
use
self
:
:
ParseResult
:
:
*
;
use
self
:
:
TokenTreeOrTokenTreeVec
:
:
*
;
use
ast
:
:
Ident
;
use
syntax_pos
:
:
{
self
BytePos
mk_sp
Span
}
;
use
codemap
:
:
Spanned
;
use
errors
:
:
FatalError
;
use
parse
:
:
lexer
:
:
*
;
use
parse
:
:
ParseSess
;
use
parse
:
:
parser
:
:
{
PathStyle
Parser
}
;
use
parse
:
:
token
:
:
{
DocComment
MatchNt
SubstNt
}
;
use
parse
:
:
token
:
:
{
Token
Nonterminal
}
;
use
parse
:
:
token
;
use
print
:
:
pprust
;
use
ptr
:
:
P
;
use
tokenstream
:
:
{
self
TokenTree
}
;
use
util
:
:
small_vector
:
:
SmallVector
;
use
std
:
:
mem
;
use
std
:
:
rc
:
:
Rc
;
use
std
:
:
collections
:
:
HashMap
;
use
std
:
:
collections
:
:
hash_map
:
:
Entry
:
:
{
Vacant
Occupied
}
;
#
[
derive
(
Clone
)
]
enum
TokenTreeOrTokenTreeVec
{
Tt
(
tokenstream
:
:
TokenTree
)
TtSeq
(
Vec
<
tokenstream
:
:
TokenTree
>
)
}
impl
TokenTreeOrTokenTreeVec
{
fn
len
(
&
self
)
-
>
usize
{
match
*
self
{
TtSeq
(
ref
v
)
=
>
v
.
len
(
)
Tt
(
ref
tt
)
=
>
tt
.
len
(
)
}
}
fn
get_tt
(
&
self
index
:
usize
)
-
>
TokenTree
{
match
*
self
{
TtSeq
(
ref
v
)
=
>
v
[
index
]
.
clone
(
)
Tt
(
ref
tt
)
=
>
tt
.
get_tt
(
index
)
}
}
}
#
[
derive
(
Clone
)
]
struct
MatcherTtFrame
{
elts
:
TokenTreeOrTokenTreeVec
idx
:
usize
}
#
[
derive
(
Clone
)
]
pub
struct
MatcherPos
{
stack
:
Vec
<
MatcherTtFrame
>
top_elts
:
TokenTreeOrTokenTreeVec
sep
:
Option
<
Token
>
idx
:
usize
up
:
Option
<
Box
<
MatcherPos
>
>
matches
:
Vec
<
Vec
<
Rc
<
NamedMatch
>
>
>
match_lo
:
usize
match_cur
:
usize
match_hi
:
usize
sp_lo
:
BytePos
}
pub
fn
count_names
(
ms
:
&
[
TokenTree
]
)
-
>
usize
{
ms
.
iter
(
)
.
fold
(
0
|
count
elt
|
{
count
+
match
*
elt
{
TokenTree
:
:
Sequence
(
_
ref
seq
)
=
>
{
seq
.
num_captures
}
TokenTree
:
:
Delimited
(
_
ref
delim
)
=
>
{
count_names
(
&
delim
.
tts
)
}
TokenTree
:
:
Token
(
_
MatchNt
(
.
.
)
)
=
>
{
1
}
TokenTree
:
:
Token
(
.
.
)
=
>
0
}
}
)
}
pub
fn
initial_matcher_pos
(
ms
:
Vec
<
TokenTree
>
sep
:
Option
<
Token
>
lo
:
BytePos
)
-
>
Box
<
MatcherPos
>
{
let
match_idx_hi
=
count_names
(
&
ms
[
.
.
]
)
;
let
matches
:
Vec
<
_
>
=
(
0
.
.
match_idx_hi
)
.
map
(
|
_
|
Vec
:
:
new
(
)
)
.
collect
(
)
;
Box
:
:
new
(
MatcherPos
{
stack
:
vec
!
[
]
top_elts
:
TtSeq
(
ms
)
sep
:
sep
idx
:
0
up
:
None
matches
:
matches
match_lo
:
0
match_cur
:
0
match_hi
:
match_idx_hi
sp_lo
:
lo
}
)
}
pub
enum
NamedMatch
{
MatchedSeq
(
Vec
<
Rc
<
NamedMatch
>
>
syntax_pos
:
:
Span
)
MatchedNonterminal
(
Nonterminal
)
}
pub
fn
nameize
(
p_s
:
&
ParseSess
ms
:
&
[
TokenTree
]
res
:
&
[
Rc
<
NamedMatch
>
]
)
-
>
ParseResult
<
HashMap
<
Ident
Rc
<
NamedMatch
>
>
>
{
fn
n_rec
(
p_s
:
&
ParseSess
m
:
&
TokenTree
res
:
&
[
Rc
<
NamedMatch
>
]
ret_val
:
&
mut
HashMap
<
Ident
Rc
<
NamedMatch
>
>
idx
:
&
mut
usize
)
-
>
Result
<
(
)
(
syntax_pos
:
:
Span
String
)
>
{
match
*
m
{
TokenTree
:
:
Sequence
(
_
ref
seq
)
=
>
{
for
next_m
in
&
seq
.
tts
{
try
!
(
n_rec
(
p_s
next_m
res
ret_val
idx
)
)
}
}
TokenTree
:
:
Delimited
(
_
ref
delim
)
=
>
{
for
next_m
in
&
delim
.
tts
{
try
!
(
n_rec
(
p_s
next_m
res
ret_val
idx
)
)
;
}
}
TokenTree
:
:
Token
(
sp
MatchNt
(
bind_name
_
)
)
=
>
{
match
ret_val
.
entry
(
bind_name
)
{
Vacant
(
spot
)
=
>
{
spot
.
insert
(
res
[
*
idx
]
.
clone
(
)
)
;
*
idx
+
=
1
;
}
Occupied
(
.
.
)
=
>
{
return
Err
(
(
sp
format
!
(
"
duplicated
bind
name
:
{
}
"
bind_name
)
)
)
}
}
}
TokenTree
:
:
Token
(
sp
SubstNt
(
.
.
)
)
=
>
{
return
Err
(
(
sp
"
missing
fragment
specifier
"
.
to_string
(
)
)
)
}
TokenTree
:
:
Token
(
.
.
)
=
>
(
)
}
Ok
(
(
)
)
}
let
mut
ret_val
=
HashMap
:
:
new
(
)
;
let
mut
idx
=
0
;
for
m
in
ms
{
match
n_rec
(
p_s
m
res
&
mut
ret_val
&
mut
idx
)
{
Ok
(
_
)
=
>
{
}
Err
(
(
sp
msg
)
)
=
>
return
Error
(
sp
msg
)
}
}
Success
(
ret_val
)
}
pub
enum
ParseResult
<
T
>
{
Success
(
T
)
Failure
(
syntax_pos
:
:
Span
Token
)
Error
(
syntax_pos
:
:
Span
String
)
}
pub
fn
parse_failure_msg
(
tok
:
Token
)
-
>
String
{
match
tok
{
token
:
:
Eof
=
>
"
unexpected
end
of
macro
invocation
"
.
to_string
(
)
_
=
>
format
!
(
"
no
rules
expected
the
token
{
}
"
pprust
:
:
token_to_string
(
&
tok
)
)
}
}
pub
type
NamedParseResult
=
ParseResult
<
HashMap
<
Ident
Rc
<
NamedMatch
>
>
>
;
pub
fn
token_name_eq
(
t1
:
&
Token
t2
:
&
Token
)
-
>
bool
{
match
(
t1
t2
)
{
(
&
token
:
:
Ident
(
id1
)
&
token
:
:
Ident
(
id2
)
)
|
(
&
token
:
:
Lifetime
(
id1
)
&
token
:
:
Lifetime
(
id2
)
)
=
>
id1
.
name
=
=
id2
.
name
_
=
>
*
t1
=
=
*
t2
}
}
pub
fn
parse
(
sess
:
&
ParseSess
mut
rdr
:
TtReader
ms
:
&
[
TokenTree
]
)
-
>
NamedParseResult
{
let
mut
cur_eis
=
SmallVector
:
:
one
(
initial_matcher_pos
(
ms
.
to_owned
(
)
None
rdr
.
peek
(
)
.
sp
.
lo
)
)
;
loop
{
let
mut
bb_eis
=
Vec
:
:
new
(
)
;
let
mut
next_eis
=
Vec
:
:
new
(
)
;
let
mut
eof_eis
=
Vec
:
:
new
(
)
;
let
TokenAndSpan
{
tok
sp
}
=
rdr
.
peek
(
)
;
loop
{
let
mut
ei
=
match
cur_eis
.
pop
(
)
{
None
=
>
break
Some
(
ei
)
=
>
ei
}
;
while
ei
.
idx
>
=
ei
.
top_elts
.
len
(
)
{
match
ei
.
stack
.
pop
(
)
{
Some
(
MatcherTtFrame
{
elts
idx
}
)
=
>
{
ei
.
top_elts
=
elts
;
ei
.
idx
=
idx
+
1
;
}
None
=
>
break
}
}
let
idx
=
ei
.
idx
;
let
len
=
ei
.
top_elts
.
len
(
)
;
if
idx
>
=
len
{
if
ei
.
up
.
is_some
(
)
{
if
idx
=
=
len
{
let
mut
new_pos
=
ei
.
up
.
clone
(
)
.
unwrap
(
)
;
for
idx
in
ei
.
match_lo
.
.
ei
.
match_hi
{
let
sub
=
(
ei
.
matches
[
idx
]
)
.
clone
(
)
;
(
&
mut
new_pos
.
matches
[
idx
]
)
.
push
(
Rc
:
:
new
(
MatchedSeq
(
sub
mk_sp
(
ei
.
sp_lo
sp
.
hi
)
)
)
)
;
}
new_pos
.
match_cur
=
ei
.
match_hi
;
new_pos
.
idx
+
=
1
;
cur_eis
.
push
(
new_pos
)
;
}
match
ei
.
sep
{
Some
(
ref
t
)
if
idx
=
=
len
=
>
{
if
token_name_eq
(
&
tok
t
)
{
let
mut
ei_t
=
ei
.
clone
(
)
;
ei_t
.
idx
+
=
1
;
next_eis
.
push
(
ei_t
)
;
}
}
_
=
>
{
let
mut
ei_t
=
ei
;
ei_t
.
match_cur
=
ei_t
.
match_lo
;
ei_t
.
idx
=
0
;
cur_eis
.
push
(
ei_t
)
;
}
}
}
else
{
eof_eis
.
push
(
ei
)
;
}
}
else
{
match
ei
.
top_elts
.
get_tt
(
idx
)
{
TokenTree
:
:
Sequence
(
sp
seq
)
=
>
{
if
seq
.
op
=
=
tokenstream
:
:
KleeneOp
:
:
ZeroOrMore
{
let
mut
new_ei
=
ei
.
clone
(
)
;
new_ei
.
match_cur
+
=
seq
.
num_captures
;
new_ei
.
idx
+
=
1
;
for
idx
in
ei
.
match_cur
.
.
ei
.
match_cur
+
seq
.
num_captures
{
(
&
mut
new_ei
.
matches
[
idx
]
)
.
push
(
Rc
:
:
new
(
MatchedSeq
(
vec
!
[
]
sp
)
)
)
;
}
cur_eis
.
push
(
new_ei
)
;
}
let
matches
:
Vec
<
_
>
=
(
0
.
.
ei
.
matches
.
len
(
)
)
.
map
(
|
_
|
Vec
:
:
new
(
)
)
.
collect
(
)
;
let
ei_t
=
ei
;
cur_eis
.
push
(
Box
:
:
new
(
MatcherPos
{
stack
:
vec
!
[
]
sep
:
seq
.
separator
.
clone
(
)
idx
:
0
matches
:
matches
match_lo
:
ei_t
.
match_cur
match_cur
:
ei_t
.
match_cur
match_hi
:
ei_t
.
match_cur
+
seq
.
num_captures
up
:
Some
(
ei_t
)
sp_lo
:
sp
.
lo
top_elts
:
Tt
(
TokenTree
:
:
Sequence
(
sp
seq
)
)
}
)
)
;
}
TokenTree
:
:
Token
(
_
MatchNt
(
.
.
)
)
=
>
{
match
tok
{
token
:
:
CloseDelim
(
_
)
=
>
{
}
_
=
>
bb_eis
.
push
(
ei
)
}
}
TokenTree
:
:
Token
(
sp
SubstNt
(
.
.
)
)
=
>
{
return
Error
(
sp
"
missing
fragment
specifier
"
.
to_string
(
)
)
}
seq
TokenTree
:
:
Delimited
(
.
.
)
|
seq
TokenTree
:
:
Token
(
_
DocComment
(
.
.
)
)
=
>
{
let
lower_elts
=
mem
:
:
replace
(
&
mut
ei
.
top_elts
Tt
(
seq
)
)
;
let
idx
=
ei
.
idx
;
ei
.
stack
.
push
(
MatcherTtFrame
{
elts
:
lower_elts
idx
:
idx
}
)
;
ei
.
idx
=
0
;
cur_eis
.
push
(
ei
)
;
}
TokenTree
:
:
Token
(
_
ref
t
)
=
>
{
if
token_name_eq
(
t
&
tok
)
{
let
mut
ei_t
=
ei
.
clone
(
)
;
ei_t
.
idx
+
=
1
;
next_eis
.
push
(
ei_t
)
;
}
}
}
}
}
if
token_name_eq
(
&
tok
&
token
:
:
Eof
)
{
if
eof_eis
.
len
(
)
=
=
1
{
let
mut
v
=
Vec
:
:
new
(
)
;
for
dv
in
&
mut
(
&
mut
eof_eis
[
0
]
)
.
matches
{
v
.
push
(
dv
.
pop
(
)
.
unwrap
(
)
)
;
}
return
nameize
(
sess
ms
&
v
[
.
.
]
)
;
}
else
if
eof_eis
.
len
(
)
>
1
{
return
Error
(
sp
"
ambiguity
:
multiple
successful
parses
"
.
to_string
(
)
)
;
}
else
{
return
Failure
(
sp
token
:
:
Eof
)
;
}
}
else
{
if
(
!
bb_eis
.
is_empty
(
)
&
&
!
next_eis
.
is_empty
(
)
)
|
|
bb_eis
.
len
(
)
>
1
{
let
nts
=
bb_eis
.
iter
(
)
.
map
(
|
ei
|
match
ei
.
top_elts
.
get_tt
(
ei
.
idx
)
{
TokenTree
:
:
Token
(
_
MatchNt
(
bind
name
)
)
=
>
{
format
!
(
"
{
}
(
'
{
}
'
)
"
name
bind
)
}
_
=
>
panic
!
(
)
}
)
.
collect
:
:
<
Vec
<
String
>
>
(
)
.
join
(
"
or
"
)
;
return
Error
(
sp
format
!
(
"
local
ambiguity
:
multiple
parsing
options
:
{
}
"
match
next_eis
.
len
(
)
{
0
=
>
format
!
(
"
built
-
in
NTs
{
}
.
"
nts
)
1
=
>
format
!
(
"
built
-
in
NTs
{
}
or
1
other
option
.
"
nts
)
n
=
>
format
!
(
"
built
-
in
NTs
{
}
or
{
}
other
options
.
"
nts
n
)
}
)
)
}
else
if
bb_eis
.
is_empty
(
)
&
&
next_eis
.
is_empty
(
)
{
return
Failure
(
sp
tok
)
;
}
else
if
!
next_eis
.
is_empty
(
)
{
while
!
next_eis
.
is_empty
(
)
{
cur_eis
.
push
(
next_eis
.
pop
(
)
.
unwrap
(
)
)
;
}
rdr
.
next_token
(
)
;
}
else
{
rdr
.
next_tok
=
{
let
mut
rust_parser
=
Parser
:
:
new
(
sess
Box
:
:
new
(
&
mut
rdr
)
)
;
let
mut
ei
=
bb_eis
.
pop
(
)
.
unwrap
(
)
;
if
let
TokenTree
:
:
Token
(
span
MatchNt
(
_
ident
)
)
=
ei
.
top_elts
.
get_tt
(
ei
.
idx
)
{
let
match_cur
=
ei
.
match_cur
;
(
&
mut
ei
.
matches
[
match_cur
]
)
.
push
(
Rc
:
:
new
(
MatchedNonterminal
(
parse_nt
(
&
mut
rust_parser
span
&
ident
.
name
.
as_str
(
)
)
)
)
)
;
ei
.
idx
+
=
1
;
ei
.
match_cur
+
=
1
;
}
else
{
unreachable
!
(
)
}
cur_eis
.
push
(
ei
)
;
Some
(
TokenAndSpan
{
tok
:
rust_parser
.
token
sp
:
rust_parser
.
span
}
)
}
;
}
}
assert
!
(
!
cur_eis
.
is_empty
(
)
)
;
}
}
pub
fn
parse_nt
<
'
a
>
(
p
:
&
mut
Parser
<
'
a
>
sp
:
Span
name
:
&
str
)
-
>
Nonterminal
{
match
name
{
"
tt
"
=
>
{
p
.
quote_depth
+
=
1
;
let
res
:
:
:
parse
:
:
PResult
<
'
a
_
>
=
p
.
parse_token_tree
(
)
;
let
res
=
token
:
:
NtTT
(
P
(
panictry
!
(
res
)
)
)
;
p
.
quote_depth
-
=
1
;
return
res
;
}
_
=
>
{
}
}
p
.
check_unknown_macro_variable
(
)
;
match
name
{
"
item
"
=
>
match
panictry
!
(
p
.
parse_item
(
)
)
{
Some
(
i
)
=
>
token
:
:
NtItem
(
i
)
None
=
>
{
p
.
fatal
(
"
expected
an
item
keyword
"
)
.
emit
(
)
;
panic
!
(
FatalError
)
;
}
}
"
block
"
=
>
token
:
:
NtBlock
(
panictry
!
(
p
.
parse_block
(
)
)
)
"
stmt
"
=
>
match
panictry
!
(
p
.
parse_stmt
(
)
)
{
Some
(
s
)
=
>
token
:
:
NtStmt
(
P
(
s
)
)
None
=
>
{
p
.
fatal
(
"
expected
a
statement
"
)
.
emit
(
)
;
panic
!
(
FatalError
)
;
}
}
"
pat
"
=
>
token
:
:
NtPat
(
panictry
!
(
p
.
parse_pat
(
)
)
)
"
expr
"
=
>
token
:
:
NtExpr
(
panictry
!
(
p
.
parse_expr
(
)
)
)
"
ty
"
=
>
token
:
:
NtTy
(
panictry
!
(
p
.
parse_ty
(
)
)
)
"
ident
"
=
>
match
p
.
token
{
token
:
:
Ident
(
sn
)
=
>
{
p
.
bump
(
)
;
token
:
:
NtIdent
(
Box
:
:
new
(
Spanned
:
:
<
Ident
>
{
node
:
sn
span
:
p
.
span
}
)
)
}
_
=
>
{
let
token_str
=
pprust
:
:
token_to_string
(
&
p
.
token
)
;
p
.
fatal
(
&
format
!
(
"
expected
ident
found
{
}
"
&
token_str
[
.
.
]
)
)
.
emit
(
)
;
panic
!
(
FatalError
)
}
}
"
path
"
=
>
{
token
:
:
NtPath
(
Box
:
:
new
(
panictry
!
(
p
.
parse_path
(
PathStyle
:
:
Type
)
)
)
)
}
"
meta
"
=
>
token
:
:
NtMeta
(
panictry
!
(
p
.
parse_meta_item
(
)
)
)
_
=
>
p
.
span_bug
(
sp
"
invalid
fragment
specifier
"
)
}
}
