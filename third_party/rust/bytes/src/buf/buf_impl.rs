#
[
cfg
(
feature
=
"
std
"
)
]
use
crate
:
:
buf
:
:
{
reader
Reader
}
;
use
crate
:
:
buf
:
:
{
take
Chain
Take
}
;
use
core
:
:
{
cmp
mem
ptr
}
;
#
[
cfg
(
feature
=
"
std
"
)
]
use
std
:
:
io
:
:
IoSlice
;
use
alloc
:
:
boxed
:
:
Box
;
macro_rules
!
buf_get_impl
{
(
this
:
ident
typ
:
tt
:
:
conv
:
tt
)
=
>
{
{
const
SIZE
:
usize
=
mem
:
:
size_of
:
:
<
typ
>
(
)
;
/
/
try
to
convert
directly
from
the
bytes
/
/
this
Option
<
ret
>
trick
is
to
avoid
keeping
a
borrow
on
self
/
/
when
advance
(
)
is
called
(
mut
borrow
)
and
to
call
bytes
(
)
only
once
let
ret
=
this
.
chunk
(
)
.
get
(
.
.
SIZE
)
.
map
(
|
src
|
unsafe
{
typ
:
:
conv
(
*
(
src
as
*
const
_
as
*
const
[
_
;
SIZE
]
)
)
}
)
;
if
let
Some
(
ret
)
=
ret
{
/
/
if
the
direct
conversion
was
possible
advance
and
return
this
.
advance
(
SIZE
)
;
return
ret
;
}
else
{
/
/
if
not
we
copy
the
bytes
in
a
temp
buffer
then
convert
let
mut
buf
=
[
0
;
SIZE
]
;
this
.
copy_to_slice
(
&
mut
buf
)
;
/
/
(
do
the
advance
)
return
typ
:
:
conv
(
buf
)
;
}
}
}
;
(
le
=
>
this
:
ident
typ
:
tt
len_to_read
:
expr
)
=
>
{
{
debug_assert
!
(
mem
:
:
size_of
:
:
<
typ
>
(
)
>
=
len_to_read
)
;
/
/
The
same
trick
as
above
does
not
improve
the
best
case
speed
.
/
/
It
seems
to
be
linked
to
the
way
the
method
is
optimised
by
the
compiler
let
mut
buf
=
[
0
;
(
mem
:
:
size_of
:
:
<
typ
>
(
)
)
]
;
this
.
copy_to_slice
(
&
mut
buf
[
.
.
(
len_to_read
)
]
)
;
return
typ
:
:
from_le_bytes
(
buf
)
;
}
}
;
(
be
=
>
this
:
ident
typ
:
tt
len_to_read
:
expr
)
=
>
{
{
debug_assert
!
(
mem
:
:
size_of
:
:
<
typ
>
(
)
>
=
len_to_read
)
;
let
mut
buf
=
[
0
;
(
mem
:
:
size_of
:
:
<
typ
>
(
)
)
]
;
this
.
copy_to_slice
(
&
mut
buf
[
mem
:
:
size_of
:
:
<
typ
>
(
)
-
(
len_to_read
)
.
.
]
)
;
return
typ
:
:
from_be_bytes
(
buf
)
;
}
}
;
}
pub
trait
Buf
{
fn
remaining
(
&
self
)
-
>
usize
;
#
[
cfg_attr
(
docsrs
doc
(
alias
=
"
bytes
"
)
)
]
fn
chunk
(
&
self
)
-
>
&
[
u8
]
;
#
[
cfg
(
feature
=
"
std
"
)
]
fn
chunks_vectored
<
'
a
>
(
&
'
a
self
dst
:
&
mut
[
IoSlice
<
'
a
>
]
)
-
>
usize
{
if
dst
.
is_empty
(
)
{
return
0
;
}
if
self
.
has_remaining
(
)
{
dst
[
0
]
=
IoSlice
:
:
new
(
self
.
chunk
(
)
)
;
1
}
else
{
0
}
}
fn
advance
(
&
mut
self
cnt
:
usize
)
;
fn
has_remaining
(
&
self
)
-
>
bool
{
self
.
remaining
(
)
>
0
}
fn
copy_to_slice
(
&
mut
self
dst
:
&
mut
[
u8
]
)
{
let
mut
off
=
0
;
assert
!
(
self
.
remaining
(
)
>
=
dst
.
len
(
)
)
;
while
off
<
dst
.
len
(
)
{
let
cnt
;
unsafe
{
let
src
=
self
.
chunk
(
)
;
cnt
=
cmp
:
:
min
(
src
.
len
(
)
dst
.
len
(
)
-
off
)
;
ptr
:
:
copy_nonoverlapping
(
src
.
as_ptr
(
)
dst
[
off
.
.
]
.
as_mut_ptr
(
)
cnt
)
;
off
+
=
cnt
;
}
self
.
advance
(
cnt
)
;
}
}
fn
get_u8
(
&
mut
self
)
-
>
u8
{
assert
!
(
self
.
remaining
(
)
>
=
1
)
;
let
ret
=
self
.
chunk
(
)
[
0
]
;
self
.
advance
(
1
)
;
ret
}
fn
get_i8
(
&
mut
self
)
-
>
i8
{
assert
!
(
self
.
remaining
(
)
>
=
1
)
;
let
ret
=
self
.
chunk
(
)
[
0
]
as
i8
;
self
.
advance
(
1
)
;
ret
}
fn
get_u16
(
&
mut
self
)
-
>
u16
{
buf_get_impl
!
(
self
u16
:
:
from_be_bytes
)
;
}
fn
get_u16_le
(
&
mut
self
)
-
>
u16
{
buf_get_impl
!
(
self
u16
:
:
from_le_bytes
)
;
}
fn
get_i16
(
&
mut
self
)
-
>
i16
{
buf_get_impl
!
(
self
i16
:
:
from_be_bytes
)
;
}
fn
get_i16_le
(
&
mut
self
)
-
>
i16
{
buf_get_impl
!
(
self
i16
:
:
from_le_bytes
)
;
}
fn
get_u32
(
&
mut
self
)
-
>
u32
{
buf_get_impl
!
(
self
u32
:
:
from_be_bytes
)
;
}
fn
get_u32_le
(
&
mut
self
)
-
>
u32
{
buf_get_impl
!
(
self
u32
:
:
from_le_bytes
)
;
}
fn
get_i32
(
&
mut
self
)
-
>
i32
{
buf_get_impl
!
(
self
i32
:
:
from_be_bytes
)
;
}
fn
get_i32_le
(
&
mut
self
)
-
>
i32
{
buf_get_impl
!
(
self
i32
:
:
from_le_bytes
)
;
}
fn
get_u64
(
&
mut
self
)
-
>
u64
{
buf_get_impl
!
(
self
u64
:
:
from_be_bytes
)
;
}
fn
get_u64_le
(
&
mut
self
)
-
>
u64
{
buf_get_impl
!
(
self
u64
:
:
from_le_bytes
)
;
}
fn
get_i64
(
&
mut
self
)
-
>
i64
{
buf_get_impl
!
(
self
i64
:
:
from_be_bytes
)
;
}
fn
get_i64_le
(
&
mut
self
)
-
>
i64
{
buf_get_impl
!
(
self
i64
:
:
from_le_bytes
)
;
}
fn
get_u128
(
&
mut
self
)
-
>
u128
{
buf_get_impl
!
(
self
u128
:
:
from_be_bytes
)
;
}
fn
get_u128_le
(
&
mut
self
)
-
>
u128
{
buf_get_impl
!
(
self
u128
:
:
from_le_bytes
)
;
}
fn
get_i128
(
&
mut
self
)
-
>
i128
{
buf_get_impl
!
(
self
i128
:
:
from_be_bytes
)
;
}
fn
get_i128_le
(
&
mut
self
)
-
>
i128
{
buf_get_impl
!
(
self
i128
:
:
from_le_bytes
)
;
}
fn
get_uint
(
&
mut
self
nbytes
:
usize
)
-
>
u64
{
buf_get_impl
!
(
be
=
>
self
u64
nbytes
)
;
}
fn
get_uint_le
(
&
mut
self
nbytes
:
usize
)
-
>
u64
{
buf_get_impl
!
(
le
=
>
self
u64
nbytes
)
;
}
fn
get_int
(
&
mut
self
nbytes
:
usize
)
-
>
i64
{
buf_get_impl
!
(
be
=
>
self
i64
nbytes
)
;
}
fn
get_int_le
(
&
mut
self
nbytes
:
usize
)
-
>
i64
{
buf_get_impl
!
(
le
=
>
self
i64
nbytes
)
;
}
fn
get_f32
(
&
mut
self
)
-
>
f32
{
f32
:
:
from_bits
(
Self
:
:
get_u32
(
self
)
)
}
fn
get_f32_le
(
&
mut
self
)
-
>
f32
{
f32
:
:
from_bits
(
Self
:
:
get_u32_le
(
self
)
)
}
fn
get_f64
(
&
mut
self
)
-
>
f64
{
f64
:
:
from_bits
(
Self
:
:
get_u64
(
self
)
)
}
fn
get_f64_le
(
&
mut
self
)
-
>
f64
{
f64
:
:
from_bits
(
Self
:
:
get_u64_le
(
self
)
)
}
fn
copy_to_bytes
(
&
mut
self
len
:
usize
)
-
>
crate
:
:
Bytes
{
use
super
:
:
BufMut
;
assert
!
(
len
<
=
self
.
remaining
(
)
"
len
greater
than
remaining
"
)
;
let
mut
ret
=
crate
:
:
BytesMut
:
:
with_capacity
(
len
)
;
ret
.
put
(
self
.
take
(
len
)
)
;
ret
.
freeze
(
)
}
fn
take
(
self
limit
:
usize
)
-
>
Take
<
Self
>
where
Self
:
Sized
{
take
:
:
new
(
self
limit
)
}
fn
chain
<
U
:
Buf
>
(
self
next
:
U
)
-
>
Chain
<
Self
U
>
where
Self
:
Sized
{
Chain
:
:
new
(
self
next
)
}
#
[
cfg
(
feature
=
"
std
"
)
]
fn
reader
(
self
)
-
>
Reader
<
Self
>
where
Self
:
Sized
{
reader
:
:
new
(
self
)
}
}
macro_rules
!
deref_forward_buf
{
(
)
=
>
{
fn
remaining
(
&
self
)
-
>
usize
{
(
*
*
self
)
.
remaining
(
)
}
fn
chunk
(
&
self
)
-
>
&
[
u8
]
{
(
*
*
self
)
.
chunk
(
)
}
#
[
cfg
(
feature
=
"
std
"
)
]
fn
chunks_vectored
<
'
b
>
(
&
'
b
self
dst
:
&
mut
[
IoSlice
<
'
b
>
]
)
-
>
usize
{
(
*
*
self
)
.
chunks_vectored
(
dst
)
}
fn
advance
(
&
mut
self
cnt
:
usize
)
{
(
*
*
self
)
.
advance
(
cnt
)
}
fn
has_remaining
(
&
self
)
-
>
bool
{
(
*
*
self
)
.
has_remaining
(
)
}
fn
copy_to_slice
(
&
mut
self
dst
:
&
mut
[
u8
]
)
{
(
*
*
self
)
.
copy_to_slice
(
dst
)
}
fn
get_u8
(
&
mut
self
)
-
>
u8
{
(
*
*
self
)
.
get_u8
(
)
}
fn
get_i8
(
&
mut
self
)
-
>
i8
{
(
*
*
self
)
.
get_i8
(
)
}
fn
get_u16
(
&
mut
self
)
-
>
u16
{
(
*
*
self
)
.
get_u16
(
)
}
fn
get_u16_le
(
&
mut
self
)
-
>
u16
{
(
*
*
self
)
.
get_u16_le
(
)
}
fn
get_i16
(
&
mut
self
)
-
>
i16
{
(
*
*
self
)
.
get_i16
(
)
}
fn
get_i16_le
(
&
mut
self
)
-
>
i16
{
(
*
*
self
)
.
get_i16_le
(
)
}
fn
get_u32
(
&
mut
self
)
-
>
u32
{
(
*
*
self
)
.
get_u32
(
)
}
fn
get_u32_le
(
&
mut
self
)
-
>
u32
{
(
*
*
self
)
.
get_u32_le
(
)
}
fn
get_i32
(
&
mut
self
)
-
>
i32
{
(
*
*
self
)
.
get_i32
(
)
}
fn
get_i32_le
(
&
mut
self
)
-
>
i32
{
(
*
*
self
)
.
get_i32_le
(
)
}
fn
get_u64
(
&
mut
self
)
-
>
u64
{
(
*
*
self
)
.
get_u64
(
)
}
fn
get_u64_le
(
&
mut
self
)
-
>
u64
{
(
*
*
self
)
.
get_u64_le
(
)
}
fn
get_i64
(
&
mut
self
)
-
>
i64
{
(
*
*
self
)
.
get_i64
(
)
}
fn
get_i64_le
(
&
mut
self
)
-
>
i64
{
(
*
*
self
)
.
get_i64_le
(
)
}
fn
get_uint
(
&
mut
self
nbytes
:
usize
)
-
>
u64
{
(
*
*
self
)
.
get_uint
(
nbytes
)
}
fn
get_uint_le
(
&
mut
self
nbytes
:
usize
)
-
>
u64
{
(
*
*
self
)
.
get_uint_le
(
nbytes
)
}
fn
get_int
(
&
mut
self
nbytes
:
usize
)
-
>
i64
{
(
*
*
self
)
.
get_int
(
nbytes
)
}
fn
get_int_le
(
&
mut
self
nbytes
:
usize
)
-
>
i64
{
(
*
*
self
)
.
get_int_le
(
nbytes
)
}
fn
copy_to_bytes
(
&
mut
self
len
:
usize
)
-
>
crate
:
:
Bytes
{
(
*
*
self
)
.
copy_to_bytes
(
len
)
}
}
;
}
impl
<
T
:
Buf
+
?
Sized
>
Buf
for
&
mut
T
{
deref_forward_buf
!
(
)
;
}
impl
<
T
:
Buf
+
?
Sized
>
Buf
for
Box
<
T
>
{
deref_forward_buf
!
(
)
;
}
impl
Buf
for
&
[
u8
]
{
#
[
inline
]
fn
remaining
(
&
self
)
-
>
usize
{
self
.
len
(
)
}
#
[
inline
]
fn
chunk
(
&
self
)
-
>
&
[
u8
]
{
self
}
#
[
inline
]
fn
advance
(
&
mut
self
cnt
:
usize
)
{
*
self
=
&
self
[
cnt
.
.
]
;
}
}
#
[
cfg
(
feature
=
"
std
"
)
]
impl
<
T
:
AsRef
<
[
u8
]
>
>
Buf
for
std
:
:
io
:
:
Cursor
<
T
>
{
fn
remaining
(
&
self
)
-
>
usize
{
let
len
=
self
.
get_ref
(
)
.
as_ref
(
)
.
len
(
)
;
let
pos
=
self
.
position
(
)
;
if
pos
>
=
len
as
u64
{
return
0
;
}
len
-
pos
as
usize
}
fn
chunk
(
&
self
)
-
>
&
[
u8
]
{
let
len
=
self
.
get_ref
(
)
.
as_ref
(
)
.
len
(
)
;
let
pos
=
self
.
position
(
)
;
if
pos
>
=
len
as
u64
{
return
&
[
]
;
}
&
self
.
get_ref
(
)
.
as_ref
(
)
[
pos
as
usize
.
.
]
}
fn
advance
(
&
mut
self
cnt
:
usize
)
{
let
pos
=
(
self
.
position
(
)
as
usize
)
.
checked_add
(
cnt
)
.
expect
(
"
overflow
"
)
;
assert
!
(
pos
<
=
self
.
get_ref
(
)
.
as_ref
(
)
.
len
(
)
)
;
self
.
set_position
(
pos
as
u64
)
;
}
}
fn
_assert_trait_object
(
_b
:
&
dyn
Buf
)
{
}
