use
crate
:
:
error
:
:
*
;
use
crate
:
:
schema
;
use
rusqlite
:
:
types
:
:
{
FromSql
ToSql
}
;
use
rusqlite
:
:
Connection
;
use
rusqlite
:
:
OpenFlags
;
use
sql_support
:
:
{
ConnExt
SqlInterruptHandle
SqlInterruptScope
}
;
use
std
:
:
fs
;
use
std
:
:
ops
:
:
{
Deref
DerefMut
}
;
use
std
:
:
path
:
:
{
Path
PathBuf
}
;
use
std
:
:
result
;
use
std
:
:
sync
:
:
{
atomic
:
:
AtomicUsize
Arc
}
;
use
url
:
:
Url
;
pub
struct
StorageDb
{
writer
:
Connection
interrupt_counter
:
Arc
<
AtomicUsize
>
}
impl
StorageDb
{
pub
fn
new
(
db_path
:
impl
AsRef
<
Path
>
)
-
>
Result
<
Self
>
{
let
db_path
=
normalize_path
(
db_path
)
?
;
Self
:
:
new_named
(
db_path
)
}
#
[
cfg
(
test
)
]
pub
fn
new_memory
(
db_path
:
&
str
)
-
>
Result
<
Self
>
{
let
name
=
PathBuf
:
:
from
(
format
!
(
"
file
:
{
}
?
mode
=
memory
&
cache
=
shared
"
db_path
)
)
;
Self
:
:
new_named
(
name
)
}
fn
new_named
(
db_path
:
PathBuf
)
-
>
Result
<
Self
>
{
let
flags
=
OpenFlags
:
:
SQLITE_OPEN_NO_MUTEX
|
OpenFlags
:
:
SQLITE_OPEN_URI
|
OpenFlags
:
:
SQLITE_OPEN_CREATE
|
OpenFlags
:
:
SQLITE_OPEN_READ_WRITE
;
let
conn
=
Connection
:
:
open_with_flags
(
db_path
.
clone
(
)
flags
)
?
;
match
init_sql_connection
(
&
conn
true
)
{
Ok
(
(
)
)
=
>
Ok
(
Self
{
writer
:
conn
interrupt_counter
:
Arc
:
:
new
(
AtomicUsize
:
:
new
(
0
)
)
}
)
Err
(
e
)
=
>
{
if
let
ErrorKind
:
:
DatabaseUpgradeError
=
e
.
kind
(
)
{
fs
:
:
remove_file
(
&
db_path
)
?
;
Self
:
:
new_named
(
db_path
)
}
else
{
Err
(
e
)
}
}
}
}
pub
fn
interrupt_handle
(
&
self
)
-
>
SqlInterruptHandle
{
SqlInterruptHandle
:
:
new
(
self
.
writer
.
get_interrupt_handle
(
)
self
.
interrupt_counter
.
clone
(
)
)
}
#
[
allow
(
dead_code
)
]
pub
fn
begin_interrupt_scope
(
&
self
)
-
>
SqlInterruptScope
{
SqlInterruptScope
:
:
new
(
self
.
interrupt_counter
.
clone
(
)
)
}
pub
fn
close
(
self
)
-
>
result
:
:
Result
<
(
)
(
StorageDb
Error
)
>
{
let
StorageDb
{
writer
interrupt_counter
}
=
self
;
writer
.
close
(
)
.
map_err
(
|
(
writer
err
)
|
{
(
StorageDb
{
writer
interrupt_counter
}
err
.
into
(
)
)
}
)
}
}
impl
Deref
for
StorageDb
{
type
Target
=
Connection
;
fn
deref
(
&
self
)
-
>
&
Self
:
:
Target
{
&
self
.
writer
}
}
impl
DerefMut
for
StorageDb
{
fn
deref_mut
(
&
mut
self
)
-
>
&
mut
Self
:
:
Target
{
&
mut
self
.
writer
}
}
fn
init_sql_connection
(
conn
:
&
Connection
is_writable
:
bool
)
-
>
Result
<
(
)
>
{
let
initial_pragmas
=
"
-
-
We
don
'
t
care
about
temp
tables
being
persisted
to
disk
.
PRAGMA
temp_store
=
2
;
-
-
we
unconditionally
want
write
-
ahead
-
logging
mode
PRAGMA
journal_mode
=
WAL
;
-
-
foreign
keys
seem
worth
enforcing
!
PRAGMA
foreign_keys
=
ON
;
"
;
conn
.
execute_batch
(
initial_pragmas
)
?
;
define_functions
(
&
conn
)
?
;
conn
.
set_prepared_statement_cache_capacity
(
128
)
;
if
is_writable
{
let
tx
=
conn
.
unchecked_transaction
(
)
?
;
schema
:
:
init
(
&
conn
)
?
;
tx
.
commit
(
)
?
;
}
;
Ok
(
(
)
)
}
fn
define_functions
(
_c
:
&
Connection
)
-
>
Result
<
(
)
>
{
Ok
(
(
)
)
}
#
[
allow
(
dead_code
)
]
pub
fn
put_meta
(
db
:
&
Connection
key
:
&
str
value
:
&
dyn
ToSql
)
-
>
Result
<
(
)
>
{
db
.
conn
(
)
.
execute_named_cached
(
"
REPLACE
INTO
meta
(
key
value
)
VALUES
(
:
key
:
value
)
"
&
[
(
"
:
key
"
&
key
)
(
"
:
value
"
value
)
]
)
?
;
Ok
(
(
)
)
}
#
[
allow
(
dead_code
)
]
pub
fn
get_meta
<
T
:
FromSql
>
(
db
:
&
Connection
key
:
&
str
)
-
>
Result
<
Option
<
T
>
>
{
let
res
=
db
.
conn
(
)
.
try_query_one
(
"
SELECT
value
FROM
meta
WHERE
key
=
:
key
"
&
[
(
"
:
key
"
&
key
)
]
true
)
?
;
Ok
(
res
)
}
#
[
allow
(
dead_code
)
]
pub
fn
delete_meta
(
db
:
&
Connection
key
:
&
str
)
-
>
Result
<
(
)
>
{
db
.
conn
(
)
.
execute_named_cached
(
"
DELETE
FROM
meta
WHERE
key
=
:
key
"
&
[
(
"
:
key
"
&
key
)
]
)
?
;
Ok
(
(
)
)
}
fn
unurl_path
(
p
:
impl
AsRef
<
Path
>
)
-
>
PathBuf
{
p
.
as_ref
(
)
.
to_str
(
)
.
and_then
(
|
s
|
Url
:
:
parse
(
s
)
.
ok
(
)
)
.
and_then
(
|
u
|
{
if
u
.
scheme
(
)
=
=
"
file
"
{
u
.
to_file_path
(
)
.
ok
(
)
}
else
{
None
}
}
)
.
unwrap_or_else
(
|
|
p
.
as_ref
(
)
.
to_owned
(
)
)
}
#
[
allow
(
dead_code
)
]
pub
fn
ensure_url_path
(
p
:
impl
AsRef
<
Path
>
)
-
>
Result
<
Url
>
{
if
let
Some
(
u
)
=
p
.
as_ref
(
)
.
to_str
(
)
.
and_then
(
|
s
|
Url
:
:
parse
(
s
)
.
ok
(
)
)
{
if
u
.
scheme
(
)
=
=
"
file
"
{
Ok
(
u
)
}
else
{
Err
(
ErrorKind
:
:
IllegalDatabasePath
(
p
.
as_ref
(
)
.
to_owned
(
)
)
.
into
(
)
)
}
}
else
{
let
p
=
p
.
as_ref
(
)
;
let
u
=
Url
:
:
from_file_path
(
p
)
.
map_err
(
|
_
|
ErrorKind
:
:
IllegalDatabasePath
(
p
.
to_owned
(
)
)
)
?
;
Ok
(
u
)
}
}
fn
normalize_path
(
p
:
impl
AsRef
<
Path
>
)
-
>
Result
<
PathBuf
>
{
let
path
=
unurl_path
(
p
)
;
if
let
Ok
(
canonical
)
=
path
.
canonicalize
(
)
{
return
Ok
(
canonical
)
;
}
let
file_name
=
path
.
file_name
(
)
.
ok_or_else
(
|
|
ErrorKind
:
:
IllegalDatabasePath
(
path
.
clone
(
)
)
)
?
;
let
parent
=
path
.
parent
(
)
.
ok_or_else
(
|
|
ErrorKind
:
:
IllegalDatabasePath
(
path
.
clone
(
)
)
)
?
;
let
mut
canonical
=
parent
.
canonicalize
(
)
?
;
canonical
.
push
(
file_name
)
;
Ok
(
canonical
)
}
#
[
cfg
(
test
)
]
pub
mod
test
{
use
super
:
:
*
;
use
std
:
:
sync
:
:
atomic
:
:
{
AtomicUsize
Ordering
}
;
static
ATOMIC_COUNTER
:
AtomicUsize
=
AtomicUsize
:
:
new
(
0
)
;
pub
fn
new_mem_db
(
)
-
>
StorageDb
{
let
_
=
env_logger
:
:
try_init
(
)
;
let
counter
=
ATOMIC_COUNTER
.
fetch_add
(
1
Ordering
:
:
Relaxed
)
;
StorageDb
:
:
new_memory
(
&
format
!
(
"
test
-
api
-
{
}
"
counter
)
)
.
expect
(
"
should
get
an
API
"
)
}
}
#
[
cfg
(
test
)
]
mod
tests
{
use
super
:
:
test
:
:
*
;
use
super
:
:
*
;
#
[
test
]
fn
test_open
(
)
{
new_mem_db
(
)
;
}
#
[
test
]
fn
test_meta
(
)
-
>
Result
<
(
)
>
{
let
writer
=
new_mem_db
(
)
;
assert_eq
!
(
get_meta
:
:
<
String
>
(
&
writer
"
foo
"
)
?
None
)
;
put_meta
(
&
writer
"
foo
"
&
"
bar
"
.
to_string
(
)
)
?
;
assert_eq
!
(
get_meta
(
&
writer
"
foo
"
)
?
Some
(
"
bar
"
.
to_string
(
)
)
)
;
delete_meta
(
&
writer
"
foo
"
)
?
;
assert_eq
!
(
get_meta
:
:
<
String
>
(
&
writer
"
foo
"
)
?
None
)
;
Ok
(
(
)
)
}
}
