use
std
:
:
{
collections
:
:
hash_map
:
:
Entry
ops
:
:
Range
vec
:
:
Drain
}
;
use
hal
:
:
CommandEncoder
;
use
crate
:
:
{
command
:
:
collect_zero_buffer_copies_for_clear_texture
device
:
:
Device
hub
:
:
Storage
id
:
:
{
self
TextureId
}
init_tracker
:
:
*
resource
:
:
{
Buffer
Texture
}
track
:
:
{
ResourceTracker
TextureSelector
TextureState
TrackerSet
}
FastHashMap
}
;
use
super
:
:
{
BakedCommands
DestroyedBufferError
DestroyedTextureError
}
;
#
[
derive
(
Clone
)
]
pub
(
crate
)
struct
TextureSurfaceDiscard
{
pub
texture
:
TextureId
pub
mip_level
:
u32
pub
layer
:
u32
}
pub
(
crate
)
type
SurfacesInDiscardState
=
Vec
<
TextureSurfaceDiscard
>
;
#
[
derive
(
Default
)
]
pub
(
crate
)
struct
CommandBufferTextureMemoryActions
{
init_actions
:
Vec
<
TextureInitTrackerAction
>
discards
:
Vec
<
TextureSurfaceDiscard
>
}
impl
CommandBufferTextureMemoryActions
{
pub
(
crate
)
fn
drain_init_actions
(
&
mut
self
)
-
>
Drain
<
TextureInitTrackerAction
>
{
self
.
init_actions
.
drain
(
.
.
)
}
pub
(
crate
)
fn
discard
(
&
mut
self
discard
:
TextureSurfaceDiscard
)
{
self
.
discards
.
push
(
discard
)
;
}
#
[
must_use
]
pub
(
crate
)
fn
register_init_action
<
A
:
hal
:
:
Api
>
(
&
mut
self
action
:
&
TextureInitTrackerAction
texture_guard
:
&
Storage
<
Texture
<
A
>
TextureId
>
)
-
>
SurfacesInDiscardState
{
let
mut
immediately_necessary_clears
=
SurfacesInDiscardState
:
:
new
(
)
;
self
.
init_actions
.
extend
(
match
texture_guard
.
get
(
action
.
id
)
{
Ok
(
texture
)
=
>
texture
.
initialization_status
.
check_action
(
action
)
Err
(
_
)
=
>
return
immediately_necessary_clears
}
)
;
let
init_actions
=
&
mut
self
.
init_actions
;
self
.
discards
.
retain
(
|
discarded_surface
|
{
if
discarded_surface
.
texture
=
=
action
.
id
&
&
action
.
range
.
layer_range
.
contains
(
&
discarded_surface
.
layer
)
&
&
action
.
range
.
mip_range
.
contains
(
&
discarded_surface
.
mip_level
)
{
if
let
MemoryInitKind
:
:
NeedsInitializedMemory
=
action
.
kind
{
immediately_necessary_clears
.
push
(
discarded_surface
.
clone
(
)
)
;
init_actions
.
push
(
TextureInitTrackerAction
{
id
:
discarded_surface
.
texture
range
:
TextureInitRange
{
mip_range
:
discarded_surface
.
mip_level
.
.
(
discarded_surface
.
mip_level
+
1
)
layer_range
:
discarded_surface
.
layer
.
.
(
discarded_surface
.
layer
+
1
)
}
kind
:
MemoryInitKind
:
:
ImplicitlyInitialized
}
)
;
}
false
}
else
{
true
}
}
)
;
immediately_necessary_clears
}
pub
(
crate
)
fn
register_implicit_init
<
A
:
hal
:
:
Api
>
(
&
mut
self
id
:
TextureId
range
:
TextureInitRange
texture_guard
:
&
Storage
<
Texture
<
A
>
TextureId
>
)
{
let
must_be_empty
=
self
.
register_init_action
(
&
TextureInitTrackerAction
{
id
range
kind
:
MemoryInitKind
:
:
ImplicitlyInitialized
}
texture_guard
)
;
assert
!
(
must_be_empty
.
is_empty
(
)
)
;
}
}
pub
(
crate
)
fn
fixup_discarded_surfaces
<
A
:
hal
:
:
Api
InitIter
:
Iterator
<
Item
=
TextureSurfaceDiscard
>
>
(
inits
:
InitIter
encoder
:
&
mut
A
:
:
CommandEncoder
texture_guard
:
&
Storage
<
Texture
<
A
>
TextureId
>
texture_tracker
:
&
mut
ResourceTracker
<
TextureState
>
device
:
&
Device
<
A
>
)
{
let
mut
zero_buffer_copy_regions
=
Vec
:
:
new
(
)
;
for
init
in
inits
{
let
mip_range
=
init
.
mip_level
.
.
(
init
.
mip_level
+
1
)
;
let
layer_range
=
init
.
layer
.
.
(
init
.
layer
+
1
)
;
let
(
texture
pending
)
=
texture_tracker
.
use_replace
(
&
*
texture_guard
init
.
texture
TextureSelector
{
levels
:
mip_range
.
clone
(
)
layers
:
layer_range
.
clone
(
)
}
hal
:
:
TextureUses
:
:
COPY_DST
)
.
unwrap
(
)
;
collect_zero_buffer_copies_for_clear_texture
(
&
texture
.
desc
device
.
alignments
.
buffer_copy_pitch
.
get
(
)
as
u32
mip_range
layer_range
&
mut
zero_buffer_copy_regions
)
;
let
barriers
=
pending
.
map
(
|
pending
|
pending
.
into_hal
(
texture
)
)
;
let
raw_texture
=
texture
.
inner
.
as_raw
(
)
.
unwrap
(
)
;
unsafe
{
encoder
.
transition_textures
(
barriers
)
;
encoder
.
copy_buffer_to_texture
(
&
device
.
zero_buffer
raw_texture
zero_buffer_copy_regions
.
drain
(
.
.
)
)
;
}
}
}
impl
<
A
:
hal
:
:
Api
>
BakedCommands
<
A
>
{
pub
(
crate
)
fn
initialize_buffer_memory
(
&
mut
self
device_tracker
:
&
mut
TrackerSet
buffer_guard
:
&
mut
Storage
<
Buffer
<
A
>
id
:
:
BufferId
>
)
-
>
Result
<
(
)
DestroyedBufferError
>
{
let
mut
uninitialized_ranges_per_buffer
=
FastHashMap
:
:
default
(
)
;
for
buffer_use
in
self
.
buffer_memory_init_actions
.
drain
(
.
.
)
{
let
buffer
=
buffer_guard
.
get_mut
(
buffer_use
.
id
)
.
map_err
(
|
_
|
DestroyedBufferError
(
buffer_use
.
id
)
)
?
;
let
end_remainder
=
buffer_use
.
range
.
end
%
wgt
:
:
COPY_BUFFER_ALIGNMENT
;
let
end
=
if
end_remainder
=
=
0
{
buffer_use
.
range
.
end
}
else
{
buffer_use
.
range
.
end
+
wgt
:
:
COPY_BUFFER_ALIGNMENT
-
end_remainder
}
;
let
uninitialized_ranges
=
buffer
.
initialization_status
.
drain
(
buffer_use
.
range
.
start
.
.
end
)
;
match
buffer_use
.
kind
{
MemoryInitKind
:
:
ImplicitlyInitialized
=
>
{
}
MemoryInitKind
:
:
NeedsInitializedMemory
=
>
{
match
uninitialized_ranges_per_buffer
.
entry
(
buffer_use
.
id
)
{
Entry
:
:
Vacant
(
e
)
=
>
{
e
.
insert
(
uninitialized_ranges
.
collect
:
:
<
Vec
<
Range
<
wgt
:
:
BufferAddress
>
>
>
(
)
)
;
}
Entry
:
:
Occupied
(
mut
e
)
=
>
{
e
.
get_mut
(
)
.
extend
(
uninitialized_ranges
)
;
}
}
}
}
}
for
(
buffer_id
mut
ranges
)
in
uninitialized_ranges_per_buffer
{
ranges
.
sort_by_key
(
|
r
|
r
.
start
)
;
for
i
in
(
1
.
.
ranges
.
len
(
)
)
.
rev
(
)
{
assert
!
(
ranges
[
i
-
1
]
.
end
<
=
ranges
[
i
]
.
start
)
;
if
ranges
[
i
]
.
start
=
=
ranges
[
i
-
1
]
.
end
{
ranges
[
i
-
1
]
.
end
=
ranges
[
i
]
.
end
;
ranges
.
swap_remove
(
i
)
;
}
}
let
transition
=
device_tracker
.
buffers
.
change_replace_tracked
(
id
:
:
Valid
(
buffer_id
)
(
)
hal
:
:
BufferUses
:
:
COPY_DST
)
;
let
buffer
=
buffer_guard
.
get_mut
(
buffer_id
)
.
map_err
(
|
_
|
DestroyedBufferError
(
buffer_id
)
)
?
;
let
raw_buf
=
buffer
.
raw
.
as_ref
(
)
.
ok_or
(
DestroyedBufferError
(
buffer_id
)
)
?
;
unsafe
{
self
.
encoder
.
transition_buffers
(
transition
.
map
(
|
pending
|
pending
.
into_hal
(
buffer
)
)
)
;
}
for
range
in
ranges
.
iter
(
)
{
assert
!
(
range
.
start
%
wgt
:
:
COPY_BUFFER_ALIGNMENT
=
=
0
"
Buffer
{
:
?
}
has
an
uninitialized
range
with
a
start
not
aligned
to
4
(
start
was
{
}
)
"
raw_buf
range
.
start
)
;
assert
!
(
range
.
end
%
wgt
:
:
COPY_BUFFER_ALIGNMENT
=
=
0
"
Buffer
{
:
?
}
has
an
uninitialized
range
with
an
end
not
aligned
to
4
(
end
was
{
}
)
"
raw_buf
range
.
end
)
;
unsafe
{
self
.
encoder
.
clear_buffer
(
raw_buf
range
.
clone
(
)
)
;
}
}
}
Ok
(
(
)
)
}
pub
(
crate
)
fn
initialize_texture_memory
(
&
mut
self
device_tracker
:
&
mut
TrackerSet
texture_guard
:
&
mut
Storage
<
Texture
<
A
>
TextureId
>
device
:
&
Device
<
A
>
)
-
>
Result
<
(
)
DestroyedTextureError
>
{
let
mut
ranges
:
Vec
<
TextureInitRange
>
=
Vec
:
:
new
(
)
;
for
texture_use
in
self
.
texture_memory_actions
.
drain_init_actions
(
)
{
let
texture
=
texture_guard
.
get_mut
(
texture_use
.
id
)
.
map_err
(
|
_
|
DestroyedTextureError
(
texture_use
.
id
)
)
?
;
let
use_range
=
texture_use
.
range
;
let
affected_mip_trackers
=
texture
.
initialization_status
.
mips
.
iter_mut
(
)
.
enumerate
(
)
.
skip
(
use_range
.
mip_range
.
start
as
usize
)
.
take
(
(
use_range
.
mip_range
.
end
-
use_range
.
mip_range
.
start
)
as
usize
)
;
match
texture_use
.
kind
{
MemoryInitKind
:
:
ImplicitlyInitialized
=
>
{
for
(
_
mip_tracker
)
in
affected_mip_trackers
{
mip_tracker
.
drain
(
use_range
.
layer_range
.
clone
(
)
)
;
}
}
MemoryInitKind
:
:
NeedsInitializedMemory
=
>
{
ranges
.
clear
(
)
;
for
(
mip_level
mip_tracker
)
in
affected_mip_trackers
{
for
layer_range
in
mip_tracker
.
drain
(
use_range
.
layer_range
.
clone
(
)
)
{
ranges
.
push
(
TextureInitRange
{
mip_range
:
mip_level
as
u32
.
.
(
mip_level
as
u32
+
1
)
layer_range
}
)
}
}
let
raw_texture
=
texture
.
inner
.
as_raw
(
)
.
ok_or
(
DestroyedTextureError
(
texture_use
.
id
)
)
?
;
let
mut
texture_barriers
=
Vec
:
:
new
(
)
;
let
mut
zero_buffer_copy_regions
=
Vec
:
:
new
(
)
;
for
range
in
&
ranges
{
texture_barriers
.
extend
(
device_tracker
.
textures
.
change_replace_tracked
(
id
:
:
Valid
(
texture_use
.
id
)
TextureSelector
{
levels
:
range
.
mip_range
.
clone
(
)
layers
:
range
.
layer_range
.
clone
(
)
}
hal
:
:
TextureUses
:
:
COPY_DST
)
.
map
(
|
pending
|
pending
.
into_hal
(
texture
)
)
)
;
collect_zero_buffer_copies_for_clear_texture
(
&
texture
.
desc
device
.
alignments
.
buffer_copy_pitch
.
get
(
)
as
u32
range
.
mip_range
.
clone
(
)
range
.
layer_range
.
clone
(
)
&
mut
zero_buffer_copy_regions
)
;
}
if
!
zero_buffer_copy_regions
.
is_empty
(
)
{
debug_assert
!
(
texture
.
hal_usage
.
contains
(
hal
:
:
TextureUses
:
:
COPY_DST
)
"
Texture
needs
to
have
the
COPY_DST
flag
.
Otherwise
we
can
'
t
ensure
initialized
memory
!
"
)
;
unsafe
{
self
.
encoder
.
transition_textures
(
texture_barriers
.
into_iter
(
)
)
;
self
.
encoder
.
copy_buffer_to_texture
(
&
device
.
zero_buffer
raw_texture
zero_buffer_copy_regions
.
into_iter
(
)
)
;
}
}
}
}
}
for
surface_discard
in
self
.
texture_memory_actions
.
discards
.
iter
(
)
{
let
texture
=
texture_guard
.
get_mut
(
surface_discard
.
texture
)
.
map_err
(
|
_
|
DestroyedTextureError
(
surface_discard
.
texture
)
)
?
;
texture
.
initialization_status
.
discard
(
surface_discard
.
mip_level
surface_discard
.
layer
)
;
}
Ok
(
(
)
)
}
}
