use
crate
:
:
ir
;
use
crate
:
:
ir
:
:
types
;
use
crate
:
:
ir
:
:
types
:
:
*
;
use
crate
:
:
ir
:
:
MemFlags
;
use
crate
:
:
ir
:
:
Opcode
;
use
crate
:
:
ir
:
:
{
ExternalName
LibCall
}
;
use
crate
:
:
isa
;
use
crate
:
:
isa
:
:
aarch64
:
:
{
inst
:
:
EmitState
inst
:
:
*
}
;
use
crate
:
:
isa
:
:
unwind
:
:
UnwindInst
;
use
crate
:
:
machinst
:
:
*
;
use
crate
:
:
settings
;
use
crate
:
:
{
CodegenError
CodegenResult
}
;
use
alloc
:
:
boxed
:
:
Box
;
use
alloc
:
:
vec
:
:
Vec
;
use
regalloc
:
:
{
RealReg
Reg
RegClass
Set
Writable
}
;
use
smallvec
:
:
{
smallvec
SmallVec
}
;
pub
(
crate
)
type
AArch64ABICallee
=
ABICalleeImpl
<
AArch64MachineDeps
>
;
pub
(
crate
)
type
AArch64ABICaller
=
ABICallerImpl
<
AArch64MachineDeps
>
;
static
BALDRDASH_SIG_REG
:
u8
=
10
;
static
BALDRDASH_TLS_REG
:
u8
=
23
;
static
BALDRDASH_CALLEE_TLS_OFFSET
:
i64
=
0
;
static
BALDRDASH_CALLER_TLS_OFFSET
:
i64
=
8
;
#
[
rustfmt
:
:
skip
]
static
BALDRDASH_JIT_CALLEE_SAVED_GPR
:
&
[
bool
]
=
&
[
false
false
false
false
false
false
false
false
false
false
false
false
false
false
false
false
true
true
true
false
false
false
false
false
false
false
false
false
false
false
true
false
]
;
#
[
rustfmt
:
:
skip
]
static
BALDRDASH_JIT_CALLEE_SAVED_FPU
:
&
[
bool
]
=
&
[
false
false
false
false
false
false
false
false
false
false
false
false
false
false
false
false
false
false
false
false
false
false
false
false
false
false
false
false
false
false
false
true
]
;
static
STACK_ARG_RET_SIZE_LIMIT
:
u64
=
128
*
1024
*
1024
;
fn
try_fill_baldrdash_reg
(
call_conv
:
isa
:
:
CallConv
param
:
&
ir
:
:
AbiParam
)
-
>
Option
<
ABIArg
>
{
if
call_conv
.
extends_baldrdash
(
)
{
match
&
param
.
purpose
{
&
ir
:
:
ArgumentPurpose
:
:
VMContext
=
>
{
Some
(
ABIArg
:
:
reg
(
xreg
(
BALDRDASH_TLS_REG
)
.
to_real_reg
(
)
ir
:
:
types
:
:
I64
param
.
extension
param
.
purpose
)
)
}
&
ir
:
:
ArgumentPurpose
:
:
SignatureId
=
>
{
Some
(
ABIArg
:
:
reg
(
xreg
(
BALDRDASH_SIG_REG
)
.
to_real_reg
(
)
ir
:
:
types
:
:
I64
param
.
extension
param
.
purpose
)
)
}
&
ir
:
:
ArgumentPurpose
:
:
CalleeTLS
=
>
{
assert
!
(
call_conv
=
=
isa
:
:
CallConv
:
:
Baldrdash2020
)
;
Some
(
ABIArg
:
:
stack
(
BALDRDASH_CALLEE_TLS_OFFSET
ir
:
:
types
:
:
I64
ir
:
:
ArgumentExtension
:
:
None
param
.
purpose
)
)
}
&
ir
:
:
ArgumentPurpose
:
:
CallerTLS
=
>
{
assert
!
(
call_conv
=
=
isa
:
:
CallConv
:
:
Baldrdash2020
)
;
Some
(
ABIArg
:
:
stack
(
BALDRDASH_CALLER_TLS_OFFSET
ir
:
:
types
:
:
I64
ir
:
:
ArgumentExtension
:
:
None
param
.
purpose
)
)
}
_
=
>
None
}
}
else
{
None
}
}
impl
Into
<
AMode
>
for
StackAMode
{
fn
into
(
self
)
-
>
AMode
{
match
self
{
StackAMode
:
:
FPOffset
(
off
ty
)
=
>
AMode
:
:
FPOffset
(
off
ty
)
StackAMode
:
:
NominalSPOffset
(
off
ty
)
=
>
AMode
:
:
NominalSPOffset
(
off
ty
)
StackAMode
:
:
SPOffset
(
off
ty
)
=
>
AMode
:
:
SPOffset
(
off
ty
)
}
}
}
fn
saved_reg_stack_size
(
int_reg
:
&
[
Writable
<
RealReg
>
]
vec_reg
:
&
[
Writable
<
RealReg
>
]
)
-
>
(
usize
usize
)
{
let
int_save_bytes
=
(
int_reg
.
len
(
)
+
(
int_reg
.
len
(
)
&
1
)
)
*
8
;
let
vec_save_bytes
=
vec_reg
.
len
(
)
*
16
;
(
int_save_bytes
vec_save_bytes
)
}
pub
(
crate
)
struct
AArch64MachineDeps
;
impl
ABIMachineSpec
for
AArch64MachineDeps
{
type
I
=
Inst
;
fn
word_bits
(
)
-
>
u32
{
64
}
fn
stack_align
(
_call_conv
:
isa
:
:
CallConv
)
-
>
u32
{
16
}
fn
compute_arg_locs
(
call_conv
:
isa
:
:
CallConv
_flags
:
&
settings
:
:
Flags
params
:
&
[
ir
:
:
AbiParam
]
args_or_rets
:
ArgsOrRets
add_ret_area_ptr
:
bool
)
-
>
CodegenResult
<
(
Vec
<
ABIArg
>
i64
Option
<
usize
>
)
>
{
let
is_baldrdash
=
call_conv
.
extends_baldrdash
(
)
;
let
has_baldrdash_tls
=
call_conv
=
=
isa
:
:
CallConv
:
:
Baldrdash2020
;
let
mut
next_xreg
=
0
;
let
mut
next_vreg
=
0
;
let
mut
next_stack
:
u64
=
0
;
let
mut
ret
=
vec
!
[
]
;
if
args_or_rets
=
=
ArgsOrRets
:
:
Args
&
&
has_baldrdash_tls
{
next_stack
=
16
;
}
let
(
max_per_class_reg_vals
mut
remaining_reg_vals
)
=
match
(
args_or_rets
is_baldrdash
)
{
(
ArgsOrRets
:
:
Args
_
)
=
>
(
8
16
)
(
ArgsOrRets
:
:
Rets
false
)
=
>
(
8
16
)
(
ArgsOrRets
:
:
Rets
true
)
=
>
(
1
1
)
}
;
for
i
in
0
.
.
params
.
len
(
)
{
let
param
=
match
(
args_or_rets
is_baldrdash
)
{
(
ArgsOrRets
:
:
Args
_
)
=
>
&
params
[
i
]
(
ArgsOrRets
:
:
Rets
false
)
=
>
&
params
[
i
]
(
ArgsOrRets
:
:
Rets
true
)
=
>
&
params
[
params
.
len
(
)
-
1
-
i
]
}
;
match
&
param
.
purpose
{
&
ir
:
:
ArgumentPurpose
:
:
VMContext
|
&
ir
:
:
ArgumentPurpose
:
:
Normal
|
&
ir
:
:
ArgumentPurpose
:
:
StackLimit
|
&
ir
:
:
ArgumentPurpose
:
:
SignatureId
|
&
ir
:
:
ArgumentPurpose
:
:
CallerTLS
|
&
ir
:
:
ArgumentPurpose
:
:
CalleeTLS
|
&
ir
:
:
ArgumentPurpose
:
:
StructReturn
|
&
ir
:
:
ArgumentPurpose
:
:
StructArgument
(
_
)
=
>
{
}
_
=
>
panic
!
(
"
Unsupported
argument
purpose
{
:
?
}
in
signature
:
{
:
?
}
"
param
.
purpose
params
)
}
assert
!
(
legal_type_for_machine
(
param
.
value_type
)
"
Invalid
type
for
AArch64
:
{
:
?
}
"
param
.
value_type
)
;
let
(
rcs
_
)
=
Inst
:
:
rc_for_type
(
param
.
value_type
)
.
unwrap
(
)
;
assert
!
(
rcs
.
len
(
)
=
=
1
"
Multi
-
reg
values
not
supported
yet
"
)
;
let
rc
=
rcs
[
0
]
;
let
next_reg
=
match
rc
{
RegClass
:
:
I64
=
>
&
mut
next_xreg
RegClass
:
:
V128
=
>
&
mut
next_vreg
_
=
>
panic
!
(
"
Invalid
register
class
:
{
:
?
}
"
rc
)
}
;
if
let
Some
(
param
)
=
try_fill_baldrdash_reg
(
call_conv
param
)
{
assert
!
(
rc
=
=
RegClass
:
:
I64
)
;
ret
.
push
(
param
)
;
}
else
if
let
ir
:
:
ArgumentPurpose
:
:
StructArgument
(
size
)
=
param
.
purpose
{
let
offset
=
next_stack
as
i64
;
let
size
=
size
as
u64
;
assert
!
(
size
%
8
=
=
0
"
StructArgument
size
is
not
properly
aligned
"
)
;
next_stack
+
=
size
;
ret
.
push
(
ABIArg
:
:
StructArg
{
offset
size
purpose
:
param
.
purpose
}
)
;
}
else
if
*
next_reg
<
max_per_class_reg_vals
&
&
remaining_reg_vals
>
0
{
let
reg
=
match
rc
{
RegClass
:
:
I64
=
>
xreg
(
*
next_reg
)
RegClass
:
:
V128
=
>
vreg
(
*
next_reg
)
_
=
>
unreachable
!
(
)
}
;
ret
.
push
(
ABIArg
:
:
reg
(
reg
.
to_real_reg
(
)
param
.
value_type
param
.
extension
param
.
purpose
)
)
;
*
next_reg
+
=
1
;
remaining_reg_vals
-
=
1
;
}
else
{
let
size
=
(
ty_bits
(
param
.
value_type
)
/
8
)
as
u64
;
let
size
=
if
call_conv
!
=
isa
:
:
CallConv
:
:
AppleAarch64
{
std
:
:
cmp
:
:
max
(
size
8
)
}
else
{
size
}
;
debug_assert
!
(
size
.
is_power_of_two
(
)
)
;
next_stack
=
align_to
(
next_stack
size
)
;
ret
.
push
(
ABIArg
:
:
stack
(
next_stack
as
i64
param
.
value_type
param
.
extension
param
.
purpose
)
)
;
next_stack
+
=
size
;
}
}
if
args_or_rets
=
=
ArgsOrRets
:
:
Rets
&
&
is_baldrdash
{
ret
.
reverse
(
)
;
}
let
extra_arg
=
if
add_ret_area_ptr
{
debug_assert
!
(
args_or_rets
=
=
ArgsOrRets
:
:
Args
)
;
if
next_xreg
<
max_per_class_reg_vals
&
&
remaining_reg_vals
>
0
{
ret
.
push
(
ABIArg
:
:
reg
(
xreg
(
next_xreg
)
.
to_real_reg
(
)
I64
ir
:
:
ArgumentExtension
:
:
None
ir
:
:
ArgumentPurpose
:
:
Normal
)
)
;
}
else
{
ret
.
push
(
ABIArg
:
:
stack
(
next_stack
as
i64
I64
ir
:
:
ArgumentExtension
:
:
None
ir
:
:
ArgumentPurpose
:
:
Normal
)
)
;
next_stack
+
=
8
;
}
Some
(
ret
.
len
(
)
-
1
)
}
else
{
None
}
;
next_stack
=
align_to
(
next_stack
16
)
;
if
next_stack
>
STACK_ARG_RET_SIZE_LIMIT
{
return
Err
(
CodegenError
:
:
ImplLimitExceeded
)
;
}
Ok
(
(
ret
next_stack
as
i64
extra_arg
)
)
}
fn
fp_to_arg_offset
(
call_conv
:
isa
:
:
CallConv
flags
:
&
settings
:
:
Flags
)
-
>
i64
{
if
call_conv
.
extends_baldrdash
(
)
{
let
num_words
=
flags
.
baldrdash_prologue_words
(
)
as
i64
;
debug_assert
!
(
num_words
>
0
"
baldrdash
must
set
baldrdash_prologue_words
"
)
;
debug_assert_eq
!
(
num_words
%
2
0
"
stack
must
be
16
-
aligned
"
)
;
num_words
*
8
}
else
{
16
}
}
fn
gen_load_stack
(
mem
:
StackAMode
into_reg
:
Writable
<
Reg
>
ty
:
Type
)
-
>
Inst
{
Inst
:
:
gen_load
(
into_reg
mem
.
into
(
)
ty
MemFlags
:
:
trusted
(
)
)
}
fn
gen_store_stack
(
mem
:
StackAMode
from_reg
:
Reg
ty
:
Type
)
-
>
Inst
{
Inst
:
:
gen_store
(
mem
.
into
(
)
from_reg
ty
MemFlags
:
:
trusted
(
)
)
}
fn
gen_move
(
to_reg
:
Writable
<
Reg
>
from_reg
:
Reg
ty
:
Type
)
-
>
Inst
{
Inst
:
:
gen_move
(
to_reg
from_reg
ty
)
}
fn
gen_extend
(
to_reg
:
Writable
<
Reg
>
from_reg
:
Reg
signed
:
bool
from_bits
:
u8
to_bits
:
u8
)
-
>
Inst
{
assert
!
(
from_bits
<
to_bits
)
;
Inst
:
:
Extend
{
rd
:
to_reg
rn
:
from_reg
signed
from_bits
to_bits
}
}
fn
gen_ret
(
)
-
>
Inst
{
Inst
:
:
Ret
}
fn
gen_add_imm
(
into_reg
:
Writable
<
Reg
>
from_reg
:
Reg
imm
:
u32
)
-
>
SmallInstVec
<
Inst
>
{
let
imm
=
imm
as
u64
;
let
mut
insts
=
SmallVec
:
:
new
(
)
;
if
let
Some
(
imm12
)
=
Imm12
:
:
maybe_from_u64
(
imm
)
{
insts
.
push
(
Inst
:
:
AluRRImm12
{
alu_op
:
ALUOp
:
:
Add64
rd
:
into_reg
rn
:
from_reg
imm12
}
)
;
}
else
{
let
scratch2
=
writable_tmp2_reg
(
)
;
assert_ne
!
(
scratch2
.
to_reg
(
)
from_reg
)
;
insts
.
extend
(
Inst
:
:
load_constant
(
scratch2
imm
.
into
(
)
)
)
;
insts
.
push
(
Inst
:
:
AluRRRExtend
{
alu_op
:
ALUOp
:
:
Add64
rd
:
into_reg
rn
:
from_reg
rm
:
scratch2
.
to_reg
(
)
extendop
:
ExtendOp
:
:
UXTX
}
)
;
}
insts
}
fn
gen_stack_lower_bound_trap
(
limit_reg
:
Reg
)
-
>
SmallInstVec
<
Inst
>
{
let
mut
insts
=
SmallVec
:
:
new
(
)
;
insts
.
push
(
Inst
:
:
AluRRRExtend
{
alu_op
:
ALUOp
:
:
SubS64
rd
:
writable_zero_reg
(
)
rn
:
stack_reg
(
)
rm
:
limit_reg
extendop
:
ExtendOp
:
:
UXTX
}
)
;
insts
.
push
(
Inst
:
:
TrapIf
{
trap_code
:
ir
:
:
TrapCode
:
:
StackOverflow
kind
:
CondBrKind
:
:
Cond
(
Cond
:
:
Lo
)
}
)
;
insts
}
fn
gen_epilogue_placeholder
(
)
-
>
Inst
{
Inst
:
:
EpiloguePlaceholder
}
fn
gen_get_stack_addr
(
mem
:
StackAMode
into_reg
:
Writable
<
Reg
>
_ty
:
Type
)
-
>
Inst
{
let
mem
=
mem
.
into
(
)
;
Inst
:
:
LoadAddr
{
rd
:
into_reg
mem
}
}
fn
get_stacklimit_reg
(
)
-
>
Reg
{
spilltmp_reg
(
)
}
fn
gen_load_base_offset
(
into_reg
:
Writable
<
Reg
>
base
:
Reg
offset
:
i32
ty
:
Type
)
-
>
Inst
{
let
mem
=
AMode
:
:
RegOffset
(
base
offset
as
i64
ty
)
;
Inst
:
:
gen_load
(
into_reg
mem
ty
MemFlags
:
:
trusted
(
)
)
}
fn
gen_store_base_offset
(
base
:
Reg
offset
:
i32
from_reg
:
Reg
ty
:
Type
)
-
>
Inst
{
let
mem
=
AMode
:
:
RegOffset
(
base
offset
as
i64
ty
)
;
Inst
:
:
gen_store
(
mem
from_reg
ty
MemFlags
:
:
trusted
(
)
)
}
fn
gen_sp_reg_adjust
(
amount
:
i32
)
-
>
SmallInstVec
<
Inst
>
{
if
amount
=
=
0
{
return
SmallVec
:
:
new
(
)
;
}
let
(
amount
is_sub
)
=
if
amount
>
0
{
(
amount
as
u64
false
)
}
else
{
(
-
amount
as
u64
true
)
}
;
let
alu_op
=
if
is_sub
{
ALUOp
:
:
Sub64
}
else
{
ALUOp
:
:
Add64
}
;
let
mut
ret
=
SmallVec
:
:
new
(
)
;
if
let
Some
(
imm12
)
=
Imm12
:
:
maybe_from_u64
(
amount
)
{
let
adj_inst
=
Inst
:
:
AluRRImm12
{
alu_op
rd
:
writable_stack_reg
(
)
rn
:
stack_reg
(
)
imm12
}
;
ret
.
push
(
adj_inst
)
;
}
else
{
let
tmp
=
writable_spilltmp_reg
(
)
;
let
const_inst
=
Inst
:
:
load_constant
(
tmp
amount
)
;
let
adj_inst
=
Inst
:
:
AluRRRExtend
{
alu_op
rd
:
writable_stack_reg
(
)
rn
:
stack_reg
(
)
rm
:
tmp
.
to_reg
(
)
extendop
:
ExtendOp
:
:
UXTX
}
;
ret
.
extend
(
const_inst
)
;
ret
.
push
(
adj_inst
)
;
}
ret
}
fn
gen_nominal_sp_adj
(
offset
:
i32
)
-
>
Inst
{
Inst
:
:
VirtualSPOffsetAdj
{
offset
:
offset
as
i64
}
}
fn
gen_prologue_frame_setup
(
flags
:
&
settings
:
:
Flags
)
-
>
SmallInstVec
<
Inst
>
{
let
mut
insts
=
SmallVec
:
:
new
(
)
;
if
flags
.
unwind_info
(
)
{
insts
.
push
(
Inst
:
:
Unwind
{
inst
:
UnwindInst
:
:
Aarch64SetPointerAuth
{
return_addresses
:
false
}
}
)
;
}
insts
.
push
(
Inst
:
:
StoreP64
{
rt
:
fp_reg
(
)
rt2
:
link_reg
(
)
mem
:
PairAMode
:
:
PreIndexed
(
writable_stack_reg
(
)
SImm7Scaled
:
:
maybe_from_i64
(
-
16
types
:
:
I64
)
.
unwrap
(
)
)
flags
:
MemFlags
:
:
trusted
(
)
}
)
;
if
flags
.
unwind_info
(
)
{
insts
.
push
(
Inst
:
:
Unwind
{
inst
:
UnwindInst
:
:
PushFrameRegs
{
offset_upward_to_caller_sp
:
16
}
}
)
;
}
insts
.
push
(
Inst
:
:
AluRRImm12
{
alu_op
:
ALUOp
:
:
Add64
rd
:
writable_fp_reg
(
)
rn
:
stack_reg
(
)
imm12
:
Imm12
{
bits
:
0
shift12
:
false
}
}
)
;
insts
}
fn
gen_epilogue_frame_restore
(
_
:
&
settings
:
:
Flags
)
-
>
SmallInstVec
<
Inst
>
{
let
mut
insts
=
SmallVec
:
:
new
(
)
;
insts
.
push
(
Inst
:
:
LoadP64
{
rt
:
writable_fp_reg
(
)
rt2
:
writable_link_reg
(
)
mem
:
PairAMode
:
:
PostIndexed
(
writable_stack_reg
(
)
SImm7Scaled
:
:
maybe_from_i64
(
16
types
:
:
I64
)
.
unwrap
(
)
)
flags
:
MemFlags
:
:
trusted
(
)
}
)
;
insts
}
fn
gen_probestack
(
_
:
u32
)
-
>
SmallInstVec
<
Self
:
:
I
>
{
smallvec
!
[
]
}
fn
gen_clobber_save
(
call_conv
:
isa
:
:
CallConv
flags
:
&
settings
:
:
Flags
clobbers
:
&
Set
<
Writable
<
RealReg
>
>
fixed_frame_storage_size
:
u32
)
-
>
(
u64
SmallVec
<
[
Inst
;
16
]
>
)
{
let
mut
insts
=
SmallVec
:
:
new
(
)
;
let
(
clobbered_int
clobbered_vec
)
=
get_regs_saved_in_prologue
(
call_conv
clobbers
)
;
let
(
int_save_bytes
vec_save_bytes
)
=
saved_reg_stack_size
(
&
clobbered_int
&
clobbered_vec
)
;
let
total_save_bytes
=
int_save_bytes
+
vec_save_bytes
;
let
clobber_size
=
total_save_bytes
as
i32
;
if
flags
.
unwind_info
(
)
{
insts
.
push
(
Inst
:
:
Unwind
{
inst
:
UnwindInst
:
:
DefineNewFrame
{
offset_downward_to_clobbers
:
clobber_size
as
u32
offset_upward_to_caller_sp
:
16
}
}
)
;
}
let
mut
clobber_offset
=
clobber_size
as
u32
;
for
reg_pair
in
clobbered_int
.
chunks
(
2
)
{
let
(
r1
r2
)
=
if
reg_pair
.
len
(
)
=
=
2
{
(
reg_pair
[
0
]
.
to_reg
(
)
.
to_reg
(
)
reg_pair
[
1
]
.
to_reg
(
)
.
to_reg
(
)
)
}
else
{
(
reg_pair
[
0
]
.
to_reg
(
)
.
to_reg
(
)
zero_reg
(
)
)
}
;
debug_assert
!
(
r1
.
get_class
(
)
=
=
RegClass
:
:
I64
)
;
debug_assert
!
(
r2
.
get_class
(
)
=
=
RegClass
:
:
I64
)
;
insts
.
push
(
Inst
:
:
StoreP64
{
rt
:
r1
rt2
:
r2
mem
:
PairAMode
:
:
PreIndexed
(
writable_stack_reg
(
)
SImm7Scaled
:
:
maybe_from_i64
(
-
16
types
:
:
I64
)
.
unwrap
(
)
)
flags
:
MemFlags
:
:
trusted
(
)
}
)
;
if
flags
.
unwind_info
(
)
{
clobber_offset
-
=
8
;
if
r2
!
=
zero_reg
(
)
{
insts
.
push
(
Inst
:
:
Unwind
{
inst
:
UnwindInst
:
:
SaveReg
{
clobber_offset
reg
:
r2
.
to_real_reg
(
)
}
}
)
;
}
clobber_offset
-
=
8
;
insts
.
push
(
Inst
:
:
Unwind
{
inst
:
UnwindInst
:
:
SaveReg
{
clobber_offset
reg
:
r1
.
to_real_reg
(
)
}
}
)
;
}
}
for
reg
in
clobbered_vec
.
iter
(
)
{
insts
.
push
(
Inst
:
:
FpuStore128
{
rd
:
reg
.
to_reg
(
)
.
to_reg
(
)
mem
:
AMode
:
:
PreIndexed
(
writable_stack_reg
(
)
SImm9
:
:
maybe_from_i64
(
-
16
)
.
unwrap
(
)
)
flags
:
MemFlags
:
:
trusted
(
)
}
)
;
if
flags
.
unwind_info
(
)
{
clobber_offset
-
=
16
;
insts
.
push
(
Inst
:
:
Unwind
{
inst
:
UnwindInst
:
:
SaveReg
{
clobber_offset
reg
:
reg
.
to_reg
(
)
}
}
)
;
}
}
if
fixed_frame_storage_size
>
0
{
insts
.
extend
(
Self
:
:
gen_sp_reg_adjust
(
-
(
fixed_frame_storage_size
as
i32
)
)
)
;
}
(
total_save_bytes
as
u64
insts
)
}
fn
gen_clobber_restore
(
call_conv
:
isa
:
:
CallConv
flags
:
&
settings
:
:
Flags
clobbers
:
&
Set
<
Writable
<
RealReg
>
>
fixed_frame_storage_size
:
u32
)
-
>
SmallVec
<
[
Inst
;
16
]
>
{
let
mut
insts
=
SmallVec
:
:
new
(
)
;
let
(
clobbered_int
clobbered_vec
)
=
get_regs_saved_in_prologue
(
call_conv
clobbers
)
;
if
fixed_frame_storage_size
>
0
{
insts
.
extend
(
Self
:
:
gen_sp_reg_adjust
(
fixed_frame_storage_size
as
i32
)
)
;
}
for
reg
in
clobbered_vec
.
iter
(
)
.
rev
(
)
{
insts
.
push
(
Inst
:
:
FpuLoad128
{
rd
:
Writable
:
:
from_reg
(
reg
.
to_reg
(
)
.
to_reg
(
)
)
mem
:
AMode
:
:
PostIndexed
(
writable_stack_reg
(
)
SImm9
:
:
maybe_from_i64
(
16
)
.
unwrap
(
)
)
flags
:
MemFlags
:
:
trusted
(
)
}
)
;
}
for
reg_pair
in
clobbered_int
.
chunks
(
2
)
.
rev
(
)
{
let
(
r1
r2
)
=
if
reg_pair
.
len
(
)
=
=
2
{
(
reg_pair
[
0
]
.
map
(
|
r
|
r
.
to_reg
(
)
)
reg_pair
[
1
]
.
map
(
|
r
|
r
.
to_reg
(
)
)
)
}
else
{
(
reg_pair
[
0
]
.
map
(
|
r
|
r
.
to_reg
(
)
)
writable_zero_reg
(
)
)
}
;
debug_assert
!
(
r1
.
to_reg
(
)
.
get_class
(
)
=
=
RegClass
:
:
I64
)
;
debug_assert
!
(
r2
.
to_reg
(
)
.
get_class
(
)
=
=
RegClass
:
:
I64
)
;
insts
.
push
(
Inst
:
:
LoadP64
{
rt
:
r1
rt2
:
r2
mem
:
PairAMode
:
:
PostIndexed
(
writable_stack_reg
(
)
SImm7Scaled
:
:
maybe_from_i64
(
16
I64
)
.
unwrap
(
)
)
flags
:
MemFlags
:
:
trusted
(
)
}
)
;
}
if
call_conv
=
=
isa
:
:
CallConv
:
:
Baldrdash2020
{
let
off
=
BALDRDASH_CALLEE_TLS_OFFSET
+
Self
:
:
fp_to_arg_offset
(
call_conv
flags
)
;
insts
.
push
(
Inst
:
:
gen_load
(
writable_xreg
(
BALDRDASH_TLS_REG
)
AMode
:
:
UnsignedOffset
(
fp_reg
(
)
UImm12Scaled
:
:
maybe_from_i64
(
off
I64
)
.
unwrap
(
)
)
I64
MemFlags
:
:
trusted
(
)
)
)
;
}
insts
}
fn
gen_call
(
dest
:
&
CallDest
uses
:
Vec
<
Reg
>
defs
:
Vec
<
Writable
<
Reg
>
>
opcode
:
ir
:
:
Opcode
tmp
:
Writable
<
Reg
>
callee_conv
:
isa
:
:
CallConv
caller_conv
:
isa
:
:
CallConv
)
-
>
SmallVec
<
[
(
InstIsSafepoint
Inst
)
;
2
]
>
{
let
mut
insts
=
SmallVec
:
:
new
(
)
;
match
&
dest
{
&
CallDest
:
:
ExtName
(
ref
name
RelocDistance
:
:
Near
)
=
>
insts
.
push
(
(
InstIsSafepoint
:
:
Yes
Inst
:
:
Call
{
info
:
Box
:
:
new
(
CallInfo
{
dest
:
name
.
clone
(
)
uses
defs
opcode
caller_callconv
:
caller_conv
callee_callconv
:
callee_conv
}
)
}
)
)
&
CallDest
:
:
ExtName
(
ref
name
RelocDistance
:
:
Far
)
=
>
{
insts
.
push
(
(
InstIsSafepoint
:
:
No
Inst
:
:
LoadExtName
{
rd
:
tmp
name
:
Box
:
:
new
(
name
.
clone
(
)
)
offset
:
0
}
)
)
;
insts
.
push
(
(
InstIsSafepoint
:
:
Yes
Inst
:
:
CallInd
{
info
:
Box
:
:
new
(
CallIndInfo
{
rn
:
tmp
.
to_reg
(
)
uses
defs
opcode
caller_callconv
:
caller_conv
callee_callconv
:
callee_conv
}
)
}
)
)
;
}
&
CallDest
:
:
Reg
(
reg
)
=
>
insts
.
push
(
(
InstIsSafepoint
:
:
Yes
Inst
:
:
CallInd
{
info
:
Box
:
:
new
(
CallIndInfo
{
rn
:
*
reg
uses
defs
opcode
caller_callconv
:
caller_conv
callee_callconv
:
callee_conv
}
)
}
)
)
}
insts
}
fn
gen_memcpy
(
call_conv
:
isa
:
:
CallConv
dst
:
Reg
src
:
Reg
size
:
usize
)
-
>
SmallVec
<
[
Self
:
:
I
;
8
]
>
{
assert
!
(
!
call_conv
.
extends_baldrdash
(
)
)
;
let
mut
insts
=
SmallVec
:
:
new
(
)
;
let
arg0
=
writable_xreg
(
0
)
;
let
arg1
=
writable_xreg
(
1
)
;
let
arg2
=
writable_xreg
(
2
)
;
insts
.
push
(
Inst
:
:
gen_move
(
arg0
dst
I64
)
)
;
insts
.
push
(
Inst
:
:
gen_move
(
arg1
src
I64
)
)
;
insts
.
extend
(
Inst
:
:
load_constant
(
arg2
size
as
u64
)
.
into_iter
(
)
)
;
insts
.
push
(
Inst
:
:
Call
{
info
:
Box
:
:
new
(
CallInfo
{
dest
:
ExternalName
:
:
LibCall
(
LibCall
:
:
Memcpy
)
uses
:
vec
!
[
arg0
.
to_reg
(
)
arg1
.
to_reg
(
)
arg2
.
to_reg
(
)
]
defs
:
Self
:
:
get_regs_clobbered_by_call
(
call_conv
)
opcode
:
Opcode
:
:
Call
caller_callconv
:
call_conv
callee_callconv
:
call_conv
}
)
}
)
;
insts
}
fn
get_number_of_spillslots_for_value
(
rc
:
RegClass
ty
:
Type
)
-
>
u32
{
match
(
rc
ty
)
{
(
RegClass
:
:
I64
_
)
=
>
1
(
RegClass
:
:
V128
F32
)
|
(
RegClass
:
:
V128
F64
)
=
>
1
(
RegClass
:
:
V128
_
)
=
>
2
_
=
>
panic
!
(
"
Unexpected
register
class
!
"
)
}
}
fn
get_virtual_sp_offset_from_state
(
s
:
&
EmitState
)
-
>
i64
{
s
.
virtual_sp_offset
}
fn
get_nominal_sp_to_fp
(
s
:
&
EmitState
)
-
>
i64
{
s
.
nominal_sp_to_fp
}
fn
get_regs_clobbered_by_call
(
call_conv_of_callee
:
isa
:
:
CallConv
)
-
>
Vec
<
Writable
<
Reg
>
>
{
let
mut
caller_saved
=
Vec
:
:
new
(
)
;
for
i
in
0
.
.
29
{
let
x
=
writable_xreg
(
i
)
;
if
is_reg_clobbered_by_call
(
call_conv_of_callee
x
.
to_reg
(
)
.
to_real_reg
(
)
)
{
caller_saved
.
push
(
x
)
;
}
}
for
i
in
0
.
.
32
{
let
v
=
writable_vreg
(
i
)
;
if
is_reg_clobbered_by_call
(
call_conv_of_callee
v
.
to_reg
(
)
.
to_real_reg
(
)
)
{
caller_saved
.
push
(
v
)
;
}
}
caller_saved
}
fn
get_ext_mode
(
call_conv
:
isa
:
:
CallConv
specified
:
ir
:
:
ArgumentExtension
)
-
>
ir
:
:
ArgumentExtension
{
if
call_conv
.
extends_baldrdash
(
)
{
specified
}
else
{
ir
:
:
ArgumentExtension
:
:
None
}
}
}
fn
legal_type_for_machine
(
ty
:
Type
)
-
>
bool
{
match
ty
{
R32
=
>
false
_
=
>
true
}
}
fn
is_reg_saved_in_prologue
(
call_conv
:
isa
:
:
CallConv
r
:
RealReg
)
-
>
bool
{
if
call_conv
.
extends_baldrdash
(
)
{
match
r
.
get_class
(
)
{
RegClass
:
:
I64
=
>
{
let
enc
=
r
.
get_hw_encoding
(
)
;
return
BALDRDASH_JIT_CALLEE_SAVED_GPR
[
enc
]
;
}
RegClass
:
:
V128
=
>
{
let
enc
=
r
.
get_hw_encoding
(
)
;
return
BALDRDASH_JIT_CALLEE_SAVED_FPU
[
enc
]
;
}
_
=
>
unimplemented
!
(
"
baldrdash
callee
saved
on
non
-
i64
reg
classes
"
)
}
;
}
match
r
.
get_class
(
)
{
RegClass
:
:
I64
=
>
{
r
.
get_hw_encoding
(
)
>
=
19
&
&
r
.
get_hw_encoding
(
)
<
=
28
}
RegClass
:
:
V128
=
>
{
r
.
get_hw_encoding
(
)
>
=
8
&
&
r
.
get_hw_encoding
(
)
<
=
15
}
_
=
>
panic
!
(
"
Unexpected
RegClass
"
)
}
}
fn
get_regs_saved_in_prologue
(
call_conv
:
isa
:
:
CallConv
regs
:
&
Set
<
Writable
<
RealReg
>
>
)
-
>
(
Vec
<
Writable
<
RealReg
>
>
Vec
<
Writable
<
RealReg
>
>
)
{
let
mut
int_saves
=
vec
!
[
]
;
let
mut
vec_saves
=
vec
!
[
]
;
for
&
reg
in
regs
.
iter
(
)
{
if
is_reg_saved_in_prologue
(
call_conv
reg
.
to_reg
(
)
)
{
match
reg
.
to_reg
(
)
.
get_class
(
)
{
RegClass
:
:
I64
=
>
int_saves
.
push
(
reg
)
RegClass
:
:
V128
=
>
vec_saves
.
push
(
reg
)
_
=
>
panic
!
(
"
Unexpected
RegClass
"
)
}
}
}
int_saves
.
sort_unstable_by_key
(
|
r
|
r
.
to_reg
(
)
.
get_index
(
)
)
;
vec_saves
.
sort_unstable_by_key
(
|
r
|
r
.
to_reg
(
)
.
get_index
(
)
)
;
(
int_saves
vec_saves
)
}
fn
is_reg_clobbered_by_call
(
call_conv_of_callee
:
isa
:
:
CallConv
r
:
RealReg
)
-
>
bool
{
if
call_conv_of_callee
.
extends_baldrdash
(
)
{
match
r
.
get_class
(
)
{
RegClass
:
:
I64
=
>
{
let
enc
=
r
.
get_hw_encoding
(
)
;
if
!
BALDRDASH_JIT_CALLEE_SAVED_GPR
[
enc
]
{
return
true
;
}
}
RegClass
:
:
V128
=
>
{
let
enc
=
r
.
get_hw_encoding
(
)
;
if
!
BALDRDASH_JIT_CALLEE_SAVED_FPU
[
enc
]
{
return
true
;
}
}
_
=
>
unimplemented
!
(
"
baldrdash
callee
saved
on
non
-
i64
reg
classes
"
)
}
;
}
match
r
.
get_class
(
)
{
RegClass
:
:
I64
=
>
{
r
.
get_hw_encoding
(
)
<
=
17
}
RegClass
:
:
V128
=
>
{
true
}
_
=
>
panic
!
(
"
Unexpected
RegClass
"
)
}
}
