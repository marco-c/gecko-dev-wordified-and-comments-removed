use
super
:
:
abi
:
:
*
;
use
crate
:
:
binemit
:
:
StackMap
;
use
crate
:
:
ir
:
:
types
:
:
*
;
use
crate
:
:
ir
:
:
{
ArgumentExtension
ArgumentPurpose
StackSlot
}
;
use
crate
:
:
machinst
:
:
*
;
use
crate
:
:
settings
;
use
crate
:
:
CodegenResult
;
use
crate
:
:
{
ir
isa
}
;
use
alloc
:
:
vec
:
:
Vec
;
use
log
:
:
{
debug
trace
}
;
use
regalloc
:
:
{
RealReg
Reg
RegClass
Set
SpillSlot
Writable
}
;
use
smallvec
:
:
{
smallvec
SmallVec
}
;
use
std
:
:
convert
:
:
TryFrom
;
use
std
:
:
marker
:
:
PhantomData
;
use
std
:
:
mem
;
#
[
derive
(
Clone
Copy
Debug
PartialEq
Eq
)
]
pub
enum
ABIArgSlot
{
Reg
{
reg
:
RealReg
ty
:
ir
:
:
Type
extension
:
ir
:
:
ArgumentExtension
}
Stack
{
offset
:
i64
ty
:
ir
:
:
Type
extension
:
ir
:
:
ArgumentExtension
}
}
#
[
derive
(
Clone
Debug
)
]
pub
enum
ABIArg
{
Slots
{
slots
:
Vec
<
ABIArgSlot
>
purpose
:
ir
:
:
ArgumentPurpose
}
StructArg
{
offset
:
i64
size
:
u64
purpose
:
ir
:
:
ArgumentPurpose
}
}
impl
ABIArg
{
fn
get_purpose
(
&
self
)
-
>
ir
:
:
ArgumentPurpose
{
match
self
{
&
ABIArg
:
:
Slots
{
purpose
.
.
}
=
>
purpose
&
ABIArg
:
:
StructArg
{
purpose
.
.
}
=
>
purpose
}
}
fn
is_struct_arg
(
&
self
)
-
>
bool
{
match
self
{
&
ABIArg
:
:
StructArg
{
.
.
}
=
>
true
_
=
>
false
}
}
pub
fn
reg
(
reg
:
RealReg
ty
:
ir
:
:
Type
extension
:
ir
:
:
ArgumentExtension
purpose
:
ir
:
:
ArgumentPurpose
)
-
>
ABIArg
{
ABIArg
:
:
Slots
{
slots
:
vec
!
[
ABIArgSlot
:
:
Reg
{
reg
ty
extension
}
]
purpose
}
}
pub
fn
stack
(
offset
:
i64
ty
:
ir
:
:
Type
extension
:
ir
:
:
ArgumentExtension
purpose
:
ir
:
:
ArgumentPurpose
)
-
>
ABIArg
{
ABIArg
:
:
Slots
{
slots
:
vec
!
[
ABIArgSlot
:
:
Stack
{
offset
ty
extension
}
]
purpose
}
}
}
#
[
derive
(
Clone
Copy
Debug
PartialEq
Eq
)
]
pub
enum
ArgsOrRets
{
Args
Rets
}
#
[
derive
(
Clone
Copy
Debug
PartialEq
Eq
)
]
pub
enum
InstIsSafepoint
{
Yes
No
}
#
[
derive
(
Clone
Copy
Debug
)
]
pub
enum
StackAMode
{
FPOffset
(
i64
ir
:
:
Type
)
NominalSPOffset
(
i64
ir
:
:
Type
)
SPOffset
(
i64
ir
:
:
Type
)
}
impl
StackAMode
{
pub
fn
offset
(
self
addend
:
i64
)
-
>
Self
{
match
self
{
StackAMode
:
:
FPOffset
(
off
ty
)
=
>
StackAMode
:
:
FPOffset
(
off
+
addend
ty
)
StackAMode
:
:
NominalSPOffset
(
off
ty
)
=
>
StackAMode
:
:
NominalSPOffset
(
off
+
addend
ty
)
StackAMode
:
:
SPOffset
(
off
ty
)
=
>
StackAMode
:
:
SPOffset
(
off
+
addend
ty
)
}
}
}
pub
trait
ABIMachineSpec
{
type
I
:
VCodeInst
;
fn
word_bits
(
)
-
>
u32
;
fn
word_bytes
(
)
-
>
u32
{
return
Self
:
:
word_bits
(
)
/
8
;
}
fn
word_type
(
)
-
>
Type
{
match
Self
:
:
word_bits
(
)
{
32
=
>
I32
64
=
>
I64
_
=
>
unreachable
!
(
)
}
}
fn
word_reg_class
(
)
-
>
RegClass
{
match
Self
:
:
word_bits
(
)
{
32
=
>
RegClass
:
:
I32
64
=
>
RegClass
:
:
I64
_
=
>
unreachable
!
(
)
}
}
fn
stack_align
(
call_conv
:
isa
:
:
CallConv
)
-
>
u32
;
fn
compute_arg_locs
(
call_conv
:
isa
:
:
CallConv
flags
:
&
settings
:
:
Flags
params
:
&
[
ir
:
:
AbiParam
]
args_or_rets
:
ArgsOrRets
add_ret_area_ptr
:
bool
)
-
>
CodegenResult
<
(
Vec
<
ABIArg
>
i64
Option
<
usize
>
)
>
;
fn
fp_to_arg_offset
(
call_conv
:
isa
:
:
CallConv
flags
:
&
settings
:
:
Flags
)
-
>
i64
;
fn
gen_load_stack
(
mem
:
StackAMode
into_reg
:
Writable
<
Reg
>
ty
:
Type
)
-
>
Self
:
:
I
;
fn
gen_store_stack
(
mem
:
StackAMode
from_reg
:
Reg
ty
:
Type
)
-
>
Self
:
:
I
;
fn
gen_move
(
to_reg
:
Writable
<
Reg
>
from_reg
:
Reg
ty
:
Type
)
-
>
Self
:
:
I
;
fn
gen_extend
(
to_reg
:
Writable
<
Reg
>
from_reg
:
Reg
is_signed
:
bool
from_bits
:
u8
to_bits
:
u8
)
-
>
Self
:
:
I
;
fn
gen_ret
(
)
-
>
Self
:
:
I
;
fn
gen_epilogue_placeholder
(
)
-
>
Self
:
:
I
;
fn
gen_add_imm
(
into_reg
:
Writable
<
Reg
>
from_reg
:
Reg
imm
:
u32
)
-
>
SmallInstVec
<
Self
:
:
I
>
;
fn
gen_stack_lower_bound_trap
(
limit_reg
:
Reg
)
-
>
SmallInstVec
<
Self
:
:
I
>
;
fn
gen_get_stack_addr
(
mem
:
StackAMode
into_reg
:
Writable
<
Reg
>
ty
:
Type
)
-
>
Self
:
:
I
;
fn
get_stacklimit_reg
(
)
-
>
Reg
;
fn
gen_load_base_offset
(
into_reg
:
Writable
<
Reg
>
base
:
Reg
offset
:
i32
ty
:
Type
)
-
>
Self
:
:
I
;
fn
gen_store_base_offset
(
base
:
Reg
offset
:
i32
from_reg
:
Reg
ty
:
Type
)
-
>
Self
:
:
I
;
fn
gen_sp_reg_adjust
(
amount
:
i32
)
-
>
SmallInstVec
<
Self
:
:
I
>
;
fn
gen_nominal_sp_adj
(
amount
:
i32
)
-
>
Self
:
:
I
;
fn
gen_prologue_frame_setup
(
flags
:
&
settings
:
:
Flags
)
-
>
SmallInstVec
<
Self
:
:
I
>
;
fn
gen_epilogue_frame_restore
(
flags
:
&
settings
:
:
Flags
)
-
>
SmallInstVec
<
Self
:
:
I
>
;
fn
gen_probestack
(
_frame_size
:
u32
)
-
>
SmallInstVec
<
Self
:
:
I
>
;
fn
gen_clobber_save
(
call_conv
:
isa
:
:
CallConv
flags
:
&
settings
:
:
Flags
clobbers
:
&
Set
<
Writable
<
RealReg
>
>
fixed_frame_storage_size
:
u32
)
-
>
(
u64
SmallVec
<
[
Self
:
:
I
;
16
]
>
)
;
fn
gen_clobber_restore
(
call_conv
:
isa
:
:
CallConv
flags
:
&
settings
:
:
Flags
clobbers
:
&
Set
<
Writable
<
RealReg
>
>
fixed_frame_storage_size
:
u32
)
-
>
SmallVec
<
[
Self
:
:
I
;
16
]
>
;
fn
gen_call
(
dest
:
&
CallDest
uses
:
Vec
<
Reg
>
defs
:
Vec
<
Writable
<
Reg
>
>
opcode
:
ir
:
:
Opcode
tmp
:
Writable
<
Reg
>
callee_conv
:
isa
:
:
CallConv
callee_conv
:
isa
:
:
CallConv
)
-
>
SmallVec
<
[
(
InstIsSafepoint
Self
:
:
I
)
;
2
]
>
;
fn
gen_memcpy
(
call_conv
:
isa
:
:
CallConv
dst
:
Reg
src
:
Reg
size
:
usize
)
-
>
SmallVec
<
[
Self
:
:
I
;
8
]
>
;
fn
get_number_of_spillslots_for_value
(
rc
:
RegClass
ty
:
Type
)
-
>
u32
;
fn
get_virtual_sp_offset_from_state
(
s
:
&
<
Self
:
:
I
as
MachInstEmit
>
:
:
State
)
-
>
i64
;
fn
get_nominal_sp_to_fp
(
s
:
&
<
Self
:
:
I
as
MachInstEmit
>
:
:
State
)
-
>
i64
;
fn
get_regs_clobbered_by_call
(
call_conv_of_callee
:
isa
:
:
CallConv
)
-
>
Vec
<
Writable
<
Reg
>
>
;
fn
get_ext_mode
(
call_conv
:
isa
:
:
CallConv
specified
:
ir
:
:
ArgumentExtension
)
-
>
ir
:
:
ArgumentExtension
;
}
struct
ABISig
{
args
:
Vec
<
ABIArg
>
rets
:
Vec
<
ABIArg
>
stack_arg_space
:
i64
stack_ret_space
:
i64
stack_ret_arg
:
Option
<
usize
>
call_conv
:
isa
:
:
CallConv
}
impl
ABISig
{
fn
from_func_sig
<
M
:
ABIMachineSpec
>
(
sig
:
&
ir
:
:
Signature
flags
:
&
settings
:
:
Flags
)
-
>
CodegenResult
<
ABISig
>
{
let
(
rets
stack_ret_space
_
)
=
M
:
:
compute_arg_locs
(
sig
.
call_conv
flags
&
sig
.
returns
ArgsOrRets
:
:
Rets
false
)
?
;
let
need_stack_return_area
=
stack_ret_space
>
0
;
let
(
args
stack_arg_space
stack_ret_arg
)
=
M
:
:
compute_arg_locs
(
sig
.
call_conv
flags
&
sig
.
params
ArgsOrRets
:
:
Args
need_stack_return_area
)
?
;
trace
!
(
"
ABISig
:
sig
{
:
?
}
=
>
args
=
{
:
?
}
rets
=
{
:
?
}
arg
stack
=
{
}
ret
stack
=
{
}
stack_ret_arg
=
{
:
?
}
"
sig
args
rets
stack_arg_space
stack_ret_space
stack_ret_arg
)
;
Ok
(
ABISig
{
args
rets
stack_arg_space
stack_ret_space
stack_ret_arg
call_conv
:
sig
.
call_conv
}
)
}
}
pub
struct
ABICalleeImpl
<
M
:
ABIMachineSpec
>
{
ir_sig
:
ir
:
:
Signature
sig
:
ABISig
stackslots
:
PrimaryMap
<
StackSlot
u32
>
stackslots_size
:
u32
clobbered
:
Set
<
Writable
<
RealReg
>
>
spillslots
:
Option
<
usize
>
fixed_frame_storage_size
:
u32
total_frame_size
:
Option
<
u32
>
ret_area_ptr
:
Option
<
Writable
<
Reg
>
>
call_conv
:
isa
:
:
CallConv
flags
:
settings
:
:
Flags
is_leaf
:
bool
stack_limit
:
Option
<
(
Reg
SmallInstVec
<
M
:
:
I
>
)
>
probestack_min_frame
:
Option
<
u32
>
_mach
:
PhantomData
<
M
>
}
fn
get_special_purpose_param_register
(
f
:
&
ir
:
:
Function
abi
:
&
ABISig
purpose
:
ir
:
:
ArgumentPurpose
)
-
>
Option
<
Reg
>
{
let
idx
=
f
.
signature
.
special_param_index
(
purpose
)
?
;
match
&
abi
.
args
[
idx
]
{
&
ABIArg
:
:
Slots
{
ref
slots
.
.
}
=
>
match
&
slots
[
0
]
{
&
ABIArgSlot
:
:
Reg
{
reg
.
.
}
=
>
Some
(
reg
.
to_reg
(
)
)
_
=
>
None
}
_
=
>
None
}
}
impl
<
M
:
ABIMachineSpec
>
ABICalleeImpl
<
M
>
{
pub
fn
new
(
f
:
&
ir
:
:
Function
flags
:
settings
:
:
Flags
)
-
>
CodegenResult
<
Self
>
{
debug
!
(
"
ABI
:
func
signature
{
:
?
}
"
f
.
signature
)
;
let
ir_sig
=
ensure_struct_return_ptr_is_returned
(
&
f
.
signature
)
;
let
sig
=
ABISig
:
:
from_func_sig
:
:
<
M
>
(
&
ir_sig
&
flags
)
?
;
let
call_conv
=
f
.
signature
.
call_conv
;
debug_assert
!
(
call_conv
=
=
isa
:
:
CallConv
:
:
SystemV
|
|
call_conv
=
=
isa
:
:
CallConv
:
:
Fast
|
|
call_conv
=
=
isa
:
:
CallConv
:
:
Cold
|
|
call_conv
.
extends_baldrdash
(
)
|
|
call_conv
.
extends_windows_fastcall
(
)
|
|
call_conv
=
=
isa
:
:
CallConv
:
:
AppleAarch64
"
Unsupported
calling
convention
:
{
:
?
}
"
call_conv
)
;
let
mut
stack_offset
:
u32
=
0
;
let
mut
stackslots
=
PrimaryMap
:
:
new
(
)
;
for
(
stackslot
data
)
in
f
.
stack_slots
.
iter
(
)
{
let
off
=
stack_offset
;
stack_offset
+
=
data
.
size
;
let
mask
=
M
:
:
word_bytes
(
)
-
1
;
stack_offset
=
(
stack_offset
+
mask
)
&
!
mask
;
debug_assert_eq
!
(
stackslot
.
as_u32
(
)
as
usize
stackslots
.
len
(
)
)
;
stackslots
.
push
(
off
)
;
}
let
stack_limit
=
get_special_purpose_param_register
(
f
&
sig
ir
:
:
ArgumentPurpose
:
:
StackLimit
)
.
map
(
|
reg
|
(
reg
smallvec
!
[
]
)
)
.
or_else
(
|
|
f
.
stack_limit
.
map
(
|
gv
|
gen_stack_limit
:
:
<
M
>
(
f
&
sig
gv
)
)
)
;
let
probestack_min_frame
=
if
flags
.
enable_probestack
(
)
{
assert
!
(
!
flags
.
probestack_func_adjusts_sp
(
)
"
SP
-
adjusting
probestack
not
supported
in
new
backends
"
)
;
Some
(
1
<
<
flags
.
probestack_size_log2
(
)
)
}
else
{
None
}
;
Ok
(
Self
{
ir_sig
sig
stackslots
stackslots_size
:
stack_offset
clobbered
:
Set
:
:
empty
(
)
spillslots
:
None
fixed_frame_storage_size
:
0
total_frame_size
:
None
ret_area_ptr
:
None
call_conv
flags
is_leaf
:
f
.
is_leaf
(
)
stack_limit
probestack_min_frame
_mach
:
PhantomData
}
)
}
fn
insert_stack_check
(
&
self
stack_limit
:
Reg
stack_size
:
u32
insts
:
&
mut
SmallInstVec
<
M
:
:
I
>
)
{
if
stack_size
=
=
0
{
insts
.
extend
(
M
:
:
gen_stack_lower_bound_trap
(
stack_limit
)
)
;
return
;
}
if
stack_size
>
=
32
*
1024
{
insts
.
extend
(
M
:
:
gen_stack_lower_bound_trap
(
stack_limit
)
)
;
}
let
scratch
=
Writable
:
:
from_reg
(
M
:
:
get_stacklimit_reg
(
)
)
;
insts
.
extend
(
M
:
:
gen_add_imm
(
scratch
stack_limit
stack_size
)
.
into_iter
(
)
)
;
insts
.
extend
(
M
:
:
gen_stack_lower_bound_trap
(
scratch
.
to_reg
(
)
)
)
;
}
}
fn
gen_stack_limit
<
M
:
ABIMachineSpec
>
(
f
:
&
ir
:
:
Function
abi
:
&
ABISig
gv
:
ir
:
:
GlobalValue
)
-
>
(
Reg
SmallInstVec
<
M
:
:
I
>
)
{
let
mut
insts
=
smallvec
!
[
]
;
let
reg
=
generate_gv
:
:
<
M
>
(
f
abi
gv
&
mut
insts
)
;
return
(
reg
insts
)
;
}
fn
generate_gv
<
M
:
ABIMachineSpec
>
(
f
:
&
ir
:
:
Function
abi
:
&
ABISig
gv
:
ir
:
:
GlobalValue
insts
:
&
mut
SmallInstVec
<
M
:
:
I
>
)
-
>
Reg
{
match
f
.
global_values
[
gv
]
{
ir
:
:
GlobalValueData
:
:
VMContext
=
>
{
get_special_purpose_param_register
(
f
abi
ir
:
:
ArgumentPurpose
:
:
VMContext
)
.
expect
(
"
no
vmcontext
parameter
found
"
)
}
ir
:
:
GlobalValueData
:
:
Load
{
base
offset
global_type
:
_
readonly
:
_
}
=
>
{
let
base
=
generate_gv
:
:
<
M
>
(
f
abi
base
insts
)
;
let
into_reg
=
Writable
:
:
from_reg
(
M
:
:
get_stacklimit_reg
(
)
)
;
insts
.
push
(
M
:
:
gen_load_base_offset
(
into_reg
base
offset
.
into
(
)
M
:
:
word_type
(
)
)
)
;
return
into_reg
.
to_reg
(
)
;
}
ref
other
=
>
panic
!
(
"
global
value
for
stack
limit
not
supported
:
{
}
"
other
)
}
}
fn
ty_from_ty_hint_or_reg_class
<
M
:
ABIMachineSpec
>
(
r
:
Reg
ty
:
Option
<
Type
>
)
-
>
Type
{
match
(
ty
r
.
get_class
(
)
)
{
(
Some
(
t
)
_
)
=
>
t
(
None
rc
)
if
rc
=
=
M
:
:
word_reg_class
(
)
=
>
M
:
:
word_type
(
)
_
=
>
panic
!
(
"
Unexpected
register
class
!
"
)
}
}
fn
gen_load_stack_multi
<
M
:
ABIMachineSpec
>
(
from
:
StackAMode
dst
:
ValueRegs
<
Writable
<
Reg
>
>
ty
:
Type
)
-
>
SmallInstVec
<
M
:
:
I
>
{
let
mut
ret
=
smallvec
!
[
]
;
let
(
_
tys
)
=
M
:
:
I
:
:
rc_for_type
(
ty
)
.
unwrap
(
)
;
let
mut
offset
=
0
;
for
(
&
dst
&
ty
)
in
dst
.
regs
(
)
.
iter
(
)
.
zip
(
tys
.
iter
(
)
)
{
ret
.
push
(
M
:
:
gen_load_stack
(
from
.
offset
(
offset
)
dst
ty
)
)
;
offset
+
=
ty
.
bytes
(
)
as
i64
;
}
ret
}
fn
gen_store_stack_multi
<
M
:
ABIMachineSpec
>
(
from
:
StackAMode
src
:
ValueRegs
<
Reg
>
ty
:
Type
)
-
>
SmallInstVec
<
M
:
:
I
>
{
let
mut
ret
=
smallvec
!
[
]
;
let
(
_
tys
)
=
M
:
:
I
:
:
rc_for_type
(
ty
)
.
unwrap
(
)
;
let
mut
offset
=
0
;
for
(
&
src
&
ty
)
in
src
.
regs
(
)
.
iter
(
)
.
zip
(
tys
.
iter
(
)
)
{
ret
.
push
(
M
:
:
gen_store_stack
(
from
.
offset
(
offset
)
src
ty
)
)
;
offset
+
=
ty
.
bytes
(
)
as
i64
;
}
ret
}
fn
ensure_struct_return_ptr_is_returned
(
sig
:
&
ir
:
:
Signature
)
-
>
ir
:
:
Signature
{
let
params_structret
=
sig
.
params
.
iter
(
)
.
find
(
|
p
|
p
.
purpose
=
=
ArgumentPurpose
:
:
StructReturn
)
;
let
rets_have_structret
=
sig
.
returns
.
len
(
)
>
0
&
&
sig
.
returns
.
iter
(
)
.
any
(
|
arg
|
arg
.
purpose
=
=
ArgumentPurpose
:
:
StructReturn
)
;
let
mut
sig
=
sig
.
clone
(
)
;
if
params_structret
.
is_some
(
)
&
&
!
rets_have_structret
{
sig
.
returns
.
insert
(
0
params_structret
.
unwrap
(
)
.
clone
(
)
)
;
}
sig
}
impl
<
M
:
ABIMachineSpec
>
ABICallee
for
ABICalleeImpl
<
M
>
{
type
I
=
M
:
:
I
;
fn
signature
(
&
self
)
-
>
&
ir
:
:
Signature
{
&
self
.
ir_sig
}
fn
temp_needed
(
&
self
)
-
>
Option
<
Type
>
{
if
self
.
sig
.
stack_ret_arg
.
is_some
(
)
{
Some
(
M
:
:
word_type
(
)
)
}
else
{
None
}
}
fn
init
(
&
mut
self
maybe_tmp
:
Option
<
Writable
<
Reg
>
>
)
{
if
self
.
sig
.
stack_ret_arg
.
is_some
(
)
{
assert
!
(
maybe_tmp
.
is_some
(
)
)
;
self
.
ret_area_ptr
=
maybe_tmp
;
}
}
fn
flags
(
&
self
)
-
>
&
settings
:
:
Flags
{
&
self
.
flags
}
fn
call_conv
(
&
self
)
-
>
isa
:
:
CallConv
{
self
.
sig
.
call_conv
}
fn
liveins
(
&
self
)
-
>
Set
<
RealReg
>
{
let
mut
set
:
Set
<
RealReg
>
=
Set
:
:
empty
(
)
;
for
arg
in
&
self
.
sig
.
args
{
if
let
&
ABIArg
:
:
Slots
{
ref
slots
.
.
}
=
arg
{
for
slot
in
slots
{
if
let
ABIArgSlot
:
:
Reg
{
reg
.
.
}
=
slot
{
set
.
insert
(
*
reg
)
;
}
}
}
}
set
}
fn
liveouts
(
&
self
)
-
>
Set
<
RealReg
>
{
let
mut
set
:
Set
<
RealReg
>
=
Set
:
:
empty
(
)
;
for
ret
in
&
self
.
sig
.
rets
{
if
let
&
ABIArg
:
:
Slots
{
ref
slots
.
.
}
=
ret
{
for
slot
in
slots
{
if
let
ABIArgSlot
:
:
Reg
{
reg
.
.
}
=
slot
{
set
.
insert
(
*
reg
)
;
}
}
}
}
set
}
fn
num_args
(
&
self
)
-
>
usize
{
self
.
sig
.
args
.
len
(
)
}
fn
num_retvals
(
&
self
)
-
>
usize
{
self
.
sig
.
rets
.
len
(
)
}
fn
num_stackslots
(
&
self
)
-
>
usize
{
self
.
stackslots
.
len
(
)
}
fn
stackslot_offsets
(
&
self
)
-
>
&
PrimaryMap
<
StackSlot
u32
>
{
&
self
.
stackslots
}
fn
gen_copy_arg_to_regs
(
&
self
idx
:
usize
into_regs
:
ValueRegs
<
Writable
<
Reg
>
>
)
-
>
SmallInstVec
<
Self
:
:
I
>
{
let
mut
insts
=
smallvec
!
[
]
;
match
&
self
.
sig
.
args
[
idx
]
{
&
ABIArg
:
:
Slots
{
ref
slots
.
.
}
=
>
{
assert_eq
!
(
into_regs
.
len
(
)
slots
.
len
(
)
)
;
for
(
slot
into_reg
)
in
slots
.
iter
(
)
.
zip
(
into_regs
.
regs
(
)
.
iter
(
)
)
{
match
slot
{
&
ABIArgSlot
:
:
Reg
{
reg
ty
.
.
}
=
>
{
insts
.
push
(
M
:
:
gen_move
(
*
into_reg
reg
.
to_reg
(
)
ty
)
)
;
}
&
ABIArgSlot
:
:
Stack
{
offset
ty
.
.
}
=
>
{
insts
.
push
(
M
:
:
gen_load_stack
(
StackAMode
:
:
FPOffset
(
M
:
:
fp_to_arg_offset
(
self
.
call_conv
&
self
.
flags
)
+
offset
ty
)
*
into_reg
ty
)
)
;
}
}
}
}
&
ABIArg
:
:
StructArg
{
offset
.
.
}
=
>
{
let
into_reg
=
into_regs
.
only_reg
(
)
.
unwrap
(
)
;
insts
.
push
(
M
:
:
gen_get_stack_addr
(
StackAMode
:
:
FPOffset
(
M
:
:
fp_to_arg_offset
(
self
.
call_conv
&
self
.
flags
)
+
offset
I8
)
into_reg
I8
)
)
;
}
}
insts
}
fn
arg_is_needed_in_body
(
&
self
idx
:
usize
)
-
>
bool
{
match
self
.
sig
.
args
[
idx
]
.
get_purpose
(
)
{
ir
:
:
ArgumentPurpose
:
:
CalleeTLS
|
ir
:
:
ArgumentPurpose
:
:
CallerTLS
=
>
false
_
=
>
true
}
}
fn
gen_copy_regs_to_retval
(
&
self
idx
:
usize
from_regs
:
ValueRegs
<
Writable
<
Reg
>
>
)
-
>
SmallInstVec
<
Self
:
:
I
>
{
let
mut
ret
=
smallvec
!
[
]
;
let
word_bits
=
M
:
:
word_bits
(
)
as
u8
;
match
&
self
.
sig
.
rets
[
idx
]
{
&
ABIArg
:
:
Slots
{
ref
slots
.
.
}
=
>
{
assert_eq
!
(
from_regs
.
len
(
)
slots
.
len
(
)
)
;
for
(
slot
from_reg
)
in
slots
.
iter
(
)
.
zip
(
from_regs
.
regs
(
)
.
iter
(
)
)
{
match
slot
{
&
ABIArgSlot
:
:
Reg
{
reg
ty
extension
.
.
}
=
>
{
let
from_bits
=
ty_bits
(
ty
)
as
u8
;
let
ext
=
M
:
:
get_ext_mode
(
self
.
sig
.
call_conv
extension
)
;
match
(
ext
from_bits
)
{
(
ArgumentExtension
:
:
Uext
n
)
|
(
ArgumentExtension
:
:
Sext
n
)
if
n
<
word_bits
=
>
{
let
signed
=
ext
=
=
ArgumentExtension
:
:
Sext
;
ret
.
push
(
M
:
:
gen_extend
(
Writable
:
:
from_reg
(
reg
.
to_reg
(
)
)
from_reg
.
to_reg
(
)
signed
from_bits
word_bits
)
)
;
}
_
=
>
{
ret
.
push
(
M
:
:
gen_move
(
Writable
:
:
from_reg
(
reg
.
to_reg
(
)
)
from_reg
.
to_reg
(
)
ty
)
)
;
}
}
;
}
&
ABIArgSlot
:
:
Stack
{
offset
ty
extension
.
.
}
=
>
{
let
mut
ty
=
ty
;
let
from_bits
=
ty_bits
(
ty
)
as
u8
;
let
off
=
i32
:
:
try_from
(
offset
)
.
expect
(
"
Argument
stack
offset
greater
than
2GB
;
should
hit
impl
limit
first
"
)
;
let
ext
=
M
:
:
get_ext_mode
(
self
.
sig
.
call_conv
extension
)
;
match
(
ext
from_bits
)
{
(
ArgumentExtension
:
:
Uext
n
)
|
(
ArgumentExtension
:
:
Sext
n
)
if
n
<
word_bits
=
>
{
assert_eq
!
(
M
:
:
word_reg_class
(
)
from_reg
.
to_reg
(
)
.
get_class
(
)
)
;
let
signed
=
ext
=
=
ArgumentExtension
:
:
Sext
;
ret
.
push
(
M
:
:
gen_extend
(
Writable
:
:
from_reg
(
from_reg
.
to_reg
(
)
)
from_reg
.
to_reg
(
)
signed
from_bits
word_bits
)
)
;
ty
=
M
:
:
word_type
(
)
;
}
_
=
>
{
}
}
;
ret
.
push
(
M
:
:
gen_store_base_offset
(
self
.
ret_area_ptr
.
unwrap
(
)
.
to_reg
(
)
off
from_reg
.
to_reg
(
)
ty
)
)
;
}
}
}
}
&
ABIArg
:
:
StructArg
{
.
.
}
=
>
{
panic
!
(
"
StructArg
in
return
position
is
unsupported
"
)
;
}
}
ret
}
fn
gen_retval_area_setup
(
&
self
)
-
>
Option
<
Self
:
:
I
>
{
if
let
Some
(
i
)
=
self
.
sig
.
stack_ret_arg
{
let
insts
=
self
.
gen_copy_arg_to_regs
(
i
ValueRegs
:
:
one
(
self
.
ret_area_ptr
.
unwrap
(
)
)
)
;
let
inst
=
insts
.
into_iter
(
)
.
next
(
)
.
unwrap
(
)
;
trace
!
(
"
gen_retval_area_setup
:
inst
{
:
?
}
;
ptr
reg
is
{
:
?
}
"
inst
self
.
ret_area_ptr
.
unwrap
(
)
.
to_reg
(
)
)
;
Some
(
inst
)
}
else
{
trace
!
(
"
gen_retval_area_setup
:
not
needed
"
)
;
None
}
}
fn
gen_ret
(
&
self
)
-
>
Self
:
:
I
{
M
:
:
gen_ret
(
)
}
fn
gen_epilogue_placeholder
(
&
self
)
-
>
Self
:
:
I
{
M
:
:
gen_epilogue_placeholder
(
)
}
fn
set_num_spillslots
(
&
mut
self
slots
:
usize
)
{
self
.
spillslots
=
Some
(
slots
)
;
}
fn
set_clobbered
(
&
mut
self
clobbered
:
Set
<
Writable
<
RealReg
>
>
)
{
self
.
clobbered
=
clobbered
;
}
fn
load_stackslot
(
&
self
slot
:
StackSlot
offset
:
u32
ty
:
Type
into_regs
:
ValueRegs
<
Writable
<
Reg
>
>
)
-
>
SmallInstVec
<
Self
:
:
I
>
{
let
stack_off
=
self
.
stackslots
[
slot
]
as
i64
;
let
sp_off
:
i64
=
stack_off
+
(
offset
as
i64
)
;
trace
!
(
"
load_stackslot
:
slot
{
}
-
>
sp_off
{
}
"
slot
sp_off
)
;
gen_load_stack_multi
:
:
<
M
>
(
StackAMode
:
:
NominalSPOffset
(
sp_off
ty
)
into_regs
ty
)
}
fn
store_stackslot
(
&
self
slot
:
StackSlot
offset
:
u32
ty
:
Type
from_regs
:
ValueRegs
<
Reg
>
)
-
>
SmallInstVec
<
Self
:
:
I
>
{
let
stack_off
=
self
.
stackslots
[
slot
]
as
i64
;
let
sp_off
:
i64
=
stack_off
+
(
offset
as
i64
)
;
trace
!
(
"
store_stackslot
:
slot
{
}
-
>
sp_off
{
}
"
slot
sp_off
)
;
gen_store_stack_multi
:
:
<
M
>
(
StackAMode
:
:
NominalSPOffset
(
sp_off
ty
)
from_regs
ty
)
}
fn
stackslot_addr
(
&
self
slot
:
StackSlot
offset
:
u32
into_reg
:
Writable
<
Reg
>
)
-
>
Self
:
:
I
{
let
stack_off
=
self
.
stackslots
[
slot
]
as
i64
;
let
sp_off
:
i64
=
stack_off
+
(
offset
as
i64
)
;
M
:
:
gen_get_stack_addr
(
StackAMode
:
:
NominalSPOffset
(
sp_off
I8
)
into_reg
I8
)
}
fn
load_spillslot
(
&
self
slot
:
SpillSlot
ty
:
Type
into_regs
:
ValueRegs
<
Writable
<
Reg
>
>
)
-
>
SmallInstVec
<
Self
:
:
I
>
{
let
islot
=
slot
.
get
(
)
as
i64
;
let
spill_off
=
islot
*
M
:
:
word_bytes
(
)
as
i64
;
let
sp_off
=
self
.
stackslots_size
as
i64
+
spill_off
;
trace
!
(
"
load_spillslot
:
slot
{
:
?
}
-
>
sp_off
{
}
"
slot
sp_off
)
;
gen_load_stack_multi
:
:
<
M
>
(
StackAMode
:
:
NominalSPOffset
(
sp_off
ty
)
into_regs
ty
)
}
fn
store_spillslot
(
&
self
slot
:
SpillSlot
ty
:
Type
from_regs
:
ValueRegs
<
Reg
>
)
-
>
SmallInstVec
<
Self
:
:
I
>
{
let
islot
=
slot
.
get
(
)
as
i64
;
let
spill_off
=
islot
*
M
:
:
word_bytes
(
)
as
i64
;
let
sp_off
=
self
.
stackslots_size
as
i64
+
spill_off
;
trace
!
(
"
store_spillslot
:
slot
{
:
?
}
-
>
sp_off
{
}
"
slot
sp_off
)
;
gen_store_stack_multi
:
:
<
M
>
(
StackAMode
:
:
NominalSPOffset
(
sp_off
ty
)
from_regs
ty
)
}
fn
spillslots_to_stack_map
(
&
self
slots
:
&
[
SpillSlot
]
state
:
&
<
Self
:
:
I
as
MachInstEmit
>
:
:
State
)
-
>
StackMap
{
let
virtual_sp_offset
=
M
:
:
get_virtual_sp_offset_from_state
(
state
)
;
let
nominal_sp_to_fp
=
M
:
:
get_nominal_sp_to_fp
(
state
)
;
assert
!
(
virtual_sp_offset
>
=
0
)
;
trace
!
(
"
spillslots_to_stackmap
:
slots
=
{
:
?
}
state
=
{
:
?
}
"
slots
state
)
;
let
map_size
=
(
virtual_sp_offset
+
nominal_sp_to_fp
)
as
u32
;
let
bytes
=
M
:
:
word_bytes
(
)
;
let
map_words
=
(
map_size
+
bytes
-
1
)
/
bytes
;
let
mut
bits
=
std
:
:
iter
:
:
repeat
(
false
)
.
take
(
map_words
as
usize
)
.
collect
:
:
<
Vec
<
bool
>
>
(
)
;
let
first_spillslot_word
=
(
(
self
.
stackslots_size
+
virtual_sp_offset
as
u32
)
/
bytes
)
as
usize
;
for
&
slot
in
slots
{
let
slot
=
slot
.
get
(
)
as
usize
;
bits
[
first_spillslot_word
+
slot
]
=
true
;
}
StackMap
:
:
from_slice
(
&
bits
[
.
.
]
)
}
fn
gen_prologue
(
&
mut
self
)
-
>
SmallInstVec
<
Self
:
:
I
>
{
let
mut
insts
=
smallvec
!
[
]
;
if
!
self
.
call_conv
.
extends_baldrdash
(
)
{
insts
.
extend
(
M
:
:
gen_prologue_frame_setup
(
&
self
.
flags
)
.
into_iter
(
)
)
;
}
let
bytes
=
M
:
:
word_bytes
(
)
;
let
mut
total_stacksize
=
self
.
stackslots_size
+
bytes
*
self
.
spillslots
.
unwrap
(
)
as
u32
;
if
self
.
call_conv
.
extends_baldrdash
(
)
{
debug_assert
!
(
!
self
.
flags
.
enable_probestack
(
)
"
baldrdash
does
not
expect
cranelift
to
emit
stack
probes
"
)
;
total_stacksize
+
=
self
.
flags
.
baldrdash_prologue_words
(
)
as
u32
*
bytes
;
}
let
mask
=
M
:
:
stack_align
(
self
.
call_conv
)
-
1
;
let
total_stacksize
=
(
total_stacksize
+
mask
)
&
!
mask
;
if
!
self
.
call_conv
.
extends_baldrdash
(
)
{
if
total_stacksize
>
0
|
|
!
self
.
is_leaf
{
if
let
Some
(
(
reg
stack_limit_load
)
)
=
&
self
.
stack_limit
{
insts
.
extend
(
stack_limit_load
.
clone
(
)
)
;
self
.
insert_stack_check
(
*
reg
total_stacksize
&
mut
insts
)
;
}
if
let
Some
(
min_frame
)
=
&
self
.
probestack_min_frame
{
if
total_stacksize
>
=
*
min_frame
{
insts
.
extend
(
M
:
:
gen_probestack
(
total_stacksize
)
)
;
}
}
}
if
total_stacksize
>
0
{
self
.
fixed_frame_storage_size
+
=
total_stacksize
;
}
}
let
(
_
clobber_insts
)
=
M
:
:
gen_clobber_save
(
self
.
call_conv
&
self
.
flags
&
self
.
clobbered
self
.
fixed_frame_storage_size
)
;
insts
.
extend
(
clobber_insts
)
;
self
.
total_frame_size
=
Some
(
total_stacksize
)
;
insts
}
fn
gen_epilogue
(
&
self
)
-
>
SmallInstVec
<
M
:
:
I
>
{
let
mut
insts
=
smallvec
!
[
]
;
insts
.
extend
(
M
:
:
gen_clobber_restore
(
self
.
call_conv
&
self
.
flags
&
self
.
clobbered
self
.
fixed_frame_storage_size
)
)
;
if
!
self
.
call_conv
.
extends_baldrdash
(
)
{
insts
.
extend
(
M
:
:
gen_epilogue_frame_restore
(
&
self
.
flags
)
)
;
insts
.
push
(
M
:
:
gen_ret
(
)
)
;
}
debug
!
(
"
Epilogue
:
{
:
?
}
"
insts
)
;
insts
}
fn
frame_size
(
&
self
)
-
>
u32
{
self
.
total_frame_size
.
expect
(
"
frame
size
not
computed
before
prologue
generation
"
)
}
fn
stack_args_size
(
&
self
)
-
>
u32
{
self
.
sig
.
stack_arg_space
as
u32
}
fn
get_spillslot_size
(
&
self
rc
:
RegClass
ty
:
Type
)
-
>
u32
{
M
:
:
get_number_of_spillslots_for_value
(
rc
ty
)
}
fn
gen_spill
(
&
self
to_slot
:
SpillSlot
from_reg
:
RealReg
ty
:
Option
<
Type
>
)
-
>
Self
:
:
I
{
let
ty
=
ty_from_ty_hint_or_reg_class
:
:
<
M
>
(
from_reg
.
to_reg
(
)
ty
)
;
self
.
store_spillslot
(
to_slot
ty
ValueRegs
:
:
one
(
from_reg
.
to_reg
(
)
)
)
.
into_iter
(
)
.
next
(
)
.
unwrap
(
)
}
fn
gen_reload
(
&
self
to_reg
:
Writable
<
RealReg
>
from_slot
:
SpillSlot
ty
:
Option
<
Type
>
)
-
>
Self
:
:
I
{
let
ty
=
ty_from_ty_hint_or_reg_class
:
:
<
M
>
(
to_reg
.
to_reg
(
)
.
to_reg
(
)
ty
)
;
self
.
load_spillslot
(
from_slot
ty
writable_value_regs
(
ValueRegs
:
:
one
(
to_reg
.
to_reg
(
)
.
to_reg
(
)
)
)
)
.
into_iter
(
)
.
next
(
)
.
unwrap
(
)
}
fn
unwind_info_kind
(
&
self
)
-
>
UnwindInfoKind
{
match
self
.
sig
.
call_conv
{
#
[
cfg
(
feature
=
"
unwind
"
)
]
isa
:
:
CallConv
:
:
Fast
|
isa
:
:
CallConv
:
:
Cold
|
isa
:
:
CallConv
:
:
SystemV
=
>
{
UnwindInfoKind
:
:
SystemV
}
#
[
cfg
(
feature
=
"
unwind
"
)
]
isa
:
:
CallConv
:
:
WindowsFastcall
=
>
UnwindInfoKind
:
:
Windows
_
=
>
UnwindInfoKind
:
:
None
}
}
}
fn
abisig_to_uses_and_defs
<
M
:
ABIMachineSpec
>
(
sig
:
&
ABISig
)
-
>
(
Vec
<
Reg
>
Vec
<
Writable
<
Reg
>
>
)
{
let
mut
uses
=
Vec
:
:
new
(
)
;
for
arg
in
&
sig
.
args
{
if
let
&
ABIArg
:
:
Slots
{
ref
slots
.
.
}
=
arg
{
for
slot
in
slots
{
match
slot
{
&
ABIArgSlot
:
:
Reg
{
reg
.
.
}
=
>
{
uses
.
push
(
reg
.
to_reg
(
)
)
;
}
_
=
>
{
}
}
}
}
}
let
mut
defs
=
M
:
:
get_regs_clobbered_by_call
(
sig
.
call_conv
)
;
for
ret
in
&
sig
.
rets
{
if
let
&
ABIArg
:
:
Slots
{
ref
slots
.
.
}
=
ret
{
for
slot
in
slots
{
match
slot
{
&
ABIArgSlot
:
:
Reg
{
reg
.
.
}
=
>
{
defs
.
push
(
Writable
:
:
from_reg
(
reg
.
to_reg
(
)
)
)
;
}
_
=
>
{
}
}
}
}
}
(
uses
defs
)
}
pub
struct
ABICallerImpl
<
M
:
ABIMachineSpec
>
{
ir_sig
:
ir
:
:
Signature
sig
:
ABISig
uses
:
Vec
<
Reg
>
defs
:
Vec
<
Writable
<
Reg
>
>
dest
:
CallDest
opcode
:
ir
:
:
Opcode
caller_conv
:
isa
:
:
CallConv
flags
:
settings
:
:
Flags
_mach
:
PhantomData
<
M
>
}
#
[
derive
(
Debug
Clone
)
]
pub
enum
CallDest
{
ExtName
(
ir
:
:
ExternalName
RelocDistance
)
Reg
(
Reg
)
}
impl
<
M
:
ABIMachineSpec
>
ABICallerImpl
<
M
>
{
pub
fn
from_func
(
sig
:
&
ir
:
:
Signature
extname
:
&
ir
:
:
ExternalName
dist
:
RelocDistance
caller_conv
:
isa
:
:
CallConv
flags
:
&
settings
:
:
Flags
)
-
>
CodegenResult
<
ABICallerImpl
<
M
>
>
{
let
ir_sig
=
ensure_struct_return_ptr_is_returned
(
sig
)
;
let
sig
=
ABISig
:
:
from_func_sig
:
:
<
M
>
(
&
ir_sig
flags
)
?
;
let
(
uses
defs
)
=
abisig_to_uses_and_defs
:
:
<
M
>
(
&
sig
)
;
Ok
(
ABICallerImpl
{
ir_sig
sig
uses
defs
dest
:
CallDest
:
:
ExtName
(
extname
.
clone
(
)
dist
)
opcode
:
ir
:
:
Opcode
:
:
Call
caller_conv
flags
:
flags
.
clone
(
)
_mach
:
PhantomData
}
)
}
pub
fn
from_ptr
(
sig
:
&
ir
:
:
Signature
ptr
:
Reg
opcode
:
ir
:
:
Opcode
caller_conv
:
isa
:
:
CallConv
flags
:
&
settings
:
:
Flags
)
-
>
CodegenResult
<
ABICallerImpl
<
M
>
>
{
let
ir_sig
=
ensure_struct_return_ptr_is_returned
(
sig
)
;
let
sig
=
ABISig
:
:
from_func_sig
:
:
<
M
>
(
&
ir_sig
flags
)
?
;
let
(
uses
defs
)
=
abisig_to_uses_and_defs
:
:
<
M
>
(
&
sig
)
;
Ok
(
ABICallerImpl
{
ir_sig
sig
uses
defs
dest
:
CallDest
:
:
Reg
(
ptr
)
opcode
caller_conv
flags
:
flags
.
clone
(
)
_mach
:
PhantomData
}
)
}
}
fn
adjust_stack_and_nominal_sp
<
M
:
ABIMachineSpec
C
:
LowerCtx
<
I
=
M
:
:
I
>
>
(
ctx
:
&
mut
C
off
:
i32
is_sub
:
bool
)
{
if
off
=
=
0
{
return
;
}
let
amt
=
if
is_sub
{
-
off
}
else
{
off
}
;
for
inst
in
M
:
:
gen_sp_reg_adjust
(
amt
)
{
ctx
.
emit
(
inst
)
;
}
ctx
.
emit
(
M
:
:
gen_nominal_sp_adj
(
-
amt
)
)
;
}
impl
<
M
:
ABIMachineSpec
>
ABICaller
for
ABICallerImpl
<
M
>
{
type
I
=
M
:
:
I
;
fn
signature
(
&
self
)
-
>
&
ir
:
:
Signature
{
&
self
.
ir_sig
}
fn
num_args
(
&
self
)
-
>
usize
{
if
self
.
sig
.
stack_ret_arg
.
is_some
(
)
{
self
.
sig
.
args
.
len
(
)
-
1
}
else
{
self
.
sig
.
args
.
len
(
)
}
}
fn
emit_stack_pre_adjust
<
C
:
LowerCtx
<
I
=
Self
:
:
I
>
>
(
&
self
ctx
:
&
mut
C
)
{
let
off
=
self
.
sig
.
stack_arg_space
+
self
.
sig
.
stack_ret_space
;
adjust_stack_and_nominal_sp
:
:
<
M
C
>
(
ctx
off
as
i32
true
)
}
fn
emit_stack_post_adjust
<
C
:
LowerCtx
<
I
=
Self
:
:
I
>
>
(
&
self
ctx
:
&
mut
C
)
{
let
off
=
self
.
sig
.
stack_arg_space
+
self
.
sig
.
stack_ret_space
;
adjust_stack_and_nominal_sp
:
:
<
M
C
>
(
ctx
off
as
i32
false
)
}
fn
emit_copy_regs_to_arg
<
C
:
LowerCtx
<
I
=
Self
:
:
I
>
>
(
&
self
ctx
:
&
mut
C
idx
:
usize
from_regs
:
ValueRegs
<
Reg
>
)
{
let
word_rc
=
M
:
:
word_reg_class
(
)
;
let
word_bits
=
M
:
:
word_bits
(
)
as
usize
;
match
&
self
.
sig
.
args
[
idx
]
{
&
ABIArg
:
:
Slots
{
ref
slots
.
.
}
=
>
{
assert_eq
!
(
from_regs
.
len
(
)
slots
.
len
(
)
)
;
for
(
slot
from_reg
)
in
slots
.
iter
(
)
.
zip
(
from_regs
.
regs
(
)
.
iter
(
)
)
{
match
slot
{
&
ABIArgSlot
:
:
Reg
{
reg
ty
extension
.
.
}
=
>
{
let
ext
=
M
:
:
get_ext_mode
(
self
.
sig
.
call_conv
extension
)
;
if
ext
!
=
ir
:
:
ArgumentExtension
:
:
None
&
&
ty_bits
(
ty
)
<
word_bits
{
assert_eq
!
(
word_rc
reg
.
get_class
(
)
)
;
let
signed
=
match
ext
{
ir
:
:
ArgumentExtension
:
:
Uext
=
>
false
ir
:
:
ArgumentExtension
:
:
Sext
=
>
true
_
=
>
unreachable
!
(
)
}
;
ctx
.
emit
(
M
:
:
gen_extend
(
Writable
:
:
from_reg
(
reg
.
to_reg
(
)
)
*
from_reg
signed
ty_bits
(
ty
)
as
u8
word_bits
as
u8
)
)
;
}
else
{
ctx
.
emit
(
M
:
:
gen_move
(
Writable
:
:
from_reg
(
reg
.
to_reg
(
)
)
*
from_reg
ty
)
)
;
}
}
&
ABIArgSlot
:
:
Stack
{
offset
ty
extension
.
.
}
=
>
{
let
mut
ty
=
ty
;
let
ext
=
M
:
:
get_ext_mode
(
self
.
sig
.
call_conv
extension
)
;
if
ext
!
=
ir
:
:
ArgumentExtension
:
:
None
&
&
ty_bits
(
ty
)
<
word_bits
{
assert_eq
!
(
word_rc
from_reg
.
get_class
(
)
)
;
let
signed
=
match
ext
{
ir
:
:
ArgumentExtension
:
:
Uext
=
>
false
ir
:
:
ArgumentExtension
:
:
Sext
=
>
true
_
=
>
unreachable
!
(
)
}
;
ctx
.
emit
(
M
:
:
gen_extend
(
Writable
:
:
from_reg
(
*
from_reg
)
*
from_reg
signed
ty_bits
(
ty
)
as
u8
word_bits
as
u8
)
)
;
ty
=
M
:
:
word_type
(
)
;
}
ctx
.
emit
(
M
:
:
gen_store_stack
(
StackAMode
:
:
SPOffset
(
offset
ty
)
*
from_reg
ty
)
)
;
}
}
}
}
&
ABIArg
:
:
StructArg
{
offset
size
.
.
}
=
>
{
let
src_ptr
=
from_regs
.
only_reg
(
)
.
unwrap
(
)
;
let
dst_ptr
=
ctx
.
alloc_tmp
(
M
:
:
word_type
(
)
)
.
only_reg
(
)
.
unwrap
(
)
;
ctx
.
emit
(
M
:
:
gen_get_stack_addr
(
StackAMode
:
:
SPOffset
(
offset
I8
)
dst_ptr
I8
)
)
;
let
memcpy_call_conv
=
isa
:
:
CallConv
:
:
for_libcall
(
&
self
.
flags
self
.
sig
.
call_conv
)
;
for
insn
in
M
:
:
gen_memcpy
(
memcpy_call_conv
dst_ptr
.
to_reg
(
)
src_ptr
size
as
usize
)
.
into_iter
(
)
{
ctx
.
emit
(
insn
)
;
}
}
}
}
fn
get_copy_to_arg_order
(
&
self
)
-
>
SmallVec
<
[
usize
;
8
]
>
{
let
mut
ret
=
SmallVec
:
:
new
(
)
;
for
(
i
arg
)
in
self
.
sig
.
args
.
iter
(
)
.
enumerate
(
)
{
if
arg
.
is_struct_arg
(
)
{
ret
.
push
(
i
)
;
}
}
for
(
i
arg
)
in
self
.
sig
.
args
.
iter
(
)
.
enumerate
(
)
{
if
!
arg
.
is_struct_arg
(
)
&
&
i
<
self
.
ir_sig
.
params
.
len
(
)
{
ret
.
push
(
i
)
;
}
}
ret
}
fn
emit_copy_retval_to_regs
<
C
:
LowerCtx
<
I
=
Self
:
:
I
>
>
(
&
self
ctx
:
&
mut
C
idx
:
usize
into_regs
:
ValueRegs
<
Writable
<
Reg
>
>
)
{
match
&
self
.
sig
.
rets
[
idx
]
{
&
ABIArg
:
:
Slots
{
ref
slots
.
.
}
=
>
{
assert_eq
!
(
into_regs
.
len
(
)
slots
.
len
(
)
)
;
for
(
slot
into_reg
)
in
slots
.
iter
(
)
.
zip
(
into_regs
.
regs
(
)
.
iter
(
)
)
{
match
slot
{
&
ABIArgSlot
:
:
Reg
{
reg
ty
.
.
}
=
>
{
ctx
.
emit
(
M
:
:
gen_move
(
*
into_reg
reg
.
to_reg
(
)
ty
)
)
;
}
&
ABIArgSlot
:
:
Stack
{
offset
ty
.
.
}
=
>
{
let
ret_area_base
=
self
.
sig
.
stack_arg_space
;
ctx
.
emit
(
M
:
:
gen_load_stack
(
StackAMode
:
:
SPOffset
(
offset
+
ret_area_base
ty
)
*
into_reg
ty
)
)
;
}
}
}
}
&
ABIArg
:
:
StructArg
{
.
.
}
=
>
{
panic
!
(
"
StructArg
not
supported
in
return
position
"
)
;
}
}
}
fn
emit_call
<
C
:
LowerCtx
<
I
=
Self
:
:
I
>
>
(
&
mut
self
ctx
:
&
mut
C
)
{
let
(
uses
defs
)
=
(
mem
:
:
replace
(
&
mut
self
.
uses
Default
:
:
default
(
)
)
mem
:
:
replace
(
&
mut
self
.
defs
Default
:
:
default
(
)
)
)
;
let
word_type
=
M
:
:
word_type
(
)
;
if
let
Some
(
i
)
=
self
.
sig
.
stack_ret_arg
{
let
rd
=
ctx
.
alloc_tmp
(
word_type
)
.
only_reg
(
)
.
unwrap
(
)
;
let
ret_area_base
=
self
.
sig
.
stack_arg_space
;
ctx
.
emit
(
M
:
:
gen_get_stack_addr
(
StackAMode
:
:
SPOffset
(
ret_area_base
I8
)
rd
I8
)
)
;
self
.
emit_copy_regs_to_arg
(
ctx
i
ValueRegs
:
:
one
(
rd
.
to_reg
(
)
)
)
;
}
let
tmp
=
ctx
.
alloc_tmp
(
word_type
)
.
only_reg
(
)
.
unwrap
(
)
;
for
(
is_safepoint
inst
)
in
M
:
:
gen_call
(
&
self
.
dest
uses
defs
self
.
opcode
tmp
self
.
sig
.
call_conv
self
.
caller_conv
)
.
into_iter
(
)
{
match
is_safepoint
{
InstIsSafepoint
:
:
Yes
=
>
ctx
.
emit_safepoint
(
inst
)
InstIsSafepoint
:
:
No
=
>
ctx
.
emit
(
inst
)
}
}
}
}
