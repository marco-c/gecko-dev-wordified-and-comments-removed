use
crate
:
:
entity
:
:
SecondaryMap
;
use
crate
:
:
fx
:
:
{
FxHashMap
FxHashSet
}
;
use
crate
:
:
inst_predicates
:
:
{
has_lowering_side_effect
is_constant_64bit
}
;
use
crate
:
:
ir
:
:
instructions
:
:
BranchInfo
;
use
crate
:
:
ir
:
:
types
:
:
I64
;
use
crate
:
:
ir
:
:
{
ArgumentPurpose
Block
Constant
ConstantData
ExternalName
Function
GlobalValueData
Immediate
Inst
InstructionData
MemFlags
Opcode
Signature
SourceLoc
Type
Value
ValueDef
}
;
use
crate
:
:
machinst
:
:
{
ABIBody
BlockIndex
BlockLoweringOrder
LoweredBlock
MachLabel
VCode
VCodeBuilder
VCodeInst
}
;
use
crate
:
:
CodegenResult
;
use
regalloc
:
:
{
Reg
RegClass
StackmapRequestInfo
VirtualReg
Writable
}
;
use
alloc
:
:
boxed
:
:
Box
;
use
alloc
:
:
vec
:
:
Vec
;
use
log
:
:
debug
;
use
smallvec
:
:
SmallVec
;
#
[
derive
(
Clone
Copy
Debug
PartialEq
Eq
Hash
)
]
pub
struct
InstColor
(
u32
)
;
impl
InstColor
{
fn
new
(
n
:
u32
)
-
>
InstColor
{
InstColor
(
n
)
}
pub
fn
get
(
self
)
-
>
u32
{
self
.
0
}
}
pub
trait
LowerCtx
{
type
I
:
VCodeInst
;
fn
abi
(
&
mut
self
)
-
>
&
dyn
ABIBody
<
I
=
Self
:
:
I
>
;
fn
retval
(
&
self
idx
:
usize
)
-
>
Writable
<
Reg
>
;
fn
get_vm_context
(
&
self
)
-
>
Option
<
Reg
>
;
fn
data
(
&
self
ir_inst
:
Inst
)
-
>
&
InstructionData
;
fn
ty
(
&
self
ir_inst
:
Inst
)
-
>
Type
;
fn
call_target
<
'
b
>
(
&
'
b
self
ir_inst
:
Inst
)
-
>
Option
<
(
&
'
b
ExternalName
RelocDistance
)
>
;
fn
call_sig
<
'
b
>
(
&
'
b
self
ir_inst
:
Inst
)
-
>
Option
<
&
'
b
Signature
>
;
fn
symbol_value
<
'
b
>
(
&
'
b
self
ir_inst
:
Inst
)
-
>
Option
<
(
&
'
b
ExternalName
RelocDistance
i64
)
>
;
fn
memflags
(
&
self
ir_inst
:
Inst
)
-
>
Option
<
MemFlags
>
;
fn
srcloc
(
&
self
ir_inst
:
Inst
)
-
>
SourceLoc
;
fn
inst_color
(
&
self
ir_inst
:
Inst
)
-
>
InstColor
;
fn
num_inputs
(
&
self
ir_inst
:
Inst
)
-
>
usize
;
fn
num_outputs
(
&
self
ir_inst
:
Inst
)
-
>
usize
;
fn
input_ty
(
&
self
ir_inst
:
Inst
idx
:
usize
)
-
>
Type
;
fn
output_ty
(
&
self
ir_inst
:
Inst
idx
:
usize
)
-
>
Type
;
fn
get_constant
(
&
self
ir_inst
:
Inst
)
-
>
Option
<
u64
>
;
fn
get_input
(
&
self
ir_inst
:
Inst
idx
:
usize
)
-
>
LowerInput
;
fn
get_output
(
&
self
ir_inst
:
Inst
idx
:
usize
)
-
>
Writable
<
Reg
>
;
fn
alloc_tmp
(
&
mut
self
rc
:
RegClass
ty
:
Type
)
-
>
Writable
<
Reg
>
;
fn
emit
(
&
mut
self
mach_inst
:
Self
:
:
I
)
;
fn
emit_safepoint
(
&
mut
self
mach_inst
:
Self
:
:
I
)
;
fn
use_input_reg
(
&
mut
self
input
:
LowerInput
)
;
fn
is_reg_needed
(
&
self
ir_inst
:
Inst
reg
:
Reg
)
-
>
bool
;
fn
get_constant_data
(
&
self
constant_handle
:
Constant
)
-
>
&
ConstantData
;
fn
get_immediate
(
&
self
imm
:
Immediate
)
-
>
&
ConstantData
;
fn
ensure_in_vreg
(
&
mut
self
reg
:
Reg
ty
:
Type
)
-
>
Reg
;
}
#
[
derive
(
Clone
Copy
Debug
)
]
pub
struct
LowerInput
{
pub
reg
:
Reg
pub
inst
:
Option
<
(
Inst
usize
)
>
pub
constant
:
Option
<
u64
>
}
pub
trait
LowerBackend
{
type
MInst
:
VCodeInst
;
fn
lower
<
C
:
LowerCtx
<
I
=
Self
:
:
MInst
>
>
(
&
self
ctx
:
&
mut
C
inst
:
Inst
)
-
>
CodegenResult
<
(
)
>
;
fn
lower_branch_group
<
C
:
LowerCtx
<
I
=
Self
:
:
MInst
>
>
(
&
self
ctx
:
&
mut
C
insts
:
&
[
Inst
]
targets
:
&
[
MachLabel
]
fallthrough
:
Option
<
MachLabel
>
)
-
>
CodegenResult
<
(
)
>
;
fn
maybe_pinned_reg
(
&
self
)
-
>
Option
<
Reg
>
{
None
}
}
struct
InstTuple
<
I
:
VCodeInst
>
{
loc
:
SourceLoc
is_safepoint
:
bool
inst
:
I
}
pub
struct
Lower
<
'
func
I
:
VCodeInst
>
{
f
:
&
'
func
Function
vcode
:
VCodeBuilder
<
I
>
value_regs
:
SecondaryMap
<
Value
Reg
>
retval_regs
:
Vec
<
Reg
>
inst_colors
:
SecondaryMap
<
Inst
InstColor
>
inst_constants
:
FxHashMap
<
Inst
u64
>
inst_needed
:
SecondaryMap
<
Inst
bool
>
vreg_needed
:
Vec
<
bool
>
next_vreg
:
u32
block_insts
:
Vec
<
InstTuple
<
I
>
>
block_ranges
:
Vec
<
(
usize
usize
)
>
bb_insts
:
Vec
<
InstTuple
<
I
>
>
ir_insts
:
Vec
<
InstTuple
<
I
>
>
pinned_reg
:
Option
<
Reg
>
vm_context
:
Option
<
Reg
>
}
#
[
derive
(
Clone
Copy
Debug
PartialEq
Eq
)
]
pub
enum
RelocDistance
{
Near
Far
}
fn
alloc_vreg
(
value_regs
:
&
mut
SecondaryMap
<
Value
Reg
>
regclass
:
RegClass
value
:
Value
next_vreg
:
&
mut
u32
)
-
>
VirtualReg
{
if
value_regs
[
value
]
.
is_invalid
(
)
{
let
v
=
*
next_vreg
;
*
next_vreg
+
=
1
;
value_regs
[
value
]
=
Reg
:
:
new_virtual
(
regclass
v
)
;
debug
!
(
"
value
{
}
gets
vreg
{
:
?
}
"
value
v
)
;
}
value_regs
[
value
]
.
as_virtual_reg
(
)
.
unwrap
(
)
}
enum
GenerateReturn
{
Yes
No
}
impl
<
'
func
I
:
VCodeInst
>
Lower
<
'
func
I
>
{
pub
fn
new
(
f
:
&
'
func
Function
abi
:
Box
<
dyn
ABIBody
<
I
=
I
>
>
block_order
:
BlockLoweringOrder
)
-
>
CodegenResult
<
Lower
<
'
func
I
>
>
{
let
mut
vcode
=
VCodeBuilder
:
:
new
(
abi
block_order
)
;
let
mut
next_vreg
:
u32
=
0
;
let
mut
value_regs
=
SecondaryMap
:
:
with_default
(
Reg
:
:
invalid
(
)
)
;
for
bb
in
f
.
layout
.
blocks
(
)
{
for
&
param
in
f
.
dfg
.
block_params
(
bb
)
{
let
ty
=
f
.
dfg
.
value_type
(
param
)
;
let
vreg
=
alloc_vreg
(
&
mut
value_regs
I
:
:
rc_for_type
(
ty
)
?
param
&
mut
next_vreg
)
;
vcode
.
set_vreg_type
(
vreg
ty
)
;
debug
!
(
"
bb
{
}
param
{
}
:
vreg
{
:
?
}
"
bb
param
vreg
)
;
}
for
inst
in
f
.
layout
.
block_insts
(
bb
)
{
for
&
result
in
f
.
dfg
.
inst_results
(
inst
)
{
let
ty
=
f
.
dfg
.
value_type
(
result
)
;
let
vreg
=
alloc_vreg
(
&
mut
value_regs
I
:
:
rc_for_type
(
ty
)
?
result
&
mut
next_vreg
)
;
vcode
.
set_vreg_type
(
vreg
ty
)
;
debug
!
(
"
bb
{
}
inst
{
}
(
{
:
?
}
)
:
result
vreg
{
:
?
}
"
bb
inst
f
.
dfg
[
inst
]
vreg
)
;
}
}
}
let
vm_context
=
f
.
signature
.
special_param_index
(
ArgumentPurpose
:
:
VMContext
)
.
map
(
|
vm_context_index
|
{
let
entry_block
=
f
.
layout
.
entry_block
(
)
.
unwrap
(
)
;
let
param
=
f
.
dfg
.
block_params
(
entry_block
)
[
vm_context_index
]
;
value_regs
[
param
]
}
)
;
let
mut
retval_regs
=
vec
!
[
]
;
for
ret
in
&
f
.
signature
.
returns
{
let
v
=
next_vreg
;
next_vreg
+
=
1
;
let
regclass
=
I
:
:
rc_for_type
(
ret
.
value_type
)
?
;
let
vreg
=
Reg
:
:
new_virtual
(
regclass
v
)
;
retval_regs
.
push
(
vreg
)
;
vcode
.
set_vreg_type
(
vreg
.
as_virtual_reg
(
)
.
unwrap
(
)
ret
.
value_type
)
;
}
let
mut
cur_color
=
0
;
let
mut
inst_colors
=
SecondaryMap
:
:
with_default
(
InstColor
:
:
new
(
0
)
)
;
let
mut
inst_constants
=
FxHashMap
:
:
default
(
)
;
let
mut
inst_needed
=
SecondaryMap
:
:
with_default
(
false
)
;
for
bb
in
f
.
layout
.
blocks
(
)
{
cur_color
+
=
1
;
for
inst
in
f
.
layout
.
block_insts
(
bb
)
{
let
side_effect
=
has_lowering_side_effect
(
f
inst
)
;
inst_colors
[
inst
]
=
InstColor
:
:
new
(
cur_color
)
;
debug
!
(
"
bb
{
}
inst
{
}
has
color
{
}
"
bb
inst
cur_color
)
;
if
side_effect
{
debug
!
(
"
-
>
side
-
effecting
"
)
;
inst_needed
[
inst
]
=
true
;
cur_color
+
=
1
;
}
if
let
Some
(
c
)
=
is_constant_64bit
(
f
inst
)
{
debug
!
(
"
-
>
constant
:
{
}
"
c
)
;
inst_constants
.
insert
(
inst
c
)
;
}
}
}
let
vreg_needed
=
std
:
:
iter
:
:
repeat
(
false
)
.
take
(
next_vreg
as
usize
)
.
collect
(
)
;
Ok
(
Lower
{
f
vcode
value_regs
retval_regs
inst_colors
inst_constants
inst_needed
vreg_needed
next_vreg
block_insts
:
vec
!
[
]
block_ranges
:
vec
!
[
]
bb_insts
:
vec
!
[
]
ir_insts
:
vec
!
[
]
pinned_reg
:
None
vm_context
}
)
}
fn
gen_arg_setup
(
&
mut
self
)
{
if
let
Some
(
entry_bb
)
=
self
.
f
.
layout
.
entry_block
(
)
{
debug
!
(
"
gen_arg_setup
:
entry
BB
{
}
args
are
:
\
n
{
:
?
}
"
entry_bb
self
.
f
.
dfg
.
block_params
(
entry_bb
)
)
;
for
(
i
param
)
in
self
.
f
.
dfg
.
block_params
(
entry_bb
)
.
iter
(
)
.
enumerate
(
)
{
let
reg
=
Writable
:
:
from_reg
(
self
.
value_regs
[
*
param
]
)
;
let
insn
=
self
.
vcode
.
abi
(
)
.
gen_copy_arg_to_reg
(
i
reg
)
;
self
.
emit
(
insn
)
;
}
if
let
Some
(
insn
)
=
self
.
vcode
.
abi
(
)
.
gen_retval_area_setup
(
)
{
self
.
emit
(
insn
)
;
}
}
}
fn
gen_retval_setup
(
&
mut
self
gen_ret_inst
:
GenerateReturn
)
{
let
retval_regs
=
self
.
retval_regs
.
clone
(
)
;
for
(
i
reg
)
in
retval_regs
.
into_iter
(
)
.
enumerate
(
)
{
let
reg
=
Writable
:
:
from_reg
(
reg
)
;
let
insns
=
self
.
vcode
.
abi
(
)
.
gen_copy_reg_to_retval
(
i
reg
)
;
for
insn
in
insns
{
self
.
emit
(
insn
)
;
}
}
let
inst
=
match
gen_ret_inst
{
GenerateReturn
:
:
Yes
=
>
self
.
vcode
.
abi
(
)
.
gen_ret
(
)
GenerateReturn
:
:
No
=
>
self
.
vcode
.
abi
(
)
.
gen_epilogue_placeholder
(
)
}
;
self
.
emit
(
inst
)
;
}
fn
lower_edge
(
&
mut
self
pred
:
Block
inst
:
Inst
succ
:
Block
)
-
>
CodegenResult
<
(
)
>
{
debug
!
(
"
lower_edge
:
pred
{
}
succ
{
}
"
pred
succ
)
;
let
num_args
=
self
.
f
.
dfg
.
block_params
(
succ
)
.
len
(
)
;
debug_assert
!
(
num_args
=
=
self
.
f
.
dfg
.
inst_variable_args
(
inst
)
.
len
(
)
)
;
if
num_args
=
=
0
{
return
Ok
(
(
)
)
;
}
let
mut
const_bundles
=
SmallVec
:
:
<
[
(
Type
Writable
<
Reg
>
u64
)
;
16
]
>
:
:
new
(
)
;
let
mut
var_bundles
=
SmallVec
:
:
<
[
(
Type
Writable
<
Reg
>
Reg
)
;
16
]
>
:
:
new
(
)
;
let
mut
i
=
0
;
for
(
dst_val
src_val
)
in
self
.
f
.
dfg
.
block_params
(
succ
)
.
iter
(
)
.
zip
(
self
.
f
.
dfg
.
inst_variable_args
(
inst
)
.
iter
(
)
)
{
let
src_val
=
self
.
f
.
dfg
.
resolve_aliases
(
*
src_val
)
;
let
ty
=
self
.
f
.
dfg
.
value_type
(
src_val
)
;
debug_assert
!
(
ty
=
=
self
.
f
.
dfg
.
value_type
(
*
dst_val
)
)
;
let
dst_reg
=
self
.
value_regs
[
*
dst_val
]
;
let
input
=
self
.
get_input_for_val
(
inst
src_val
)
;
debug
!
(
"
jump
arg
{
}
is
{
}
reg
{
:
?
}
"
i
src_val
input
.
reg
)
;
i
+
=
1
;
if
let
Some
(
c
)
=
input
.
constant
{
const_bundles
.
push
(
(
ty
Writable
:
:
from_reg
(
dst_reg
)
c
)
)
;
}
else
{
self
.
use_input_reg
(
input
)
;
let
src_reg
=
input
.
reg
;
if
dst_reg
!
=
src_reg
{
var_bundles
.
push
(
(
ty
Writable
:
:
from_reg
(
dst_reg
)
src_reg
)
)
;
}
}
}
let
mut
src_reg_set
=
FxHashSet
:
:
<
Reg
>
:
:
default
(
)
;
for
(
_
_
src_reg
)
in
&
var_bundles
{
src_reg_set
.
insert
(
*
src_reg
)
;
}
let
mut
overlaps
=
false
;
for
(
_
dst_reg
_
)
in
&
var_bundles
{
if
src_reg_set
.
contains
(
&
dst_reg
.
to_reg
(
)
)
{
overlaps
=
true
;
break
;
}
}
if
!
overlaps
{
for
(
ty
dst_reg
src_reg
)
in
&
var_bundles
{
self
.
emit
(
I
:
:
gen_move
(
*
dst_reg
*
src_reg
*
ty
)
)
;
}
}
else
{
let
mut
tmp_regs
=
SmallVec
:
:
<
[
Writable
<
Reg
>
;
16
]
>
:
:
new
(
)
;
for
(
ty
_
_
)
in
&
var_bundles
{
tmp_regs
.
push
(
self
.
alloc_tmp
(
I
:
:
rc_for_type
(
*
ty
)
?
*
ty
)
)
;
}
for
(
(
ty
_
src_reg
)
tmp_reg
)
in
var_bundles
.
iter
(
)
.
zip
(
tmp_regs
.
iter
(
)
)
{
self
.
emit
(
I
:
:
gen_move
(
*
tmp_reg
*
src_reg
*
ty
)
)
;
}
for
(
(
ty
dst_reg
_
)
tmp_reg
)
in
var_bundles
.
iter
(
)
.
zip
(
tmp_regs
.
iter
(
)
)
{
self
.
emit
(
I
:
:
gen_move
(
*
dst_reg
(
*
tmp_reg
)
.
to_reg
(
)
*
ty
)
)
;
}
}
for
(
ty
dst_reg
const_u64
)
in
&
const_bundles
{
for
inst
in
I
:
:
gen_constant
(
*
dst_reg
*
const_u64
*
ty
|
reg_class
ty
|
{
self
.
alloc_tmp
(
reg_class
ty
)
}
)
.
into_iter
(
)
{
self
.
emit
(
inst
)
;
}
}
Ok
(
(
)
)
}
fn
lower_clif_block
<
B
:
LowerBackend
<
MInst
=
I
>
>
(
&
mut
self
backend
:
&
B
block
:
Block
)
-
>
CodegenResult
<
(
)
>
{
for
inst
in
self
.
f
.
layout
.
block_insts
(
block
)
.
rev
(
)
{
let
data
=
&
self
.
f
.
dfg
[
inst
]
;
let
value_needed
=
self
.
f
.
dfg
.
inst_results
(
inst
)
.
iter
(
)
.
any
(
|
&
result
|
self
.
vreg_needed
[
self
.
value_regs
[
result
]
.
get_index
(
)
]
)
;
debug
!
(
"
lower_clif_block
:
block
{
}
inst
{
}
(
{
:
?
}
)
is_branch
{
}
inst_needed
{
}
value_needed
{
}
"
block
inst
data
data
.
opcode
(
)
.
is_branch
(
)
self
.
inst_needed
[
inst
]
value_needed
)
;
if
self
.
f
.
dfg
[
inst
]
.
opcode
(
)
.
is_branch
(
)
{
continue
;
}
if
self
.
inst_needed
[
inst
]
|
|
value_needed
{
debug
!
(
"
lowering
:
inst
{
}
:
{
:
?
}
"
inst
self
.
f
.
dfg
[
inst
]
)
;
backend
.
lower
(
self
inst
)
?
;
}
if
data
.
opcode
(
)
.
is_return
(
)
{
let
gen_ret
=
if
data
.
opcode
(
)
=
=
Opcode
:
:
Return
{
GenerateReturn
:
:
Yes
}
else
{
debug_assert
!
(
data
.
opcode
(
)
=
=
Opcode
:
:
FallthroughReturn
)
;
GenerateReturn
:
:
No
}
;
self
.
gen_retval_setup
(
gen_ret
)
;
}
let
loc
=
self
.
srcloc
(
inst
)
;
self
.
finish_ir_inst
(
loc
)
;
}
Ok
(
(
)
)
}
fn
finish_ir_inst
(
&
mut
self
loc
:
SourceLoc
)
{
for
mut
tuple
in
self
.
ir_insts
.
drain
(
.
.
)
.
rev
(
)
{
tuple
.
loc
=
loc
;
self
.
bb_insts
.
push
(
tuple
)
;
}
}
fn
finish_bb
(
&
mut
self
)
{
let
start
=
self
.
block_insts
.
len
(
)
;
for
tuple
in
self
.
bb_insts
.
drain
(
.
.
)
.
rev
(
)
{
self
.
block_insts
.
push
(
tuple
)
;
}
let
end
=
self
.
block_insts
.
len
(
)
;
self
.
block_ranges
.
push
(
(
start
end
)
)
;
}
fn
copy_bbs_to_vcode
(
&
mut
self
)
{
for
&
(
start
end
)
in
self
.
block_ranges
.
iter
(
)
.
rev
(
)
{
for
&
InstTuple
{
loc
is_safepoint
ref
inst
}
in
&
self
.
block_insts
[
start
.
.
end
]
{
self
.
vcode
.
set_srcloc
(
loc
)
;
self
.
vcode
.
push
(
inst
.
clone
(
)
is_safepoint
)
;
}
self
.
vcode
.
end_bb
(
)
;
}
}
fn
lower_clif_branches
<
B
:
LowerBackend
<
MInst
=
I
>
>
(
&
mut
self
backend
:
&
B
block
:
Block
branches
:
&
SmallVec
<
[
Inst
;
2
]
>
targets
:
&
SmallVec
<
[
MachLabel
;
2
]
>
maybe_fallthrough
:
Option
<
MachLabel
>
)
-
>
CodegenResult
<
(
)
>
{
debug
!
(
"
lower_clif_branches
:
block
{
}
branches
{
:
?
}
targets
{
:
?
}
maybe_fallthrough
{
:
?
}
"
block
branches
targets
maybe_fallthrough
)
;
backend
.
lower_branch_group
(
self
branches
targets
maybe_fallthrough
)
?
;
let
loc
=
self
.
srcloc
(
branches
[
0
]
)
;
self
.
finish_ir_inst
(
loc
)
;
Ok
(
(
)
)
}
fn
collect_branches_and_targets
(
&
self
bindex
:
BlockIndex
_bb
:
Block
branches
:
&
mut
SmallVec
<
[
Inst
;
2
]
>
targets
:
&
mut
SmallVec
<
[
MachLabel
;
2
]
>
)
{
branches
.
clear
(
)
;
targets
.
clear
(
)
;
let
mut
last_inst
=
None
;
for
&
(
inst
succ
)
in
self
.
vcode
.
block_order
(
)
.
succ_indices
(
bindex
)
{
if
last_inst
!
=
Some
(
inst
)
{
branches
.
push
(
inst
)
;
}
else
{
debug_assert
!
(
self
.
f
.
dfg
[
inst
]
.
opcode
(
)
=
=
Opcode
:
:
BrTable
)
;
debug_assert
!
(
branches
.
len
(
)
=
=
1
)
;
}
last_inst
=
Some
(
inst
)
;
targets
.
push
(
MachLabel
:
:
from_block
(
succ
)
)
;
}
}
pub
fn
lower
<
B
:
LowerBackend
<
MInst
=
I
>
>
(
mut
self
backend
:
&
B
)
-
>
CodegenResult
<
(
VCode
<
I
>
StackmapRequestInfo
)
>
{
debug
!
(
"
about
to
lower
function
:
{
:
?
}
"
self
.
f
)
;
let
maybe_tmp
=
if
self
.
vcode
.
abi
(
)
.
temp_needed
(
)
{
Some
(
self
.
alloc_tmp
(
RegClass
:
:
I64
I64
)
)
}
else
{
None
}
;
self
.
vcode
.
abi
(
)
.
init
(
maybe_tmp
)
;
self
.
pinned_reg
=
backend
.
maybe_pinned_reg
(
)
;
self
.
vcode
.
set_entry
(
0
)
;
let
mut
branches
:
SmallVec
<
[
Inst
;
2
]
>
=
SmallVec
:
:
new
(
)
;
let
mut
targets
:
SmallVec
<
[
MachLabel
;
2
]
>
=
SmallVec
:
:
new
(
)
;
let
lowered_order
:
SmallVec
<
[
LoweredBlock
;
64
]
>
=
self
.
vcode
.
block_order
(
)
.
lowered_order
(
)
.
iter
(
)
.
cloned
(
)
.
collect
(
)
;
for
(
bindex
lb
)
in
lowered_order
.
iter
(
)
.
enumerate
(
)
.
rev
(
)
{
let
bindex
=
bindex
as
BlockIndex
;
if
let
Some
(
bb
)
=
lb
.
orig_block
(
)
{
self
.
collect_branches_and_targets
(
bindex
bb
&
mut
branches
&
mut
targets
)
;
if
branches
.
len
(
)
>
0
{
let
maybe_fallthrough
=
if
(
bindex
+
1
)
<
(
lowered_order
.
len
(
)
as
BlockIndex
)
{
Some
(
MachLabel
:
:
from_block
(
bindex
+
1
)
)
}
else
{
None
}
;
self
.
lower_clif_branches
(
backend
bb
&
branches
&
targets
maybe_fallthrough
)
?
;
self
.
finish_ir_inst
(
self
.
srcloc
(
branches
[
0
]
)
)
;
}
}
else
{
let
(
_
succ
)
=
self
.
vcode
.
block_order
(
)
.
succ_indices
(
bindex
)
[
0
]
;
self
.
emit
(
I
:
:
gen_jump
(
MachLabel
:
:
from_block
(
succ
)
)
)
;
self
.
finish_ir_inst
(
SourceLoc
:
:
default
(
)
)
;
}
if
let
Some
(
(
pred
inst
succ
)
)
=
lb
.
out_edge
(
)
{
self
.
lower_edge
(
pred
inst
succ
)
?
;
self
.
finish_ir_inst
(
SourceLoc
:
:
default
(
)
)
;
}
if
let
Some
(
bb
)
=
lb
.
orig_block
(
)
{
self
.
lower_clif_block
(
backend
bb
)
?
;
}
if
let
Some
(
(
pred
inst
succ
)
)
=
lb
.
in_edge
(
)
{
self
.
lower_edge
(
pred
inst
succ
)
?
;
self
.
finish_ir_inst
(
SourceLoc
:
:
default
(
)
)
;
}
if
bindex
=
=
0
{
self
.
gen_arg_setup
(
)
;
self
.
finish_ir_inst
(
SourceLoc
:
:
default
(
)
)
;
}
self
.
finish_bb
(
)
;
}
self
.
copy_bbs_to_vcode
(
)
;
let
(
vcode
stack_map_info
)
=
self
.
vcode
.
build
(
)
;
debug
!
(
"
built
vcode
:
{
:
?
}
"
vcode
)
;
Ok
(
(
vcode
stack_map_info
)
)
}
fn
get_input_for_val
(
&
self
at_inst
:
Inst
val
:
Value
)
-
>
LowerInput
{
debug
!
(
"
get_input_for_val
:
val
{
}
at
inst
{
}
"
val
at_inst
)
;
let
mut
reg
=
self
.
value_regs
[
val
]
;
debug
!
(
"
-
>
reg
{
:
?
}
"
reg
)
;
assert
!
(
reg
.
is_valid
(
)
)
;
let
mut
inst
=
match
self
.
f
.
dfg
.
value_def
(
val
)
{
ValueDef
:
:
Result
(
src_inst
result_idx
)
=
>
{
debug
!
(
"
-
>
src
inst
{
}
"
src_inst
)
;
debug
!
(
"
-
>
has
lowering
side
effect
:
{
}
"
has_lowering_side_effect
(
self
.
f
src_inst
)
)
;
debug
!
(
"
-
>
our
color
is
{
:
?
}
src
inst
is
{
:
?
}
"
self
.
inst_color
(
at_inst
)
self
.
inst_color
(
src_inst
)
)
;
if
!
has_lowering_side_effect
(
self
.
f
src_inst
)
|
|
self
.
inst_color
(
at_inst
)
=
=
self
.
inst_color
(
src_inst
)
{
Some
(
(
src_inst
result_idx
)
)
}
else
{
None
}
}
_
=
>
None
}
;
let
constant
=
inst
.
and_then
(
|
(
inst
_
)
|
self
.
get_constant
(
inst
)
)
;
if
let
Some
(
(
i
_
)
)
=
inst
{
if
self
.
f
.
dfg
[
i
]
.
opcode
(
)
=
=
Opcode
:
:
GetPinnedReg
{
if
let
Some
(
pr
)
=
self
.
pinned_reg
{
reg
=
pr
;
}
inst
=
None
;
}
}
LowerInput
{
reg
inst
constant
}
}
}
impl
<
'
func
I
:
VCodeInst
>
LowerCtx
for
Lower
<
'
func
I
>
{
type
I
=
I
;
fn
abi
(
&
mut
self
)
-
>
&
dyn
ABIBody
<
I
=
I
>
{
self
.
vcode
.
abi
(
)
}
fn
retval
(
&
self
idx
:
usize
)
-
>
Writable
<
Reg
>
{
Writable
:
:
from_reg
(
self
.
retval_regs
[
idx
]
)
}
fn
get_vm_context
(
&
self
)
-
>
Option
<
Reg
>
{
self
.
vm_context
}
fn
data
(
&
self
ir_inst
:
Inst
)
-
>
&
InstructionData
{
&
self
.
f
.
dfg
[
ir_inst
]
}
fn
ty
(
&
self
ir_inst
:
Inst
)
-
>
Type
{
self
.
f
.
dfg
.
ctrl_typevar
(
ir_inst
)
}
fn
call_target
<
'
b
>
(
&
'
b
self
ir_inst
:
Inst
)
-
>
Option
<
(
&
'
b
ExternalName
RelocDistance
)
>
{
match
&
self
.
f
.
dfg
[
ir_inst
]
{
&
InstructionData
:
:
Call
{
func_ref
.
.
}
|
&
InstructionData
:
:
FuncAddr
{
func_ref
.
.
}
=
>
{
let
funcdata
=
&
self
.
f
.
dfg
.
ext_funcs
[
func_ref
]
;
let
dist
=
funcdata
.
reloc_distance
(
)
;
Some
(
(
&
funcdata
.
name
dist
)
)
}
_
=
>
None
}
}
fn
call_sig
<
'
b
>
(
&
'
b
self
ir_inst
:
Inst
)
-
>
Option
<
&
'
b
Signature
>
{
match
&
self
.
f
.
dfg
[
ir_inst
]
{
&
InstructionData
:
:
Call
{
func_ref
.
.
}
=
>
{
let
funcdata
=
&
self
.
f
.
dfg
.
ext_funcs
[
func_ref
]
;
Some
(
&
self
.
f
.
dfg
.
signatures
[
funcdata
.
signature
]
)
}
&
InstructionData
:
:
CallIndirect
{
sig_ref
.
.
}
=
>
Some
(
&
self
.
f
.
dfg
.
signatures
[
sig_ref
]
)
_
=
>
None
}
}
fn
symbol_value
<
'
b
>
(
&
'
b
self
ir_inst
:
Inst
)
-
>
Option
<
(
&
'
b
ExternalName
RelocDistance
i64
)
>
{
match
&
self
.
f
.
dfg
[
ir_inst
]
{
&
InstructionData
:
:
UnaryGlobalValue
{
global_value
.
.
}
=
>
{
let
gvdata
=
&
self
.
f
.
global_values
[
global_value
]
;
match
gvdata
{
&
GlobalValueData
:
:
Symbol
{
ref
name
ref
offset
.
.
}
=
>
{
let
offset
=
offset
.
bits
(
)
;
let
dist
=
gvdata
.
maybe_reloc_distance
(
)
.
unwrap
(
)
;
Some
(
(
name
dist
offset
)
)
}
_
=
>
None
}
}
_
=
>
None
}
}
fn
memflags
(
&
self
ir_inst
:
Inst
)
-
>
Option
<
MemFlags
>
{
match
&
self
.
f
.
dfg
[
ir_inst
]
{
&
InstructionData
:
:
AtomicCas
{
flags
.
.
}
=
>
Some
(
flags
)
&
InstructionData
:
:
AtomicRmw
{
flags
.
.
}
=
>
Some
(
flags
)
&
InstructionData
:
:
Load
{
flags
.
.
}
|
&
InstructionData
:
:
LoadComplex
{
flags
.
.
}
|
&
InstructionData
:
:
LoadNoOffset
{
flags
.
.
}
|
&
InstructionData
:
:
Store
{
flags
.
.
}
|
&
InstructionData
:
:
StoreComplex
{
flags
.
.
}
=
>
Some
(
flags
)
&
InstructionData
:
:
StoreNoOffset
{
flags
.
.
}
=
>
Some
(
flags
)
_
=
>
None
}
}
fn
srcloc
(
&
self
ir_inst
:
Inst
)
-
>
SourceLoc
{
self
.
f
.
srclocs
[
ir_inst
]
}
fn
inst_color
(
&
self
ir_inst
:
Inst
)
-
>
InstColor
{
self
.
inst_colors
[
ir_inst
]
}
fn
num_inputs
(
&
self
ir_inst
:
Inst
)
-
>
usize
{
self
.
f
.
dfg
.
inst_args
(
ir_inst
)
.
len
(
)
}
fn
num_outputs
(
&
self
ir_inst
:
Inst
)
-
>
usize
{
self
.
f
.
dfg
.
inst_results
(
ir_inst
)
.
len
(
)
}
fn
input_ty
(
&
self
ir_inst
:
Inst
idx
:
usize
)
-
>
Type
{
let
val
=
self
.
f
.
dfg
.
inst_args
(
ir_inst
)
[
idx
]
;
let
val
=
self
.
f
.
dfg
.
resolve_aliases
(
val
)
;
self
.
f
.
dfg
.
value_type
(
val
)
}
fn
output_ty
(
&
self
ir_inst
:
Inst
idx
:
usize
)
-
>
Type
{
self
.
f
.
dfg
.
value_type
(
self
.
f
.
dfg
.
inst_results
(
ir_inst
)
[
idx
]
)
}
fn
get_constant
(
&
self
ir_inst
:
Inst
)
-
>
Option
<
u64
>
{
self
.
inst_constants
.
get
(
&
ir_inst
)
.
cloned
(
)
}
fn
get_input
(
&
self
ir_inst
:
Inst
idx
:
usize
)
-
>
LowerInput
{
let
val
=
self
.
f
.
dfg
.
inst_args
(
ir_inst
)
[
idx
]
;
let
val
=
self
.
f
.
dfg
.
resolve_aliases
(
val
)
;
self
.
get_input_for_val
(
ir_inst
val
)
}
fn
get_output
(
&
self
ir_inst
:
Inst
idx
:
usize
)
-
>
Writable
<
Reg
>
{
let
val
=
self
.
f
.
dfg
.
inst_results
(
ir_inst
)
[
idx
]
;
Writable
:
:
from_reg
(
self
.
value_regs
[
val
]
)
}
fn
alloc_tmp
(
&
mut
self
rc
:
RegClass
ty
:
Type
)
-
>
Writable
<
Reg
>
{
let
v
=
self
.
next_vreg
;
self
.
next_vreg
+
=
1
;
let
vreg
=
Reg
:
:
new_virtual
(
rc
v
)
;
self
.
vcode
.
set_vreg_type
(
vreg
.
as_virtual_reg
(
)
.
unwrap
(
)
ty
)
;
Writable
:
:
from_reg
(
vreg
)
}
fn
emit
(
&
mut
self
mach_inst
:
I
)
{
self
.
ir_insts
.
push
(
InstTuple
{
loc
:
SourceLoc
:
:
default
(
)
is_safepoint
:
false
inst
:
mach_inst
}
)
;
}
fn
emit_safepoint
(
&
mut
self
mach_inst
:
I
)
{
self
.
ir_insts
.
push
(
InstTuple
{
loc
:
SourceLoc
:
:
default
(
)
is_safepoint
:
true
inst
:
mach_inst
}
)
;
}
fn
use_input_reg
(
&
mut
self
input
:
LowerInput
)
{
debug
!
(
"
use_input_reg
:
vreg
{
:
?
}
is
needed
"
input
.
reg
)
;
if
input
.
reg
.
is_virtual
(
)
{
self
.
vreg_needed
[
input
.
reg
.
get_index
(
)
]
=
true
;
}
}
fn
is_reg_needed
(
&
self
ir_inst
:
Inst
reg
:
Reg
)
-
>
bool
{
self
.
inst_needed
[
ir_inst
]
|
|
self
.
vreg_needed
[
reg
.
get_index
(
)
]
}
fn
get_constant_data
(
&
self
constant_handle
:
Constant
)
-
>
&
ConstantData
{
self
.
f
.
dfg
.
constants
.
get
(
constant_handle
)
}
fn
get_immediate
(
&
self
imm
:
Immediate
)
-
>
&
ConstantData
{
self
.
f
.
dfg
.
immediates
.
get
(
imm
)
.
unwrap
(
)
}
fn
ensure_in_vreg
(
&
mut
self
reg
:
Reg
ty
:
Type
)
-
>
Reg
{
if
reg
.
is_virtual
(
)
{
reg
}
else
{
let
rc
=
reg
.
get_class
(
)
;
let
new_reg
=
self
.
alloc_tmp
(
rc
ty
)
;
self
.
emit
(
I
:
:
gen_move
(
new_reg
reg
ty
)
)
;
new_reg
.
to_reg
(
)
}
}
}
pub
(
crate
)
fn
visit_block_succs
<
F
:
FnMut
(
Inst
Block
)
>
(
f
:
&
Function
block
:
Block
mut
visit
:
F
)
{
for
inst
in
f
.
layout
.
block_likely_branches
(
block
)
{
if
f
.
dfg
[
inst
]
.
opcode
(
)
.
is_branch
(
)
{
visit_branch_targets
(
f
block
inst
&
mut
visit
)
;
}
}
}
fn
visit_branch_targets
<
F
:
FnMut
(
Inst
Block
)
>
(
f
:
&
Function
block
:
Block
inst
:
Inst
visit
:
&
mut
F
)
{
if
f
.
dfg
[
inst
]
.
opcode
(
)
=
=
Opcode
:
:
Fallthrough
{
visit
(
inst
f
.
layout
.
next_block
(
block
)
.
unwrap
(
)
)
;
}
else
{
match
f
.
dfg
[
inst
]
.
analyze_branch
(
&
f
.
dfg
.
value_lists
)
{
BranchInfo
:
:
NotABranch
=
>
{
}
BranchInfo
:
:
SingleDest
(
dest
_
)
=
>
{
visit
(
inst
dest
)
;
}
BranchInfo
:
:
Table
(
table
maybe_dest
)
=
>
{
if
let
Some
(
dest
)
=
maybe_dest
{
visit
(
inst
dest
)
;
}
for
&
dest
in
f
.
jump_tables
[
table
]
.
as_slice
(
)
{
visit
(
inst
dest
)
;
}
}
}
}
}
