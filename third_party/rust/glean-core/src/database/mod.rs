use
std
:
:
collections
:
:
btree_map
:
:
Entry
;
use
std
:
:
collections
:
:
BTreeMap
;
use
std
:
:
fs
;
use
std
:
:
num
:
:
NonZeroU64
;
use
std
:
:
path
:
:
Path
;
use
std
:
:
str
;
use
std
:
:
sync
:
:
RwLock
;
use
rkv
:
:
StoreOptions
;
#
[
cfg
(
not
(
feature
=
"
rkv
-
safe
-
mode
"
)
)
]
mod
backend
{
use
std
:
:
path
:
:
Path
;
/
/
/
cbindgen
:
ignore
pub
type
Rkv
=
rkv
:
:
Rkv
<
rkv
:
:
backend
:
:
LmdbEnvironment
>
;
/
/
/
cbindgen
:
ignore
pub
type
SingleStore
=
rkv
:
:
SingleStore
<
rkv
:
:
backend
:
:
LmdbDatabase
>
;
/
/
/
cbindgen
:
ignore
pub
type
Writer
<
'
t
>
=
rkv
:
:
Writer
<
rkv
:
:
backend
:
:
LmdbRwTransaction
<
'
t
>
>
;
pub
fn
rkv_new
(
path
:
&
Path
)
-
>
Result
<
Rkv
rkv
:
:
StoreError
>
{
Rkv
:
:
new
:
:
<
rkv
:
:
backend
:
:
Lmdb
>
(
path
)
}
pub
fn
migrate
(
_path
:
&
Path
_dst_env
:
&
Rkv
)
{
}
}
#
[
cfg
(
feature
=
"
rkv
-
safe
-
mode
"
)
]
mod
backend
{
use
rkv
:
:
migrator
:
:
Migrator
;
use
std
:
:
{
fs
path
:
:
Path
}
;
/
/
/
cbindgen
:
ignore
pub
type
Rkv
=
rkv
:
:
Rkv
<
rkv
:
:
backend
:
:
SafeModeEnvironment
>
;
/
/
/
cbindgen
:
ignore
pub
type
SingleStore
=
rkv
:
:
SingleStore
<
rkv
:
:
backend
:
:
SafeModeDatabase
>
;
/
/
/
cbindgen
:
ignore
pub
type
Writer
<
'
t
>
=
rkv
:
:
Writer
<
rkv
:
:
backend
:
:
SafeModeRwTransaction
<
'
t
>
>
;
pub
fn
rkv_new
(
path
:
&
Path
)
-
>
Result
<
Rkv
rkv
:
:
StoreError
>
{
match
Rkv
:
:
new
:
:
<
rkv
:
:
backend
:
:
SafeMode
>
(
path
)
{
Err
(
rkv
:
:
StoreError
:
:
FileInvalid
)
=
>
{
let
safebin
=
path
.
join
(
"
data
.
safe
.
bin
"
)
;
fs
:
:
remove_file
(
safebin
)
.
map_err
(
|
_
|
rkv
:
:
StoreError
:
:
FileInvalid
)
?
;
Rkv
:
:
new
:
:
<
rkv
:
:
backend
:
:
SafeMode
>
(
path
)
}
other
=
>
other
}
}
fn
delete_and_log
(
path
:
&
Path
msg
:
&
str
)
{
if
let
Err
(
err
)
=
fs
:
:
remove_file
(
path
)
{
match
err
.
kind
(
)
{
std
:
:
io
:
:
ErrorKind
:
:
NotFound
=
>
{
}
_
=
>
log
:
:
warn
!
(
"
{
}
"
msg
)
}
}
}
fn
delete_lmdb_database
(
path
:
&
Path
)
{
let
datamdb
=
path
.
join
(
"
data
.
mdb
"
)
;
delete_and_log
(
&
datamdb
"
Failed
to
delete
old
data
.
"
)
;
let
lockmdb
=
path
.
join
(
"
lock
.
mdb
"
)
;
delete_and_log
(
&
lockmdb
"
Failed
to
delete
old
lock
.
"
)
;
}
pub
fn
migrate
(
path
:
&
Path
dst_env
:
&
Rkv
)
{
use
rkv
:
:
{
MigrateError
StoreError
}
;
log
:
:
debug
!
(
"
Migrating
files
in
{
}
"
path
.
display
(
)
)
;
let
datamdb
=
path
.
join
(
"
data
.
mdb
"
)
;
if
!
datamdb
.
exists
(
)
{
log
:
:
debug
!
(
"
No
data
to
migrate
.
"
)
;
return
;
}
let
should_delete
=
match
Migrator
:
:
open_and_migrate_lmdb_to_safe_mode
(
path
|
builder
|
builder
dst_env
)
{
Err
(
MigrateError
:
:
StoreError
(
StoreError
:
:
FileInvalid
)
)
=
>
true
Err
(
MigrateError
:
:
StoreError
(
StoreError
:
:
DatabaseCorrupted
)
)
=
>
true
Err
(
MigrateError
:
:
StoreError
(
StoreError
:
:
IoError
(
_
)
)
)
=
>
true
Err
(
MigrateError
:
:
StoreError
(
StoreError
:
:
UnsuitableEnvironmentPath
(
_
)
)
)
=
>
true
Err
(
MigrateError
:
:
SourceEmpty
)
=
>
true
Err
(
MigrateError
:
:
DestinationNotEmpty
)
=
>
{
log
:
:
warn
!
(
"
Failed
to
migrate
old
data
.
Destination
was
not
empty
"
)
;
true
}
Err
(
MigrateError
:
:
ManagerPoisonError
)
=
>
false
Err
(
MigrateError
:
:
CloseError
(
_
)
)
=
>
false
Err
(
MigrateError
:
:
StoreError
(
_
)
)
=
>
false
Ok
(
(
)
)
=
>
false
}
;
if
should_delete
{
log
:
:
debug
!
(
"
Need
to
delete
remaining
LMDB
files
.
"
)
;
delete_lmdb_database
(
path
)
;
}
log
:
:
debug
!
(
"
Migration
ended
.
Safe
-
mode
database
in
{
}
"
path
.
display
(
)
)
;
}
}
use
crate
:
:
metrics
:
:
Metric
;
use
crate
:
:
CommonMetricData
;
use
crate
:
:
Glean
;
use
crate
:
:
Lifetime
;
use
crate
:
:
Result
;
use
backend
:
:
*
;
pub
struct
Database
{
rkv
:
Rkv
user_store
:
SingleStore
ping_store
:
SingleStore
application_store
:
SingleStore
ping_lifetime_data
:
Option
<
RwLock
<
BTreeMap
<
String
Metric
>
>
>
file_size
:
Option
<
NonZeroU64
>
}
impl
std
:
:
fmt
:
:
Debug
for
Database
{
fn
fmt
(
&
self
fmt
:
&
mut
std
:
:
fmt
:
:
Formatter
)
-
>
std
:
:
fmt
:
:
Result
{
fmt
.
debug_struct
(
"
Database
"
)
.
field
(
"
rkv
"
&
self
.
rkv
)
.
field
(
"
user_store
"
&
"
SingleStore
"
)
.
field
(
"
ping_store
"
&
"
SingleStore
"
)
.
field
(
"
application_store
"
&
"
SingleStore
"
)
.
field
(
"
ping_lifetime_data
"
&
self
.
ping_lifetime_data
)
.
finish
(
)
}
}
fn
database_size
(
dir
:
&
Path
)
-
>
Option
<
NonZeroU64
>
{
let
mut
total_size
=
0
;
if
let
Ok
(
entries
)
=
fs
:
:
read_dir
(
dir
)
{
for
entry
in
entries
.
flatten
(
)
{
if
let
Ok
(
file_type
)
=
entry
.
file_type
(
)
{
if
file_type
.
is_file
(
)
{
let
path
=
entry
.
path
(
)
;
if
let
Ok
(
metadata
)
=
fs
:
:
metadata
(
path
)
{
total_size
+
=
metadata
.
len
(
)
;
}
else
{
continue
;
}
}
}
}
}
NonZeroU64
:
:
new
(
total_size
)
}
impl
Database
{
pub
fn
new
(
data_path
:
&
Path
delay_ping_lifetime_io
:
bool
)
-
>
Result
<
Self
>
{
#
[
cfg
(
all
(
windows
not
(
feature
=
"
rkv
-
safe
-
mode
"
)
)
)
]
{
if
data_path
.
to_str
(
)
.
is_none
(
)
{
return
Err
(
crate
:
:
Error
:
:
utf8_error
(
)
)
;
}
}
let
path
=
data_path
.
join
(
"
db
"
)
;
log
:
:
debug
!
(
"
Database
path
:
{
:
?
}
"
path
.
display
(
)
)
;
let
file_size
=
database_size
(
&
path
)
;
let
rkv
=
Self
:
:
open_rkv
(
&
path
)
?
;
let
user_store
=
rkv
.
open_single
(
Lifetime
:
:
User
.
as_str
(
)
StoreOptions
:
:
create
(
)
)
?
;
let
ping_store
=
rkv
.
open_single
(
Lifetime
:
:
Ping
.
as_str
(
)
StoreOptions
:
:
create
(
)
)
?
;
let
application_store
=
rkv
.
open_single
(
Lifetime
:
:
Application
.
as_str
(
)
StoreOptions
:
:
create
(
)
)
?
;
let
ping_lifetime_data
=
if
delay_ping_lifetime_io
{
Some
(
RwLock
:
:
new
(
BTreeMap
:
:
new
(
)
)
)
}
else
{
None
}
;
let
db
=
Self
{
rkv
user_store
ping_store
application_store
ping_lifetime_data
file_size
}
;
db
.
load_ping_lifetime_data
(
)
;
Ok
(
db
)
}
pub
fn
file_size
(
&
self
)
-
>
Option
<
NonZeroU64
>
{
self
.
file_size
}
fn
get_store
(
&
self
lifetime
:
Lifetime
)
-
>
&
SingleStore
{
match
lifetime
{
Lifetime
:
:
User
=
>
&
self
.
user_store
Lifetime
:
:
Ping
=
>
&
self
.
ping_store
Lifetime
:
:
Application
=
>
&
self
.
application_store
}
}
fn
open_rkv
(
path
:
&
Path
)
-
>
Result
<
Rkv
>
{
fs
:
:
create_dir_all
(
&
path
)
?
;
let
rkv
=
rkv_new
(
path
)
?
;
migrate
(
path
&
rkv
)
;
log
:
:
info
!
(
"
Database
initialized
"
)
;
Ok
(
rkv
)
}
fn
get_storage_key
(
storage_name
:
&
str
metric_key
:
Option
<
&
str
>
)
-
>
String
{
match
metric_key
{
Some
(
k
)
=
>
format
!
(
"
{
}
#
{
}
"
storage_name
k
)
None
=
>
format
!
(
"
{
}
#
"
storage_name
)
}
}
fn
load_ping_lifetime_data
(
&
self
)
{
if
let
Some
(
ping_lifetime_data
)
=
&
self
.
ping_lifetime_data
{
let
mut
data
=
ping_lifetime_data
.
write
(
)
.
expect
(
"
Can
'
t
read
ping
lifetime
data
"
)
;
let
reader
=
unwrap_or
!
(
self
.
rkv
.
read
(
)
return
)
;
let
store
=
self
.
get_store
(
Lifetime
:
:
Ping
)
;
let
mut
iter
=
unwrap_or
!
(
store
.
iter_start
(
&
reader
)
return
)
;
while
let
Some
(
Ok
(
(
metric_id
value
)
)
)
=
iter
.
next
(
)
{
let
metric_id
=
match
str
:
:
from_utf8
(
metric_id
)
{
Ok
(
metric_id
)
=
>
metric_id
.
to_string
(
)
_
=
>
continue
}
;
let
metric
:
Metric
=
match
value
{
rkv
:
:
Value
:
:
Blob
(
blob
)
=
>
unwrap_or
!
(
bincode
:
:
deserialize
(
blob
)
continue
)
_
=
>
continue
}
;
data
.
insert
(
metric_id
metric
)
;
}
}
}
pub
fn
iter_store_from
<
F
>
(
&
self
lifetime
:
Lifetime
storage_name
:
&
str
metric_key
:
Option
<
&
str
>
mut
transaction_fn
:
F
)
where
F
:
FnMut
(
&
[
u8
]
&
Metric
)
{
let
iter_start
=
Self
:
:
get_storage_key
(
storage_name
metric_key
)
;
let
len
=
iter_start
.
len
(
)
;
if
lifetime
=
=
Lifetime
:
:
Ping
{
if
let
Some
(
ping_lifetime_data
)
=
&
self
.
ping_lifetime_data
{
let
data
=
ping_lifetime_data
.
read
(
)
.
expect
(
"
Can
'
t
read
ping
lifetime
data
"
)
;
for
(
key
value
)
in
data
.
iter
(
)
{
if
key
.
starts_with
(
&
iter_start
)
{
let
key
=
&
key
[
len
.
.
]
;
transaction_fn
(
key
.
as_bytes
(
)
value
)
;
}
}
return
;
}
}
let
reader
=
unwrap_or
!
(
self
.
rkv
.
read
(
)
return
)
;
let
mut
iter
=
unwrap_or
!
(
self
.
get_store
(
lifetime
)
.
iter_from
(
&
reader
&
iter_start
)
return
)
;
while
let
Some
(
Ok
(
(
metric_id
value
)
)
)
=
iter
.
next
(
)
{
if
!
metric_id
.
starts_with
(
iter_start
.
as_bytes
(
)
)
{
break
;
}
let
metric_id
=
&
metric_id
[
len
.
.
]
;
let
metric
:
Metric
=
match
value
{
rkv
:
:
Value
:
:
Blob
(
blob
)
=
>
unwrap_or
!
(
bincode
:
:
deserialize
(
blob
)
continue
)
_
=
>
continue
}
;
transaction_fn
(
metric_id
&
metric
)
;
}
}
pub
fn
has_metric
(
&
self
lifetime
:
Lifetime
storage_name
:
&
str
metric_identifier
:
&
str
)
-
>
bool
{
let
key
=
Self
:
:
get_storage_key
(
storage_name
Some
(
metric_identifier
)
)
;
if
lifetime
=
=
Lifetime
:
:
Ping
{
if
let
Some
(
ping_lifetime_data
)
=
&
self
.
ping_lifetime_data
{
return
ping_lifetime_data
.
read
(
)
.
map
(
|
data
|
data
.
contains_key
(
&
key
)
)
.
unwrap_or
(
false
)
;
}
}
let
reader
=
unwrap_or
!
(
self
.
rkv
.
read
(
)
return
false
)
;
self
.
get_store
(
lifetime
)
.
get
(
&
reader
&
key
)
.
unwrap_or
(
None
)
.
is_some
(
)
}
fn
write_with_store
<
F
>
(
&
self
store_name
:
Lifetime
mut
transaction_fn
:
F
)
-
>
Result
<
(
)
>
where
F
:
FnMut
(
Writer
&
SingleStore
)
-
>
Result
<
(
)
>
{
let
writer
=
self
.
rkv
.
write
(
)
.
unwrap
(
)
;
let
store
=
self
.
get_store
(
store_name
)
;
transaction_fn
(
writer
store
)
}
pub
fn
record
(
&
self
glean
:
&
Glean
data
:
&
CommonMetricData
value
:
&
Metric
)
{
if
!
glean
.
is_upload_enabled
(
)
{
return
;
}
let
name
=
data
.
identifier
(
glean
)
;
for
ping_name
in
data
.
storage_names
(
)
{
if
let
Err
(
e
)
=
self
.
record_per_lifetime
(
data
.
lifetime
ping_name
&
name
value
)
{
log
:
:
error
!
(
"
Failed
to
record
metric
into
{
}
:
{
:
?
}
"
ping_name
e
)
;
}
}
}
fn
record_per_lifetime
(
&
self
lifetime
:
Lifetime
storage_name
:
&
str
key
:
&
str
metric
:
&
Metric
)
-
>
Result
<
(
)
>
{
let
final_key
=
Self
:
:
get_storage_key
(
storage_name
Some
(
key
)
)
;
if
lifetime
=
=
Lifetime
:
:
Ping
{
if
let
Some
(
ping_lifetime_data
)
=
&
self
.
ping_lifetime_data
{
let
mut
data
=
ping_lifetime_data
.
write
(
)
.
expect
(
"
Can
'
t
read
ping
lifetime
data
"
)
;
data
.
insert
(
final_key
metric
.
clone
(
)
)
;
return
Ok
(
(
)
)
;
}
}
let
encoded
=
bincode
:
:
serialize
(
&
metric
)
.
expect
(
"
IMPOSSIBLE
:
Serializing
metric
failed
"
)
;
let
value
=
rkv
:
:
Value
:
:
Blob
(
&
encoded
)
;
let
mut
writer
=
self
.
rkv
.
write
(
)
?
;
self
.
get_store
(
lifetime
)
.
put
(
&
mut
writer
final_key
&
value
)
?
;
writer
.
commit
(
)
?
;
Ok
(
(
)
)
}
pub
fn
record_with
<
F
>
(
&
self
glean
:
&
Glean
data
:
&
CommonMetricData
mut
transform
:
F
)
where
F
:
FnMut
(
Option
<
Metric
>
)
-
>
Metric
{
if
!
glean
.
is_upload_enabled
(
)
{
return
;
}
let
name
=
data
.
identifier
(
glean
)
;
for
ping_name
in
data
.
storage_names
(
)
{
if
let
Err
(
e
)
=
self
.
record_per_lifetime_with
(
data
.
lifetime
ping_name
&
name
&
mut
transform
)
{
log
:
:
error
!
(
"
Failed
to
record
metric
into
{
}
:
{
:
?
}
"
ping_name
e
)
;
}
}
}
fn
record_per_lifetime_with
<
F
>
(
&
self
lifetime
:
Lifetime
storage_name
:
&
str
key
:
&
str
mut
transform
:
F
)
-
>
Result
<
(
)
>
where
F
:
FnMut
(
Option
<
Metric
>
)
-
>
Metric
{
let
final_key
=
Self
:
:
get_storage_key
(
storage_name
Some
(
key
)
)
;
if
lifetime
=
=
Lifetime
:
:
Ping
{
if
let
Some
(
ping_lifetime_data
)
=
&
self
.
ping_lifetime_data
{
let
mut
data
=
ping_lifetime_data
.
write
(
)
.
expect
(
"
Can
'
t
access
ping
lifetime
data
as
writable
"
)
;
let
entry
=
data
.
entry
(
final_key
)
;
match
entry
{
Entry
:
:
Vacant
(
entry
)
=
>
{
entry
.
insert
(
transform
(
None
)
)
;
}
Entry
:
:
Occupied
(
mut
entry
)
=
>
{
let
old_value
=
entry
.
get
(
)
.
clone
(
)
;
entry
.
insert
(
transform
(
Some
(
old_value
)
)
)
;
}
}
return
Ok
(
(
)
)
;
}
}
let
mut
writer
=
self
.
rkv
.
write
(
)
?
;
let
store
=
self
.
get_store
(
lifetime
)
;
let
new_value
:
Metric
=
{
let
old_value
=
store
.
get
(
&
writer
&
final_key
)
?
;
match
old_value
{
Some
(
rkv
:
:
Value
:
:
Blob
(
blob
)
)
=
>
{
let
old_value
=
bincode
:
:
deserialize
(
blob
)
.
ok
(
)
;
transform
(
old_value
)
}
_
=
>
transform
(
None
)
}
}
;
let
encoded
=
bincode
:
:
serialize
(
&
new_value
)
.
expect
(
"
IMPOSSIBLE
:
Serializing
metric
failed
"
)
;
let
value
=
rkv
:
:
Value
:
:
Blob
(
&
encoded
)
;
store
.
put
(
&
mut
writer
final_key
&
value
)
?
;
writer
.
commit
(
)
?
;
Ok
(
(
)
)
}
pub
fn
clear_ping_lifetime_storage
(
&
self
storage_name
:
&
str
)
-
>
Result
<
(
)
>
{
if
let
Some
(
ping_lifetime_data
)
=
&
self
.
ping_lifetime_data
{
ping_lifetime_data
.
write
(
)
.
expect
(
"
Can
'
t
access
ping
lifetime
data
as
writable
"
)
.
retain
(
|
metric_id
_
|
!
metric_id
.
starts_with
(
storage_name
)
)
;
}
self
.
write_with_store
(
Lifetime
:
:
Ping
|
mut
writer
store
|
{
let
mut
metrics
=
Vec
:
:
new
(
)
;
{
let
mut
iter
=
store
.
iter_from
(
&
writer
&
storage_name
)
?
;
while
let
Some
(
Ok
(
(
metric_id
_
)
)
)
=
iter
.
next
(
)
{
if
let
Ok
(
metric_id
)
=
std
:
:
str
:
:
from_utf8
(
metric_id
)
{
if
!
metric_id
.
starts_with
(
&
storage_name
)
{
break
;
}
metrics
.
push
(
metric_id
.
to_owned
(
)
)
;
}
}
}
let
mut
res
=
Ok
(
(
)
)
;
for
to_delete
in
metrics
{
if
let
Err
(
e
)
=
store
.
delete
(
&
mut
writer
to_delete
)
{
log
:
:
warn
!
(
"
Can
'
t
delete
from
store
:
{
:
?
}
"
e
)
;
res
=
Err
(
e
)
;
}
}
writer
.
commit
(
)
?
;
Ok
(
res
?
)
}
)
}
pub
fn
remove_single_metric
(
&
self
lifetime
:
Lifetime
storage_name
:
&
str
metric_id
:
&
str
)
-
>
Result
<
(
)
>
{
let
final_key
=
Self
:
:
get_storage_key
(
storage_name
Some
(
metric_id
)
)
;
if
lifetime
=
=
Lifetime
:
:
Ping
{
if
let
Some
(
ping_lifetime_data
)
=
&
self
.
ping_lifetime_data
{
let
mut
data
=
ping_lifetime_data
.
write
(
)
.
expect
(
"
Can
'
t
access
app
lifetime
data
as
writable
"
)
;
data
.
remove
(
&
final_key
)
;
}
}
self
.
write_with_store
(
lifetime
|
mut
writer
store
|
{
if
let
Err
(
e
)
=
store
.
delete
(
&
mut
writer
final_key
.
clone
(
)
)
{
if
self
.
ping_lifetime_data
.
is_some
(
)
{
return
Ok
(
(
)
)
;
}
return
Err
(
e
.
into
(
)
)
;
}
writer
.
commit
(
)
?
;
Ok
(
(
)
)
}
)
}
pub
fn
clear_lifetime
(
&
self
lifetime
:
Lifetime
)
{
let
res
=
self
.
write_with_store
(
lifetime
|
mut
writer
store
|
{
store
.
clear
(
&
mut
writer
)
?
;
writer
.
commit
(
)
?
;
Ok
(
(
)
)
}
)
;
if
let
Err
(
e
)
=
res
{
log
:
:
warn
!
(
"
Could
not
clear
store
for
lifetime
{
:
?
}
:
{
:
?
}
"
lifetime
e
)
;
}
}
pub
fn
clear_all
(
&
self
)
{
if
let
Some
(
ping_lifetime_data
)
=
&
self
.
ping_lifetime_data
{
ping_lifetime_data
.
write
(
)
.
expect
(
"
Can
'
t
access
ping
lifetime
data
as
writable
"
)
.
clear
(
)
;
}
for
lifetime
in
[
Lifetime
:
:
User
Lifetime
:
:
Ping
Lifetime
:
:
Application
]
.
iter
(
)
{
self
.
clear_lifetime
(
*
lifetime
)
;
}
}
pub
fn
persist_ping_lifetime_data
(
&
self
)
-
>
Result
<
(
)
>
{
if
let
Some
(
ping_lifetime_data
)
=
&
self
.
ping_lifetime_data
{
let
data
=
ping_lifetime_data
.
read
(
)
.
expect
(
"
Can
'
t
read
ping
lifetime
data
"
)
;
self
.
write_with_store
(
Lifetime
:
:
Ping
|
mut
writer
store
|
{
for
(
key
value
)
in
data
.
iter
(
)
{
let
encoded
=
bincode
:
:
serialize
(
&
value
)
.
expect
(
"
IMPOSSIBLE
:
Serializing
metric
failed
"
)
;
store
.
put
(
&
mut
writer
&
key
&
rkv
:
:
Value
:
:
Blob
(
&
encoded
)
)
?
;
}
writer
.
commit
(
)
?
;
Ok
(
(
)
)
}
)
?
;
}
Ok
(
(
)
)
}
}
#
[
cfg
(
test
)
]
mod
test
{
use
super
:
:
*
;
use
crate
:
:
tests
:
:
new_glean
;
use
crate
:
:
CommonMetricData
;
use
std
:
:
collections
:
:
HashMap
;
use
std
:
:
path
:
:
Path
;
use
tempfile
:
:
tempdir
;
#
[
test
]
fn
test_panicks_if_fails_dir_creation
(
)
{
let
path
=
Path
:
:
new
(
"
/
!
#
\
"
'
#
"
)
;
assert
!
(
Database
:
:
new
(
path
false
)
.
is_err
(
)
)
;
}
#
[
test
]
#
[
cfg
(
windows
)
]
fn
windows_invalid_utf16_panicfree
(
)
{
use
std
:
:
ffi
:
:
OsString
;
use
std
:
:
os
:
:
windows
:
:
prelude
:
:
*
;
let
source
=
[
0x0066
0x006f
0xD800
0x006f
]
;
let
os_string
=
OsString
:
:
from_wide
(
&
source
[
.
.
]
)
;
let
os_str
=
os_string
.
as_os_str
(
)
;
let
dir
=
tempdir
(
)
.
unwrap
(
)
;
let
path
=
dir
.
path
(
)
.
join
(
os_str
)
;
let
res
=
Database
:
:
new
(
&
path
false
)
;
#
[
cfg
(
feature
=
"
rkv
-
safe
-
mode
"
)
]
{
assert
!
(
res
.
is_ok
(
)
"
Database
should
succeed
at
{
}
:
{
:
?
}
"
path
.
display
(
)
res
)
;
}
#
[
cfg
(
not
(
feature
=
"
rkv
-
safe
-
mode
"
)
)
]
{
assert
!
(
res
.
is_err
(
)
"
Database
should
fail
at
{
}
:
{
:
?
}
"
path
.
display
(
)
res
)
;
}
}
#
[
test
]
#
[
cfg
(
target_os
=
"
linux
"
)
]
fn
linux_invalid_utf8_panicfree
(
)
{
use
std
:
:
ffi
:
:
OsStr
;
use
std
:
:
os
:
:
unix
:
:
ffi
:
:
OsStrExt
;
let
source
=
[
0x66
0x6f
0x80
0x6f
]
;
let
os_str
=
OsStr
:
:
from_bytes
(
&
source
[
.
.
]
)
;
let
dir
=
tempdir
(
)
.
unwrap
(
)
;
let
path
=
dir
.
path
(
)
.
join
(
os_str
)
;
let
res
=
Database
:
:
new
(
&
path
false
)
;
assert
!
(
res
.
is_ok
(
)
"
Database
should
not
fail
at
{
}
:
{
:
?
}
"
path
.
display
(
)
res
)
;
}
#
[
test
]
#
[
cfg
(
target_os
=
"
macos
"
)
]
fn
macos_invalid_utf8_panicfree
(
)
{
use
std
:
:
ffi
:
:
OsStr
;
use
std
:
:
os
:
:
unix
:
:
ffi
:
:
OsStrExt
;
let
source
=
[
0x66
0x6f
0x80
0x6f
]
;
let
os_str
=
OsStr
:
:
from_bytes
(
&
source
[
.
.
]
)
;
let
dir
=
tempdir
(
)
.
unwrap
(
)
;
let
path
=
dir
.
path
(
)
.
join
(
os_str
)
;
let
res
=
Database
:
:
new
(
&
path
false
)
;
assert
!
(
res
.
is_err
(
)
"
Database
should
not
fail
at
{
}
:
{
:
?
}
"
path
.
display
(
)
res
)
;
}
#
[
test
]
fn
test_data_dir_rkv_inits
(
)
{
let
dir
=
tempdir
(
)
.
unwrap
(
)
;
Database
:
:
new
(
dir
.
path
(
)
false
)
.
unwrap
(
)
;
assert
!
(
dir
.
path
(
)
.
exists
(
)
)
;
}
#
[
test
]
fn
test_ping_lifetime_metric_recorded
(
)
{
let
dir
=
tempdir
(
)
.
unwrap
(
)
;
let
db
=
Database
:
:
new
(
dir
.
path
(
)
false
)
.
unwrap
(
)
;
assert
!
(
db
.
ping_lifetime_data
.
is_none
(
)
)
;
let
test_value
=
"
test
-
value
"
;
let
test_storage
=
"
test
-
storage
"
;
let
test_metric_id
=
"
telemetry_test
.
test_name
"
;
db
.
record_per_lifetime
(
Lifetime
:
:
Ping
test_storage
test_metric_id
&
Metric
:
:
String
(
test_value
.
to_string
(
)
)
)
.
unwrap
(
)
;
let
mut
found_metrics
=
0
;
let
mut
snapshotter
=
|
metric_id
:
&
[
u8
]
metric
:
&
Metric
|
{
found_metrics
+
=
1
;
let
metric_id
=
String
:
:
from_utf8_lossy
(
metric_id
)
.
into_owned
(
)
;
assert_eq
!
(
test_metric_id
metric_id
)
;
match
metric
{
Metric
:
:
String
(
s
)
=
>
assert_eq
!
(
test_value
s
)
_
=
>
panic
!
(
"
Unexpected
data
found
"
)
}
}
;
db
.
iter_store_from
(
Lifetime
:
:
Ping
test_storage
None
&
mut
snapshotter
)
;
assert_eq
!
(
1
found_metrics
"
We
only
expect
1
Lifetime
.
Ping
metric
.
"
)
;
}
#
[
test
]
fn
test_application_lifetime_metric_recorded
(
)
{
let
dir
=
tempdir
(
)
.
unwrap
(
)
;
let
db
=
Database
:
:
new
(
dir
.
path
(
)
false
)
.
unwrap
(
)
;
let
test_value
=
"
test
-
value
"
;
let
test_storage
=
"
test
-
storage1
"
;
let
test_metric_id
=
"
telemetry_test
.
test_name
"
;
db
.
record_per_lifetime
(
Lifetime
:
:
Application
test_storage
test_metric_id
&
Metric
:
:
String
(
test_value
.
to_string
(
)
)
)
.
unwrap
(
)
;
let
mut
found_metrics
=
0
;
let
mut
snapshotter
=
|
metric_id
:
&
[
u8
]
metric
:
&
Metric
|
{
found_metrics
+
=
1
;
let
metric_id
=
String
:
:
from_utf8_lossy
(
metric_id
)
.
into_owned
(
)
;
assert_eq
!
(
test_metric_id
metric_id
)
;
match
metric
{
Metric
:
:
String
(
s
)
=
>
assert_eq
!
(
test_value
s
)
_
=
>
panic
!
(
"
Unexpected
data
found
"
)
}
}
;
db
.
iter_store_from
(
Lifetime
:
:
Application
test_storage
None
&
mut
snapshotter
)
;
assert_eq
!
(
1
found_metrics
"
We
only
expect
1
Lifetime
.
Application
metric
.
"
)
;
}
#
[
test
]
fn
test_user_lifetime_metric_recorded
(
)
{
let
dir
=
tempdir
(
)
.
unwrap
(
)
;
let
db
=
Database
:
:
new
(
dir
.
path
(
)
false
)
.
unwrap
(
)
;
let
test_value
=
"
test
-
value
"
;
let
test_storage
=
"
test
-
storage2
"
;
let
test_metric_id
=
"
telemetry_test
.
test_name
"
;
db
.
record_per_lifetime
(
Lifetime
:
:
User
test_storage
test_metric_id
&
Metric
:
:
String
(
test_value
.
to_string
(
)
)
)
.
unwrap
(
)
;
let
mut
found_metrics
=
0
;
let
mut
snapshotter
=
|
metric_id
:
&
[
u8
]
metric
:
&
Metric
|
{
found_metrics
+
=
1
;
let
metric_id
=
String
:
:
from_utf8_lossy
(
metric_id
)
.
into_owned
(
)
;
assert_eq
!
(
test_metric_id
metric_id
)
;
match
metric
{
Metric
:
:
String
(
s
)
=
>
assert_eq
!
(
test_value
s
)
_
=
>
panic
!
(
"
Unexpected
data
found
"
)
}
}
;
db
.
iter_store_from
(
Lifetime
:
:
User
test_storage
None
&
mut
snapshotter
)
;
assert_eq
!
(
1
found_metrics
"
We
only
expect
1
Lifetime
.
User
metric
.
"
)
;
}
#
[
test
]
fn
test_clear_ping_storage
(
)
{
let
dir
=
tempdir
(
)
.
unwrap
(
)
;
let
db
=
Database
:
:
new
(
dir
.
path
(
)
false
)
.
unwrap
(
)
;
let
test_storage
=
"
test
-
storage
"
;
db
.
record_per_lifetime
(
Lifetime
:
:
User
test_storage
"
telemetry_test
.
test_name_user
"
&
Metric
:
:
String
(
"
test
-
value
-
user
"
.
to_string
(
)
)
)
.
unwrap
(
)
;
db
.
record_per_lifetime
(
Lifetime
:
:
Ping
test_storage
"
telemetry_test
.
test_name_ping
"
&
Metric
:
:
String
(
"
test
-
value
-
ping
"
.
to_string
(
)
)
)
.
unwrap
(
)
;
db
.
record_per_lifetime
(
Lifetime
:
:
Application
test_storage
"
telemetry_test
.
test_name_application
"
&
Metric
:
:
String
(
"
test
-
value
-
application
"
.
to_string
(
)
)
)
.
unwrap
(
)
;
{
let
mut
snapshot
:
HashMap
<
String
String
>
=
HashMap
:
:
new
(
)
;
let
mut
snapshotter
=
|
metric_id
:
&
[
u8
]
metric
:
&
Metric
|
{
let
metric_id
=
String
:
:
from_utf8_lossy
(
metric_id
)
.
into_owned
(
)
;
match
metric
{
Metric
:
:
String
(
s
)
=
>
snapshot
.
insert
(
metric_id
s
.
to_string
(
)
)
_
=
>
panic
!
(
"
Unexpected
data
found
"
)
}
;
}
;
db
.
iter_store_from
(
Lifetime
:
:
User
test_storage
None
&
mut
snapshotter
)
;
db
.
iter_store_from
(
Lifetime
:
:
Ping
test_storage
None
&
mut
snapshotter
)
;
db
.
iter_store_from
(
Lifetime
:
:
Application
test_storage
None
&
mut
snapshotter
)
;
assert_eq
!
(
3
snapshot
.
len
(
)
"
We
expect
all
lifetimes
to
be
present
.
"
)
;
assert
!
(
snapshot
.
contains_key
(
"
telemetry_test
.
test_name_user
"
)
)
;
assert
!
(
snapshot
.
contains_key
(
"
telemetry_test
.
test_name_ping
"
)
)
;
assert
!
(
snapshot
.
contains_key
(
"
telemetry_test
.
test_name_application
"
)
)
;
}
db
.
clear_ping_lifetime_storage
(
test_storage
)
.
unwrap
(
)
;
{
let
mut
snapshot
:
HashMap
<
String
String
>
=
HashMap
:
:
new
(
)
;
let
mut
snapshotter
=
|
metric_id
:
&
[
u8
]
metric
:
&
Metric
|
{
let
metric_id
=
String
:
:
from_utf8_lossy
(
metric_id
)
.
into_owned
(
)
;
match
metric
{
Metric
:
:
String
(
s
)
=
>
snapshot
.
insert
(
metric_id
s
.
to_string
(
)
)
_
=
>
panic
!
(
"
Unexpected
data
found
"
)
}
;
}
;
db
.
iter_store_from
(
Lifetime
:
:
User
test_storage
None
&
mut
snapshotter
)
;
db
.
iter_store_from
(
Lifetime
:
:
Ping
test_storage
None
&
mut
snapshotter
)
;
db
.
iter_store_from
(
Lifetime
:
:
Application
test_storage
None
&
mut
snapshotter
)
;
assert_eq
!
(
2
snapshot
.
len
(
)
"
We
only
expect
2
metrics
to
be
left
.
"
)
;
assert
!
(
snapshot
.
contains_key
(
"
telemetry_test
.
test_name_user
"
)
)
;
assert
!
(
snapshot
.
contains_key
(
"
telemetry_test
.
test_name_application
"
)
)
;
}
}
#
[
test
]
fn
test_remove_single_metric
(
)
{
let
dir
=
tempdir
(
)
.
unwrap
(
)
;
let
db
=
Database
:
:
new
(
dir
.
path
(
)
false
)
.
unwrap
(
)
;
let
test_storage
=
"
test
-
storage
-
single
-
lifetime
"
;
let
metric_id_pattern
=
"
telemetry_test
.
single_metric
"
;
let
lifetimes
=
vec
!
[
Lifetime
:
:
User
Lifetime
:
:
Ping
Lifetime
:
:
Application
]
;
for
lifetime
in
lifetimes
.
iter
(
)
{
for
value
in
&
[
"
retain
"
"
delete
"
]
{
db
.
record_per_lifetime
(
*
lifetime
test_storage
&
format
!
(
"
{
}
_
{
}
"
metric_id_pattern
value
)
&
Metric
:
:
String
(
(
*
value
)
.
to_string
(
)
)
)
.
unwrap
(
)
;
}
}
for
lifetime
in
lifetimes
.
iter
(
)
{
db
.
remove_single_metric
(
*
lifetime
test_storage
&
format
!
(
"
{
}
_delete
"
metric_id_pattern
)
)
.
unwrap
(
)
;
}
for
lifetime
in
lifetimes
.
iter
(
)
{
let
mut
found_metrics
=
0
;
let
mut
snapshotter
=
|
metric_id
:
&
[
u8
]
metric
:
&
Metric
|
{
found_metrics
+
=
1
;
let
metric_id
=
String
:
:
from_utf8_lossy
(
metric_id
)
.
into_owned
(
)
;
assert_eq
!
(
format
!
(
"
{
}
_retain
"
metric_id_pattern
)
metric_id
)
;
match
metric
{
Metric
:
:
String
(
s
)
=
>
assert_eq
!
(
"
retain
"
s
)
_
=
>
panic
!
(
"
Unexpected
data
found
"
)
}
}
;
db
.
iter_store_from
(
*
lifetime
test_storage
None
&
mut
snapshotter
)
;
assert_eq
!
(
1
found_metrics
"
We
only
expect
1
metric
for
this
lifetime
.
"
)
;
}
}
#
[
test
]
fn
test_delayed_ping_lifetime_persistence
(
)
{
let
dir
=
tempdir
(
)
.
unwrap
(
)
;
let
db
=
Database
:
:
new
(
dir
.
path
(
)
true
)
.
unwrap
(
)
;
let
test_storage
=
"
test
-
storage
"
;
assert
!
(
db
.
ping_lifetime_data
.
is_some
(
)
)
;
let
test_value1
=
"
test
-
value1
"
;
let
test_metric_id1
=
"
telemetry_test
.
test_name1
"
;
db
.
record_per_lifetime
(
Lifetime
:
:
Ping
test_storage
test_metric_id1
&
Metric
:
:
String
(
test_value1
.
to_string
(
)
)
)
.
unwrap
(
)
;
db
.
persist_ping_lifetime_data
(
)
.
unwrap
(
)
;
let
test_value2
=
"
test
-
value2
"
;
let
test_metric_id2
=
"
telemetry_test
.
test_name2
"
;
db
.
record_per_lifetime
(
Lifetime
:
:
Ping
test_storage
test_metric_id2
&
Metric
:
:
String
(
test_value2
.
to_string
(
)
)
)
.
unwrap
(
)
;
{
let
store
:
SingleStore
=
db
.
rkv
.
open_single
(
Lifetime
:
:
Ping
.
as_str
(
)
StoreOptions
:
:
create
(
)
)
.
unwrap
(
)
;
let
reader
=
db
.
rkv
.
read
(
)
.
unwrap
(
)
;
assert
!
(
store
.
get
(
&
reader
format
!
(
"
{
}
#
{
}
"
test_storage
test_metric_id1
)
)
.
unwrap_or
(
None
)
.
is_some
(
)
)
;
assert
!
(
store
.
get
(
&
reader
format
!
(
"
{
}
#
{
}
"
test_storage
test_metric_id2
)
)
.
unwrap_or
(
None
)
.
is_none
(
)
)
;
let
data
=
match
&
db
.
ping_lifetime_data
{
Some
(
ping_lifetime_data
)
=
>
ping_lifetime_data
None
=
>
panic
!
(
"
Expected
ping_lifetime_data
to
exist
here
!
"
)
}
;
let
data
=
data
.
read
(
)
.
unwrap
(
)
;
assert
!
(
data
.
get
(
&
format
!
(
"
{
}
#
{
}
"
test_storage
test_metric_id1
)
)
.
is_some
(
)
)
;
assert
!
(
data
.
get
(
&
format
!
(
"
{
}
#
{
}
"
test_storage
test_metric_id2
)
)
.
is_some
(
)
)
;
}
db
.
persist_ping_lifetime_data
(
)
.
unwrap
(
)
;
{
let
store
:
SingleStore
=
db
.
rkv
.
open_single
(
Lifetime
:
:
Ping
.
as_str
(
)
StoreOptions
:
:
create
(
)
)
.
unwrap
(
)
;
let
reader
=
db
.
rkv
.
read
(
)
.
unwrap
(
)
;
assert
!
(
store
.
get
(
&
reader
format
!
(
"
{
}
#
{
}
"
test_storage
test_metric_id1
)
)
.
unwrap_or
(
None
)
.
is_some
(
)
)
;
assert
!
(
store
.
get
(
&
reader
format
!
(
"
{
}
#
{
}
"
test_storage
test_metric_id2
)
)
.
unwrap_or
(
None
)
.
is_some
(
)
)
;
let
data
=
match
&
db
.
ping_lifetime_data
{
Some
(
ping_lifetime_data
)
=
>
ping_lifetime_data
None
=
>
panic
!
(
"
Expected
ping_lifetime_data
to
exist
here
!
"
)
}
;
let
data
=
data
.
read
(
)
.
unwrap
(
)
;
assert
!
(
data
.
get
(
&
format
!
(
"
{
}
#
{
}
"
test_storage
test_metric_id1
)
)
.
is_some
(
)
)
;
assert
!
(
data
.
get
(
&
format
!
(
"
{
}
#
{
}
"
test_storage
test_metric_id2
)
)
.
is_some
(
)
)
;
}
}
#
[
test
]
fn
test_load_ping_lifetime_data_from_memory
(
)
{
let
dir
=
tempdir
(
)
.
unwrap
(
)
;
let
test_storage
=
"
test
-
storage
"
;
let
test_value
=
"
test
-
value
"
;
let
test_metric_id
=
"
telemetry_test
.
test_name
"
;
{
let
db
=
Database
:
:
new
(
dir
.
path
(
)
true
)
.
unwrap
(
)
;
db
.
record_per_lifetime
(
Lifetime
:
:
Ping
test_storage
test_metric_id
&
Metric
:
:
String
(
test_value
.
to_string
(
)
)
)
.
unwrap
(
)
;
let
data
=
match
&
db
.
ping_lifetime_data
{
Some
(
ping_lifetime_data
)
=
>
ping_lifetime_data
None
=
>
panic
!
(
"
Expected
ping_lifetime_data
to
exist
here
!
"
)
}
;
let
data
=
data
.
read
(
)
.
unwrap
(
)
;
assert
!
(
data
.
get
(
&
format
!
(
"
{
}
#
{
}
"
test_storage
test_metric_id
)
)
.
is_some
(
)
)
;
db
.
persist_ping_lifetime_data
(
)
.
unwrap
(
)
;
let
store
:
SingleStore
=
db
.
rkv
.
open_single
(
Lifetime
:
:
Ping
.
as_str
(
)
StoreOptions
:
:
create
(
)
)
.
unwrap
(
)
;
let
reader
=
db
.
rkv
.
read
(
)
.
unwrap
(
)
;
assert
!
(
store
.
get
(
&
reader
format
!
(
"
{
}
#
{
}
"
test_storage
test_metric_id
)
)
.
unwrap_or
(
None
)
.
is_some
(
)
)
;
}
{
let
db
=
Database
:
:
new
(
dir
.
path
(
)
true
)
.
unwrap
(
)
;
let
data
=
match
&
db
.
ping_lifetime_data
{
Some
(
ping_lifetime_data
)
=
>
ping_lifetime_data
None
=
>
panic
!
(
"
Expected
ping_lifetime_data
to
exist
here
!
"
)
}
;
let
data
=
data
.
read
(
)
.
unwrap
(
)
;
assert
!
(
data
.
get
(
&
format
!
(
"
{
}
#
{
}
"
test_storage
test_metric_id
)
)
.
is_some
(
)
)
;
let
store
:
SingleStore
=
db
.
rkv
.
open_single
(
Lifetime
:
:
Ping
.
as_str
(
)
StoreOptions
:
:
create
(
)
)
.
unwrap
(
)
;
let
reader
=
db
.
rkv
.
read
(
)
.
unwrap
(
)
;
assert
!
(
store
.
get
(
&
reader
format
!
(
"
{
}
#
{
}
"
test_storage
test_metric_id
)
)
.
unwrap_or
(
None
)
.
is_some
(
)
)
;
}
}
#
[
test
]
fn
test_delayed_ping_lifetime_clear
(
)
{
let
dir
=
tempdir
(
)
.
unwrap
(
)
;
let
db
=
Database
:
:
new
(
dir
.
path
(
)
true
)
.
unwrap
(
)
;
let
test_storage
=
"
test
-
storage
"
;
assert
!
(
db
.
ping_lifetime_data
.
is_some
(
)
)
;
let
test_value1
=
"
test
-
value1
"
;
let
test_metric_id1
=
"
telemetry_test
.
test_name1
"
;
db
.
record_per_lifetime
(
Lifetime
:
:
Ping
test_storage
test_metric_id1
&
Metric
:
:
String
(
test_value1
.
to_string
(
)
)
)
.
unwrap
(
)
;
{
let
data
=
match
&
db
.
ping_lifetime_data
{
Some
(
ping_lifetime_data
)
=
>
ping_lifetime_data
None
=
>
panic
!
(
"
Expected
ping_lifetime_data
to
exist
here
!
"
)
}
;
let
data
=
data
.
read
(
)
.
unwrap
(
)
;
assert
!
(
data
.
get
(
&
format
!
(
"
{
}
#
{
}
"
test_storage
test_metric_id1
)
)
.
is_some
(
)
)
;
}
db
.
clear_ping_lifetime_storage
(
&
(
test_storage
.
to_owned
(
)
+
"
x
"
)
)
.
unwrap
(
)
;
{
let
data
=
match
&
db
.
ping_lifetime_data
{
Some
(
ping_lifetime_data
)
=
>
ping_lifetime_data
None
=
>
panic
!
(
"
Expected
ping_lifetime_data
to
exist
here
!
"
)
}
;
let
data
=
data
.
read
(
)
.
unwrap
(
)
;
assert
!
(
data
.
get
(
&
format
!
(
"
{
}
#
{
}
"
test_storage
test_metric_id1
)
)
.
is_some
(
)
)
;
}
db
.
clear_ping_lifetime_storage
(
test_storage
)
.
unwrap
(
)
;
{
let
data
=
match
&
db
.
ping_lifetime_data
{
Some
(
ping_lifetime_data
)
=
>
ping_lifetime_data
None
=
>
panic
!
(
"
Expected
ping_lifetime_data
to
exist
here
!
"
)
}
;
let
data
=
data
.
read
(
)
.
unwrap
(
)
;
assert
!
(
data
.
get
(
&
format
!
(
"
{
}
#
{
}
"
test_storage
test_metric_id1
)
)
.
is_none
(
)
)
;
}
}
#
[
test
]
fn
doesnt_record_when_upload_is_disabled
(
)
{
let
(
mut
glean
dir
)
=
new_glean
(
None
)
;
let
test_storage
=
"
test
-
storage
"
;
let
test_data
=
CommonMetricData
:
:
new
(
"
category
"
"
name
"
test_storage
)
;
let
test_metric_id
=
test_data
.
identifier
(
&
glean
)
;
let
db
=
Database
:
:
new
(
dir
.
path
(
)
true
)
.
unwrap
(
)
;
db
.
record
(
&
glean
&
test_data
&
Metric
:
:
String
(
"
record
"
.
to_owned
(
)
)
)
;
db
.
iter_store_from
(
Lifetime
:
:
Ping
test_storage
None
&
mut
|
metric_id
:
&
[
u8
]
metric
:
&
Metric
|
{
assert_eq
!
(
String
:
:
from_utf8_lossy
(
metric_id
)
.
into_owned
(
)
test_metric_id
)
;
match
metric
{
Metric
:
:
String
(
v
)
=
>
assert_eq
!
(
"
record
"
*
v
)
_
=
>
panic
!
(
"
Unexpected
data
found
"
)
}
}
)
;
db
.
record_with
(
&
glean
&
test_data
|
_
|
{
Metric
:
:
String
(
"
record_with
"
.
to_owned
(
)
)
}
)
;
db
.
iter_store_from
(
Lifetime
:
:
Ping
test_storage
None
&
mut
|
metric_id
:
&
[
u8
]
metric
:
&
Metric
|
{
assert_eq
!
(
String
:
:
from_utf8_lossy
(
metric_id
)
.
into_owned
(
)
test_metric_id
)
;
match
metric
{
Metric
:
:
String
(
v
)
=
>
assert_eq
!
(
"
record_with
"
*
v
)
_
=
>
panic
!
(
"
Unexpected
data
found
"
)
}
}
)
;
glean
.
set_upload_enabled
(
false
)
;
db
.
record
(
&
glean
&
test_data
&
Metric
:
:
String
(
"
record_nop
"
.
to_owned
(
)
)
)
;
db
.
iter_store_from
(
Lifetime
:
:
Ping
test_storage
None
&
mut
|
metric_id
:
&
[
u8
]
metric
:
&
Metric
|
{
assert_eq
!
(
String
:
:
from_utf8_lossy
(
metric_id
)
.
into_owned
(
)
test_metric_id
)
;
match
metric
{
Metric
:
:
String
(
v
)
=
>
assert_eq
!
(
"
record_with
"
*
v
)
_
=
>
panic
!
(
"
Unexpected
data
found
"
)
}
}
)
;
db
.
record_with
(
&
glean
&
test_data
|
_
|
{
Metric
:
:
String
(
"
record_with_nop
"
.
to_owned
(
)
)
}
)
;
db
.
iter_store_from
(
Lifetime
:
:
Ping
test_storage
None
&
mut
|
metric_id
:
&
[
u8
]
metric
:
&
Metric
|
{
assert_eq
!
(
String
:
:
from_utf8_lossy
(
metric_id
)
.
into_owned
(
)
test_metric_id
)
;
match
metric
{
Metric
:
:
String
(
v
)
=
>
assert_eq
!
(
"
record_with
"
*
v
)
_
=
>
panic
!
(
"
Unexpected
data
found
"
)
}
}
)
;
}
#
[
cfg
(
not
(
feature
=
"
rkv
-
safe
-
mode
"
)
)
]
#
[
test
]
fn
empty_data_file
(
)
{
let
dir
=
tempdir
(
)
.
unwrap
(
)
;
let
database_dir
=
dir
.
path
(
)
.
join
(
"
db
"
)
;
fs
:
:
create_dir_all
(
&
database_dir
)
.
expect
(
"
create
database
dir
"
)
;
let
datamdb
=
database_dir
.
join
(
"
data
.
mdb
"
)
;
let
f
=
fs
:
:
File
:
:
create
(
datamdb
)
.
expect
(
"
create
database
file
"
)
;
drop
(
f
)
;
Database
:
:
new
(
dir
.
path
(
)
false
)
.
unwrap
(
)
;
assert
!
(
dir
.
path
(
)
.
exists
(
)
)
;
}
#
[
cfg
(
feature
=
"
rkv
-
safe
-
mode
"
)
]
mod
safe_mode
{
use
std
:
:
fs
:
:
File
;
use
super
:
:
*
;
use
rkv
:
:
Value
;
#
[
test
]
fn
empty_data_file
(
)
{
let
dir
=
tempdir
(
)
.
unwrap
(
)
;
let
database_dir
=
dir
.
path
(
)
.
join
(
"
db
"
)
;
fs
:
:
create_dir_all
(
&
database_dir
)
.
expect
(
"
create
database
dir
"
)
;
let
safebin
=
database_dir
.
join
(
"
data
.
safe
.
bin
"
)
;
let
f
=
File
:
:
create
(
safebin
)
.
expect
(
"
create
database
file
"
)
;
drop
(
f
)
;
Database
:
:
new
(
dir
.
path
(
)
false
)
.
unwrap
(
)
;
assert
!
(
dir
.
path
(
)
.
exists
(
)
)
;
}
#
[
test
]
fn
corrupted_data_file
(
)
{
let
dir
=
tempdir
(
)
.
unwrap
(
)
;
let
database_dir
=
dir
.
path
(
)
.
join
(
"
db
"
)
;
fs
:
:
create_dir_all
(
&
database_dir
)
.
expect
(
"
create
database
dir
"
)
;
let
safebin
=
database_dir
.
join
(
"
data
.
safe
.
bin
"
)
;
fs
:
:
write
(
safebin
"
<
broken
>
"
)
.
expect
(
"
write
to
database
file
"
)
;
Database
:
:
new
(
dir
.
path
(
)
false
)
.
unwrap
(
)
;
assert
!
(
dir
.
path
(
)
.
exists
(
)
)
;
}
#
[
test
]
fn
migration_works_on_startup
(
)
{
let
dir
=
tempdir
(
)
.
unwrap
(
)
;
let
database_dir
=
dir
.
path
(
)
.
join
(
"
db
"
)
;
let
datamdb
=
database_dir
.
join
(
"
data
.
mdb
"
)
;
let
lockmdb
=
database_dir
.
join
(
"
lock
.
mdb
"
)
;
let
safebin
=
database_dir
.
join
(
"
data
.
safe
.
bin
"
)
;
assert
!
(
!
safebin
.
exists
(
)
)
;
assert
!
(
!
datamdb
.
exists
(
)
)
;
assert
!
(
!
lockmdb
.
exists
(
)
)
;
let
store_name
=
"
store1
"
;
let
metric_name
=
"
bool
"
;
let
key
=
Database
:
:
get_storage_key
(
store_name
Some
(
metric_name
)
)
;
{
fs
:
:
create_dir_all
(
&
database_dir
)
.
expect
(
"
create
dir
"
)
;
let
rkv_db
=
rkv
:
:
Rkv
:
:
new
:
:
<
rkv
:
:
backend
:
:
Lmdb
>
(
&
database_dir
)
.
expect
(
"
rkv
env
"
)
;
let
store
=
rkv_db
.
open_single
(
"
ping
"
StoreOptions
:
:
create
(
)
)
.
expect
(
"
opened
"
)
;
let
mut
writer
=
rkv_db
.
write
(
)
.
expect
(
"
writer
"
)
;
let
metric
=
Metric
:
:
Boolean
(
true
)
;
let
value
=
bincode
:
:
serialize
(
&
metric
)
.
expect
(
"
serialized
"
)
;
store
.
put
(
&
mut
writer
&
key
&
Value
:
:
Blob
(
&
value
)
)
.
expect
(
"
wrote
"
)
;
writer
.
commit
(
)
.
expect
(
"
committed
"
)
;
assert
!
(
datamdb
.
exists
(
)
)
;
assert
!
(
lockmdb
.
exists
(
)
)
;
assert
!
(
!
safebin
.
exists
(
)
)
;
}
{
let
db
=
Database
:
:
new
(
dir
.
path
(
)
false
)
.
unwrap
(
)
;
let
safebin
=
database_dir
.
join
(
"
data
.
safe
.
bin
"
)
;
assert
!
(
safebin
.
exists
(
)
"
safe
-
mode
file
should
exist
"
)
;
assert
!
(
!
datamdb
.
exists
(
)
"
LMDB
data
should
be
deleted
"
)
;
assert
!
(
!
lockmdb
.
exists
(
)
"
LMDB
lock
should
be
deleted
"
)
;
let
mut
stored_metrics
=
vec
!
[
]
;
let
mut
snapshotter
=
|
name
:
&
[
u8
]
metric
:
&
Metric
|
{
let
name
=
str
:
:
from_utf8
(
name
)
.
unwrap
(
)
.
to_string
(
)
;
stored_metrics
.
push
(
(
name
metric
.
clone
(
)
)
)
}
;
db
.
iter_store_from
(
Lifetime
:
:
Ping
"
store1
"
None
&
mut
snapshotter
)
;
assert_eq
!
(
1
stored_metrics
.
len
(
)
)
;
assert_eq
!
(
metric_name
stored_metrics
[
0
]
.
0
)
;
assert_eq
!
(
&
Metric
:
:
Boolean
(
true
)
&
stored_metrics
[
0
]
.
1
)
;
}
{
let
db
=
Database
:
:
new
(
dir
.
path
(
)
false
)
.
unwrap
(
)
;
let
safebin
=
database_dir
.
join
(
"
data
.
safe
.
bin
"
)
;
assert
!
(
safebin
.
exists
(
)
"
safe
-
mode
file
exists
"
)
;
assert
!
(
!
datamdb
.
exists
(
)
"
LMDB
data
should
not
be
recreated
"
)
;
assert
!
(
!
lockmdb
.
exists
(
)
"
LMDB
lock
should
not
be
recreated
"
)
;
let
mut
stored_metrics
=
vec
!
[
]
;
let
mut
snapshotter
=
|
name
:
&
[
u8
]
metric
:
&
Metric
|
{
let
name
=
str
:
:
from_utf8
(
name
)
.
unwrap
(
)
.
to_string
(
)
;
stored_metrics
.
push
(
(
name
metric
.
clone
(
)
)
)
}
;
db
.
iter_store_from
(
Lifetime
:
:
Ping
"
store1
"
None
&
mut
snapshotter
)
;
assert_eq
!
(
1
stored_metrics
.
len
(
)
)
;
assert_eq
!
(
metric_name
stored_metrics
[
0
]
.
0
)
;
assert_eq
!
(
&
Metric
:
:
Boolean
(
true
)
&
stored_metrics
[
0
]
.
1
)
;
}
}
#
[
test
]
fn
migration_doesnt_overwrite
(
)
{
let
dir
=
tempdir
(
)
.
unwrap
(
)
;
let
database_dir
=
dir
.
path
(
)
.
join
(
"
db
"
)
;
let
datamdb
=
database_dir
.
join
(
"
data
.
mdb
"
)
;
let
lockmdb
=
database_dir
.
join
(
"
lock
.
mdb
"
)
;
let
safebin
=
database_dir
.
join
(
"
data
.
safe
.
bin
"
)
;
assert
!
(
!
safebin
.
exists
(
)
)
;
assert
!
(
!
datamdb
.
exists
(
)
)
;
assert
!
(
!
lockmdb
.
exists
(
)
)
;
let
store_name
=
"
store1
"
;
let
metric_name
=
"
counter
"
;
let
key
=
Database
:
:
get_storage_key
(
store_name
Some
(
metric_name
)
)
;
{
fs
:
:
create_dir_all
(
&
database_dir
)
.
expect
(
"
create
dir
"
)
;
let
rkv_db
=
rkv
:
:
Rkv
:
:
new
:
:
<
rkv
:
:
backend
:
:
Lmdb
>
(
&
database_dir
)
.
expect
(
"
rkv
env
"
)
;
let
store
=
rkv_db
.
open_single
(
"
ping
"
StoreOptions
:
:
create
(
)
)
.
expect
(
"
opened
"
)
;
let
mut
writer
=
rkv_db
.
write
(
)
.
expect
(
"
writer
"
)
;
let
metric
=
Metric
:
:
Counter
(
734
)
;
let
value
=
bincode
:
:
serialize
(
&
metric
)
.
expect
(
"
serialized
"
)
;
store
.
put
(
&
mut
writer
&
key
&
Value
:
:
Blob
(
&
value
)
)
.
expect
(
"
wrote
"
)
;
writer
.
commit
(
)
.
expect
(
"
committed
"
)
;
assert
!
(
datamdb
.
exists
(
)
)
;
assert
!
(
lockmdb
.
exists
(
)
)
;
}
{
fs
:
:
create_dir_all
(
&
database_dir
)
.
expect
(
"
create
dir
"
)
;
let
rkv_db
=
rkv
:
:
Rkv
:
:
new
:
:
<
rkv
:
:
backend
:
:
SafeMode
>
(
&
database_dir
)
.
expect
(
"
rkv
env
"
)
;
let
store
=
rkv_db
.
open_single
(
"
ping
"
StoreOptions
:
:
create
(
)
)
.
expect
(
"
opened
"
)
;
let
mut
writer
=
rkv_db
.
write
(
)
.
expect
(
"
writer
"
)
;
let
metric
=
Metric
:
:
Counter
(
2
)
;
let
value
=
bincode
:
:
serialize
(
&
metric
)
.
expect
(
"
serialized
"
)
;
store
.
put
(
&
mut
writer
&
key
&
Value
:
:
Blob
(
&
value
)
)
.
expect
(
"
wrote
"
)
;
writer
.
commit
(
)
.
expect
(
"
committed
"
)
;
assert
!
(
safebin
.
exists
(
)
)
;
}
{
let
db
=
Database
:
:
new
(
dir
.
path
(
)
false
)
.
unwrap
(
)
;
let
safebin
=
database_dir
.
join
(
"
data
.
safe
.
bin
"
)
;
assert
!
(
safebin
.
exists
(
)
"
safe
-
mode
file
should
exist
"
)
;
assert
!
(
!
datamdb
.
exists
(
)
"
LMDB
data
should
be
deleted
"
)
;
assert
!
(
!
lockmdb
.
exists
(
)
"
LMDB
lock
should
be
deleted
"
)
;
let
mut
stored_metrics
=
vec
!
[
]
;
let
mut
snapshotter
=
|
name
:
&
[
u8
]
metric
:
&
Metric
|
{
let
name
=
str
:
:
from_utf8
(
name
)
.
unwrap
(
)
.
to_string
(
)
;
stored_metrics
.
push
(
(
name
metric
.
clone
(
)
)
)
}
;
db
.
iter_store_from
(
Lifetime
:
:
Ping
"
store1
"
None
&
mut
snapshotter
)
;
assert_eq
!
(
1
stored_metrics
.
len
(
)
)
;
assert_eq
!
(
metric_name
stored_metrics
[
0
]
.
0
)
;
assert_eq
!
(
&
Metric
:
:
Counter
(
2
)
&
stored_metrics
[
0
]
.
1
)
;
}
}
#
[
test
]
fn
migration_ignores_broken_database
(
)
{
let
dir
=
tempdir
(
)
.
unwrap
(
)
;
let
database_dir
=
dir
.
path
(
)
.
join
(
"
db
"
)
;
let
datamdb
=
database_dir
.
join
(
"
data
.
mdb
"
)
;
let
lockmdb
=
database_dir
.
join
(
"
lock
.
mdb
"
)
;
let
safebin
=
database_dir
.
join
(
"
data
.
safe
.
bin
"
)
;
assert
!
(
!
safebin
.
exists
(
)
)
;
assert
!
(
!
datamdb
.
exists
(
)
)
;
assert
!
(
!
lockmdb
.
exists
(
)
)
;
let
store_name
=
"
store1
"
;
let
metric_name
=
"
counter
"
;
let
key
=
Database
:
:
get_storage_key
(
store_name
Some
(
metric_name
)
)
;
{
fs
:
:
create_dir_all
(
&
database_dir
)
.
expect
(
"
create
dir
"
)
;
fs
:
:
write
(
&
datamdb
"
bogus
"
)
.
expect
(
"
dbfile
created
"
)
;
assert
!
(
datamdb
.
exists
(
)
)
;
}
{
fs
:
:
create_dir_all
(
&
database_dir
)
.
expect
(
"
create
dir
"
)
;
let
rkv_db
=
rkv
:
:
Rkv
:
:
new
:
:
<
rkv
:
:
backend
:
:
SafeMode
>
(
&
database_dir
)
.
expect
(
"
rkv
env
"
)
;
let
store
=
rkv_db
.
open_single
(
"
ping
"
StoreOptions
:
:
create
(
)
)
.
expect
(
"
opened
"
)
;
let
mut
writer
=
rkv_db
.
write
(
)
.
expect
(
"
writer
"
)
;
let
metric
=
Metric
:
:
Counter
(
2
)
;
let
value
=
bincode
:
:
serialize
(
&
metric
)
.
expect
(
"
serialized
"
)
;
store
.
put
(
&
mut
writer
&
key
&
Value
:
:
Blob
(
&
value
)
)
.
expect
(
"
wrote
"
)
;
writer
.
commit
(
)
.
expect
(
"
committed
"
)
;
}
{
let
db
=
Database
:
:
new
(
dir
.
path
(
)
false
)
.
unwrap
(
)
;
let
safebin
=
database_dir
.
join
(
"
data
.
safe
.
bin
"
)
;
assert
!
(
safebin
.
exists
(
)
"
safe
-
mode
file
should
exist
"
)
;
assert
!
(
!
datamdb
.
exists
(
)
"
LMDB
data
should
be
deleted
"
)
;
assert
!
(
!
lockmdb
.
exists
(
)
"
LMDB
lock
should
be
deleted
"
)
;
let
mut
stored_metrics
=
vec
!
[
]
;
let
mut
snapshotter
=
|
name
:
&
[
u8
]
metric
:
&
Metric
|
{
let
name
=
str
:
:
from_utf8
(
name
)
.
unwrap
(
)
.
to_string
(
)
;
stored_metrics
.
push
(
(
name
metric
.
clone
(
)
)
)
}
;
db
.
iter_store_from
(
Lifetime
:
:
Ping
"
store1
"
None
&
mut
snapshotter
)
;
assert_eq
!
(
1
stored_metrics
.
len
(
)
)
;
assert_eq
!
(
metric_name
stored_metrics
[
0
]
.
0
)
;
assert_eq
!
(
&
Metric
:
:
Counter
(
2
)
&
stored_metrics
[
0
]
.
1
)
;
}
}
#
[
test
]
fn
migration_ignores_empty_database
(
)
{
let
dir
=
tempdir
(
)
.
unwrap
(
)
;
let
database_dir
=
dir
.
path
(
)
.
join
(
"
db
"
)
;
let
datamdb
=
database_dir
.
join
(
"
data
.
mdb
"
)
;
let
lockmdb
=
database_dir
.
join
(
"
lock
.
mdb
"
)
;
let
safebin
=
database_dir
.
join
(
"
data
.
safe
.
bin
"
)
;
assert
!
(
!
safebin
.
exists
(
)
)
;
assert
!
(
!
datamdb
.
exists
(
)
)
;
assert
!
(
!
lockmdb
.
exists
(
)
)
;
{
fs
:
:
create_dir_all
(
&
database_dir
)
.
expect
(
"
create
dir
"
)
;
let
rkv_db
=
rkv
:
:
Rkv
:
:
new
:
:
<
rkv
:
:
backend
:
:
Lmdb
>
(
&
database_dir
)
.
expect
(
"
rkv
env
"
)
;
drop
(
rkv_db
)
;
assert
!
(
datamdb
.
exists
(
)
)
;
assert
!
(
lockmdb
.
exists
(
)
)
;
}
{
let
_db
=
Database
:
:
new
(
dir
.
path
(
)
false
)
.
unwrap
(
)
;
let
safebin
=
database_dir
.
join
(
"
data
.
safe
.
bin
"
)
;
assert
!
(
!
safebin
.
exists
(
)
"
safe
-
mode
file
should
exist
"
)
;
assert
!
(
!
datamdb
.
exists
(
)
"
LMDB
data
should
be
deleted
"
)
;
assert
!
(
!
lockmdb
.
exists
(
)
"
LMDB
lock
should
be
deleted
"
)
;
}
}
}
}
