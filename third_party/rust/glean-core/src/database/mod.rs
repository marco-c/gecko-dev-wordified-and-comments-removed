use
std
:
:
cell
:
:
{
Cell
RefCell
}
;
use
std
:
:
collections
:
:
btree_map
:
:
Entry
;
use
std
:
:
collections
:
:
BTreeMap
;
use
std
:
:
fs
;
use
std
:
:
io
;
use
std
:
:
num
:
:
NonZeroU64
;
use
std
:
:
path
:
:
Path
;
use
std
:
:
str
;
use
std
:
:
sync
:
:
atomic
:
:
{
AtomicUsize
Ordering
}
;
use
std
:
:
sync
:
:
RwLock
;
use
std
:
:
time
:
:
{
Duration
Instant
}
;
use
crate
:
:
internal_metrics
:
:
LoadSizesObject
;
use
crate
:
:
ErrorKind
;
use
malloc_size_of
:
:
MallocSizeOf
;
use
rkv
:
:
{
StoreError
StoreOptions
}
;
macro_rules
!
unwrap_or
{
(
expr
:
expr
or
:
expr
)
=
>
{
match
expr
{
Ok
(
x
)
=
>
x
Err
(
_
)
=
>
{
or
;
}
}
}
;
}
macro_rules
!
measure_commit
{
(
this
:
ident
expr
:
expr
)
=
>
{
{
let
now
=
:
:
std
:
:
time
:
:
Instant
:
:
now
(
)
;
let
res
=
expr
;
let
elapsed
=
now
.
elapsed
(
)
;
if
let
Ok
(
elapsed
)
=
elapsed
.
as_micros
(
)
.
try_into
(
)
{
let
mut
samples
=
this
.
write_timings
.
borrow_mut
(
)
;
samples
.
push
(
elapsed
)
;
}
res
}
}
;
}
/
/
/
cbindgen
:
ignore
pub
type
Rkv
=
rkv
:
:
Rkv
<
rkv
:
:
backend
:
:
SafeModeEnvironment
>
;
/
/
/
cbindgen
:
ignore
pub
type
SingleStore
=
rkv
:
:
SingleStore
<
rkv
:
:
backend
:
:
SafeModeDatabase
>
;
/
/
/
cbindgen
:
ignore
pub
type
Writer
<
'
t
>
=
rkv
:
:
Writer
<
rkv
:
:
backend
:
:
SafeModeRwTransaction
<
'
t
>
>
;
#
[
derive
(
Debug
)
]
pub
enum
RkvLoadState
{
Ok
Err
(
rkv
:
:
StoreError
)
}
pub
fn
rkv_new
(
path
:
&
Path
)
-
>
std
:
:
result
:
:
Result
<
(
Rkv
RkvLoadState
)
rkv
:
:
StoreError
>
{
match
Rkv
:
:
new
:
:
<
rkv
:
:
backend
:
:
SafeMode
>
(
path
)
{
Err
(
rkv
:
:
StoreError
:
:
FileInvalid
)
=
>
{
log
:
:
debug
!
(
"
rkv
failed
:
invalid
file
.
starting
from
scratch
.
"
)
;
let
safebin
=
path
.
join
(
"
data
.
safe
.
bin
"
)
;
fs
:
:
remove_file
(
safebin
)
.
map_err
(
|
_
|
rkv
:
:
StoreError
:
:
FileInvalid
)
?
;
let
rkv
=
Rkv
:
:
new
:
:
<
rkv
:
:
backend
:
:
SafeMode
>
(
path
)
?
;
Ok
(
(
rkv
RkvLoadState
:
:
Err
(
rkv
:
:
StoreError
:
:
FileInvalid
)
)
)
}
Err
(
rkv
:
:
StoreError
:
:
DatabaseCorrupted
)
=
>
{
log
:
:
debug
!
(
"
rkv
failed
:
database
corrupted
.
starting
from
scratch
.
"
)
;
let
safebin
=
path
.
join
(
"
data
.
safe
.
bin
"
)
;
fs
:
:
remove_file
(
safebin
)
.
map_err
(
|
_
|
rkv
:
:
StoreError
:
:
DatabaseCorrupted
)
?
;
let
rkv
=
Rkv
:
:
new
:
:
<
rkv
:
:
backend
:
:
SafeMode
>
(
path
)
?
;
Ok
(
(
rkv
RkvLoadState
:
:
Err
(
rkv
:
:
StoreError
:
:
DatabaseCorrupted
)
)
)
}
other
=
>
{
let
rkv
=
other
?
;
Ok
(
(
rkv
RkvLoadState
:
:
Ok
)
)
}
}
}
use
crate
:
:
common_metric_data
:
:
CommonMetricDataInternal
;
use
crate
:
:
metrics
:
:
Metric
;
use
crate
:
:
Glean
;
use
crate
:
:
Lifetime
;
use
crate
:
:
Result
;
pub
struct
Database
{
rkv
:
Rkv
user_store
:
SingleStore
ping_store
:
SingleStore
application_store
:
SingleStore
ping_lifetime_data
:
Option
<
RwLock
<
BTreeMap
<
String
Metric
>
>
>
ping_lifetime_count
:
AtomicUsize
ping_lifetime_threshold
:
usize
ping_lifetime_store_ts
:
Cell
<
Instant
>
ping_lifetime_max_time
:
Duration
file_size
:
Option
<
NonZeroU64
>
rkv_load_state
:
RkvLoadState
pub
(
crate
)
write_timings
:
RefCell
<
Vec
<
i64
>
>
load_sizes
:
Option
<
LoadSizesObject
>
}
impl
MallocSizeOf
for
Database
{
fn
size_of
(
&
self
ops
:
&
mut
malloc_size_of
:
:
MallocSizeOfOps
)
-
>
usize
{
let
mut
n
=
0
;
n
+
=
self
.
rkv
.
size_of
(
ops
)
;
n
+
=
self
.
user_store
.
size_of
(
ops
)
;
n
+
=
self
.
ping_store
.
size_of
(
ops
)
;
n
+
=
self
.
application_store
.
size_of
(
ops
)
;
n
+
=
self
.
ping_lifetime_data
.
as_ref
(
)
.
map
(
|
data
|
{
let
lock
=
data
.
read
(
)
.
unwrap
(
)
;
(
*
lock
)
.
size_of
(
ops
)
}
)
.
unwrap_or
(
0
)
;
n
}
}
impl
std
:
:
fmt
:
:
Debug
for
Database
{
fn
fmt
(
&
self
fmt
:
&
mut
std
:
:
fmt
:
:
Formatter
)
-
>
std
:
:
fmt
:
:
Result
{
fmt
.
debug_struct
(
"
Database
"
)
.
field
(
"
rkv
"
&
self
.
rkv
)
.
field
(
"
user_store
"
&
"
SingleStore
"
)
.
field
(
"
ping_store
"
&
"
SingleStore
"
)
.
field
(
"
application_store
"
&
"
SingleStore
"
)
.
field
(
"
ping_lifetime_data
"
&
self
.
ping_lifetime_data
)
.
finish
(
)
}
}
fn
database_size
(
dir
:
&
Path
)
-
>
Option
<
NonZeroU64
>
{
let
mut
total_size
=
0
;
if
let
Ok
(
entries
)
=
fs
:
:
read_dir
(
dir
)
{
for
entry
in
entries
.
flatten
(
)
{
if
let
Ok
(
file_type
)
=
entry
.
file_type
(
)
{
if
file_type
.
is_file
(
)
{
let
path
=
entry
.
path
(
)
;
if
let
Ok
(
metadata
)
=
fs
:
:
metadata
(
path
)
{
total_size
+
=
metadata
.
len
(
)
;
}
else
{
continue
;
}
}
}
}
}
NonZeroU64
:
:
new
(
total_size
)
}
impl
Database
{
pub
fn
new
(
data_path
:
&
Path
delay_ping_lifetime_io
:
bool
ping_lifetime_threshold
:
usize
ping_lifetime_max_time
:
Duration
)
-
>
Result
<
Self
>
{
let
path
=
data_path
.
join
(
"
db
"
)
;
let
mut
load_sizes
=
LoadSizesObject
{
new
:
database_size
(
&
path
)
.
map
(
|
x
|
x
.
get
(
)
as
i64
)
.
.
Default
:
:
default
(
)
}
;
log
:
:
debug
!
(
"
Database
path
:
{
:
?
}
"
path
.
display
(
)
)
;
let
file_size
=
database_size
(
&
path
)
;
load_sizes
.
open
=
file_size
.
map
(
|
x
|
x
.
get
(
)
as
i64
)
;
let
(
rkv
rkv_load_state
)
=
Self
:
:
open_rkv
(
&
path
)
?
;
load_sizes
.
post_open
=
database_size
(
&
path
)
.
map
(
|
x
|
x
.
get
(
)
as
i64
)
;
let
user_store
=
rkv
.
open_single
(
Lifetime
:
:
User
.
as_str
(
)
StoreOptions
:
:
create
(
)
)
?
;
load_sizes
.
post_open_user
=
database_size
(
&
path
)
.
map
(
|
x
|
x
.
get
(
)
as
i64
)
;
let
ping_store
=
rkv
.
open_single
(
Lifetime
:
:
Ping
.
as_str
(
)
StoreOptions
:
:
create
(
)
)
?
;
let
application_store
=
rkv
.
open_single
(
Lifetime
:
:
Application
.
as_str
(
)
StoreOptions
:
:
create
(
)
)
?
;
let
ping_lifetime_data
=
if
delay_ping_lifetime_io
{
Some
(
RwLock
:
:
new
(
BTreeMap
:
:
new
(
)
)
)
}
else
{
None
}
;
let
write_timings
=
RefCell
:
:
new
(
Vec
:
:
with_capacity
(
64
)
)
;
let
now
=
Instant
:
:
now
(
)
;
let
mut
db
=
Self
{
rkv
user_store
ping_store
application_store
ping_lifetime_data
ping_lifetime_count
:
AtomicUsize
:
:
new
(
0
)
ping_lifetime_threshold
ping_lifetime_store_ts
:
Cell
:
:
new
(
now
)
ping_lifetime_max_time
file_size
rkv_load_state
write_timings
load_sizes
:
Some
(
load_sizes
)
}
;
db
.
load_ping_lifetime_data
(
)
;
db
.
load_sizes
.
as_mut
(
)
.
unwrap
(
)
.
post_load_ping_lifetime_data
=
database_size
(
&
path
)
.
map
(
|
x
|
x
.
get
(
)
as
i64
)
;
Ok
(
db
)
}
pub
fn
file_size
(
&
self
)
-
>
Option
<
NonZeroU64
>
{
self
.
file_size
}
pub
fn
rkv_load_state
(
&
self
)
-
>
Option
<
String
>
{
if
let
RkvLoadState
:
:
Err
(
e
)
=
&
self
.
rkv_load_state
{
Some
(
e
.
to_string
(
)
)
}
else
{
None
}
}
pub
fn
load_sizes
(
&
mut
self
)
-
>
Option
<
LoadSizesObject
>
{
self
.
load_sizes
.
take
(
)
}
fn
get_store
(
&
self
lifetime
:
Lifetime
)
-
>
&
SingleStore
{
match
lifetime
{
Lifetime
:
:
User
=
>
&
self
.
user_store
Lifetime
:
:
Ping
=
>
&
self
.
ping_store
Lifetime
:
:
Application
=
>
&
self
.
application_store
}
}
fn
open_rkv
(
path
:
&
Path
)
-
>
Result
<
(
Rkv
RkvLoadState
)
>
{
fs
:
:
create_dir_all
(
path
)
?
;
let
(
rkv
load_state
)
=
rkv_new
(
path
)
?
;
log
:
:
info
!
(
"
Database
initialized
"
)
;
Ok
(
(
rkv
load_state
)
)
}
fn
get_storage_key
(
storage_name
:
&
str
metric_key
:
Option
<
&
str
>
)
-
>
String
{
match
metric_key
{
Some
(
k
)
=
>
format
!
(
"
{
}
#
{
}
"
storage_name
k
)
None
=
>
format
!
(
"
{
}
#
"
storage_name
)
}
}
fn
load_ping_lifetime_data
(
&
self
)
{
if
let
Some
(
ping_lifetime_data
)
=
&
self
.
ping_lifetime_data
{
let
mut
data
=
ping_lifetime_data
.
write
(
)
.
expect
(
"
Can
'
t
read
ping
lifetime
data
"
)
;
let
reader
=
unwrap_or
!
(
self
.
rkv
.
read
(
)
return
)
;
let
store
=
self
.
get_store
(
Lifetime
:
:
Ping
)
;
let
mut
iter
=
unwrap_or
!
(
store
.
iter_start
(
&
reader
)
return
)
;
while
let
Some
(
Ok
(
(
metric_id
value
)
)
)
=
iter
.
next
(
)
{
let
metric_id
=
match
str
:
:
from_utf8
(
metric_id
)
{
Ok
(
metric_id
)
=
>
metric_id
.
to_string
(
)
_
=
>
continue
}
;
let
metric
:
Metric
=
match
value
{
rkv
:
:
Value
:
:
Blob
(
blob
)
=
>
unwrap_or
!
(
bincode
:
:
deserialize
(
blob
)
continue
)
_
=
>
continue
}
;
data
.
insert
(
metric_id
metric
)
;
}
}
}
pub
fn
iter_store_from
<
F
>
(
&
self
lifetime
:
Lifetime
storage_name
:
&
str
metric_key
:
Option
<
&
str
>
mut
transaction_fn
:
F
)
where
F
:
FnMut
(
&
[
u8
]
&
Metric
)
{
let
iter_start
=
Self
:
:
get_storage_key
(
storage_name
metric_key
)
;
let
len
=
iter_start
.
len
(
)
;
if
lifetime
=
=
Lifetime
:
:
Ping
{
if
let
Some
(
ping_lifetime_data
)
=
&
self
.
ping_lifetime_data
{
let
data
=
ping_lifetime_data
.
read
(
)
.
expect
(
"
Can
'
t
read
ping
lifetime
data
"
)
;
for
(
key
value
)
in
data
.
iter
(
)
{
if
key
.
starts_with
(
&
iter_start
)
{
let
key
=
&
key
[
len
.
.
]
;
transaction_fn
(
key
.
as_bytes
(
)
value
)
;
}
}
return
;
}
}
let
reader
=
unwrap_or
!
(
self
.
rkv
.
read
(
)
return
)
;
let
mut
iter
=
unwrap_or
!
(
self
.
get_store
(
lifetime
)
.
iter_from
(
&
reader
&
iter_start
)
return
)
;
while
let
Some
(
Ok
(
(
metric_id
value
)
)
)
=
iter
.
next
(
)
{
if
!
metric_id
.
starts_with
(
iter_start
.
as_bytes
(
)
)
{
break
;
}
let
metric_id
=
&
metric_id
[
len
.
.
]
;
let
metric
:
Metric
=
match
value
{
rkv
:
:
Value
:
:
Blob
(
blob
)
=
>
unwrap_or
!
(
bincode
:
:
deserialize
(
blob
)
continue
)
_
=
>
continue
}
;
transaction_fn
(
metric_id
&
metric
)
;
}
}
pub
fn
has_metric
(
&
self
lifetime
:
Lifetime
storage_name
:
&
str
metric_identifier
:
&
str
)
-
>
bool
{
let
key
=
Self
:
:
get_storage_key
(
storage_name
Some
(
metric_identifier
)
)
;
if
lifetime
=
=
Lifetime
:
:
Ping
{
if
let
Some
(
ping_lifetime_data
)
=
&
self
.
ping_lifetime_data
{
return
ping_lifetime_data
.
read
(
)
.
map
(
|
data
|
data
.
contains_key
(
&
key
)
)
.
unwrap_or
(
false
)
;
}
}
let
reader
=
unwrap_or
!
(
self
.
rkv
.
read
(
)
return
false
)
;
self
.
get_store
(
lifetime
)
.
get
(
&
reader
&
key
)
.
unwrap_or
(
None
)
.
is_some
(
)
}
fn
write_with_store
<
F
>
(
&
self
store_name
:
Lifetime
mut
transaction_fn
:
F
)
-
>
Result
<
(
)
>
where
F
:
FnMut
(
Writer
&
SingleStore
)
-
>
Result
<
(
)
>
{
let
writer
=
self
.
rkv
.
write
(
)
.
unwrap
(
)
;
let
store
=
self
.
get_store
(
store_name
)
;
transaction_fn
(
writer
store
)
}
pub
fn
record
(
&
self
glean
:
&
Glean
data
:
&
CommonMetricDataInternal
value
:
&
Metric
)
{
let
name
=
data
.
identifier
(
glean
)
;
for
ping_name
in
data
.
storage_names
(
)
{
if
glean
.
is_ping_enabled
(
ping_name
)
{
if
let
Err
(
e
)
=
self
.
record_per_lifetime
(
data
.
inner
.
lifetime
ping_name
&
name
value
)
{
log
:
:
error
!
(
"
Failed
to
record
metric
'
{
}
'
into
{
}
:
{
:
?
}
"
data
.
base_identifier
(
)
ping_name
e
)
;
}
}
}
}
fn
record_per_lifetime
(
&
self
lifetime
:
Lifetime
storage_name
:
&
str
key
:
&
str
metric
:
&
Metric
)
-
>
Result
<
(
)
>
{
let
final_key
=
Self
:
:
get_storage_key
(
storage_name
Some
(
key
)
)
;
if
lifetime
=
=
Lifetime
:
:
Ping
{
if
let
Some
(
ping_lifetime_data
)
=
&
self
.
ping_lifetime_data
{
let
mut
data
=
ping_lifetime_data
.
write
(
)
.
expect
(
"
Can
'
t
read
ping
lifetime
data
"
)
;
data
.
insert
(
final_key
metric
.
clone
(
)
)
;
self
.
persist_ping_lifetime_data_if_full
(
&
data
)
?
;
return
Ok
(
(
)
)
;
}
}
let
encoded
=
bincode
:
:
serialize
(
&
metric
)
.
expect
(
"
IMPOSSIBLE
:
Serializing
metric
failed
"
)
;
let
value
=
rkv
:
:
Value
:
:
Blob
(
&
encoded
)
;
let
mut
writer
=
self
.
rkv
.
write
(
)
?
;
self
.
get_store
(
lifetime
)
.
put
(
&
mut
writer
final_key
&
value
)
?
;
measure_commit
!
(
self
writer
.
commit
(
)
)
?
;
Ok
(
(
)
)
}
pub
fn
record_with
<
F
>
(
&
self
glean
:
&
Glean
data
:
&
CommonMetricDataInternal
mut
transform
:
F
)
where
F
:
FnMut
(
Option
<
Metric
>
)
-
>
Metric
{
let
name
=
data
.
identifier
(
glean
)
;
for
ping_name
in
data
.
storage_names
(
)
{
if
glean
.
is_ping_enabled
(
ping_name
)
{
if
let
Err
(
e
)
=
self
.
record_per_lifetime_with
(
data
.
inner
.
lifetime
ping_name
&
name
&
mut
transform
)
{
log
:
:
error
!
(
"
Failed
to
record
metric
'
{
}
'
into
{
}
:
{
:
?
}
"
data
.
base_identifier
(
)
ping_name
e
)
;
}
}
}
}
fn
record_per_lifetime_with
<
F
>
(
&
self
lifetime
:
Lifetime
storage_name
:
&
str
key
:
&
str
mut
transform
:
F
)
-
>
Result
<
(
)
>
where
F
:
FnMut
(
Option
<
Metric
>
)
-
>
Metric
{
let
final_key
=
Self
:
:
get_storage_key
(
storage_name
Some
(
key
)
)
;
if
lifetime
=
=
Lifetime
:
:
Ping
{
if
let
Some
(
ping_lifetime_data
)
=
&
self
.
ping_lifetime_data
{
let
mut
data
=
ping_lifetime_data
.
write
(
)
.
expect
(
"
Can
'
t
access
ping
lifetime
data
as
writable
"
)
;
let
entry
=
data
.
entry
(
final_key
)
;
match
entry
{
Entry
:
:
Vacant
(
entry
)
=
>
{
entry
.
insert
(
transform
(
None
)
)
;
}
Entry
:
:
Occupied
(
mut
entry
)
=
>
{
let
old_value
=
entry
.
get
(
)
.
clone
(
)
;
entry
.
insert
(
transform
(
Some
(
old_value
)
)
)
;
}
}
self
.
persist_ping_lifetime_data_if_full
(
&
data
)
?
;
return
Ok
(
(
)
)
;
}
}
let
mut
writer
=
self
.
rkv
.
write
(
)
?
;
let
store
=
self
.
get_store
(
lifetime
)
;
let
new_value
:
Metric
=
{
let
old_value
=
store
.
get
(
&
writer
&
final_key
)
?
;
match
old_value
{
Some
(
rkv
:
:
Value
:
:
Blob
(
blob
)
)
=
>
{
let
old_value
=
bincode
:
:
deserialize
(
blob
)
.
ok
(
)
;
transform
(
old_value
)
}
_
=
>
transform
(
None
)
}
}
;
let
encoded
=
bincode
:
:
serialize
(
&
new_value
)
.
expect
(
"
IMPOSSIBLE
:
Serializing
metric
failed
"
)
;
let
value
=
rkv
:
:
Value
:
:
Blob
(
&
encoded
)
;
store
.
put
(
&
mut
writer
final_key
&
value
)
?
;
measure_commit
!
(
self
writer
.
commit
(
)
)
?
;
Ok
(
(
)
)
}
pub
fn
clear_ping_lifetime_storage
(
&
self
storage_name
:
&
str
)
-
>
Result
<
(
)
>
{
if
let
Some
(
ping_lifetime_data
)
=
&
self
.
ping_lifetime_data
{
ping_lifetime_data
.
write
(
)
.
expect
(
"
Can
'
t
access
ping
lifetime
data
as
writable
"
)
.
retain
(
|
metric_id
_
|
!
metric_id
.
starts_with
(
storage_name
)
)
;
}
self
.
write_with_store
(
Lifetime
:
:
Ping
|
mut
writer
store
|
{
let
mut
metrics
=
Vec
:
:
new
(
)
;
{
let
mut
iter
=
store
.
iter_from
(
&
writer
storage_name
)
?
;
while
let
Some
(
Ok
(
(
metric_id
_
)
)
)
=
iter
.
next
(
)
{
if
let
Ok
(
metric_id
)
=
std
:
:
str
:
:
from_utf8
(
metric_id
)
{
if
!
metric_id
.
starts_with
(
storage_name
)
{
break
;
}
metrics
.
push
(
metric_id
.
to_owned
(
)
)
;
}
}
}
let
mut
res
=
Ok
(
(
)
)
;
for
to_delete
in
metrics
{
if
let
Err
(
e
)
=
store
.
delete
(
&
mut
writer
to_delete
)
{
log
:
:
warn
!
(
"
Can
'
t
delete
from
store
:
{
:
?
}
"
e
)
;
res
=
Err
(
e
)
;
}
}
measure_commit
!
(
self
writer
.
commit
(
)
)
?
;
Ok
(
res
?
)
}
)
}
pub
fn
clear_lifetime_storage
(
&
self
lifetime
:
Lifetime
storage_name
:
&
str
)
-
>
Result
<
(
)
>
{
self
.
write_with_store
(
lifetime
|
mut
writer
store
|
{
let
mut
metrics
=
Vec
:
:
new
(
)
;
{
let
mut
iter
=
store
.
iter_from
(
&
writer
storage_name
)
?
;
while
let
Some
(
Ok
(
(
metric_id
_
)
)
)
=
iter
.
next
(
)
{
if
let
Ok
(
metric_id
)
=
std
:
:
str
:
:
from_utf8
(
metric_id
)
{
if
!
metric_id
.
starts_with
(
storage_name
)
{
break
;
}
metrics
.
push
(
metric_id
.
to_owned
(
)
)
;
}
}
}
let
mut
res
=
Ok
(
(
)
)
;
for
to_delete
in
metrics
{
if
let
Err
(
e
)
=
store
.
delete
(
&
mut
writer
to_delete
)
{
log
:
:
warn
!
(
"
Can
'
t
delete
from
store
:
{
:
?
}
"
e
)
;
res
=
Err
(
e
)
;
}
}
measure_commit
!
(
self
writer
.
commit
(
)
)
?
;
Ok
(
res
?
)
}
)
}
pub
fn
remove_single_metric
(
&
self
lifetime
:
Lifetime
storage_name
:
&
str
metric_id
:
&
str
)
-
>
Result
<
(
)
>
{
let
final_key
=
Self
:
:
get_storage_key
(
storage_name
Some
(
metric_id
)
)
;
if
lifetime
=
=
Lifetime
:
:
Ping
{
if
let
Some
(
ping_lifetime_data
)
=
&
self
.
ping_lifetime_data
{
let
mut
data
=
ping_lifetime_data
.
write
(
)
.
expect
(
"
Can
'
t
access
app
lifetime
data
as
writable
"
)
;
data
.
remove
(
&
final_key
)
;
}
}
self
.
write_with_store
(
lifetime
|
mut
writer
store
|
{
if
let
Err
(
e
)
=
store
.
delete
(
&
mut
writer
final_key
.
clone
(
)
)
{
if
self
.
ping_lifetime_data
.
is_some
(
)
{
return
Ok
(
(
)
)
;
}
return
Err
(
e
.
into
(
)
)
;
}
measure_commit
!
(
self
writer
.
commit
(
)
)
?
;
Ok
(
(
)
)
}
)
}
pub
fn
clear_lifetime
(
&
self
lifetime
:
Lifetime
)
{
let
res
=
self
.
write_with_store
(
lifetime
|
mut
writer
store
|
{
store
.
clear
(
&
mut
writer
)
?
;
measure_commit
!
(
self
writer
.
commit
(
)
)
?
;
Ok
(
(
)
)
}
)
;
if
let
Err
(
e
)
=
res
{
if
let
ErrorKind
:
:
Rkv
(
StoreError
:
:
IoError
(
ioerr
)
)
=
e
.
kind
(
)
{
if
let
io
:
:
ErrorKind
:
:
NotFound
=
ioerr
.
kind
(
)
{
log
:
:
debug
!
(
"
Could
not
clear
store
for
lifetime
{
:
?
}
:
{
:
?
}
"
lifetime
ioerr
)
;
return
;
}
}
log
:
:
warn
!
(
"
Could
not
clear
store
for
lifetime
{
:
?
}
:
{
:
?
}
"
lifetime
e
)
;
}
}
pub
fn
clear_all
(
&
self
)
{
if
let
Some
(
ping_lifetime_data
)
=
&
self
.
ping_lifetime_data
{
ping_lifetime_data
.
write
(
)
.
expect
(
"
Can
'
t
access
ping
lifetime
data
as
writable
"
)
.
clear
(
)
;
}
for
lifetime
in
[
Lifetime
:
:
User
Lifetime
:
:
Ping
Lifetime
:
:
Application
]
.
iter
(
)
{
self
.
clear_lifetime
(
*
lifetime
)
;
}
}
pub
fn
persist_ping_lifetime_data
(
&
self
)
-
>
Result
<
(
)
>
{
if
let
Some
(
ping_lifetime_data
)
=
&
self
.
ping_lifetime_data
{
let
data
=
ping_lifetime_data
.
read
(
)
.
expect
(
"
Can
'
t
read
ping
lifetime
data
"
)
;
self
.
ping_lifetime_count
.
store
(
0
Ordering
:
:
Release
)
;
self
.
ping_lifetime_store_ts
.
replace
(
Instant
:
:
now
(
)
)
;
self
.
write_with_store
(
Lifetime
:
:
Ping
|
mut
writer
store
|
{
for
(
key
value
)
in
data
.
iter
(
)
{
let
encoded
=
bincode
:
:
serialize
(
&
value
)
.
expect
(
"
IMPOSSIBLE
:
Serializing
metric
failed
"
)
;
store
.
put
(
&
mut
writer
key
&
rkv
:
:
Value
:
:
Blob
(
&
encoded
)
)
?
;
}
measure_commit
!
(
self
writer
.
commit
(
)
)
?
;
Ok
(
(
)
)
}
)
?
;
}
Ok
(
(
)
)
}
pub
fn
persist_ping_lifetime_data_if_full
(
&
self
data
:
&
BTreeMap
<
String
Metric
>
)
-
>
Result
<
(
)
>
{
if
self
.
ping_lifetime_threshold
=
=
0
&
&
self
.
ping_lifetime_max_time
.
is_zero
(
)
{
return
Ok
(
(
)
)
;
}
let
write_count
=
self
.
ping_lifetime_count
.
fetch_add
(
1
Ordering
:
:
Release
)
+
1
;
let
last_write
=
self
.
ping_lifetime_store_ts
.
get
(
)
;
let
elapsed
=
last_write
.
elapsed
(
)
;
if
(
self
.
ping_lifetime_threshold
=
=
0
|
|
write_count
<
self
.
ping_lifetime_threshold
)
&
&
(
self
.
ping_lifetime_max_time
.
is_zero
(
)
|
|
elapsed
<
self
.
ping_lifetime_max_time
)
{
log
:
:
trace
!
(
"
Not
flushing
.
write_count
=
{
}
(
threshold
=
{
}
)
elapsed
=
{
:
?
}
(
max
=
{
:
?
}
)
"
write_count
self
.
ping_lifetime_threshold
elapsed
self
.
ping_lifetime_max_time
)
;
return
Ok
(
(
)
)
;
}
if
self
.
ping_lifetime_threshold
>
0
&
&
write_count
>
=
self
.
ping_lifetime_threshold
{
log
:
:
debug
!
(
"
Flushing
database
due
to
threshold
of
{
}
reached
.
"
self
.
ping_lifetime_threshold
)
}
else
if
!
self
.
ping_lifetime_max_time
.
is_zero
(
)
&
&
elapsed
>
=
self
.
ping_lifetime_max_time
{
log
:
:
debug
!
(
"
Flushing
database
due
to
last
write
more
than
{
:
?
}
ago
"
self
.
ping_lifetime_max_time
)
;
}
self
.
ping_lifetime_count
.
store
(
0
Ordering
:
:
Release
)
;
self
.
ping_lifetime_store_ts
.
replace
(
Instant
:
:
now
(
)
)
;
self
.
write_with_store
(
Lifetime
:
:
Ping
|
mut
writer
store
|
{
for
(
key
value
)
in
data
.
iter
(
)
{
let
encoded
=
bincode
:
:
serialize
(
&
value
)
.
expect
(
"
IMPOSSIBLE
:
Serializing
metric
failed
"
)
;
store
.
put
(
&
mut
writer
key
&
rkv
:
:
Value
:
:
Blob
(
&
encoded
)
)
?
;
}
writer
.
commit
(
)
?
;
Ok
(
(
)
)
}
)
}
}
#
[
cfg
(
test
)
]
mod
test
{
use
super
:
:
*
;
use
crate
:
:
tests
:
:
new_glean
;
use
std
:
:
collections
:
:
HashMap
;
use
tempfile
:
:
tempdir
;
#
[
test
]
fn
test_panicks_if_fails_dir_creation
(
)
{
let
path
=
Path
:
:
new
(
"
/
!
#
\
"
'
#
"
)
;
assert
!
(
Database
:
:
new
(
path
false
0
Duration
:
:
ZERO
)
.
is_err
(
)
)
;
}
#
[
test
]
#
[
cfg
(
windows
)
]
fn
windows_invalid_utf16_panicfree
(
)
{
use
std
:
:
ffi
:
:
OsString
;
use
std
:
:
os
:
:
windows
:
:
prelude
:
:
*
;
let
source
=
[
0x0066
0x006f
0xD800
0x006f
]
;
let
os_string
=
OsString
:
:
from_wide
(
&
source
[
.
.
]
)
;
let
os_str
=
os_string
.
as_os_str
(
)
;
let
dir
=
tempdir
(
)
.
unwrap
(
)
;
let
path
=
dir
.
path
(
)
.
join
(
os_str
)
;
let
res
=
Database
:
:
new
(
&
path
false
0
Duration
:
:
ZERO
)
;
assert
!
(
res
.
is_ok
(
)
"
Database
should
succeed
at
{
}
:
{
:
?
}
"
path
.
display
(
)
res
)
;
}
#
[
test
]
#
[
cfg
(
target_os
=
"
linux
"
)
]
fn
linux_invalid_utf8_panicfree
(
)
{
use
std
:
:
ffi
:
:
OsStr
;
use
std
:
:
os
:
:
unix
:
:
ffi
:
:
OsStrExt
;
let
source
=
[
0x66
0x6f
0x80
0x6f
]
;
let
os_str
=
OsStr
:
:
from_bytes
(
&
source
[
.
.
]
)
;
let
dir
=
tempdir
(
)
.
unwrap
(
)
;
let
path
=
dir
.
path
(
)
.
join
(
os_str
)
;
let
res
=
Database
:
:
new
(
&
path
false
0
Duration
:
:
ZERO
)
;
assert
!
(
res
.
is_ok
(
)
"
Database
should
not
fail
at
{
}
:
{
:
?
}
"
path
.
display
(
)
res
)
;
}
#
[
test
]
#
[
cfg
(
target_os
=
"
macos
"
)
]
fn
macos_invalid_utf8_panicfree
(
)
{
use
std
:
:
ffi
:
:
OsStr
;
use
std
:
:
os
:
:
unix
:
:
ffi
:
:
OsStrExt
;
let
source
=
[
0x66
0x6f
0x80
0x6f
]
;
let
os_str
=
OsStr
:
:
from_bytes
(
&
source
[
.
.
]
)
;
let
dir
=
tempdir
(
)
.
unwrap
(
)
;
let
path
=
dir
.
path
(
)
.
join
(
os_str
)
;
let
res
=
Database
:
:
new
(
&
path
false
0
Duration
:
:
ZERO
)
;
assert
!
(
res
.
is_err
(
)
"
Database
should
not
fail
at
{
}
:
{
:
?
}
"
path
.
display
(
)
res
)
;
}
#
[
test
]
fn
test_data_dir_rkv_inits
(
)
{
let
dir
=
tempdir
(
)
.
unwrap
(
)
;
Database
:
:
new
(
dir
.
path
(
)
false
0
Duration
:
:
ZERO
)
.
unwrap
(
)
;
assert
!
(
dir
.
path
(
)
.
exists
(
)
)
;
}
#
[
test
]
fn
test_ping_lifetime_metric_recorded
(
)
{
let
dir
=
tempdir
(
)
.
unwrap
(
)
;
let
db
=
Database
:
:
new
(
dir
.
path
(
)
false
0
Duration
:
:
ZERO
)
.
unwrap
(
)
;
assert
!
(
db
.
ping_lifetime_data
.
is_none
(
)
)
;
let
test_value
=
"
test
-
value
"
;
let
test_storage
=
"
test
-
storage
"
;
let
test_metric_id
=
"
telemetry_test
.
test_name
"
;
db
.
record_per_lifetime
(
Lifetime
:
:
Ping
test_storage
test_metric_id
&
Metric
:
:
String
(
test_value
.
to_string
(
)
)
)
.
unwrap
(
)
;
let
mut
found_metrics
=
0
;
let
mut
snapshotter
=
|
metric_id
:
&
[
u8
]
metric
:
&
Metric
|
{
found_metrics
+
=
1
;
let
metric_id
=
String
:
:
from_utf8_lossy
(
metric_id
)
.
into_owned
(
)
;
assert_eq
!
(
test_metric_id
metric_id
)
;
match
metric
{
Metric
:
:
String
(
s
)
=
>
assert_eq
!
(
test_value
s
)
_
=
>
panic
!
(
"
Unexpected
data
found
"
)
}
}
;
db
.
iter_store_from
(
Lifetime
:
:
Ping
test_storage
None
&
mut
snapshotter
)
;
assert_eq
!
(
1
found_metrics
"
We
only
expect
1
Lifetime
.
Ping
metric
.
"
)
;
}
#
[
test
]
fn
test_application_lifetime_metric_recorded
(
)
{
let
dir
=
tempdir
(
)
.
unwrap
(
)
;
let
db
=
Database
:
:
new
(
dir
.
path
(
)
false
0
Duration
:
:
ZERO
)
.
unwrap
(
)
;
let
test_value
=
"
test
-
value
"
;
let
test_storage
=
"
test
-
storage1
"
;
let
test_metric_id
=
"
telemetry_test
.
test_name
"
;
db
.
record_per_lifetime
(
Lifetime
:
:
Application
test_storage
test_metric_id
&
Metric
:
:
String
(
test_value
.
to_string
(
)
)
)
.
unwrap
(
)
;
let
mut
found_metrics
=
0
;
let
mut
snapshotter
=
|
metric_id
:
&
[
u8
]
metric
:
&
Metric
|
{
found_metrics
+
=
1
;
let
metric_id
=
String
:
:
from_utf8_lossy
(
metric_id
)
.
into_owned
(
)
;
assert_eq
!
(
test_metric_id
metric_id
)
;
match
metric
{
Metric
:
:
String
(
s
)
=
>
assert_eq
!
(
test_value
s
)
_
=
>
panic
!
(
"
Unexpected
data
found
"
)
}
}
;
db
.
iter_store_from
(
Lifetime
:
:
Application
test_storage
None
&
mut
snapshotter
)
;
assert_eq
!
(
1
found_metrics
"
We
only
expect
1
Lifetime
.
Application
metric
.
"
)
;
}
#
[
test
]
fn
test_user_lifetime_metric_recorded
(
)
{
let
dir
=
tempdir
(
)
.
unwrap
(
)
;
let
db
=
Database
:
:
new
(
dir
.
path
(
)
false
0
Duration
:
:
ZERO
)
.
unwrap
(
)
;
let
test_value
=
"
test
-
value
"
;
let
test_storage
=
"
test
-
storage2
"
;
let
test_metric_id
=
"
telemetry_test
.
test_name
"
;
db
.
record_per_lifetime
(
Lifetime
:
:
User
test_storage
test_metric_id
&
Metric
:
:
String
(
test_value
.
to_string
(
)
)
)
.
unwrap
(
)
;
let
mut
found_metrics
=
0
;
let
mut
snapshotter
=
|
metric_id
:
&
[
u8
]
metric
:
&
Metric
|
{
found_metrics
+
=
1
;
let
metric_id
=
String
:
:
from_utf8_lossy
(
metric_id
)
.
into_owned
(
)
;
assert_eq
!
(
test_metric_id
metric_id
)
;
match
metric
{
Metric
:
:
String
(
s
)
=
>
assert_eq
!
(
test_value
s
)
_
=
>
panic
!
(
"
Unexpected
data
found
"
)
}
}
;
db
.
iter_store_from
(
Lifetime
:
:
User
test_storage
None
&
mut
snapshotter
)
;
assert_eq
!
(
1
found_metrics
"
We
only
expect
1
Lifetime
.
User
metric
.
"
)
;
}
#
[
test
]
fn
test_clear_ping_storage
(
)
{
let
dir
=
tempdir
(
)
.
unwrap
(
)
;
let
db
=
Database
:
:
new
(
dir
.
path
(
)
false
0
Duration
:
:
ZERO
)
.
unwrap
(
)
;
let
test_storage
=
"
test
-
storage
"
;
db
.
record_per_lifetime
(
Lifetime
:
:
User
test_storage
"
telemetry_test
.
test_name_user
"
&
Metric
:
:
String
(
"
test
-
value
-
user
"
.
to_string
(
)
)
)
.
unwrap
(
)
;
db
.
record_per_lifetime
(
Lifetime
:
:
Ping
test_storage
"
telemetry_test
.
test_name_ping
"
&
Metric
:
:
String
(
"
test
-
value
-
ping
"
.
to_string
(
)
)
)
.
unwrap
(
)
;
db
.
record_per_lifetime
(
Lifetime
:
:
Application
test_storage
"
telemetry_test
.
test_name_application
"
&
Metric
:
:
String
(
"
test
-
value
-
application
"
.
to_string
(
)
)
)
.
unwrap
(
)
;
{
let
mut
snapshot
:
HashMap
<
String
String
>
=
HashMap
:
:
new
(
)
;
let
mut
snapshotter
=
|
metric_id
:
&
[
u8
]
metric
:
&
Metric
|
{
let
metric_id
=
String
:
:
from_utf8_lossy
(
metric_id
)
.
into_owned
(
)
;
match
metric
{
Metric
:
:
String
(
s
)
=
>
snapshot
.
insert
(
metric_id
s
.
to_string
(
)
)
_
=
>
panic
!
(
"
Unexpected
data
found
"
)
}
;
}
;
db
.
iter_store_from
(
Lifetime
:
:
User
test_storage
None
&
mut
snapshotter
)
;
db
.
iter_store_from
(
Lifetime
:
:
Ping
test_storage
None
&
mut
snapshotter
)
;
db
.
iter_store_from
(
Lifetime
:
:
Application
test_storage
None
&
mut
snapshotter
)
;
assert_eq
!
(
3
snapshot
.
len
(
)
"
We
expect
all
lifetimes
to
be
present
.
"
)
;
assert
!
(
snapshot
.
contains_key
(
"
telemetry_test
.
test_name_user
"
)
)
;
assert
!
(
snapshot
.
contains_key
(
"
telemetry_test
.
test_name_ping
"
)
)
;
assert
!
(
snapshot
.
contains_key
(
"
telemetry_test
.
test_name_application
"
)
)
;
}
db
.
clear_ping_lifetime_storage
(
test_storage
)
.
unwrap
(
)
;
{
let
mut
snapshot
:
HashMap
<
String
String
>
=
HashMap
:
:
new
(
)
;
let
mut
snapshotter
=
|
metric_id
:
&
[
u8
]
metric
:
&
Metric
|
{
let
metric_id
=
String
:
:
from_utf8_lossy
(
metric_id
)
.
into_owned
(
)
;
match
metric
{
Metric
:
:
String
(
s
)
=
>
snapshot
.
insert
(
metric_id
s
.
to_string
(
)
)
_
=
>
panic
!
(
"
Unexpected
data
found
"
)
}
;
}
;
db
.
iter_store_from
(
Lifetime
:
:
User
test_storage
None
&
mut
snapshotter
)
;
db
.
iter_store_from
(
Lifetime
:
:
Ping
test_storage
None
&
mut
snapshotter
)
;
db
.
iter_store_from
(
Lifetime
:
:
Application
test_storage
None
&
mut
snapshotter
)
;
assert_eq
!
(
2
snapshot
.
len
(
)
"
We
only
expect
2
metrics
to
be
left
.
"
)
;
assert
!
(
snapshot
.
contains_key
(
"
telemetry_test
.
test_name_user
"
)
)
;
assert
!
(
snapshot
.
contains_key
(
"
telemetry_test
.
test_name_application
"
)
)
;
}
}
#
[
test
]
fn
test_remove_single_metric
(
)
{
let
dir
=
tempdir
(
)
.
unwrap
(
)
;
let
db
=
Database
:
:
new
(
dir
.
path
(
)
false
0
Duration
:
:
ZERO
)
.
unwrap
(
)
;
let
test_storage
=
"
test
-
storage
-
single
-
lifetime
"
;
let
metric_id_pattern
=
"
telemetry_test
.
single_metric
"
;
let
lifetimes
=
[
Lifetime
:
:
User
Lifetime
:
:
Ping
Lifetime
:
:
Application
]
;
for
lifetime
in
lifetimes
.
iter
(
)
{
for
value
in
&
[
"
retain
"
"
delete
"
]
{
db
.
record_per_lifetime
(
*
lifetime
test_storage
&
format
!
(
"
{
}
_
{
}
"
metric_id_pattern
value
)
&
Metric
:
:
String
(
(
*
value
)
.
to_string
(
)
)
)
.
unwrap
(
)
;
}
}
for
lifetime
in
lifetimes
.
iter
(
)
{
db
.
remove_single_metric
(
*
lifetime
test_storage
&
format
!
(
"
{
}
_delete
"
metric_id_pattern
)
)
.
unwrap
(
)
;
}
for
lifetime
in
lifetimes
.
iter
(
)
{
let
mut
found_metrics
=
0
;
let
mut
snapshotter
=
|
metric_id
:
&
[
u8
]
metric
:
&
Metric
|
{
found_metrics
+
=
1
;
let
metric_id
=
String
:
:
from_utf8_lossy
(
metric_id
)
.
into_owned
(
)
;
assert_eq
!
(
format
!
(
"
{
}
_retain
"
metric_id_pattern
)
metric_id
)
;
match
metric
{
Metric
:
:
String
(
s
)
=
>
assert_eq
!
(
"
retain
"
s
)
_
=
>
panic
!
(
"
Unexpected
data
found
"
)
}
}
;
db
.
iter_store_from
(
*
lifetime
test_storage
None
&
mut
snapshotter
)
;
assert_eq
!
(
1
found_metrics
"
We
only
expect
1
metric
for
this
lifetime
.
"
)
;
}
}
#
[
test
]
fn
test_delayed_ping_lifetime_persistence
(
)
{
let
dir
=
tempdir
(
)
.
unwrap
(
)
;
let
db
=
Database
:
:
new
(
dir
.
path
(
)
true
0
Duration
:
:
ZERO
)
.
unwrap
(
)
;
let
test_storage
=
"
test
-
storage
"
;
assert
!
(
db
.
ping_lifetime_data
.
is_some
(
)
)
;
let
test_value1
=
"
test
-
value1
"
;
let
test_metric_id1
=
"
telemetry_test
.
test_name1
"
;
db
.
record_per_lifetime
(
Lifetime
:
:
Ping
test_storage
test_metric_id1
&
Metric
:
:
String
(
test_value1
.
to_string
(
)
)
)
.
unwrap
(
)
;
db
.
persist_ping_lifetime_data
(
)
.
unwrap
(
)
;
let
test_value2
=
"
test
-
value2
"
;
let
test_metric_id2
=
"
telemetry_test
.
test_name2
"
;
db
.
record_per_lifetime
(
Lifetime
:
:
Ping
test_storage
test_metric_id2
&
Metric
:
:
String
(
test_value2
.
to_string
(
)
)
)
.
unwrap
(
)
;
{
let
store
:
SingleStore
=
db
.
rkv
.
open_single
(
Lifetime
:
:
Ping
.
as_str
(
)
StoreOptions
:
:
create
(
)
)
.
unwrap
(
)
;
let
reader
=
db
.
rkv
.
read
(
)
.
unwrap
(
)
;
assert
!
(
store
.
get
(
&
reader
format
!
(
"
{
}
#
{
}
"
test_storage
test_metric_id1
)
)
.
unwrap_or
(
None
)
.
is_some
(
)
)
;
assert
!
(
store
.
get
(
&
reader
format
!
(
"
{
}
#
{
}
"
test_storage
test_metric_id2
)
)
.
unwrap_or
(
None
)
.
is_none
(
)
)
;
let
data
=
match
&
db
.
ping_lifetime_data
{
Some
(
ping_lifetime_data
)
=
>
ping_lifetime_data
None
=
>
panic
!
(
"
Expected
ping_lifetime_data
to
exist
here
!
"
)
}
;
let
data
=
data
.
read
(
)
.
unwrap
(
)
;
assert
!
(
data
.
get
(
&
format
!
(
"
{
}
#
{
}
"
test_storage
test_metric_id1
)
)
.
is_some
(
)
)
;
assert
!
(
data
.
get
(
&
format
!
(
"
{
}
#
{
}
"
test_storage
test_metric_id2
)
)
.
is_some
(
)
)
;
}
db
.
persist_ping_lifetime_data
(
)
.
unwrap
(
)
;
{
let
store
:
SingleStore
=
db
.
rkv
.
open_single
(
Lifetime
:
:
Ping
.
as_str
(
)
StoreOptions
:
:
create
(
)
)
.
unwrap
(
)
;
let
reader
=
db
.
rkv
.
read
(
)
.
unwrap
(
)
;
assert
!
(
store
.
get
(
&
reader
format
!
(
"
{
}
#
{
}
"
test_storage
test_metric_id1
)
)
.
unwrap_or
(
None
)
.
is_some
(
)
)
;
assert
!
(
store
.
get
(
&
reader
format
!
(
"
{
}
#
{
}
"
test_storage
test_metric_id2
)
)
.
unwrap_or
(
None
)
.
is_some
(
)
)
;
let
data
=
match
&
db
.
ping_lifetime_data
{
Some
(
ping_lifetime_data
)
=
>
ping_lifetime_data
None
=
>
panic
!
(
"
Expected
ping_lifetime_data
to
exist
here
!
"
)
}
;
let
data
=
data
.
read
(
)
.
unwrap
(
)
;
assert
!
(
data
.
get
(
&
format
!
(
"
{
}
#
{
}
"
test_storage
test_metric_id1
)
)
.
is_some
(
)
)
;
assert
!
(
data
.
get
(
&
format
!
(
"
{
}
#
{
}
"
test_storage
test_metric_id2
)
)
.
is_some
(
)
)
;
}
}
#
[
test
]
fn
test_load_ping_lifetime_data_from_memory
(
)
{
let
dir
=
tempdir
(
)
.
unwrap
(
)
;
let
test_storage
=
"
test
-
storage
"
;
let
test_value
=
"
test
-
value
"
;
let
test_metric_id
=
"
telemetry_test
.
test_name
"
;
{
let
db
=
Database
:
:
new
(
dir
.
path
(
)
true
0
Duration
:
:
ZERO
)
.
unwrap
(
)
;
db
.
record_per_lifetime
(
Lifetime
:
:
Ping
test_storage
test_metric_id
&
Metric
:
:
String
(
test_value
.
to_string
(
)
)
)
.
unwrap
(
)
;
let
data
=
match
&
db
.
ping_lifetime_data
{
Some
(
ping_lifetime_data
)
=
>
ping_lifetime_data
None
=
>
panic
!
(
"
Expected
ping_lifetime_data
to
exist
here
!
"
)
}
;
let
data
=
data
.
read
(
)
.
unwrap
(
)
;
assert
!
(
data
.
get
(
&
format
!
(
"
{
}
#
{
}
"
test_storage
test_metric_id
)
)
.
is_some
(
)
)
;
db
.
persist_ping_lifetime_data
(
)
.
unwrap
(
)
;
let
store
:
SingleStore
=
db
.
rkv
.
open_single
(
Lifetime
:
:
Ping
.
as_str
(
)
StoreOptions
:
:
create
(
)
)
.
unwrap
(
)
;
let
reader
=
db
.
rkv
.
read
(
)
.
unwrap
(
)
;
assert
!
(
store
.
get
(
&
reader
format
!
(
"
{
}
#
{
}
"
test_storage
test_metric_id
)
)
.
unwrap_or
(
None
)
.
is_some
(
)
)
;
}
{
let
db
=
Database
:
:
new
(
dir
.
path
(
)
true
0
Duration
:
:
ZERO
)
.
unwrap
(
)
;
let
data
=
match
&
db
.
ping_lifetime_data
{
Some
(
ping_lifetime_data
)
=
>
ping_lifetime_data
None
=
>
panic
!
(
"
Expected
ping_lifetime_data
to
exist
here
!
"
)
}
;
let
data
=
data
.
read
(
)
.
unwrap
(
)
;
assert
!
(
data
.
get
(
&
format
!
(
"
{
}
#
{
}
"
test_storage
test_metric_id
)
)
.
is_some
(
)
)
;
let
store
:
SingleStore
=
db
.
rkv
.
open_single
(
Lifetime
:
:
Ping
.
as_str
(
)
StoreOptions
:
:
create
(
)
)
.
unwrap
(
)
;
let
reader
=
db
.
rkv
.
read
(
)
.
unwrap
(
)
;
assert
!
(
store
.
get
(
&
reader
format
!
(
"
{
}
#
{
}
"
test_storage
test_metric_id
)
)
.
unwrap_or
(
None
)
.
is_some
(
)
)
;
}
}
#
[
test
]
fn
test_delayed_ping_lifetime_clear
(
)
{
let
dir
=
tempdir
(
)
.
unwrap
(
)
;
let
db
=
Database
:
:
new
(
dir
.
path
(
)
true
0
Duration
:
:
ZERO
)
.
unwrap
(
)
;
let
test_storage
=
"
test
-
storage
"
;
assert
!
(
db
.
ping_lifetime_data
.
is_some
(
)
)
;
let
test_value1
=
"
test
-
value1
"
;
let
test_metric_id1
=
"
telemetry_test
.
test_name1
"
;
db
.
record_per_lifetime
(
Lifetime
:
:
Ping
test_storage
test_metric_id1
&
Metric
:
:
String
(
test_value1
.
to_string
(
)
)
)
.
unwrap
(
)
;
{
let
data
=
match
&
db
.
ping_lifetime_data
{
Some
(
ping_lifetime_data
)
=
>
ping_lifetime_data
None
=
>
panic
!
(
"
Expected
ping_lifetime_data
to
exist
here
!
"
)
}
;
let
data
=
data
.
read
(
)
.
unwrap
(
)
;
assert
!
(
data
.
get
(
&
format
!
(
"
{
}
#
{
}
"
test_storage
test_metric_id1
)
)
.
is_some
(
)
)
;
}
db
.
clear_ping_lifetime_storage
(
&
(
test_storage
.
to_owned
(
)
+
"
x
"
)
)
.
unwrap
(
)
;
{
let
data
=
match
&
db
.
ping_lifetime_data
{
Some
(
ping_lifetime_data
)
=
>
ping_lifetime_data
None
=
>
panic
!
(
"
Expected
ping_lifetime_data
to
exist
here
!
"
)
}
;
let
data
=
data
.
read
(
)
.
unwrap
(
)
;
assert
!
(
data
.
get
(
&
format
!
(
"
{
}
#
{
}
"
test_storage
test_metric_id1
)
)
.
is_some
(
)
)
;
}
db
.
clear_ping_lifetime_storage
(
test_storage
)
.
unwrap
(
)
;
{
let
data
=
match
&
db
.
ping_lifetime_data
{
Some
(
ping_lifetime_data
)
=
>
ping_lifetime_data
None
=
>
panic
!
(
"
Expected
ping_lifetime_data
to
exist
here
!
"
)
}
;
let
data
=
data
.
read
(
)
.
unwrap
(
)
;
assert
!
(
data
.
get
(
&
format
!
(
"
{
}
#
{
}
"
test_storage
test_metric_id1
)
)
.
is_none
(
)
)
;
}
}
#
[
test
]
fn
doesnt_record_when_upload_is_disabled
(
)
{
let
(
mut
glean
dir
)
=
new_glean
(
None
)
;
let
test_storage
=
"
test
-
storage
"
;
let
test_data
=
CommonMetricDataInternal
:
:
new
(
"
category
"
"
name
"
test_storage
)
;
let
test_metric_id
=
test_data
.
identifier
(
&
glean
)
;
let
db
=
Database
:
:
new
(
dir
.
path
(
)
true
0
Duration
:
:
ZERO
)
.
unwrap
(
)
;
db
.
record
(
&
glean
&
test_data
&
Metric
:
:
String
(
"
record
"
.
to_owned
(
)
)
)
;
db
.
iter_store_from
(
Lifetime
:
:
Ping
test_storage
None
&
mut
|
metric_id
:
&
[
u8
]
metric
:
&
Metric
|
{
assert_eq
!
(
String
:
:
from_utf8_lossy
(
metric_id
)
.
into_owned
(
)
test_metric_id
)
;
match
metric
{
Metric
:
:
String
(
v
)
=
>
assert_eq
!
(
"
record
"
*
v
)
_
=
>
panic
!
(
"
Unexpected
data
found
"
)
}
}
)
;
db
.
record_with
(
&
glean
&
test_data
|
_
|
{
Metric
:
:
String
(
"
record_with
"
.
to_owned
(
)
)
}
)
;
db
.
iter_store_from
(
Lifetime
:
:
Ping
test_storage
None
&
mut
|
metric_id
:
&
[
u8
]
metric
:
&
Metric
|
{
assert_eq
!
(
String
:
:
from_utf8_lossy
(
metric_id
)
.
into_owned
(
)
test_metric_id
)
;
match
metric
{
Metric
:
:
String
(
v
)
=
>
assert_eq
!
(
"
record_with
"
*
v
)
_
=
>
panic
!
(
"
Unexpected
data
found
"
)
}
}
)
;
glean
.
set_upload_enabled
(
false
)
;
db
.
record
(
&
glean
&
test_data
&
Metric
:
:
String
(
"
record_nop
"
.
to_owned
(
)
)
)
;
db
.
iter_store_from
(
Lifetime
:
:
Ping
test_storage
None
&
mut
|
metric_id
:
&
[
u8
]
metric
:
&
Metric
|
{
assert_eq
!
(
String
:
:
from_utf8_lossy
(
metric_id
)
.
into_owned
(
)
test_metric_id
)
;
match
metric
{
Metric
:
:
String
(
v
)
=
>
assert_eq
!
(
"
record_with
"
*
v
)
_
=
>
panic
!
(
"
Unexpected
data
found
"
)
}
}
)
;
db
.
record_with
(
&
glean
&
test_data
|
_
|
{
Metric
:
:
String
(
"
record_with_nop
"
.
to_owned
(
)
)
}
)
;
db
.
iter_store_from
(
Lifetime
:
:
Ping
test_storage
None
&
mut
|
metric_id
:
&
[
u8
]
metric
:
&
Metric
|
{
assert_eq
!
(
String
:
:
from_utf8_lossy
(
metric_id
)
.
into_owned
(
)
test_metric_id
)
;
match
metric
{
Metric
:
:
String
(
v
)
=
>
assert_eq
!
(
"
record_with
"
*
v
)
_
=
>
panic
!
(
"
Unexpected
data
found
"
)
}
}
)
;
}
mod
safe_mode
{
use
std
:
:
fs
:
:
File
;
use
super
:
:
*
;
#
[
test
]
fn
empty_data_file
(
)
{
let
dir
=
tempdir
(
)
.
unwrap
(
)
;
let
database_dir
=
dir
.
path
(
)
.
join
(
"
db
"
)
;
fs
:
:
create_dir_all
(
&
database_dir
)
.
expect
(
"
create
database
dir
"
)
;
let
safebin
=
database_dir
.
join
(
"
data
.
safe
.
bin
"
)
;
let
f
=
File
:
:
create
(
safebin
)
.
expect
(
"
create
database
file
"
)
;
drop
(
f
)
;
let
db
=
Database
:
:
new
(
dir
.
path
(
)
false
0
Duration
:
:
ZERO
)
.
unwrap
(
)
;
assert
!
(
dir
.
path
(
)
.
exists
(
)
)
;
assert
!
(
matches
!
(
db
.
rkv_load_state
RkvLoadState
:
:
Err
(
_
)
)
"
Load
error
recorded
"
)
;
}
#
[
test
]
fn
corrupted_data_file
(
)
{
let
dir
=
tempdir
(
)
.
unwrap
(
)
;
let
database_dir
=
dir
.
path
(
)
.
join
(
"
db
"
)
;
fs
:
:
create_dir_all
(
&
database_dir
)
.
expect
(
"
create
database
dir
"
)
;
let
safebin
=
database_dir
.
join
(
"
data
.
safe
.
bin
"
)
;
fs
:
:
write
(
safebin
"
<
broken
>
"
)
.
expect
(
"
write
to
database
file
"
)
;
let
db
=
Database
:
:
new
(
dir
.
path
(
)
false
0
Duration
:
:
ZERO
)
.
unwrap
(
)
;
assert
!
(
dir
.
path
(
)
.
exists
(
)
)
;
assert
!
(
matches
!
(
db
.
rkv_load_state
RkvLoadState
:
:
Err
(
_
)
)
"
Load
error
recorded
"
)
;
}
}
}
