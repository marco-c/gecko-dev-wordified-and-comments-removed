use
crate
:
:
RngCore
;
use
core
:
:
cmp
:
:
min
;
pub
fn
next_u64_via_u32
<
R
:
RngCore
+
?
Sized
>
(
rng
:
&
mut
R
)
-
>
u64
{
let
x
=
u64
:
:
from
(
rng
.
next_u32
(
)
)
;
let
y
=
u64
:
:
from
(
rng
.
next_u32
(
)
)
;
(
y
<
<
32
)
|
x
}
pub
fn
fill_bytes_via_next
<
R
:
RngCore
+
?
Sized
>
(
rng
:
&
mut
R
dest
:
&
mut
[
u8
]
)
{
let
mut
left
=
dest
;
while
left
.
len
(
)
>
=
8
{
let
(
l
r
)
=
{
left
}
.
split_at_mut
(
8
)
;
left
=
r
;
let
chunk
:
[
u8
;
8
]
=
rng
.
next_u64
(
)
.
to_le_bytes
(
)
;
l
.
copy_from_slice
(
&
chunk
)
;
}
let
n
=
left
.
len
(
)
;
if
n
>
4
{
let
chunk
:
[
u8
;
8
]
=
rng
.
next_u64
(
)
.
to_le_bytes
(
)
;
left
.
copy_from_slice
(
&
chunk
[
.
.
n
]
)
;
}
else
if
n
>
0
{
let
chunk
:
[
u8
;
4
]
=
rng
.
next_u32
(
)
.
to_le_bytes
(
)
;
left
.
copy_from_slice
(
&
chunk
[
.
.
n
]
)
;
}
}
macro_rules
!
fill_via_chunks
{
(
src
:
expr
dst
:
expr
ty
:
ty
)
=
>
{
{
const
SIZE
:
usize
=
core
:
:
mem
:
:
size_of
:
:
<
ty
>
(
)
;
let
chunk_size_u8
=
min
(
src
.
len
(
)
*
SIZE
dst
.
len
(
)
)
;
let
chunk_size
=
(
chunk_size_u8
+
SIZE
-
1
)
/
SIZE
;
/
/
The
following
can
be
replaced
with
safe
code
but
unfortunately
it
'
s
/
/
ca
.
8
%
slower
.
if
cfg
!
(
target_endian
=
"
little
"
)
{
unsafe
{
core
:
:
ptr
:
:
copy_nonoverlapping
(
src
.
as_ptr
(
)
as
*
const
u8
dst
.
as_mut_ptr
(
)
chunk_size_u8
)
;
}
}
else
{
for
(
&
n
chunk
)
in
src
.
iter
(
)
.
zip
(
dst
.
chunks_mut
(
SIZE
)
)
{
let
tmp
=
n
.
to_le
(
)
;
let
src_ptr
=
&
tmp
as
*
const
ty
as
*
const
u8
;
unsafe
{
core
:
:
ptr
:
:
copy_nonoverlapping
(
src_ptr
chunk
.
as_mut_ptr
(
)
chunk
.
len
(
)
)
;
}
}
}
(
chunk_size
chunk_size_u8
)
}
}
;
}
pub
fn
fill_via_u32_chunks
(
src
:
&
[
u32
]
dest
:
&
mut
[
u8
]
)
-
>
(
usize
usize
)
{
fill_via_chunks
!
(
src
dest
u32
)
}
pub
fn
fill_via_u64_chunks
(
src
:
&
[
u64
]
dest
:
&
mut
[
u8
]
)
-
>
(
usize
usize
)
{
fill_via_chunks
!
(
src
dest
u64
)
}
pub
fn
next_u32_via_fill
<
R
:
RngCore
+
?
Sized
>
(
rng
:
&
mut
R
)
-
>
u32
{
let
mut
buf
=
[
0
;
4
]
;
rng
.
fill_bytes
(
&
mut
buf
)
;
u32
:
:
from_le_bytes
(
buf
)
}
pub
fn
next_u64_via_fill
<
R
:
RngCore
+
?
Sized
>
(
rng
:
&
mut
R
)
-
>
u64
{
let
mut
buf
=
[
0
;
8
]
;
rng
.
fill_bytes
(
&
mut
buf
)
;
u64
:
:
from_le_bytes
(
buf
)
}
#
[
cfg
(
test
)
]
mod
test
{
use
super
:
:
*
;
#
[
test
]
fn
test_fill_via_u32_chunks
(
)
{
let
src
=
[
1
2
3
]
;
let
mut
dst
=
[
0u8
;
11
]
;
assert_eq
!
(
fill_via_u32_chunks
(
&
src
&
mut
dst
)
(
3
11
)
)
;
assert_eq
!
(
dst
[
1
0
0
0
2
0
0
0
3
0
0
]
)
;
let
mut
dst
=
[
0u8
;
13
]
;
assert_eq
!
(
fill_via_u32_chunks
(
&
src
&
mut
dst
)
(
3
12
)
)
;
assert_eq
!
(
dst
[
1
0
0
0
2
0
0
0
3
0
0
0
0
]
)
;
let
mut
dst
=
[
0u8
;
5
]
;
assert_eq
!
(
fill_via_u32_chunks
(
&
src
&
mut
dst
)
(
2
5
)
)
;
assert_eq
!
(
dst
[
1
0
0
0
2
]
)
;
}
#
[
test
]
fn
test_fill_via_u64_chunks
(
)
{
let
src
=
[
1
2
]
;
let
mut
dst
=
[
0u8
;
11
]
;
assert_eq
!
(
fill_via_u64_chunks
(
&
src
&
mut
dst
)
(
2
11
)
)
;
assert_eq
!
(
dst
[
1
0
0
0
0
0
0
0
2
0
0
]
)
;
let
mut
dst
=
[
0u8
;
17
]
;
assert_eq
!
(
fill_via_u64_chunks
(
&
src
&
mut
dst
)
(
2
16
)
)
;
assert_eq
!
(
dst
[
1
0
0
0
0
0
0
0
2
0
0
0
0
0
0
0
0
]
)
;
let
mut
dst
=
[
0u8
;
5
]
;
assert_eq
!
(
fill_via_u64_chunks
(
&
src
&
mut
dst
)
(
1
5
)
)
;
assert_eq
!
(
dst
[
1
0
0
0
0
]
)
;
}
}
