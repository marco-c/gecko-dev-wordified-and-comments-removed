extern
crate
crossbeam_epoch
as
epoch
;
extern
crate
crossbeam_utils
as
utils
;
use
std
:
:
cmp
;
use
std
:
:
fmt
;
use
std
:
:
marker
:
:
PhantomData
;
use
std
:
:
mem
;
use
std
:
:
ptr
;
use
std
:
:
sync
:
:
Arc
;
use
std
:
:
sync
:
:
atomic
:
:
{
self
AtomicIsize
}
;
use
std
:
:
sync
:
:
atomic
:
:
Ordering
:
:
{
Acquire
Relaxed
Release
SeqCst
}
;
use
epoch
:
:
{
Atomic
Owned
}
;
use
utils
:
:
cache_padded
:
:
CachePadded
;
const
DEFAULT_MIN_CAP
:
usize
=
16
;
const
FLUSH_THRESHOLD_BYTES
:
usize
=
1
<
<
10
;
#
[
derive
(
Debug
PartialEq
Eq
PartialOrd
Ord
Copy
Clone
)
]
pub
enum
Steal
<
T
>
{
Empty
Data
(
T
)
Retry
}
struct
Buffer
<
T
>
{
ptr
:
*
mut
T
cap
:
usize
}
unsafe
impl
<
T
>
Send
for
Buffer
<
T
>
{
}
impl
<
T
>
Buffer
<
T
>
{
fn
new
(
cap
:
usize
)
-
>
Self
{
debug_assert_eq
!
(
cap
cap
.
next_power_of_two
(
)
)
;
let
mut
v
=
Vec
:
:
with_capacity
(
cap
)
;
let
ptr
=
v
.
as_mut_ptr
(
)
;
mem
:
:
forget
(
v
)
;
Buffer
{
ptr
cap
}
}
unsafe
fn
at
(
&
self
index
:
isize
)
-
>
*
mut
T
{
self
.
ptr
.
offset
(
index
&
(
self
.
cap
-
1
)
as
isize
)
}
unsafe
fn
write
(
&
self
index
:
isize
value
:
T
)
{
ptr
:
:
write
(
self
.
at
(
index
)
value
)
}
unsafe
fn
read
(
&
self
index
:
isize
)
-
>
T
{
ptr
:
:
read
(
self
.
at
(
index
)
)
}
}
impl
<
T
>
Drop
for
Buffer
<
T
>
{
fn
drop
(
&
mut
self
)
{
unsafe
{
drop
(
Vec
:
:
from_raw_parts
(
self
.
ptr
0
self
.
cap
)
)
;
}
}
}
struct
Inner
<
T
>
{
bottom
:
AtomicIsize
top
:
AtomicIsize
buffer
:
Atomic
<
Buffer
<
T
>
>
min_cap
:
usize
}
impl
<
T
>
Inner
<
T
>
{
fn
new
(
)
-
>
Self
{
Self
:
:
with_min_capacity
(
DEFAULT_MIN_CAP
)
}
fn
with_min_capacity
(
min_cap
:
usize
)
-
>
Self
{
let
power
=
min_cap
.
next_power_of_two
(
)
;
assert
!
(
power
>
=
min_cap
"
capacity
too
large
:
{
}
"
min_cap
)
;
Inner
{
bottom
:
AtomicIsize
:
:
new
(
0
)
top
:
AtomicIsize
:
:
new
(
0
)
buffer
:
Atomic
:
:
new
(
Buffer
:
:
new
(
power
)
)
min_cap
:
power
}
}
#
[
cold
]
unsafe
fn
resize
(
&
self
new_cap
:
usize
)
{
let
b
=
self
.
bottom
.
load
(
Relaxed
)
;
let
t
=
self
.
top
.
load
(
Relaxed
)
;
let
buffer
=
self
.
buffer
.
load
(
Relaxed
epoch
:
:
unprotected
(
)
)
;
let
new
=
Buffer
:
:
new
(
new_cap
)
;
let
mut
i
=
t
;
while
i
!
=
b
{
ptr
:
:
copy_nonoverlapping
(
buffer
.
deref
(
)
.
at
(
i
)
new
.
at
(
i
)
1
)
;
i
=
i
.
wrapping_add
(
1
)
;
}
let
guard
=
&
epoch
:
:
pin
(
)
;
let
old
=
self
.
buffer
.
swap
(
Owned
:
:
new
(
new
)
.
into_shared
(
guard
)
Release
guard
)
;
guard
.
defer
(
move
|
|
old
.
into_owned
(
)
)
;
if
mem
:
:
size_of
:
:
<
T
>
(
)
*
new_cap
>
=
FLUSH_THRESHOLD_BYTES
{
guard
.
flush
(
)
;
}
}
}
impl
<
T
>
Drop
for
Inner
<
T
>
{
fn
drop
(
&
mut
self
)
{
let
b
=
self
.
bottom
.
load
(
Relaxed
)
;
let
t
=
self
.
top
.
load
(
Relaxed
)
;
unsafe
{
let
buffer
=
self
.
buffer
.
load
(
Relaxed
epoch
:
:
unprotected
(
)
)
;
let
mut
i
=
t
;
while
i
!
=
b
{
ptr
:
:
drop_in_place
(
buffer
.
deref
(
)
.
at
(
i
)
)
;
i
=
i
.
wrapping_add
(
1
)
;
}
drop
(
buffer
.
into_owned
(
)
)
;
}
}
}
pub
struct
Deque
<
T
>
{
inner
:
Arc
<
CachePadded
<
Inner
<
T
>
>
>
_marker
:
PhantomData
<
*
mut
(
)
>
}
unsafe
impl
<
T
:
Send
>
Send
for
Deque
<
T
>
{
}
impl
<
T
>
Deque
<
T
>
{
pub
fn
new
(
)
-
>
Deque
<
T
>
{
Deque
{
inner
:
Arc
:
:
new
(
CachePadded
:
:
new
(
Inner
:
:
new
(
)
)
)
_marker
:
PhantomData
}
}
pub
fn
with_min_capacity
(
min_cap
:
usize
)
-
>
Deque
<
T
>
{
Deque
{
inner
:
Arc
:
:
new
(
CachePadded
:
:
new
(
Inner
:
:
with_min_capacity
(
min_cap
)
)
)
_marker
:
PhantomData
}
}
pub
fn
is_empty
(
&
self
)
-
>
bool
{
self
.
len
(
)
=
=
0
}
pub
fn
len
(
&
self
)
-
>
usize
{
let
b
=
self
.
inner
.
bottom
.
load
(
Relaxed
)
;
let
t
=
self
.
inner
.
top
.
load
(
Relaxed
)
;
b
.
wrapping_sub
(
t
)
as
usize
}
pub
fn
min_capacity
(
&
self
)
-
>
usize
{
self
.
inner
.
min_cap
}
pub
fn
capacity
(
&
self
)
-
>
usize
{
unsafe
{
let
buf
=
self
.
inner
.
buffer
.
load
(
Relaxed
epoch
:
:
unprotected
(
)
)
;
buf
.
deref
(
)
.
cap
}
}
pub
fn
shrink_to_fit
(
&
self
)
{
let
b
=
self
.
inner
.
bottom
.
load
(
Relaxed
)
;
let
t
=
self
.
inner
.
top
.
load
(
Acquire
)
;
let
cap
=
self
.
capacity
(
)
;
let
len
=
b
.
wrapping_sub
(
t
)
;
let
mut
new_cap
=
cap
;
while
self
.
inner
.
min_cap
<
=
new_cap
/
2
&
&
len
<
=
new_cap
as
isize
/
2
{
new_cap
/
=
2
;
}
if
new_cap
!
=
cap
{
unsafe
{
self
.
inner
.
resize
(
new_cap
)
;
}
}
}
pub
fn
push
(
&
self
value
:
T
)
{
unsafe
{
let
b
=
self
.
inner
.
bottom
.
load
(
Relaxed
)
;
let
t
=
self
.
inner
.
top
.
load
(
Acquire
)
;
let
mut
buffer
=
self
.
inner
.
buffer
.
load
(
Relaxed
epoch
:
:
unprotected
(
)
)
;
let
len
=
b
.
wrapping_sub
(
t
)
;
let
cap
=
buffer
.
deref
(
)
.
cap
;
if
len
>
=
cap
as
isize
{
self
.
inner
.
resize
(
2
*
cap
)
;
buffer
=
self
.
inner
.
buffer
.
load
(
Relaxed
epoch
:
:
unprotected
(
)
)
;
}
else
if
cap
>
self
.
inner
.
min_cap
&
&
len
+
1
<
cap
as
isize
/
4
{
self
.
inner
.
resize
(
cap
/
2
)
;
buffer
=
self
.
inner
.
buffer
.
load
(
Relaxed
epoch
:
:
unprotected
(
)
)
;
}
buffer
.
deref
(
)
.
write
(
b
value
)
;
atomic
:
:
fence
(
Release
)
;
self
.
inner
.
bottom
.
store
(
b
.
wrapping_add
(
1
)
Relaxed
)
;
}
}
pub
fn
pop
(
&
self
)
-
>
Option
<
T
>
{
let
b
=
self
.
inner
.
bottom
.
load
(
Relaxed
)
;
let
t
=
self
.
inner
.
top
.
load
(
Relaxed
)
;
if
b
.
wrapping_sub
(
t
)
<
=
0
{
return
None
;
}
let
b
=
b
.
wrapping_sub
(
1
)
;
self
.
inner
.
bottom
.
store
(
b
Relaxed
)
;
let
buf
=
unsafe
{
self
.
inner
.
buffer
.
load
(
Relaxed
epoch
:
:
unprotected
(
)
)
}
;
atomic
:
:
fence
(
SeqCst
)
;
let
t
=
self
.
inner
.
top
.
load
(
Relaxed
)
;
let
len
=
b
.
wrapping_sub
(
t
)
;
if
len
<
0
{
self
.
inner
.
bottom
.
store
(
b
.
wrapping_add
(
1
)
Relaxed
)
;
None
}
else
{
let
mut
value
=
unsafe
{
Some
(
buf
.
deref
(
)
.
read
(
b
)
)
}
;
if
len
=
=
0
{
if
self
.
inner
.
top
.
compare_exchange
(
t
t
.
wrapping_add
(
1
)
SeqCst
Relaxed
)
.
is_err
(
)
{
mem
:
:
forget
(
value
.
take
(
)
)
;
}
self
.
inner
.
bottom
.
store
(
b
.
wrapping_add
(
1
)
Relaxed
)
;
}
else
{
unsafe
{
let
cap
=
buf
.
deref
(
)
.
cap
;
if
cap
>
self
.
inner
.
min_cap
&
&
len
<
cap
as
isize
/
4
{
self
.
inner
.
resize
(
cap
/
2
)
;
}
}
}
value
}
}
pub
fn
steal
(
&
self
)
-
>
Steal
<
T
>
{
let
b
=
self
.
inner
.
bottom
.
load
(
Relaxed
)
;
let
buf
=
unsafe
{
self
.
inner
.
buffer
.
load
(
Relaxed
epoch
:
:
unprotected
(
)
)
}
;
let
t
=
self
.
inner
.
top
.
load
(
Relaxed
)
;
let
len
=
b
.
wrapping_sub
(
t
)
;
if
len
<
=
0
{
return
Steal
:
:
Empty
;
}
if
self
.
inner
.
top
.
compare_exchange
(
t
t
.
wrapping_add
(
1
)
SeqCst
Relaxed
)
.
is_ok
(
)
{
let
data
=
unsafe
{
buf
.
deref
(
)
.
read
(
t
)
}
;
unsafe
{
let
cap
=
buf
.
deref
(
)
.
cap
;
if
cap
>
self
.
inner
.
min_cap
&
&
len
<
=
cap
as
isize
/
4
{
self
.
inner
.
resize
(
cap
/
2
)
;
}
}
return
Steal
:
:
Data
(
data
)
;
}
Steal
:
:
Retry
}
pub
fn
stealer
(
&
self
)
-
>
Stealer
<
T
>
{
Stealer
{
inner
:
self
.
inner
.
clone
(
)
_marker
:
PhantomData
}
}
}
impl
<
T
>
fmt
:
:
Debug
for
Deque
<
T
>
{
fn
fmt
(
&
self
f
:
&
mut
fmt
:
:
Formatter
)
-
>
fmt
:
:
Result
{
write
!
(
f
"
Deque
{
{
.
.
.
}
}
"
)
}
}
impl
<
T
>
Default
for
Deque
<
T
>
{
fn
default
(
)
-
>
Deque
<
T
>
{
Deque
:
:
new
(
)
}
}
pub
struct
Stealer
<
T
>
{
inner
:
Arc
<
CachePadded
<
Inner
<
T
>
>
>
_marker
:
PhantomData
<
*
mut
(
)
>
}
unsafe
impl
<
T
:
Send
>
Send
for
Stealer
<
T
>
{
}
unsafe
impl
<
T
:
Send
>
Sync
for
Stealer
<
T
>
{
}
impl
<
T
>
Stealer
<
T
>
{
pub
fn
is_empty
(
&
self
)
-
>
bool
{
self
.
len
(
)
=
=
0
}
pub
fn
len
(
&
self
)
-
>
usize
{
let
t
=
self
.
inner
.
top
.
load
(
Relaxed
)
;
atomic
:
:
fence
(
SeqCst
)
;
let
b
=
self
.
inner
.
bottom
.
load
(
Relaxed
)
;
cmp
:
:
max
(
b
.
wrapping_sub
(
t
)
0
)
as
usize
}
pub
fn
steal
(
&
self
)
-
>
Steal
<
T
>
{
let
t
=
self
.
inner
.
top
.
load
(
Acquire
)
;
if
epoch
:
:
is_pinned
(
)
{
atomic
:
:
fence
(
SeqCst
)
;
}
let
guard
=
&
epoch
:
:
pin
(
)
;
let
b
=
self
.
inner
.
bottom
.
load
(
Acquire
)
;
if
b
.
wrapping_sub
(
t
)
<
=
0
{
return
Steal
:
:
Empty
;
}
let
buf
=
self
.
inner
.
buffer
.
load
(
Acquire
guard
)
;
let
value
=
unsafe
{
buf
.
deref
(
)
.
read
(
t
)
}
;
if
self
.
inner
.
top
.
compare_exchange
(
t
t
.
wrapping_add
(
1
)
SeqCst
Relaxed
)
.
is_ok
(
)
{
return
Steal
:
:
Data
(
value
)
;
}
mem
:
:
forget
(
value
)
;
Steal
:
:
Retry
}
}
impl
<
T
>
Clone
for
Stealer
<
T
>
{
fn
clone
(
&
self
)
-
>
Stealer
<
T
>
{
Stealer
{
inner
:
self
.
inner
.
clone
(
)
_marker
:
PhantomData
}
}
}
impl
<
T
>
fmt
:
:
Debug
for
Stealer
<
T
>
{
fn
fmt
(
&
self
f
:
&
mut
fmt
:
:
Formatter
)
-
>
fmt
:
:
Result
{
write
!
(
f
"
Stealer
{
{
.
.
.
}
}
"
)
}
}
#
[
cfg
(
test
)
]
mod
tests
{
extern
crate
rand
;
use
std
:
:
sync
:
:
{
Arc
Mutex
}
;
use
std
:
:
sync
:
:
atomic
:
:
{
AtomicBool
AtomicUsize
}
;
use
std
:
:
sync
:
:
atomic
:
:
Ordering
:
:
SeqCst
;
use
std
:
:
thread
;
use
epoch
;
use
self
:
:
rand
:
:
Rng
;
use
super
:
:
{
Deque
Steal
}
;
#
[
test
]
fn
smoke
(
)
{
let
d
=
Deque
:
:
new
(
)
;
let
s
=
d
.
stealer
(
)
;
assert_eq
!
(
d
.
pop
(
)
None
)
;
assert_eq
!
(
s
.
steal
(
)
Steal
:
:
Empty
)
;
assert_eq
!
(
d
.
len
(
)
0
)
;
assert_eq
!
(
s
.
len
(
)
0
)
;
d
.
push
(
1
)
;
assert_eq
!
(
d
.
len
(
)
1
)
;
assert_eq
!
(
s
.
len
(
)
1
)
;
assert_eq
!
(
d
.
pop
(
)
Some
(
1
)
)
;
assert_eq
!
(
d
.
pop
(
)
None
)
;
assert_eq
!
(
s
.
steal
(
)
Steal
:
:
Empty
)
;
assert_eq
!
(
d
.
len
(
)
0
)
;
assert_eq
!
(
s
.
len
(
)
0
)
;
d
.
push
(
2
)
;
assert_eq
!
(
s
.
steal
(
)
Steal
:
:
Data
(
2
)
)
;
assert_eq
!
(
s
.
steal
(
)
Steal
:
:
Empty
)
;
assert_eq
!
(
d
.
pop
(
)
None
)
;
d
.
push
(
3
)
;
d
.
push
(
4
)
;
d
.
push
(
5
)
;
assert_eq
!
(
d
.
steal
(
)
Steal
:
:
Data
(
3
)
)
;
assert_eq
!
(
s
.
steal
(
)
Steal
:
:
Data
(
4
)
)
;
assert_eq
!
(
d
.
steal
(
)
Steal
:
:
Data
(
5
)
)
;
assert_eq
!
(
d
.
steal
(
)
Steal
:
:
Empty
)
;
}
#
[
test
]
fn
steal_push
(
)
{
const
STEPS
:
usize
=
50_000
;
let
d
=
Deque
:
:
new
(
)
;
let
s
=
d
.
stealer
(
)
;
let
t
=
thread
:
:
spawn
(
move
|
|
for
i
in
0
.
.
STEPS
{
loop
{
if
let
Steal
:
:
Data
(
v
)
=
s
.
steal
(
)
{
assert_eq
!
(
i
v
)
;
break
;
}
}
}
)
;
for
i
in
0
.
.
STEPS
{
d
.
push
(
i
)
;
}
t
.
join
(
)
.
unwrap
(
)
;
}
#
[
test
]
fn
stampede
(
)
{
const
COUNT
:
usize
=
50_000
;
let
d
=
Deque
:
:
new
(
)
;
for
i
in
0
.
.
COUNT
{
d
.
push
(
Box
:
:
new
(
i
+
1
)
)
;
}
let
remaining
=
Arc
:
:
new
(
AtomicUsize
:
:
new
(
COUNT
)
)
;
let
threads
=
(
0
.
.
8
)
.
map
(
|
_
|
{
let
s
=
d
.
stealer
(
)
;
let
remaining
=
remaining
.
clone
(
)
;
thread
:
:
spawn
(
move
|
|
{
let
mut
last
=
0
;
while
remaining
.
load
(
SeqCst
)
>
0
{
if
let
Steal
:
:
Data
(
x
)
=
s
.
steal
(
)
{
assert
!
(
last
<
*
x
)
;
last
=
*
x
;
remaining
.
fetch_sub
(
1
SeqCst
)
;
}
}
}
)
}
)
.
collect
:
:
<
Vec
<
_
>
>
(
)
;
let
mut
last
=
COUNT
+
1
;
while
remaining
.
load
(
SeqCst
)
>
0
{
if
let
Some
(
x
)
=
d
.
pop
(
)
{
assert
!
(
last
>
*
x
)
;
last
=
*
x
;
remaining
.
fetch_sub
(
1
SeqCst
)
;
}
}
for
t
in
threads
{
t
.
join
(
)
.
unwrap
(
)
;
}
}
fn
run_stress
(
)
{
const
COUNT
:
usize
=
50_000
;
let
d
=
Deque
:
:
new
(
)
;
let
done
=
Arc
:
:
new
(
AtomicBool
:
:
new
(
false
)
)
;
let
hits
=
Arc
:
:
new
(
AtomicUsize
:
:
new
(
0
)
)
;
let
threads
=
(
0
.
.
8
)
.
map
(
|
_
|
{
let
s
=
d
.
stealer
(
)
;
let
done
=
done
.
clone
(
)
;
let
hits
=
hits
.
clone
(
)
;
thread
:
:
spawn
(
move
|
|
while
!
done
.
load
(
SeqCst
)
{
if
let
Steal
:
:
Data
(
_
)
=
s
.
steal
(
)
{
hits
.
fetch_add
(
1
SeqCst
)
;
}
}
)
}
)
.
collect
:
:
<
Vec
<
_
>
>
(
)
;
let
mut
rng
=
rand
:
:
thread_rng
(
)
;
let
mut
expected
=
0
;
while
expected
<
COUNT
{
if
rng
.
gen_range
(
0
3
)
=
=
0
{
if
d
.
pop
(
)
.
is_some
(
)
{
hits
.
fetch_add
(
1
SeqCst
)
;
}
}
else
{
d
.
push
(
expected
)
;
expected
+
=
1
;
}
}
while
hits
.
load
(
SeqCst
)
<
COUNT
{
if
d
.
pop
(
)
.
is_some
(
)
{
hits
.
fetch_add
(
1
SeqCst
)
;
}
}
done
.
store
(
true
SeqCst
)
;
for
t
in
threads
{
t
.
join
(
)
.
unwrap
(
)
;
}
}
#
[
test
]
fn
stress
(
)
{
run_stress
(
)
;
}
#
[
test
]
fn
stress_pinned
(
)
{
let
_guard
=
epoch
:
:
pin
(
)
;
run_stress
(
)
;
}
#
[
test
]
fn
no_starvation
(
)
{
const
COUNT
:
usize
=
50_000
;
let
d
=
Deque
:
:
new
(
)
;
let
done
=
Arc
:
:
new
(
AtomicBool
:
:
new
(
false
)
)
;
let
(
threads
hits
)
:
(
Vec
<
_
>
Vec
<
_
>
)
=
(
0
.
.
8
)
.
map
(
|
_
|
{
let
s
=
d
.
stealer
(
)
;
let
done
=
done
.
clone
(
)
;
let
hits
=
Arc
:
:
new
(
AtomicUsize
:
:
new
(
0
)
)
;
let
t
=
{
let
hits
=
hits
.
clone
(
)
;
thread
:
:
spawn
(
move
|
|
while
!
done
.
load
(
SeqCst
)
{
if
let
Steal
:
:
Data
(
_
)
=
s
.
steal
(
)
{
hits
.
fetch_add
(
1
SeqCst
)
;
}
}
)
}
;
(
t
hits
)
}
)
.
unzip
(
)
;
let
mut
rng
=
rand
:
:
thread_rng
(
)
;
let
mut
my_hits
=
0
;
loop
{
for
i
in
0
.
.
rng
.
gen_range
(
0
COUNT
)
{
if
rng
.
gen_range
(
0
3
)
=
=
0
&
&
my_hits
=
=
0
{
if
d
.
pop
(
)
.
is_some
(
)
{
my_hits
+
=
1
;
}
}
else
{
d
.
push
(
i
)
;
}
}
if
my_hits
>
0
&
&
hits
.
iter
(
)
.
all
(
|
h
|
h
.
load
(
SeqCst
)
>
0
)
{
break
;
}
}
done
.
store
(
true
SeqCst
)
;
for
t
in
threads
{
t
.
join
(
)
.
unwrap
(
)
;
}
}
#
[
test
]
fn
destructors
(
)
{
const
COUNT
:
usize
=
50_000
;
struct
Elem
(
usize
Arc
<
Mutex
<
Vec
<
usize
>
>
>
)
;
impl
Drop
for
Elem
{
fn
drop
(
&
mut
self
)
{
self
.
1
.
lock
(
)
.
unwrap
(
)
.
push
(
self
.
0
)
;
}
}
let
d
=
Deque
:
:
new
(
)
;
let
dropped
=
Arc
:
:
new
(
Mutex
:
:
new
(
Vec
:
:
new
(
)
)
)
;
let
remaining
=
Arc
:
:
new
(
AtomicUsize
:
:
new
(
COUNT
)
)
;
for
i
in
0
.
.
COUNT
{
d
.
push
(
Elem
(
i
dropped
.
clone
(
)
)
)
;
}
let
threads
=
(
0
.
.
8
)
.
map
(
|
_
|
{
let
s
=
d
.
stealer
(
)
;
let
remaining
=
remaining
.
clone
(
)
;
thread
:
:
spawn
(
move
|
|
for
_
in
0
.
.
1000
{
if
let
Steal
:
:
Data
(
_
)
=
s
.
steal
(
)
{
remaining
.
fetch_sub
(
1
SeqCst
)
;
}
}
)
}
)
.
collect
:
:
<
Vec
<
_
>
>
(
)
;
for
_
in
0
.
.
1000
{
if
d
.
pop
(
)
.
is_some
(
)
{
remaining
.
fetch_sub
(
1
SeqCst
)
;
}
}
for
t
in
threads
{
t
.
join
(
)
.
unwrap
(
)
;
}
let
rem
=
remaining
.
load
(
SeqCst
)
;
assert
!
(
rem
>
0
)
;
assert_eq
!
(
d
.
len
(
)
rem
)
;
{
let
mut
v
=
dropped
.
lock
(
)
.
unwrap
(
)
;
assert_eq
!
(
v
.
len
(
)
COUNT
-
rem
)
;
v
.
clear
(
)
;
}
drop
(
d
)
;
{
let
mut
v
=
dropped
.
lock
(
)
.
unwrap
(
)
;
assert_eq
!
(
v
.
len
(
)
rem
)
;
v
.
sort
(
)
;
for
pair
in
v
.
windows
(
2
)
{
assert_eq
!
(
pair
[
0
]
+
1
pair
[
1
]
)
;
}
}
}
}
