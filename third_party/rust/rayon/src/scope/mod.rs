use
latch
:
:
{
Latch
SpinLatch
LockLatch
}
;
use
job
:
:
{
JobMode
HeapJob
StackJob
}
;
use
std
:
:
any
:
:
Any
;
use
std
:
:
marker
:
:
PhantomData
;
use
std
:
:
mem
;
use
std
:
:
ptr
;
use
std
:
:
sync
:
:
atomic
:
:
{
AtomicUsize
AtomicPtr
Ordering
}
;
use
thread_pool
:
:
{
self
WorkerThread
}
;
use
unwind
;
#
[
cfg
(
test
)
]
mod
test
;
pub
struct
Scope
<
'
scope
>
{
owner_thread
:
*
mut
WorkerThread
counter
:
AtomicUsize
panic
:
AtomicPtr
<
Box
<
Any
+
Send
+
'
static
>
>
job_completed_latch
:
SpinLatch
marker
:
PhantomData
<
Box
<
FnOnce
(
&
Scope
<
'
scope
>
)
+
'
scope
>
>
}
pub
fn
scope
<
'
scope
OP
>
(
op
:
OP
)
where
OP
:
for
<
'
s
>
FnOnce
(
&
'
s
Scope
<
'
scope
>
)
+
'
scope
+
Send
{
unsafe
{
let
owner_thread
=
WorkerThread
:
:
current
(
)
;
if
!
owner_thread
.
is_null
(
)
{
let
scope
:
Scope
<
'
scope
>
=
Scope
{
owner_thread
:
owner_thread
counter
:
AtomicUsize
:
:
new
(
1
)
panic
:
AtomicPtr
:
:
new
(
ptr
:
:
null_mut
(
)
)
job_completed_latch
:
SpinLatch
:
:
new
(
)
marker
:
PhantomData
}
;
let
spawn_count
=
(
*
owner_thread
)
.
current_spawn_count
(
)
;
scope
.
execute_job_closure
(
op
)
;
(
*
owner_thread
)
.
pop_spawned_jobs
(
spawn_count
)
;
scope
.
steal_till_jobs_complete
(
)
;
}
else
{
scope_not_in_worker
(
op
)
}
}
}
#
[
cold
]
unsafe
fn
scope_not_in_worker
<
'
scope
OP
>
(
op
:
OP
)
where
OP
:
for
<
'
s
>
FnOnce
(
&
'
s
Scope
<
'
scope
>
)
+
'
scope
+
Send
{
debug_assert
!
(
WorkerThread
:
:
current
(
)
.
is_null
(
)
)
;
let
mut
result
=
None
;
{
let
job
=
StackJob
:
:
new
(
|
|
result
=
Some
(
scope
(
op
)
)
LockLatch
:
:
new
(
)
)
;
thread_pool
:
:
get_registry
(
)
.
inject
(
&
[
job
.
as_job_ref
(
)
]
)
;
job
.
latch
.
wait
(
)
;
}
result
.
unwrap
(
)
}
impl
<
'
scope
>
Scope
<
'
scope
>
{
pub
fn
spawn
<
BODY
>
(
&
self
body
:
BODY
)
where
BODY
:
FnOnce
(
&
Scope
<
'
scope
>
)
+
'
scope
{
unsafe
{
let
old_value
=
self
.
counter
.
fetch_add
(
1
Ordering
:
:
SeqCst
)
;
assert
!
(
old_value
>
0
)
;
let
job_ref
=
Box
:
:
new
(
HeapJob
:
:
new
(
move
|
mode
|
self
.
execute_job
(
body
mode
)
)
)
.
as_job_ref
(
)
;
let
worker_thread
=
WorkerThread
:
:
current
(
)
;
debug_assert
!
(
!
WorkerThread
:
:
current
(
)
.
is_null
(
)
)
;
let
worker_thread
=
&
*
worker_thread
;
worker_thread
.
bump_spawn_count
(
)
;
worker_thread
.
push
(
job_ref
)
;
}
}
unsafe
fn
execute_job
<
FUNC
>
(
&
self
func
:
FUNC
mode
:
JobMode
)
where
FUNC
:
FnOnce
(
&
Scope
<
'
scope
>
)
+
'
scope
{
match
mode
{
JobMode
:
:
Execute
=
>
self
.
execute_job_closure
(
func
)
JobMode
:
:
Abort
=
>
self
.
job_completed_ok
(
)
}
}
unsafe
fn
execute_job_closure
<
FUNC
>
(
&
self
func
:
FUNC
)
where
FUNC
:
FnOnce
(
&
Scope
<
'
scope
>
)
+
'
scope
{
match
unwind
:
:
halt_unwinding
(
move
|
|
func
(
self
)
)
{
Ok
(
(
)
)
=
>
self
.
job_completed_ok
(
)
Err
(
err
)
=
>
self
.
job_panicked
(
err
)
}
}
unsafe
fn
job_panicked
(
&
self
err
:
Box
<
Any
+
Send
+
'
static
>
)
{
let
nil
=
ptr
:
:
null_mut
(
)
;
let
mut
err
=
Box
:
:
new
(
err
)
;
if
self
.
panic
.
compare_and_swap
(
nil
&
mut
*
err
Ordering
:
:
SeqCst
)
.
is_null
(
)
{
mem
:
:
forget
(
err
)
;
}
self
.
job_completed_ok
(
)
}
unsafe
fn
job_completed_ok
(
&
self
)
{
let
old_value
=
self
.
counter
.
fetch_sub
(
1
Ordering
:
:
Release
)
;
if
old_value
=
=
1
{
self
.
job_completed_latch
.
set
(
)
;
}
}
unsafe
fn
steal_till_jobs_complete
(
&
self
)
{
debug_assert
!
(
self
.
job_completed_latch
.
probe
(
)
|
|
(
*
self
.
owner_thread
)
.
pop
(
)
.
is_none
(
)
)
;
(
*
self
.
owner_thread
)
.
steal_until
(
&
self
.
job_completed_latch
)
;
let
panic
=
self
.
panic
.
swap
(
ptr
:
:
null_mut
(
)
Ordering
:
:
Relaxed
)
;
if
!
panic
.
is_null
(
)
{
let
value
:
Box
<
Box
<
Any
+
Send
+
'
static
>
>
=
mem
:
:
transmute
(
panic
)
;
unwind
:
:
resume_unwinding
(
*
value
)
;
}
}
}
