import
sys
sys
.
path
.
insert
(
0
"
.
.
/
.
.
"
)
from
ply
import
*
import
decimal
tokens
=
(
    
'
DEF
'
    
'
IF
'
    
'
NAME
'
    
'
NUMBER
'
    
'
STRING
'
    
'
LPAR
'
    
'
RPAR
'
    
'
COLON
'
    
'
EQ
'
    
'
ASSIGN
'
    
'
LT
'
    
'
GT
'
    
'
PLUS
'
    
'
MINUS
'
    
'
MULT
'
    
'
DIV
'
    
'
RETURN
'
    
'
WS
'
    
'
NEWLINE
'
    
'
COMMA
'
    
'
SEMICOLON
'
    
'
INDENT
'
    
'
DEDENT
'
    
'
ENDMARKER
'
)
def
t_NUMBER
(
t
)
:
    
r
"
"
"
(
\
d
+
(
\
.
\
d
*
)
?
|
\
.
\
d
+
)
(
[
eE
]
[
-
+
]
?
\
d
+
)
?
"
"
"
    
t
.
value
=
decimal
.
Decimal
(
t
.
value
)
    
return
t
def
t_STRING
(
t
)
:
    
r
"
'
(
[
^
\
\
'
]
+
|
\
\
'
|
\
\
\
\
)
*
'
"
    
t
.
value
=
t
.
value
[
1
:
-
1
]
.
decode
(
"
string
-
escape
"
)
    
return
t
t_COLON
=
r
'
:
'
t_EQ
=
r
'
=
=
'
t_ASSIGN
=
r
'
=
'
t_LT
=
r
'
<
'
t_GT
=
r
'
>
'
t_PLUS
=
r
'
\
+
'
t_MINUS
=
r
'
-
'
t_MULT
=
r
'
\
*
'
t_DIV
=
r
'
/
'
t_COMMA
=
r
'
'
t_SEMICOLON
=
r
'
;
'
RESERVED
=
{
    
"
def
"
:
"
DEF
"
    
"
if
"
:
"
IF
"
    
"
return
"
:
"
RETURN
"
}
def
t_NAME
(
t
)
:
    
r
'
[
a
-
zA
-
Z_
]
[
a
-
zA
-
Z0
-
9_
]
*
'
    
t
.
type
=
RESERVED
.
get
(
t
.
value
"
NAME
"
)
    
return
t
def
t_comment
(
t
)
:
    
r
"
[
]
*
\
043
[
^
\
n
]
*
"
    
pass
def
t_WS
(
t
)
:
    
r
'
[
]
+
'
    
if
t
.
lexer
.
at_line_start
and
t
.
lexer
.
paren_count
=
=
0
:
        
return
t
def
t_newline
(
t
)
:
    
r
'
\
n
+
'
    
t
.
lexer
.
lineno
+
=
len
(
t
.
value
)
    
t
.
type
=
"
NEWLINE
"
    
if
t
.
lexer
.
paren_count
=
=
0
:
        
return
t
def
t_LPAR
(
t
)
:
    
r
'
\
(
'
    
t
.
lexer
.
paren_count
+
=
1
    
return
t
def
t_RPAR
(
t
)
:
    
r
'
\
)
'
    
t
.
lexer
.
paren_count
-
=
1
    
return
t
def
t_error
(
t
)
:
    
raise
SyntaxError
(
"
Unknown
symbol
%
r
"
%
(
t
.
value
[
0
]
)
)
    
print
"
Skipping
"
repr
(
t
.
value
[
0
]
)
    
t
.
lexer
.
skip
(
1
)
NO_INDENT
=
0
MAY_INDENT
=
1
MUST_INDENT
=
2
def
track_tokens_filter
(
lexer
tokens
)
:
    
lexer
.
at_line_start
=
at_line_start
=
True
    
indent
=
NO_INDENT
    
saw_colon
=
False
    
for
token
in
tokens
:
        
token
.
at_line_start
=
at_line_start
        
if
token
.
type
=
=
"
COLON
"
:
            
at_line_start
=
False
            
indent
=
MAY_INDENT
            
token
.
must_indent
=
False
        
elif
token
.
type
=
=
"
NEWLINE
"
:
            
at_line_start
=
True
            
if
indent
=
=
MAY_INDENT
:
                
indent
=
MUST_INDENT
            
token
.
must_indent
=
False
        
elif
token
.
type
=
=
"
WS
"
:
            
assert
token
.
at_line_start
=
=
True
            
at_line_start
=
True
            
token
.
must_indent
=
False
        
else
:
            
if
indent
=
=
MUST_INDENT
:
                
token
.
must_indent
=
True
            
else
:
                
token
.
must_indent
=
False
            
at_line_start
=
False
            
indent
=
NO_INDENT
        
yield
token
        
lexer
.
at_line_start
=
at_line_start
def
_new_token
(
type
lineno
)
:
    
tok
=
lex
.
LexToken
(
)
    
tok
.
type
=
type
    
tok
.
value
=
None
    
tok
.
lineno
=
lineno
    
return
tok
def
DEDENT
(
lineno
)
:
    
return
_new_token
(
"
DEDENT
"
lineno
)
def
INDENT
(
lineno
)
:
    
return
_new_token
(
"
INDENT
"
lineno
)
def
indentation_filter
(
tokens
)
:
    
levels
=
[
0
]
    
token
=
None
    
depth
=
0
    
prev_was_ws
=
False
    
for
token
in
tokens
:
        
if
token
.
type
=
=
"
WS
"
:
            
assert
depth
=
=
0
            
depth
=
len
(
token
.
value
)
            
prev_was_ws
=
True
            
continue
        
if
token
.
type
=
=
"
NEWLINE
"
:
            
depth
=
0
            
if
prev_was_ws
or
token
.
at_line_start
:
                
continue
            
yield
token
            
continue
        
prev_was_ws
=
False
        
if
token
.
must_indent
:
            
if
not
(
depth
>
levels
[
-
1
]
)
:
                
raise
IndentationError
(
"
expected
an
indented
block
"
)
            
levels
.
append
(
depth
)
            
yield
INDENT
(
token
.
lineno
)
        
elif
token
.
at_line_start
:
            
if
depth
=
=
levels
[
-
1
]
:
                
pass
            
elif
depth
>
levels
[
-
1
]
:
                
raise
IndentationError
(
                    
"
indentation
increase
but
not
in
new
block
"
)
            
else
:
                
try
:
                    
i
=
levels
.
index
(
depth
)
                
except
ValueError
:
                    
raise
IndentationError
(
"
inconsistent
indentation
"
)
                
for
_
in
range
(
i
+
1
len
(
levels
)
)
:
                    
yield
DEDENT
(
token
.
lineno
)
                    
levels
.
pop
(
)
        
yield
token
    
if
len
(
levels
)
>
1
:
        
assert
token
is
not
None
        
for
_
in
range
(
1
len
(
levels
)
)
:
            
yield
DEDENT
(
token
.
lineno
)
def
filter
(
lexer
add_endmarker
=
True
)
:
    
token
=
None
    
tokens
=
iter
(
lexer
.
token
None
)
    
tokens
=
track_tokens_filter
(
lexer
tokens
)
    
for
token
in
indentation_filter
(
tokens
)
:
        
yield
token
    
if
add_endmarker
:
        
lineno
=
1
        
if
token
is
not
None
:
            
lineno
=
token
.
lineno
        
yield
_new_token
(
"
ENDMARKER
"
lineno
)
class
IndentLexer
(
object
)
:
    
def
__init__
(
self
debug
=
0
optimize
=
0
lextab
=
'
lextab
'
reflags
=
0
)
:
        
self
.
lexer
=
lex
.
lex
(
debug
=
debug
optimize
=
optimize
                             
lextab
=
lextab
reflags
=
reflags
)
        
self
.
token_stream
=
None
    
def
input
(
self
s
add_endmarker
=
True
)
:
        
self
.
lexer
.
paren_count
=
0
        
self
.
lexer
.
input
(
s
)
        
self
.
token_stream
=
filter
(
self
.
lexer
add_endmarker
)
    
def
token
(
self
)
:
        
try
:
            
return
self
.
token_stream
.
next
(
)
        
except
StopIteration
:
            
return
None
from
compiler
import
ast
def
Assign
(
left
right
)
:
    
names
=
[
]
    
if
isinstance
(
left
ast
.
Name
)
:
        
return
ast
.
Assign
(
[
ast
.
AssName
(
left
.
name
'
OP_ASSIGN
'
)
]
right
)
    
elif
isinstance
(
left
ast
.
Tuple
)
:
        
names
=
[
]
        
for
child
in
left
.
getChildren
(
)
:
            
if
not
isinstance
(
child
ast
.
Name
)
:
                
raise
SyntaxError
(
"
that
assignment
not
supported
"
)
            
names
.
append
(
child
.
name
)
        
ass_list
=
[
ast
.
AssName
(
name
'
OP_ASSIGN
'
)
for
name
in
names
]
        
return
ast
.
Assign
(
[
ast
.
AssTuple
(
ass_list
)
]
right
)
    
else
:
        
raise
SyntaxError
(
"
Can
'
t
do
that
yet
"
)
def
p_file_input_end
(
p
)
:
    
"
"
"
file_input_end
:
file_input
ENDMARKER
"
"
"
    
p
[
0
]
=
ast
.
Stmt
(
p
[
1
]
)
def
p_file_input
(
p
)
:
    
"
"
"
file_input
:
file_input
NEWLINE
                  
|
file_input
stmt
                  
|
NEWLINE
                  
|
stmt
"
"
"
    
if
isinstance
(
p
[
len
(
p
)
-
1
]
basestring
)
:
        
if
len
(
p
)
=
=
3
:
            
p
[
0
]
=
p
[
1
]
        
else
:
            
p
[
0
]
=
[
]
    
else
:
        
if
len
(
p
)
=
=
3
:
            
p
[
0
]
=
p
[
1
]
+
p
[
2
]
        
else
:
            
p
[
0
]
=
p
[
1
]
def
p_funcdef
(
p
)
:
    
"
funcdef
:
DEF
NAME
parameters
COLON
suite
"
    
p
[
0
]
=
ast
.
Function
(
None
p
[
2
]
tuple
(
p
[
3
]
)
(
)
0
None
p
[
5
]
)
def
p_parameters
(
p
)
:
    
"
"
"
parameters
:
LPAR
RPAR
                  
|
LPAR
varargslist
RPAR
"
"
"
    
if
len
(
p
)
=
=
3
:
        
p
[
0
]
=
[
]
    
else
:
        
p
[
0
]
=
p
[
2
]
def
p_varargslist
(
p
)
:
    
"
"
"
varargslist
:
varargslist
COMMA
NAME
                   
|
NAME
"
"
"
    
if
len
(
p
)
=
=
4
:
        
p
[
0
]
=
p
[
1
]
+
p
[
3
]
    
else
:
        
p
[
0
]
=
[
p
[
1
]
]
def
p_stmt_simple
(
p
)
:
    
"
"
"
stmt
:
simple_stmt
"
"
"
    
p
[
0
]
=
p
[
1
]
def
p_stmt_compound
(
p
)
:
    
"
"
"
stmt
:
compound_stmt
"
"
"
    
p
[
0
]
=
[
p
[
1
]
]
def
p_simple_stmt
(
p
)
:
    
"
"
"
simple_stmt
:
small_stmts
NEWLINE
                   
|
small_stmts
SEMICOLON
NEWLINE
"
"
"
    
p
[
0
]
=
p
[
1
]
def
p_small_stmts
(
p
)
:
    
"
"
"
small_stmts
:
small_stmts
SEMICOLON
small_stmt
                   
|
small_stmt
"
"
"
    
if
len
(
p
)
=
=
4
:
        
p
[
0
]
=
p
[
1
]
+
[
p
[
3
]
]
    
else
:
        
p
[
0
]
=
[
p
[
1
]
]
def
p_small_stmt
(
p
)
:
    
"
"
"
small_stmt
:
flow_stmt
                  
|
expr_stmt
"
"
"
    
p
[
0
]
=
p
[
1
]
def
p_expr_stmt
(
p
)
:
    
"
"
"
expr_stmt
:
testlist
ASSIGN
testlist
                 
|
testlist
"
"
"
    
if
len
(
p
)
=
=
2
:
        
p
[
0
]
=
ast
.
Discard
(
p
[
1
]
)
    
else
:
        
p
[
0
]
=
Assign
(
p
[
1
]
p
[
3
]
)
def
p_flow_stmt
(
p
)
:
    
"
flow_stmt
:
return_stmt
"
    
p
[
0
]
=
p
[
1
]
def
p_return_stmt
(
p
)
:
    
"
return_stmt
:
RETURN
testlist
"
    
p
[
0
]
=
ast
.
Return
(
p
[
2
]
)
def
p_compound_stmt
(
p
)
:
    
"
"
"
compound_stmt
:
if_stmt
                     
|
funcdef
"
"
"
    
p
[
0
]
=
p
[
1
]
def
p_if_stmt
(
p
)
:
    
'
if_stmt
:
IF
test
COLON
suite
'
    
p
[
0
]
=
ast
.
If
(
[
(
p
[
2
]
p
[
4
]
)
]
None
)
def
p_suite
(
p
)
:
    
"
"
"
suite
:
simple_stmt
             
|
NEWLINE
INDENT
stmts
DEDENT
"
"
"
    
if
len
(
p
)
=
=
2
:
        
p
[
0
]
=
ast
.
Stmt
(
p
[
1
]
)
    
else
:
        
p
[
0
]
=
ast
.
Stmt
(
p
[
3
]
)
def
p_stmts
(
p
)
:
    
"
"
"
stmts
:
stmts
stmt
             
|
stmt
"
"
"
    
if
len
(
p
)
=
=
3
:
        
p
[
0
]
=
p
[
1
]
+
p
[
2
]
    
else
:
        
p
[
0
]
=
p
[
1
]
def
make_lt_compare
(
(
left
right
)
)
:
    
return
ast
.
Compare
(
left
[
(
'
<
'
right
)
]
)
def
make_gt_compare
(
(
left
right
)
)
:
    
return
ast
.
Compare
(
left
[
(
'
>
'
right
)
]
)
def
make_eq_compare
(
(
left
right
)
)
:
    
return
ast
.
Compare
(
left
[
(
'
=
=
'
right
)
]
)
binary_ops
=
{
    
"
+
"
:
ast
.
Add
    
"
-
"
:
ast
.
Sub
    
"
*
"
:
ast
.
Mul
    
"
/
"
:
ast
.
Div
    
"
<
"
:
make_lt_compare
    
"
>
"
:
make_gt_compare
    
"
=
=
"
:
make_eq_compare
}
unary_ops
=
{
    
"
+
"
:
ast
.
UnaryAdd
    
"
-
"
:
ast
.
UnarySub
}
precedence
=
(
    
(
"
left
"
"
EQ
"
"
GT
"
"
LT
"
)
    
(
"
left
"
"
PLUS
"
"
MINUS
"
)
    
(
"
left
"
"
MULT
"
"
DIV
"
)
)
def
p_comparison
(
p
)
:
    
"
"
"
comparison
:
comparison
PLUS
comparison
                  
|
comparison
MINUS
comparison
                  
|
comparison
MULT
comparison
                  
|
comparison
DIV
comparison
                  
|
comparison
LT
comparison
                  
|
comparison
EQ
comparison
                  
|
comparison
GT
comparison
                  
|
PLUS
comparison
                  
|
MINUS
comparison
                  
|
power
"
"
"
    
if
len
(
p
)
=
=
4
:
        
p
[
0
]
=
binary_ops
[
p
[
2
]
]
(
(
p
[
1
]
p
[
3
]
)
)
    
elif
len
(
p
)
=
=
3
:
        
p
[
0
]
=
unary_ops
[
p
[
1
]
]
(
p
[
2
]
)
    
else
:
        
p
[
0
]
=
p
[
1
]
def
p_power
(
p
)
:
    
"
"
"
power
:
atom
             
|
atom
trailer
"
"
"
    
if
len
(
p
)
=
=
2
:
        
p
[
0
]
=
p
[
1
]
    
else
:
        
if
p
[
2
]
[
0
]
=
=
"
CALL
"
:
            
p
[
0
]
=
ast
.
CallFunc
(
p
[
1
]
p
[
2
]
[
1
]
None
None
)
        
else
:
            
raise
AssertionError
(
"
not
implemented
"
)
def
p_atom_name
(
p
)
:
    
"
"
"
atom
:
NAME
"
"
"
    
p
[
0
]
=
ast
.
Name
(
p
[
1
]
)
def
p_atom_number
(
p
)
:
    
"
"
"
atom
:
NUMBER
            
|
STRING
"
"
"
    
p
[
0
]
=
ast
.
Const
(
p
[
1
]
)
def
p_atom_tuple
(
p
)
:
    
"
"
"
atom
:
LPAR
testlist
RPAR
"
"
"
    
p
[
0
]
=
p
[
2
]
def
p_trailer
(
p
)
:
    
"
trailer
:
LPAR
arglist
RPAR
"
    
p
[
0
]
=
(
"
CALL
"
p
[
2
]
)
def
p_testlist
(
p
)
:
    
"
"
"
testlist
:
testlist_multi
COMMA
                
|
testlist_multi
"
"
"
    
if
len
(
p
)
=
=
2
:
        
p
[
0
]
=
p
[
1
]
    
else
:
        
if
isinstance
(
p
[
1
]
list
)
:
            
p
[
0
]
=
p
[
1
]
        
else
:
            
p
[
0
]
=
[
p
[
1
]
]
    
if
isinstance
(
p
[
0
]
list
)
:
        
p
[
0
]
=
ast
.
Tuple
(
p
[
0
]
)
def
p_testlist_multi
(
p
)
:
    
"
"
"
testlist_multi
:
testlist_multi
COMMA
test
                      
|
test
"
"
"
    
if
len
(
p
)
=
=
2
:
        
p
[
0
]
=
p
[
1
]
    
else
:
        
if
isinstance
(
p
[
1
]
list
)
:
            
p
[
0
]
=
p
[
1
]
+
[
p
[
3
]
]
        
else
:
            
p
[
0
]
=
[
p
[
1
]
p
[
3
]
]
def
p_test
(
p
)
:
    
"
test
:
comparison
"
    
p
[
0
]
=
p
[
1
]
def
p_arglist
(
p
)
:
    
"
"
"
arglist
:
arglist
COMMA
argument
               
|
argument
"
"
"
    
if
len
(
p
)
=
=
4
:
        
p
[
0
]
=
p
[
1
]
+
[
p
[
3
]
]
    
else
:
        
p
[
0
]
=
[
p
[
1
]
]
def
p_argument
(
p
)
:
    
"
argument
:
test
"
    
p
[
0
]
=
p
[
1
]
def
p_error
(
p
)
:
    
raise
SyntaxError
(
p
)
class
GardenSnakeParser
(
object
)
:
    
def
__init__
(
self
lexer
=
None
)
:
        
if
lexer
is
None
:
            
lexer
=
IndentLexer
(
)
        
self
.
lexer
=
lexer
        
self
.
parser
=
yacc
.
yacc
(
start
=
"
file_input_end
"
)
    
def
parse
(
self
code
)
:
        
self
.
lexer
.
input
(
code
)
        
result
=
self
.
parser
.
parse
(
lexer
=
self
.
lexer
)
        
return
ast
.
Module
(
None
result
)
from
compiler
import
misc
syntax
pycodegen
class
GardenSnakeCompiler
(
object
)
:
    
def
__init__
(
self
)
:
        
self
.
parser
=
GardenSnakeParser
(
)
    
def
compile
(
self
code
filename
=
"
<
string
>
"
)
:
        
tree
=
self
.
parser
.
parse
(
code
)
        
misc
.
set_filename
(
filename
tree
)
        
syntax
.
check
(
tree
)
        
gen
=
pycodegen
.
ModuleCodeGenerator
(
tree
)
        
code
=
gen
.
getCode
(
)
        
return
code
compile
=
GardenSnakeCompiler
(
)
.
compile
code
=
r
"
"
"
print
(
'
LET
\
'
S
TRY
THIS
\
\
OUT
'
)
#
Comment
here
def
x
(
a
)
:
    
print
(
'
called
with
'
a
)
    
if
a
=
=
1
:
        
return
2
    
if
a
*
2
>
10
:
return
999
/
4
        
#
Another
comment
here
    
return
a
+
2
*
3
ints
=
(
1
2
   
3
4
5
)
print
(
'
mutiline
-
expression
'
ints
)
t
=
4
+
1
/
3
*
2
+
6
*
(
9
-
5
+
1
)
print
(
'
predence
test
;
should
be
34
+
2
/
3
:
'
t
t
=
=
(
34
+
2
/
3
)
)
print
(
'
numbers
'
1
2
3
4
5
)
if
1
:
 
8
 
a
=
9
 
print
(
x
(
a
)
)
print
(
x
(
1
)
)
print
(
x
(
2
)
)
print
(
x
(
8
)
'
3
'
)
print
(
'
this
is
decimal
'
1
/
5
)
print
(
'
BIG
DECIMAL
'
1
.
234567891234567e12345
)
"
"
"
def
print_
(
*
args
)
:
    
print
"
-
-
>
"
"
"
.
join
(
map
(
str
args
)
)
globals
(
)
[
"
print
"
]
=
print_
compiled_code
=
compile
(
code
)
exec
compiled_code
in
globals
(
)
print
"
Done
"
