#
include
"
lib
/
threads
/
thread_parallel_runner_internal
.
h
"
#
if
defined
(
ADDRESS_SANITIZER
)
|
|
defined
(
MEMORY_SANITIZER
)
|
|
\
defined
(
THREAD_SANITIZER
)
#
include
"
sanitizer
/
common_interface_defs
.
h
"
#
endif
#
include
"
jxl
/
thread_parallel_runner
.
h
"
#
include
"
lib
/
jxl
/
base
/
profiler
.
h
"
#
include
<
algorithm
>
namespace
{
bool
Abort
(
)
{
#
if
defined
(
ADDRESS_SANITIZER
)
|
|
defined
(
MEMORY_SANITIZER
)
|
|
\
defined
(
THREAD_SANITIZER
)
__sanitizer_print_stack_trace
(
)
;
#
endif
#
ifdef
_MSC_VER
__debugbreak
(
)
;
abort
(
)
;
#
else
__builtin_trap
(
)
;
#
endif
}
#
if
JXL_ENABLE_ASSERT
#
define
JXL_ASSERT
(
condition
)
\
do
{
\
if
(
!
(
condition
)
)
{
\
Abort
(
)
;
\
}
\
}
while
(
0
)
#
else
#
define
JXL_ASSERT
(
condition
)
\
do
{
\
}
while
(
0
)
#
endif
}
namespace
jpegxl
{
JxlParallelRetCode
ThreadParallelRunner
:
:
Runner
(
void
*
runner_opaque
void
*
jpegxl_opaque
JxlParallelRunInit
init
JxlParallelRunFunction
func
uint32_t
start_range
uint32_t
end_range
)
{
ThreadParallelRunner
*
self
=
static_cast
<
ThreadParallelRunner
*
>
(
runner_opaque
)
;
if
(
start_range
>
end_range
)
return
-
1
;
if
(
start_range
=
=
end_range
)
return
0
;
int
ret
=
init
(
jpegxl_opaque
std
:
:
max
<
size_t
>
(
self
-
>
num_worker_threads_
1
)
)
;
if
(
ret
!
=
0
)
return
ret
;
if
(
self
-
>
num_worker_threads_
=
=
0
)
{
const
size_t
thread
=
0
;
for
(
uint32_t
task
=
start_range
;
task
<
end_range
;
+
+
task
)
{
func
(
jpegxl_opaque
task
thread
)
;
}
return
0
;
}
if
(
self
-
>
depth_
.
fetch_add
(
1
std
:
:
memory_order_acq_rel
)
!
=
0
)
{
return
-
1
;
}
const
WorkerCommand
worker_command
=
(
static_cast
<
WorkerCommand
>
(
start_range
)
<
<
32
)
+
end_range
;
JXL_ASSERT
(
worker_command
!
=
kWorkerWait
)
;
JXL_ASSERT
(
worker_command
!
=
kWorkerOnce
)
;
JXL_ASSERT
(
worker_command
!
=
kWorkerExit
)
;
self
-
>
data_func_
=
func
;
self
-
>
jpegxl_opaque_
=
jpegxl_opaque
;
self
-
>
num_reserved_
.
store
(
0
std
:
:
memory_order_relaxed
)
;
self
-
>
StartWorkers
(
worker_command
)
;
self
-
>
WorkersReadyBarrier
(
)
;
if
(
self
-
>
depth_
.
fetch_add
(
-
1
std
:
:
memory_order_acq_rel
)
!
=
1
)
{
return
-
1
;
}
return
0
;
}
void
ThreadParallelRunner
:
:
RunRange
(
ThreadParallelRunner
*
self
const
WorkerCommand
command
const
int
thread
)
{
const
uint32_t
begin
=
command
>
>
32
;
const
uint32_t
end
=
command
&
0xFFFFFFFF
;
const
uint32_t
num_tasks
=
end
-
begin
;
const
uint32_t
num_worker_threads
=
self
-
>
num_worker_threads_
;
for
(
;
;
)
{
#
if
0
const
uint32_t
my_size
=
std
:
:
max
(
num_tasks
/
(
num_worker_threads
*
4
)
1
)
;
#
else
const
uint32_t
num_reserved
=
self
-
>
num_reserved_
.
load
(
std
:
:
memory_order_relaxed
)
;
const
uint32_t
num_remaining
=
num_tasks
-
num_reserved
;
const
uint32_t
my_size
=
std
:
:
max
(
num_remaining
/
(
num_worker_threads
*
4
)
1u
)
;
#
endif
const
uint32_t
my_begin
=
begin
+
self
-
>
num_reserved_
.
fetch_add
(
my_size
std
:
:
memory_order_relaxed
)
;
const
uint32_t
my_end
=
std
:
:
min
(
my_begin
+
my_size
begin
+
num_tasks
)
;
if
(
my_begin
>
=
my_end
)
{
break
;
}
for
(
uint32_t
task
=
my_begin
;
task
<
my_end
;
+
+
task
)
{
self
-
>
data_func_
(
self
-
>
jpegxl_opaque_
task
thread
)
;
}
}
}
void
ThreadParallelRunner
:
:
ThreadFunc
(
ThreadParallelRunner
*
self
const
int
thread
)
{
for
(
;
;
)
{
std
:
:
unique_lock
<
std
:
:
mutex
>
lock
(
self
-
>
mutex_
)
;
if
(
+
+
self
-
>
workers_ready_
=
=
self
-
>
num_threads_
)
{
self
-
>
workers_ready_cv_
.
notify_one
(
)
;
}
RESUME_WAIT
:
self
-
>
worker_start_cv_
.
wait
(
lock
)
;
const
WorkerCommand
command
=
self
-
>
worker_start_command_
;
switch
(
command
)
{
case
kWorkerWait
:
goto
RESUME_WAIT
;
case
kWorkerOnce
:
lock
.
unlock
(
)
;
self
-
>
data_func_
(
self
-
>
jpegxl_opaque_
thread
thread
)
;
break
;
case
kWorkerExit
:
return
;
default
:
lock
.
unlock
(
)
;
RunRange
(
self
command
thread
)
;
break
;
}
}
}
ThreadParallelRunner
:
:
ThreadParallelRunner
(
const
int
num_worker_threads
)
#
if
defined
(
__EMSCRIPTEN__
)
:
num_worker_threads_
(
0
)
num_threads_
(
1
)
{
(
void
)
num_worker_threads
;
#
else
:
num_worker_threads_
(
num_worker_threads
)
num_threads_
(
std
:
:
max
(
num_worker_threads
1
)
)
{
#
endif
PROFILER_ZONE
(
"
ThreadParallelRunner
ctor
"
)
;
threads_
.
reserve
(
num_worker_threads_
)
;
(
void
)
padding1
;
(
void
)
padding2
;
worker_start_command_
=
kWorkerWait
;
for
(
uint32_t
i
=
0
;
i
<
num_worker_threads_
;
+
+
i
)
{
threads_
.
emplace_back
(
ThreadFunc
this
i
)
;
}
if
(
num_worker_threads_
!
=
0
)
{
WorkersReadyBarrier
(
)
;
}
RunOnEachThread
(
[
]
(
const
int
task
const
int
thread
)
{
PROFILER_ZONE
(
"
InitWorkers
"
)
;
}
)
;
}
ThreadParallelRunner
:
:
~
ThreadParallelRunner
(
)
{
if
(
num_worker_threads_
!
=
0
)
{
StartWorkers
(
kWorkerExit
)
;
}
for
(
std
:
:
thread
&
thread
:
threads_
)
{
JXL_ASSERT
(
thread
.
joinable
(
)
)
;
thread
.
join
(
)
;
}
}
}
