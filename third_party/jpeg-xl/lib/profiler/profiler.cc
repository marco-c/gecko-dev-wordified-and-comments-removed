#
include
"
lib
/
jxl
/
base
/
profiler
.
h
"
#
if
PROFILER_ENABLED
#
include
<
stdio
.
h
>
#
include
<
stdlib
.
h
>
#
include
<
string
.
h
>
#
include
<
algorithm
>
#
include
<
atomic
>
#
include
<
cinttypes
>
#
include
<
hwy
/
highway
.
h
>
#
include
<
new
>
#
include
"
lib
/
jxl
/
base
/
robust_statistics
.
h
"
#
ifndef
PROFILER_THREAD_STORAGE
#
define
PROFILER_THREAD_STORAGE
32ULL
#
endif
#
define
PROFILER_PRINT_OVERHEAD
0
#
if
PROFILER_BUFFER
HWY_BEFORE_NAMESPACE
(
)
;
namespace
jxl
{
namespace
HWY_NAMESPACE
{
void
StreamCacheLine
(
const
Packet
*
JXL_RESTRICT
from
Packet
*
JXL_RESTRICT
to
)
{
constexpr
size_t
kLanes
=
16
/
sizeof
(
Packet
)
;
static_assert
(
kLanes
=
=
2
"
Update
descriptor
type
"
)
;
const
HWY_CAPPED
(
uint64_t
kLanes
)
d
;
JXL_COMPILER_FENCE
;
const
uint64_t
*
JXL_RESTRICT
from64
=
reinterpret_cast
<
const
uint64_t
*
>
(
from
)
;
const
auto
v0
=
Load
(
d
from64
+
0
*
kLanes
)
;
const
auto
v1
=
Load
(
d
from64
+
1
*
kLanes
)
;
const
auto
v2
=
Load
(
d
from64
+
2
*
kLanes
)
;
const
auto
v3
=
Load
(
d
from64
+
3
*
kLanes
)
;
JXL_COMPILER_FENCE
;
uint64_t
*
JXL_RESTRICT
to64
=
reinterpret_cast
<
uint64_t
*
>
(
to
)
;
Stream
(
v0
d
to64
+
0
*
kLanes
)
;
Stream
(
v1
d
to64
+
1
*
kLanes
)
;
Stream
(
v2
d
to64
+
2
*
kLanes
)
;
Stream
(
v3
d
to64
+
3
*
kLanes
)
;
JXL_COMPILER_FENCE
;
}
}
}
HWY_AFTER_NAMESPACE
(
)
;
#
endif
namespace
jxl
{
namespace
{
constexpr
size_t
kMaxThreads
=
1024
;
constexpr
size_t
kMaxDepth
=
64
;
constexpr
size_t
kMaxZones
=
256
;
uintptr_t
StringOrigin
(
)
{
static
const
char
*
string_origin
=
"
__
#
Origin
#
__
"
;
return
reinterpret_cast
<
uintptr_t
>
(
string_origin
)
-
Packet
:
:
kOffsetBias
;
}
struct
ProfilerNode
{
Packet
packet
;
uint64_t
child_total
;
}
;
struct
Accumulator
{
static
constexpr
size_t
kNumCallBits
=
64
-
Packet
:
:
kOffsetBits
;
uintptr_t
BiasedOffset
(
)
const
{
return
num_calls
>
>
kNumCallBits
;
}
uint64_t
NumCalls
(
)
const
{
return
num_calls
&
(
(
1ULL
<
<
kNumCallBits
)
-
1
)
;
}
uint64_t
num_calls
=
0
;
uint64_t
total_duration
=
0
;
}
;
#
if
JXL_ARCH_X64
static_assert
(
sizeof
(
Accumulator
)
=
=
2
*
sizeof
(
uint64_t
)
"
Accumulator
size
"
)
;
#
endif
template
<
typename
T
>
inline
T
ClampedSubtract
(
const
T
minuend
const
T
subtrahend
)
{
if
(
subtrahend
>
minuend
)
{
return
0
;
}
return
minuend
-
subtrahend
;
}
}
class
Results
{
public
:
Results
(
)
{
memset
(
zones_
0
sizeof
(
Accumulator
)
)
;
}
uint64_t
ZoneDuration
(
const
Packet
*
packets
)
{
JXL_CHECK
(
depth_
=
=
0
)
;
JXL_CHECK
(
num_zones_
=
=
0
)
;
AnalyzePackets
(
packets
2
)
;
const
uint64_t
duration
=
zones_
[
0
]
.
total_duration
;
zones_
[
0
]
.
num_calls
=
0
;
zones_
[
0
]
.
total_duration
=
0
;
JXL_CHECK
(
depth_
=
=
0
)
;
num_zones_
=
0
;
return
duration
;
}
void
SetSelfOverhead
(
const
uint64_t
self_overhead
)
{
self_overhead_
=
self_overhead
;
}
void
SetChildOverhead
(
const
uint64_t
child_overhead
)
{
child_overhead_
=
child_overhead
;
}
void
AnalyzePackets
(
const
Packet
*
packets
const
size_t
num_packets
)
{
const
uint64_t
t0
=
TicksBefore
(
)
;
for
(
size_t
i
=
0
;
i
<
num_packets
;
+
+
i
)
{
const
Packet
p
=
packets
[
i
]
;
if
(
p
.
BiasedOffset
(
)
!
=
Packet
:
:
kOffsetBias
)
{
JXL_ASSERT
(
depth_
<
kMaxDepth
)
;
nodes_
[
depth_
]
.
packet
=
p
;
nodes_
[
depth_
]
.
child_total
=
0
;
+
+
depth_
;
continue
;
}
JXL_ASSERT
(
depth_
!
=
0
)
;
const
ProfilerNode
&
node
=
nodes_
[
depth_
-
1
]
;
const
uint64_t
duration
=
(
p
.
Timestamp
(
)
-
node
.
packet
.
Timestamp
(
)
)
&
Packet
:
:
kTimestampMask
;
const
uint64_t
self_duration
=
ClampedSubtract
(
duration
self_overhead_
+
child_overhead_
+
node
.
child_total
)
;
UpdateOrAdd
(
node
.
packet
.
BiasedOffset
(
)
1
self_duration
)
;
-
-
depth_
;
if
(
depth_
!
=
0
)
{
nodes_
[
depth_
-
1
]
.
child_total
+
=
duration
+
child_overhead_
;
}
}
const
uint64_t
t1
=
TicksAfter
(
)
;
analyze_elapsed_
+
=
t1
-
t0
;
}
void
Assimilate
(
const
Results
&
other
)
{
const
uint64_t
t0
=
TicksBefore
(
)
;
JXL_ASSERT
(
depth_
=
=
0
)
;
JXL_ASSERT
(
other
.
depth_
=
=
0
)
;
for
(
size_t
i
=
0
;
i
<
other
.
num_zones_
;
+
+
i
)
{
const
Accumulator
&
zone
=
other
.
zones_
[
i
]
;
UpdateOrAdd
(
zone
.
BiasedOffset
(
)
zone
.
NumCalls
(
)
zone
.
total_duration
)
;
}
const
uint64_t
t1
=
TicksAfter
(
)
;
analyze_elapsed_
+
=
t1
-
t0
+
other
.
analyze_elapsed_
;
}
void
Print
(
)
{
const
uint64_t
t0
=
TicksBefore
(
)
;
MergeDuplicates
(
)
;
std
:
:
sort
(
zones_
zones_
+
num_zones_
[
]
(
const
Accumulator
&
r1
const
Accumulator
&
r2
)
{
return
r1
.
total_duration
>
r2
.
total_duration
;
}
)
;
const
uintptr_t
string_origin
=
StringOrigin
(
)
;
uint64_t
total_visible_duration
=
0
;
for
(
size_t
i
=
0
;
i
<
num_zones_
;
+
+
i
)
{
const
Accumulator
&
r
=
zones_
[
i
]
;
const
uint64_t
num_calls
=
r
.
NumCalls
(
)
;
const
char
*
name
=
reinterpret_cast
<
const
char
*
>
(
string_origin
+
r
.
BiasedOffset
(
)
)
;
if
(
name
[
0
]
!
=
'
'
)
{
total_visible_duration
+
=
r
.
total_duration
;
printf
(
"
%
-
40s
:
%
10
"
PRIu64
"
x
%
15
"
PRIu64
"
=
%
15
"
PRIu64
"
\
n
"
name
num_calls
r
.
total_duration
/
num_calls
r
.
total_duration
)
;
}
}
const
uint64_t
t1
=
TicksAfter
(
)
;
analyze_elapsed_
+
=
t1
-
t0
;
printf
(
"
Total
clocks
during
analysis
:
%
"
PRIu64
"
\
n
"
analyze_elapsed_
)
;
printf
(
"
Total
clocks
measured
:
%
"
PRIu64
"
\
n
"
total_visible_duration
)
;
}
void
Reset
(
)
{
analyze_elapsed_
=
0
;
JXL_CHECK
(
depth_
=
=
0
)
;
num_zones_
=
0
;
memset
(
nodes_
0
sizeof
(
nodes_
)
)
;
memset
(
zones_
0
sizeof
(
zones_
)
)
;
}
private
:
#
if
JXL_ARCH_X64
static
bool
SameOffset
(
const
__m128i
zone
const
uint64_t
biased_offset
)
{
const
uint64_t
num_calls
=
_mm_cvtsi128_si64
(
zone
)
;
return
(
num_calls
>
>
Accumulator
:
:
kNumCallBits
)
=
=
biased_offset
;
}
#
endif
void
UpdateOrAdd
(
const
uint64_t
biased_offset
const
uint64_t
num_calls
const
uint64_t
duration
)
{
JXL_ASSERT
(
biased_offset
<
(
1ULL
<
<
Packet
:
:
kOffsetBits
)
)
;
#
if
JXL_ARCH_X64
const
__m128i
num_calls_64
=
_mm_cvtsi64_si128
(
num_calls
)
;
const
__m128i
duration_64
=
_mm_cvtsi64_si128
(
duration
)
;
const
__m128i
add_duration_call
=
_mm_unpacklo_epi64
(
num_calls_64
duration_64
)
;
__m128i
*
const
JXL_RESTRICT
zones
=
reinterpret_cast
<
__m128i
*
>
(
zones_
)
;
__m128i
prev
=
_mm_load_si128
(
zones
)
;
if
(
SameOffset
(
prev
biased_offset
)
)
{
prev
=
_mm_add_epi64
(
prev
add_duration_call
)
;
JXL_ASSERT
(
SameOffset
(
prev
biased_offset
)
)
;
_mm_store_si128
(
zones
prev
)
;
return
;
}
for
(
size_t
i
=
1
;
i
<
num_zones_
;
+
+
i
)
{
__m128i
zone
=
_mm_load_si128
(
zones
+
i
)
;
if
(
SameOffset
(
zone
biased_offset
)
)
{
zone
=
_mm_add_epi64
(
zone
add_duration_call
)
;
JXL_ASSERT
(
SameOffset
(
zone
biased_offset
)
)
;
_mm_store_si128
(
zones
+
i
-
1
zone
)
;
_mm_store_si128
(
zones
+
i
prev
)
;
return
;
}
prev
=
zone
;
}
const
__m128i
biased_offset_64
=
_mm_slli_epi64
(
_mm_cvtsi64_si128
(
biased_offset
)
Accumulator
:
:
kNumCallBits
)
;
const
__m128i
zone
=
_mm_add_epi64
(
biased_offset_64
add_duration_call
)
;
JXL_ASSERT
(
SameOffset
(
zone
biased_offset
)
)
;
JXL_ASSERT
(
num_zones_
<
kMaxZones
)
;
_mm_store_si128
(
zones
+
num_zones_
zone
)
;
+
+
num_zones_
;
#
else
if
(
zones_
[
0
]
.
BiasedOffset
(
)
=
=
biased_offset
)
{
zones_
[
0
]
.
total_duration
+
=
duration
;
zones_
[
0
]
.
num_calls
+
=
num_calls
;
JXL_ASSERT
(
zones_
[
0
]
.
BiasedOffset
(
)
=
=
biased_offset
)
;
return
;
}
for
(
size_t
i
=
1
;
i
<
num_zones_
;
+
+
i
)
{
if
(
zones_
[
i
]
.
BiasedOffset
(
)
=
=
biased_offset
)
{
zones_
[
i
]
.
total_duration
+
=
duration
;
zones_
[
i
]
.
num_calls
+
=
num_calls
;
JXL_ASSERT
(
zones_
[
i
]
.
BiasedOffset
(
)
=
=
biased_offset
)
;
const
Accumulator
prev
=
zones_
[
i
-
1
]
;
zones_
[
i
-
1
]
=
zones_
[
i
]
;
zones_
[
i
]
=
prev
;
return
;
}
}
JXL_ASSERT
(
num_zones_
<
kMaxZones
)
;
Accumulator
*
JXL_RESTRICT
zone
=
zones_
+
num_zones_
;
zone
-
>
num_calls
=
(
biased_offset
<
<
Accumulator
:
:
kNumCallBits
)
+
num_calls
;
zone
-
>
total_duration
=
duration
;
JXL_ASSERT
(
zone
-
>
BiasedOffset
(
)
=
=
biased_offset
)
;
+
+
num_zones_
;
#
endif
}
void
MergeDuplicates
(
)
{
const
uintptr_t
string_origin
=
StringOrigin
(
)
;
for
(
size_t
i
=
0
;
i
<
num_zones_
;
+
+
i
)
{
const
uint64_t
biased_offset
=
zones_
[
i
]
.
BiasedOffset
(
)
;
const
char
*
name
=
reinterpret_cast
<
const
char
*
>
(
string_origin
+
biased_offset
)
;
uint64_t
num_calls
=
zones_
[
i
]
.
NumCalls
(
)
;
for
(
size_t
j
=
i
+
1
;
j
<
num_zones_
;
)
{
if
(
!
strcmp
(
name
reinterpret_cast
<
const
char
*
>
(
string_origin
+
zones_
[
j
]
.
BiasedOffset
(
)
)
)
)
{
num_calls
+
=
zones_
[
j
]
.
NumCalls
(
)
;
zones_
[
i
]
.
total_duration
+
=
zones_
[
j
]
.
total_duration
;
zones_
[
j
]
=
zones_
[
-
-
num_zones_
]
;
}
else
{
+
+
j
;
}
}
JXL_ASSERT
(
num_calls
<
(
1ULL
<
<
Accumulator
:
:
kNumCallBits
)
)
;
zones_
[
i
]
.
num_calls
=
(
biased_offset
<
<
Accumulator
:
:
kNumCallBits
)
+
num_calls
;
}
}
uint64_t
analyze_elapsed_
=
0
;
uint64_t
self_overhead_
=
0
;
uint64_t
child_overhead_
=
0
;
size_t
depth_
=
0
;
size_t
num_zones_
=
0
;
alignas
(
64
)
ProfilerNode
nodes_
[
kMaxDepth
]
;
alignas
(
64
)
Accumulator
zones_
[
kMaxZones
]
;
}
;
ThreadSpecific
:
:
ThreadSpecific
(
const
char
*
zone_name
)
:
packets_
(
static_cast
<
Packet
*
>
(
CacheAligned
:
:
Allocate
(
PROFILER_THREAD_STORAGE
<
<
20
)
)
)
num_packets_
(
0
)
max_packets_
(
PROFILER_THREAD_STORAGE
<
<
17
)
string_origin_
(
StringOrigin
(
)
)
results_
(
static_cast
<
Results
*
>
(
CacheAligned
:
:
Allocate
(
sizeof
(
Results
)
)
)
)
{
new
(
results_
)
Results
(
)
;
const
uint64_t
biased_offset
=
reinterpret_cast
<
uintptr_t
>
(
zone_name
)
-
string_origin_
;
JXL_CHECK
(
biased_offset
<
=
(
1ULL
<
<
Packet
:
:
kOffsetBits
)
)
;
}
ThreadSpecific
:
:
~
ThreadSpecific
(
)
{
results_
-
>
~
Results
(
)
;
CacheAligned
:
:
Free
(
packets_
)
;
CacheAligned
:
:
Free
(
results_
)
;
}
void
ThreadSpecific
:
:
FlushStorage
(
)
{
results_
-
>
AnalyzePackets
(
packets_
num_packets_
)
;
num_packets_
=
0
;
}
#
if
PROFILER_BUFFER
void
ThreadSpecific
:
:
FlushBuffer
(
)
{
if
(
num_packets_
+
kBufferCapacity
>
max_packets_
)
{
FlushStorage
(
)
;
}
HWY_STATIC_DISPATCH
(
StreamCacheLine
)
(
buffer_
packets_
+
num_packets_
)
;
num_packets_
+
=
kBufferCapacity
;
buffer_size_
=
0
;
}
#
endif
void
ThreadSpecific
:
:
AnalyzeRemainingPackets
(
)
{
#
if
PROFILER_BUFFER
hwy
:
:
StoreFence
(
)
;
if
(
num_packets_
+
buffer_size_
>
max_packets_
)
{
results_
-
>
AnalyzePackets
(
packets_
num_packets_
)
;
num_packets_
=
0
;
}
memcpy
(
packets_
+
num_packets_
buffer_
buffer_size_
*
sizeof
(
Packet
)
)
;
num_packets_
+
=
buffer_size_
;
buffer_size_
=
0
;
#
endif
results_
-
>
AnalyzePackets
(
packets_
num_packets_
)
;
num_packets_
=
0
;
}
void
ThreadSpecific
:
:
ComputeOverhead
(
)
{
uint64_t
self_overhead
;
{
const
size_t
kNumSamples
=
32
;
uint32_t
samples
[
kNumSamples
]
;
for
(
size_t
idx_sample
=
0
;
idx_sample
<
kNumSamples
;
+
+
idx_sample
)
{
const
size_t
kNumDurations
=
1024
;
uint32_t
durations
[
kNumDurations
]
;
for
(
size_t
idx_duration
=
0
;
idx_duration
<
kNumDurations
;
+
+
idx_duration
)
{
{
PROFILER_ZONE
(
"
Dummy
Zone
(
never
shown
)
"
)
;
}
#
if
PROFILER_BUFFER
const
uint64_t
duration
=
results_
-
>
ZoneDuration
(
buffer_
)
;
buffer_size_
=
0
;
#
else
const
uint64_t
duration
=
results_
-
>
ZoneDuration
(
packets_
)
;
num_packets_
=
0
;
#
endif
durations
[
idx_duration
]
=
static_cast
<
uint32_t
>
(
duration
)
;
JXL_CHECK
(
num_packets_
=
=
0
)
;
}
CountingSort
(
durations
durations
+
kNumDurations
)
;
samples
[
idx_sample
]
=
HalfSampleMode
(
)
(
durations
kNumDurations
)
;
}
CountingSort
(
samples
samples
+
kNumSamples
)
;
self_overhead
=
samples
[
kNumSamples
/
2
]
;
#
if
PROFILER_PRINT_OVERHEAD
printf
(
"
Overhead
:
%
zu
\
n
"
self_overhead
)
;
#
endif
results_
-
>
SetSelfOverhead
(
self_overhead
)
;
}
const
size_t
kNumSamples
=
32
;
uint32_t
samples
[
kNumSamples
]
;
for
(
size_t
idx_sample
=
0
;
idx_sample
<
kNumSamples
;
+
+
idx_sample
)
{
const
size_t
kNumDurations
=
16
;
uint32_t
durations
[
kNumDurations
]
;
for
(
size_t
idx_duration
=
0
;
idx_duration
<
kNumDurations
;
+
+
idx_duration
)
{
const
size_t
kReps
=
10000
;
JXL_CHECK
(
kReps
*
2
<
max_packets_
)
;
#
if
JXL_ARCH_X64
_mm_mfence
(
)
;
#
endif
const
uint64_t
t0
=
TicksBefore
(
)
;
for
(
size_t
i
=
0
;
i
<
kReps
;
+
+
i
)
{
PROFILER_ZONE
(
"
Dummy
"
)
;
}
hwy
:
:
StoreFence
(
)
;
const
uint64_t
t1
=
TicksAfter
(
)
;
#
if
PROFILER_BUFFER
JXL_CHECK
(
num_packets_
+
buffer_size_
=
=
kReps
*
2
)
;
buffer_size_
=
0
;
#
else
JXL_CHECK
(
num_packets_
=
=
kReps
*
2
)
;
#
endif
num_packets_
=
0
;
const
uint64_t
avg_duration
=
(
t1
-
t0
+
kReps
/
2
)
/
kReps
;
durations
[
idx_duration
]
=
static_cast
<
uint32_t
>
(
ClampedSubtract
(
avg_duration
self_overhead
)
)
;
}
CountingSort
(
durations
durations
+
kNumDurations
)
;
samples
[
idx_sample
]
=
HalfSampleMode
(
)
(
durations
kNumDurations
)
;
}
CountingSort
(
samples
samples
+
kNumSamples
)
;
const
uint64_t
child_overhead
=
samples
[
9
*
kNumSamples
/
10
]
;
#
if
PROFILER_PRINT_OVERHEAD
printf
(
"
Child
overhead
:
%
zu
\
n
"
child_overhead
)
;
#
endif
results_
-
>
SetChildOverhead
(
child_overhead
)
;
}
namespace
{
class
ThreadList
{
public
:
void
Add
(
ThreadSpecific
*
const
ts
)
{
const
uint32_t
index
=
num_threads_
.
fetch_add
(
1
std
:
:
memory_order_relaxed
)
;
JXL_CHECK
(
index
<
kMaxThreads
)
;
threads_
[
index
]
=
ts
;
}
void
PrintResults
(
)
{
const
uint32_t
num_threads
=
num_threads_
.
load
(
std
:
:
memory_order_relaxed
)
;
for
(
uint32_t
i
=
0
;
i
<
num_threads
;
+
+
i
)
{
threads_
[
i
]
-
>
AnalyzeRemainingPackets
(
)
;
}
for
(
uint32_t
i
=
1
;
i
<
num_threads
;
+
+
i
)
{
threads_
[
0
]
-
>
GetResults
(
)
.
Assimilate
(
threads_
[
i
]
-
>
GetResults
(
)
)
;
}
if
(
num_threads
!
=
0
)
{
threads_
[
0
]
-
>
GetResults
(
)
.
Print
(
)
;
for
(
uint32_t
i
=
0
;
i
<
num_threads
;
+
+
i
)
{
threads_
[
i
]
-
>
GetResults
(
)
.
Reset
(
)
;
}
}
}
private
:
alignas
(
64
)
ThreadSpecific
*
threads_
[
kMaxThreads
]
;
std
:
:
atomic
<
uint32_t
>
num_threads_
{
0
}
;
}
;
ThreadList
&
GetThreadList
(
)
{
static
ThreadList
threads_
;
return
threads_
;
}
}
ThreadSpecific
*
Zone
:
:
InitThreadSpecific
(
const
char
*
zone_name
)
{
void
*
mem
=
CacheAligned
:
:
Allocate
(
sizeof
(
ThreadSpecific
)
)
;
ThreadSpecific
*
thread_specific
=
new
(
mem
)
ThreadSpecific
(
zone_name
)
;
GetThreadList
(
)
.
Add
(
thread_specific
)
;
GetThreadSpecific
(
)
=
thread_specific
;
thread_specific
-
>
ComputeOverhead
(
)
;
return
thread_specific
;
}
void
Zone
:
:
PrintResults
(
)
{
GetThreadList
(
)
.
PrintResults
(
)
;
}
}
#
endif
