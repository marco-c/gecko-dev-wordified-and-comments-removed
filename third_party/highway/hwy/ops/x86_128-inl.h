#
include
<
emmintrin
.
h
>
#
include
<
smmintrin
.
h
>
#
include
<
stddef
.
h
>
#
include
<
stdint
.
h
>
#
include
"
hwy
/
base
.
h
"
#
include
"
hwy
/
ops
/
shared
-
inl
.
h
"
#
ifndef
HWY_LOADDUP_ASM
#
define
HWY_LOADDUP_ASM
0
#
endif
HWY_BEFORE_NAMESPACE
(
)
;
namespace
hwy
{
namespace
HWY_NAMESPACE
{
template
<
typename
T
>
struct
Raw128
{
using
type
=
__m128i
;
}
;
template
<
>
struct
Raw128
<
float
>
{
using
type
=
__m128
;
}
;
template
<
>
struct
Raw128
<
double
>
{
using
type
=
__m128d
;
}
;
template
<
typename
T
>
using
Full128
=
Simd
<
T
16
/
sizeof
(
T
)
>
;
template
<
typename
T
size_t
N
=
16
/
sizeof
(
T
)
>
class
Vec128
{
using
Raw
=
typename
Raw128
<
T
>
:
:
type
;
public
:
HWY_INLINE
Vec128
&
operator
*
=
(
const
Vec128
other
)
{
return
*
this
=
(
*
this
*
other
)
;
}
HWY_INLINE
Vec128
&
operator
/
=
(
const
Vec128
other
)
{
return
*
this
=
(
*
this
/
other
)
;
}
HWY_INLINE
Vec128
&
operator
+
=
(
const
Vec128
other
)
{
return
*
this
=
(
*
this
+
other
)
;
}
HWY_INLINE
Vec128
&
operator
-
=
(
const
Vec128
other
)
{
return
*
this
=
(
*
this
-
other
)
;
}
HWY_INLINE
Vec128
&
operator
&
=
(
const
Vec128
other
)
{
return
*
this
=
(
*
this
&
other
)
;
}
HWY_INLINE
Vec128
&
operator
|
=
(
const
Vec128
other
)
{
return
*
this
=
(
*
this
|
other
)
;
}
HWY_INLINE
Vec128
&
operator
^
=
(
const
Vec128
other
)
{
return
*
this
=
(
*
this
^
other
)
;
}
Raw
raw
;
}
;
template
<
typename
T
size_t
N
=
16
/
sizeof
(
T
)
>
class
Mask128
{
using
Raw
=
typename
Raw128
<
T
>
:
:
type
;
public
:
Raw
raw
;
}
;
namespace
detail
{
HWY_API
__m128i
BitCastToInteger
(
__m128i
v
)
{
return
v
;
}
HWY_API
__m128i
BitCastToInteger
(
__m128
v
)
{
return
_mm_castps_si128
(
v
)
;
}
HWY_API
__m128i
BitCastToInteger
(
__m128d
v
)
{
return
_mm_castpd_si128
(
v
)
;
}
template
<
typename
T
size_t
N
>
HWY_API
Vec128
<
uint8_t
N
*
sizeof
(
T
)
>
BitCastToByte
(
Vec128
<
T
N
>
v
)
{
return
Vec128
<
uint8_t
N
*
sizeof
(
T
)
>
{
BitCastToInteger
(
v
.
raw
)
}
;
}
template
<
typename
T
>
struct
BitCastFromInteger128
{
HWY_INLINE
__m128i
operator
(
)
(
__m128i
v
)
{
return
v
;
}
}
;
template
<
>
struct
BitCastFromInteger128
<
float
>
{
HWY_INLINE
__m128
operator
(
)
(
__m128i
v
)
{
return
_mm_castsi128_ps
(
v
)
;
}
}
;
template
<
>
struct
BitCastFromInteger128
<
double
>
{
HWY_INLINE
__m128d
operator
(
)
(
__m128i
v
)
{
return
_mm_castsi128_pd
(
v
)
;
}
}
;
template
<
typename
T
size_t
N
>
HWY_API
Vec128
<
T
N
>
BitCastFromByte
(
Simd
<
T
N
>
Vec128
<
uint8_t
N
*
sizeof
(
T
)
>
v
)
{
return
Vec128
<
T
N
>
{
BitCastFromInteger128
<
T
>
(
)
(
v
.
raw
)
}
;
}
}
template
<
typename
T
size_t
N
typename
FromT
>
HWY_API
Vec128
<
T
N
>
BitCast
(
Simd
<
T
N
>
d
Vec128
<
FromT
N
*
sizeof
(
T
)
/
sizeof
(
FromT
)
>
v
)
{
return
detail
:
:
BitCastFromByte
(
d
detail
:
:
BitCastToByte
(
v
)
)
;
}
template
<
typename
T
size_t
N
HWY_IF_LE128
(
T
N
)
>
HWY_API
Vec128
<
T
N
>
Zero
(
Simd
<
T
N
>
)
{
return
Vec128
<
T
N
>
{
_mm_setzero_si128
(
)
}
;
}
template
<
size_t
N
HWY_IF_LE128
(
float
N
)
>
HWY_API
Vec128
<
float
N
>
Zero
(
Simd
<
float
N
>
)
{
return
Vec128
<
float
N
>
{
_mm_setzero_ps
(
)
}
;
}
template
<
size_t
N
HWY_IF_LE128
(
double
N
)
>
HWY_API
Vec128
<
double
N
>
Zero
(
Simd
<
double
N
>
)
{
return
Vec128
<
double
N
>
{
_mm_setzero_pd
(
)
}
;
}
template
<
size_t
N
HWY_IF_LE128
(
uint8_t
N
)
>
HWY_API
Vec128
<
uint8_t
N
>
Set
(
Simd
<
uint8_t
N
>
const
uint8_t
t
)
{
return
Vec128
<
uint8_t
N
>
{
_mm_set1_epi8
(
static_cast
<
char
>
(
t
)
)
}
;
}
template
<
size_t
N
HWY_IF_LE128
(
uint16_t
N
)
>
HWY_API
Vec128
<
uint16_t
N
>
Set
(
Simd
<
uint16_t
N
>
const
uint16_t
t
)
{
return
Vec128
<
uint16_t
N
>
{
_mm_set1_epi16
(
static_cast
<
short
>
(
t
)
)
}
;
}
template
<
size_t
N
HWY_IF_LE128
(
uint32_t
N
)
>
HWY_API
Vec128
<
uint32_t
N
>
Set
(
Simd
<
uint32_t
N
>
const
uint32_t
t
)
{
return
Vec128
<
uint32_t
N
>
{
_mm_set1_epi32
(
static_cast
<
int
>
(
t
)
)
}
;
}
template
<
size_t
N
HWY_IF_LE128
(
uint64_t
N
)
>
HWY_API
Vec128
<
uint64_t
N
>
Set
(
Simd
<
uint64_t
N
>
const
uint64_t
t
)
{
return
Vec128
<
uint64_t
N
>
{
_mm_set1_epi64x
(
static_cast
<
long
long
>
(
t
)
)
}
;
}
template
<
size_t
N
HWY_IF_LE128
(
int8_t
N
)
>
HWY_API
Vec128
<
int8_t
N
>
Set
(
Simd
<
int8_t
N
>
const
int8_t
t
)
{
return
Vec128
<
int8_t
N
>
{
_mm_set1_epi8
(
static_cast
<
char
>
(
t
)
)
}
;
}
template
<
size_t
N
HWY_IF_LE128
(
int16_t
N
)
>
HWY_API
Vec128
<
int16_t
N
>
Set
(
Simd
<
int16_t
N
>
const
int16_t
t
)
{
return
Vec128
<
int16_t
N
>
{
_mm_set1_epi16
(
static_cast
<
short
>
(
t
)
)
}
;
}
template
<
size_t
N
HWY_IF_LE128
(
int32_t
N
)
>
HWY_API
Vec128
<
int32_t
N
>
Set
(
Simd
<
int32_t
N
>
const
int32_t
t
)
{
return
Vec128
<
int32_t
N
>
{
_mm_set1_epi32
(
t
)
}
;
}
template
<
size_t
N
HWY_IF_LE128
(
int64_t
N
)
>
HWY_API
Vec128
<
int64_t
N
>
Set
(
Simd
<
int64_t
N
>
const
int64_t
t
)
{
return
Vec128
<
int64_t
N
>
{
_mm_set1_epi64x
(
static_cast
<
long
long
>
(
t
)
)
}
;
}
template
<
size_t
N
HWY_IF_LE128
(
float
N
)
>
HWY_API
Vec128
<
float
N
>
Set
(
Simd
<
float
N
>
const
float
t
)
{
return
Vec128
<
float
N
>
{
_mm_set1_ps
(
t
)
}
;
}
template
<
size_t
N
HWY_IF_LE128
(
double
N
)
>
HWY_API
Vec128
<
double
N
>
Set
(
Simd
<
double
N
>
const
double
t
)
{
return
Vec128
<
double
N
>
{
_mm_set1_pd
(
t
)
}
;
}
HWY_DIAGNOSTICS
(
push
)
HWY_DIAGNOSTICS_OFF
(
disable
:
4700
ignored
"
-
Wuninitialized
"
)
template
<
typename
T
size_t
N
HWY_IF_LE128
(
T
N
)
>
HWY_API
Vec128
<
T
N
>
Undefined
(
Simd
<
T
N
>
)
{
return
Vec128
<
T
N
>
{
_mm_undefined_si128
(
)
}
;
}
template
<
size_t
N
HWY_IF_LE128
(
float
N
)
>
HWY_API
Vec128
<
float
N
>
Undefined
(
Simd
<
float
N
>
)
{
return
Vec128
<
float
N
>
{
_mm_undefined_ps
(
)
}
;
}
template
<
size_t
N
HWY_IF_LE128
(
double
N
)
>
HWY_API
Vec128
<
double
N
>
Undefined
(
Simd
<
double
N
>
)
{
return
Vec128
<
double
N
>
{
_mm_undefined_pd
(
)
}
;
}
HWY_DIAGNOSTICS
(
pop
)
template
<
size_t
N
>
HWY_API
uint8_t
GetLane
(
const
Vec128
<
uint8_t
N
>
v
)
{
return
_mm_cvtsi128_si32
(
v
.
raw
)
&
0xFF
;
}
template
<
size_t
N
>
HWY_API
int8_t
GetLane
(
const
Vec128
<
int8_t
N
>
v
)
{
return
_mm_cvtsi128_si32
(
v
.
raw
)
&
0xFF
;
}
template
<
size_t
N
>
HWY_API
uint16_t
GetLane
(
const
Vec128
<
uint16_t
N
>
v
)
{
return
_mm_cvtsi128_si32
(
v
.
raw
)
&
0xFFFF
;
}
template
<
size_t
N
>
HWY_API
int16_t
GetLane
(
const
Vec128
<
int16_t
N
>
v
)
{
return
_mm_cvtsi128_si32
(
v
.
raw
)
&
0xFFFF
;
}
template
<
size_t
N
>
HWY_API
uint32_t
GetLane
(
const
Vec128
<
uint32_t
N
>
v
)
{
return
_mm_cvtsi128_si32
(
v
.
raw
)
;
}
template
<
size_t
N
>
HWY_API
int32_t
GetLane
(
const
Vec128
<
int32_t
N
>
v
)
{
return
_mm_cvtsi128_si32
(
v
.
raw
)
;
}
template
<
size_t
N
>
HWY_API
float
GetLane
(
const
Vec128
<
float
N
>
v
)
{
return
_mm_cvtss_f32
(
v
.
raw
)
;
}
template
<
size_t
N
>
HWY_API
uint64_t
GetLane
(
const
Vec128
<
uint64_t
N
>
v
)
{
#
if
HWY_ARCH_X86_32
alignas
(
16
)
uint64_t
lanes
[
2
]
;
Store
(
v
Simd
<
uint64_t
N
>
(
)
lanes
)
;
return
lanes
[
0
]
;
#
else
return
_mm_cvtsi128_si64
(
v
.
raw
)
;
#
endif
}
template
<
size_t
N
>
HWY_API
int64_t
GetLane
(
const
Vec128
<
int64_t
N
>
v
)
{
#
if
HWY_ARCH_X86_32
alignas
(
16
)
int64_t
lanes
[
2
]
;
Store
(
v
Simd
<
int64_t
N
>
(
)
lanes
)
;
return
lanes
[
0
]
;
#
else
return
_mm_cvtsi128_si64
(
v
.
raw
)
;
#
endif
}
template
<
size_t
N
>
HWY_API
double
GetLane
(
const
Vec128
<
double
N
>
v
)
{
return
_mm_cvtsd_f64
(
v
.
raw
)
;
}
template
<
typename
T
size_t
N
>
HWY_API
Vec128
<
T
N
>
And
(
Vec128
<
T
N
>
a
Vec128
<
T
N
>
b
)
{
return
Vec128
<
T
N
>
{
_mm_and_si128
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
float
N
>
And
(
const
Vec128
<
float
N
>
a
const
Vec128
<
float
N
>
b
)
{
return
Vec128
<
float
N
>
{
_mm_and_ps
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
double
N
>
And
(
const
Vec128
<
double
N
>
a
const
Vec128
<
double
N
>
b
)
{
return
Vec128
<
double
N
>
{
_mm_and_pd
(
a
.
raw
b
.
raw
)
}
;
}
template
<
typename
T
size_t
N
>
HWY_API
Vec128
<
T
N
>
AndNot
(
Vec128
<
T
N
>
not_mask
Vec128
<
T
N
>
mask
)
{
return
Vec128
<
T
N
>
{
_mm_andnot_si128
(
not_mask
.
raw
mask
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
float
N
>
AndNot
(
const
Vec128
<
float
N
>
not_mask
const
Vec128
<
float
N
>
mask
)
{
return
Vec128
<
float
N
>
{
_mm_andnot_ps
(
not_mask
.
raw
mask
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
double
N
>
AndNot
(
const
Vec128
<
double
N
>
not_mask
const
Vec128
<
double
N
>
mask
)
{
return
Vec128
<
double
N
>
{
_mm_andnot_pd
(
not_mask
.
raw
mask
.
raw
)
}
;
}
template
<
typename
T
size_t
N
>
HWY_API
Vec128
<
T
N
>
Or
(
Vec128
<
T
N
>
a
Vec128
<
T
N
>
b
)
{
return
Vec128
<
T
N
>
{
_mm_or_si128
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
float
N
>
Or
(
const
Vec128
<
float
N
>
a
const
Vec128
<
float
N
>
b
)
{
return
Vec128
<
float
N
>
{
_mm_or_ps
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
double
N
>
Or
(
const
Vec128
<
double
N
>
a
const
Vec128
<
double
N
>
b
)
{
return
Vec128
<
double
N
>
{
_mm_or_pd
(
a
.
raw
b
.
raw
)
}
;
}
template
<
typename
T
size_t
N
>
HWY_API
Vec128
<
T
N
>
Xor
(
Vec128
<
T
N
>
a
Vec128
<
T
N
>
b
)
{
return
Vec128
<
T
N
>
{
_mm_xor_si128
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
float
N
>
Xor
(
const
Vec128
<
float
N
>
a
const
Vec128
<
float
N
>
b
)
{
return
Vec128
<
float
N
>
{
_mm_xor_ps
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
double
N
>
Xor
(
const
Vec128
<
double
N
>
a
const
Vec128
<
double
N
>
b
)
{
return
Vec128
<
double
N
>
{
_mm_xor_pd
(
a
.
raw
b
.
raw
)
}
;
}
template
<
typename
T
size_t
N
>
HWY_API
Vec128
<
T
N
>
Not
(
const
Vec128
<
T
N
>
v
)
{
using
TU
=
MakeUnsigned
<
T
>
;
#
if
HWY_TARGET
=
=
HWY_AVX3
const
__m128i
vu
=
BitCast
(
Simd
<
TU
N
>
(
)
v
)
.
raw
;
return
BitCast
(
Simd
<
T
N
>
(
)
Vec128
<
TU
N
>
{
_mm_ternarylogic_epi32
(
vu
vu
vu
0x55
)
}
)
;
#
else
return
Xor
(
v
BitCast
(
Simd
<
T
N
>
(
)
Vec128
<
TU
N
>
{
_mm_set1_epi32
(
-
1
)
}
)
)
;
#
endif
}
template
<
typename
T
size_t
N
>
HWY_API
Vec128
<
T
N
>
operator
&
(
const
Vec128
<
T
N
>
a
const
Vec128
<
T
N
>
b
)
{
return
And
(
a
b
)
;
}
template
<
typename
T
size_t
N
>
HWY_API
Vec128
<
T
N
>
operator
|
(
const
Vec128
<
T
N
>
a
const
Vec128
<
T
N
>
b
)
{
return
Or
(
a
b
)
;
}
template
<
typename
T
size_t
N
>
HWY_API
Vec128
<
T
N
>
operator
^
(
const
Vec128
<
T
N
>
a
const
Vec128
<
T
N
>
b
)
{
return
Xor
(
a
b
)
;
}
template
<
typename
T
size_t
N
>
HWY_API
Vec128
<
T
N
>
CopySign
(
const
Vec128
<
T
N
>
magn
const
Vec128
<
T
N
>
sign
)
{
static_assert
(
IsFloat
<
T
>
(
)
"
Only
makes
sense
for
floating
-
point
"
)
;
const
Simd
<
T
N
>
d
;
const
auto
msb
=
SignBit
(
d
)
;
#
if
HWY_TARGET
=
=
HWY_AVX3
const
Rebind
<
MakeUnsigned
<
T
>
decltype
(
d
)
>
du
;
const
__m128i
out
=
_mm_ternarylogic_epi32
(
BitCast
(
du
msb
)
.
raw
BitCast
(
du
magn
)
.
raw
BitCast
(
du
sign
)
.
raw
0xAC
)
;
return
BitCast
(
d
decltype
(
Zero
(
du
)
)
{
out
}
)
;
#
else
return
Or
(
AndNot
(
msb
magn
)
And
(
msb
sign
)
)
;
#
endif
}
template
<
typename
T
size_t
N
>
HWY_API
Vec128
<
T
N
>
CopySignToAbs
(
const
Vec128
<
T
N
>
abs
const
Vec128
<
T
N
>
sign
)
{
#
if
HWY_TARGET
=
=
HWY_AVX3
return
CopySign
(
abs
sign
)
;
#
else
return
Or
(
abs
And
(
SignBit
(
Simd
<
T
N
>
(
)
)
sign
)
)
;
#
endif
}
template
<
typename
T
size_t
N
>
HWY_API
Mask128
<
T
N
>
MaskFromVec
(
const
Vec128
<
T
N
>
v
)
{
return
Mask128
<
T
N
>
{
v
.
raw
}
;
}
template
<
typename
T
size_t
N
>
HWY_API
Vec128
<
T
N
>
VecFromMask
(
const
Mask128
<
T
N
>
v
)
{
return
Vec128
<
T
N
>
{
v
.
raw
}
;
}
template
<
typename
T
size_t
N
>
HWY_API
Vec128
<
T
N
>
VecFromMask
(
const
Simd
<
T
N
>
const
Mask128
<
T
N
>
v
)
{
return
Vec128
<
T
N
>
{
v
.
raw
}
;
}
template
<
typename
T
size_t
N
>
HWY_API
Vec128
<
T
N
>
IfThenElse
(
Mask128
<
T
N
>
mask
Vec128
<
T
N
>
yes
Vec128
<
T
N
>
no
)
{
return
Vec128
<
T
N
>
{
_mm_blendv_epi8
(
no
.
raw
yes
.
raw
mask
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
float
N
>
IfThenElse
(
const
Mask128
<
float
N
>
mask
const
Vec128
<
float
N
>
yes
const
Vec128
<
float
N
>
no
)
{
return
Vec128
<
float
N
>
{
_mm_blendv_ps
(
no
.
raw
yes
.
raw
mask
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
double
N
>
IfThenElse
(
const
Mask128
<
double
N
>
mask
const
Vec128
<
double
N
>
yes
const
Vec128
<
double
N
>
no
)
{
return
Vec128
<
double
N
>
{
_mm_blendv_pd
(
no
.
raw
yes
.
raw
mask
.
raw
)
}
;
}
template
<
typename
T
size_t
N
>
HWY_API
Vec128
<
T
N
>
IfThenElseZero
(
Mask128
<
T
N
>
mask
Vec128
<
T
N
>
yes
)
{
return
yes
&
VecFromMask
(
Simd
<
T
N
>
(
)
mask
)
;
}
template
<
typename
T
size_t
N
>
HWY_API
Vec128
<
T
N
>
IfThenZeroElse
(
Mask128
<
T
N
>
mask
Vec128
<
T
N
>
no
)
{
return
AndNot
(
VecFromMask
(
Simd
<
T
N
>
(
)
mask
)
no
)
;
}
template
<
typename
T
size_t
N
HWY_IF_FLOAT
(
T
)
>
HWY_API
Vec128
<
T
N
>
ZeroIfNegative
(
Vec128
<
T
N
>
v
)
{
const
Simd
<
T
N
>
d
;
return
IfThenElse
(
MaskFromVec
(
v
)
Zero
(
d
)
v
)
;
}
template
<
typename
T
size_t
N
>
HWY_API
Mask128
<
T
N
>
Not
(
const
Mask128
<
T
N
>
m
)
{
const
Simd
<
T
N
>
d
;
return
MaskFromVec
(
Not
(
VecFromMask
(
d
m
)
)
)
;
}
template
<
typename
T
size_t
N
>
HWY_API
Mask128
<
T
N
>
And
(
const
Mask128
<
T
N
>
a
Mask128
<
T
N
>
b
)
{
const
Simd
<
T
N
>
d
;
return
MaskFromVec
(
And
(
VecFromMask
(
d
a
)
VecFromMask
(
d
b
)
)
)
;
}
template
<
typename
T
size_t
N
>
HWY_API
Mask128
<
T
N
>
AndNot
(
const
Mask128
<
T
N
>
a
Mask128
<
T
N
>
b
)
{
const
Simd
<
T
N
>
d
;
return
MaskFromVec
(
AndNot
(
VecFromMask
(
d
a
)
VecFromMask
(
d
b
)
)
)
;
}
template
<
typename
T
size_t
N
>
HWY_API
Mask128
<
T
N
>
Or
(
const
Mask128
<
T
N
>
a
Mask128
<
T
N
>
b
)
{
const
Simd
<
T
N
>
d
;
return
MaskFromVec
(
Or
(
VecFromMask
(
d
a
)
VecFromMask
(
d
b
)
)
)
;
}
template
<
typename
T
size_t
N
>
HWY_API
Mask128
<
T
N
>
Xor
(
const
Mask128
<
T
N
>
a
Mask128
<
T
N
>
b
)
{
const
Simd
<
T
N
>
d
;
return
MaskFromVec
(
Xor
(
VecFromMask
(
d
a
)
VecFromMask
(
d
b
)
)
)
;
}
template
<
typename
TFrom
typename
TTo
size_t
N
>
HWY_API
Mask128
<
TTo
N
>
RebindMask
(
Simd
<
TTo
N
>
Mask128
<
TFrom
N
>
m
)
{
static_assert
(
sizeof
(
TFrom
)
=
=
sizeof
(
TTo
)
"
Must
have
same
size
"
)
;
const
Simd
<
TFrom
N
>
d
;
return
MaskFromVec
(
BitCast
(
Simd
<
TTo
N
>
(
)
VecFromMask
(
d
m
)
)
)
;
}
template
<
size_t
N
>
HWY_API
Mask128
<
uint8_t
N
>
operator
=
=
(
const
Vec128
<
uint8_t
N
>
a
const
Vec128
<
uint8_t
N
>
b
)
{
return
Mask128
<
uint8_t
N
>
{
_mm_cmpeq_epi8
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Mask128
<
uint16_t
N
>
operator
=
=
(
const
Vec128
<
uint16_t
N
>
a
const
Vec128
<
uint16_t
N
>
b
)
{
return
Mask128
<
uint16_t
N
>
{
_mm_cmpeq_epi16
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Mask128
<
uint32_t
N
>
operator
=
=
(
const
Vec128
<
uint32_t
N
>
a
const
Vec128
<
uint32_t
N
>
b
)
{
return
Mask128
<
uint32_t
N
>
{
_mm_cmpeq_epi32
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Mask128
<
uint64_t
N
>
operator
=
=
(
const
Vec128
<
uint64_t
N
>
a
const
Vec128
<
uint64_t
N
>
b
)
{
return
Mask128
<
uint64_t
N
>
{
_mm_cmpeq_epi64
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Mask128
<
int8_t
N
>
operator
=
=
(
const
Vec128
<
int8_t
N
>
a
const
Vec128
<
int8_t
N
>
b
)
{
return
Mask128
<
int8_t
N
>
{
_mm_cmpeq_epi8
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Mask128
<
int16_t
N
>
operator
=
=
(
Vec128
<
int16_t
N
>
a
Vec128
<
int16_t
N
>
b
)
{
return
Mask128
<
int16_t
N
>
{
_mm_cmpeq_epi16
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Mask128
<
int32_t
N
>
operator
=
=
(
const
Vec128
<
int32_t
N
>
a
const
Vec128
<
int32_t
N
>
b
)
{
return
Mask128
<
int32_t
N
>
{
_mm_cmpeq_epi32
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Mask128
<
int64_t
N
>
operator
=
=
(
const
Vec128
<
int64_t
N
>
a
const
Vec128
<
int64_t
N
>
b
)
{
return
Mask128
<
int64_t
N
>
{
_mm_cmpeq_epi64
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Mask128
<
float
N
>
operator
=
=
(
const
Vec128
<
float
N
>
a
const
Vec128
<
float
N
>
b
)
{
return
Mask128
<
float
N
>
{
_mm_cmpeq_ps
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Mask128
<
double
N
>
operator
=
=
(
const
Vec128
<
double
N
>
a
const
Vec128
<
double
N
>
b
)
{
return
Mask128
<
double
N
>
{
_mm_cmpeq_pd
(
a
.
raw
b
.
raw
)
}
;
}
template
<
typename
T
size_t
N
>
HWY_API
Mask128
<
T
N
>
TestBit
(
Vec128
<
T
N
>
v
Vec128
<
T
N
>
bit
)
{
static_assert
(
!
hwy
:
:
IsFloat
<
T
>
(
)
"
Only
integer
vectors
supported
"
)
;
return
(
v
&
bit
)
=
=
bit
;
}
template
<
size_t
N
>
HWY_API
Mask128
<
int8_t
N
>
operator
<
(
const
Vec128
<
int8_t
N
>
a
const
Vec128
<
int8_t
N
>
b
)
{
return
Mask128
<
int8_t
N
>
{
_mm_cmpgt_epi8
(
b
.
raw
a
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Mask128
<
int16_t
N
>
operator
<
(
const
Vec128
<
int16_t
N
>
a
const
Vec128
<
int16_t
N
>
b
)
{
return
Mask128
<
int16_t
N
>
{
_mm_cmpgt_epi16
(
b
.
raw
a
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Mask128
<
int32_t
N
>
operator
<
(
const
Vec128
<
int32_t
N
>
a
const
Vec128
<
int32_t
N
>
b
)
{
return
Mask128
<
int32_t
N
>
{
_mm_cmpgt_epi32
(
b
.
raw
a
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Mask128
<
float
N
>
operator
<
(
const
Vec128
<
float
N
>
a
const
Vec128
<
float
N
>
b
)
{
return
Mask128
<
float
N
>
{
_mm_cmplt_ps
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Mask128
<
double
N
>
operator
<
(
const
Vec128
<
double
N
>
a
const
Vec128
<
double
N
>
b
)
{
return
Mask128
<
double
N
>
{
_mm_cmplt_pd
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Mask128
<
int8_t
N
>
operator
>
(
const
Vec128
<
int8_t
N
>
a
const
Vec128
<
int8_t
N
>
b
)
{
return
Mask128
<
int8_t
N
>
{
_mm_cmpgt_epi8
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Mask128
<
int16_t
N
>
operator
>
(
const
Vec128
<
int16_t
N
>
a
const
Vec128
<
int16_t
N
>
b
)
{
return
Mask128
<
int16_t
N
>
{
_mm_cmpgt_epi16
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Mask128
<
int32_t
N
>
operator
>
(
const
Vec128
<
int32_t
N
>
a
const
Vec128
<
int32_t
N
>
b
)
{
return
Mask128
<
int32_t
N
>
{
_mm_cmpgt_epi32
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Mask128
<
float
N
>
operator
>
(
const
Vec128
<
float
N
>
a
const
Vec128
<
float
N
>
b
)
{
return
Mask128
<
float
N
>
{
_mm_cmpgt_ps
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Mask128
<
double
N
>
operator
>
(
const
Vec128
<
double
N
>
a
const
Vec128
<
double
N
>
b
)
{
return
Mask128
<
double
N
>
{
_mm_cmpgt_pd
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Mask128
<
int64_t
N
>
operator
>
(
const
Vec128
<
int64_t
N
>
a
const
Vec128
<
int64_t
N
>
b
)
{
#
if
HWY_TARGET
=
=
HWY_SSE4
const
__m128i
m_gt
=
_mm_cmpgt_epi32
(
a
.
raw
b
.
raw
)
;
const
__m128i
m_eq
=
_mm_cmpeq_epi32
(
a
.
raw
b
.
raw
)
;
const
__m128i
lo_in_hi
=
_mm_shuffle_epi32
(
m_gt
_MM_SHUFFLE
(
2
2
0
0
)
)
;
const
__m128i
lo_gt
=
_mm_and_si128
(
m_eq
lo_in_hi
)
;
const
__m128i
gt
=
_mm_or_si128
(
lo_gt
m_gt
)
;
return
Mask128
<
int64_t
N
>
{
_mm_shuffle_epi32
(
gt
_MM_SHUFFLE
(
3
3
1
1
)
)
}
;
#
else
return
Mask128
<
int64_t
N
>
{
_mm_cmpgt_epi64
(
a
.
raw
b
.
raw
)
}
;
#
endif
}
template
<
size_t
N
>
HWY_API
Mask128
<
int64_t
N
>
operator
<
(
const
Vec128
<
int64_t
N
>
a
const
Vec128
<
int64_t
N
>
b
)
{
return
operator
>
(
b
a
)
;
}
template
<
size_t
N
>
HWY_API
Mask128
<
float
N
>
operator
<
=
(
const
Vec128
<
float
N
>
a
const
Vec128
<
float
N
>
b
)
{
return
Mask128
<
float
N
>
{
_mm_cmple_ps
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Mask128
<
double
N
>
operator
<
=
(
const
Vec128
<
double
N
>
a
const
Vec128
<
double
N
>
b
)
{
return
Mask128
<
double
N
>
{
_mm_cmple_pd
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Mask128
<
float
N
>
operator
>
=
(
const
Vec128
<
float
N
>
a
const
Vec128
<
float
N
>
b
)
{
return
Mask128
<
float
N
>
{
_mm_cmpge_ps
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Mask128
<
double
N
>
operator
>
=
(
const
Vec128
<
double
N
>
a
const
Vec128
<
double
N
>
b
)
{
return
Mask128
<
double
N
>
{
_mm_cmpge_pd
(
a
.
raw
b
.
raw
)
}
;
}
template
<
typename
T
size_t
N
HWY_IF_LE128
(
T
N
)
>
HWY_API
Mask128
<
T
N
>
FirstN
(
const
Simd
<
T
N
>
d
size_t
num
)
{
const
RebindToSigned
<
decltype
(
d
)
>
di
;
return
RebindMask
(
d
Iota
(
di
0
)
<
Set
(
di
static_cast
<
MakeSigned
<
T
>
>
(
num
)
)
)
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint8_t
N
>
operator
+
(
const
Vec128
<
uint8_t
N
>
a
const
Vec128
<
uint8_t
N
>
b
)
{
return
Vec128
<
uint8_t
N
>
{
_mm_add_epi8
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint16_t
N
>
operator
+
(
const
Vec128
<
uint16_t
N
>
a
const
Vec128
<
uint16_t
N
>
b
)
{
return
Vec128
<
uint16_t
N
>
{
_mm_add_epi16
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint32_t
N
>
operator
+
(
const
Vec128
<
uint32_t
N
>
a
const
Vec128
<
uint32_t
N
>
b
)
{
return
Vec128
<
uint32_t
N
>
{
_mm_add_epi32
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint64_t
N
>
operator
+
(
const
Vec128
<
uint64_t
N
>
a
const
Vec128
<
uint64_t
N
>
b
)
{
return
Vec128
<
uint64_t
N
>
{
_mm_add_epi64
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
int8_t
N
>
operator
+
(
const
Vec128
<
int8_t
N
>
a
const
Vec128
<
int8_t
N
>
b
)
{
return
Vec128
<
int8_t
N
>
{
_mm_add_epi8
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
int16_t
N
>
operator
+
(
const
Vec128
<
int16_t
N
>
a
const
Vec128
<
int16_t
N
>
b
)
{
return
Vec128
<
int16_t
N
>
{
_mm_add_epi16
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
int32_t
N
>
operator
+
(
const
Vec128
<
int32_t
N
>
a
const
Vec128
<
int32_t
N
>
b
)
{
return
Vec128
<
int32_t
N
>
{
_mm_add_epi32
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
int64_t
N
>
operator
+
(
const
Vec128
<
int64_t
N
>
a
const
Vec128
<
int64_t
N
>
b
)
{
return
Vec128
<
int64_t
N
>
{
_mm_add_epi64
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
float
N
>
operator
+
(
const
Vec128
<
float
N
>
a
const
Vec128
<
float
N
>
b
)
{
return
Vec128
<
float
N
>
{
_mm_add_ps
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
double
N
>
operator
+
(
const
Vec128
<
double
N
>
a
const
Vec128
<
double
N
>
b
)
{
return
Vec128
<
double
N
>
{
_mm_add_pd
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint8_t
N
>
operator
-
(
const
Vec128
<
uint8_t
N
>
a
const
Vec128
<
uint8_t
N
>
b
)
{
return
Vec128
<
uint8_t
N
>
{
_mm_sub_epi8
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint16_t
N
>
operator
-
(
Vec128
<
uint16_t
N
>
a
Vec128
<
uint16_t
N
>
b
)
{
return
Vec128
<
uint16_t
N
>
{
_mm_sub_epi16
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint32_t
N
>
operator
-
(
const
Vec128
<
uint32_t
N
>
a
const
Vec128
<
uint32_t
N
>
b
)
{
return
Vec128
<
uint32_t
N
>
{
_mm_sub_epi32
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint64_t
N
>
operator
-
(
const
Vec128
<
uint64_t
N
>
a
const
Vec128
<
uint64_t
N
>
b
)
{
return
Vec128
<
uint64_t
N
>
{
_mm_sub_epi64
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
int8_t
N
>
operator
-
(
const
Vec128
<
int8_t
N
>
a
const
Vec128
<
int8_t
N
>
b
)
{
return
Vec128
<
int8_t
N
>
{
_mm_sub_epi8
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
int16_t
N
>
operator
-
(
const
Vec128
<
int16_t
N
>
a
const
Vec128
<
int16_t
N
>
b
)
{
return
Vec128
<
int16_t
N
>
{
_mm_sub_epi16
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
int32_t
N
>
operator
-
(
const
Vec128
<
int32_t
N
>
a
const
Vec128
<
int32_t
N
>
b
)
{
return
Vec128
<
int32_t
N
>
{
_mm_sub_epi32
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
int64_t
N
>
operator
-
(
const
Vec128
<
int64_t
N
>
a
const
Vec128
<
int64_t
N
>
b
)
{
return
Vec128
<
int64_t
N
>
{
_mm_sub_epi64
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
float
N
>
operator
-
(
const
Vec128
<
float
N
>
a
const
Vec128
<
float
N
>
b
)
{
return
Vec128
<
float
N
>
{
_mm_sub_ps
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
double
N
>
operator
-
(
const
Vec128
<
double
N
>
a
const
Vec128
<
double
N
>
b
)
{
return
Vec128
<
double
N
>
{
_mm_sub_pd
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint8_t
N
>
SaturatedAdd
(
const
Vec128
<
uint8_t
N
>
a
const
Vec128
<
uint8_t
N
>
b
)
{
return
Vec128
<
uint8_t
N
>
{
_mm_adds_epu8
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint16_t
N
>
SaturatedAdd
(
const
Vec128
<
uint16_t
N
>
a
const
Vec128
<
uint16_t
N
>
b
)
{
return
Vec128
<
uint16_t
N
>
{
_mm_adds_epu16
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
int8_t
N
>
SaturatedAdd
(
const
Vec128
<
int8_t
N
>
a
const
Vec128
<
int8_t
N
>
b
)
{
return
Vec128
<
int8_t
N
>
{
_mm_adds_epi8
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
int16_t
N
>
SaturatedAdd
(
const
Vec128
<
int16_t
N
>
a
const
Vec128
<
int16_t
N
>
b
)
{
return
Vec128
<
int16_t
N
>
{
_mm_adds_epi16
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint8_t
N
>
SaturatedSub
(
const
Vec128
<
uint8_t
N
>
a
const
Vec128
<
uint8_t
N
>
b
)
{
return
Vec128
<
uint8_t
N
>
{
_mm_subs_epu8
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint16_t
N
>
SaturatedSub
(
const
Vec128
<
uint16_t
N
>
a
const
Vec128
<
uint16_t
N
>
b
)
{
return
Vec128
<
uint16_t
N
>
{
_mm_subs_epu16
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
int8_t
N
>
SaturatedSub
(
const
Vec128
<
int8_t
N
>
a
const
Vec128
<
int8_t
N
>
b
)
{
return
Vec128
<
int8_t
N
>
{
_mm_subs_epi8
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
int16_t
N
>
SaturatedSub
(
const
Vec128
<
int16_t
N
>
a
const
Vec128
<
int16_t
N
>
b
)
{
return
Vec128
<
int16_t
N
>
{
_mm_subs_epi16
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint8_t
N
>
AverageRound
(
const
Vec128
<
uint8_t
N
>
a
const
Vec128
<
uint8_t
N
>
b
)
{
return
Vec128
<
uint8_t
N
>
{
_mm_avg_epu8
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint16_t
N
>
AverageRound
(
const
Vec128
<
uint16_t
N
>
a
const
Vec128
<
uint16_t
N
>
b
)
{
return
Vec128
<
uint16_t
N
>
{
_mm_avg_epu16
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
int8_t
N
>
Abs
(
const
Vec128
<
int8_t
N
>
v
)
{
#
if
HWY_COMPILER_MSVC
const
auto
zero
=
Zero
(
Simd
<
int8_t
N
>
(
)
)
;
return
Vec128
<
int8_t
N
>
{
_mm_max_epi8
(
v
.
raw
(
zero
-
v
)
.
raw
)
}
;
#
else
return
Vec128
<
int8_t
N
>
{
_mm_abs_epi8
(
v
.
raw
)
}
;
#
endif
}
template
<
size_t
N
>
HWY_API
Vec128
<
int16_t
N
>
Abs
(
const
Vec128
<
int16_t
N
>
v
)
{
return
Vec128
<
int16_t
N
>
{
_mm_abs_epi16
(
v
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
int32_t
N
>
Abs
(
const
Vec128
<
int32_t
N
>
v
)
{
return
Vec128
<
int32_t
N
>
{
_mm_abs_epi32
(
v
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
float
N
>
Abs
(
const
Vec128
<
float
N
>
v
)
{
const
Vec128
<
int32_t
N
>
mask
{
_mm_set1_epi32
(
0x7FFFFFFF
)
}
;
return
v
&
BitCast
(
Simd
<
float
N
>
(
)
mask
)
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
double
N
>
Abs
(
const
Vec128
<
double
N
>
v
)
{
const
Vec128
<
int64_t
N
>
mask
{
_mm_set1_epi64x
(
0x7FFFFFFFFFFFFFFFLL
)
}
;
return
v
&
BitCast
(
Simd
<
double
N
>
(
)
mask
)
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint16_t
N
>
operator
*
(
const
Vec128
<
uint16_t
N
>
a
const
Vec128
<
uint16_t
N
>
b
)
{
return
Vec128
<
uint16_t
N
>
{
_mm_mullo_epi16
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint32_t
N
>
operator
*
(
const
Vec128
<
uint32_t
N
>
a
const
Vec128
<
uint32_t
N
>
b
)
{
return
Vec128
<
uint32_t
N
>
{
_mm_mullo_epi32
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
int16_t
N
>
operator
*
(
const
Vec128
<
int16_t
N
>
a
const
Vec128
<
int16_t
N
>
b
)
{
return
Vec128
<
int16_t
N
>
{
_mm_mullo_epi16
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
int32_t
N
>
operator
*
(
const
Vec128
<
int32_t
N
>
a
const
Vec128
<
int32_t
N
>
b
)
{
return
Vec128
<
int32_t
N
>
{
_mm_mullo_epi32
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint16_t
N
>
MulHigh
(
const
Vec128
<
uint16_t
N
>
a
const
Vec128
<
uint16_t
N
>
b
)
{
return
Vec128
<
uint16_t
N
>
{
_mm_mulhi_epu16
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
int16_t
N
>
MulHigh
(
const
Vec128
<
int16_t
N
>
a
const
Vec128
<
int16_t
N
>
b
)
{
return
Vec128
<
int16_t
N
>
{
_mm_mulhi_epi16
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
int64_t
(
N
+
1
)
/
2
>
MulEven
(
const
Vec128
<
int32_t
N
>
a
const
Vec128
<
int32_t
N
>
b
)
{
return
Vec128
<
int64_t
(
N
+
1
)
/
2
>
{
_mm_mul_epi32
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint64_t
(
N
+
1
)
/
2
>
MulEven
(
const
Vec128
<
uint32_t
N
>
a
const
Vec128
<
uint32_t
N
>
b
)
{
return
Vec128
<
uint64_t
(
N
+
1
)
/
2
>
{
_mm_mul_epu32
(
a
.
raw
b
.
raw
)
}
;
}
template
<
int
kBits
size_t
N
>
HWY_API
Vec128
<
uint16_t
N
>
ShiftLeft
(
const
Vec128
<
uint16_t
N
>
v
)
{
return
Vec128
<
uint16_t
N
>
{
_mm_slli_epi16
(
v
.
raw
kBits
)
}
;
}
template
<
int
kBits
size_t
N
>
HWY_API
Vec128
<
uint32_t
N
>
ShiftLeft
(
const
Vec128
<
uint32_t
N
>
v
)
{
return
Vec128
<
uint32_t
N
>
{
_mm_slli_epi32
(
v
.
raw
kBits
)
}
;
}
template
<
int
kBits
size_t
N
>
HWY_API
Vec128
<
uint64_t
N
>
ShiftLeft
(
const
Vec128
<
uint64_t
N
>
v
)
{
return
Vec128
<
uint64_t
N
>
{
_mm_slli_epi64
(
v
.
raw
kBits
)
}
;
}
template
<
int
kBits
size_t
N
>
HWY_API
Vec128
<
int16_t
N
>
ShiftLeft
(
const
Vec128
<
int16_t
N
>
v
)
{
return
Vec128
<
int16_t
N
>
{
_mm_slli_epi16
(
v
.
raw
kBits
)
}
;
}
template
<
int
kBits
size_t
N
>
HWY_API
Vec128
<
int32_t
N
>
ShiftLeft
(
const
Vec128
<
int32_t
N
>
v
)
{
return
Vec128
<
int32_t
N
>
{
_mm_slli_epi32
(
v
.
raw
kBits
)
}
;
}
template
<
int
kBits
size_t
N
>
HWY_API
Vec128
<
int64_t
N
>
ShiftLeft
(
const
Vec128
<
int64_t
N
>
v
)
{
return
Vec128
<
int64_t
N
>
{
_mm_slli_epi64
(
v
.
raw
kBits
)
}
;
}
template
<
int
kBits
typename
T
size_t
N
HWY_IF_LANE_SIZE
(
T
1
)
>
HWY_API
Vec128
<
T
N
>
ShiftLeft
(
const
Vec128
<
T
N
>
v
)
{
const
Simd
<
T
N
>
d8
;
const
Vec128
<
T
N
>
shifted
{
ShiftLeft
<
kBits
>
(
Vec128
<
MakeWide
<
T
>
>
{
v
.
raw
}
)
.
raw
}
;
return
kBits
=
=
1
?
(
v
+
v
)
:
(
shifted
&
Set
(
d8
static_cast
<
T
>
(
(
0xFF
<
<
kBits
)
&
0xFF
)
)
)
;
}
template
<
int
kBits
size_t
N
>
HWY_API
Vec128
<
uint16_t
N
>
ShiftRight
(
const
Vec128
<
uint16_t
N
>
v
)
{
return
Vec128
<
uint16_t
N
>
{
_mm_srli_epi16
(
v
.
raw
kBits
)
}
;
}
template
<
int
kBits
size_t
N
>
HWY_API
Vec128
<
uint32_t
N
>
ShiftRight
(
const
Vec128
<
uint32_t
N
>
v
)
{
return
Vec128
<
uint32_t
N
>
{
_mm_srli_epi32
(
v
.
raw
kBits
)
}
;
}
template
<
int
kBits
size_t
N
>
HWY_API
Vec128
<
uint64_t
N
>
ShiftRight
(
const
Vec128
<
uint64_t
N
>
v
)
{
return
Vec128
<
uint64_t
N
>
{
_mm_srli_epi64
(
v
.
raw
kBits
)
}
;
}
template
<
int
kBits
size_t
N
>
HWY_API
Vec128
<
uint8_t
N
>
ShiftRight
(
const
Vec128
<
uint8_t
N
>
v
)
{
const
Simd
<
uint8_t
N
>
d8
;
const
Vec128
<
uint8_t
N
>
shifted
{
ShiftRight
<
kBits
>
(
Vec128
<
uint16_t
>
{
v
.
raw
}
)
.
raw
}
;
return
shifted
&
Set
(
d8
0xFF
>
>
kBits
)
;
}
template
<
int
kBits
size_t
N
>
HWY_API
Vec128
<
int16_t
N
>
ShiftRight
(
const
Vec128
<
int16_t
N
>
v
)
{
return
Vec128
<
int16_t
N
>
{
_mm_srai_epi16
(
v
.
raw
kBits
)
}
;
}
template
<
int
kBits
size_t
N
>
HWY_API
Vec128
<
int32_t
N
>
ShiftRight
(
const
Vec128
<
int32_t
N
>
v
)
{
return
Vec128
<
int32_t
N
>
{
_mm_srai_epi32
(
v
.
raw
kBits
)
}
;
}
template
<
int
kBits
size_t
N
>
HWY_API
Vec128
<
int8_t
N
>
ShiftRight
(
const
Vec128
<
int8_t
N
>
v
)
{
const
Simd
<
int8_t
N
>
di
;
const
Simd
<
uint8_t
N
>
du
;
const
auto
shifted
=
BitCast
(
di
ShiftRight
<
kBits
>
(
BitCast
(
du
v
)
)
)
;
const
auto
shifted_sign
=
BitCast
(
di
Set
(
du
0x80
>
>
kBits
)
)
;
return
(
shifted
^
shifted_sign
)
-
shifted_sign
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
int8_t
N
>
BroadcastSignBit
(
const
Vec128
<
int8_t
N
>
v
)
{
return
VecFromMask
(
v
<
Zero
(
Simd
<
int8_t
N
>
(
)
)
)
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
int16_t
N
>
BroadcastSignBit
(
const
Vec128
<
int16_t
N
>
v
)
{
return
ShiftRight
<
15
>
(
v
)
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
int32_t
N
>
BroadcastSignBit
(
const
Vec128
<
int32_t
N
>
v
)
{
return
ShiftRight
<
31
>
(
v
)
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
int64_t
N
>
BroadcastSignBit
(
const
Vec128
<
int64_t
N
>
v
)
{
#
if
HWY_TARGET
=
=
HWY_AVX3
return
Vec128
<
int64_t
N
>
{
_mm_srai_epi64
(
v
.
raw
63
)
}
;
#
elif
HWY_TARGET
=
=
HWY_AVX2
return
VecFromMask
(
v
<
Zero
(
Simd
<
int64_t
N
>
(
)
)
)
;
#
else
const
Simd
<
int32_t
N
*
2
>
d32
;
const
auto
sign
=
ShiftRight
<
31
>
(
BitCast
(
d32
v
)
)
;
return
Vec128
<
int64_t
N
>
{
_mm_shuffle_epi32
(
sign
.
raw
_MM_SHUFFLE
(
3
3
1
1
)
)
}
;
#
endif
}
template
<
size_t
N
>
HWY_API
Vec128
<
int64_t
N
>
Abs
(
const
Vec128
<
int64_t
N
>
v
)
{
#
if
HWY_TARGET
=
=
HWY_AVX3
return
Vec128
<
int64_t
N
>
{
_mm_abs_epi64
(
v
.
raw
)
}
;
#
else
const
auto
zero
=
Zero
(
Simd
<
int64_t
N
>
(
)
)
;
return
IfThenElse
(
MaskFromVec
(
BroadcastSignBit
(
v
)
)
zero
-
v
v
)
;
#
endif
}
template
<
int
kBits
size_t
N
>
HWY_API
Vec128
<
int64_t
N
>
ShiftRight
(
const
Vec128
<
int64_t
N
>
v
)
{
#
if
HWY_TARGET
=
=
HWY_AVX3
return
Vec128
<
int64_t
N
>
{
_mm_srai_epi64
(
v
.
raw
kBits
)
}
;
#
else
const
Simd
<
int64_t
N
>
di
;
const
Simd
<
uint64_t
N
>
du
;
const
auto
right
=
BitCast
(
di
ShiftRight
<
kBits
>
(
BitCast
(
du
v
)
)
)
;
const
auto
sign
=
ShiftLeft
<
64
-
kBits
>
(
BroadcastSignBit
(
v
)
)
;
return
right
|
sign
;
#
endif
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint16_t
N
>
ShiftLeftSame
(
const
Vec128
<
uint16_t
N
>
v
const
int
bits
)
{
return
Vec128
<
uint16_t
N
>
{
_mm_sll_epi16
(
v
.
raw
_mm_cvtsi32_si128
(
bits
)
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint32_t
N
>
ShiftLeftSame
(
const
Vec128
<
uint32_t
N
>
v
const
int
bits
)
{
return
Vec128
<
uint32_t
N
>
{
_mm_sll_epi32
(
v
.
raw
_mm_cvtsi32_si128
(
bits
)
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint64_t
N
>
ShiftLeftSame
(
const
Vec128
<
uint64_t
N
>
v
const
int
bits
)
{
return
Vec128
<
uint64_t
N
>
{
_mm_sll_epi64
(
v
.
raw
_mm_cvtsi32_si128
(
bits
)
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
int16_t
N
>
ShiftLeftSame
(
const
Vec128
<
int16_t
N
>
v
const
int
bits
)
{
return
Vec128
<
int16_t
N
>
{
_mm_sll_epi16
(
v
.
raw
_mm_cvtsi32_si128
(
bits
)
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
int32_t
N
>
ShiftLeftSame
(
const
Vec128
<
int32_t
N
>
v
const
int
bits
)
{
return
Vec128
<
int32_t
N
>
{
_mm_sll_epi32
(
v
.
raw
_mm_cvtsi32_si128
(
bits
)
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
int64_t
N
>
ShiftLeftSame
(
const
Vec128
<
int64_t
N
>
v
const
int
bits
)
{
return
Vec128
<
int64_t
N
>
{
_mm_sll_epi64
(
v
.
raw
_mm_cvtsi32_si128
(
bits
)
)
}
;
}
template
<
typename
T
size_t
N
HWY_IF_LANE_SIZE
(
T
1
)
>
HWY_API
Vec128
<
T
N
>
ShiftLeftSame
(
const
Vec128
<
T
N
>
v
const
int
bits
)
{
const
Simd
<
T
N
>
d8
;
const
Vec128
<
T
N
>
shifted
{
ShiftLeftSame
(
Vec128
<
MakeWide
<
T
>
>
{
v
.
raw
}
bits
)
.
raw
}
;
return
shifted
&
Set
(
d8
(
0xFF
<
<
bits
)
&
0xFF
)
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint16_t
N
>
ShiftRightSame
(
const
Vec128
<
uint16_t
N
>
v
const
int
bits
)
{
return
Vec128
<
uint16_t
N
>
{
_mm_srl_epi16
(
v
.
raw
_mm_cvtsi32_si128
(
bits
)
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint32_t
N
>
ShiftRightSame
(
const
Vec128
<
uint32_t
N
>
v
const
int
bits
)
{
return
Vec128
<
uint32_t
N
>
{
_mm_srl_epi32
(
v
.
raw
_mm_cvtsi32_si128
(
bits
)
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint64_t
N
>
ShiftRightSame
(
const
Vec128
<
uint64_t
N
>
v
const
int
bits
)
{
return
Vec128
<
uint64_t
N
>
{
_mm_srl_epi64
(
v
.
raw
_mm_cvtsi32_si128
(
bits
)
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint8_t
N
>
ShiftRightSame
(
Vec128
<
uint8_t
N
>
v
const
int
bits
)
{
const
Simd
<
uint8_t
N
>
d8
;
const
Vec128
<
uint8_t
N
>
shifted
{
ShiftRightSame
(
Vec128
<
uint16_t
>
{
v
.
raw
}
bits
)
.
raw
}
;
return
shifted
&
Set
(
d8
0xFF
>
>
bits
)
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
int16_t
N
>
ShiftRightSame
(
const
Vec128
<
int16_t
N
>
v
const
int
bits
)
{
return
Vec128
<
int16_t
N
>
{
_mm_sra_epi16
(
v
.
raw
_mm_cvtsi32_si128
(
bits
)
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
int32_t
N
>
ShiftRightSame
(
const
Vec128
<
int32_t
N
>
v
const
int
bits
)
{
return
Vec128
<
int32_t
N
>
{
_mm_sra_epi32
(
v
.
raw
_mm_cvtsi32_si128
(
bits
)
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
int64_t
N
>
ShiftRightSame
(
const
Vec128
<
int64_t
N
>
v
const
int
bits
)
{
#
if
HWY_TARGET
=
=
HWY_AVX3
return
Vec128
<
int64_t
N
>
{
_mm_sra_epi64
(
v
.
raw
_mm_cvtsi32_si128
(
bits
)
)
}
;
#
else
const
Simd
<
int64_t
N
>
di
;
const
Simd
<
uint64_t
N
>
du
;
const
auto
right
=
BitCast
(
di
ShiftRightSame
(
BitCast
(
du
v
)
bits
)
)
;
const
auto
sign
=
ShiftLeftSame
(
BroadcastSignBit
(
v
)
64
-
bits
)
;
return
right
|
sign
;
#
endif
}
template
<
size_t
N
>
HWY_API
Vec128
<
int8_t
N
>
ShiftRightSame
(
Vec128
<
int8_t
N
>
v
const
int
bits
)
{
const
Simd
<
int8_t
N
>
di
;
const
Simd
<
uint8_t
N
>
du
;
const
auto
shifted
=
BitCast
(
di
ShiftRightSame
(
BitCast
(
du
v
)
bits
)
)
;
const
auto
shifted_sign
=
BitCast
(
di
Set
(
du
0x80
>
>
bits
)
)
;
return
(
shifted
^
shifted_sign
)
-
shifted_sign
;
}
template
<
typename
T
size_t
N
HWY_IF_FLOAT
(
T
)
>
HWY_API
Vec128
<
T
N
>
Neg
(
const
Vec128
<
T
N
>
v
)
{
return
Xor
(
v
SignBit
(
Simd
<
T
N
>
(
)
)
)
;
}
template
<
typename
T
size_t
N
HWY_IF_NOT_FLOAT
(
T
)
>
HWY_API
Vec128
<
T
N
>
Neg
(
const
Vec128
<
T
N
>
v
)
{
return
Zero
(
Simd
<
T
N
>
(
)
)
-
v
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
float
N
>
operator
*
(
Vec128
<
float
N
>
a
Vec128
<
float
N
>
b
)
{
return
Vec128
<
float
N
>
{
_mm_mul_ps
(
a
.
raw
b
.
raw
)
}
;
}
HWY_API
Vec128
<
float
1
>
operator
*
(
const
Vec128
<
float
1
>
a
const
Vec128
<
float
1
>
b
)
{
return
Vec128
<
float
1
>
{
_mm_mul_ss
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
double
N
>
operator
*
(
const
Vec128
<
double
N
>
a
const
Vec128
<
double
N
>
b
)
{
return
Vec128
<
double
N
>
{
_mm_mul_pd
(
a
.
raw
b
.
raw
)
}
;
}
HWY_API
Vec128
<
double
1
>
operator
*
(
const
Vec128
<
double
1
>
a
const
Vec128
<
double
1
>
b
)
{
return
Vec128
<
double
1
>
{
_mm_mul_sd
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
float
N
>
operator
/
(
const
Vec128
<
float
N
>
a
const
Vec128
<
float
N
>
b
)
{
return
Vec128
<
float
N
>
{
_mm_div_ps
(
a
.
raw
b
.
raw
)
}
;
}
HWY_API
Vec128
<
float
1
>
operator
/
(
const
Vec128
<
float
1
>
a
const
Vec128
<
float
1
>
b
)
{
return
Vec128
<
float
1
>
{
_mm_div_ss
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
double
N
>
operator
/
(
const
Vec128
<
double
N
>
a
const
Vec128
<
double
N
>
b
)
{
return
Vec128
<
double
N
>
{
_mm_div_pd
(
a
.
raw
b
.
raw
)
}
;
}
HWY_API
Vec128
<
double
1
>
operator
/
(
const
Vec128
<
double
1
>
a
const
Vec128
<
double
1
>
b
)
{
return
Vec128
<
double
1
>
{
_mm_div_sd
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
float
N
>
ApproximateReciprocal
(
const
Vec128
<
float
N
>
v
)
{
return
Vec128
<
float
N
>
{
_mm_rcp_ps
(
v
.
raw
)
}
;
}
HWY_API
Vec128
<
float
1
>
ApproximateReciprocal
(
const
Vec128
<
float
1
>
v
)
{
return
Vec128
<
float
1
>
{
_mm_rcp_ss
(
v
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
float
N
>
AbsDiff
(
const
Vec128
<
float
N
>
a
const
Vec128
<
float
N
>
b
)
{
return
Abs
(
a
-
b
)
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
float
N
>
MulAdd
(
const
Vec128
<
float
N
>
mul
const
Vec128
<
float
N
>
x
const
Vec128
<
float
N
>
add
)
{
#
if
HWY_TARGET
=
=
HWY_SSE4
return
mul
*
x
+
add
;
#
else
return
Vec128
<
float
N
>
{
_mm_fmadd_ps
(
mul
.
raw
x
.
raw
add
.
raw
)
}
;
#
endif
}
template
<
size_t
N
>
HWY_API
Vec128
<
double
N
>
MulAdd
(
const
Vec128
<
double
N
>
mul
const
Vec128
<
double
N
>
x
const
Vec128
<
double
N
>
add
)
{
#
if
HWY_TARGET
=
=
HWY_SSE4
return
mul
*
x
+
add
;
#
else
return
Vec128
<
double
N
>
{
_mm_fmadd_pd
(
mul
.
raw
x
.
raw
add
.
raw
)
}
;
#
endif
}
template
<
size_t
N
>
HWY_API
Vec128
<
float
N
>
NegMulAdd
(
const
Vec128
<
float
N
>
mul
const
Vec128
<
float
N
>
x
const
Vec128
<
float
N
>
add
)
{
#
if
HWY_TARGET
=
=
HWY_SSE4
return
add
-
mul
*
x
;
#
else
return
Vec128
<
float
N
>
{
_mm_fnmadd_ps
(
mul
.
raw
x
.
raw
add
.
raw
)
}
;
#
endif
}
template
<
size_t
N
>
HWY_API
Vec128
<
double
N
>
NegMulAdd
(
const
Vec128
<
double
N
>
mul
const
Vec128
<
double
N
>
x
const
Vec128
<
double
N
>
add
)
{
#
if
HWY_TARGET
=
=
HWY_SSE4
return
add
-
mul
*
x
;
#
else
return
Vec128
<
double
N
>
{
_mm_fnmadd_pd
(
mul
.
raw
x
.
raw
add
.
raw
)
}
;
#
endif
}
template
<
size_t
N
>
HWY_API
Vec128
<
float
N
>
MulSub
(
const
Vec128
<
float
N
>
mul
const
Vec128
<
float
N
>
x
const
Vec128
<
float
N
>
sub
)
{
#
if
HWY_TARGET
=
=
HWY_SSE4
return
mul
*
x
-
sub
;
#
else
return
Vec128
<
float
N
>
{
_mm_fmsub_ps
(
mul
.
raw
x
.
raw
sub
.
raw
)
}
;
#
endif
}
template
<
size_t
N
>
HWY_API
Vec128
<
double
N
>
MulSub
(
const
Vec128
<
double
N
>
mul
const
Vec128
<
double
N
>
x
const
Vec128
<
double
N
>
sub
)
{
#
if
HWY_TARGET
=
=
HWY_SSE4
return
mul
*
x
-
sub
;
#
else
return
Vec128
<
double
N
>
{
_mm_fmsub_pd
(
mul
.
raw
x
.
raw
sub
.
raw
)
}
;
#
endif
}
template
<
size_t
N
>
HWY_API
Vec128
<
float
N
>
NegMulSub
(
const
Vec128
<
float
N
>
mul
const
Vec128
<
float
N
>
x
const
Vec128
<
float
N
>
sub
)
{
#
if
HWY_TARGET
=
=
HWY_SSE4
return
Neg
(
mul
)
*
x
-
sub
;
#
else
return
Vec128
<
float
N
>
{
_mm_fnmsub_ps
(
mul
.
raw
x
.
raw
sub
.
raw
)
}
;
#
endif
}
template
<
size_t
N
>
HWY_API
Vec128
<
double
N
>
NegMulSub
(
const
Vec128
<
double
N
>
mul
const
Vec128
<
double
N
>
x
const
Vec128
<
double
N
>
sub
)
{
#
if
HWY_TARGET
=
=
HWY_SSE4
return
Neg
(
mul
)
*
x
-
sub
;
#
else
return
Vec128
<
double
N
>
{
_mm_fnmsub_pd
(
mul
.
raw
x
.
raw
sub
.
raw
)
}
;
#
endif
}
template
<
size_t
N
>
HWY_API
Vec128
<
float
N
>
Sqrt
(
const
Vec128
<
float
N
>
v
)
{
return
Vec128
<
float
N
>
{
_mm_sqrt_ps
(
v
.
raw
)
}
;
}
HWY_API
Vec128
<
float
1
>
Sqrt
(
const
Vec128
<
float
1
>
v
)
{
return
Vec128
<
float
1
>
{
_mm_sqrt_ss
(
v
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
double
N
>
Sqrt
(
const
Vec128
<
double
N
>
v
)
{
return
Vec128
<
double
N
>
{
_mm_sqrt_pd
(
v
.
raw
)
}
;
}
HWY_API
Vec128
<
double
1
>
Sqrt
(
const
Vec128
<
double
1
>
v
)
{
return
Vec128
<
double
1
>
{
_mm_sqrt_sd
(
_mm_setzero_pd
(
)
v
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
float
N
>
ApproximateReciprocalSqrt
(
const
Vec128
<
float
N
>
v
)
{
return
Vec128
<
float
N
>
{
_mm_rsqrt_ps
(
v
.
raw
)
}
;
}
HWY_API
Vec128
<
float
1
>
ApproximateReciprocalSqrt
(
const
Vec128
<
float
1
>
v
)
{
return
Vec128
<
float
1
>
{
_mm_rsqrt_ss
(
v
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
float
N
>
Round
(
const
Vec128
<
float
N
>
v
)
{
return
Vec128
<
float
N
>
{
_mm_round_ps
(
v
.
raw
_MM_FROUND_TO_NEAREST_INT
|
_MM_FROUND_NO_EXC
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
double
N
>
Round
(
const
Vec128
<
double
N
>
v
)
{
return
Vec128
<
double
N
>
{
_mm_round_pd
(
v
.
raw
_MM_FROUND_TO_NEAREST_INT
|
_MM_FROUND_NO_EXC
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
float
N
>
Trunc
(
const
Vec128
<
float
N
>
v
)
{
return
Vec128
<
float
N
>
{
_mm_round_ps
(
v
.
raw
_MM_FROUND_TO_ZERO
|
_MM_FROUND_NO_EXC
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
double
N
>
Trunc
(
const
Vec128
<
double
N
>
v
)
{
return
Vec128
<
double
N
>
{
_mm_round_pd
(
v
.
raw
_MM_FROUND_TO_ZERO
|
_MM_FROUND_NO_EXC
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
float
N
>
Ceil
(
const
Vec128
<
float
N
>
v
)
{
return
Vec128
<
float
N
>
{
_mm_round_ps
(
v
.
raw
_MM_FROUND_TO_POS_INF
|
_MM_FROUND_NO_EXC
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
double
N
>
Ceil
(
const
Vec128
<
double
N
>
v
)
{
return
Vec128
<
double
N
>
{
_mm_round_pd
(
v
.
raw
_MM_FROUND_TO_POS_INF
|
_MM_FROUND_NO_EXC
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
float
N
>
Floor
(
const
Vec128
<
float
N
>
v
)
{
return
Vec128
<
float
N
>
{
_mm_round_ps
(
v
.
raw
_MM_FROUND_TO_NEG_INF
|
_MM_FROUND_NO_EXC
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
double
N
>
Floor
(
const
Vec128
<
double
N
>
v
)
{
return
Vec128
<
double
N
>
{
_mm_round_pd
(
v
.
raw
_MM_FROUND_TO_NEG_INF
|
_MM_FROUND_NO_EXC
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint8_t
N
>
Min
(
const
Vec128
<
uint8_t
N
>
a
const
Vec128
<
uint8_t
N
>
b
)
{
return
Vec128
<
uint8_t
N
>
{
_mm_min_epu8
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint16_t
N
>
Min
(
const
Vec128
<
uint16_t
N
>
a
const
Vec128
<
uint16_t
N
>
b
)
{
return
Vec128
<
uint16_t
N
>
{
_mm_min_epu16
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint32_t
N
>
Min
(
const
Vec128
<
uint32_t
N
>
a
const
Vec128
<
uint32_t
N
>
b
)
{
return
Vec128
<
uint32_t
N
>
{
_mm_min_epu32
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint64_t
N
>
Min
(
const
Vec128
<
uint64_t
N
>
a
const
Vec128
<
uint64_t
N
>
b
)
{
#
if
HWY_TARGET
=
=
HWY_AVX3
return
Vec128
<
uint64_t
N
>
{
_mm_min_epu64
(
a
.
raw
b
.
raw
)
}
;
#
else
const
Simd
<
uint64_t
N
>
du
;
const
Simd
<
int64_t
N
>
di
;
const
auto
msb
=
Set
(
du
1ull
<
<
63
)
;
const
auto
gt
=
RebindMask
(
du
BitCast
(
di
a
^
msb
)
>
BitCast
(
di
b
^
msb
)
)
;
return
IfThenElse
(
gt
b
a
)
;
#
endif
}
template
<
size_t
N
>
HWY_API
Vec128
<
int8_t
N
>
Min
(
const
Vec128
<
int8_t
N
>
a
const
Vec128
<
int8_t
N
>
b
)
{
return
Vec128
<
int8_t
N
>
{
_mm_min_epi8
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
int16_t
N
>
Min
(
const
Vec128
<
int16_t
N
>
a
const
Vec128
<
int16_t
N
>
b
)
{
return
Vec128
<
int16_t
N
>
{
_mm_min_epi16
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
int32_t
N
>
Min
(
const
Vec128
<
int32_t
N
>
a
const
Vec128
<
int32_t
N
>
b
)
{
return
Vec128
<
int32_t
N
>
{
_mm_min_epi32
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
int64_t
N
>
Min
(
const
Vec128
<
int64_t
N
>
a
const
Vec128
<
int64_t
N
>
b
)
{
#
if
HWY_TARGET
=
=
HWY_AVX3
return
Vec128
<
int64_t
N
>
{
_mm_min_epi64
(
a
.
raw
b
.
raw
)
}
;
#
else
return
IfThenElse
(
a
<
b
a
b
)
;
#
endif
}
template
<
size_t
N
>
HWY_API
Vec128
<
float
N
>
Min
(
const
Vec128
<
float
N
>
a
const
Vec128
<
float
N
>
b
)
{
return
Vec128
<
float
N
>
{
_mm_min_ps
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
double
N
>
Min
(
const
Vec128
<
double
N
>
a
const
Vec128
<
double
N
>
b
)
{
return
Vec128
<
double
N
>
{
_mm_min_pd
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint8_t
N
>
Max
(
const
Vec128
<
uint8_t
N
>
a
const
Vec128
<
uint8_t
N
>
b
)
{
return
Vec128
<
uint8_t
N
>
{
_mm_max_epu8
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint16_t
N
>
Max
(
const
Vec128
<
uint16_t
N
>
a
const
Vec128
<
uint16_t
N
>
b
)
{
return
Vec128
<
uint16_t
N
>
{
_mm_max_epu16
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint32_t
N
>
Max
(
const
Vec128
<
uint32_t
N
>
a
const
Vec128
<
uint32_t
N
>
b
)
{
return
Vec128
<
uint32_t
N
>
{
_mm_max_epu32
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint64_t
N
>
Max
(
const
Vec128
<
uint64_t
N
>
a
const
Vec128
<
uint64_t
N
>
b
)
{
#
if
HWY_TARGET
=
=
HWY_AVX3
return
Vec128
<
uint64_t
N
>
{
_mm_max_epu64
(
a
.
raw
b
.
raw
)
}
;
#
else
const
Simd
<
uint64_t
N
>
du
;
const
Simd
<
int64_t
N
>
di
;
const
auto
msb
=
Set
(
du
1ull
<
<
63
)
;
const
auto
gt
=
RebindMask
(
du
BitCast
(
di
a
^
msb
)
>
BitCast
(
di
b
^
msb
)
)
;
return
IfThenElse
(
gt
a
b
)
;
#
endif
}
template
<
size_t
N
>
HWY_API
Vec128
<
int8_t
N
>
Max
(
const
Vec128
<
int8_t
N
>
a
const
Vec128
<
int8_t
N
>
b
)
{
return
Vec128
<
int8_t
N
>
{
_mm_max_epi8
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
int16_t
N
>
Max
(
const
Vec128
<
int16_t
N
>
a
const
Vec128
<
int16_t
N
>
b
)
{
return
Vec128
<
int16_t
N
>
{
_mm_max_epi16
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
int32_t
N
>
Max
(
const
Vec128
<
int32_t
N
>
a
const
Vec128
<
int32_t
N
>
b
)
{
return
Vec128
<
int32_t
N
>
{
_mm_max_epi32
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
int64_t
N
>
Max
(
const
Vec128
<
int64_t
N
>
a
const
Vec128
<
int64_t
N
>
b
)
{
#
if
HWY_TARGET
=
=
HWY_AVX3
return
Vec128
<
int64_t
N
>
{
_mm_max_epi64
(
a
.
raw
b
.
raw
)
}
;
#
else
return
IfThenElse
(
a
<
b
b
a
)
;
#
endif
}
template
<
size_t
N
>
HWY_API
Vec128
<
float
N
>
Max
(
const
Vec128
<
float
N
>
a
const
Vec128
<
float
N
>
b
)
{
return
Vec128
<
float
N
>
{
_mm_max_ps
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
double
N
>
Max
(
const
Vec128
<
double
N
>
a
const
Vec128
<
double
N
>
b
)
{
return
Vec128
<
double
N
>
{
_mm_max_pd
(
a
.
raw
b
.
raw
)
}
;
}
#
ifndef
HWY_SAFE_PARTIAL_LOAD_STORE
#
if
defined
(
__clang_analyzer__
)
|
|
\
(
HWY_COMPILER_CLANG
!
=
0
&
&
HWY_COMPILER_CLANG
<
700
)
#
define
HWY_SAFE_PARTIAL_LOAD_STORE
1
#
else
#
define
HWY_SAFE_PARTIAL_LOAD_STORE
0
#
endif
#
endif
template
<
typename
T
>
HWY_API
Vec128
<
T
>
Load
(
Full128
<
T
>
const
T
*
HWY_RESTRICT
aligned
)
{
return
Vec128
<
T
>
{
_mm_load_si128
(
reinterpret_cast
<
const
__m128i
*
>
(
aligned
)
)
}
;
}
HWY_API
Vec128
<
float
>
Load
(
Full128
<
float
>
const
float
*
HWY_RESTRICT
aligned
)
{
return
Vec128
<
float
>
{
_mm_load_ps
(
aligned
)
}
;
}
HWY_API
Vec128
<
double
>
Load
(
Full128
<
double
>
const
double
*
HWY_RESTRICT
aligned
)
{
return
Vec128
<
double
>
{
_mm_load_pd
(
aligned
)
}
;
}
template
<
typename
T
>
HWY_API
Vec128
<
T
>
LoadU
(
Full128
<
T
>
const
T
*
HWY_RESTRICT
p
)
{
return
Vec128
<
T
>
{
_mm_loadu_si128
(
reinterpret_cast
<
const
__m128i
*
>
(
p
)
)
}
;
}
HWY_API
Vec128
<
float
>
LoadU
(
Full128
<
float
>
const
float
*
HWY_RESTRICT
p
)
{
return
Vec128
<
float
>
{
_mm_loadu_ps
(
p
)
}
;
}
HWY_API
Vec128
<
double
>
LoadU
(
Full128
<
double
>
const
double
*
HWY_RESTRICT
p
)
{
return
Vec128
<
double
>
{
_mm_loadu_pd
(
p
)
}
;
}
template
<
typename
T
>
HWY_API
Vec128
<
T
8
/
sizeof
(
T
)
>
Load
(
Simd
<
T
8
/
sizeof
(
T
)
>
const
T
*
HWY_RESTRICT
p
)
{
#
if
HWY_SAFE_PARTIAL_LOAD_STORE
__m128i
v
=
_mm_setzero_si128
(
)
;
CopyBytes
<
8
>
(
p
&
v
)
;
return
Vec128
<
T
8
/
sizeof
(
T
)
>
{
v
}
;
#
else
return
Vec128
<
T
8
/
sizeof
(
T
)
>
{
_mm_loadl_epi64
(
reinterpret_cast
<
const
__m128i
*
>
(
p
)
)
}
;
#
endif
}
HWY_API
Vec128
<
float
2
>
Load
(
Simd
<
float
2
>
const
float
*
HWY_RESTRICT
p
)
{
#
if
HWY_SAFE_PARTIAL_LOAD_STORE
__m128
v
=
_mm_setzero_ps
(
)
;
CopyBytes
<
8
>
(
p
&
v
)
;
return
Vec128
<
float
2
>
{
v
}
;
#
else
const
__m128
hi
=
_mm_setzero_ps
(
)
;
return
Vec128
<
float
2
>
{
_mm_loadl_pi
(
hi
reinterpret_cast
<
const
__m64
*
>
(
p
)
)
}
;
#
endif
}
HWY_API
Vec128
<
double
1
>
Load
(
Simd
<
double
1
>
const
double
*
HWY_RESTRICT
p
)
{
#
if
HWY_SAFE_PARTIAL_LOAD_STORE
__m128d
v
=
_mm_setzero_pd
(
)
;
CopyBytes
<
8
>
(
p
&
v
)
;
return
Vec128
<
double
1
>
{
v
}
;
#
else
return
Vec128
<
double
1
>
{
_mm_load_sd
(
p
)
}
;
#
endif
}
HWY_API
Vec128
<
float
1
>
Load
(
Simd
<
float
1
>
const
float
*
HWY_RESTRICT
p
)
{
#
if
HWY_SAFE_PARTIAL_LOAD_STORE
__m128
v
=
_mm_setzero_ps
(
)
;
CopyBytes
<
4
>
(
p
&
v
)
;
return
Vec128
<
float
1
>
{
v
}
;
#
else
return
Vec128
<
float
1
>
{
_mm_load_ss
(
p
)
}
;
#
endif
}
template
<
typename
T
size_t
N
HWY_IF_LE32
(
T
N
)
>
HWY_API
Vec128
<
T
N
>
Load
(
Simd
<
T
N
>
const
T
*
HWY_RESTRICT
p
)
{
constexpr
size_t
kSize
=
sizeof
(
T
)
*
N
;
#
if
HWY_SAFE_PARTIAL_LOAD_STORE
__m128
v
=
_mm_setzero_ps
(
)
;
CopyBytes
<
kSize
>
(
p
&
v
)
;
return
Vec128
<
T
N
>
{
v
}
;
#
else
int32_t
bits
;
CopyBytes
<
kSize
>
(
p
&
bits
)
;
return
Vec128
<
T
N
>
{
_mm_cvtsi32_si128
(
bits
)
}
;
#
endif
}
template
<
typename
T
size_t
N
HWY_IF_LE64
(
T
N
)
>
HWY_API
Vec128
<
T
N
>
LoadU
(
Simd
<
T
N
>
d
const
T
*
HWY_RESTRICT
p
)
{
return
Load
(
d
p
)
;
}
template
<
typename
T
size_t
N
HWY_IF_LE128
(
T
N
)
>
HWY_API
Vec128
<
T
N
>
LoadDup128
(
Simd
<
T
N
>
d
const
T
*
HWY_RESTRICT
p
)
{
return
LoadU
(
d
p
)
;
}
template
<
typename
T
>
HWY_API
void
Store
(
Vec128
<
T
>
v
Full128
<
T
>
T
*
HWY_RESTRICT
aligned
)
{
_mm_store_si128
(
reinterpret_cast
<
__m128i
*
>
(
aligned
)
v
.
raw
)
;
}
HWY_API
void
Store
(
const
Vec128
<
float
>
v
Full128
<
float
>
float
*
HWY_RESTRICT
aligned
)
{
_mm_store_ps
(
aligned
v
.
raw
)
;
}
HWY_API
void
Store
(
const
Vec128
<
double
>
v
Full128
<
double
>
double
*
HWY_RESTRICT
aligned
)
{
_mm_store_pd
(
aligned
v
.
raw
)
;
}
template
<
typename
T
>
HWY_API
void
StoreU
(
Vec128
<
T
>
v
Full128
<
T
>
T
*
HWY_RESTRICT
p
)
{
_mm_storeu_si128
(
reinterpret_cast
<
__m128i
*
>
(
p
)
v
.
raw
)
;
}
HWY_API
void
StoreU
(
const
Vec128
<
float
>
v
Full128
<
float
>
float
*
HWY_RESTRICT
p
)
{
_mm_storeu_ps
(
p
v
.
raw
)
;
}
HWY_API
void
StoreU
(
const
Vec128
<
double
>
v
Full128
<
double
>
double
*
HWY_RESTRICT
p
)
{
_mm_storeu_pd
(
p
v
.
raw
)
;
}
template
<
typename
T
>
HWY_API
void
Store
(
Vec128
<
T
8
/
sizeof
(
T
)
>
v
Simd
<
T
8
/
sizeof
(
T
)
>
T
*
HWY_RESTRICT
p
)
{
#
if
HWY_SAFE_PARTIAL_LOAD_STORE
CopyBytes
<
8
>
(
&
v
p
)
;
#
else
_mm_storel_epi64
(
reinterpret_cast
<
__m128i
*
>
(
p
)
v
.
raw
)
;
#
endif
}
HWY_API
void
Store
(
const
Vec128
<
float
2
>
v
Simd
<
float
2
>
float
*
HWY_RESTRICT
p
)
{
#
if
HWY_SAFE_PARTIAL_LOAD_STORE
CopyBytes
<
8
>
(
&
v
p
)
;
#
else
_mm_storel_pi
(
reinterpret_cast
<
__m64
*
>
(
p
)
v
.
raw
)
;
#
endif
}
HWY_API
void
Store
(
const
Vec128
<
double
1
>
v
Simd
<
double
1
>
double
*
HWY_RESTRICT
p
)
{
#
if
HWY_SAFE_PARTIAL_LOAD_STORE
CopyBytes
<
8
>
(
&
v
p
)
;
#
else
_mm_storel_pd
(
p
v
.
raw
)
;
#
endif
}
template
<
typename
T
size_t
N
HWY_IF_LE32
(
T
N
)
>
HWY_API
void
Store
(
Vec128
<
T
N
>
v
Simd
<
T
N
>
T
*
HWY_RESTRICT
p
)
{
CopyBytes
<
sizeof
(
T
)
*
N
>
(
&
v
p
)
;
}
HWY_API
void
Store
(
const
Vec128
<
float
1
>
v
Simd
<
float
1
>
float
*
HWY_RESTRICT
p
)
{
#
if
HWY_SAFE_PARTIAL_LOAD_STORE
CopyBytes
<
4
>
(
&
v
p
)
;
#
else
_mm_store_ss
(
p
v
.
raw
)
;
#
endif
}
template
<
typename
T
size_t
N
HWY_IF_LE64
(
T
N
)
>
HWY_API
void
StoreU
(
const
Vec128
<
T
N
>
v
Simd
<
T
N
>
d
T
*
HWY_RESTRICT
p
)
{
Store
(
v
d
p
)
;
}
template
<
typename
T
size_t
N
>
HWY_API
void
Stream
(
Vec128
<
T
N
>
v
Simd
<
T
N
>
T
*
HWY_RESTRICT
aligned
)
{
_mm_stream_si128
(
reinterpret_cast
<
__m128i
*
>
(
aligned
)
v
.
raw
)
;
}
template
<
size_t
N
>
HWY_API
void
Stream
(
const
Vec128
<
float
N
>
v
Simd
<
float
N
>
float
*
HWY_RESTRICT
aligned
)
{
_mm_stream_ps
(
aligned
v
.
raw
)
;
}
template
<
size_t
N
>
HWY_API
void
Stream
(
const
Vec128
<
double
N
>
v
Simd
<
double
N
>
double
*
HWY_RESTRICT
aligned
)
{
_mm_stream_pd
(
aligned
v
.
raw
)
;
}
HWY_DIAGNOSTICS
(
push
)
HWY_DIAGNOSTICS_OFF
(
disable
:
4245
4365
ignored
"
-
Wsign
-
conversion
"
)
using
GatherIndex64
=
long
long
int
;
static_assert
(
sizeof
(
GatherIndex64
)
=
=
8
"
Must
be
64
-
bit
type
"
)
;
#
if
HWY_TARGET
=
=
HWY_AVX3
namespace
detail
{
template
<
typename
T
size_t
N
>
HWY_API
void
ScatterOffset
(
hwy
:
:
SizeTag
<
4
>
Vec128
<
T
N
>
v
Simd
<
T
N
>
T
*
HWY_RESTRICT
base
const
Vec128
<
int32_t
N
>
offset
)
{
if
(
N
=
=
4
)
{
_mm_i32scatter_epi32
(
base
offset
.
raw
v
.
raw
1
)
;
}
else
{
const
__mmask8
mask
=
(
1u
<
<
N
)
-
1
;
_mm_mask_i32scatter_epi32
(
base
mask
offset
.
raw
v
.
raw
1
)
;
}
}
template
<
typename
T
size_t
N
>
HWY_API
void
ScatterIndex
(
hwy
:
:
SizeTag
<
4
>
Vec128
<
T
N
>
v
Simd
<
T
N
>
T
*
HWY_RESTRICT
base
const
Vec128
<
int32_t
N
>
index
)
{
if
(
N
=
=
4
)
{
_mm_i32scatter_epi32
(
base
index
.
raw
v
.
raw
4
)
;
}
else
{
const
__mmask8
mask
=
(
1u
<
<
N
)
-
1
;
_mm_mask_i32scatter_epi32
(
base
mask
index
.
raw
v
.
raw
4
)
;
}
}
template
<
typename
T
size_t
N
>
HWY_API
void
ScatterOffset
(
hwy
:
:
SizeTag
<
8
>
Vec128
<
T
N
>
v
Simd
<
T
N
>
T
*
HWY_RESTRICT
base
const
Vec128
<
int64_t
N
>
offset
)
{
if
(
N
=
=
2
)
{
_mm_i64scatter_epi64
(
base
offset
.
raw
v
.
raw
1
)
;
}
else
{
const
__mmask8
mask
=
(
1u
<
<
N
)
-
1
;
_mm_mask_i64scatter_epi64
(
base
mask
offset
.
raw
v
.
raw
1
)
;
}
}
template
<
typename
T
size_t
N
>
HWY_API
void
ScatterIndex
(
hwy
:
:
SizeTag
<
8
>
Vec128
<
T
N
>
v
Simd
<
T
N
>
T
*
HWY_RESTRICT
base
const
Vec128
<
int64_t
N
>
index
)
{
if
(
N
=
=
2
)
{
_mm_i64scatter_epi64
(
base
index
.
raw
v
.
raw
8
)
;
}
else
{
const
__mmask8
mask
=
(
1u
<
<
N
)
-
1
;
_mm_mask_i64scatter_epi64
(
base
mask
index
.
raw
v
.
raw
8
)
;
}
}
}
template
<
typename
T
size_t
N
typename
Offset
>
HWY_API
void
ScatterOffset
(
Vec128
<
T
N
>
v
Simd
<
T
N
>
d
T
*
HWY_RESTRICT
base
const
Vec128
<
Offset
N
>
offset
)
{
static_assert
(
sizeof
(
T
)
=
=
sizeof
(
Offset
)
"
Must
match
for
portability
"
)
;
return
detail
:
:
ScatterOffset
(
hwy
:
:
SizeTag
<
sizeof
(
T
)
>
(
)
v
d
base
offset
)
;
}
template
<
typename
T
size_t
N
typename
Index
>
HWY_API
void
ScatterIndex
(
Vec128
<
T
N
>
v
Simd
<
T
N
>
d
T
*
HWY_RESTRICT
base
const
Vec128
<
Index
N
>
index
)
{
static_assert
(
sizeof
(
T
)
=
=
sizeof
(
Index
)
"
Must
match
for
portability
"
)
;
return
detail
:
:
ScatterIndex
(
hwy
:
:
SizeTag
<
sizeof
(
T
)
>
(
)
v
d
base
index
)
;
}
template
<
size_t
N
>
HWY_INLINE
void
ScatterOffset
(
Vec128
<
float
N
>
v
Simd
<
float
N
>
float
*
HWY_RESTRICT
base
const
Vec128
<
int32_t
N
>
offset
)
{
if
(
N
=
=
4
)
{
_mm_i32scatter_ps
(
base
offset
.
raw
v
.
raw
1
)
;
}
else
{
const
__mmask8
mask
=
(
1u
<
<
N
)
-
1
;
_mm_mask_i32scatter_ps
(
base
mask
offset
.
raw
v
.
raw
1
)
;
}
}
template
<
size_t
N
>
HWY_INLINE
void
ScatterIndex
(
Vec128
<
float
N
>
v
Simd
<
float
N
>
float
*
HWY_RESTRICT
base
const
Vec128
<
int32_t
N
>
index
)
{
if
(
N
=
=
4
)
{
_mm_i32scatter_ps
(
base
index
.
raw
v
.
raw
4
)
;
}
else
{
const
__mmask8
mask
=
(
1u
<
<
N
)
-
1
;
_mm_mask_i32scatter_ps
(
base
mask
index
.
raw
v
.
raw
4
)
;
}
}
template
<
size_t
N
>
HWY_INLINE
void
ScatterOffset
(
Vec128
<
double
N
>
v
Simd
<
double
N
>
double
*
HWY_RESTRICT
base
const
Vec128
<
int64_t
N
>
offset
)
{
if
(
N
=
=
2
)
{
_mm_i64scatter_pd
(
base
offset
.
raw
v
.
raw
1
)
;
}
else
{
const
__mmask8
mask
=
(
1u
<
<
N
)
-
1
;
_mm_mask_i64scatter_pd
(
base
mask
offset
.
raw
v
.
raw
1
)
;
}
}
template
<
size_t
N
>
HWY_INLINE
void
ScatterIndex
(
Vec128
<
double
N
>
v
Simd
<
double
N
>
double
*
HWY_RESTRICT
base
const
Vec128
<
int64_t
N
>
index
)
{
if
(
N
=
=
2
)
{
_mm_i64scatter_pd
(
base
index
.
raw
v
.
raw
8
)
;
}
else
{
const
__mmask8
mask
=
(
1u
<
<
N
)
-
1
;
_mm_mask_i64scatter_pd
(
base
mask
index
.
raw
v
.
raw
8
)
;
}
}
#
else
template
<
typename
T
size_t
N
typename
Offset
HWY_IF_LE128
(
T
N
)
>
HWY_API
void
ScatterOffset
(
Vec128
<
T
N
>
v
Simd
<
T
N
>
d
T
*
HWY_RESTRICT
base
const
Vec128
<
Offset
N
>
offset
)
{
static_assert
(
sizeof
(
T
)
=
=
sizeof
(
Offset
)
"
Must
match
for
portability
"
)
;
alignas
(
16
)
T
lanes
[
N
]
;
Store
(
v
d
lanes
)
;
alignas
(
16
)
Offset
offset_lanes
[
N
]
;
Store
(
offset
Simd
<
Offset
N
>
(
)
offset_lanes
)
;
uint8_t
*
base_bytes
=
reinterpret_cast
<
uint8_t
*
>
(
base
)
;
for
(
size_t
i
=
0
;
i
<
N
;
+
+
i
)
{
CopyBytes
<
sizeof
(
T
)
>
(
&
lanes
[
i
]
base_bytes
+
offset_lanes
[
i
]
)
;
}
}
template
<
typename
T
size_t
N
typename
Index
HWY_IF_LE128
(
T
N
)
>
HWY_API
void
ScatterIndex
(
Vec128
<
T
N
>
v
Simd
<
T
N
>
d
T
*
HWY_RESTRICT
base
const
Vec128
<
Index
N
>
index
)
{
static_assert
(
sizeof
(
T
)
=
=
sizeof
(
Index
)
"
Must
match
for
portability
"
)
;
alignas
(
16
)
T
lanes
[
N
]
;
Store
(
v
d
lanes
)
;
alignas
(
16
)
Index
index_lanes
[
N
]
;
Store
(
index
Simd
<
Index
N
>
(
)
index_lanes
)
;
for
(
size_t
i
=
0
;
i
<
N
;
+
+
i
)
{
base
[
index_lanes
[
i
]
]
=
lanes
[
i
]
;
}
}
#
endif
#
if
HWY_TARGET
=
=
HWY_SSE4
template
<
typename
T
size_t
N
typename
Offset
>
HWY_API
Vec128
<
T
N
>
GatherOffset
(
const
Simd
<
T
N
>
d
const
T
*
HWY_RESTRICT
base
const
Vec128
<
Offset
N
>
offset
)
{
static_assert
(
sizeof
(
T
)
=
=
sizeof
(
Offset
)
"
Must
match
for
portability
"
)
;
alignas
(
16
)
Offset
offset_lanes
[
N
]
;
Store
(
offset
Simd
<
Offset
N
>
(
)
offset_lanes
)
;
alignas
(
16
)
T
lanes
[
N
]
;
const
uint8_t
*
base_bytes
=
reinterpret_cast
<
const
uint8_t
*
>
(
base
)
;
for
(
size_t
i
=
0
;
i
<
N
;
+
+
i
)
{
CopyBytes
<
sizeof
(
T
)
>
(
base_bytes
+
offset_lanes
[
i
]
&
lanes
[
i
]
)
;
}
return
Load
(
d
lanes
)
;
}
template
<
typename
T
size_t
N
typename
Index
>
HWY_API
Vec128
<
T
N
>
GatherIndex
(
const
Simd
<
T
N
>
d
const
T
*
HWY_RESTRICT
base
const
Vec128
<
Index
N
>
index
)
{
static_assert
(
sizeof
(
T
)
=
=
sizeof
(
Index
)
"
Must
match
for
portability
"
)
;
alignas
(
16
)
Index
index_lanes
[
N
]
;
Store
(
index
Simd
<
Index
N
>
(
)
index_lanes
)
;
alignas
(
16
)
T
lanes
[
N
]
;
for
(
size_t
i
=
0
;
i
<
N
;
+
+
i
)
{
lanes
[
i
]
=
base
[
index_lanes
[
i
]
]
;
}
return
Load
(
d
lanes
)
;
}
#
else
namespace
detail
{
template
<
typename
T
size_t
N
>
HWY_API
Vec128
<
T
N
>
GatherOffset
(
hwy
:
:
SizeTag
<
4
>
Simd
<
T
N
>
const
T
*
HWY_RESTRICT
base
const
Vec128
<
int32_t
N
>
offset
)
{
return
Vec128
<
T
N
>
{
_mm_i32gather_epi32
(
reinterpret_cast
<
const
int32_t
*
>
(
base
)
offset
.
raw
1
)
}
;
}
template
<
typename
T
size_t
N
>
HWY_API
Vec128
<
T
N
>
GatherIndex
(
hwy
:
:
SizeTag
<
4
>
Simd
<
T
N
>
const
T
*
HWY_RESTRICT
base
const
Vec128
<
int32_t
N
>
index
)
{
return
Vec128
<
T
N
>
{
_mm_i32gather_epi32
(
reinterpret_cast
<
const
int32_t
*
>
(
base
)
index
.
raw
4
)
}
;
}
template
<
typename
T
size_t
N
>
HWY_API
Vec128
<
T
N
>
GatherOffset
(
hwy
:
:
SizeTag
<
8
>
Simd
<
T
N
>
const
T
*
HWY_RESTRICT
base
const
Vec128
<
int64_t
N
>
offset
)
{
return
Vec128
<
T
N
>
{
_mm_i64gather_epi64
(
reinterpret_cast
<
const
GatherIndex64
*
>
(
base
)
offset
.
raw
1
)
}
;
}
template
<
typename
T
size_t
N
>
HWY_API
Vec128
<
T
N
>
GatherIndex
(
hwy
:
:
SizeTag
<
8
>
Simd
<
T
N
>
const
T
*
HWY_RESTRICT
base
const
Vec128
<
int64_t
N
>
index
)
{
return
Vec128
<
T
N
>
{
_mm_i64gather_epi64
(
reinterpret_cast
<
const
GatherIndex64
*
>
(
base
)
index
.
raw
8
)
}
;
}
}
template
<
typename
T
size_t
N
typename
Offset
>
HWY_API
Vec128
<
T
N
>
GatherOffset
(
Simd
<
T
N
>
d
const
T
*
HWY_RESTRICT
base
const
Vec128
<
Offset
N
>
offset
)
{
return
detail
:
:
GatherOffset
(
hwy
:
:
SizeTag
<
sizeof
(
T
)
>
(
)
d
base
offset
)
;
}
template
<
typename
T
size_t
N
typename
Index
>
HWY_API
Vec128
<
T
N
>
GatherIndex
(
Simd
<
T
N
>
d
const
T
*
HWY_RESTRICT
base
const
Vec128
<
Index
N
>
index
)
{
return
detail
:
:
GatherIndex
(
hwy
:
:
SizeTag
<
sizeof
(
T
)
>
(
)
d
base
index
)
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
float
N
>
GatherOffset
(
Simd
<
float
N
>
const
float
*
HWY_RESTRICT
base
const
Vec128
<
int32_t
N
>
offset
)
{
return
Vec128
<
float
N
>
{
_mm_i32gather_ps
(
base
offset
.
raw
1
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
float
N
>
GatherIndex
(
Simd
<
float
N
>
const
float
*
HWY_RESTRICT
base
const
Vec128
<
int32_t
N
>
index
)
{
return
Vec128
<
float
N
>
{
_mm_i32gather_ps
(
base
index
.
raw
4
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
double
N
>
GatherOffset
(
Simd
<
double
N
>
const
double
*
HWY_RESTRICT
base
const
Vec128
<
int64_t
N
>
offset
)
{
return
Vec128
<
double
N
>
{
_mm_i64gather_pd
(
base
offset
.
raw
1
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
double
N
>
GatherIndex
(
Simd
<
double
N
>
const
double
*
HWY_RESTRICT
base
const
Vec128
<
int64_t
N
>
index
)
{
return
Vec128
<
double
N
>
{
_mm_i64gather_pd
(
base
index
.
raw
8
)
}
;
}
#
endif
HWY_DIAGNOSTICS
(
pop
)
template
<
typename
T
size_t
N
>
HWY_API
Vec128
<
T
N
/
2
>
LowerHalf
(
Vec128
<
T
N
>
v
)
{
return
Vec128
<
T
N
/
2
>
{
v
.
raw
}
;
}
template
<
typename
T
>
HWY_API
Vec128
<
T
8
/
sizeof
(
T
)
>
UpperHalf
(
Vec128
<
T
>
v
)
{
return
Vec128
<
T
8
/
sizeof
(
T
)
>
{
_mm_unpackhi_epi64
(
v
.
raw
v
.
raw
)
}
;
}
template
<
>
HWY_INLINE
Vec128
<
float
2
>
UpperHalf
(
Vec128
<
float
>
v
)
{
return
Vec128
<
float
2
>
{
_mm_movehl_ps
(
v
.
raw
v
.
raw
)
}
;
}
template
<
>
HWY_INLINE
Vec128
<
double
1
>
UpperHalf
(
Vec128
<
double
>
v
)
{
return
Vec128
<
double
1
>
{
_mm_unpackhi_pd
(
v
.
raw
v
.
raw
)
}
;
}
template
<
int
kBytes
typename
T
size_t
N
>
HWY_API
Vec128
<
T
N
>
ShiftLeftBytes
(
const
Vec128
<
T
N
>
v
)
{
static_assert
(
0
<
=
kBytes
&
&
kBytes
<
=
16
"
Invalid
kBytes
"
)
;
return
Vec128
<
T
N
>
{
_mm_slli_si128
(
v
.
raw
kBytes
)
}
;
}
template
<
int
kLanes
typename
T
size_t
N
>
HWY_API
Vec128
<
T
N
>
ShiftLeftLanes
(
const
Vec128
<
T
N
>
v
)
{
const
Simd
<
uint8_t
N
*
sizeof
(
T
)
>
d8
;
const
Simd
<
T
N
>
d
;
return
BitCast
(
d
ShiftLeftBytes
<
kLanes
*
sizeof
(
T
)
>
(
BitCast
(
d8
v
)
)
)
;
}
template
<
int
kBytes
typename
T
size_t
N
>
HWY_API
Vec128
<
T
N
>
ShiftRightBytes
(
const
Vec128
<
T
N
>
v
)
{
static_assert
(
0
<
=
kBytes
&
&
kBytes
<
=
16
"
Invalid
kBytes
"
)
;
return
Vec128
<
T
N
>
{
_mm_srli_si128
(
v
.
raw
kBytes
)
}
;
}
template
<
int
kLanes
typename
T
size_t
N
>
HWY_API
Vec128
<
T
N
>
ShiftRightLanes
(
const
Vec128
<
T
N
>
v
)
{
const
Simd
<
uint8_t
N
*
sizeof
(
T
)
>
d8
;
const
Simd
<
T
N
>
d
;
return
BitCast
(
d
ShiftRightBytes
<
kLanes
*
sizeof
(
T
)
>
(
BitCast
(
d8
v
)
)
)
;
}
template
<
int
kBytes
typename
T
>
HWY_API
Vec128
<
T
>
CombineShiftRightBytes
(
const
Vec128
<
T
>
hi
const
Vec128
<
T
>
lo
)
{
const
Full128
<
uint8_t
>
d8
;
const
Vec128
<
uint8_t
>
extracted_bytes
{
_mm_alignr_epi8
(
BitCast
(
d8
hi
)
.
raw
BitCast
(
d8
lo
)
.
raw
kBytes
)
}
;
return
BitCast
(
Full128
<
T
>
(
)
extracted_bytes
)
;
}
template
<
int
kLane
size_t
N
>
HWY_API
Vec128
<
uint16_t
N
>
Broadcast
(
const
Vec128
<
uint16_t
N
>
v
)
{
static_assert
(
0
<
=
kLane
&
&
kLane
<
N
"
Invalid
lane
"
)
;
if
(
kLane
<
4
)
{
const
__m128i
lo
=
_mm_shufflelo_epi16
(
v
.
raw
(
0x55
*
kLane
)
&
0xFF
)
;
return
Vec128
<
uint16_t
N
>
{
_mm_unpacklo_epi64
(
lo
lo
)
}
;
}
else
{
const
__m128i
hi
=
_mm_shufflehi_epi16
(
v
.
raw
(
0x55
*
(
kLane
-
4
)
)
&
0xFF
)
;
return
Vec128
<
uint16_t
N
>
{
_mm_unpackhi_epi64
(
hi
hi
)
}
;
}
}
template
<
int
kLane
size_t
N
>
HWY_API
Vec128
<
uint32_t
N
>
Broadcast
(
const
Vec128
<
uint32_t
N
>
v
)
{
static_assert
(
0
<
=
kLane
&
&
kLane
<
N
"
Invalid
lane
"
)
;
return
Vec128
<
uint32_t
N
>
{
_mm_shuffle_epi32
(
v
.
raw
0x55
*
kLane
)
}
;
}
template
<
int
kLane
size_t
N
>
HWY_API
Vec128
<
uint64_t
N
>
Broadcast
(
const
Vec128
<
uint64_t
N
>
v
)
{
static_assert
(
0
<
=
kLane
&
&
kLane
<
N
"
Invalid
lane
"
)
;
return
Vec128
<
uint64_t
N
>
{
_mm_shuffle_epi32
(
v
.
raw
kLane
?
0xEE
:
0x44
)
}
;
}
template
<
int
kLane
size_t
N
>
HWY_API
Vec128
<
int16_t
N
>
Broadcast
(
const
Vec128
<
int16_t
N
>
v
)
{
static_assert
(
0
<
=
kLane
&
&
kLane
<
N
"
Invalid
lane
"
)
;
if
(
kLane
<
4
)
{
const
__m128i
lo
=
_mm_shufflelo_epi16
(
v
.
raw
(
0x55
*
kLane
)
&
0xFF
)
;
return
Vec128
<
int16_t
N
>
{
_mm_unpacklo_epi64
(
lo
lo
)
}
;
}
else
{
const
__m128i
hi
=
_mm_shufflehi_epi16
(
v
.
raw
(
0x55
*
(
kLane
-
4
)
)
&
0xFF
)
;
return
Vec128
<
int16_t
N
>
{
_mm_unpackhi_epi64
(
hi
hi
)
}
;
}
}
template
<
int
kLane
size_t
N
>
HWY_API
Vec128
<
int32_t
N
>
Broadcast
(
const
Vec128
<
int32_t
N
>
v
)
{
static_assert
(
0
<
=
kLane
&
&
kLane
<
N
"
Invalid
lane
"
)
;
return
Vec128
<
int32_t
N
>
{
_mm_shuffle_epi32
(
v
.
raw
0x55
*
kLane
)
}
;
}
template
<
int
kLane
size_t
N
>
HWY_API
Vec128
<
int64_t
N
>
Broadcast
(
const
Vec128
<
int64_t
N
>
v
)
{
static_assert
(
0
<
=
kLane
&
&
kLane
<
N
"
Invalid
lane
"
)
;
return
Vec128
<
int64_t
N
>
{
_mm_shuffle_epi32
(
v
.
raw
kLane
?
0xEE
:
0x44
)
}
;
}
template
<
int
kLane
size_t
N
>
HWY_API
Vec128
<
float
N
>
Broadcast
(
const
Vec128
<
float
N
>
v
)
{
static_assert
(
0
<
=
kLane
&
&
kLane
<
N
"
Invalid
lane
"
)
;
return
Vec128
<
float
N
>
{
_mm_shuffle_ps
(
v
.
raw
v
.
raw
0x55
*
kLane
)
}
;
}
template
<
int
kLane
size_t
N
>
HWY_API
Vec128
<
double
N
>
Broadcast
(
const
Vec128
<
double
N
>
v
)
{
static_assert
(
0
<
=
kLane
&
&
kLane
<
N
"
Invalid
lane
"
)
;
return
Vec128
<
double
N
>
{
_mm_shuffle_pd
(
v
.
raw
v
.
raw
3
*
kLane
)
}
;
}
template
<
typename
T
size_t
N
>
HWY_API
Vec128
<
T
N
>
TableLookupBytes
(
const
Vec128
<
T
N
>
bytes
const
Vec128
<
T
N
>
from
)
{
return
Vec128
<
T
N
>
{
_mm_shuffle_epi8
(
bytes
.
raw
from
.
raw
)
}
;
}
HWY_API
Vec128
<
uint32_t
>
Shuffle2301
(
const
Vec128
<
uint32_t
>
v
)
{
return
Vec128
<
uint32_t
>
{
_mm_shuffle_epi32
(
v
.
raw
0xB1
)
}
;
}
HWY_API
Vec128
<
int32_t
>
Shuffle2301
(
const
Vec128
<
int32_t
>
v
)
{
return
Vec128
<
int32_t
>
{
_mm_shuffle_epi32
(
v
.
raw
0xB1
)
}
;
}
HWY_API
Vec128
<
float
>
Shuffle2301
(
const
Vec128
<
float
>
v
)
{
return
Vec128
<
float
>
{
_mm_shuffle_ps
(
v
.
raw
v
.
raw
0xB1
)
}
;
}
HWY_API
Vec128
<
uint32_t
>
Shuffle1032
(
const
Vec128
<
uint32_t
>
v
)
{
return
Vec128
<
uint32_t
>
{
_mm_shuffle_epi32
(
v
.
raw
0x4E
)
}
;
}
HWY_API
Vec128
<
int32_t
>
Shuffle1032
(
const
Vec128
<
int32_t
>
v
)
{
return
Vec128
<
int32_t
>
{
_mm_shuffle_epi32
(
v
.
raw
0x4E
)
}
;
}
HWY_API
Vec128
<
float
>
Shuffle1032
(
const
Vec128
<
float
>
v
)
{
return
Vec128
<
float
>
{
_mm_shuffle_ps
(
v
.
raw
v
.
raw
0x4E
)
}
;
}
HWY_API
Vec128
<
uint64_t
>
Shuffle01
(
const
Vec128
<
uint64_t
>
v
)
{
return
Vec128
<
uint64_t
>
{
_mm_shuffle_epi32
(
v
.
raw
0x4E
)
}
;
}
HWY_API
Vec128
<
int64_t
>
Shuffle01
(
const
Vec128
<
int64_t
>
v
)
{
return
Vec128
<
int64_t
>
{
_mm_shuffle_epi32
(
v
.
raw
0x4E
)
}
;
}
HWY_API
Vec128
<
double
>
Shuffle01
(
const
Vec128
<
double
>
v
)
{
return
Vec128
<
double
>
{
_mm_shuffle_pd
(
v
.
raw
v
.
raw
1
)
}
;
}
HWY_API
Vec128
<
uint32_t
>
Shuffle0321
(
const
Vec128
<
uint32_t
>
v
)
{
return
Vec128
<
uint32_t
>
{
_mm_shuffle_epi32
(
v
.
raw
0x39
)
}
;
}
HWY_API
Vec128
<
int32_t
>
Shuffle0321
(
const
Vec128
<
int32_t
>
v
)
{
return
Vec128
<
int32_t
>
{
_mm_shuffle_epi32
(
v
.
raw
0x39
)
}
;
}
HWY_API
Vec128
<
float
>
Shuffle0321
(
const
Vec128
<
float
>
v
)
{
return
Vec128
<
float
>
{
_mm_shuffle_ps
(
v
.
raw
v
.
raw
0x39
)
}
;
}
HWY_API
Vec128
<
uint32_t
>
Shuffle2103
(
const
Vec128
<
uint32_t
>
v
)
{
return
Vec128
<
uint32_t
>
{
_mm_shuffle_epi32
(
v
.
raw
0x93
)
}
;
}
HWY_API
Vec128
<
int32_t
>
Shuffle2103
(
const
Vec128
<
int32_t
>
v
)
{
return
Vec128
<
int32_t
>
{
_mm_shuffle_epi32
(
v
.
raw
0x93
)
}
;
}
HWY_API
Vec128
<
float
>
Shuffle2103
(
const
Vec128
<
float
>
v
)
{
return
Vec128
<
float
>
{
_mm_shuffle_ps
(
v
.
raw
v
.
raw
0x93
)
}
;
}
HWY_API
Vec128
<
uint32_t
>
Shuffle0123
(
const
Vec128
<
uint32_t
>
v
)
{
return
Vec128
<
uint32_t
>
{
_mm_shuffle_epi32
(
v
.
raw
0x1B
)
}
;
}
HWY_API
Vec128
<
int32_t
>
Shuffle0123
(
const
Vec128
<
int32_t
>
v
)
{
return
Vec128
<
int32_t
>
{
_mm_shuffle_epi32
(
v
.
raw
0x1B
)
}
;
}
HWY_API
Vec128
<
float
>
Shuffle0123
(
const
Vec128
<
float
>
v
)
{
return
Vec128
<
float
>
{
_mm_shuffle_ps
(
v
.
raw
v
.
raw
0x1B
)
}
;
}
template
<
typename
T
size_t
N
>
struct
Indices128
{
__m128i
raw
;
}
;
template
<
typename
T
size_t
N
HWY_IF_LE128
(
T
N
)
>
HWY_API
Indices128
<
T
N
>
SetTableIndices
(
Simd
<
T
N
>
d
const
int32_t
*
idx
)
{
#
if
!
defined
(
NDEBUG
)
|
|
defined
(
ADDRESS_SANITIZER
)
for
(
size_t
i
=
0
;
i
<
N
;
+
+
i
)
{
HWY_DASSERT
(
0
<
=
idx
[
i
]
&
&
idx
[
i
]
<
static_cast
<
int32_t
>
(
N
)
)
;
}
#
endif
const
Repartition
<
uint8_t
decltype
(
d
)
>
d8
;
alignas
(
16
)
uint8_t
control
[
16
]
=
{
0
}
;
for
(
size_t
idx_lane
=
0
;
idx_lane
<
N
;
+
+
idx_lane
)
{
for
(
size_t
idx_byte
=
0
;
idx_byte
<
sizeof
(
T
)
;
+
+
idx_byte
)
{
control
[
idx_lane
*
sizeof
(
T
)
+
idx_byte
]
=
static_cast
<
uint8_t
>
(
idx
[
idx_lane
]
*
sizeof
(
T
)
+
idx_byte
)
;
}
}
return
Indices128
<
T
N
>
{
Load
(
d8
control
)
.
raw
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint32_t
N
>
TableLookupLanes
(
const
Vec128
<
uint32_t
N
>
v
const
Indices128
<
uint32_t
N
>
idx
)
{
return
TableLookupBytes
(
v
Vec128
<
uint32_t
N
>
{
idx
.
raw
}
)
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
int32_t
N
>
TableLookupLanes
(
const
Vec128
<
int32_t
N
>
v
const
Indices128
<
int32_t
N
>
idx
)
{
return
TableLookupBytes
(
v
Vec128
<
int32_t
N
>
{
idx
.
raw
}
)
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
float
N
>
TableLookupLanes
(
const
Vec128
<
float
N
>
v
const
Indices128
<
float
N
>
idx
)
{
const
Simd
<
int32_t
N
>
di
;
const
Simd
<
float
N
>
df
;
return
BitCast
(
df
TableLookupBytes
(
BitCast
(
di
v
)
Vec128
<
int32_t
N
>
{
idx
.
raw
}
)
)
;
}
HWY_API
Vec128
<
uint8_t
>
InterleaveLower
(
const
Vec128
<
uint8_t
>
a
const
Vec128
<
uint8_t
>
b
)
{
return
Vec128
<
uint8_t
>
{
_mm_unpacklo_epi8
(
a
.
raw
b
.
raw
)
}
;
}
HWY_API
Vec128
<
uint16_t
>
InterleaveLower
(
const
Vec128
<
uint16_t
>
a
const
Vec128
<
uint16_t
>
b
)
{
return
Vec128
<
uint16_t
>
{
_mm_unpacklo_epi16
(
a
.
raw
b
.
raw
)
}
;
}
HWY_API
Vec128
<
uint32_t
>
InterleaveLower
(
const
Vec128
<
uint32_t
>
a
const
Vec128
<
uint32_t
>
b
)
{
return
Vec128
<
uint32_t
>
{
_mm_unpacklo_epi32
(
a
.
raw
b
.
raw
)
}
;
}
HWY_API
Vec128
<
uint64_t
>
InterleaveLower
(
const
Vec128
<
uint64_t
>
a
const
Vec128
<
uint64_t
>
b
)
{
return
Vec128
<
uint64_t
>
{
_mm_unpacklo_epi64
(
a
.
raw
b
.
raw
)
}
;
}
HWY_API
Vec128
<
int8_t
>
InterleaveLower
(
const
Vec128
<
int8_t
>
a
const
Vec128
<
int8_t
>
b
)
{
return
Vec128
<
int8_t
>
{
_mm_unpacklo_epi8
(
a
.
raw
b
.
raw
)
}
;
}
HWY_API
Vec128
<
int16_t
>
InterleaveLower
(
const
Vec128
<
int16_t
>
a
const
Vec128
<
int16_t
>
b
)
{
return
Vec128
<
int16_t
>
{
_mm_unpacklo_epi16
(
a
.
raw
b
.
raw
)
}
;
}
HWY_API
Vec128
<
int32_t
>
InterleaveLower
(
const
Vec128
<
int32_t
>
a
const
Vec128
<
int32_t
>
b
)
{
return
Vec128
<
int32_t
>
{
_mm_unpacklo_epi32
(
a
.
raw
b
.
raw
)
}
;
}
HWY_API
Vec128
<
int64_t
>
InterleaveLower
(
const
Vec128
<
int64_t
>
a
const
Vec128
<
int64_t
>
b
)
{
return
Vec128
<
int64_t
>
{
_mm_unpacklo_epi64
(
a
.
raw
b
.
raw
)
}
;
}
HWY_API
Vec128
<
float
>
InterleaveLower
(
const
Vec128
<
float
>
a
const
Vec128
<
float
>
b
)
{
return
Vec128
<
float
>
{
_mm_unpacklo_ps
(
a
.
raw
b
.
raw
)
}
;
}
HWY_API
Vec128
<
double
>
InterleaveLower
(
const
Vec128
<
double
>
a
const
Vec128
<
double
>
b
)
{
return
Vec128
<
double
>
{
_mm_unpacklo_pd
(
a
.
raw
b
.
raw
)
}
;
}
HWY_API
Vec128
<
uint8_t
>
InterleaveUpper
(
const
Vec128
<
uint8_t
>
a
const
Vec128
<
uint8_t
>
b
)
{
return
Vec128
<
uint8_t
>
{
_mm_unpackhi_epi8
(
a
.
raw
b
.
raw
)
}
;
}
HWY_API
Vec128
<
uint16_t
>
InterleaveUpper
(
const
Vec128
<
uint16_t
>
a
const
Vec128
<
uint16_t
>
b
)
{
return
Vec128
<
uint16_t
>
{
_mm_unpackhi_epi16
(
a
.
raw
b
.
raw
)
}
;
}
HWY_API
Vec128
<
uint32_t
>
InterleaveUpper
(
const
Vec128
<
uint32_t
>
a
const
Vec128
<
uint32_t
>
b
)
{
return
Vec128
<
uint32_t
>
{
_mm_unpackhi_epi32
(
a
.
raw
b
.
raw
)
}
;
}
HWY_API
Vec128
<
uint64_t
>
InterleaveUpper
(
const
Vec128
<
uint64_t
>
a
const
Vec128
<
uint64_t
>
b
)
{
return
Vec128
<
uint64_t
>
{
_mm_unpackhi_epi64
(
a
.
raw
b
.
raw
)
}
;
}
HWY_API
Vec128
<
int8_t
>
InterleaveUpper
(
const
Vec128
<
int8_t
>
a
const
Vec128
<
int8_t
>
b
)
{
return
Vec128
<
int8_t
>
{
_mm_unpackhi_epi8
(
a
.
raw
b
.
raw
)
}
;
}
HWY_API
Vec128
<
int16_t
>
InterleaveUpper
(
const
Vec128
<
int16_t
>
a
const
Vec128
<
int16_t
>
b
)
{
return
Vec128
<
int16_t
>
{
_mm_unpackhi_epi16
(
a
.
raw
b
.
raw
)
}
;
}
HWY_API
Vec128
<
int32_t
>
InterleaveUpper
(
const
Vec128
<
int32_t
>
a
const
Vec128
<
int32_t
>
b
)
{
return
Vec128
<
int32_t
>
{
_mm_unpackhi_epi32
(
a
.
raw
b
.
raw
)
}
;
}
HWY_API
Vec128
<
int64_t
>
InterleaveUpper
(
const
Vec128
<
int64_t
>
a
const
Vec128
<
int64_t
>
b
)
{
return
Vec128
<
int64_t
>
{
_mm_unpackhi_epi64
(
a
.
raw
b
.
raw
)
}
;
}
HWY_API
Vec128
<
float
>
InterleaveUpper
(
const
Vec128
<
float
>
a
const
Vec128
<
float
>
b
)
{
return
Vec128
<
float
>
{
_mm_unpackhi_ps
(
a
.
raw
b
.
raw
)
}
;
}
HWY_API
Vec128
<
double
>
InterleaveUpper
(
const
Vec128
<
double
>
a
const
Vec128
<
double
>
b
)
{
return
Vec128
<
double
>
{
_mm_unpackhi_pd
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint16_t
(
N
+
1
)
/
2
>
ZipLower
(
const
Vec128
<
uint8_t
N
>
a
const
Vec128
<
uint8_t
N
>
b
)
{
return
Vec128
<
uint16_t
(
N
+
1
)
/
2
>
{
_mm_unpacklo_epi8
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint32_t
(
N
+
1
)
/
2
>
ZipLower
(
const
Vec128
<
uint16_t
N
>
a
const
Vec128
<
uint16_t
N
>
b
)
{
return
Vec128
<
uint32_t
(
N
+
1
)
/
2
>
{
_mm_unpacklo_epi16
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint64_t
(
N
+
1
)
/
2
>
ZipLower
(
const
Vec128
<
uint32_t
N
>
a
const
Vec128
<
uint32_t
N
>
b
)
{
return
Vec128
<
uint64_t
(
N
+
1
)
/
2
>
{
_mm_unpacklo_epi32
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
int16_t
(
N
+
1
)
/
2
>
ZipLower
(
const
Vec128
<
int8_t
N
>
a
const
Vec128
<
int8_t
N
>
b
)
{
return
Vec128
<
int16_t
(
N
+
1
)
/
2
>
{
_mm_unpacklo_epi8
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
int32_t
(
N
+
1
)
/
2
>
ZipLower
(
const
Vec128
<
int16_t
N
>
a
const
Vec128
<
int16_t
N
>
b
)
{
return
Vec128
<
int32_t
(
N
+
1
)
/
2
>
{
_mm_unpacklo_epi16
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
int64_t
(
N
+
1
)
/
2
>
ZipLower
(
const
Vec128
<
int32_t
N
>
a
const
Vec128
<
int32_t
N
>
b
)
{
return
Vec128
<
int64_t
(
N
+
1
)
/
2
>
{
_mm_unpacklo_epi32
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint16_t
(
N
+
1
)
/
2
>
ZipUpper
(
const
Vec128
<
uint8_t
N
>
a
const
Vec128
<
uint8_t
N
>
b
)
{
return
Vec128
<
uint16_t
(
N
+
1
)
/
2
>
{
_mm_unpackhi_epi8
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint32_t
(
N
+
1
)
/
2
>
ZipUpper
(
const
Vec128
<
uint16_t
N
>
a
const
Vec128
<
uint16_t
N
>
b
)
{
return
Vec128
<
uint32_t
(
N
+
1
)
/
2
>
{
_mm_unpackhi_epi16
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint64_t
(
N
+
1
)
/
2
>
ZipUpper
(
const
Vec128
<
uint32_t
N
>
a
const
Vec128
<
uint32_t
N
>
b
)
{
return
Vec128
<
uint64_t
(
N
+
1
)
/
2
>
{
_mm_unpackhi_epi32
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
int16_t
(
N
+
1
)
/
2
>
ZipUpper
(
const
Vec128
<
int8_t
N
>
a
const
Vec128
<
int8_t
N
>
b
)
{
return
Vec128
<
int16_t
(
N
+
1
)
/
2
>
{
_mm_unpackhi_epi8
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
int32_t
(
N
+
1
)
/
2
>
ZipUpper
(
const
Vec128
<
int16_t
N
>
a
const
Vec128
<
int16_t
N
>
b
)
{
return
Vec128
<
int32_t
(
N
+
1
)
/
2
>
{
_mm_unpackhi_epi16
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
int64_t
(
N
+
1
)
/
2
>
ZipUpper
(
const
Vec128
<
int32_t
N
>
a
const
Vec128
<
int32_t
N
>
b
)
{
return
Vec128
<
int64_t
(
N
+
1
)
/
2
>
{
_mm_unpackhi_epi32
(
a
.
raw
b
.
raw
)
}
;
}
template
<
typename
T
>
HWY_API
Vec128
<
T
>
ConcatLowerLower
(
const
Vec128
<
T
>
hi
const
Vec128
<
T
>
lo
)
{
const
Full128
<
uint64_t
>
d64
;
return
BitCast
(
Full128
<
T
>
(
)
InterleaveLower
(
BitCast
(
d64
lo
)
BitCast
(
d64
hi
)
)
)
;
}
template
<
typename
T
>
HWY_API
Vec128
<
T
>
ConcatUpperUpper
(
const
Vec128
<
T
>
hi
const
Vec128
<
T
>
lo
)
{
const
Full128
<
uint64_t
>
d64
;
return
BitCast
(
Full128
<
T
>
(
)
InterleaveUpper
(
BitCast
(
d64
lo
)
BitCast
(
d64
hi
)
)
)
;
}
template
<
typename
T
>
HWY_API
Vec128
<
T
>
ConcatLowerUpper
(
const
Vec128
<
T
>
hi
const
Vec128
<
T
>
lo
)
{
return
CombineShiftRightBytes
<
8
>
(
hi
lo
)
;
}
template
<
typename
T
>
HWY_API
Vec128
<
T
>
ConcatUpperLower
(
const
Vec128
<
T
>
hi
const
Vec128
<
T
>
lo
)
{
return
Vec128
<
T
>
{
_mm_blend_epi16
(
hi
.
raw
lo
.
raw
0x0F
)
}
;
}
template
<
>
HWY_INLINE
Vec128
<
float
>
ConcatUpperLower
(
const
Vec128
<
float
>
hi
const
Vec128
<
float
>
lo
)
{
return
Vec128
<
float
>
{
_mm_blend_ps
(
hi
.
raw
lo
.
raw
3
)
}
;
}
template
<
>
HWY_INLINE
Vec128
<
double
>
ConcatUpperLower
(
const
Vec128
<
double
>
hi
const
Vec128
<
double
>
lo
)
{
return
Vec128
<
double
>
{
_mm_blend_pd
(
hi
.
raw
lo
.
raw
1
)
}
;
}
namespace
detail
{
template
<
typename
T
size_t
N
>
HWY_API
Vec128
<
T
N
>
OddEven
(
hwy
:
:
SizeTag
<
1
>
const
Vec128
<
T
N
>
a
const
Vec128
<
T
N
>
b
)
{
const
Simd
<
T
N
>
d
;
const
Repartition
<
uint8_t
decltype
(
d
)
>
d8
;
alignas
(
16
)
constexpr
uint8_t
mask
[
16
]
=
{
0xFF
0
0xFF
0
0xFF
0
0xFF
0
0xFF
0
0xFF
0
0xFF
0
0xFF
0
}
;
return
IfThenElse
(
MaskFromVec
(
BitCast
(
d
Load
(
d8
mask
)
)
)
b
a
)
;
}
template
<
typename
T
size_t
N
>
HWY_API
Vec128
<
T
N
>
OddEven
(
hwy
:
:
SizeTag
<
2
>
const
Vec128
<
T
N
>
a
const
Vec128
<
T
N
>
b
)
{
return
Vec128
<
T
N
>
{
_mm_blend_epi16
(
a
.
raw
b
.
raw
0x55
)
}
;
}
template
<
typename
T
size_t
N
>
HWY_API
Vec128
<
T
N
>
OddEven
(
hwy
:
:
SizeTag
<
4
>
const
Vec128
<
T
N
>
a
const
Vec128
<
T
N
>
b
)
{
return
Vec128
<
T
N
>
{
_mm_blend_epi16
(
a
.
raw
b
.
raw
0x33
)
}
;
}
template
<
typename
T
size_t
N
>
HWY_API
Vec128
<
T
N
>
OddEven
(
hwy
:
:
SizeTag
<
8
>
const
Vec128
<
T
N
>
a
const
Vec128
<
T
N
>
b
)
{
return
Vec128
<
T
N
>
{
_mm_blend_epi16
(
a
.
raw
b
.
raw
0x0F
)
}
;
}
}
template
<
typename
T
size_t
N
>
HWY_API
Vec128
<
T
N
>
OddEven
(
const
Vec128
<
T
N
>
a
const
Vec128
<
T
N
>
b
)
{
return
detail
:
:
OddEven
(
hwy
:
:
SizeTag
<
sizeof
(
T
)
>
(
)
a
b
)
;
}
template
<
size_t
N
>
HWY_INLINE
Vec128
<
float
N
>
OddEven
(
const
Vec128
<
float
N
>
a
const
Vec128
<
float
N
>
b
)
{
return
Vec128
<
float
N
>
{
_mm_blend_ps
(
a
.
raw
b
.
raw
5
)
}
;
}
template
<
size_t
N
>
HWY_INLINE
Vec128
<
double
N
>
OddEven
(
const
Vec128
<
double
N
>
a
const
Vec128
<
double
N
>
b
)
{
return
Vec128
<
double
N
>
{
_mm_blend_pd
(
a
.
raw
b
.
raw
1
)
}
;
}
#
if
HWY_TARGET
!
=
HWY_AVX3
namespace
detail
{
template
<
typename
T
size_t
N
HWY_IF_LANE_SIZE
(
T
2
)
>
HWY_API
Vec128
<
MakeUnsigned
<
T
>
N
>
Pow2
(
const
Vec128
<
T
N
>
v
)
{
const
Simd
<
T
N
>
d
;
const
Repartition
<
float
decltype
(
d
)
>
df
;
const
auto
zero
=
Zero
(
d
)
;
const
auto
exp
=
ShiftLeft
<
23
-
16
>
(
v
)
;
const
auto
upper
=
exp
+
Set
(
d
0x3F80
)
;
const
auto
f0
=
ZipLower
(
zero
upper
)
;
const
auto
f1
=
ZipUpper
(
zero
upper
)
;
const
Vec128
<
int32_t
N
>
bits0
{
_mm_cvtps_epi32
(
BitCast
(
df
f0
)
.
raw
)
}
;
const
Vec128
<
int32_t
N
>
bits1
{
_mm_cvtps_epi32
(
BitCast
(
df
f1
)
.
raw
)
}
;
return
Vec128
<
MakeUnsigned
<
T
>
N
>
{
_mm_packus_epi32
(
bits0
.
raw
bits1
.
raw
)
}
;
}
template
<
typename
T
size_t
N
HWY_IF_LANE_SIZE
(
T
4
)
>
HWY_API
Vec128
<
MakeUnsigned
<
T
>
N
>
Pow2
(
const
Vec128
<
T
N
>
v
)
{
const
Simd
<
T
N
>
d
;
const
auto
exp
=
ShiftLeft
<
23
>
(
v
)
;
const
auto
f
=
exp
+
Set
(
d
0x3F800000
)
;
return
Vec128
<
MakeUnsigned
<
T
>
N
>
{
_mm_cvtps_epi32
(
_mm_castsi128_ps
(
f
.
raw
)
)
}
;
}
}
#
endif
template
<
size_t
N
>
HWY_API
Vec128
<
uint16_t
N
>
operator
<
<
(
const
Vec128
<
uint16_t
N
>
v
const
Vec128
<
uint16_t
N
>
bits
)
{
#
if
HWY_TARGET
=
=
HWY_AVX3
return
Vec128
<
uint16_t
N
>
{
_mm_sllv_epi16
(
v
.
raw
bits
.
raw
)
}
;
#
else
return
v
*
detail
:
:
Pow2
(
bits
)
;
#
endif
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint32_t
N
>
operator
<
<
(
const
Vec128
<
uint32_t
N
>
v
const
Vec128
<
uint32_t
N
>
bits
)
{
#
if
HWY_TARGET
=
=
HWY_SSE4
return
v
*
detail
:
:
Pow2
(
bits
)
;
#
else
return
Vec128
<
uint32_t
N
>
{
_mm_sllv_epi32
(
v
.
raw
bits
.
raw
)
}
;
#
endif
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint64_t
N
>
operator
<
<
(
const
Vec128
<
uint64_t
N
>
v
const
Vec128
<
uint64_t
N
>
bits
)
{
#
if
HWY_TARGET
=
=
HWY_SSE4
const
__m128i
out0
=
_mm_sll_epi64
(
v
.
raw
bits
.
raw
)
;
const
__m128i
bits1
=
_mm_unpackhi_epi64
(
bits
.
raw
bits
.
raw
)
;
const
__m128i
out1
=
_mm_sll_epi64
(
v
.
raw
bits1
)
;
return
Vec128
<
uint64_t
N
>
{
_mm_blend_epi16
(
out0
out1
0xF0
)
}
;
#
else
return
Vec128
<
uint64_t
N
>
{
_mm_sllv_epi64
(
v
.
raw
bits
.
raw
)
}
;
#
endif
}
template
<
typename
T
size_t
N
HWY_IF_SIGNED
(
T
)
>
HWY_API
Vec128
<
T
N
>
operator
<
<
(
const
Vec128
<
T
N
>
v
const
Vec128
<
T
N
>
bits
)
{
const
Simd
<
T
N
>
di
;
const
Simd
<
MakeUnsigned
<
T
>
N
>
du
;
return
BitCast
(
di
BitCast
(
du
v
)
<
<
BitCast
(
du
bits
)
)
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint16_t
N
>
operator
>
>
(
const
Vec128
<
uint16_t
N
>
in
const
Vec128
<
uint16_t
N
>
bits
)
{
#
if
HWY_TARGET
=
=
HWY_AVX3
return
Vec128
<
uint16_t
N
>
{
_mm_srlv_epi16
(
in
.
raw
bits
.
raw
)
}
;
#
else
const
Simd
<
uint16_t
N
>
d
;
const
auto
out
=
MulHigh
(
in
detail
:
:
Pow2
(
Set
(
d
16
)
-
bits
)
)
;
return
IfThenElse
(
bits
=
=
Zero
(
d
)
in
out
)
;
#
endif
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint32_t
N
>
operator
>
>
(
const
Vec128
<
uint32_t
N
>
in
const
Vec128
<
uint32_t
N
>
bits
)
{
#
if
HWY_TARGET
=
=
HWY_SSE4
const
Simd
<
uint32_t
N
>
d32
;
const
Vec128
<
uint32_t
N
>
in31
{
_mm_shuffle_epi32
(
in
.
raw
0x31
)
}
;
const
auto
mul
=
detail
:
:
Pow2
(
Set
(
d32
32
)
-
bits
)
;
const
auto
out20
=
ShiftRight
<
32
>
(
MulEven
(
in
mul
)
)
;
const
Vec128
<
uint32_t
N
>
mul31
{
_mm_shuffle_epi32
(
mul
.
raw
0x31
)
}
;
const
auto
out31
=
MulEven
(
in31
mul31
)
;
const
Vec128
<
uint32_t
N
>
out
{
_mm_blend_epi16
(
out31
.
raw
out20
.
raw
0x33
)
}
;
return
IfThenElse
(
bits
=
=
Zero
(
d32
)
in
out
)
;
#
else
return
Vec128
<
uint32_t
N
>
{
_mm_srlv_epi32
(
in
.
raw
bits
.
raw
)
}
;
#
endif
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint64_t
N
>
operator
>
>
(
const
Vec128
<
uint64_t
N
>
v
const
Vec128
<
uint64_t
N
>
bits
)
{
#
if
HWY_TARGET
=
=
HWY_SSE4
const
__m128i
out0
=
_mm_srl_epi64
(
v
.
raw
bits
.
raw
)
;
const
__m128i
bits1
=
_mm_unpackhi_epi64
(
bits
.
raw
bits
.
raw
)
;
const
__m128i
out1
=
_mm_srl_epi64
(
v
.
raw
bits1
)
;
return
Vec128
<
uint64_t
N
>
{
_mm_blend_epi16
(
out0
out1
0xF0
)
}
;
#
else
return
Vec128
<
uint64_t
N
>
{
_mm_srlv_epi64
(
v
.
raw
bits
.
raw
)
}
;
#
endif
}
#
if
HWY_TARGET
!
=
HWY_AVX3
namespace
detail
{
template
<
class
DI
class
V
>
HWY_API
V
SignedShr
(
const
DI
di
const
V
v
const
V
count_i
)
{
const
RebindToUnsigned
<
DI
>
du
;
const
auto
count
=
BitCast
(
du
count_i
)
;
const
auto
sign
=
BroadcastSignBit
(
v
)
;
const
auto
abs
=
BitCast
(
du
v
^
sign
)
;
return
BitCast
(
di
abs
>
>
count
)
^
sign
;
}
}
#
endif
template
<
size_t
N
>
HWY_API
Vec128
<
int16_t
N
>
operator
>
>
(
const
Vec128
<
int16_t
N
>
v
const
Vec128
<
int16_t
N
>
bits
)
{
#
if
HWY_TARGET
=
=
HWY_AVX3
return
Vec128
<
int16_t
N
>
{
_mm_srav_epi16
(
v
.
raw
bits
.
raw
)
}
;
#
else
return
detail
:
:
SignedShr
(
Simd
<
int16_t
N
>
(
)
v
bits
)
;
#
endif
}
template
<
size_t
N
>
HWY_API
Vec128
<
int32_t
N
>
operator
>
>
(
const
Vec128
<
int32_t
N
>
v
const
Vec128
<
int32_t
N
>
bits
)
{
#
if
HWY_TARGET
=
=
HWY_AVX3
return
Vec128
<
int32_t
N
>
{
_mm_srav_epi32
(
v
.
raw
bits
.
raw
)
}
;
#
else
return
detail
:
:
SignedShr
(
Simd
<
int32_t
N
>
(
)
v
bits
)
;
#
endif
}
template
<
size_t
N
>
HWY_API
Vec128
<
int64_t
N
>
operator
>
>
(
const
Vec128
<
int64_t
N
>
v
const
Vec128
<
int64_t
N
>
bits
)
{
#
if
HWY_TARGET
=
=
HWY_AVX3
return
Vec128
<
int64_t
N
>
{
_mm_srav_epi64
(
v
.
raw
bits
.
raw
)
}
;
#
else
return
detail
:
:
SignedShr
(
Simd
<
int64_t
N
>
(
)
v
bits
)
;
#
endif
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint16_t
N
>
PromoteTo
(
Simd
<
uint16_t
N
>
const
Vec128
<
uint8_t
N
>
v
)
{
return
Vec128
<
uint16_t
N
>
{
_mm_cvtepu8_epi16
(
v
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint32_t
N
>
PromoteTo
(
Simd
<
uint32_t
N
>
const
Vec128
<
uint8_t
N
>
v
)
{
return
Vec128
<
uint32_t
N
>
{
_mm_cvtepu8_epi32
(
v
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
int16_t
N
>
PromoteTo
(
Simd
<
int16_t
N
>
const
Vec128
<
uint8_t
N
>
v
)
{
return
Vec128
<
int16_t
N
>
{
_mm_cvtepu8_epi16
(
v
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
int32_t
N
>
PromoteTo
(
Simd
<
int32_t
N
>
const
Vec128
<
uint8_t
N
>
v
)
{
return
Vec128
<
int32_t
N
>
{
_mm_cvtepu8_epi32
(
v
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint32_t
N
>
PromoteTo
(
Simd
<
uint32_t
N
>
const
Vec128
<
uint16_t
N
>
v
)
{
return
Vec128
<
uint32_t
N
>
{
_mm_cvtepu16_epi32
(
v
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
int32_t
N
>
PromoteTo
(
Simd
<
int32_t
N
>
const
Vec128
<
uint16_t
N
>
v
)
{
return
Vec128
<
int32_t
N
>
{
_mm_cvtepu16_epi32
(
v
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint64_t
N
>
PromoteTo
(
Simd
<
uint64_t
N
>
const
Vec128
<
uint32_t
N
>
v
)
{
return
Vec128
<
uint64_t
N
>
{
_mm_cvtepu32_epi64
(
v
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
int16_t
N
>
PromoteTo
(
Simd
<
int16_t
N
>
const
Vec128
<
int8_t
N
>
v
)
{
return
Vec128
<
int16_t
N
>
{
_mm_cvtepi8_epi16
(
v
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
int32_t
N
>
PromoteTo
(
Simd
<
int32_t
N
>
const
Vec128
<
int8_t
N
>
v
)
{
return
Vec128
<
int32_t
N
>
{
_mm_cvtepi8_epi32
(
v
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
int32_t
N
>
PromoteTo
(
Simd
<
int32_t
N
>
const
Vec128
<
int16_t
N
>
v
)
{
return
Vec128
<
int32_t
N
>
{
_mm_cvtepi16_epi32
(
v
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
int64_t
N
>
PromoteTo
(
Simd
<
int64_t
N
>
const
Vec128
<
int32_t
N
>
v
)
{
return
Vec128
<
int64_t
N
>
{
_mm_cvtepi32_epi64
(
v
.
raw
)
}
;
}
#
if
defined
(
MEMORY_SANITIZER
)
&
&
\
(
HWY_COMPILER_CLANG
!
=
0
&
&
HWY_COMPILER_CLANG
<
1100
)
#
define
HWY_INLINE_F16
HWY_NOINLINE
#
else
#
define
HWY_INLINE_F16
HWY_INLINE
#
endif
template
<
size_t
N
>
HWY_INLINE_F16
Vec128
<
float
N
>
PromoteTo
(
Simd
<
float
N
>
const
Vec128
<
float16_t
N
>
v
)
{
#
if
HWY_TARGET
=
=
HWY_SSE4
const
Simd
<
int32_t
N
>
di32
;
const
Simd
<
uint32_t
N
>
du32
;
const
Simd
<
float
N
>
df32
;
const
auto
bits16
=
PromoteTo
(
du32
Vec128
<
uint16_t
N
>
{
v
.
raw
}
)
;
const
auto
sign
=
ShiftRight
<
15
>
(
bits16
)
;
const
auto
biased_exp
=
ShiftRight
<
10
>
(
bits16
)
&
Set
(
du32
0x1F
)
;
const
auto
mantissa
=
bits16
&
Set
(
du32
0x3FF
)
;
const
auto
subnormal
=
BitCast
(
du32
ConvertTo
(
df32
BitCast
(
di32
mantissa
)
)
*
Set
(
df32
1
.
0f
/
16384
/
1024
)
)
;
const
auto
biased_exp32
=
biased_exp
+
Set
(
du32
127
-
15
)
;
const
auto
mantissa32
=
ShiftLeft
<
23
-
10
>
(
mantissa
)
;
const
auto
normal
=
ShiftLeft
<
23
>
(
biased_exp32
)
|
mantissa32
;
const
auto
bits32
=
IfThenElse
(
biased_exp
=
=
Zero
(
du32
)
subnormal
normal
)
;
return
BitCast
(
df32
ShiftLeft
<
31
>
(
sign
)
|
bits32
)
;
#
else
return
Vec128
<
float
N
>
{
_mm_cvtph_ps
(
v
.
raw
)
}
;
#
endif
}
template
<
size_t
N
>
HWY_API
Vec128
<
double
N
>
PromoteTo
(
Simd
<
double
N
>
const
Vec128
<
float
N
>
v
)
{
return
Vec128
<
double
N
>
{
_mm_cvtps_pd
(
v
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
double
N
>
PromoteTo
(
Simd
<
double
N
>
const
Vec128
<
int32_t
N
>
v
)
{
return
Vec128
<
double
N
>
{
_mm_cvtepi32_pd
(
v
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint16_t
N
>
DemoteTo
(
Simd
<
uint16_t
N
>
const
Vec128
<
int32_t
N
>
v
)
{
return
Vec128
<
uint16_t
N
>
{
_mm_packus_epi32
(
v
.
raw
v
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
int16_t
N
>
DemoteTo
(
Simd
<
int16_t
N
>
const
Vec128
<
int32_t
N
>
v
)
{
return
Vec128
<
int16_t
N
>
{
_mm_packs_epi32
(
v
.
raw
v
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint8_t
N
>
DemoteTo
(
Simd
<
uint8_t
N
>
const
Vec128
<
int32_t
N
>
v
)
{
const
__m128i
u16
=
_mm_packus_epi32
(
v
.
raw
v
.
raw
)
;
const
__m128i
i16
=
_mm_and_si128
(
u16
_mm_set1_epi16
(
0x7FFF
)
)
;
return
Vec128
<
uint8_t
N
>
{
_mm_packus_epi16
(
i16
i16
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint8_t
N
>
DemoteTo
(
Simd
<
uint8_t
N
>
const
Vec128
<
int16_t
N
>
v
)
{
return
Vec128
<
uint8_t
N
>
{
_mm_packus_epi16
(
v
.
raw
v
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
int8_t
N
>
DemoteTo
(
Simd
<
int8_t
N
>
const
Vec128
<
int32_t
N
>
v
)
{
const
__m128i
i16
=
_mm_packs_epi32
(
v
.
raw
v
.
raw
)
;
return
Vec128
<
int8_t
N
>
{
_mm_packs_epi16
(
i16
i16
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
int8_t
N
>
DemoteTo
(
Simd
<
int8_t
N
>
const
Vec128
<
int16_t
N
>
v
)
{
return
Vec128
<
int8_t
N
>
{
_mm_packs_epi16
(
v
.
raw
v
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_INLINE
Vec128
<
float16_t
N
>
DemoteTo
(
Simd
<
float16_t
N
>
const
Vec128
<
float
N
>
v
)
{
#
if
HWY_TARGET
=
=
HWY_SSE4
const
Simd
<
int32_t
N
>
di
;
const
Simd
<
uint32_t
N
>
du
;
const
Simd
<
uint16_t
N
>
du16
;
const
Simd
<
float16_t
N
>
df16
;
const
auto
bits32
=
BitCast
(
du
v
)
;
const
auto
sign
=
ShiftRight
<
31
>
(
bits32
)
;
const
auto
biased_exp32
=
ShiftRight
<
23
>
(
bits32
)
&
Set
(
du
0xFF
)
;
const
auto
mantissa32
=
bits32
&
Set
(
du
0x7FFFFF
)
;
const
auto
k15
=
Set
(
di
15
)
;
const
auto
exp
=
Min
(
BitCast
(
di
biased_exp32
)
-
Set
(
di
127
)
k15
)
;
const
auto
is_tiny
=
exp
<
Set
(
di
-
24
)
;
const
auto
is_subnormal
=
exp
<
Set
(
di
-
14
)
;
const
auto
biased_exp16
=
BitCast
(
du
IfThenZeroElse
(
is_subnormal
exp
+
k15
)
)
;
const
auto
sub_exp
=
BitCast
(
du
Set
(
di
-
14
)
-
exp
)
;
const
auto
sub_m
=
(
Set
(
du
1
)
<
<
(
Set
(
du
10
)
-
sub_exp
)
)
+
(
mantissa32
>
>
(
Set
(
du
13
)
+
sub_exp
)
)
;
const
auto
mantissa16
=
IfThenElse
(
RebindMask
(
du
is_subnormal
)
sub_m
ShiftRight
<
13
>
(
mantissa32
)
)
;
const
auto
sign16
=
ShiftLeft
<
15
>
(
sign
)
;
const
auto
normal16
=
sign16
|
ShiftLeft
<
10
>
(
biased_exp16
)
|
mantissa16
;
const
auto
bits16
=
IfThenZeroElse
(
is_tiny
BitCast
(
di
normal16
)
)
;
return
BitCast
(
df16
DemoteTo
(
du16
bits16
)
)
;
#
else
return
Vec128
<
float16_t
N
>
{
_mm_cvtps_ph
(
v
.
raw
_MM_FROUND_NO_EXC
)
}
;
#
endif
}
template
<
size_t
N
>
HWY_INLINE
Vec128
<
float
N
>
DemoteTo
(
Simd
<
float
N
>
const
Vec128
<
double
N
>
v
)
{
return
Vec128
<
float
N
>
{
_mm_cvtpd_ps
(
v
.
raw
)
}
;
}
namespace
detail
{
template
<
size_t
N
>
HWY_API
auto
ClampF64ToI32Max
(
Simd
<
double
N
>
d
decltype
(
Zero
(
d
)
)
v
)
-
>
decltype
(
Zero
(
d
)
)
{
return
Min
(
v
Set
(
d
2147483647
.
0
)
)
;
}
template
<
typename
TI
size_t
N
class
DF
=
Simd
<
MakeFloat
<
TI
>
N
>
>
HWY_API
auto
FixConversionOverflow
(
Simd
<
TI
N
>
di
decltype
(
Zero
(
DF
(
)
)
)
original
decltype
(
Zero
(
di
)
.
raw
)
converted_raw
)
-
>
decltype
(
Zero
(
di
)
)
{
const
auto
converted
=
decltype
(
Zero
(
di
)
)
{
converted_raw
}
;
const
auto
sign_wrong
=
AndNot
(
BitCast
(
di
original
)
converted
)
;
return
BitCast
(
di
Xor
(
converted
BroadcastSignBit
(
sign_wrong
)
)
)
;
}
}
template
<
size_t
N
>
HWY_INLINE
Vec128
<
int32_t
N
>
DemoteTo
(
Simd
<
int32_t
N
>
const
Vec128
<
double
N
>
v
)
{
const
auto
clamped
=
detail
:
:
ClampF64ToI32Max
(
Simd
<
double
N
>
(
)
v
)
;
return
Vec128
<
int32_t
N
>
{
_mm_cvttpd_epi32
(
clamped
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint8_t
N
>
U8FromU32
(
const
Vec128
<
uint32_t
N
>
v
)
{
const
Simd
<
uint32_t
N
>
d32
;
const
Simd
<
uint8_t
N
*
4
>
d8
;
alignas
(
16
)
static
constexpr
uint32_t
k8From32
[
4
]
=
{
0x0C080400u
0x0C080400u
0x0C080400u
0x0C080400u
}
;
const
auto
quad
=
TableLookupBytes
(
v
Load
(
d32
k8From32
)
)
;
return
LowerHalf
(
LowerHalf
(
BitCast
(
d8
quad
)
)
)
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
float
N
>
ConvertTo
(
Simd
<
float
N
>
const
Vec128
<
int32_t
N
>
v
)
{
return
Vec128
<
float
N
>
{
_mm_cvtepi32_ps
(
v
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
double
N
>
ConvertTo
(
Simd
<
double
N
>
dd
const
Vec128
<
int64_t
N
>
v
)
{
#
if
HWY_TARGET
=
=
HWY_AVX3
(
void
)
dd
;
return
Vec128
<
double
N
>
{
_mm_cvtepi64_pd
(
v
.
raw
)
}
;
#
else
const
Repartition
<
uint32_t
decltype
(
dd
)
>
d32
;
const
Repartition
<
uint64_t
decltype
(
dd
)
>
d64
;
const
auto
k84_63
=
Set
(
d64
0x4530000080000000ULL
)
;
const
auto
v_upper
=
BitCast
(
dd
ShiftRight
<
32
>
(
BitCast
(
d64
v
)
)
^
k84_63
)
;
const
auto
k52
=
Set
(
d32
0x43300000
)
;
const
auto
v_lower
=
BitCast
(
dd
OddEven
(
k52
BitCast
(
d32
v
)
)
)
;
const
auto
k84_63_52
=
BitCast
(
dd
Set
(
d64
0x4530000080100000ULL
)
)
;
return
(
v_upper
-
k84_63_52
)
+
v_lower
;
#
endif
}
template
<
size_t
N
>
HWY_API
Vec128
<
int32_t
N
>
ConvertTo
(
const
Simd
<
int32_t
N
>
di
const
Vec128
<
float
N
>
v
)
{
return
detail
:
:
FixConversionOverflow
(
di
v
_mm_cvttps_epi32
(
v
.
raw
)
)
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
int64_t
N
>
ConvertTo
(
Simd
<
int64_t
N
>
di
const
Vec128
<
double
N
>
v
)
{
#
if
HWY_TARGET
=
=
HWY_AVX3
return
detail
:
:
FixConversionOverflow
(
di
v
_mm_cvttpd_epi64
(
v
.
raw
)
)
;
#
else
alignas
(
16
)
double
lanes_d
[
2
]
;
Store
(
v
Simd
<
double
N
>
(
)
lanes_d
)
;
alignas
(
16
)
int64_t
lanes_i
[
2
]
;
for
(
size_t
i
=
0
;
i
<
N
;
+
+
i
)
{
if
(
lanes_d
[
i
]
>
=
static_cast
<
double
>
(
LimitsMax
<
int64_t
>
(
)
)
)
{
lanes_i
[
i
]
=
LimitsMax
<
int64_t
>
(
)
;
}
else
if
(
lanes_d
[
i
]
<
=
static_cast
<
double
>
(
LimitsMin
<
int64_t
>
(
)
)
)
{
lanes_i
[
i
]
=
LimitsMin
<
int64_t
>
(
)
;
}
else
{
lanes_i
[
i
]
=
static_cast
<
int64_t
>
(
lanes_d
[
i
]
)
;
}
}
return
Load
(
di
lanes_i
)
;
#
endif
}
template
<
size_t
N
>
HWY_API
Vec128
<
int32_t
N
>
NearestInt
(
const
Vec128
<
float
N
>
v
)
{
const
Simd
<
int32_t
N
>
di
;
return
detail
:
:
FixConversionOverflow
(
di
v
_mm_cvtps_epi32
(
v
.
raw
)
)
;
}
template
<
typename
T
size_t
N
typename
T2
HWY_IF_LE128
(
T
N
)
>
Vec128
<
T
N
>
Iota
(
const
Simd
<
T
N
>
d
const
T2
first
)
{
HWY_ALIGN
T
lanes
[
16
/
sizeof
(
T
)
]
;
for
(
size_t
i
=
0
;
i
<
16
/
sizeof
(
T
)
;
+
+
i
)
{
lanes
[
i
]
=
static_cast
<
T
>
(
first
+
static_cast
<
T2
>
(
i
)
)
;
}
return
Load
(
d
lanes
)
;
}
namespace
detail
{
constexpr
HWY_INLINE
uint64_t
U64FromInt
(
int
bits
)
{
return
static_cast
<
uint64_t
>
(
static_cast
<
unsigned
>
(
bits
)
)
;
}
template
<
typename
T
size_t
N
>
HWY_API
uint64_t
BitsFromMask
(
hwy
:
:
SizeTag
<
1
>
const
Mask128
<
T
N
>
mask
)
{
const
Simd
<
T
N
>
d
;
const
auto
sign_bits
=
BitCast
(
d
VecFromMask
(
d
mask
)
)
.
raw
;
return
U64FromInt
(
_mm_movemask_epi8
(
sign_bits
)
)
;
}
template
<
typename
T
size_t
N
>
HWY_API
uint64_t
BitsFromMask
(
hwy
:
:
SizeTag
<
2
>
const
Mask128
<
T
N
>
mask
)
{
const
auto
sign_bits
=
_mm_packs_epi16
(
mask
.
raw
_mm_setzero_si128
(
)
)
;
return
U64FromInt
(
_mm_movemask_epi8
(
sign_bits
)
)
;
}
template
<
typename
T
size_t
N
>
HWY_API
uint64_t
BitsFromMask
(
hwy
:
:
SizeTag
<
4
>
const
Mask128
<
T
N
>
mask
)
{
const
Simd
<
T
N
>
d
;
const
Simd
<
float
N
>
df
;
const
auto
sign_bits
=
BitCast
(
df
VecFromMask
(
d
mask
)
)
;
return
U64FromInt
(
_mm_movemask_ps
(
sign_bits
.
raw
)
)
;
}
template
<
typename
T
size_t
N
>
HWY_API
uint64_t
BitsFromMask
(
hwy
:
:
SizeTag
<
8
>
const
Mask128
<
T
N
>
mask
)
{
const
Simd
<
T
N
>
d
;
const
Simd
<
double
N
>
df
;
const
auto
sign_bits
=
BitCast
(
df
VecFromMask
(
d
mask
)
)
;
return
U64FromInt
(
_mm_movemask_pd
(
sign_bits
.
raw
)
)
;
}
template
<
typename
T
size_t
N
>
constexpr
uint64_t
OnlyActive
(
uint64_t
bits
)
{
return
(
(
N
*
sizeof
(
T
)
)
=
=
16
)
?
bits
:
bits
&
(
(
1ull
<
<
N
)
-
1
)
;
}
template
<
typename
T
size_t
N
>
HWY_API
uint64_t
BitsFromMask
(
const
Mask128
<
T
N
>
mask
)
{
return
OnlyActive
<
T
N
>
(
BitsFromMask
(
hwy
:
:
SizeTag
<
sizeof
(
T
)
>
(
)
mask
)
)
;
}
}
template
<
typename
T
size_t
N
>
HWY_INLINE
size_t
StoreMaskBits
(
const
Mask128
<
T
N
>
mask
uint8_t
*
p
)
{
const
uint64_t
bits
=
detail
:
:
BitsFromMask
(
mask
)
;
const
size_t
kNumBytes
=
(
N
+
7
)
/
8
;
CopyBytes
<
kNumBytes
>
(
&
bits
p
)
;
return
kNumBytes
;
}
template
<
typename
T
size_t
N
>
HWY_API
bool
AllFalse
(
const
Mask128
<
T
N
>
mask
)
{
return
detail
:
:
BitsFromMask
(
mask
)
=
=
0
;
}
template
<
typename
T
size_t
N
>
HWY_API
bool
AllTrue
(
const
Mask128
<
T
N
>
mask
)
{
constexpr
uint64_t
kAllBits
=
detail
:
:
OnlyActive
<
T
N
>
(
(
1ull
<
<
(
16
/
sizeof
(
T
)
)
)
-
1
)
;
return
detail
:
:
BitsFromMask
(
mask
)
=
=
kAllBits
;
}
template
<
typename
T
size_t
N
>
HWY_API
size_t
CountTrue
(
const
Mask128
<
T
N
>
mask
)
{
return
PopCount
(
detail
:
:
BitsFromMask
(
mask
)
)
;
}
namespace
detail
{
template
<
typename
T
size_t
N
>
HWY_INLINE
Vec128
<
T
N
>
Idx16x8FromBits
(
const
uint64_t
mask_bits
)
{
HWY_DASSERT
(
mask_bits
<
256
)
;
const
Simd
<
T
N
>
d
;
const
Rebind
<
uint8_t
decltype
(
d
)
>
d8
;
const
Simd
<
uint16_t
N
>
du
;
alignas
(
16
)
constexpr
uint8_t
table
[
256
*
8
]
=
{
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
2
0
0
0
0
0
0
0
0
2
0
0
0
0
0
0
4
0
0
0
0
0
0
0
0
4
0
0
0
0
0
0
2
4
0
0
0
0
0
0
0
2
4
0
0
0
0
0
6
0
0
0
0
0
0
0
0
6
0
0
0
0
0
0
2
6
0
0
0
0
0
0
0
2
6
0
0
0
0
0
4
6
0
0
0
0
0
0
0
4
6
0
0
0
0
0
2
4
6
0
0
0
0
0
0
2
4
6
0
0
0
0
8
0
0
0
0
0
0
0
0
8
0
0
0
0
0
0
2
8
0
0
0
0
0
0
0
2
8
0
0
0
0
0
4
8
0
0
0
0
0
0
0
4
8
0
0
0
0
0
2
4
8
0
0
0
0
0
0
2
4
8
0
0
0
0
6
8
0
0
0
0
0
0
0
6
8
0
0
0
0
0
2
6
8
0
0
0
0
0
0
2
6
8
0
0
0
0
4
6
8
0
0
0
0
0
0
4
6
8
0
0
0
0
2
4
6
8
0
0
0
0
0
2
4
6
8
0
0
0
10
0
0
0
0
0
0
0
0
10
0
0
0
0
0
0
2
10
0
0
0
0
0
0
0
2
10
0
0
0
0
0
4
10
0
0
0
0
0
0
0
4
10
0
0
0
0
0
2
4
10
0
0
0
0
0
0
2
4
10
0
0
0
0
6
10
0
0
0
0
0
0
0
6
10
0
0
0
0
0
2
6
10
0
0
0
0
0
0
2
6
10
0
0
0
0
4
6
10
0
0
0
0
0
0
4
6
10
0
0
0
0
2
4
6
10
0
0
0
0
0
2
4
6
10
0
0
0
8
10
0
0
0
0
0
0
0
8
10
0
0
0
0
0
2
8
10
0
0
0
0
0
0
2
8
10
0
0
0
0
4
8
10
0
0
0
0
0
0
4
8
10
0
0
0
0
2
4
8
10
0
0
0
0
0
2
4
8
10
0
0
0
6
8
10
0
0
0
0
0
0
6
8
10
0
0
0
0
2
6
8
10
0
0
0
0
0
2
6
8
10
0
0
0
4
6
8
10
0
0
0
0
0
4
6
8
10
0
0
0
2
4
6
8
10
0
0
0
0
2
4
6
8
10
0
0
12
0
0
0
0
0
0
0
0
12
0
0
0
0
0
0
2
12
0
0
0
0
0
0
0
2
12
0
0
0
0
0
4
12
0
0
0
0
0
0
0
4
12
0
0
0
0
0
2
4
12
0
0
0
0
0
0
2
4
12
0
0
0
0
6
12
0
0
0
0
0
0
0
6
12
0
0
0
0
0
2
6
12
0
0
0
0
0
0
2
6
12
0
0
0
0
4
6
12
0
0
0
0
0
0
4
6
12
0
0
0
0
2
4
6
12
0
0
0
0
0
2
4
6
12
0
0
0
8
12
0
0
0
0
0
0
0
8
12
0
0
0
0
0
2
8
12
0
0
0
0
0
0
2
8
12
0
0
0
0
4
8
12
0
0
0
0
0
0
4
8
12
0
0
0
0
2
4
8
12
0
0
0
0
0
2
4
8
12
0
0
0
6
8
12
0
0
0
0
0
0
6
8
12
0
0
0
0
2
6
8
12
0
0
0
0
0
2
6
8
12
0
0
0
4
6
8
12
0
0
0
0
0
4
6
8
12
0
0
0
2
4
6
8
12
0
0
0
0
2
4
6
8
12
0
0
10
12
0
0
0
0
0
0
0
10
12
0
0
0
0
0
2
10
12
0
0
0
0
0
0
2
10
12
0
0
0
0
4
10
12
0
0
0
0
0
0
4
10
12
0
0
0
0
2
4
10
12
0
0
0
0
0
2
4
10
12
0
0
0
6
10
12
0
0
0
0
0
0
6
10
12
0
0
0
0
2
6
10
12
0
0
0
0
0
2
6
10
12
0
0
0
4
6
10
12
0
0
0
0
0
4
6
10
12
0
0
0
2
4
6
10
12
0
0
0
0
2
4
6
10
12
0
0
8
10
12
0
0
0
0
0
0
8
10
12
0
0
0
0
2
8
10
12
0
0
0
0
0
2
8
10
12
0
0
0
4
8
10
12
0
0
0
0
0
4
8
10
12
0
0
0
2
4
8
10
12
0
0
0
0
2
4
8
10
12
0
0
6
8
10
12
0
0
0
0
0
6
8
10
12
0
0
0
2
6
8
10
12
0
0
0
0
2
6
8
10
12
0
0
4
6
8
10
12
0
0
0
0
4
6
8
10
12
0
0
2
4
6
8
10
12
0
0
0
2
4
6
8
10
12
0
14
0
0
0
0
0
0
0
0
14
0
0
0
0
0
0
2
14
0
0
0
0
0
0
0
2
14
0
0
0
0
0
4
14
0
0
0
0
0
0
0
4
14
0
0
0
0
0
2
4
14
0
0
0
0
0
0
2
4
14
0
0
0
0
6
14
0
0
0
0
0
0
0
6
14
0
0
0
0
0
2
6
14
0
0
0
0
0
0
2
6
14
0
0
0
0
4
6
14
0
0
0
0
0
0
4
6
14
0
0
0
0
2
4
6
14
0
0
0
0
0
2
4
6
14
0
0
0
8
14
0
0
0
0
0
0
0
8
14
0
0
0
0
0
2
8
14
0
0
0
0
0
0
2
8
14
0
0
0
0
4
8
14
0
0
0
0
0
0
4
8
14
0
0
0
0
2
4
8
14
0
0
0
0
0
2
4
8
14
0
0
0
6
8
14
0
0
0
0
0
0
6
8
14
0
0
0
0
2
6
8
14
0
0
0
0
0
2
6
8
14
0
0
0
4
6
8
14
0
0
0
0
0
4
6
8
14
0
0
0
2
4
6
8
14
0
0
0
0
2
4
6
8
14
0
0
10
14
0
0
0
0
0
0
0
10
14
0
0
0
0
0
2
10
14
0
0
0
0
0
0
2
10
14
0
0
0
0
4
10
14
0
0
0
0
0
0
4
10
14
0
0
0
0
2
4
10
14
0
0
0
0
0
2
4
10
14
0
0
0
6
10
14
0
0
0
0
0
0
6
10
14
0
0
0
0
2
6
10
14
0
0
0
0
0
2
6
10
14
0
0
0
4
6
10
14
0
0
0
0
0
4
6
10
14
0
0
0
2
4
6
10
14
0
0
0
0
2
4
6
10
14
0
0
8
10
14
0
0
0
0
0
0
8
10
14
0
0
0
0
2
8
10
14
0
0
0
0
0
2
8
10
14
0
0
0
4
8
10
14
0
0
0
0
0
4
8
10
14
0
0
0
2
4
8
10
14
0
0
0
0
2
4
8
10
14
0
0
6
8
10
14
0
0
0
0
0
6
8
10
14
0
0
0
2
6
8
10
14
0
0
0
0
2
6
8
10
14
0
0
4
6
8
10
14
0
0
0
0
4
6
8
10
14
0
0
2
4
6
8
10
14
0
0
0
2
4
6
8
10
14
0
12
14
0
0
0
0
0
0
0
12
14
0
0
0
0
0
2
12
14
0
0
0
0
0
0
2
12
14
0
0
0
0
4
12
14
0
0
0
0
0
0
4
12
14
0
0
0
0
2
4
12
14
0
0
0
0
0
2
4
12
14
0
0
0
6
12
14
0
0
0
0
0
0
6
12
14
0
0
0
0
2
6
12
14
0
0
0
0
0
2
6
12
14
0
0
0
4
6
12
14
0
0
0
0
0
4
6
12
14
0
0
0
2
4
6
12
14
0
0
0
0
2
4
6
12
14
0
0
8
12
14
0
0
0
0
0
0
8
12
14
0
0
0
0
2
8
12
14
0
0
0
0
0
2
8
12
14
0
0
0
4
8
12
14
0
0
0
0
0
4
8
12
14
0
0
0
2
4
8
12
14
0
0
0
0
2
4
8
12
14
0
0
6
8
12
14
0
0
0
0
0
6
8
12
14
0
0
0
2
6
8
12
14
0
0
0
0
2
6
8
12
14
0
0
4
6
8
12
14
0
0
0
0
4
6
8
12
14
0
0
2
4
6
8
12
14
0
0
0
2
4
6
8
12
14
0
10
12
14
0
0
0
0
0
0
10
12
14
0
0
0
0
2
10
12
14
0
0
0
0
0
2
10
12
14
0
0
0
4
10
12
14
0
0
0
0
0
4
10
12
14
0
0
0
2
4
10
12
14
0
0
0
0
2
4
10
12
14
0
0
6
10
12
14
0
0
0
0
0
6
10
12
14
0
0
0
2
6
10
12
14
0
0
0
0
2
6
10
12
14
0
0
4
6
10
12
14
0
0
0
0
4
6
10
12
14
0
0
2
4
6
10
12
14
0
0
0
2
4
6
10
12
14
0
8
10
12
14
0
0
0
0
0
8
10
12
14
0
0
0
2
8
10
12
14
0
0
0
0
2
8
10
12
14
0
0
4
8
10
12
14
0
0
0
0
4
8
10
12
14
0
0
2
4
8
10
12
14
0
0
0
2
4
8
10
12
14
0
6
8
10
12
14
0
0
0
0
6
8
10
12
14
0
0
2
6
8
10
12
14
0
0
0
2
6
8
10
12
14
0
4
6
8
10
12
14
0
0
0
4
6
8
10
12
14
0
2
4
6
8
10
12
14
0
0
2
4
6
8
10
12
14
}
;
const
Vec128
<
uint8_t
2
*
N
>
byte_idx
{
Load
(
d8
table
+
mask_bits
*
8
)
.
raw
}
;
const
Vec128
<
uint16_t
N
>
pairs
=
ZipLower
(
byte_idx
byte_idx
)
;
return
BitCast
(
d
pairs
+
Set
(
du
0x0100
)
)
;
}
template
<
typename
T
size_t
N
>
HWY_INLINE
Vec128
<
T
N
>
Idx32x4FromBits
(
const
uint64_t
mask_bits
)
{
HWY_DASSERT
(
mask_bits
<
16
)
;
alignas
(
16
)
constexpr
uint8_t
packed_array
[
16
*
16
]
=
{
0
1
2
3
0
1
2
3
0
1
2
3
0
1
2
3
0
1
2
3
0
1
2
3
0
1
2
3
0
1
2
3
4
5
6
7
0
1
2
3
0
1
2
3
0
1
2
3
0
1
2
3
4
5
6
7
0
1
2
3
0
1
2
3
8
9
10
11
0
1
2
3
0
1
2
3
0
1
2
3
0
1
2
3
8
9
10
11
0
1
2
3
0
1
2
3
4
5
6
7
8
9
10
11
0
1
2
3
0
1
2
3
0
1
2
3
4
5
6
7
8
9
10
11
0
1
2
3
12
13
14
15
0
1
2
3
0
1
2
3
0
1
2
3
0
1
2
3
12
13
14
15
0
1
2
3
0
1
2
3
4
5
6
7
12
13
14
15
0
1
2
3
0
1
2
3
0
1
2
3
4
5
6
7
12
13
14
15
0
1
2
3
8
9
10
11
12
13
14
15
0
1
2
3
0
1
2
3
0
1
2
3
8
9
10
11
12
13
14
15
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
0
1
2
3
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
}
;
const
Simd
<
T
N
>
d
;
const
Repartition
<
uint8_t
decltype
(
d
)
>
d8
;
return
BitCast
(
d
Load
(
d8
packed_array
+
16
*
mask_bits
)
)
;
}
template
<
typename
T
size_t
N
>
HWY_INLINE
Vec128
<
T
N
>
Idx64x2FromBits
(
const
uint64_t
mask_bits
)
{
HWY_DASSERT
(
mask_bits
<
4
)
;
alignas
(
16
)
constexpr
uint8_t
packed_array
[
4
*
16
]
=
{
0
1
2
3
4
5
6
7
0
1
2
3
4
5
6
7
0
1
2
3
4
5
6
7
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
0
1
2
3
4
5
6
7
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
}
;
const
Simd
<
T
N
>
d
;
const
Repartition
<
uint8_t
decltype
(
d
)
>
d8
;
return
BitCast
(
d
Load
(
d8
packed_array
+
16
*
mask_bits
)
)
;
}
template
<
typename
T
size_t
N
>
HWY_API
Vec128
<
T
N
>
Compress
(
hwy
:
:
SizeTag
<
2
>
Vec128
<
T
N
>
v
const
uint64_t
mask_bits
)
{
const
auto
idx
=
detail
:
:
Idx16x8FromBits
<
T
N
>
(
mask_bits
)
;
using
D
=
Simd
<
T
N
>
;
const
RebindToSigned
<
D
>
di
;
return
BitCast
(
D
(
)
TableLookupBytes
(
BitCast
(
di
v
)
BitCast
(
di
idx
)
)
)
;
}
template
<
typename
T
size_t
N
>
HWY_API
Vec128
<
T
N
>
Compress
(
hwy
:
:
SizeTag
<
4
>
Vec128
<
T
N
>
v
const
uint64_t
mask_bits
)
{
using
D
=
Simd
<
T
N
>
;
using
TI
=
MakeSigned
<
T
>
;
const
Rebind
<
TI
D
>
di
;
#
if
HWY_TARGET
=
=
HWY_AVX3
return
BitCast
(
D
(
)
Vec128
<
TI
N
>
{
_mm_maskz_compress_epi32
(
mask_bits
BitCast
(
di
v
)
.
raw
)
}
)
;
#
else
const
auto
idx
=
detail
:
:
Idx32x4FromBits
<
T
N
>
(
mask_bits
)
;
return
BitCast
(
D
(
)
TableLookupBytes
(
BitCast
(
di
v
)
BitCast
(
di
idx
)
)
)
;
#
endif
}
template
<
typename
T
size_t
N
>
HWY_API
Vec128
<
T
N
>
Compress
(
hwy
:
:
SizeTag
<
8
>
Vec128
<
T
N
>
v
const
uint64_t
mask_bits
)
{
using
D
=
Simd
<
T
N
>
;
using
TI
=
MakeSigned
<
T
>
;
const
Rebind
<
TI
D
>
di
;
#
if
HWY_TARGET
=
=
HWY_AVX3
return
BitCast
(
D
(
)
Vec128
<
TI
N
>
{
_mm_maskz_compress_epi64
(
mask_bits
BitCast
(
di
v
)
.
raw
)
}
)
;
#
else
const
auto
idx
=
detail
:
:
Idx64x2FromBits
<
T
N
>
(
mask_bits
)
;
return
BitCast
(
D
(
)
TableLookupBytes
(
BitCast
(
di
v
)
BitCast
(
di
idx
)
)
)
;
#
endif
}
}
template
<
typename
T
size_t
N
>
HWY_API
Vec128
<
T
N
>
Compress
(
Vec128
<
T
N
>
v
const
Mask128
<
T
N
>
mask
)
{
return
detail
:
:
Compress
(
hwy
:
:
SizeTag
<
sizeof
(
T
)
>
(
)
v
detail
:
:
BitsFromMask
(
mask
)
)
;
}
template
<
typename
T
size_t
N
>
HWY_API
size_t
CompressStore
(
Vec128
<
T
N
>
v
const
Mask128
<
T
N
>
mask
Simd
<
T
N
>
d
T
*
HWY_RESTRICT
aligned
)
{
const
uint64_t
mask_bits
=
detail
:
:
BitsFromMask
(
mask
)
;
Store
(
detail
:
:
Compress
(
hwy
:
:
SizeTag
<
sizeof
(
T
)
>
(
)
v
mask_bits
)
d
aligned
)
;
return
PopCount
(
mask_bits
)
;
}
HWY_API
void
StoreInterleaved3
(
const
Vec128
<
uint8_t
>
v0
const
Vec128
<
uint8_t
>
v1
const
Vec128
<
uint8_t
>
v2
Full128
<
uint8_t
>
d
uint8_t
*
HWY_RESTRICT
unaligned
)
{
const
auto
k5
=
Set
(
d
5
)
;
const
auto
k6
=
Set
(
d
6
)
;
alignas
(
16
)
static
constexpr
uint8_t
tbl_r0
[
16
]
=
{
0
0x80
0x80
1
0x80
0x80
2
0x80
0x80
3
0x80
0x80
4
0x80
0x80
5
}
;
alignas
(
16
)
static
constexpr
uint8_t
tbl_g0
[
16
]
=
{
0x80
0
0x80
0x80
1
0x80
0x80
2
0x80
0x80
3
0x80
0x80
4
0x80
0x80
}
;
const
auto
shuf_r0
=
Load
(
d
tbl_r0
)
;
const
auto
shuf_g0
=
Load
(
d
tbl_g0
)
;
const
auto
shuf_b0
=
CombineShiftRightBytes
<
15
>
(
shuf_g0
shuf_g0
)
;
const
auto
r0
=
TableLookupBytes
(
v0
shuf_r0
)
;
const
auto
g0
=
TableLookupBytes
(
v1
shuf_g0
)
;
const
auto
b0
=
TableLookupBytes
(
v2
shuf_b0
)
;
const
auto
int0
=
r0
|
g0
|
b0
;
StoreU
(
int0
d
unaligned
+
0
*
16
)
;
const
auto
shuf_r1
=
shuf_b0
+
k6
;
const
auto
shuf_g1
=
shuf_r0
+
k5
;
const
auto
shuf_b1
=
shuf_g0
+
k5
;
const
auto
r1
=
TableLookupBytes
(
v0
shuf_r1
)
;
const
auto
g1
=
TableLookupBytes
(
v1
shuf_g1
)
;
const
auto
b1
=
TableLookupBytes
(
v2
shuf_b1
)
;
const
auto
int1
=
r1
|
g1
|
b1
;
StoreU
(
int1
d
unaligned
+
1
*
16
)
;
const
auto
shuf_r2
=
shuf_b1
+
k6
;
const
auto
shuf_g2
=
shuf_r1
+
k5
;
const
auto
shuf_b2
=
shuf_g1
+
k5
;
const
auto
r2
=
TableLookupBytes
(
v0
shuf_r2
)
;
const
auto
g2
=
TableLookupBytes
(
v1
shuf_g2
)
;
const
auto
b2
=
TableLookupBytes
(
v2
shuf_b2
)
;
const
auto
int2
=
r2
|
g2
|
b2
;
StoreU
(
int2
d
unaligned
+
2
*
16
)
;
}
HWY_API
void
StoreInterleaved3
(
const
Vec128
<
uint8_t
8
>
v0
const
Vec128
<
uint8_t
8
>
v1
const
Vec128
<
uint8_t
8
>
v2
Simd
<
uint8_t
8
>
d
uint8_t
*
HWY_RESTRICT
unaligned
)
{
const
Full128
<
uint8_t
>
d_full
;
const
auto
k5
=
Set
(
d_full
5
)
;
const
auto
k6
=
Set
(
d_full
6
)
;
const
Vec128
<
uint8_t
>
full_a
{
v0
.
raw
}
;
const
Vec128
<
uint8_t
>
full_b
{
v1
.
raw
}
;
const
Vec128
<
uint8_t
>
full_c
{
v2
.
raw
}
;
alignas
(
16
)
static
constexpr
uint8_t
tbl_r0
[
16
]
=
{
0
0x80
0x80
1
0x80
0x80
2
0x80
0x80
3
0x80
0x80
4
0x80
0x80
5
}
;
alignas
(
16
)
static
constexpr
uint8_t
tbl_g0
[
16
]
=
{
0x80
0
0x80
0x80
1
0x80
0x80
2
0x80
0x80
3
0x80
0x80
4
0x80
0x80
}
;
const
auto
shuf_r0
=
Load
(
d_full
tbl_r0
)
;
const
auto
shuf_g0
=
Load
(
d_full
tbl_g0
)
;
const
auto
shuf_b0
=
CombineShiftRightBytes
<
15
>
(
shuf_g0
shuf_g0
)
;
const
auto
r0
=
TableLookupBytes
(
full_a
shuf_r0
)
;
const
auto
g0
=
TableLookupBytes
(
full_b
shuf_g0
)
;
const
auto
b0
=
TableLookupBytes
(
full_c
shuf_b0
)
;
const
auto
int0
=
r0
|
g0
|
b0
;
StoreU
(
int0
d_full
unaligned
+
0
*
16
)
;
const
auto
shuf_r1
=
shuf_b0
+
k6
;
const
auto
shuf_g1
=
shuf_r0
+
k5
;
const
auto
shuf_b1
=
shuf_g0
+
k5
;
const
auto
r1
=
TableLookupBytes
(
full_a
shuf_r1
)
;
const
auto
g1
=
TableLookupBytes
(
full_b
shuf_g1
)
;
const
auto
b1
=
TableLookupBytes
(
full_c
shuf_b1
)
;
const
decltype
(
Zero
(
d
)
)
int1
{
(
r1
|
g1
|
b1
)
.
raw
}
;
StoreU
(
int1
d
unaligned
+
1
*
16
)
;
}
template
<
size_t
N
HWY_IF_LE32
(
uint8_t
N
)
>
HWY_API
void
StoreInterleaved3
(
const
Vec128
<
uint8_t
N
>
v0
const
Vec128
<
uint8_t
N
>
v1
const
Vec128
<
uint8_t
N
>
v2
Simd
<
uint8_t
N
>
uint8_t
*
HWY_RESTRICT
unaligned
)
{
const
Full128
<
uint8_t
>
d_full
;
const
Vec128
<
uint8_t
>
full_a
{
v0
.
raw
}
;
const
Vec128
<
uint8_t
>
full_b
{
v1
.
raw
}
;
const
Vec128
<
uint8_t
>
full_c
{
v2
.
raw
}
;
alignas
(
16
)
static
constexpr
uint8_t
tbl_r0
[
16
]
=
{
0
0x80
0x80
1
0x80
0x80
2
0x80
0x80
3
0x80
0x80
0x80
0x80
0x80
0x80
}
;
const
auto
shuf_r0
=
Load
(
d_full
tbl_r0
)
;
const
auto
shuf_g0
=
CombineShiftRightBytes
<
15
>
(
shuf_r0
shuf_r0
)
;
const
auto
shuf_b0
=
CombineShiftRightBytes
<
14
>
(
shuf_r0
shuf_r0
)
;
const
auto
r0
=
TableLookupBytes
(
full_a
shuf_r0
)
;
const
auto
g0
=
TableLookupBytes
(
full_b
shuf_g0
)
;
const
auto
b0
=
TableLookupBytes
(
full_c
shuf_b0
)
;
const
auto
int0
=
r0
|
g0
|
b0
;
alignas
(
16
)
uint8_t
buf
[
16
]
;
StoreU
(
int0
d_full
buf
)
;
CopyBytes
<
N
*
3
>
(
buf
unaligned
)
;
}
HWY_API
void
StoreInterleaved4
(
const
Vec128
<
uint8_t
>
v0
const
Vec128
<
uint8_t
>
v1
const
Vec128
<
uint8_t
>
v2
const
Vec128
<
uint8_t
>
v3
Full128
<
uint8_t
>
d
uint8_t
*
HWY_RESTRICT
unaligned
)
{
const
auto
ba0
=
ZipLower
(
v0
v1
)
;
const
auto
dc0
=
ZipLower
(
v2
v3
)
;
const
auto
ba8
=
ZipUpper
(
v0
v1
)
;
const
auto
dc8
=
ZipUpper
(
v2
v3
)
;
const
auto
dcba_0
=
ZipLower
(
ba0
dc0
)
;
const
auto
dcba_4
=
ZipUpper
(
ba0
dc0
)
;
const
auto
dcba_8
=
ZipLower
(
ba8
dc8
)
;
const
auto
dcba_C
=
ZipUpper
(
ba8
dc8
)
;
StoreU
(
BitCast
(
d
dcba_0
)
d
unaligned
+
0
*
16
)
;
StoreU
(
BitCast
(
d
dcba_4
)
d
unaligned
+
1
*
16
)
;
StoreU
(
BitCast
(
d
dcba_8
)
d
unaligned
+
2
*
16
)
;
StoreU
(
BitCast
(
d
dcba_C
)
d
unaligned
+
3
*
16
)
;
}
HWY_API
void
StoreInterleaved4
(
const
Vec128
<
uint8_t
8
>
in0
const
Vec128
<
uint8_t
8
>
in1
const
Vec128
<
uint8_t
8
>
in2
const
Vec128
<
uint8_t
8
>
in3
Simd
<
uint8_t
8
>
uint8_t
*
HWY_RESTRICT
unaligned
)
{
const
Vec128
<
uint8_t
>
v0
{
in0
.
raw
}
;
const
Vec128
<
uint8_t
>
v1
{
in1
.
raw
}
;
const
Vec128
<
uint8_t
>
v2
{
in2
.
raw
}
;
const
Vec128
<
uint8_t
>
v3
{
in3
.
raw
}
;
const
auto
ba0
=
ZipLower
(
v0
v1
)
;
const
auto
dc0
=
ZipLower
(
v2
v3
)
;
const
auto
dcba_0
=
ZipLower
(
ba0
dc0
)
;
const
auto
dcba_4
=
ZipUpper
(
ba0
dc0
)
;
const
Full128
<
uint8_t
>
d_full
;
StoreU
(
BitCast
(
d_full
dcba_0
)
d_full
unaligned
+
0
*
16
)
;
StoreU
(
BitCast
(
d_full
dcba_4
)
d_full
unaligned
+
1
*
16
)
;
}
template
<
size_t
N
HWY_IF_LE32
(
uint8_t
N
)
>
HWY_API
void
StoreInterleaved4
(
const
Vec128
<
uint8_t
N
>
in0
const
Vec128
<
uint8_t
N
>
in1
const
Vec128
<
uint8_t
N
>
in2
const
Vec128
<
uint8_t
N
>
in3
Simd
<
uint8_t
N
>
uint8_t
*
HWY_RESTRICT
unaligned
)
{
const
Vec128
<
uint8_t
>
v0
{
in0
.
raw
}
;
const
Vec128
<
uint8_t
>
v1
{
in1
.
raw
}
;
const
Vec128
<
uint8_t
>
v2
{
in2
.
raw
}
;
const
Vec128
<
uint8_t
>
v3
{
in3
.
raw
}
;
const
auto
ba0
=
ZipLower
(
v0
v1
)
;
const
auto
dc0
=
ZipLower
(
v2
v3
)
;
const
auto
dcba_0
=
ZipLower
(
ba0
dc0
)
;
alignas
(
16
)
uint8_t
buf
[
16
]
;
const
Full128
<
uint8_t
>
d_full
;
StoreU
(
BitCast
(
d_full
dcba_0
)
d_full
buf
)
;
CopyBytes
<
4
*
N
>
(
buf
unaligned
)
;
}
namespace
detail
{
template
<
typename
T
>
HWY_API
Vec128
<
T
1
>
SumOfLanes
(
hwy
:
:
SizeTag
<
sizeof
(
T
)
>
const
Vec128
<
T
1
>
v
)
{
return
v
;
}
template
<
typename
T
>
HWY_API
Vec128
<
T
1
>
MinOfLanes
(
hwy
:
:
SizeTag
<
sizeof
(
T
)
>
const
Vec128
<
T
1
>
v
)
{
return
v
;
}
template
<
typename
T
>
HWY_API
Vec128
<
T
1
>
MaxOfLanes
(
hwy
:
:
SizeTag
<
sizeof
(
T
)
>
const
Vec128
<
T
1
>
v
)
{
return
v
;
}
template
<
typename
T
>
HWY_API
Vec128
<
T
2
>
SumOfLanes
(
hwy
:
:
SizeTag
<
4
>
const
Vec128
<
T
2
>
v10
)
{
return
v10
+
Vec128
<
T
2
>
{
Shuffle2301
(
Vec128
<
T
>
{
v10
.
raw
}
)
.
raw
}
;
}
template
<
typename
T
>
HWY_API
Vec128
<
T
2
>
MinOfLanes
(
hwy
:
:
SizeTag
<
4
>
const
Vec128
<
T
2
>
v10
)
{
return
Min
(
v10
Vec128
<
T
2
>
{
Shuffle2301
(
Vec128
<
T
>
{
v10
.
raw
}
)
.
raw
}
)
;
}
template
<
typename
T
>
HWY_API
Vec128
<
T
2
>
MaxOfLanes
(
hwy
:
:
SizeTag
<
4
>
const
Vec128
<
T
2
>
v10
)
{
return
Max
(
v10
Vec128
<
T
2
>
{
Shuffle2301
(
Vec128
<
T
>
{
v10
.
raw
}
)
.
raw
}
)
;
}
template
<
typename
T
>
HWY_API
Vec128
<
T
>
SumOfLanes
(
hwy
:
:
SizeTag
<
4
>
const
Vec128
<
T
>
v3210
)
{
const
Vec128
<
T
>
v1032
=
Shuffle1032
(
v3210
)
;
const
Vec128
<
T
>
v31_20_31_20
=
v3210
+
v1032
;
const
Vec128
<
T
>
v20_31_20_31
=
Shuffle0321
(
v31_20_31_20
)
;
return
v20_31_20_31
+
v31_20_31_20
;
}
template
<
typename
T
>
HWY_API
Vec128
<
T
>
MinOfLanes
(
hwy
:
:
SizeTag
<
4
>
const
Vec128
<
T
>
v3210
)
{
const
Vec128
<
T
>
v1032
=
Shuffle1032
(
v3210
)
;
const
Vec128
<
T
>
v31_20_31_20
=
Min
(
v3210
v1032
)
;
const
Vec128
<
T
>
v20_31_20_31
=
Shuffle0321
(
v31_20_31_20
)
;
return
Min
(
v20_31_20_31
v31_20_31_20
)
;
}
template
<
typename
T
>
HWY_API
Vec128
<
T
>
MaxOfLanes
(
hwy
:
:
SizeTag
<
4
>
const
Vec128
<
T
>
v3210
)
{
const
Vec128
<
T
>
v1032
=
Shuffle1032
(
v3210
)
;
const
Vec128
<
T
>
v31_20_31_20
=
Max
(
v3210
v1032
)
;
const
Vec128
<
T
>
v20_31_20_31
=
Shuffle0321
(
v31_20_31_20
)
;
return
Max
(
v20_31_20_31
v31_20_31_20
)
;
}
template
<
typename
T
>
HWY_API
Vec128
<
T
>
SumOfLanes
(
hwy
:
:
SizeTag
<
8
>
const
Vec128
<
T
>
v10
)
{
const
Vec128
<
T
>
v01
=
Shuffle01
(
v10
)
;
return
v10
+
v01
;
}
template
<
typename
T
>
HWY_API
Vec128
<
T
>
MinOfLanes
(
hwy
:
:
SizeTag
<
8
>
const
Vec128
<
T
>
v10
)
{
const
Vec128
<
T
>
v01
=
Shuffle01
(
v10
)
;
return
Min
(
v10
v01
)
;
}
template
<
typename
T
>
HWY_API
Vec128
<
T
>
MaxOfLanes
(
hwy
:
:
SizeTag
<
8
>
const
Vec128
<
T
>
v10
)
{
const
Vec128
<
T
>
v01
=
Shuffle01
(
v10
)
;
return
Max
(
v10
v01
)
;
}
}
template
<
typename
T
size_t
N
>
HWY_API
Vec128
<
T
N
>
SumOfLanes
(
const
Vec128
<
T
N
>
v
)
{
return
detail
:
:
SumOfLanes
(
hwy
:
:
SizeTag
<
sizeof
(
T
)
>
(
)
v
)
;
}
template
<
typename
T
size_t
N
>
HWY_API
Vec128
<
T
N
>
MinOfLanes
(
const
Vec128
<
T
N
>
v
)
{
return
detail
:
:
MinOfLanes
(
hwy
:
:
SizeTag
<
sizeof
(
T
)
>
(
)
v
)
;
}
template
<
typename
T
size_t
N
>
HWY_API
Vec128
<
T
N
>
MaxOfLanes
(
const
Vec128
<
T
N
>
v
)
{
return
detail
:
:
MaxOfLanes
(
hwy
:
:
SizeTag
<
sizeof
(
T
)
>
(
)
v
)
;
}
template
<
class
V
>
HWY_API
V
Add
(
V
a
V
b
)
{
return
a
+
b
;
}
template
<
class
V
>
HWY_API
V
Sub
(
V
a
V
b
)
{
return
a
-
b
;
}
template
<
class
V
>
HWY_API
V
Mul
(
V
a
V
b
)
{
return
a
*
b
;
}
template
<
class
V
>
HWY_API
V
Div
(
V
a
V
b
)
{
return
a
/
b
;
}
template
<
class
V
>
V
Shl
(
V
a
V
b
)
{
return
a
<
<
b
;
}
template
<
class
V
>
V
Shr
(
V
a
V
b
)
{
return
a
>
>
b
;
}
template
<
class
V
>
HWY_API
auto
Eq
(
V
a
V
b
)
-
>
decltype
(
a
=
=
b
)
{
return
a
=
=
b
;
}
template
<
class
V
>
HWY_API
auto
Lt
(
V
a
V
b
)
-
>
decltype
(
a
=
=
b
)
{
return
a
<
b
;
}
template
<
class
V
>
HWY_API
auto
Gt
(
V
a
V
b
)
-
>
decltype
(
a
=
=
b
)
{
return
a
>
b
;
}
template
<
class
V
>
HWY_API
auto
Ge
(
V
a
V
b
)
-
>
decltype
(
a
=
=
b
)
{
return
a
>
=
b
;
}
template
<
class
V
>
HWY_API
auto
Le
(
V
a
V
b
)
-
>
decltype
(
a
=
=
b
)
{
return
a
<
=
b
;
}
}
}
HWY_AFTER_NAMESPACE
(
)
;
