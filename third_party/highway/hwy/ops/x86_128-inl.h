#
include
<
emmintrin
.
h
>
#
if
HWY_TARGET
=
=
HWY_SSSE3
#
include
<
tmmintrin
.
h
>
#
else
#
include
<
smmintrin
.
h
>
#
include
<
wmmintrin
.
h
>
#
endif
#
include
<
stddef
.
h
>
#
include
<
stdint
.
h
>
#
include
"
hwy
/
base
.
h
"
#
include
"
hwy
/
ops
/
shared
-
inl
.
h
"
#
ifndef
HWY_LOADDUP_ASM
#
define
HWY_LOADDUP_ASM
0
#
endif
HWY_BEFORE_NAMESPACE
(
)
;
namespace
hwy
{
namespace
HWY_NAMESPACE
{
template
<
typename
T
>
using
Full32
=
Simd
<
T
4
/
sizeof
(
T
)
0
>
;
template
<
typename
T
>
using
Full64
=
Simd
<
T
8
/
sizeof
(
T
)
0
>
;
template
<
typename
T
>
using
Full128
=
Simd
<
T
16
/
sizeof
(
T
)
0
>
;
#
if
HWY_TARGET
<
=
HWY_AVX2
template
<
typename
T
>
using
Full256
=
Simd
<
T
32
/
sizeof
(
T
)
0
>
;
#
endif
#
if
HWY_TARGET
<
=
HWY_AVX3
template
<
typename
T
>
using
Full512
=
Simd
<
T
64
/
sizeof
(
T
)
0
>
;
#
endif
namespace
detail
{
template
<
typename
T
>
struct
Raw128
{
using
type
=
__m128i
;
}
;
template
<
>
struct
Raw128
<
float
>
{
using
type
=
__m128
;
}
;
template
<
>
struct
Raw128
<
double
>
{
using
type
=
__m128d
;
}
;
}
template
<
typename
T
size_t
N
=
16
/
sizeof
(
T
)
>
class
Vec128
{
using
Raw
=
typename
detail
:
:
Raw128
<
T
>
:
:
type
;
public
:
HWY_INLINE
Vec128
&
operator
*
=
(
const
Vec128
other
)
{
return
*
this
=
(
*
this
*
other
)
;
}
HWY_INLINE
Vec128
&
operator
/
=
(
const
Vec128
other
)
{
return
*
this
=
(
*
this
/
other
)
;
}
HWY_INLINE
Vec128
&
operator
+
=
(
const
Vec128
other
)
{
return
*
this
=
(
*
this
+
other
)
;
}
HWY_INLINE
Vec128
&
operator
-
=
(
const
Vec128
other
)
{
return
*
this
=
(
*
this
-
other
)
;
}
HWY_INLINE
Vec128
&
operator
&
=
(
const
Vec128
other
)
{
return
*
this
=
(
*
this
&
other
)
;
}
HWY_INLINE
Vec128
&
operator
|
=
(
const
Vec128
other
)
{
return
*
this
=
(
*
this
|
other
)
;
}
HWY_INLINE
Vec128
&
operator
^
=
(
const
Vec128
other
)
{
return
*
this
=
(
*
this
^
other
)
;
}
Raw
raw
;
}
;
template
<
typename
T
>
using
Vec64
=
Vec128
<
T
8
/
sizeof
(
T
)
>
;
#
if
HWY_TARGET
<
=
HWY_AVX3
template
<
typename
T
>
class
Vec512
;
namespace
detail
{
template
<
size_t
size
>
struct
RawMask128
{
}
;
template
<
>
struct
RawMask128
<
1
>
{
using
type
=
__mmask16
;
}
;
template
<
>
struct
RawMask128
<
2
>
{
using
type
=
__mmask8
;
}
;
template
<
>
struct
RawMask128
<
4
>
{
using
type
=
__mmask8
;
}
;
template
<
>
struct
RawMask128
<
8
>
{
using
type
=
__mmask8
;
}
;
}
template
<
typename
T
size_t
N
>
struct
Mask128
{
using
Raw
=
typename
detail
:
:
RawMask128
<
sizeof
(
T
)
>
:
:
type
;
static
Mask128
<
T
N
>
FromBits
(
uint64_t
mask_bits
)
{
return
Mask128
<
T
N
>
{
static_cast
<
Raw
>
(
mask_bits
)
}
;
}
Raw
raw
;
}
;
#
else
template
<
typename
T
size_t
N
=
16
/
sizeof
(
T
)
>
struct
Mask128
{
typename
detail
:
:
Raw128
<
T
>
:
:
type
raw
;
}
;
#
endif
#
if
HWY_TARGET
<
=
HWY_AVX2
template
<
typename
T
>
class
Vec256
;
#
endif
namespace
detail
{
struct
DeduceD
{
template
<
typename
T
size_t
N
>
Simd
<
T
N
0
>
operator
(
)
(
const
Vec128
<
T
N
>
*
)
const
{
return
Simd
<
T
N
0
>
(
)
;
}
#
if
HWY_TARGET
<
=
HWY_AVX2
template
<
typename
T
>
Full256
<
T
>
operator
(
)
(
const
hwy
:
:
HWY_NAMESPACE
:
:
Vec256
<
T
>
*
)
const
{
return
Full256
<
T
>
(
)
;
}
#
endif
#
if
HWY_TARGET
<
=
HWY_AVX3
template
<
typename
T
>
Full512
<
T
>
operator
(
)
(
const
hwy
:
:
HWY_NAMESPACE
:
:
Vec512
<
T
>
*
)
const
{
return
Full512
<
T
>
(
)
;
}
#
endif
}
;
template
<
class
V
>
struct
ExpandDFromV
{
using
type
=
decltype
(
DeduceD
(
)
(
static_cast
<
V
*
>
(
nullptr
)
)
)
;
}
;
}
template
<
class
V
>
using
DFromV
=
typename
detail
:
:
ExpandDFromV
<
V
>
:
:
type
;
template
<
class
V
>
using
TFromV
=
TFromD
<
DFromV
<
V
>
>
;
namespace
detail
{
HWY_INLINE
__m128i
BitCastToInteger
(
__m128i
v
)
{
return
v
;
}
HWY_INLINE
__m128i
BitCastToInteger
(
__m128
v
)
{
return
_mm_castps_si128
(
v
)
;
}
HWY_INLINE
__m128i
BitCastToInteger
(
__m128d
v
)
{
return
_mm_castpd_si128
(
v
)
;
}
template
<
typename
T
size_t
N
>
HWY_INLINE
Vec128
<
uint8_t
N
*
sizeof
(
T
)
>
BitCastToByte
(
Vec128
<
T
N
>
v
)
{
return
Vec128
<
uint8_t
N
*
sizeof
(
T
)
>
{
BitCastToInteger
(
v
.
raw
)
}
;
}
template
<
typename
T
>
struct
BitCastFromInteger128
{
HWY_INLINE
__m128i
operator
(
)
(
__m128i
v
)
{
return
v
;
}
}
;
template
<
>
struct
BitCastFromInteger128
<
float
>
{
HWY_INLINE
__m128
operator
(
)
(
__m128i
v
)
{
return
_mm_castsi128_ps
(
v
)
;
}
}
;
template
<
>
struct
BitCastFromInteger128
<
double
>
{
HWY_INLINE
__m128d
operator
(
)
(
__m128i
v
)
{
return
_mm_castsi128_pd
(
v
)
;
}
}
;
template
<
typename
T
size_t
N
>
HWY_INLINE
Vec128
<
T
N
>
BitCastFromByte
(
Simd
<
T
N
0
>
Vec128
<
uint8_t
N
*
sizeof
(
T
)
>
v
)
{
return
Vec128
<
T
N
>
{
BitCastFromInteger128
<
T
>
(
)
(
v
.
raw
)
}
;
}
}
template
<
typename
T
size_t
N
typename
FromT
>
HWY_API
Vec128
<
T
N
>
BitCast
(
Simd
<
T
N
0
>
d
Vec128
<
FromT
N
*
sizeof
(
T
)
/
sizeof
(
FromT
)
>
v
)
{
return
detail
:
:
BitCastFromByte
(
d
detail
:
:
BitCastToByte
(
v
)
)
;
}
template
<
typename
T
size_t
N
HWY_IF_LE128
(
T
N
)
>
HWY_API
Vec128
<
T
N
>
Zero
(
Simd
<
T
N
0
>
)
{
return
Vec128
<
T
N
>
{
_mm_setzero_si128
(
)
}
;
}
template
<
size_t
N
HWY_IF_LE128
(
float
N
)
>
HWY_API
Vec128
<
float
N
>
Zero
(
Simd
<
float
N
0
>
)
{
return
Vec128
<
float
N
>
{
_mm_setzero_ps
(
)
}
;
}
template
<
size_t
N
HWY_IF_LE128
(
double
N
)
>
HWY_API
Vec128
<
double
N
>
Zero
(
Simd
<
double
N
0
>
)
{
return
Vec128
<
double
N
>
{
_mm_setzero_pd
(
)
}
;
}
template
<
class
D
>
using
VFromD
=
decltype
(
Zero
(
D
(
)
)
)
;
template
<
size_t
N
HWY_IF_LE128
(
uint8_t
N
)
>
HWY_API
Vec128
<
uint8_t
N
>
Set
(
Simd
<
uint8_t
N
0
>
const
uint8_t
t
)
{
return
Vec128
<
uint8_t
N
>
{
_mm_set1_epi8
(
static_cast
<
char
>
(
t
)
)
}
;
}
template
<
size_t
N
HWY_IF_LE128
(
uint16_t
N
)
>
HWY_API
Vec128
<
uint16_t
N
>
Set
(
Simd
<
uint16_t
N
0
>
const
uint16_t
t
)
{
return
Vec128
<
uint16_t
N
>
{
_mm_set1_epi16
(
static_cast
<
short
>
(
t
)
)
}
;
}
template
<
size_t
N
HWY_IF_LE128
(
uint32_t
N
)
>
HWY_API
Vec128
<
uint32_t
N
>
Set
(
Simd
<
uint32_t
N
0
>
const
uint32_t
t
)
{
return
Vec128
<
uint32_t
N
>
{
_mm_set1_epi32
(
static_cast
<
int
>
(
t
)
)
}
;
}
template
<
size_t
N
HWY_IF_LE128
(
uint64_t
N
)
>
HWY_API
Vec128
<
uint64_t
N
>
Set
(
Simd
<
uint64_t
N
0
>
const
uint64_t
t
)
{
return
Vec128
<
uint64_t
N
>
{
_mm_set1_epi64x
(
static_cast
<
long
long
>
(
t
)
)
}
;
}
template
<
size_t
N
HWY_IF_LE128
(
int8_t
N
)
>
HWY_API
Vec128
<
int8_t
N
>
Set
(
Simd
<
int8_t
N
0
>
const
int8_t
t
)
{
return
Vec128
<
int8_t
N
>
{
_mm_set1_epi8
(
static_cast
<
char
>
(
t
)
)
}
;
}
template
<
size_t
N
HWY_IF_LE128
(
int16_t
N
)
>
HWY_API
Vec128
<
int16_t
N
>
Set
(
Simd
<
int16_t
N
0
>
const
int16_t
t
)
{
return
Vec128
<
int16_t
N
>
{
_mm_set1_epi16
(
static_cast
<
short
>
(
t
)
)
}
;
}
template
<
size_t
N
HWY_IF_LE128
(
int32_t
N
)
>
HWY_API
Vec128
<
int32_t
N
>
Set
(
Simd
<
int32_t
N
0
>
const
int32_t
t
)
{
return
Vec128
<
int32_t
N
>
{
_mm_set1_epi32
(
t
)
}
;
}
template
<
size_t
N
HWY_IF_LE128
(
int64_t
N
)
>
HWY_API
Vec128
<
int64_t
N
>
Set
(
Simd
<
int64_t
N
0
>
const
int64_t
t
)
{
return
Vec128
<
int64_t
N
>
{
_mm_set1_epi64x
(
static_cast
<
long
long
>
(
t
)
)
}
;
}
template
<
size_t
N
HWY_IF_LE128
(
float
N
)
>
HWY_API
Vec128
<
float
N
>
Set
(
Simd
<
float
N
0
>
const
float
t
)
{
return
Vec128
<
float
N
>
{
_mm_set1_ps
(
t
)
}
;
}
template
<
size_t
N
HWY_IF_LE128
(
double
N
)
>
HWY_API
Vec128
<
double
N
>
Set
(
Simd
<
double
N
0
>
const
double
t
)
{
return
Vec128
<
double
N
>
{
_mm_set1_pd
(
t
)
}
;
}
HWY_DIAGNOSTICS
(
push
)
HWY_DIAGNOSTICS_OFF
(
disable
:
4700
ignored
"
-
Wuninitialized
"
)
template
<
typename
T
size_t
N
HWY_IF_LE128
(
T
N
)
>
HWY_API
Vec128
<
T
N
>
Undefined
(
Simd
<
T
N
0
>
)
{
return
Vec128
<
T
N
>
{
_mm_undefined_si128
(
)
}
;
}
template
<
size_t
N
HWY_IF_LE128
(
float
N
)
>
HWY_API
Vec128
<
float
N
>
Undefined
(
Simd
<
float
N
0
>
)
{
return
Vec128
<
float
N
>
{
_mm_undefined_ps
(
)
}
;
}
template
<
size_t
N
HWY_IF_LE128
(
double
N
)
>
HWY_API
Vec128
<
double
N
>
Undefined
(
Simd
<
double
N
0
>
)
{
return
Vec128
<
double
N
>
{
_mm_undefined_pd
(
)
}
;
}
HWY_DIAGNOSTICS
(
pop
)
template
<
size_t
N
>
HWY_API
uint8_t
GetLane
(
const
Vec128
<
uint8_t
N
>
v
)
{
return
static_cast
<
uint8_t
>
(
_mm_cvtsi128_si32
(
v
.
raw
)
&
0xFF
)
;
}
template
<
size_t
N
>
HWY_API
int8_t
GetLane
(
const
Vec128
<
int8_t
N
>
v
)
{
return
static_cast
<
int8_t
>
(
_mm_cvtsi128_si32
(
v
.
raw
)
&
0xFF
)
;
}
template
<
size_t
N
>
HWY_API
uint16_t
GetLane
(
const
Vec128
<
uint16_t
N
>
v
)
{
return
static_cast
<
uint16_t
>
(
_mm_cvtsi128_si32
(
v
.
raw
)
&
0xFFFF
)
;
}
template
<
size_t
N
>
HWY_API
int16_t
GetLane
(
const
Vec128
<
int16_t
N
>
v
)
{
return
static_cast
<
int16_t
>
(
_mm_cvtsi128_si32
(
v
.
raw
)
&
0xFFFF
)
;
}
template
<
size_t
N
>
HWY_API
uint32_t
GetLane
(
const
Vec128
<
uint32_t
N
>
v
)
{
return
static_cast
<
uint32_t
>
(
_mm_cvtsi128_si32
(
v
.
raw
)
)
;
}
template
<
size_t
N
>
HWY_API
int32_t
GetLane
(
const
Vec128
<
int32_t
N
>
v
)
{
return
_mm_cvtsi128_si32
(
v
.
raw
)
;
}
template
<
size_t
N
>
HWY_API
float
GetLane
(
const
Vec128
<
float
N
>
v
)
{
return
_mm_cvtss_f32
(
v
.
raw
)
;
}
template
<
size_t
N
>
HWY_API
uint64_t
GetLane
(
const
Vec128
<
uint64_t
N
>
v
)
{
#
if
HWY_ARCH_X86_32
alignas
(
16
)
uint64_t
lanes
[
2
]
;
Store
(
v
Simd
<
uint64_t
N
0
>
(
)
lanes
)
;
return
lanes
[
0
]
;
#
else
return
static_cast
<
uint64_t
>
(
_mm_cvtsi128_si64
(
v
.
raw
)
)
;
#
endif
}
template
<
size_t
N
>
HWY_API
int64_t
GetLane
(
const
Vec128
<
int64_t
N
>
v
)
{
#
if
HWY_ARCH_X86_32
alignas
(
16
)
int64_t
lanes
[
2
]
;
Store
(
v
Simd
<
int64_t
N
0
>
(
)
lanes
)
;
return
lanes
[
0
]
;
#
else
return
_mm_cvtsi128_si64
(
v
.
raw
)
;
#
endif
}
template
<
size_t
N
>
HWY_API
double
GetLane
(
const
Vec128
<
double
N
>
v
)
{
return
_mm_cvtsd_f64
(
v
.
raw
)
;
}
template
<
typename
T
size_t
N
>
HWY_API
Vec128
<
T
N
>
And
(
Vec128
<
T
N
>
a
Vec128
<
T
N
>
b
)
{
return
Vec128
<
T
N
>
{
_mm_and_si128
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
float
N
>
And
(
const
Vec128
<
float
N
>
a
const
Vec128
<
float
N
>
b
)
{
return
Vec128
<
float
N
>
{
_mm_and_ps
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
double
N
>
And
(
const
Vec128
<
double
N
>
a
const
Vec128
<
double
N
>
b
)
{
return
Vec128
<
double
N
>
{
_mm_and_pd
(
a
.
raw
b
.
raw
)
}
;
}
template
<
typename
T
size_t
N
>
HWY_API
Vec128
<
T
N
>
AndNot
(
Vec128
<
T
N
>
not_mask
Vec128
<
T
N
>
mask
)
{
return
Vec128
<
T
N
>
{
_mm_andnot_si128
(
not_mask
.
raw
mask
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
float
N
>
AndNot
(
const
Vec128
<
float
N
>
not_mask
const
Vec128
<
float
N
>
mask
)
{
return
Vec128
<
float
N
>
{
_mm_andnot_ps
(
not_mask
.
raw
mask
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
double
N
>
AndNot
(
const
Vec128
<
double
N
>
not_mask
const
Vec128
<
double
N
>
mask
)
{
return
Vec128
<
double
N
>
{
_mm_andnot_pd
(
not_mask
.
raw
mask
.
raw
)
}
;
}
template
<
typename
T
size_t
N
>
HWY_API
Vec128
<
T
N
>
Or
(
Vec128
<
T
N
>
a
Vec128
<
T
N
>
b
)
{
return
Vec128
<
T
N
>
{
_mm_or_si128
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
float
N
>
Or
(
const
Vec128
<
float
N
>
a
const
Vec128
<
float
N
>
b
)
{
return
Vec128
<
float
N
>
{
_mm_or_ps
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
double
N
>
Or
(
const
Vec128
<
double
N
>
a
const
Vec128
<
double
N
>
b
)
{
return
Vec128
<
double
N
>
{
_mm_or_pd
(
a
.
raw
b
.
raw
)
}
;
}
template
<
typename
T
size_t
N
>
HWY_API
Vec128
<
T
N
>
Xor
(
Vec128
<
T
N
>
a
Vec128
<
T
N
>
b
)
{
return
Vec128
<
T
N
>
{
_mm_xor_si128
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
float
N
>
Xor
(
const
Vec128
<
float
N
>
a
const
Vec128
<
float
N
>
b
)
{
return
Vec128
<
float
N
>
{
_mm_xor_ps
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
double
N
>
Xor
(
const
Vec128
<
double
N
>
a
const
Vec128
<
double
N
>
b
)
{
return
Vec128
<
double
N
>
{
_mm_xor_pd
(
a
.
raw
b
.
raw
)
}
;
}
template
<
typename
T
size_t
N
>
HWY_API
Vec128
<
T
N
>
Not
(
const
Vec128
<
T
N
>
v
)
{
const
DFromV
<
decltype
(
v
)
>
d
;
const
RebindToUnsigned
<
decltype
(
d
)
>
du
;
using
VU
=
VFromD
<
decltype
(
du
)
>
;
#
if
HWY_TARGET
<
=
HWY_AVX3
const
__m128i
vu
=
BitCast
(
du
v
)
.
raw
;
return
BitCast
(
d
VU
{
_mm_ternarylogic_epi32
(
vu
vu
vu
0x55
)
}
)
;
#
else
return
Xor
(
v
BitCast
(
d
VU
{
_mm_set1_epi32
(
-
1
)
}
)
)
;
#
endif
}
template
<
typename
T
size_t
N
>
HWY_API
Vec128
<
T
N
>
OrAnd
(
Vec128
<
T
N
>
o
Vec128
<
T
N
>
a1
Vec128
<
T
N
>
a2
)
{
#
if
HWY_TARGET
<
=
HWY_AVX3
const
DFromV
<
decltype
(
o
)
>
d
;
const
RebindToUnsigned
<
decltype
(
d
)
>
du
;
using
VU
=
VFromD
<
decltype
(
du
)
>
;
const
__m128i
ret
=
_mm_ternarylogic_epi64
(
BitCast
(
du
o
)
.
raw
BitCast
(
du
a1
)
.
raw
BitCast
(
du
a2
)
.
raw
0xF8
)
;
return
BitCast
(
d
VU
{
ret
}
)
;
#
else
return
Or
(
o
And
(
a1
a2
)
)
;
#
endif
}
template
<
typename
T
size_t
N
>
HWY_API
Vec128
<
T
N
>
IfVecThenElse
(
Vec128
<
T
N
>
mask
Vec128
<
T
N
>
yes
Vec128
<
T
N
>
no
)
{
#
if
HWY_TARGET
<
=
HWY_AVX3
const
DFromV
<
decltype
(
no
)
>
d
;
const
RebindToUnsigned
<
decltype
(
d
)
>
du
;
using
VU
=
VFromD
<
decltype
(
du
)
>
;
return
BitCast
(
d
VU
{
_mm_ternarylogic_epi64
(
BitCast
(
du
mask
)
.
raw
BitCast
(
du
yes
)
.
raw
BitCast
(
du
no
)
.
raw
0xCA
)
}
)
;
#
else
return
IfThenElse
(
MaskFromVec
(
mask
)
yes
no
)
;
#
endif
}
template
<
typename
T
size_t
N
>
HWY_API
Vec128
<
T
N
>
operator
&
(
const
Vec128
<
T
N
>
a
const
Vec128
<
T
N
>
b
)
{
return
And
(
a
b
)
;
}
template
<
typename
T
size_t
N
>
HWY_API
Vec128
<
T
N
>
operator
|
(
const
Vec128
<
T
N
>
a
const
Vec128
<
T
N
>
b
)
{
return
Or
(
a
b
)
;
}
template
<
typename
T
size_t
N
>
HWY_API
Vec128
<
T
N
>
operator
^
(
const
Vec128
<
T
N
>
a
const
Vec128
<
T
N
>
b
)
{
return
Xor
(
a
b
)
;
}
#
if
HWY_TARGET
=
=
HWY_AVX3_DL
#
ifdef
HWY_NATIVE_POPCNT
#
undef
HWY_NATIVE_POPCNT
#
else
#
define
HWY_NATIVE_POPCNT
#
endif
namespace
detail
{
template
<
typename
T
size_t
N
>
HWY_INLINE
Vec128
<
T
N
>
PopulationCount
(
hwy
:
:
SizeTag
<
1
>
Vec128
<
T
N
>
v
)
{
return
Vec128
<
T
N
>
{
_mm_popcnt_epi8
(
v
.
raw
)
}
;
}
template
<
typename
T
size_t
N
>
HWY_INLINE
Vec128
<
T
N
>
PopulationCount
(
hwy
:
:
SizeTag
<
2
>
Vec128
<
T
N
>
v
)
{
return
Vec128
<
T
N
>
{
_mm_popcnt_epi16
(
v
.
raw
)
}
;
}
template
<
typename
T
size_t
N
>
HWY_INLINE
Vec128
<
T
N
>
PopulationCount
(
hwy
:
:
SizeTag
<
4
>
Vec128
<
T
N
>
v
)
{
return
Vec128
<
T
N
>
{
_mm_popcnt_epi32
(
v
.
raw
)
}
;
}
template
<
typename
T
size_t
N
>
HWY_INLINE
Vec128
<
T
N
>
PopulationCount
(
hwy
:
:
SizeTag
<
8
>
Vec128
<
T
N
>
v
)
{
return
Vec128
<
T
N
>
{
_mm_popcnt_epi64
(
v
.
raw
)
}
;
}
}
template
<
typename
T
size_t
N
>
HWY_API
Vec128
<
T
N
>
PopulationCount
(
Vec128
<
T
N
>
v
)
{
return
detail
:
:
PopulationCount
(
hwy
:
:
SizeTag
<
sizeof
(
T
)
>
(
)
v
)
;
}
#
endif
template
<
typename
T
size_t
N
HWY_IF_FLOAT
(
T
)
>
HWY_API
Vec128
<
T
N
>
Neg
(
const
Vec128
<
T
N
>
v
)
{
return
Xor
(
v
SignBit
(
DFromV
<
decltype
(
v
)
>
(
)
)
)
;
}
template
<
typename
T
size_t
N
HWY_IF_NOT_FLOAT
(
T
)
>
HWY_API
Vec128
<
T
N
>
Neg
(
const
Vec128
<
T
N
>
v
)
{
return
Zero
(
DFromV
<
decltype
(
v
)
>
(
)
)
-
v
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
int8_t
N
>
Abs
(
const
Vec128
<
int8_t
N
>
v
)
{
#
if
HWY_COMPILER_MSVC
const
auto
zero
=
Zero
(
DFromV
<
decltype
(
v
)
>
(
)
)
;
return
Vec128
<
int8_t
N
>
{
_mm_max_epi8
(
v
.
raw
(
zero
-
v
)
.
raw
)
}
;
#
else
return
Vec128
<
int8_t
N
>
{
_mm_abs_epi8
(
v
.
raw
)
}
;
#
endif
}
template
<
size_t
N
>
HWY_API
Vec128
<
int16_t
N
>
Abs
(
const
Vec128
<
int16_t
N
>
v
)
{
return
Vec128
<
int16_t
N
>
{
_mm_abs_epi16
(
v
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
int32_t
N
>
Abs
(
const
Vec128
<
int32_t
N
>
v
)
{
return
Vec128
<
int32_t
N
>
{
_mm_abs_epi32
(
v
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
float
N
>
Abs
(
const
Vec128
<
float
N
>
v
)
{
const
Vec128
<
int32_t
N
>
mask
{
_mm_set1_epi32
(
0x7FFFFFFF
)
}
;
return
v
&
BitCast
(
DFromV
<
decltype
(
v
)
>
(
)
mask
)
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
double
N
>
Abs
(
const
Vec128
<
double
N
>
v
)
{
const
Vec128
<
int64_t
N
>
mask
{
_mm_set1_epi64x
(
0x7FFFFFFFFFFFFFFFLL
)
}
;
return
v
&
BitCast
(
DFromV
<
decltype
(
v
)
>
(
)
mask
)
;
}
template
<
typename
T
size_t
N
>
HWY_API
Vec128
<
T
N
>
CopySign
(
const
Vec128
<
T
N
>
magn
const
Vec128
<
T
N
>
sign
)
{
static_assert
(
IsFloat
<
T
>
(
)
"
Only
makes
sense
for
floating
-
point
"
)
;
const
DFromV
<
decltype
(
magn
)
>
d
;
const
auto
msb
=
SignBit
(
d
)
;
#
if
HWY_TARGET
<
=
HWY_AVX3
const
RebindToUnsigned
<
decltype
(
d
)
>
du
;
const
__m128i
out
=
_mm_ternarylogic_epi32
(
BitCast
(
du
msb
)
.
raw
BitCast
(
du
magn
)
.
raw
BitCast
(
du
sign
)
.
raw
0xAC
)
;
return
BitCast
(
d
VFromD
<
decltype
(
du
)
>
{
out
}
)
;
#
else
return
Or
(
AndNot
(
msb
magn
)
And
(
msb
sign
)
)
;
#
endif
}
template
<
typename
T
size_t
N
>
HWY_API
Vec128
<
T
N
>
CopySignToAbs
(
const
Vec128
<
T
N
>
abs
const
Vec128
<
T
N
>
sign
)
{
#
if
HWY_TARGET
<
=
HWY_AVX3
return
CopySign
(
abs
sign
)
;
#
else
return
Or
(
abs
And
(
SignBit
(
DFromV
<
decltype
(
abs
)
>
(
)
)
sign
)
)
;
#
endif
}
#
if
HWY_TARGET
<
=
HWY_AVX3
namespace
detail
{
template
<
typename
T
size_t
N
>
HWY_INLINE
Vec128
<
T
N
>
IfThenElse
(
hwy
:
:
SizeTag
<
1
>
Mask128
<
T
N
>
mask
Vec128
<
T
N
>
yes
Vec128
<
T
N
>
no
)
{
return
Vec128
<
T
N
>
{
_mm_mask_mov_epi8
(
no
.
raw
mask
.
raw
yes
.
raw
)
}
;
}
template
<
typename
T
size_t
N
>
HWY_INLINE
Vec128
<
T
N
>
IfThenElse
(
hwy
:
:
SizeTag
<
2
>
Mask128
<
T
N
>
mask
Vec128
<
T
N
>
yes
Vec128
<
T
N
>
no
)
{
return
Vec128
<
T
N
>
{
_mm_mask_mov_epi16
(
no
.
raw
mask
.
raw
yes
.
raw
)
}
;
}
template
<
typename
T
size_t
N
>
HWY_INLINE
Vec128
<
T
N
>
IfThenElse
(
hwy
:
:
SizeTag
<
4
>
Mask128
<
T
N
>
mask
Vec128
<
T
N
>
yes
Vec128
<
T
N
>
no
)
{
return
Vec128
<
T
N
>
{
_mm_mask_mov_epi32
(
no
.
raw
mask
.
raw
yes
.
raw
)
}
;
}
template
<
typename
T
size_t
N
>
HWY_INLINE
Vec128
<
T
N
>
IfThenElse
(
hwy
:
:
SizeTag
<
8
>
Mask128
<
T
N
>
mask
Vec128
<
T
N
>
yes
Vec128
<
T
N
>
no
)
{
return
Vec128
<
T
N
>
{
_mm_mask_mov_epi64
(
no
.
raw
mask
.
raw
yes
.
raw
)
}
;
}
}
template
<
typename
T
size_t
N
>
HWY_API
Vec128
<
T
N
>
IfThenElse
(
Mask128
<
T
N
>
mask
Vec128
<
T
N
>
yes
Vec128
<
T
N
>
no
)
{
return
detail
:
:
IfThenElse
(
hwy
:
:
SizeTag
<
sizeof
(
T
)
>
(
)
mask
yes
no
)
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
float
N
>
IfThenElse
(
Mask128
<
float
N
>
mask
Vec128
<
float
N
>
yes
Vec128
<
float
N
>
no
)
{
return
Vec128
<
float
N
>
{
_mm_mask_mov_ps
(
no
.
raw
mask
.
raw
yes
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
double
N
>
IfThenElse
(
Mask128
<
double
N
>
mask
Vec128
<
double
N
>
yes
Vec128
<
double
N
>
no
)
{
return
Vec128
<
double
N
>
{
_mm_mask_mov_pd
(
no
.
raw
mask
.
raw
yes
.
raw
)
}
;
}
namespace
detail
{
template
<
typename
T
size_t
N
>
HWY_INLINE
Vec128
<
T
N
>
IfThenElseZero
(
hwy
:
:
SizeTag
<
1
>
Mask128
<
T
N
>
mask
Vec128
<
T
N
>
yes
)
{
return
Vec128
<
T
N
>
{
_mm_maskz_mov_epi8
(
mask
.
raw
yes
.
raw
)
}
;
}
template
<
typename
T
size_t
N
>
HWY_INLINE
Vec128
<
T
N
>
IfThenElseZero
(
hwy
:
:
SizeTag
<
2
>
Mask128
<
T
N
>
mask
Vec128
<
T
N
>
yes
)
{
return
Vec128
<
T
N
>
{
_mm_maskz_mov_epi16
(
mask
.
raw
yes
.
raw
)
}
;
}
template
<
typename
T
size_t
N
>
HWY_INLINE
Vec128
<
T
N
>
IfThenElseZero
(
hwy
:
:
SizeTag
<
4
>
Mask128
<
T
N
>
mask
Vec128
<
T
N
>
yes
)
{
return
Vec128
<
T
N
>
{
_mm_maskz_mov_epi32
(
mask
.
raw
yes
.
raw
)
}
;
}
template
<
typename
T
size_t
N
>
HWY_INLINE
Vec128
<
T
N
>
IfThenElseZero
(
hwy
:
:
SizeTag
<
8
>
Mask128
<
T
N
>
mask
Vec128
<
T
N
>
yes
)
{
return
Vec128
<
T
N
>
{
_mm_maskz_mov_epi64
(
mask
.
raw
yes
.
raw
)
}
;
}
}
template
<
typename
T
size_t
N
>
HWY_API
Vec128
<
T
N
>
IfThenElseZero
(
Mask128
<
T
N
>
mask
Vec128
<
T
N
>
yes
)
{
return
detail
:
:
IfThenElseZero
(
hwy
:
:
SizeTag
<
sizeof
(
T
)
>
(
)
mask
yes
)
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
float
N
>
IfThenElseZero
(
Mask128
<
float
N
>
mask
Vec128
<
float
N
>
yes
)
{
return
Vec128
<
float
N
>
{
_mm_maskz_mov_ps
(
mask
.
raw
yes
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
double
N
>
IfThenElseZero
(
Mask128
<
double
N
>
mask
Vec128
<
double
N
>
yes
)
{
return
Vec128
<
double
N
>
{
_mm_maskz_mov_pd
(
mask
.
raw
yes
.
raw
)
}
;
}
namespace
detail
{
template
<
typename
T
size_t
N
>
HWY_INLINE
Vec128
<
T
N
>
IfThenZeroElse
(
hwy
:
:
SizeTag
<
1
>
Mask128
<
T
N
>
mask
Vec128
<
T
N
>
no
)
{
return
Vec128
<
T
N
>
{
_mm_mask_sub_epi8
(
no
.
raw
mask
.
raw
no
.
raw
no
.
raw
)
}
;
}
template
<
typename
T
size_t
N
>
HWY_INLINE
Vec128
<
T
N
>
IfThenZeroElse
(
hwy
:
:
SizeTag
<
2
>
Mask128
<
T
N
>
mask
Vec128
<
T
N
>
no
)
{
return
Vec128
<
T
N
>
{
_mm_mask_sub_epi16
(
no
.
raw
mask
.
raw
no
.
raw
no
.
raw
)
}
;
}
template
<
typename
T
size_t
N
>
HWY_INLINE
Vec128
<
T
N
>
IfThenZeroElse
(
hwy
:
:
SizeTag
<
4
>
Mask128
<
T
N
>
mask
Vec128
<
T
N
>
no
)
{
return
Vec128
<
T
N
>
{
_mm_mask_xor_epi32
(
no
.
raw
mask
.
raw
no
.
raw
no
.
raw
)
}
;
}
template
<
typename
T
size_t
N
>
HWY_INLINE
Vec128
<
T
N
>
IfThenZeroElse
(
hwy
:
:
SizeTag
<
8
>
Mask128
<
T
N
>
mask
Vec128
<
T
N
>
no
)
{
return
Vec128
<
T
N
>
{
_mm_mask_xor_epi64
(
no
.
raw
mask
.
raw
no
.
raw
no
.
raw
)
}
;
}
}
template
<
typename
T
size_t
N
>
HWY_API
Vec128
<
T
N
>
IfThenZeroElse
(
Mask128
<
T
N
>
mask
Vec128
<
T
N
>
no
)
{
return
detail
:
:
IfThenZeroElse
(
hwy
:
:
SizeTag
<
sizeof
(
T
)
>
(
)
mask
no
)
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
float
N
>
IfThenZeroElse
(
Mask128
<
float
N
>
mask
Vec128
<
float
N
>
no
)
{
return
Vec128
<
float
N
>
{
_mm_mask_xor_ps
(
no
.
raw
mask
.
raw
no
.
raw
no
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
double
N
>
IfThenZeroElse
(
Mask128
<
double
N
>
mask
Vec128
<
double
N
>
no
)
{
return
Vec128
<
double
N
>
{
_mm_mask_xor_pd
(
no
.
raw
mask
.
raw
no
.
raw
no
.
raw
)
}
;
}
#
if
!
defined
(
HWY_COMPILER_HAS_MASK_INTRINSICS
)
&
&
\
(
HWY_COMPILER_MSVC
!
=
0
|
|
HWY_COMPILER_GCC
>
=
700
|
|
\
HWY_COMPILER_CLANG
>
=
800
)
#
define
HWY_COMPILER_HAS_MASK_INTRINSICS
1
#
else
#
define
HWY_COMPILER_HAS_MASK_INTRINSICS
0
#
endif
namespace
detail
{
template
<
typename
T
size_t
N
>
HWY_INLINE
Mask128
<
T
N
>
And
(
hwy
:
:
SizeTag
<
1
>
const
Mask128
<
T
N
>
a
const
Mask128
<
T
N
>
b
)
{
#
if
HWY_COMPILER_HAS_MASK_INTRINSICS
return
Mask128
<
T
N
>
{
_kand_mask16
(
a
.
raw
b
.
raw
)
}
;
#
else
return
Mask128
<
T
N
>
{
static_cast
<
__mmask16
>
(
a
.
raw
&
b
.
raw
)
}
;
#
endif
}
template
<
typename
T
size_t
N
>
HWY_INLINE
Mask128
<
T
N
>
And
(
hwy
:
:
SizeTag
<
2
>
const
Mask128
<
T
N
>
a
const
Mask128
<
T
N
>
b
)
{
#
if
HWY_COMPILER_HAS_MASK_INTRINSICS
return
Mask128
<
T
N
>
{
_kand_mask8
(
a
.
raw
b
.
raw
)
}
;
#
else
return
Mask128
<
T
N
>
{
static_cast
<
__mmask8
>
(
a
.
raw
&
b
.
raw
)
}
;
#
endif
}
template
<
typename
T
size_t
N
>
HWY_INLINE
Mask128
<
T
N
>
And
(
hwy
:
:
SizeTag
<
4
>
const
Mask128
<
T
N
>
a
const
Mask128
<
T
N
>
b
)
{
#
if
HWY_COMPILER_HAS_MASK_INTRINSICS
return
Mask128
<
T
N
>
{
_kand_mask8
(
a
.
raw
b
.
raw
)
}
;
#
else
return
Mask128
<
T
N
>
{
static_cast
<
__mmask8
>
(
a
.
raw
&
b
.
raw
)
}
;
#
endif
}
template
<
typename
T
size_t
N
>
HWY_INLINE
Mask128
<
T
N
>
And
(
hwy
:
:
SizeTag
<
8
>
const
Mask128
<
T
N
>
a
const
Mask128
<
T
N
>
b
)
{
#
if
HWY_COMPILER_HAS_MASK_INTRINSICS
return
Mask128
<
T
N
>
{
_kand_mask8
(
a
.
raw
b
.
raw
)
}
;
#
else
return
Mask128
<
T
N
>
{
static_cast
<
__mmask8
>
(
a
.
raw
&
b
.
raw
)
}
;
#
endif
}
template
<
typename
T
size_t
N
>
HWY_INLINE
Mask128
<
T
N
>
AndNot
(
hwy
:
:
SizeTag
<
1
>
const
Mask128
<
T
N
>
a
const
Mask128
<
T
N
>
b
)
{
#
if
HWY_COMPILER_HAS_MASK_INTRINSICS
return
Mask128
<
T
N
>
{
_kandn_mask16
(
a
.
raw
b
.
raw
)
}
;
#
else
return
Mask128
<
T
N
>
{
static_cast
<
__mmask16
>
(
~
a
.
raw
&
b
.
raw
)
}
;
#
endif
}
template
<
typename
T
size_t
N
>
HWY_INLINE
Mask128
<
T
N
>
AndNot
(
hwy
:
:
SizeTag
<
2
>
const
Mask128
<
T
N
>
a
const
Mask128
<
T
N
>
b
)
{
#
if
HWY_COMPILER_HAS_MASK_INTRINSICS
return
Mask128
<
T
N
>
{
_kandn_mask8
(
a
.
raw
b
.
raw
)
}
;
#
else
return
Mask128
<
T
N
>
{
static_cast
<
__mmask8
>
(
~
a
.
raw
&
b
.
raw
)
}
;
#
endif
}
template
<
typename
T
size_t
N
>
HWY_INLINE
Mask128
<
T
N
>
AndNot
(
hwy
:
:
SizeTag
<
4
>
const
Mask128
<
T
N
>
a
const
Mask128
<
T
N
>
b
)
{
#
if
HWY_COMPILER_HAS_MASK_INTRINSICS
return
Mask128
<
T
N
>
{
_kandn_mask8
(
a
.
raw
b
.
raw
)
}
;
#
else
return
Mask128
<
T
N
>
{
static_cast
<
__mmask8
>
(
~
a
.
raw
&
b
.
raw
)
}
;
#
endif
}
template
<
typename
T
size_t
N
>
HWY_INLINE
Mask128
<
T
N
>
AndNot
(
hwy
:
:
SizeTag
<
8
>
const
Mask128
<
T
N
>
a
const
Mask128
<
T
N
>
b
)
{
#
if
HWY_COMPILER_HAS_MASK_INTRINSICS
return
Mask128
<
T
N
>
{
_kandn_mask8
(
a
.
raw
b
.
raw
)
}
;
#
else
return
Mask128
<
T
N
>
{
static_cast
<
__mmask8
>
(
~
a
.
raw
&
b
.
raw
)
}
;
#
endif
}
template
<
typename
T
size_t
N
>
HWY_INLINE
Mask128
<
T
N
>
Or
(
hwy
:
:
SizeTag
<
1
>
const
Mask128
<
T
N
>
a
const
Mask128
<
T
N
>
b
)
{
#
if
HWY_COMPILER_HAS_MASK_INTRINSICS
return
Mask128
<
T
N
>
{
_kor_mask16
(
a
.
raw
b
.
raw
)
}
;
#
else
return
Mask128
<
T
N
>
{
static_cast
<
__mmask16
>
(
a
.
raw
|
b
.
raw
)
}
;
#
endif
}
template
<
typename
T
size_t
N
>
HWY_INLINE
Mask128
<
T
N
>
Or
(
hwy
:
:
SizeTag
<
2
>
const
Mask128
<
T
N
>
a
const
Mask128
<
T
N
>
b
)
{
#
if
HWY_COMPILER_HAS_MASK_INTRINSICS
return
Mask128
<
T
N
>
{
_kor_mask8
(
a
.
raw
b
.
raw
)
}
;
#
else
return
Mask128
<
T
N
>
{
static_cast
<
__mmask8
>
(
a
.
raw
|
b
.
raw
)
}
;
#
endif
}
template
<
typename
T
size_t
N
>
HWY_INLINE
Mask128
<
T
N
>
Or
(
hwy
:
:
SizeTag
<
4
>
const
Mask128
<
T
N
>
a
const
Mask128
<
T
N
>
b
)
{
#
if
HWY_COMPILER_HAS_MASK_INTRINSICS
return
Mask128
<
T
N
>
{
_kor_mask8
(
a
.
raw
b
.
raw
)
}
;
#
else
return
Mask128
<
T
N
>
{
static_cast
<
__mmask8
>
(
a
.
raw
|
b
.
raw
)
}
;
#
endif
}
template
<
typename
T
size_t
N
>
HWY_INLINE
Mask128
<
T
N
>
Or
(
hwy
:
:
SizeTag
<
8
>
const
Mask128
<
T
N
>
a
const
Mask128
<
T
N
>
b
)
{
#
if
HWY_COMPILER_HAS_MASK_INTRINSICS
return
Mask128
<
T
N
>
{
_kor_mask8
(
a
.
raw
b
.
raw
)
}
;
#
else
return
Mask128
<
T
N
>
{
static_cast
<
__mmask8
>
(
a
.
raw
|
b
.
raw
)
}
;
#
endif
}
template
<
typename
T
size_t
N
>
HWY_INLINE
Mask128
<
T
N
>
Xor
(
hwy
:
:
SizeTag
<
1
>
const
Mask128
<
T
N
>
a
const
Mask128
<
T
N
>
b
)
{
#
if
HWY_COMPILER_HAS_MASK_INTRINSICS
return
Mask128
<
T
N
>
{
_kxor_mask16
(
a
.
raw
b
.
raw
)
}
;
#
else
return
Mask128
<
T
N
>
{
static_cast
<
__mmask16
>
(
a
.
raw
^
b
.
raw
)
}
;
#
endif
}
template
<
typename
T
size_t
N
>
HWY_INLINE
Mask128
<
T
N
>
Xor
(
hwy
:
:
SizeTag
<
2
>
const
Mask128
<
T
N
>
a
const
Mask128
<
T
N
>
b
)
{
#
if
HWY_COMPILER_HAS_MASK_INTRINSICS
return
Mask128
<
T
N
>
{
_kxor_mask8
(
a
.
raw
b
.
raw
)
}
;
#
else
return
Mask128
<
T
N
>
{
static_cast
<
__mmask8
>
(
a
.
raw
^
b
.
raw
)
}
;
#
endif
}
template
<
typename
T
size_t
N
>
HWY_INLINE
Mask128
<
T
N
>
Xor
(
hwy
:
:
SizeTag
<
4
>
const
Mask128
<
T
N
>
a
const
Mask128
<
T
N
>
b
)
{
#
if
HWY_COMPILER_HAS_MASK_INTRINSICS
return
Mask128
<
T
N
>
{
_kxor_mask8
(
a
.
raw
b
.
raw
)
}
;
#
else
return
Mask128
<
T
N
>
{
static_cast
<
__mmask8
>
(
a
.
raw
^
b
.
raw
)
}
;
#
endif
}
template
<
typename
T
size_t
N
>
HWY_INLINE
Mask128
<
T
N
>
Xor
(
hwy
:
:
SizeTag
<
8
>
const
Mask128
<
T
N
>
a
const
Mask128
<
T
N
>
b
)
{
#
if
HWY_COMPILER_HAS_MASK_INTRINSICS
return
Mask128
<
T
N
>
{
_kxor_mask8
(
a
.
raw
b
.
raw
)
}
;
#
else
return
Mask128
<
T
N
>
{
static_cast
<
__mmask8
>
(
a
.
raw
^
b
.
raw
)
}
;
#
endif
}
}
template
<
typename
T
size_t
N
>
HWY_API
Mask128
<
T
N
>
And
(
const
Mask128
<
T
N
>
a
Mask128
<
T
N
>
b
)
{
return
detail
:
:
And
(
hwy
:
:
SizeTag
<
sizeof
(
T
)
>
(
)
a
b
)
;
}
template
<
typename
T
size_t
N
>
HWY_API
Mask128
<
T
N
>
AndNot
(
const
Mask128
<
T
N
>
a
Mask128
<
T
N
>
b
)
{
return
detail
:
:
AndNot
(
hwy
:
:
SizeTag
<
sizeof
(
T
)
>
(
)
a
b
)
;
}
template
<
typename
T
size_t
N
>
HWY_API
Mask128
<
T
N
>
Or
(
const
Mask128
<
T
N
>
a
Mask128
<
T
N
>
b
)
{
return
detail
:
:
Or
(
hwy
:
:
SizeTag
<
sizeof
(
T
)
>
(
)
a
b
)
;
}
template
<
typename
T
size_t
N
>
HWY_API
Mask128
<
T
N
>
Xor
(
const
Mask128
<
T
N
>
a
Mask128
<
T
N
>
b
)
{
return
detail
:
:
Xor
(
hwy
:
:
SizeTag
<
sizeof
(
T
)
>
(
)
a
b
)
;
}
template
<
typename
T
size_t
N
>
HWY_API
Mask128
<
T
N
>
Not
(
const
Mask128
<
T
N
>
m
)
{
return
Xor
(
m
Mask128
<
T
N
>
:
:
FromBits
(
(
1ull
<
<
N
)
-
1
)
)
;
}
#
else
template
<
typename
T
size_t
N
>
HWY_API
Mask128
<
T
N
>
MaskFromVec
(
const
Vec128
<
T
N
>
v
)
{
return
Mask128
<
T
N
>
{
v
.
raw
}
;
}
template
<
typename
T
size_t
N
>
HWY_API
Vec128
<
T
N
>
VecFromMask
(
const
Mask128
<
T
N
>
v
)
{
return
Vec128
<
T
N
>
{
v
.
raw
}
;
}
template
<
typename
T
size_t
N
>
HWY_API
Vec128
<
T
N
>
VecFromMask
(
const
Simd
<
T
N
0
>
const
Mask128
<
T
N
>
v
)
{
return
Vec128
<
T
N
>
{
v
.
raw
}
;
}
#
if
HWY_TARGET
=
=
HWY_SSSE3
template
<
typename
T
size_t
N
>
HWY_API
Vec128
<
T
N
>
IfThenElse
(
Mask128
<
T
N
>
mask
Vec128
<
T
N
>
yes
Vec128
<
T
N
>
no
)
{
const
auto
vmask
=
VecFromMask
(
DFromV
<
decltype
(
no
)
>
(
)
mask
)
;
return
Or
(
And
(
vmask
yes
)
AndNot
(
vmask
no
)
)
;
}
#
else
template
<
typename
T
size_t
N
>
HWY_API
Vec128
<
T
N
>
IfThenElse
(
Mask128
<
T
N
>
mask
Vec128
<
T
N
>
yes
Vec128
<
T
N
>
no
)
{
return
Vec128
<
T
N
>
{
_mm_blendv_epi8
(
no
.
raw
yes
.
raw
mask
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
float
N
>
IfThenElse
(
const
Mask128
<
float
N
>
mask
const
Vec128
<
float
N
>
yes
const
Vec128
<
float
N
>
no
)
{
return
Vec128
<
float
N
>
{
_mm_blendv_ps
(
no
.
raw
yes
.
raw
mask
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
double
N
>
IfThenElse
(
const
Mask128
<
double
N
>
mask
const
Vec128
<
double
N
>
yes
const
Vec128
<
double
N
>
no
)
{
return
Vec128
<
double
N
>
{
_mm_blendv_pd
(
no
.
raw
yes
.
raw
mask
.
raw
)
}
;
}
#
endif
template
<
typename
T
size_t
N
>
HWY_API
Vec128
<
T
N
>
IfThenElseZero
(
Mask128
<
T
N
>
mask
Vec128
<
T
N
>
yes
)
{
return
yes
&
VecFromMask
(
DFromV
<
decltype
(
yes
)
>
(
)
mask
)
;
}
template
<
typename
T
size_t
N
>
HWY_API
Vec128
<
T
N
>
IfThenZeroElse
(
Mask128
<
T
N
>
mask
Vec128
<
T
N
>
no
)
{
return
AndNot
(
VecFromMask
(
DFromV
<
decltype
(
no
)
>
(
)
mask
)
no
)
;
}
template
<
typename
T
size_t
N
>
HWY_API
Mask128
<
T
N
>
Not
(
const
Mask128
<
T
N
>
m
)
{
return
MaskFromVec
(
Not
(
VecFromMask
(
Simd
<
T
N
0
>
(
)
m
)
)
)
;
}
template
<
typename
T
size_t
N
>
HWY_API
Mask128
<
T
N
>
And
(
const
Mask128
<
T
N
>
a
Mask128
<
T
N
>
b
)
{
const
Simd
<
T
N
0
>
d
;
return
MaskFromVec
(
And
(
VecFromMask
(
d
a
)
VecFromMask
(
d
b
)
)
)
;
}
template
<
typename
T
size_t
N
>
HWY_API
Mask128
<
T
N
>
AndNot
(
const
Mask128
<
T
N
>
a
Mask128
<
T
N
>
b
)
{
const
Simd
<
T
N
0
>
d
;
return
MaskFromVec
(
AndNot
(
VecFromMask
(
d
a
)
VecFromMask
(
d
b
)
)
)
;
}
template
<
typename
T
size_t
N
>
HWY_API
Mask128
<
T
N
>
Or
(
const
Mask128
<
T
N
>
a
Mask128
<
T
N
>
b
)
{
const
Simd
<
T
N
0
>
d
;
return
MaskFromVec
(
Or
(
VecFromMask
(
d
a
)
VecFromMask
(
d
b
)
)
)
;
}
template
<
typename
T
size_t
N
>
HWY_API
Mask128
<
T
N
>
Xor
(
const
Mask128
<
T
N
>
a
Mask128
<
T
N
>
b
)
{
const
Simd
<
T
N
0
>
d
;
return
MaskFromVec
(
Xor
(
VecFromMask
(
d
a
)
VecFromMask
(
d
b
)
)
)
;
}
#
endif
template
<
size_t
N
>
HWY_API
Vec128
<
uint32_t
N
>
Shuffle2301
(
const
Vec128
<
uint32_t
N
>
v
)
{
static_assert
(
N
=
=
2
|
|
N
=
=
4
"
Does
not
make
sense
for
N
=
1
"
)
;
return
Vec128
<
uint32_t
N
>
{
_mm_shuffle_epi32
(
v
.
raw
0xB1
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
int32_t
N
>
Shuffle2301
(
const
Vec128
<
int32_t
N
>
v
)
{
static_assert
(
N
=
=
2
|
|
N
=
=
4
"
Does
not
make
sense
for
N
=
1
"
)
;
return
Vec128
<
int32_t
N
>
{
_mm_shuffle_epi32
(
v
.
raw
0xB1
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
float
N
>
Shuffle2301
(
const
Vec128
<
float
N
>
v
)
{
static_assert
(
N
=
=
2
|
|
N
=
=
4
"
Does
not
make
sense
for
N
=
1
"
)
;
return
Vec128
<
float
N
>
{
_mm_shuffle_ps
(
v
.
raw
v
.
raw
0xB1
)
}
;
}
HWY_API
Vec128
<
uint32_t
>
Shuffle1032
(
const
Vec128
<
uint32_t
>
v
)
{
return
Vec128
<
uint32_t
>
{
_mm_shuffle_epi32
(
v
.
raw
0x4E
)
}
;
}
HWY_API
Vec128
<
int32_t
>
Shuffle1032
(
const
Vec128
<
int32_t
>
v
)
{
return
Vec128
<
int32_t
>
{
_mm_shuffle_epi32
(
v
.
raw
0x4E
)
}
;
}
HWY_API
Vec128
<
float
>
Shuffle1032
(
const
Vec128
<
float
>
v
)
{
return
Vec128
<
float
>
{
_mm_shuffle_ps
(
v
.
raw
v
.
raw
0x4E
)
}
;
}
HWY_API
Vec128
<
uint64_t
>
Shuffle01
(
const
Vec128
<
uint64_t
>
v
)
{
return
Vec128
<
uint64_t
>
{
_mm_shuffle_epi32
(
v
.
raw
0x4E
)
}
;
}
HWY_API
Vec128
<
int64_t
>
Shuffle01
(
const
Vec128
<
int64_t
>
v
)
{
return
Vec128
<
int64_t
>
{
_mm_shuffle_epi32
(
v
.
raw
0x4E
)
}
;
}
HWY_API
Vec128
<
double
>
Shuffle01
(
const
Vec128
<
double
>
v
)
{
return
Vec128
<
double
>
{
_mm_shuffle_pd
(
v
.
raw
v
.
raw
1
)
}
;
}
HWY_API
Vec128
<
uint32_t
>
Shuffle0321
(
const
Vec128
<
uint32_t
>
v
)
{
return
Vec128
<
uint32_t
>
{
_mm_shuffle_epi32
(
v
.
raw
0x39
)
}
;
}
HWY_API
Vec128
<
int32_t
>
Shuffle0321
(
const
Vec128
<
int32_t
>
v
)
{
return
Vec128
<
int32_t
>
{
_mm_shuffle_epi32
(
v
.
raw
0x39
)
}
;
}
HWY_API
Vec128
<
float
>
Shuffle0321
(
const
Vec128
<
float
>
v
)
{
return
Vec128
<
float
>
{
_mm_shuffle_ps
(
v
.
raw
v
.
raw
0x39
)
}
;
}
HWY_API
Vec128
<
uint32_t
>
Shuffle2103
(
const
Vec128
<
uint32_t
>
v
)
{
return
Vec128
<
uint32_t
>
{
_mm_shuffle_epi32
(
v
.
raw
0x93
)
}
;
}
HWY_API
Vec128
<
int32_t
>
Shuffle2103
(
const
Vec128
<
int32_t
>
v
)
{
return
Vec128
<
int32_t
>
{
_mm_shuffle_epi32
(
v
.
raw
0x93
)
}
;
}
HWY_API
Vec128
<
float
>
Shuffle2103
(
const
Vec128
<
float
>
v
)
{
return
Vec128
<
float
>
{
_mm_shuffle_ps
(
v
.
raw
v
.
raw
0x93
)
}
;
}
HWY_API
Vec128
<
uint32_t
>
Shuffle0123
(
const
Vec128
<
uint32_t
>
v
)
{
return
Vec128
<
uint32_t
>
{
_mm_shuffle_epi32
(
v
.
raw
0x1B
)
}
;
}
HWY_API
Vec128
<
int32_t
>
Shuffle0123
(
const
Vec128
<
int32_t
>
v
)
{
return
Vec128
<
int32_t
>
{
_mm_shuffle_epi32
(
v
.
raw
0x1B
)
}
;
}
HWY_API
Vec128
<
float
>
Shuffle0123
(
const
Vec128
<
float
>
v
)
{
return
Vec128
<
float
>
{
_mm_shuffle_ps
(
v
.
raw
v
.
raw
0x1B
)
}
;
}
#
if
HWY_TARGET
<
=
HWY_AVX3
template
<
typename
TFrom
size_t
NFrom
typename
TTo
size_t
NTo
>
HWY_API
Mask128
<
TTo
NTo
>
RebindMask
(
Simd
<
TTo
NTo
0
>
Mask128
<
TFrom
NFrom
>
m
)
{
static_assert
(
sizeof
(
TFrom
)
=
=
sizeof
(
TTo
)
"
Must
have
same
size
"
)
;
return
Mask128
<
TTo
NTo
>
{
m
.
raw
}
;
}
namespace
detail
{
template
<
typename
T
size_t
N
>
HWY_INLINE
Mask128
<
T
N
>
TestBit
(
hwy
:
:
SizeTag
<
1
>
const
Vec128
<
T
N
>
v
const
Vec128
<
T
N
>
bit
)
{
return
Mask128
<
T
N
>
{
_mm_test_epi8_mask
(
v
.
raw
bit
.
raw
)
}
;
}
template
<
typename
T
size_t
N
>
HWY_INLINE
Mask128
<
T
N
>
TestBit
(
hwy
:
:
SizeTag
<
2
>
const
Vec128
<
T
N
>
v
const
Vec128
<
T
N
>
bit
)
{
return
Mask128
<
T
N
>
{
_mm_test_epi16_mask
(
v
.
raw
bit
.
raw
)
}
;
}
template
<
typename
T
size_t
N
>
HWY_INLINE
Mask128
<
T
N
>
TestBit
(
hwy
:
:
SizeTag
<
4
>
const
Vec128
<
T
N
>
v
const
Vec128
<
T
N
>
bit
)
{
return
Mask128
<
T
N
>
{
_mm_test_epi32_mask
(
v
.
raw
bit
.
raw
)
}
;
}
template
<
typename
T
size_t
N
>
HWY_INLINE
Mask128
<
T
N
>
TestBit
(
hwy
:
:
SizeTag
<
8
>
const
Vec128
<
T
N
>
v
const
Vec128
<
T
N
>
bit
)
{
return
Mask128
<
T
N
>
{
_mm_test_epi64_mask
(
v
.
raw
bit
.
raw
)
}
;
}
}
template
<
typename
T
size_t
N
>
HWY_API
Mask128
<
T
N
>
TestBit
(
const
Vec128
<
T
N
>
v
const
Vec128
<
T
N
>
bit
)
{
static_assert
(
!
hwy
:
:
IsFloat
<
T
>
(
)
"
Only
integer
vectors
supported
"
)
;
return
detail
:
:
TestBit
(
hwy
:
:
SizeTag
<
sizeof
(
T
)
>
(
)
v
bit
)
;
}
template
<
typename
T
size_t
N
HWY_IF_LANE_SIZE
(
T
1
)
>
HWY_API
Mask128
<
T
N
>
operator
=
=
(
const
Vec128
<
T
N
>
a
const
Vec128
<
T
N
>
b
)
{
return
Mask128
<
T
N
>
{
_mm_cmpeq_epi8_mask
(
a
.
raw
b
.
raw
)
}
;
}
template
<
typename
T
size_t
N
HWY_IF_LANE_SIZE
(
T
2
)
>
HWY_API
Mask128
<
T
N
>
operator
=
=
(
const
Vec128
<
T
N
>
a
const
Vec128
<
T
N
>
b
)
{
return
Mask128
<
T
N
>
{
_mm_cmpeq_epi16_mask
(
a
.
raw
b
.
raw
)
}
;
}
template
<
typename
T
size_t
N
HWY_IF_LANE_SIZE
(
T
4
)
>
HWY_API
Mask128
<
T
N
>
operator
=
=
(
const
Vec128
<
T
N
>
a
const
Vec128
<
T
N
>
b
)
{
return
Mask128
<
T
N
>
{
_mm_cmpeq_epi32_mask
(
a
.
raw
b
.
raw
)
}
;
}
template
<
typename
T
size_t
N
HWY_IF_LANE_SIZE
(
T
8
)
>
HWY_API
Mask128
<
T
N
>
operator
=
=
(
const
Vec128
<
T
N
>
a
const
Vec128
<
T
N
>
b
)
{
return
Mask128
<
T
N
>
{
_mm_cmpeq_epi64_mask
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Mask128
<
float
N
>
operator
=
=
(
Vec128
<
float
N
>
a
Vec128
<
float
N
>
b
)
{
return
Mask128
<
float
N
>
{
_mm_cmp_ps_mask
(
a
.
raw
b
.
raw
_CMP_EQ_OQ
)
}
;
}
template
<
size_t
N
>
HWY_API
Mask128
<
double
N
>
operator
=
=
(
Vec128
<
double
N
>
a
Vec128
<
double
N
>
b
)
{
return
Mask128
<
double
N
>
{
_mm_cmp_pd_mask
(
a
.
raw
b
.
raw
_CMP_EQ_OQ
)
}
;
}
template
<
typename
T
size_t
N
HWY_IF_LANE_SIZE
(
T
1
)
>
HWY_API
Mask128
<
T
N
>
operator
!
=
(
const
Vec128
<
T
N
>
a
const
Vec128
<
T
N
>
b
)
{
return
Mask128
<
T
N
>
{
_mm_cmpneq_epi8_mask
(
a
.
raw
b
.
raw
)
}
;
}
template
<
typename
T
size_t
N
HWY_IF_LANE_SIZE
(
T
2
)
>
HWY_API
Mask128
<
T
N
>
operator
!
=
(
const
Vec128
<
T
N
>
a
const
Vec128
<
T
N
>
b
)
{
return
Mask128
<
T
N
>
{
_mm_cmpneq_epi16_mask
(
a
.
raw
b
.
raw
)
}
;
}
template
<
typename
T
size_t
N
HWY_IF_LANE_SIZE
(
T
4
)
>
HWY_API
Mask128
<
T
N
>
operator
!
=
(
const
Vec128
<
T
N
>
a
const
Vec128
<
T
N
>
b
)
{
return
Mask128
<
T
N
>
{
_mm_cmpneq_epi32_mask
(
a
.
raw
b
.
raw
)
}
;
}
template
<
typename
T
size_t
N
HWY_IF_LANE_SIZE
(
T
8
)
>
HWY_API
Mask128
<
T
N
>
operator
!
=
(
const
Vec128
<
T
N
>
a
const
Vec128
<
T
N
>
b
)
{
return
Mask128
<
T
N
>
{
_mm_cmpneq_epi64_mask
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Mask128
<
float
N
>
operator
!
=
(
Vec128
<
float
N
>
a
Vec128
<
float
N
>
b
)
{
return
Mask128
<
float
N
>
{
_mm_cmp_ps_mask
(
a
.
raw
b
.
raw
_CMP_NEQ_OQ
)
}
;
}
template
<
size_t
N
>
HWY_API
Mask128
<
double
N
>
operator
!
=
(
Vec128
<
double
N
>
a
Vec128
<
double
N
>
b
)
{
return
Mask128
<
double
N
>
{
_mm_cmp_pd_mask
(
a
.
raw
b
.
raw
_CMP_NEQ_OQ
)
}
;
}
template
<
size_t
N
>
HWY_API
Mask128
<
int8_t
N
>
operator
>
(
Vec128
<
int8_t
N
>
a
Vec128
<
int8_t
N
>
b
)
{
return
Mask128
<
int8_t
N
>
{
_mm_cmpgt_epi8_mask
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Mask128
<
int16_t
N
>
operator
>
(
Vec128
<
int16_t
N
>
a
Vec128
<
int16_t
N
>
b
)
{
return
Mask128
<
int16_t
N
>
{
_mm_cmpgt_epi16_mask
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Mask128
<
int32_t
N
>
operator
>
(
Vec128
<
int32_t
N
>
a
Vec128
<
int32_t
N
>
b
)
{
return
Mask128
<
int32_t
N
>
{
_mm_cmpgt_epi32_mask
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Mask128
<
int64_t
N
>
operator
>
(
Vec128
<
int64_t
N
>
a
Vec128
<
int64_t
N
>
b
)
{
return
Mask128
<
int64_t
N
>
{
_mm_cmpgt_epi64_mask
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Mask128
<
uint8_t
N
>
operator
>
(
Vec128
<
uint8_t
N
>
a
Vec128
<
uint8_t
N
>
b
)
{
return
Mask128
<
uint8_t
N
>
{
_mm_cmpgt_epu8_mask
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Mask128
<
uint16_t
N
>
operator
>
(
Vec128
<
uint16_t
N
>
a
Vec128
<
uint16_t
N
>
b
)
{
return
Mask128
<
uint16_t
N
>
{
_mm_cmpgt_epu16_mask
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Mask128
<
uint32_t
N
>
operator
>
(
Vec128
<
uint32_t
N
>
a
Vec128
<
uint32_t
N
>
b
)
{
return
Mask128
<
uint32_t
N
>
{
_mm_cmpgt_epu32_mask
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Mask128
<
uint64_t
N
>
operator
>
(
Vec128
<
uint64_t
N
>
a
Vec128
<
uint64_t
N
>
b
)
{
return
Mask128
<
uint64_t
N
>
{
_mm_cmpgt_epu64_mask
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Mask128
<
float
N
>
operator
>
(
Vec128
<
float
N
>
a
Vec128
<
float
N
>
b
)
{
return
Mask128
<
float
N
>
{
_mm_cmp_ps_mask
(
a
.
raw
b
.
raw
_CMP_GT_OQ
)
}
;
}
template
<
size_t
N
>
HWY_API
Mask128
<
double
N
>
operator
>
(
Vec128
<
double
N
>
a
Vec128
<
double
N
>
b
)
{
return
Mask128
<
double
N
>
{
_mm_cmp_pd_mask
(
a
.
raw
b
.
raw
_CMP_GT_OQ
)
}
;
}
template
<
size_t
N
>
HWY_API
Mask128
<
float
N
>
operator
>
=
(
Vec128
<
float
N
>
a
Vec128
<
float
N
>
b
)
{
return
Mask128
<
float
N
>
{
_mm_cmp_ps_mask
(
a
.
raw
b
.
raw
_CMP_GE_OQ
)
}
;
}
template
<
size_t
N
>
HWY_API
Mask128
<
double
N
>
operator
>
=
(
Vec128
<
double
N
>
a
Vec128
<
double
N
>
b
)
{
return
Mask128
<
double
N
>
{
_mm_cmp_pd_mask
(
a
.
raw
b
.
raw
_CMP_GE_OQ
)
}
;
}
namespace
detail
{
template
<
typename
T
size_t
N
>
HWY_INLINE
Mask128
<
T
N
>
MaskFromVec
(
hwy
:
:
SizeTag
<
1
>
const
Vec128
<
T
N
>
v
)
{
return
Mask128
<
T
N
>
{
_mm_movepi8_mask
(
v
.
raw
)
}
;
}
template
<
typename
T
size_t
N
>
HWY_INLINE
Mask128
<
T
N
>
MaskFromVec
(
hwy
:
:
SizeTag
<
2
>
const
Vec128
<
T
N
>
v
)
{
return
Mask128
<
T
N
>
{
_mm_movepi16_mask
(
v
.
raw
)
}
;
}
template
<
typename
T
size_t
N
>
HWY_INLINE
Mask128
<
T
N
>
MaskFromVec
(
hwy
:
:
SizeTag
<
4
>
const
Vec128
<
T
N
>
v
)
{
return
Mask128
<
T
N
>
{
_mm_movepi32_mask
(
v
.
raw
)
}
;
}
template
<
typename
T
size_t
N
>
HWY_INLINE
Mask128
<
T
N
>
MaskFromVec
(
hwy
:
:
SizeTag
<
8
>
const
Vec128
<
T
N
>
v
)
{
return
Mask128
<
T
N
>
{
_mm_movepi64_mask
(
v
.
raw
)
}
;
}
}
template
<
typename
T
size_t
N
>
HWY_API
Mask128
<
T
N
>
MaskFromVec
(
const
Vec128
<
T
N
>
v
)
{
return
detail
:
:
MaskFromVec
(
hwy
:
:
SizeTag
<
sizeof
(
T
)
>
(
)
v
)
;
}
template
<
size_t
N
>
HWY_API
Mask128
<
float
N
>
MaskFromVec
(
const
Vec128
<
float
N
>
v
)
{
const
RebindToSigned
<
DFromV
<
decltype
(
v
)
>
>
di
;
return
Mask128
<
float
N
>
{
MaskFromVec
(
BitCast
(
di
v
)
)
.
raw
}
;
}
template
<
size_t
N
>
HWY_API
Mask128
<
double
N
>
MaskFromVec
(
const
Vec128
<
double
N
>
v
)
{
const
RebindToSigned
<
DFromV
<
decltype
(
v
)
>
>
di
;
return
Mask128
<
double
N
>
{
MaskFromVec
(
BitCast
(
di
v
)
)
.
raw
}
;
}
template
<
typename
T
size_t
N
HWY_IF_LANE_SIZE
(
T
1
)
>
HWY_API
Vec128
<
T
N
>
VecFromMask
(
const
Mask128
<
T
N
>
v
)
{
return
Vec128
<
T
N
>
{
_mm_movm_epi8
(
v
.
raw
)
}
;
}
template
<
typename
T
size_t
N
HWY_IF_LANE_SIZE
(
T
2
)
>
HWY_API
Vec128
<
T
N
>
VecFromMask
(
const
Mask128
<
T
N
>
v
)
{
return
Vec128
<
T
N
>
{
_mm_movm_epi16
(
v
.
raw
)
}
;
}
template
<
typename
T
size_t
N
HWY_IF_LANE_SIZE
(
T
4
)
>
HWY_API
Vec128
<
T
N
>
VecFromMask
(
const
Mask128
<
T
N
>
v
)
{
return
Vec128
<
T
N
>
{
_mm_movm_epi32
(
v
.
raw
)
}
;
}
template
<
typename
T
size_t
N
HWY_IF_LANE_SIZE
(
T
8
)
>
HWY_API
Vec128
<
T
N
>
VecFromMask
(
const
Mask128
<
T
N
>
v
)
{
return
Vec128
<
T
N
>
{
_mm_movm_epi64
(
v
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
float
N
>
VecFromMask
(
const
Mask128
<
float
N
>
v
)
{
return
Vec128
<
float
N
>
{
_mm_castsi128_ps
(
_mm_movm_epi32
(
v
.
raw
)
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
double
N
>
VecFromMask
(
const
Mask128
<
double
N
>
v
)
{
return
Vec128
<
double
N
>
{
_mm_castsi128_pd
(
_mm_movm_epi64
(
v
.
raw
)
)
}
;
}
template
<
typename
T
size_t
N
>
HWY_API
Vec128
<
T
N
>
VecFromMask
(
Simd
<
T
N
0
>
const
Mask128
<
T
N
>
v
)
{
return
VecFromMask
(
v
)
;
}
#
else
template
<
typename
TFrom
typename
TTo
size_t
N
>
HWY_API
Mask128
<
TTo
N
>
RebindMask
(
Simd
<
TTo
N
0
>
Mask128
<
TFrom
N
>
m
)
{
static_assert
(
sizeof
(
TFrom
)
=
=
sizeof
(
TTo
)
"
Must
have
same
size
"
)
;
const
Simd
<
TFrom
N
0
>
d
;
return
MaskFromVec
(
BitCast
(
Simd
<
TTo
N
0
>
(
)
VecFromMask
(
d
m
)
)
)
;
}
template
<
typename
T
size_t
N
>
HWY_API
Mask128
<
T
N
>
TestBit
(
Vec128
<
T
N
>
v
Vec128
<
T
N
>
bit
)
{
static_assert
(
!
hwy
:
:
IsFloat
<
T
>
(
)
"
Only
integer
vectors
supported
"
)
;
return
(
v
&
bit
)
=
=
bit
;
}
template
<
size_t
N
>
HWY_API
Mask128
<
uint8_t
N
>
operator
=
=
(
const
Vec128
<
uint8_t
N
>
a
const
Vec128
<
uint8_t
N
>
b
)
{
return
Mask128
<
uint8_t
N
>
{
_mm_cmpeq_epi8
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Mask128
<
uint16_t
N
>
operator
=
=
(
const
Vec128
<
uint16_t
N
>
a
const
Vec128
<
uint16_t
N
>
b
)
{
return
Mask128
<
uint16_t
N
>
{
_mm_cmpeq_epi16
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Mask128
<
uint32_t
N
>
operator
=
=
(
const
Vec128
<
uint32_t
N
>
a
const
Vec128
<
uint32_t
N
>
b
)
{
return
Mask128
<
uint32_t
N
>
{
_mm_cmpeq_epi32
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Mask128
<
uint64_t
N
>
operator
=
=
(
const
Vec128
<
uint64_t
N
>
a
const
Vec128
<
uint64_t
N
>
b
)
{
#
if
HWY_TARGET
=
=
HWY_SSSE3
const
Simd
<
uint32_t
N
*
2
0
>
d32
;
const
Simd
<
uint64_t
N
0
>
d64
;
const
auto
cmp32
=
VecFromMask
(
d32
Eq
(
BitCast
(
d32
a
)
BitCast
(
d32
b
)
)
)
;
const
auto
cmp64
=
cmp32
&
Shuffle2301
(
cmp32
)
;
return
MaskFromVec
(
BitCast
(
d64
cmp64
)
)
;
#
else
return
Mask128
<
uint64_t
N
>
{
_mm_cmpeq_epi64
(
a
.
raw
b
.
raw
)
}
;
#
endif
}
template
<
size_t
N
>
HWY_API
Mask128
<
int8_t
N
>
operator
=
=
(
const
Vec128
<
int8_t
N
>
a
const
Vec128
<
int8_t
N
>
b
)
{
return
Mask128
<
int8_t
N
>
{
_mm_cmpeq_epi8
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Mask128
<
int16_t
N
>
operator
=
=
(
Vec128
<
int16_t
N
>
a
Vec128
<
int16_t
N
>
b
)
{
return
Mask128
<
int16_t
N
>
{
_mm_cmpeq_epi16
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Mask128
<
int32_t
N
>
operator
=
=
(
const
Vec128
<
int32_t
N
>
a
const
Vec128
<
int32_t
N
>
b
)
{
return
Mask128
<
int32_t
N
>
{
_mm_cmpeq_epi32
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Mask128
<
int64_t
N
>
operator
=
=
(
const
Vec128
<
int64_t
N
>
a
const
Vec128
<
int64_t
N
>
b
)
{
const
DFromV
<
decltype
(
a
)
>
d
;
RebindToUnsigned
<
decltype
(
d
)
>
du
;
return
RebindMask
(
d
BitCast
(
du
a
)
=
=
BitCast
(
du
b
)
)
;
}
template
<
size_t
N
>
HWY_API
Mask128
<
float
N
>
operator
=
=
(
const
Vec128
<
float
N
>
a
const
Vec128
<
float
N
>
b
)
{
return
Mask128
<
float
N
>
{
_mm_cmpeq_ps
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Mask128
<
double
N
>
operator
=
=
(
const
Vec128
<
double
N
>
a
const
Vec128
<
double
N
>
b
)
{
return
Mask128
<
double
N
>
{
_mm_cmpeq_pd
(
a
.
raw
b
.
raw
)
}
;
}
template
<
typename
T
size_t
N
HWY_IF_NOT_FLOAT
(
T
)
>
HWY_API
Mask128
<
T
N
>
operator
!
=
(
const
Vec128
<
T
N
>
a
const
Vec128
<
T
N
>
b
)
{
return
Not
(
a
=
=
b
)
;
}
template
<
size_t
N
>
HWY_API
Mask128
<
float
N
>
operator
!
=
(
const
Vec128
<
float
N
>
a
const
Vec128
<
float
N
>
b
)
{
return
Mask128
<
float
N
>
{
_mm_cmpneq_ps
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Mask128
<
double
N
>
operator
!
=
(
const
Vec128
<
double
N
>
a
const
Vec128
<
double
N
>
b
)
{
return
Mask128
<
double
N
>
{
_mm_cmpneq_pd
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Mask128
<
int8_t
N
>
operator
>
(
Vec128
<
int8_t
N
>
a
Vec128
<
int8_t
N
>
b
)
{
return
Mask128
<
int8_t
N
>
{
_mm_cmpgt_epi8
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Mask128
<
int16_t
N
>
operator
>
(
Vec128
<
int16_t
N
>
a
Vec128
<
int16_t
N
>
b
)
{
return
Mask128
<
int16_t
N
>
{
_mm_cmpgt_epi16
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Mask128
<
int32_t
N
>
operator
>
(
Vec128
<
int32_t
N
>
a
Vec128
<
int32_t
N
>
b
)
{
return
Mask128
<
int32_t
N
>
{
_mm_cmpgt_epi32
(
a
.
raw
b
.
raw
)
}
;
}
template
<
typename
T
size_t
N
HWY_IF_UNSIGNED
(
T
)
>
HWY_API
Mask128
<
T
N
>
operator
>
(
Vec128
<
T
N
>
a
Vec128
<
T
N
>
b
)
{
const
DFromV
<
decltype
(
a
)
>
du
;
const
RebindToSigned
<
decltype
(
du
)
>
di
;
const
Vec128
<
T
N
>
msb
=
Set
(
du
(
LimitsMax
<
T
>
(
)
>
>
1
)
+
1
)
;
return
RebindMask
(
du
BitCast
(
di
Xor
(
a
msb
)
)
>
BitCast
(
di
Xor
(
b
msb
)
)
)
;
}
template
<
size_t
N
>
HWY_API
Mask128
<
float
N
>
operator
>
(
Vec128
<
float
N
>
a
Vec128
<
float
N
>
b
)
{
return
Mask128
<
float
N
>
{
_mm_cmpgt_ps
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Mask128
<
double
N
>
operator
>
(
Vec128
<
double
N
>
a
Vec128
<
double
N
>
b
)
{
return
Mask128
<
double
N
>
{
_mm_cmpgt_pd
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Mask128
<
int64_t
N
>
operator
>
(
const
Vec128
<
int64_t
N
>
a
const
Vec128
<
int64_t
N
>
b
)
{
#
if
HWY_TARGET
=
=
HWY_SSSE3
const
__m128i
m_gt
=
_mm_cmpgt_epi32
(
a
.
raw
b
.
raw
)
;
const
__m128i
m_eq
=
_mm_cmpeq_epi32
(
a
.
raw
b
.
raw
)
;
const
__m128i
lo_in_hi
=
_mm_shuffle_epi32
(
m_gt
_MM_SHUFFLE
(
2
2
0
0
)
)
;
const
__m128i
lo_gt
=
_mm_and_si128
(
m_eq
lo_in_hi
)
;
const
__m128i
gt
=
_mm_or_si128
(
lo_gt
m_gt
)
;
return
Mask128
<
int64_t
N
>
{
_mm_shuffle_epi32
(
gt
_MM_SHUFFLE
(
3
3
1
1
)
)
}
;
#
else
return
Mask128
<
int64_t
N
>
{
_mm_cmpgt_epi64
(
a
.
raw
b
.
raw
)
}
;
#
endif
}
template
<
size_t
N
>
HWY_API
Mask128
<
float
N
>
operator
>
=
(
const
Vec128
<
float
N
>
a
const
Vec128
<
float
N
>
b
)
{
return
Mask128
<
float
N
>
{
_mm_cmpge_ps
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Mask128
<
double
N
>
operator
>
=
(
const
Vec128
<
double
N
>
a
const
Vec128
<
double
N
>
b
)
{
return
Mask128
<
double
N
>
{
_mm_cmpge_pd
(
a
.
raw
b
.
raw
)
}
;
}
#
endif
template
<
typename
T
size_t
N
>
HWY_API
Mask128
<
T
N
>
operator
<
(
Vec128
<
T
N
>
a
Vec128
<
T
N
>
b
)
{
return
b
>
a
;
}
template
<
typename
T
size_t
N
>
HWY_API
Mask128
<
T
N
>
operator
<
=
(
Vec128
<
T
N
>
a
Vec128
<
T
N
>
b
)
{
return
b
>
=
a
;
}
template
<
typename
T
size_t
N
HWY_IF_LE128
(
T
N
)
>
HWY_API
Mask128
<
T
N
>
FirstN
(
const
Simd
<
T
N
0
>
d
size_t
num
)
{
#
if
HWY_TARGET
<
=
HWY_AVX3
(
void
)
d
;
const
uint64_t
all
=
(
1ull
<
<
N
)
-
1
;
const
uint64_t
bits
=
(
num
>
255
)
?
all
:
_bzhi_u64
(
all
num
)
;
return
Mask128
<
T
N
>
:
:
FromBits
(
bits
)
;
#
else
const
RebindToSigned
<
decltype
(
d
)
>
di
;
return
RebindMask
(
d
Iota
(
di
0
)
<
Set
(
di
static_cast
<
MakeSigned
<
T
>
>
(
num
)
)
)
;
#
endif
}
template
<
class
D
>
using
MFromD
=
decltype
(
FirstN
(
D
(
)
0
)
)
;
#
ifndef
HWY_SAFE_PARTIAL_LOAD_STORE
#
if
defined
(
__clang_analyzer__
)
|
|
\
(
HWY_COMPILER_CLANG
!
=
0
&
&
HWY_COMPILER_CLANG
<
700
)
#
define
HWY_SAFE_PARTIAL_LOAD_STORE
1
#
else
#
define
HWY_SAFE_PARTIAL_LOAD_STORE
0
#
endif
#
endif
template
<
typename
T
>
HWY_API
Vec128
<
T
>
Load
(
Full128
<
T
>
const
T
*
HWY_RESTRICT
aligned
)
{
return
Vec128
<
T
>
{
_mm_load_si128
(
reinterpret_cast
<
const
__m128i
*
>
(
aligned
)
)
}
;
}
HWY_API
Vec128
<
float
>
Load
(
Full128
<
float
>
const
float
*
HWY_RESTRICT
aligned
)
{
return
Vec128
<
float
>
{
_mm_load_ps
(
aligned
)
}
;
}
HWY_API
Vec128
<
double
>
Load
(
Full128
<
double
>
const
double
*
HWY_RESTRICT
aligned
)
{
return
Vec128
<
double
>
{
_mm_load_pd
(
aligned
)
}
;
}
template
<
typename
T
>
HWY_API
Vec128
<
T
>
LoadU
(
Full128
<
T
>
const
T
*
HWY_RESTRICT
p
)
{
return
Vec128
<
T
>
{
_mm_loadu_si128
(
reinterpret_cast
<
const
__m128i
*
>
(
p
)
)
}
;
}
HWY_API
Vec128
<
float
>
LoadU
(
Full128
<
float
>
const
float
*
HWY_RESTRICT
p
)
{
return
Vec128
<
float
>
{
_mm_loadu_ps
(
p
)
}
;
}
HWY_API
Vec128
<
double
>
LoadU
(
Full128
<
double
>
const
double
*
HWY_RESTRICT
p
)
{
return
Vec128
<
double
>
{
_mm_loadu_pd
(
p
)
}
;
}
template
<
typename
T
>
HWY_API
Vec64
<
T
>
Load
(
Full64
<
T
>
const
T
*
HWY_RESTRICT
p
)
{
#
if
HWY_SAFE_PARTIAL_LOAD_STORE
__m128i
v
=
_mm_setzero_si128
(
)
;
CopyBytes
<
8
>
(
p
&
v
)
;
return
Vec64
<
T
>
{
v
}
;
#
else
return
Vec64
<
T
>
{
_mm_loadl_epi64
(
reinterpret_cast
<
const
__m128i
*
>
(
p
)
)
}
;
#
endif
}
HWY_API
Vec128
<
float
2
>
Load
(
Full64
<
float
>
const
float
*
HWY_RESTRICT
p
)
{
#
if
HWY_SAFE_PARTIAL_LOAD_STORE
__m128
v
=
_mm_setzero_ps
(
)
;
CopyBytes
<
8
>
(
p
&
v
)
;
return
Vec128
<
float
2
>
{
v
}
;
#
else
const
__m128
hi
=
_mm_setzero_ps
(
)
;
return
Vec128
<
float
2
>
{
_mm_loadl_pi
(
hi
reinterpret_cast
<
const
__m64
*
>
(
p
)
)
}
;
#
endif
}
HWY_API
Vec64
<
double
>
Load
(
Full64
<
double
>
const
double
*
HWY_RESTRICT
p
)
{
#
if
HWY_SAFE_PARTIAL_LOAD_STORE
__m128d
v
=
_mm_setzero_pd
(
)
;
CopyBytes
<
8
>
(
p
&
v
)
;
return
Vec64
<
double
>
{
v
}
;
#
else
return
Vec64
<
double
>
{
_mm_load_sd
(
p
)
}
;
#
endif
}
HWY_API
Vec128
<
float
1
>
Load
(
Full32
<
float
>
const
float
*
HWY_RESTRICT
p
)
{
#
if
HWY_SAFE_PARTIAL_LOAD_STORE
__m128
v
=
_mm_setzero_ps
(
)
;
CopyBytes
<
4
>
(
p
&
v
)
;
return
Vec128
<
float
1
>
{
v
}
;
#
else
return
Vec128
<
float
1
>
{
_mm_load_ss
(
p
)
}
;
#
endif
}
template
<
typename
T
size_t
N
HWY_IF_LE32
(
T
N
)
>
HWY_API
Vec128
<
T
N
>
Load
(
Simd
<
T
N
0
>
const
T
*
HWY_RESTRICT
p
)
{
constexpr
size_t
kSize
=
sizeof
(
T
)
*
N
;
#
if
HWY_SAFE_PARTIAL_LOAD_STORE
__m128
v
=
_mm_setzero_ps
(
)
;
CopyBytes
<
kSize
>
(
p
&
v
)
;
return
Vec128
<
T
N
>
{
v
}
;
#
else
int32_t
bits
;
CopyBytes
<
kSize
>
(
p
&
bits
)
;
return
Vec128
<
T
N
>
{
_mm_cvtsi32_si128
(
bits
)
}
;
#
endif
}
template
<
typename
T
size_t
N
HWY_IF_LE64
(
T
N
)
>
HWY_API
Vec128
<
T
N
>
LoadU
(
Simd
<
T
N
0
>
d
const
T
*
HWY_RESTRICT
p
)
{
return
Load
(
d
p
)
;
}
template
<
typename
T
size_t
N
HWY_IF_LE128
(
T
N
)
>
HWY_API
Vec128
<
T
N
>
LoadDup128
(
Simd
<
T
N
0
>
d
const
T
*
HWY_RESTRICT
p
)
{
return
LoadU
(
d
p
)
;
}
template
<
typename
T
size_t
N
typename
T2
HWY_IF_LE128
(
T
N
)
>
HWY_API
Vec128
<
T
N
>
Iota
(
const
Simd
<
T
N
0
>
d
const
T2
first
)
{
HWY_ALIGN
T
lanes
[
16
/
sizeof
(
T
)
]
;
for
(
size_t
i
=
0
;
i
<
16
/
sizeof
(
T
)
;
+
+
i
)
{
lanes
[
i
]
=
static_cast
<
T
>
(
first
+
static_cast
<
T2
>
(
i
)
)
;
}
return
Load
(
d
lanes
)
;
}
#
if
HWY_TARGET
<
=
HWY_AVX3
template
<
typename
T
size_t
N
HWY_IF_LANE_SIZE
(
T
4
)
>
HWY_API
Vec128
<
T
N
>
MaskedLoad
(
Mask128
<
T
N
>
m
Simd
<
T
N
0
>
const
T
*
HWY_RESTRICT
aligned
)
{
return
Vec128
<
T
N
>
{
_mm_maskz_load_epi32
(
m
.
raw
aligned
)
}
;
}
template
<
typename
T
size_t
N
HWY_IF_LANE_SIZE
(
T
8
)
>
HWY_API
Vec128
<
T
N
>
MaskedLoad
(
Mask128
<
T
N
>
m
Simd
<
T
N
0
>
const
T
*
HWY_RESTRICT
aligned
)
{
return
Vec128
<
T
N
>
{
_mm_maskz_load_epi64
(
m
.
raw
aligned
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
float
N
>
MaskedLoad
(
Mask128
<
float
N
>
m
Simd
<
float
N
0
>
const
float
*
HWY_RESTRICT
aligned
)
{
return
Vec128
<
float
N
>
{
_mm_maskz_load_ps
(
m
.
raw
aligned
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
double
N
>
MaskedLoad
(
Mask128
<
double
N
>
m
Simd
<
double
N
0
>
const
double
*
HWY_RESTRICT
aligned
)
{
return
Vec128
<
double
N
>
{
_mm_maskz_load_pd
(
m
.
raw
aligned
)
}
;
}
template
<
typename
T
size_t
N
HWY_IF_LANE_SIZE
(
T
1
)
>
HWY_API
Vec128
<
T
N
>
MaskedLoad
(
Mask128
<
T
N
>
m
Simd
<
T
N
0
>
const
T
*
HWY_RESTRICT
aligned
)
{
return
Vec128
<
T
N
>
{
_mm_maskz_loadu_epi8
(
m
.
raw
aligned
)
}
;
}
template
<
typename
T
size_t
N
HWY_IF_LANE_SIZE
(
T
2
)
>
HWY_API
Vec128
<
T
N
>
MaskedLoad
(
Mask128
<
T
N
>
m
Simd
<
T
N
0
>
const
T
*
HWY_RESTRICT
aligned
)
{
return
Vec128
<
T
N
>
{
_mm_maskz_loadu_epi16
(
m
.
raw
aligned
)
}
;
}
#
elif
HWY_TARGET
=
=
HWY_AVX2
template
<
typename
T
size_t
N
HWY_IF_LANE_SIZE
(
T
4
)
>
HWY_API
Vec128
<
T
N
>
MaskedLoad
(
Mask128
<
T
N
>
m
Simd
<
T
N
0
>
const
T
*
HWY_RESTRICT
aligned
)
{
auto
aligned_p
=
reinterpret_cast
<
const
int
*
>
(
aligned
)
;
return
Vec128
<
T
N
>
{
_mm_maskload_epi32
(
aligned_p
m
.
raw
)
}
;
}
template
<
typename
T
size_t
N
HWY_IF_LANE_SIZE
(
T
8
)
>
HWY_API
Vec128
<
T
N
>
MaskedLoad
(
Mask128
<
T
N
>
m
Simd
<
T
N
0
>
const
T
*
HWY_RESTRICT
aligned
)
{
auto
aligned_p
=
reinterpret_cast
<
const
long
long
*
>
(
aligned
)
;
return
Vec128
<
T
N
>
{
_mm_maskload_epi64
(
aligned_p
m
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
float
N
>
MaskedLoad
(
Mask128
<
float
N
>
m
Simd
<
float
N
0
>
d
const
float
*
HWY_RESTRICT
aligned
)
{
const
Vec128
<
int32_t
N
>
mi
=
BitCast
(
RebindToSigned
<
decltype
(
d
)
>
(
)
VecFromMask
(
d
m
)
)
;
return
Vec128
<
float
N
>
{
_mm_maskload_ps
(
aligned
mi
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
double
N
>
MaskedLoad
(
Mask128
<
double
N
>
m
Simd
<
double
N
0
>
d
const
double
*
HWY_RESTRICT
aligned
)
{
const
Vec128
<
int64_t
N
>
mi
=
BitCast
(
RebindToSigned
<
decltype
(
d
)
>
(
)
VecFromMask
(
d
m
)
)
;
return
Vec128
<
double
N
>
{
_mm_maskload_pd
(
aligned
mi
.
raw
)
}
;
}
template
<
typename
T
size_t
N
hwy
:
:
EnableIf
<
sizeof
(
T
)
<
=
2
>
*
=
nullptr
>
HWY_API
Vec128
<
T
N
>
MaskedLoad
(
Mask128
<
T
N
>
m
Simd
<
T
N
0
>
d
const
T
*
HWY_RESTRICT
aligned
)
{
return
IfThenElseZero
(
m
Load
(
d
aligned
)
)
;
}
#
else
template
<
typename
T
size_t
N
>
HWY_API
Vec128
<
T
N
>
MaskedLoad
(
Mask128
<
T
N
>
m
Simd
<
T
N
0
>
d
const
T
*
HWY_RESTRICT
aligned
)
{
return
IfThenElseZero
(
m
Load
(
d
aligned
)
)
;
}
#
endif
template
<
typename
T
>
HWY_API
void
Store
(
Vec128
<
T
>
v
Full128
<
T
>
T
*
HWY_RESTRICT
aligned
)
{
_mm_store_si128
(
reinterpret_cast
<
__m128i
*
>
(
aligned
)
v
.
raw
)
;
}
HWY_API
void
Store
(
const
Vec128
<
float
>
v
Full128
<
float
>
float
*
HWY_RESTRICT
aligned
)
{
_mm_store_ps
(
aligned
v
.
raw
)
;
}
HWY_API
void
Store
(
const
Vec128
<
double
>
v
Full128
<
double
>
double
*
HWY_RESTRICT
aligned
)
{
_mm_store_pd
(
aligned
v
.
raw
)
;
}
template
<
typename
T
>
HWY_API
void
StoreU
(
Vec128
<
T
>
v
Full128
<
T
>
T
*
HWY_RESTRICT
p
)
{
_mm_storeu_si128
(
reinterpret_cast
<
__m128i
*
>
(
p
)
v
.
raw
)
;
}
HWY_API
void
StoreU
(
const
Vec128
<
float
>
v
Full128
<
float
>
float
*
HWY_RESTRICT
p
)
{
_mm_storeu_ps
(
p
v
.
raw
)
;
}
HWY_API
void
StoreU
(
const
Vec128
<
double
>
v
Full128
<
double
>
double
*
HWY_RESTRICT
p
)
{
_mm_storeu_pd
(
p
v
.
raw
)
;
}
template
<
typename
T
>
HWY_API
void
Store
(
Vec64
<
T
>
v
Full64
<
T
>
T
*
HWY_RESTRICT
p
)
{
#
if
HWY_SAFE_PARTIAL_LOAD_STORE
CopyBytes
<
8
>
(
&
v
p
)
;
#
else
_mm_storel_epi64
(
reinterpret_cast
<
__m128i
*
>
(
p
)
v
.
raw
)
;
#
endif
}
HWY_API
void
Store
(
const
Vec128
<
float
2
>
v
Full64
<
float
>
float
*
HWY_RESTRICT
p
)
{
#
if
HWY_SAFE_PARTIAL_LOAD_STORE
CopyBytes
<
8
>
(
&
v
p
)
;
#
else
_mm_storel_pi
(
reinterpret_cast
<
__m64
*
>
(
p
)
v
.
raw
)
;
#
endif
}
HWY_API
void
Store
(
const
Vec64
<
double
>
v
Full64
<
double
>
double
*
HWY_RESTRICT
p
)
{
#
if
HWY_SAFE_PARTIAL_LOAD_STORE
CopyBytes
<
8
>
(
&
v
p
)
;
#
else
_mm_storel_pd
(
p
v
.
raw
)
;
#
endif
}
template
<
typename
T
size_t
N
HWY_IF_LE32
(
T
N
)
>
HWY_API
void
Store
(
Vec128
<
T
N
>
v
Simd
<
T
N
0
>
T
*
HWY_RESTRICT
p
)
{
CopyBytes
<
sizeof
(
T
)
*
N
>
(
&
v
p
)
;
}
HWY_API
void
Store
(
const
Vec128
<
float
1
>
v
Full32
<
float
>
float
*
HWY_RESTRICT
p
)
{
#
if
HWY_SAFE_PARTIAL_LOAD_STORE
CopyBytes
<
4
>
(
&
v
p
)
;
#
else
_mm_store_ss
(
p
v
.
raw
)
;
#
endif
}
template
<
typename
T
size_t
N
HWY_IF_LE64
(
T
N
)
>
HWY_API
void
StoreU
(
const
Vec128
<
T
N
>
v
Simd
<
T
N
0
>
d
T
*
HWY_RESTRICT
p
)
{
Store
(
v
d
p
)
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint8_t
N
>
operator
+
(
const
Vec128
<
uint8_t
N
>
a
const
Vec128
<
uint8_t
N
>
b
)
{
return
Vec128
<
uint8_t
N
>
{
_mm_add_epi8
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint16_t
N
>
operator
+
(
const
Vec128
<
uint16_t
N
>
a
const
Vec128
<
uint16_t
N
>
b
)
{
return
Vec128
<
uint16_t
N
>
{
_mm_add_epi16
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint32_t
N
>
operator
+
(
const
Vec128
<
uint32_t
N
>
a
const
Vec128
<
uint32_t
N
>
b
)
{
return
Vec128
<
uint32_t
N
>
{
_mm_add_epi32
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint64_t
N
>
operator
+
(
const
Vec128
<
uint64_t
N
>
a
const
Vec128
<
uint64_t
N
>
b
)
{
return
Vec128
<
uint64_t
N
>
{
_mm_add_epi64
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
int8_t
N
>
operator
+
(
const
Vec128
<
int8_t
N
>
a
const
Vec128
<
int8_t
N
>
b
)
{
return
Vec128
<
int8_t
N
>
{
_mm_add_epi8
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
int16_t
N
>
operator
+
(
const
Vec128
<
int16_t
N
>
a
const
Vec128
<
int16_t
N
>
b
)
{
return
Vec128
<
int16_t
N
>
{
_mm_add_epi16
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
int32_t
N
>
operator
+
(
const
Vec128
<
int32_t
N
>
a
const
Vec128
<
int32_t
N
>
b
)
{
return
Vec128
<
int32_t
N
>
{
_mm_add_epi32
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
int64_t
N
>
operator
+
(
const
Vec128
<
int64_t
N
>
a
const
Vec128
<
int64_t
N
>
b
)
{
return
Vec128
<
int64_t
N
>
{
_mm_add_epi64
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
float
N
>
operator
+
(
const
Vec128
<
float
N
>
a
const
Vec128
<
float
N
>
b
)
{
return
Vec128
<
float
N
>
{
_mm_add_ps
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
double
N
>
operator
+
(
const
Vec128
<
double
N
>
a
const
Vec128
<
double
N
>
b
)
{
return
Vec128
<
double
N
>
{
_mm_add_pd
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint8_t
N
>
operator
-
(
const
Vec128
<
uint8_t
N
>
a
const
Vec128
<
uint8_t
N
>
b
)
{
return
Vec128
<
uint8_t
N
>
{
_mm_sub_epi8
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint16_t
N
>
operator
-
(
Vec128
<
uint16_t
N
>
a
Vec128
<
uint16_t
N
>
b
)
{
return
Vec128
<
uint16_t
N
>
{
_mm_sub_epi16
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint32_t
N
>
operator
-
(
const
Vec128
<
uint32_t
N
>
a
const
Vec128
<
uint32_t
N
>
b
)
{
return
Vec128
<
uint32_t
N
>
{
_mm_sub_epi32
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint64_t
N
>
operator
-
(
const
Vec128
<
uint64_t
N
>
a
const
Vec128
<
uint64_t
N
>
b
)
{
return
Vec128
<
uint64_t
N
>
{
_mm_sub_epi64
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
int8_t
N
>
operator
-
(
const
Vec128
<
int8_t
N
>
a
const
Vec128
<
int8_t
N
>
b
)
{
return
Vec128
<
int8_t
N
>
{
_mm_sub_epi8
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
int16_t
N
>
operator
-
(
const
Vec128
<
int16_t
N
>
a
const
Vec128
<
int16_t
N
>
b
)
{
return
Vec128
<
int16_t
N
>
{
_mm_sub_epi16
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
int32_t
N
>
operator
-
(
const
Vec128
<
int32_t
N
>
a
const
Vec128
<
int32_t
N
>
b
)
{
return
Vec128
<
int32_t
N
>
{
_mm_sub_epi32
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
int64_t
N
>
operator
-
(
const
Vec128
<
int64_t
N
>
a
const
Vec128
<
int64_t
N
>
b
)
{
return
Vec128
<
int64_t
N
>
{
_mm_sub_epi64
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
float
N
>
operator
-
(
const
Vec128
<
float
N
>
a
const
Vec128
<
float
N
>
b
)
{
return
Vec128
<
float
N
>
{
_mm_sub_ps
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
double
N
>
operator
-
(
const
Vec128
<
double
N
>
a
const
Vec128
<
double
N
>
b
)
{
return
Vec128
<
double
N
>
{
_mm_sub_pd
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint64_t
N
/
8
>
SumsOf8
(
const
Vec128
<
uint8_t
N
>
v
)
{
return
Vec128
<
uint64_t
N
/
8
>
{
_mm_sad_epu8
(
v
.
raw
_mm_setzero_si128
(
)
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint8_t
N
>
SaturatedAdd
(
const
Vec128
<
uint8_t
N
>
a
const
Vec128
<
uint8_t
N
>
b
)
{
return
Vec128
<
uint8_t
N
>
{
_mm_adds_epu8
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint16_t
N
>
SaturatedAdd
(
const
Vec128
<
uint16_t
N
>
a
const
Vec128
<
uint16_t
N
>
b
)
{
return
Vec128
<
uint16_t
N
>
{
_mm_adds_epu16
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
int8_t
N
>
SaturatedAdd
(
const
Vec128
<
int8_t
N
>
a
const
Vec128
<
int8_t
N
>
b
)
{
return
Vec128
<
int8_t
N
>
{
_mm_adds_epi8
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
int16_t
N
>
SaturatedAdd
(
const
Vec128
<
int16_t
N
>
a
const
Vec128
<
int16_t
N
>
b
)
{
return
Vec128
<
int16_t
N
>
{
_mm_adds_epi16
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint8_t
N
>
SaturatedSub
(
const
Vec128
<
uint8_t
N
>
a
const
Vec128
<
uint8_t
N
>
b
)
{
return
Vec128
<
uint8_t
N
>
{
_mm_subs_epu8
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint16_t
N
>
SaturatedSub
(
const
Vec128
<
uint16_t
N
>
a
const
Vec128
<
uint16_t
N
>
b
)
{
return
Vec128
<
uint16_t
N
>
{
_mm_subs_epu16
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
int8_t
N
>
SaturatedSub
(
const
Vec128
<
int8_t
N
>
a
const
Vec128
<
int8_t
N
>
b
)
{
return
Vec128
<
int8_t
N
>
{
_mm_subs_epi8
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
int16_t
N
>
SaturatedSub
(
const
Vec128
<
int16_t
N
>
a
const
Vec128
<
int16_t
N
>
b
)
{
return
Vec128
<
int16_t
N
>
{
_mm_subs_epi16
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint8_t
N
>
AverageRound
(
const
Vec128
<
uint8_t
N
>
a
const
Vec128
<
uint8_t
N
>
b
)
{
return
Vec128
<
uint8_t
N
>
{
_mm_avg_epu8
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint16_t
N
>
AverageRound
(
const
Vec128
<
uint16_t
N
>
a
const
Vec128
<
uint16_t
N
>
b
)
{
return
Vec128
<
uint16_t
N
>
{
_mm_avg_epu16
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint16_t
N
>
operator
*
(
const
Vec128
<
uint16_t
N
>
a
const
Vec128
<
uint16_t
N
>
b
)
{
return
Vec128
<
uint16_t
N
>
{
_mm_mullo_epi16
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
int16_t
N
>
operator
*
(
const
Vec128
<
int16_t
N
>
a
const
Vec128
<
int16_t
N
>
b
)
{
return
Vec128
<
int16_t
N
>
{
_mm_mullo_epi16
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint16_t
N
>
MulHigh
(
const
Vec128
<
uint16_t
N
>
a
const
Vec128
<
uint16_t
N
>
b
)
{
return
Vec128
<
uint16_t
N
>
{
_mm_mulhi_epu16
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
int16_t
N
>
MulHigh
(
const
Vec128
<
int16_t
N
>
a
const
Vec128
<
int16_t
N
>
b
)
{
return
Vec128
<
int16_t
N
>
{
_mm_mulhi_epi16
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint64_t
(
N
+
1
)
/
2
>
MulEven
(
const
Vec128
<
uint32_t
N
>
a
const
Vec128
<
uint32_t
N
>
b
)
{
return
Vec128
<
uint64_t
(
N
+
1
)
/
2
>
{
_mm_mul_epu32
(
a
.
raw
b
.
raw
)
}
;
}
#
if
HWY_TARGET
=
=
HWY_SSSE3
template
<
size_t
N
HWY_IF_LE64
(
int32_t
N
)
>
HWY_API
Vec128
<
int64_t
(
N
+
1
)
/
2
>
MulEven
(
const
Vec128
<
int32_t
N
>
a
const
Vec128
<
int32_t
N
>
b
)
{
return
Set
(
Simd
<
int64_t
(
N
+
1
)
/
2
0
>
(
)
int64_t
(
GetLane
(
a
)
)
*
GetLane
(
b
)
)
;
}
HWY_API
Vec128
<
int64_t
>
MulEven
(
const
Vec128
<
int32_t
>
a
const
Vec128
<
int32_t
>
b
)
{
alignas
(
16
)
int32_t
a_lanes
[
4
]
;
alignas
(
16
)
int32_t
b_lanes
[
4
]
;
const
Full128
<
int32_t
>
di32
;
Store
(
a
di32
a_lanes
)
;
Store
(
b
di32
b_lanes
)
;
alignas
(
16
)
int64_t
mul
[
2
]
;
mul
[
0
]
=
int64_t
(
a_lanes
[
0
]
)
*
b_lanes
[
0
]
;
mul
[
1
]
=
int64_t
(
a_lanes
[
2
]
)
*
b_lanes
[
2
]
;
return
Load
(
Full128
<
int64_t
>
(
)
mul
)
;
}
#
else
template
<
size_t
N
>
HWY_API
Vec128
<
int64_t
(
N
+
1
)
/
2
>
MulEven
(
const
Vec128
<
int32_t
N
>
a
const
Vec128
<
int32_t
N
>
b
)
{
return
Vec128
<
int64_t
(
N
+
1
)
/
2
>
{
_mm_mul_epi32
(
a
.
raw
b
.
raw
)
}
;
}
#
endif
template
<
size_t
N
>
HWY_API
Vec128
<
uint32_t
N
>
operator
*
(
const
Vec128
<
uint32_t
N
>
a
const
Vec128
<
uint32_t
N
>
b
)
{
#
if
HWY_TARGET
=
=
HWY_SSSE3
const
__m128i
a_x3x1
=
_mm_shuffle_epi32
(
a
.
raw
_MM_SHUFFLE
(
3
3
1
1
)
)
;
const
auto
mullo_x2x0
=
MulEven
(
a
b
)
;
const
__m128i
b_x3x1
=
_mm_shuffle_epi32
(
b
.
raw
_MM_SHUFFLE
(
3
3
1
1
)
)
;
const
auto
mullo_x3x1
=
MulEven
(
Vec128
<
uint32_t
N
>
{
a_x3x1
}
Vec128
<
uint32_t
N
>
{
b_x3x1
}
)
;
const
__m128i
mul_20
=
_mm_shuffle_epi32
(
mullo_x2x0
.
raw
_MM_SHUFFLE
(
2
0
2
0
)
)
;
const
__m128i
mul_31
=
_mm_shuffle_epi32
(
mullo_x3x1
.
raw
_MM_SHUFFLE
(
2
0
2
0
)
)
;
return
Vec128
<
uint32_t
N
>
{
_mm_unpacklo_epi32
(
mul_20
mul_31
)
}
;
#
else
return
Vec128
<
uint32_t
N
>
{
_mm_mullo_epi32
(
a
.
raw
b
.
raw
)
}
;
#
endif
}
template
<
size_t
N
>
HWY_API
Vec128
<
int32_t
N
>
operator
*
(
const
Vec128
<
int32_t
N
>
a
const
Vec128
<
int32_t
N
>
b
)
{
const
DFromV
<
decltype
(
a
)
>
d
;
const
RebindToUnsigned
<
decltype
(
d
)
>
du
;
return
BitCast
(
d
BitCast
(
du
a
)
*
BitCast
(
du
b
)
)
;
}
template
<
int
kBits
size_t
N
>
HWY_API
Vec128
<
uint16_t
N
>
ShiftLeft
(
const
Vec128
<
uint16_t
N
>
v
)
{
return
Vec128
<
uint16_t
N
>
{
_mm_slli_epi16
(
v
.
raw
kBits
)
}
;
}
template
<
int
kBits
size_t
N
>
HWY_API
Vec128
<
uint32_t
N
>
ShiftLeft
(
const
Vec128
<
uint32_t
N
>
v
)
{
return
Vec128
<
uint32_t
N
>
{
_mm_slli_epi32
(
v
.
raw
kBits
)
}
;
}
template
<
int
kBits
size_t
N
>
HWY_API
Vec128
<
uint64_t
N
>
ShiftLeft
(
const
Vec128
<
uint64_t
N
>
v
)
{
return
Vec128
<
uint64_t
N
>
{
_mm_slli_epi64
(
v
.
raw
kBits
)
}
;
}
template
<
int
kBits
size_t
N
>
HWY_API
Vec128
<
int16_t
N
>
ShiftLeft
(
const
Vec128
<
int16_t
N
>
v
)
{
return
Vec128
<
int16_t
N
>
{
_mm_slli_epi16
(
v
.
raw
kBits
)
}
;
}
template
<
int
kBits
size_t
N
>
HWY_API
Vec128
<
int32_t
N
>
ShiftLeft
(
const
Vec128
<
int32_t
N
>
v
)
{
return
Vec128
<
int32_t
N
>
{
_mm_slli_epi32
(
v
.
raw
kBits
)
}
;
}
template
<
int
kBits
size_t
N
>
HWY_API
Vec128
<
int64_t
N
>
ShiftLeft
(
const
Vec128
<
int64_t
N
>
v
)
{
return
Vec128
<
int64_t
N
>
{
_mm_slli_epi64
(
v
.
raw
kBits
)
}
;
}
template
<
int
kBits
typename
T
size_t
N
HWY_IF_LANE_SIZE
(
T
1
)
>
HWY_API
Vec128
<
T
N
>
ShiftLeft
(
const
Vec128
<
T
N
>
v
)
{
const
DFromV
<
decltype
(
v
)
>
d8
;
const
Vec128
<
T
N
>
shifted
{
ShiftLeft
<
kBits
>
(
Vec128
<
MakeWide
<
T
>
>
{
v
.
raw
}
)
.
raw
}
;
return
kBits
=
=
1
?
(
v
+
v
)
:
(
shifted
&
Set
(
d8
static_cast
<
T
>
(
(
0xFF
<
<
kBits
)
&
0xFF
)
)
)
;
}
template
<
int
kBits
size_t
N
>
HWY_API
Vec128
<
uint16_t
N
>
ShiftRight
(
const
Vec128
<
uint16_t
N
>
v
)
{
return
Vec128
<
uint16_t
N
>
{
_mm_srli_epi16
(
v
.
raw
kBits
)
}
;
}
template
<
int
kBits
size_t
N
>
HWY_API
Vec128
<
uint32_t
N
>
ShiftRight
(
const
Vec128
<
uint32_t
N
>
v
)
{
return
Vec128
<
uint32_t
N
>
{
_mm_srli_epi32
(
v
.
raw
kBits
)
}
;
}
template
<
int
kBits
size_t
N
>
HWY_API
Vec128
<
uint64_t
N
>
ShiftRight
(
const
Vec128
<
uint64_t
N
>
v
)
{
return
Vec128
<
uint64_t
N
>
{
_mm_srli_epi64
(
v
.
raw
kBits
)
}
;
}
template
<
int
kBits
size_t
N
>
HWY_API
Vec128
<
uint8_t
N
>
ShiftRight
(
const
Vec128
<
uint8_t
N
>
v
)
{
const
DFromV
<
decltype
(
v
)
>
d8
;
const
Vec128
<
uint8_t
N
>
shifted
{
ShiftRight
<
kBits
>
(
Vec128
<
uint16_t
>
{
v
.
raw
}
)
.
raw
}
;
return
shifted
&
Set
(
d8
0xFF
>
>
kBits
)
;
}
template
<
int
kBits
size_t
N
>
HWY_API
Vec128
<
int16_t
N
>
ShiftRight
(
const
Vec128
<
int16_t
N
>
v
)
{
return
Vec128
<
int16_t
N
>
{
_mm_srai_epi16
(
v
.
raw
kBits
)
}
;
}
template
<
int
kBits
size_t
N
>
HWY_API
Vec128
<
int32_t
N
>
ShiftRight
(
const
Vec128
<
int32_t
N
>
v
)
{
return
Vec128
<
int32_t
N
>
{
_mm_srai_epi32
(
v
.
raw
kBits
)
}
;
}
template
<
int
kBits
size_t
N
>
HWY_API
Vec128
<
int8_t
N
>
ShiftRight
(
const
Vec128
<
int8_t
N
>
v
)
{
const
DFromV
<
decltype
(
v
)
>
di
;
const
RebindToUnsigned
<
decltype
(
di
)
>
du
;
const
auto
shifted
=
BitCast
(
di
ShiftRight
<
kBits
>
(
BitCast
(
du
v
)
)
)
;
const
auto
shifted_sign
=
BitCast
(
di
Set
(
du
0x80
>
>
kBits
)
)
;
return
(
shifted
^
shifted_sign
)
-
shifted_sign
;
}
template
<
int
kBits
size_t
N
>
HWY_API
Vec128
<
uint32_t
N
>
RotateRight
(
const
Vec128
<
uint32_t
N
>
v
)
{
static_assert
(
0
<
=
kBits
&
&
kBits
<
32
"
Invalid
shift
count
"
)
;
#
if
HWY_TARGET
<
=
HWY_AVX3
return
Vec128
<
uint32_t
N
>
{
_mm_ror_epi32
(
v
.
raw
kBits
)
}
;
#
else
if
(
kBits
=
=
0
)
return
v
;
return
Or
(
ShiftRight
<
kBits
>
(
v
)
ShiftLeft
<
HWY_MIN
(
31
32
-
kBits
)
>
(
v
)
)
;
#
endif
}
template
<
int
kBits
size_t
N
>
HWY_API
Vec128
<
uint64_t
N
>
RotateRight
(
const
Vec128
<
uint64_t
N
>
v
)
{
static_assert
(
0
<
=
kBits
&
&
kBits
<
64
"
Invalid
shift
count
"
)
;
#
if
HWY_TARGET
<
=
HWY_AVX3
return
Vec128
<
uint64_t
N
>
{
_mm_ror_epi64
(
v
.
raw
kBits
)
}
;
#
else
if
(
kBits
=
=
0
)
return
v
;
return
Or
(
ShiftRight
<
kBits
>
(
v
)
ShiftLeft
<
HWY_MIN
(
63
64
-
kBits
)
>
(
v
)
)
;
#
endif
}
template
<
size_t
N
>
HWY_API
Vec128
<
int8_t
N
>
BroadcastSignBit
(
const
Vec128
<
int8_t
N
>
v
)
{
const
DFromV
<
decltype
(
v
)
>
d
;
return
VecFromMask
(
v
<
Zero
(
d
)
)
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
int16_t
N
>
BroadcastSignBit
(
const
Vec128
<
int16_t
N
>
v
)
{
return
ShiftRight
<
15
>
(
v
)
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
int32_t
N
>
BroadcastSignBit
(
const
Vec128
<
int32_t
N
>
v
)
{
return
ShiftRight
<
31
>
(
v
)
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
int64_t
N
>
BroadcastSignBit
(
const
Vec128
<
int64_t
N
>
v
)
{
const
DFromV
<
decltype
(
v
)
>
d
;
#
if
HWY_TARGET
<
=
HWY_AVX3
(
void
)
d
;
return
Vec128
<
int64_t
N
>
{
_mm_srai_epi64
(
v
.
raw
63
)
}
;
#
elif
HWY_TARGET
=
=
HWY_AVX2
|
|
HWY_TARGET
=
=
HWY_SSE4
return
VecFromMask
(
v
<
Zero
(
d
)
)
;
#
else
const
RepartitionToNarrow
<
decltype
(
d
)
>
d32
;
const
auto
sign
=
ShiftRight
<
31
>
(
BitCast
(
d32
v
)
)
;
return
Vec128
<
int64_t
N
>
{
_mm_shuffle_epi32
(
sign
.
raw
_MM_SHUFFLE
(
3
3
1
1
)
)
}
;
#
endif
}
template
<
size_t
N
>
HWY_API
Vec128
<
int64_t
N
>
Abs
(
const
Vec128
<
int64_t
N
>
v
)
{
#
if
HWY_TARGET
<
=
HWY_AVX3
return
Vec128
<
int64_t
N
>
{
_mm_abs_epi64
(
v
.
raw
)
}
;
#
else
const
auto
zero
=
Zero
(
DFromV
<
decltype
(
v
)
>
(
)
)
;
return
IfThenElse
(
MaskFromVec
(
BroadcastSignBit
(
v
)
)
zero
-
v
v
)
;
#
endif
}
template
<
int
kBits
size_t
N
>
HWY_API
Vec128
<
int64_t
N
>
ShiftRight
(
const
Vec128
<
int64_t
N
>
v
)
{
#
if
HWY_TARGET
<
=
HWY_AVX3
return
Vec128
<
int64_t
N
>
{
_mm_srai_epi64
(
v
.
raw
kBits
)
}
;
#
else
const
DFromV
<
decltype
(
v
)
>
di
;
const
RebindToUnsigned
<
decltype
(
di
)
>
du
;
const
auto
right
=
BitCast
(
di
ShiftRight
<
kBits
>
(
BitCast
(
du
v
)
)
)
;
const
auto
sign
=
ShiftLeft
<
64
-
kBits
>
(
BroadcastSignBit
(
v
)
)
;
return
right
|
sign
;
#
endif
}
template
<
typename
T
size_t
N
HWY_IF_FLOAT
(
T
)
>
HWY_API
Vec128
<
T
N
>
ZeroIfNegative
(
Vec128
<
T
N
>
v
)
{
const
DFromV
<
decltype
(
v
)
>
d
;
#
if
HWY_TARGET
=
=
HWY_SSSE3
const
RebindToSigned
<
decltype
(
d
)
>
di
;
const
auto
mask
=
MaskFromVec
(
BitCast
(
d
BroadcastSignBit
(
BitCast
(
di
v
)
)
)
)
;
#
else
const
auto
mask
=
MaskFromVec
(
v
)
;
#
endif
return
IfThenElse
(
mask
Zero
(
d
)
v
)
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
int8_t
N
>
IfNegativeThenElse
(
const
Vec128
<
int8_t
N
>
v
const
Vec128
<
int8_t
N
>
yes
const
Vec128
<
int8_t
N
>
no
)
{
return
IfThenElse
(
MaskFromVec
(
v
)
yes
no
)
;
}
template
<
typename
T
size_t
N
HWY_IF_LANE_SIZE
(
T
2
)
>
HWY_API
Vec128
<
T
N
>
IfNegativeThenElse
(
Vec128
<
T
N
>
v
Vec128
<
T
N
>
yes
Vec128
<
T
N
>
no
)
{
static_assert
(
IsSigned
<
T
>
(
)
"
Only
works
for
signed
/
float
"
)
;
const
DFromV
<
decltype
(
v
)
>
d
;
const
RebindToSigned
<
decltype
(
d
)
>
di
;
v
=
BitCast
(
d
BroadcastSignBit
(
BitCast
(
di
v
)
)
)
;
return
IfThenElse
(
MaskFromVec
(
v
)
yes
no
)
;
}
template
<
typename
T
size_t
N
HWY_IF_NOT_LANE_SIZE
(
T
2
)
>
HWY_API
Vec128
<
T
N
>
IfNegativeThenElse
(
Vec128
<
T
N
>
v
Vec128
<
T
N
>
yes
Vec128
<
T
N
>
no
)
{
static_assert
(
IsSigned
<
T
>
(
)
"
Only
works
for
signed
/
float
"
)
;
const
DFromV
<
decltype
(
v
)
>
d
;
const
RebindToFloat
<
decltype
(
d
)
>
df
;
return
BitCast
(
d
IfThenElse
(
MaskFromVec
(
BitCast
(
df
v
)
)
BitCast
(
df
yes
)
BitCast
(
df
no
)
)
)
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint16_t
N
>
ShiftLeftSame
(
const
Vec128
<
uint16_t
N
>
v
const
int
bits
)
{
return
Vec128
<
uint16_t
N
>
{
_mm_sll_epi16
(
v
.
raw
_mm_cvtsi32_si128
(
bits
)
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint32_t
N
>
ShiftLeftSame
(
const
Vec128
<
uint32_t
N
>
v
const
int
bits
)
{
return
Vec128
<
uint32_t
N
>
{
_mm_sll_epi32
(
v
.
raw
_mm_cvtsi32_si128
(
bits
)
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint64_t
N
>
ShiftLeftSame
(
const
Vec128
<
uint64_t
N
>
v
const
int
bits
)
{
return
Vec128
<
uint64_t
N
>
{
_mm_sll_epi64
(
v
.
raw
_mm_cvtsi32_si128
(
bits
)
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
int16_t
N
>
ShiftLeftSame
(
const
Vec128
<
int16_t
N
>
v
const
int
bits
)
{
return
Vec128
<
int16_t
N
>
{
_mm_sll_epi16
(
v
.
raw
_mm_cvtsi32_si128
(
bits
)
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
int32_t
N
>
ShiftLeftSame
(
const
Vec128
<
int32_t
N
>
v
const
int
bits
)
{
return
Vec128
<
int32_t
N
>
{
_mm_sll_epi32
(
v
.
raw
_mm_cvtsi32_si128
(
bits
)
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
int64_t
N
>
ShiftLeftSame
(
const
Vec128
<
int64_t
N
>
v
const
int
bits
)
{
return
Vec128
<
int64_t
N
>
{
_mm_sll_epi64
(
v
.
raw
_mm_cvtsi32_si128
(
bits
)
)
}
;
}
template
<
typename
T
size_t
N
HWY_IF_LANE_SIZE
(
T
1
)
>
HWY_API
Vec128
<
T
N
>
ShiftLeftSame
(
const
Vec128
<
T
N
>
v
const
int
bits
)
{
const
DFromV
<
decltype
(
v
)
>
d8
;
const
Vec128
<
T
N
>
shifted
{
ShiftLeftSame
(
Vec128
<
MakeWide
<
T
>
>
{
v
.
raw
}
bits
)
.
raw
}
;
return
shifted
&
Set
(
d8
static_cast
<
T
>
(
(
0xFF
<
<
bits
)
&
0xFF
)
)
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint16_t
N
>
ShiftRightSame
(
const
Vec128
<
uint16_t
N
>
v
const
int
bits
)
{
return
Vec128
<
uint16_t
N
>
{
_mm_srl_epi16
(
v
.
raw
_mm_cvtsi32_si128
(
bits
)
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint32_t
N
>
ShiftRightSame
(
const
Vec128
<
uint32_t
N
>
v
const
int
bits
)
{
return
Vec128
<
uint32_t
N
>
{
_mm_srl_epi32
(
v
.
raw
_mm_cvtsi32_si128
(
bits
)
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint64_t
N
>
ShiftRightSame
(
const
Vec128
<
uint64_t
N
>
v
const
int
bits
)
{
return
Vec128
<
uint64_t
N
>
{
_mm_srl_epi64
(
v
.
raw
_mm_cvtsi32_si128
(
bits
)
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint8_t
N
>
ShiftRightSame
(
Vec128
<
uint8_t
N
>
v
const
int
bits
)
{
const
DFromV
<
decltype
(
v
)
>
d8
;
const
Vec128
<
uint8_t
N
>
shifted
{
ShiftRightSame
(
Vec128
<
uint16_t
>
{
v
.
raw
}
bits
)
.
raw
}
;
return
shifted
&
Set
(
d8
static_cast
<
uint8_t
>
(
0xFF
>
>
bits
)
)
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
int16_t
N
>
ShiftRightSame
(
const
Vec128
<
int16_t
N
>
v
const
int
bits
)
{
return
Vec128
<
int16_t
N
>
{
_mm_sra_epi16
(
v
.
raw
_mm_cvtsi32_si128
(
bits
)
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
int32_t
N
>
ShiftRightSame
(
const
Vec128
<
int32_t
N
>
v
const
int
bits
)
{
return
Vec128
<
int32_t
N
>
{
_mm_sra_epi32
(
v
.
raw
_mm_cvtsi32_si128
(
bits
)
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
int64_t
N
>
ShiftRightSame
(
const
Vec128
<
int64_t
N
>
v
const
int
bits
)
{
#
if
HWY_TARGET
<
=
HWY_AVX3
return
Vec128
<
int64_t
N
>
{
_mm_sra_epi64
(
v
.
raw
_mm_cvtsi32_si128
(
bits
)
)
}
;
#
else
const
DFromV
<
decltype
(
v
)
>
di
;
const
RebindToUnsigned
<
decltype
(
di
)
>
du
;
const
auto
right
=
BitCast
(
di
ShiftRightSame
(
BitCast
(
du
v
)
bits
)
)
;
const
auto
sign
=
ShiftLeftSame
(
BroadcastSignBit
(
v
)
64
-
bits
)
;
return
right
|
sign
;
#
endif
}
template
<
size_t
N
>
HWY_API
Vec128
<
int8_t
N
>
ShiftRightSame
(
Vec128
<
int8_t
N
>
v
const
int
bits
)
{
const
DFromV
<
decltype
(
v
)
>
di
;
const
RebindToUnsigned
<
decltype
(
di
)
>
du
;
const
auto
shifted
=
BitCast
(
di
ShiftRightSame
(
BitCast
(
du
v
)
bits
)
)
;
const
auto
shifted_sign
=
BitCast
(
di
Set
(
du
static_cast
<
uint8_t
>
(
0x80
>
>
bits
)
)
)
;
return
(
shifted
^
shifted_sign
)
-
shifted_sign
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
float
N
>
operator
*
(
Vec128
<
float
N
>
a
Vec128
<
float
N
>
b
)
{
return
Vec128
<
float
N
>
{
_mm_mul_ps
(
a
.
raw
b
.
raw
)
}
;
}
HWY_API
Vec128
<
float
1
>
operator
*
(
const
Vec128
<
float
1
>
a
const
Vec128
<
float
1
>
b
)
{
return
Vec128
<
float
1
>
{
_mm_mul_ss
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
double
N
>
operator
*
(
const
Vec128
<
double
N
>
a
const
Vec128
<
double
N
>
b
)
{
return
Vec128
<
double
N
>
{
_mm_mul_pd
(
a
.
raw
b
.
raw
)
}
;
}
HWY_API
Vec64
<
double
>
operator
*
(
const
Vec64
<
double
>
a
const
Vec64
<
double
>
b
)
{
return
Vec64
<
double
>
{
_mm_mul_sd
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
float
N
>
operator
/
(
const
Vec128
<
float
N
>
a
const
Vec128
<
float
N
>
b
)
{
return
Vec128
<
float
N
>
{
_mm_div_ps
(
a
.
raw
b
.
raw
)
}
;
}
HWY_API
Vec128
<
float
1
>
operator
/
(
const
Vec128
<
float
1
>
a
const
Vec128
<
float
1
>
b
)
{
return
Vec128
<
float
1
>
{
_mm_div_ss
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
double
N
>
operator
/
(
const
Vec128
<
double
N
>
a
const
Vec128
<
double
N
>
b
)
{
return
Vec128
<
double
N
>
{
_mm_div_pd
(
a
.
raw
b
.
raw
)
}
;
}
HWY_API
Vec64
<
double
>
operator
/
(
const
Vec64
<
double
>
a
const
Vec64
<
double
>
b
)
{
return
Vec64
<
double
>
{
_mm_div_sd
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
float
N
>
ApproximateReciprocal
(
const
Vec128
<
float
N
>
v
)
{
return
Vec128
<
float
N
>
{
_mm_rcp_ps
(
v
.
raw
)
}
;
}
HWY_API
Vec128
<
float
1
>
ApproximateReciprocal
(
const
Vec128
<
float
1
>
v
)
{
return
Vec128
<
float
1
>
{
_mm_rcp_ss
(
v
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
float
N
>
AbsDiff
(
const
Vec128
<
float
N
>
a
const
Vec128
<
float
N
>
b
)
{
return
Abs
(
a
-
b
)
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
float
N
>
MulAdd
(
const
Vec128
<
float
N
>
mul
const
Vec128
<
float
N
>
x
const
Vec128
<
float
N
>
add
)
{
#
if
HWY_TARGET
=
=
HWY_SSSE3
|
|
HWY_TARGET
=
=
HWY_SSE4
return
mul
*
x
+
add
;
#
else
return
Vec128
<
float
N
>
{
_mm_fmadd_ps
(
mul
.
raw
x
.
raw
add
.
raw
)
}
;
#
endif
}
template
<
size_t
N
>
HWY_API
Vec128
<
double
N
>
MulAdd
(
const
Vec128
<
double
N
>
mul
const
Vec128
<
double
N
>
x
const
Vec128
<
double
N
>
add
)
{
#
if
HWY_TARGET
=
=
HWY_SSSE3
|
|
HWY_TARGET
=
=
HWY_SSE4
return
mul
*
x
+
add
;
#
else
return
Vec128
<
double
N
>
{
_mm_fmadd_pd
(
mul
.
raw
x
.
raw
add
.
raw
)
}
;
#
endif
}
template
<
size_t
N
>
HWY_API
Vec128
<
float
N
>
NegMulAdd
(
const
Vec128
<
float
N
>
mul
const
Vec128
<
float
N
>
x
const
Vec128
<
float
N
>
add
)
{
#
if
HWY_TARGET
=
=
HWY_SSSE3
|
|
HWY_TARGET
=
=
HWY_SSE4
return
add
-
mul
*
x
;
#
else
return
Vec128
<
float
N
>
{
_mm_fnmadd_ps
(
mul
.
raw
x
.
raw
add
.
raw
)
}
;
#
endif
}
template
<
size_t
N
>
HWY_API
Vec128
<
double
N
>
NegMulAdd
(
const
Vec128
<
double
N
>
mul
const
Vec128
<
double
N
>
x
const
Vec128
<
double
N
>
add
)
{
#
if
HWY_TARGET
=
=
HWY_SSSE3
|
|
HWY_TARGET
=
=
HWY_SSE4
return
add
-
mul
*
x
;
#
else
return
Vec128
<
double
N
>
{
_mm_fnmadd_pd
(
mul
.
raw
x
.
raw
add
.
raw
)
}
;
#
endif
}
template
<
size_t
N
>
HWY_API
Vec128
<
float
N
>
MulSub
(
const
Vec128
<
float
N
>
mul
const
Vec128
<
float
N
>
x
const
Vec128
<
float
N
>
sub
)
{
#
if
HWY_TARGET
=
=
HWY_SSSE3
|
|
HWY_TARGET
=
=
HWY_SSE4
return
mul
*
x
-
sub
;
#
else
return
Vec128
<
float
N
>
{
_mm_fmsub_ps
(
mul
.
raw
x
.
raw
sub
.
raw
)
}
;
#
endif
}
template
<
size_t
N
>
HWY_API
Vec128
<
double
N
>
MulSub
(
const
Vec128
<
double
N
>
mul
const
Vec128
<
double
N
>
x
const
Vec128
<
double
N
>
sub
)
{
#
if
HWY_TARGET
=
=
HWY_SSSE3
|
|
HWY_TARGET
=
=
HWY_SSE4
return
mul
*
x
-
sub
;
#
else
return
Vec128
<
double
N
>
{
_mm_fmsub_pd
(
mul
.
raw
x
.
raw
sub
.
raw
)
}
;
#
endif
}
template
<
size_t
N
>
HWY_API
Vec128
<
float
N
>
NegMulSub
(
const
Vec128
<
float
N
>
mul
const
Vec128
<
float
N
>
x
const
Vec128
<
float
N
>
sub
)
{
#
if
HWY_TARGET
=
=
HWY_SSSE3
|
|
HWY_TARGET
=
=
HWY_SSE4
return
Neg
(
mul
)
*
x
-
sub
;
#
else
return
Vec128
<
float
N
>
{
_mm_fnmsub_ps
(
mul
.
raw
x
.
raw
sub
.
raw
)
}
;
#
endif
}
template
<
size_t
N
>
HWY_API
Vec128
<
double
N
>
NegMulSub
(
const
Vec128
<
double
N
>
mul
const
Vec128
<
double
N
>
x
const
Vec128
<
double
N
>
sub
)
{
#
if
HWY_TARGET
=
=
HWY_SSSE3
|
|
HWY_TARGET
=
=
HWY_SSE4
return
Neg
(
mul
)
*
x
-
sub
;
#
else
return
Vec128
<
double
N
>
{
_mm_fnmsub_pd
(
mul
.
raw
x
.
raw
sub
.
raw
)
}
;
#
endif
}
template
<
size_t
N
>
HWY_API
Vec128
<
float
N
>
Sqrt
(
const
Vec128
<
float
N
>
v
)
{
return
Vec128
<
float
N
>
{
_mm_sqrt_ps
(
v
.
raw
)
}
;
}
HWY_API
Vec128
<
float
1
>
Sqrt
(
const
Vec128
<
float
1
>
v
)
{
return
Vec128
<
float
1
>
{
_mm_sqrt_ss
(
v
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
double
N
>
Sqrt
(
const
Vec128
<
double
N
>
v
)
{
return
Vec128
<
double
N
>
{
_mm_sqrt_pd
(
v
.
raw
)
}
;
}
HWY_API
Vec64
<
double
>
Sqrt
(
const
Vec64
<
double
>
v
)
{
return
Vec64
<
double
>
{
_mm_sqrt_sd
(
_mm_setzero_pd
(
)
v
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
float
N
>
ApproximateReciprocalSqrt
(
const
Vec128
<
float
N
>
v
)
{
return
Vec128
<
float
N
>
{
_mm_rsqrt_ps
(
v
.
raw
)
}
;
}
HWY_API
Vec128
<
float
1
>
ApproximateReciprocalSqrt
(
const
Vec128
<
float
1
>
v
)
{
return
Vec128
<
float
1
>
{
_mm_rsqrt_ss
(
v
.
raw
)
}
;
}
namespace
detail
{
template
<
typename
T
size_t
N
>
HWY_INLINE
HWY_MAYBE_UNUSED
Vec128
<
T
N
>
MinU
(
const
Vec128
<
T
N
>
a
const
Vec128
<
T
N
>
b
)
{
const
DFromV
<
decltype
(
a
)
>
d
;
const
RebindToUnsigned
<
decltype
(
d
)
>
du
;
const
RebindToSigned
<
decltype
(
d
)
>
di
;
const
auto
msb
=
Set
(
du
static_cast
<
T
>
(
T
(
1
)
<
<
(
sizeof
(
T
)
*
8
-
1
)
)
)
;
const
auto
gt
=
RebindMask
(
du
BitCast
(
di
a
^
msb
)
>
BitCast
(
di
b
^
msb
)
)
;
return
IfThenElse
(
gt
b
a
)
;
}
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint8_t
N
>
Min
(
const
Vec128
<
uint8_t
N
>
a
const
Vec128
<
uint8_t
N
>
b
)
{
return
Vec128
<
uint8_t
N
>
{
_mm_min_epu8
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint16_t
N
>
Min
(
const
Vec128
<
uint16_t
N
>
a
const
Vec128
<
uint16_t
N
>
b
)
{
#
if
HWY_TARGET
=
=
HWY_SSSE3
return
detail
:
:
MinU
(
a
b
)
;
#
else
return
Vec128
<
uint16_t
N
>
{
_mm_min_epu16
(
a
.
raw
b
.
raw
)
}
;
#
endif
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint32_t
N
>
Min
(
const
Vec128
<
uint32_t
N
>
a
const
Vec128
<
uint32_t
N
>
b
)
{
#
if
HWY_TARGET
=
=
HWY_SSSE3
return
detail
:
:
MinU
(
a
b
)
;
#
else
return
Vec128
<
uint32_t
N
>
{
_mm_min_epu32
(
a
.
raw
b
.
raw
)
}
;
#
endif
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint64_t
N
>
Min
(
const
Vec128
<
uint64_t
N
>
a
const
Vec128
<
uint64_t
N
>
b
)
{
#
if
HWY_TARGET
<
=
HWY_AVX3
return
Vec128
<
uint64_t
N
>
{
_mm_min_epu64
(
a
.
raw
b
.
raw
)
}
;
#
else
return
detail
:
:
MinU
(
a
b
)
;
#
endif
}
template
<
size_t
N
>
HWY_API
Vec128
<
int8_t
N
>
Min
(
const
Vec128
<
int8_t
N
>
a
const
Vec128
<
int8_t
N
>
b
)
{
#
if
HWY_TARGET
=
=
HWY_SSSE3
return
IfThenElse
(
a
<
b
a
b
)
;
#
else
return
Vec128
<
int8_t
N
>
{
_mm_min_epi8
(
a
.
raw
b
.
raw
)
}
;
#
endif
}
template
<
size_t
N
>
HWY_API
Vec128
<
int16_t
N
>
Min
(
const
Vec128
<
int16_t
N
>
a
const
Vec128
<
int16_t
N
>
b
)
{
return
Vec128
<
int16_t
N
>
{
_mm_min_epi16
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
int32_t
N
>
Min
(
const
Vec128
<
int32_t
N
>
a
const
Vec128
<
int32_t
N
>
b
)
{
#
if
HWY_TARGET
=
=
HWY_SSSE3
return
IfThenElse
(
a
<
b
a
b
)
;
#
else
return
Vec128
<
int32_t
N
>
{
_mm_min_epi32
(
a
.
raw
b
.
raw
)
}
;
#
endif
}
template
<
size_t
N
>
HWY_API
Vec128
<
int64_t
N
>
Min
(
const
Vec128
<
int64_t
N
>
a
const
Vec128
<
int64_t
N
>
b
)
{
#
if
HWY_TARGET
<
=
HWY_AVX3
return
Vec128
<
int64_t
N
>
{
_mm_min_epi64
(
a
.
raw
b
.
raw
)
}
;
#
else
return
IfThenElse
(
a
<
b
a
b
)
;
#
endif
}
template
<
size_t
N
>
HWY_API
Vec128
<
float
N
>
Min
(
const
Vec128
<
float
N
>
a
const
Vec128
<
float
N
>
b
)
{
return
Vec128
<
float
N
>
{
_mm_min_ps
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
double
N
>
Min
(
const
Vec128
<
double
N
>
a
const
Vec128
<
double
N
>
b
)
{
return
Vec128
<
double
N
>
{
_mm_min_pd
(
a
.
raw
b
.
raw
)
}
;
}
namespace
detail
{
template
<
typename
T
size_t
N
>
HWY_INLINE
HWY_MAYBE_UNUSED
Vec128
<
T
N
>
MaxU
(
const
Vec128
<
T
N
>
a
const
Vec128
<
T
N
>
b
)
{
const
DFromV
<
decltype
(
a
)
>
d
;
const
RebindToUnsigned
<
decltype
(
d
)
>
du
;
const
RebindToSigned
<
decltype
(
d
)
>
di
;
const
auto
msb
=
Set
(
du
static_cast
<
T
>
(
T
(
1
)
<
<
(
sizeof
(
T
)
*
8
-
1
)
)
)
;
const
auto
gt
=
RebindMask
(
du
BitCast
(
di
a
^
msb
)
>
BitCast
(
di
b
^
msb
)
)
;
return
IfThenElse
(
gt
a
b
)
;
}
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint8_t
N
>
Max
(
const
Vec128
<
uint8_t
N
>
a
const
Vec128
<
uint8_t
N
>
b
)
{
return
Vec128
<
uint8_t
N
>
{
_mm_max_epu8
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint16_t
N
>
Max
(
const
Vec128
<
uint16_t
N
>
a
const
Vec128
<
uint16_t
N
>
b
)
{
#
if
HWY_TARGET
=
=
HWY_SSSE3
return
detail
:
:
MaxU
(
a
b
)
;
#
else
return
Vec128
<
uint16_t
N
>
{
_mm_max_epu16
(
a
.
raw
b
.
raw
)
}
;
#
endif
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint32_t
N
>
Max
(
const
Vec128
<
uint32_t
N
>
a
const
Vec128
<
uint32_t
N
>
b
)
{
#
if
HWY_TARGET
=
=
HWY_SSSE3
return
detail
:
:
MaxU
(
a
b
)
;
#
else
return
Vec128
<
uint32_t
N
>
{
_mm_max_epu32
(
a
.
raw
b
.
raw
)
}
;
#
endif
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint64_t
N
>
Max
(
const
Vec128
<
uint64_t
N
>
a
const
Vec128
<
uint64_t
N
>
b
)
{
#
if
HWY_TARGET
<
=
HWY_AVX3
return
Vec128
<
uint64_t
N
>
{
_mm_max_epu64
(
a
.
raw
b
.
raw
)
}
;
#
else
return
detail
:
:
MaxU
(
a
b
)
;
#
endif
}
template
<
size_t
N
>
HWY_API
Vec128
<
int8_t
N
>
Max
(
const
Vec128
<
int8_t
N
>
a
const
Vec128
<
int8_t
N
>
b
)
{
#
if
HWY_TARGET
=
=
HWY_SSSE3
return
IfThenElse
(
a
<
b
b
a
)
;
#
else
return
Vec128
<
int8_t
N
>
{
_mm_max_epi8
(
a
.
raw
b
.
raw
)
}
;
#
endif
}
template
<
size_t
N
>
HWY_API
Vec128
<
int16_t
N
>
Max
(
const
Vec128
<
int16_t
N
>
a
const
Vec128
<
int16_t
N
>
b
)
{
return
Vec128
<
int16_t
N
>
{
_mm_max_epi16
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
int32_t
N
>
Max
(
const
Vec128
<
int32_t
N
>
a
const
Vec128
<
int32_t
N
>
b
)
{
#
if
HWY_TARGET
=
=
HWY_SSSE3
return
IfThenElse
(
a
<
b
b
a
)
;
#
else
return
Vec128
<
int32_t
N
>
{
_mm_max_epi32
(
a
.
raw
b
.
raw
)
}
;
#
endif
}
template
<
size_t
N
>
HWY_API
Vec128
<
int64_t
N
>
Max
(
const
Vec128
<
int64_t
N
>
a
const
Vec128
<
int64_t
N
>
b
)
{
#
if
HWY_TARGET
<
=
HWY_AVX3
return
Vec128
<
int64_t
N
>
{
_mm_max_epi64
(
a
.
raw
b
.
raw
)
}
;
#
else
return
IfThenElse
(
a
<
b
b
a
)
;
#
endif
}
template
<
size_t
N
>
HWY_API
Vec128
<
float
N
>
Max
(
const
Vec128
<
float
N
>
a
const
Vec128
<
float
N
>
b
)
{
return
Vec128
<
float
N
>
{
_mm_max_ps
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
double
N
>
Max
(
const
Vec128
<
double
N
>
a
const
Vec128
<
double
N
>
b
)
{
return
Vec128
<
double
N
>
{
_mm_max_pd
(
a
.
raw
b
.
raw
)
}
;
}
template
<
typename
T
size_t
N
>
HWY_API
void
Stream
(
Vec128
<
T
N
>
v
Simd
<
T
N
0
>
T
*
HWY_RESTRICT
aligned
)
{
_mm_stream_si128
(
reinterpret_cast
<
__m128i
*
>
(
aligned
)
v
.
raw
)
;
}
template
<
size_t
N
>
HWY_API
void
Stream
(
const
Vec128
<
float
N
>
v
Simd
<
float
N
0
>
float
*
HWY_RESTRICT
aligned
)
{
_mm_stream_ps
(
aligned
v
.
raw
)
;
}
template
<
size_t
N
>
HWY_API
void
Stream
(
const
Vec128
<
double
N
>
v
Simd
<
double
N
0
>
double
*
HWY_RESTRICT
aligned
)
{
_mm_stream_pd
(
aligned
v
.
raw
)
;
}
HWY_DIAGNOSTICS
(
push
)
HWY_DIAGNOSTICS_OFF
(
disable
:
4245
4365
ignored
"
-
Wsign
-
conversion
"
)
using
GatherIndex64
=
long
long
int
;
static_assert
(
sizeof
(
GatherIndex64
)
=
=
8
"
Must
be
64
-
bit
type
"
)
;
#
if
HWY_TARGET
<
=
HWY_AVX3
namespace
detail
{
template
<
typename
T
size_t
N
>
HWY_INLINE
void
ScatterOffset
(
hwy
:
:
SizeTag
<
4
>
Vec128
<
T
N
>
v
Simd
<
T
N
0
>
T
*
HWY_RESTRICT
base
const
Vec128
<
int32_t
N
>
offset
)
{
if
(
N
=
=
4
)
{
_mm_i32scatter_epi32
(
base
offset
.
raw
v
.
raw
1
)
;
}
else
{
const
__mmask8
mask
=
(
1u
<
<
N
)
-
1
;
_mm_mask_i32scatter_epi32
(
base
mask
offset
.
raw
v
.
raw
1
)
;
}
}
template
<
typename
T
size_t
N
>
HWY_INLINE
void
ScatterIndex
(
hwy
:
:
SizeTag
<
4
>
Vec128
<
T
N
>
v
Simd
<
T
N
0
>
T
*
HWY_RESTRICT
base
const
Vec128
<
int32_t
N
>
index
)
{
if
(
N
=
=
4
)
{
_mm_i32scatter_epi32
(
base
index
.
raw
v
.
raw
4
)
;
}
else
{
const
__mmask8
mask
=
(
1u
<
<
N
)
-
1
;
_mm_mask_i32scatter_epi32
(
base
mask
index
.
raw
v
.
raw
4
)
;
}
}
template
<
typename
T
size_t
N
>
HWY_INLINE
void
ScatterOffset
(
hwy
:
:
SizeTag
<
8
>
Vec128
<
T
N
>
v
Simd
<
T
N
0
>
T
*
HWY_RESTRICT
base
const
Vec128
<
int64_t
N
>
offset
)
{
if
(
N
=
=
2
)
{
_mm_i64scatter_epi64
(
base
offset
.
raw
v
.
raw
1
)
;
}
else
{
const
__mmask8
mask
=
(
1u
<
<
N
)
-
1
;
_mm_mask_i64scatter_epi64
(
base
mask
offset
.
raw
v
.
raw
1
)
;
}
}
template
<
typename
T
size_t
N
>
HWY_INLINE
void
ScatterIndex
(
hwy
:
:
SizeTag
<
8
>
Vec128
<
T
N
>
v
Simd
<
T
N
0
>
T
*
HWY_RESTRICT
base
const
Vec128
<
int64_t
N
>
index
)
{
if
(
N
=
=
2
)
{
_mm_i64scatter_epi64
(
base
index
.
raw
v
.
raw
8
)
;
}
else
{
const
__mmask8
mask
=
(
1u
<
<
N
)
-
1
;
_mm_mask_i64scatter_epi64
(
base
mask
index
.
raw
v
.
raw
8
)
;
}
}
}
template
<
typename
T
size_t
N
typename
Offset
>
HWY_API
void
ScatterOffset
(
Vec128
<
T
N
>
v
Simd
<
T
N
0
>
d
T
*
HWY_RESTRICT
base
const
Vec128
<
Offset
N
>
offset
)
{
static_assert
(
sizeof
(
T
)
=
=
sizeof
(
Offset
)
"
Must
match
for
portability
"
)
;
return
detail
:
:
ScatterOffset
(
hwy
:
:
SizeTag
<
sizeof
(
T
)
>
(
)
v
d
base
offset
)
;
}
template
<
typename
T
size_t
N
typename
Index
>
HWY_API
void
ScatterIndex
(
Vec128
<
T
N
>
v
Simd
<
T
N
0
>
d
T
*
HWY_RESTRICT
base
const
Vec128
<
Index
N
>
index
)
{
static_assert
(
sizeof
(
T
)
=
=
sizeof
(
Index
)
"
Must
match
for
portability
"
)
;
return
detail
:
:
ScatterIndex
(
hwy
:
:
SizeTag
<
sizeof
(
T
)
>
(
)
v
d
base
index
)
;
}
template
<
size_t
N
>
HWY_API
void
ScatterOffset
(
Vec128
<
float
N
>
v
Simd
<
float
N
0
>
float
*
HWY_RESTRICT
base
const
Vec128
<
int32_t
N
>
offset
)
{
if
(
N
=
=
4
)
{
_mm_i32scatter_ps
(
base
offset
.
raw
v
.
raw
1
)
;
}
else
{
const
__mmask8
mask
=
(
1u
<
<
N
)
-
1
;
_mm_mask_i32scatter_ps
(
base
mask
offset
.
raw
v
.
raw
1
)
;
}
}
template
<
size_t
N
>
HWY_API
void
ScatterIndex
(
Vec128
<
float
N
>
v
Simd
<
float
N
0
>
float
*
HWY_RESTRICT
base
const
Vec128
<
int32_t
N
>
index
)
{
if
(
N
=
=
4
)
{
_mm_i32scatter_ps
(
base
index
.
raw
v
.
raw
4
)
;
}
else
{
const
__mmask8
mask
=
(
1u
<
<
N
)
-
1
;
_mm_mask_i32scatter_ps
(
base
mask
index
.
raw
v
.
raw
4
)
;
}
}
template
<
size_t
N
>
HWY_API
void
ScatterOffset
(
Vec128
<
double
N
>
v
Simd
<
double
N
0
>
double
*
HWY_RESTRICT
base
const
Vec128
<
int64_t
N
>
offset
)
{
if
(
N
=
=
2
)
{
_mm_i64scatter_pd
(
base
offset
.
raw
v
.
raw
1
)
;
}
else
{
const
__mmask8
mask
=
(
1u
<
<
N
)
-
1
;
_mm_mask_i64scatter_pd
(
base
mask
offset
.
raw
v
.
raw
1
)
;
}
}
template
<
size_t
N
>
HWY_API
void
ScatterIndex
(
Vec128
<
double
N
>
v
Simd
<
double
N
0
>
double
*
HWY_RESTRICT
base
const
Vec128
<
int64_t
N
>
index
)
{
if
(
N
=
=
2
)
{
_mm_i64scatter_pd
(
base
index
.
raw
v
.
raw
8
)
;
}
else
{
const
__mmask8
mask
=
(
1u
<
<
N
)
-
1
;
_mm_mask_i64scatter_pd
(
base
mask
index
.
raw
v
.
raw
8
)
;
}
}
#
else
template
<
typename
T
size_t
N
typename
Offset
HWY_IF_LE128
(
T
N
)
>
HWY_API
void
ScatterOffset
(
Vec128
<
T
N
>
v
Simd
<
T
N
0
>
d
T
*
HWY_RESTRICT
base
const
Vec128
<
Offset
N
>
offset
)
{
static_assert
(
sizeof
(
T
)
=
=
sizeof
(
Offset
)
"
Must
match
for
portability
"
)
;
alignas
(
16
)
T
lanes
[
N
]
;
Store
(
v
d
lanes
)
;
alignas
(
16
)
Offset
offset_lanes
[
N
]
;
Store
(
offset
Rebind
<
Offset
decltype
(
d
)
>
(
)
offset_lanes
)
;
uint8_t
*
base_bytes
=
reinterpret_cast
<
uint8_t
*
>
(
base
)
;
for
(
size_t
i
=
0
;
i
<
N
;
+
+
i
)
{
CopyBytes
<
sizeof
(
T
)
>
(
&
lanes
[
i
]
base_bytes
+
offset_lanes
[
i
]
)
;
}
}
template
<
typename
T
size_t
N
typename
Index
HWY_IF_LE128
(
T
N
)
>
HWY_API
void
ScatterIndex
(
Vec128
<
T
N
>
v
Simd
<
T
N
0
>
d
T
*
HWY_RESTRICT
base
const
Vec128
<
Index
N
>
index
)
{
static_assert
(
sizeof
(
T
)
=
=
sizeof
(
Index
)
"
Must
match
for
portability
"
)
;
alignas
(
16
)
T
lanes
[
N
]
;
Store
(
v
d
lanes
)
;
alignas
(
16
)
Index
index_lanes
[
N
]
;
Store
(
index
Rebind
<
Index
decltype
(
d
)
>
(
)
index_lanes
)
;
for
(
size_t
i
=
0
;
i
<
N
;
+
+
i
)
{
base
[
index_lanes
[
i
]
]
=
lanes
[
i
]
;
}
}
#
endif
#
if
HWY_TARGET
=
=
HWY_SSSE3
|
|
HWY_TARGET
=
=
HWY_SSE4
template
<
typename
T
size_t
N
typename
Offset
>
HWY_API
Vec128
<
T
N
>
GatherOffset
(
const
Simd
<
T
N
0
>
d
const
T
*
HWY_RESTRICT
base
const
Vec128
<
Offset
N
>
offset
)
{
static_assert
(
sizeof
(
T
)
=
=
sizeof
(
Offset
)
"
Must
match
for
portability
"
)
;
alignas
(
16
)
Offset
offset_lanes
[
N
]
;
Store
(
offset
Rebind
<
Offset
decltype
(
d
)
>
(
)
offset_lanes
)
;
alignas
(
16
)
T
lanes
[
N
]
;
const
uint8_t
*
base_bytes
=
reinterpret_cast
<
const
uint8_t
*
>
(
base
)
;
for
(
size_t
i
=
0
;
i
<
N
;
+
+
i
)
{
CopyBytes
<
sizeof
(
T
)
>
(
base_bytes
+
offset_lanes
[
i
]
&
lanes
[
i
]
)
;
}
return
Load
(
d
lanes
)
;
}
template
<
typename
T
size_t
N
typename
Index
>
HWY_API
Vec128
<
T
N
>
GatherIndex
(
const
Simd
<
T
N
0
>
d
const
T
*
HWY_RESTRICT
base
const
Vec128
<
Index
N
>
index
)
{
static_assert
(
sizeof
(
T
)
=
=
sizeof
(
Index
)
"
Must
match
for
portability
"
)
;
alignas
(
16
)
Index
index_lanes
[
N
]
;
Store
(
index
Rebind
<
Index
decltype
(
d
)
>
(
)
index_lanes
)
;
alignas
(
16
)
T
lanes
[
N
]
;
for
(
size_t
i
=
0
;
i
<
N
;
+
+
i
)
{
lanes
[
i
]
=
base
[
index_lanes
[
i
]
]
;
}
return
Load
(
d
lanes
)
;
}
#
else
namespace
detail
{
template
<
typename
T
size_t
N
>
HWY_INLINE
Vec128
<
T
N
>
GatherOffset
(
hwy
:
:
SizeTag
<
4
>
Simd
<
T
N
0
>
const
T
*
HWY_RESTRICT
base
const
Vec128
<
int32_t
N
>
offset
)
{
return
Vec128
<
T
N
>
{
_mm_i32gather_epi32
(
reinterpret_cast
<
const
int32_t
*
>
(
base
)
offset
.
raw
1
)
}
;
}
template
<
typename
T
size_t
N
>
HWY_INLINE
Vec128
<
T
N
>
GatherIndex
(
hwy
:
:
SizeTag
<
4
>
Simd
<
T
N
0
>
const
T
*
HWY_RESTRICT
base
const
Vec128
<
int32_t
N
>
index
)
{
return
Vec128
<
T
N
>
{
_mm_i32gather_epi32
(
reinterpret_cast
<
const
int32_t
*
>
(
base
)
index
.
raw
4
)
}
;
}
template
<
typename
T
size_t
N
>
HWY_INLINE
Vec128
<
T
N
>
GatherOffset
(
hwy
:
:
SizeTag
<
8
>
Simd
<
T
N
0
>
const
T
*
HWY_RESTRICT
base
const
Vec128
<
int64_t
N
>
offset
)
{
return
Vec128
<
T
N
>
{
_mm_i64gather_epi64
(
reinterpret_cast
<
const
GatherIndex64
*
>
(
base
)
offset
.
raw
1
)
}
;
}
template
<
typename
T
size_t
N
>
HWY_INLINE
Vec128
<
T
N
>
GatherIndex
(
hwy
:
:
SizeTag
<
8
>
Simd
<
T
N
0
>
const
T
*
HWY_RESTRICT
base
const
Vec128
<
int64_t
N
>
index
)
{
return
Vec128
<
T
N
>
{
_mm_i64gather_epi64
(
reinterpret_cast
<
const
GatherIndex64
*
>
(
base
)
index
.
raw
8
)
}
;
}
}
template
<
typename
T
size_t
N
typename
Offset
>
HWY_API
Vec128
<
T
N
>
GatherOffset
(
Simd
<
T
N
0
>
d
const
T
*
HWY_RESTRICT
base
const
Vec128
<
Offset
N
>
offset
)
{
return
detail
:
:
GatherOffset
(
hwy
:
:
SizeTag
<
sizeof
(
T
)
>
(
)
d
base
offset
)
;
}
template
<
typename
T
size_t
N
typename
Index
>
HWY_API
Vec128
<
T
N
>
GatherIndex
(
Simd
<
T
N
0
>
d
const
T
*
HWY_RESTRICT
base
const
Vec128
<
Index
N
>
index
)
{
return
detail
:
:
GatherIndex
(
hwy
:
:
SizeTag
<
sizeof
(
T
)
>
(
)
d
base
index
)
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
float
N
>
GatherOffset
(
Simd
<
float
N
0
>
const
float
*
HWY_RESTRICT
base
const
Vec128
<
int32_t
N
>
offset
)
{
return
Vec128
<
float
N
>
{
_mm_i32gather_ps
(
base
offset
.
raw
1
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
float
N
>
GatherIndex
(
Simd
<
float
N
0
>
const
float
*
HWY_RESTRICT
base
const
Vec128
<
int32_t
N
>
index
)
{
return
Vec128
<
float
N
>
{
_mm_i32gather_ps
(
base
index
.
raw
4
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
double
N
>
GatherOffset
(
Simd
<
double
N
0
>
const
double
*
HWY_RESTRICT
base
const
Vec128
<
int64_t
N
>
offset
)
{
return
Vec128
<
double
N
>
{
_mm_i64gather_pd
(
base
offset
.
raw
1
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
double
N
>
GatherIndex
(
Simd
<
double
N
0
>
const
double
*
HWY_RESTRICT
base
const
Vec128
<
int64_t
N
>
index
)
{
return
Vec128
<
double
N
>
{
_mm_i64gather_pd
(
base
index
.
raw
8
)
}
;
}
#
endif
HWY_DIAGNOSTICS
(
pop
)
template
<
typename
T
size_t
N
>
HWY_API
Vec128
<
T
N
/
2
>
LowerHalf
(
Simd
<
T
N
/
2
0
>
Vec128
<
T
N
>
v
)
{
return
Vec128
<
T
N
/
2
>
{
v
.
raw
}
;
}
template
<
typename
T
size_t
N
>
HWY_API
Vec128
<
T
N
/
2
>
LowerHalf
(
Vec128
<
T
N
>
v
)
{
return
LowerHalf
(
Simd
<
T
N
/
2
0
>
(
)
v
)
;
}
template
<
int
kBytes
typename
T
size_t
N
>
HWY_API
Vec128
<
T
N
>
ShiftLeftBytes
(
Simd
<
T
N
0
>
Vec128
<
T
N
>
v
)
{
static_assert
(
0
<
=
kBytes
&
&
kBytes
<
=
16
"
Invalid
kBytes
"
)
;
return
Vec128
<
T
N
>
{
_mm_slli_si128
(
v
.
raw
kBytes
)
}
;
}
template
<
int
kBytes
typename
T
size_t
N
>
HWY_API
Vec128
<
T
N
>
ShiftLeftBytes
(
const
Vec128
<
T
N
>
v
)
{
return
ShiftLeftBytes
<
kBytes
>
(
DFromV
<
decltype
(
v
)
>
(
)
v
)
;
}
template
<
int
kLanes
typename
T
size_t
N
>
HWY_API
Vec128
<
T
N
>
ShiftLeftLanes
(
Simd
<
T
N
0
>
d
const
Vec128
<
T
N
>
v
)
{
const
Repartition
<
uint8_t
decltype
(
d
)
>
d8
;
return
BitCast
(
d
ShiftLeftBytes
<
kLanes
*
sizeof
(
T
)
>
(
BitCast
(
d8
v
)
)
)
;
}
template
<
int
kLanes
typename
T
size_t
N
>
HWY_API
Vec128
<
T
N
>
ShiftLeftLanes
(
const
Vec128
<
T
N
>
v
)
{
return
ShiftLeftLanes
<
kLanes
>
(
DFromV
<
decltype
(
v
)
>
(
)
v
)
;
}
template
<
int
kBytes
typename
T
size_t
N
>
HWY_API
Vec128
<
T
N
>
ShiftRightBytes
(
Simd
<
T
N
0
>
Vec128
<
T
N
>
v
)
{
static_assert
(
0
<
=
kBytes
&
&
kBytes
<
=
16
"
Invalid
kBytes
"
)
;
if
(
N
!
=
16
/
sizeof
(
T
)
)
{
const
Vec128
<
T
>
vfull
{
v
.
raw
}
;
v
=
Vec128
<
T
N
>
{
IfThenElseZero
(
FirstN
(
Full128
<
T
>
(
)
N
)
vfull
)
.
raw
}
;
}
return
Vec128
<
T
N
>
{
_mm_srli_si128
(
v
.
raw
kBytes
)
}
;
}
template
<
int
kLanes
typename
T
size_t
N
>
HWY_API
Vec128
<
T
N
>
ShiftRightLanes
(
Simd
<
T
N
0
>
d
const
Vec128
<
T
N
>
v
)
{
const
Repartition
<
uint8_t
decltype
(
d
)
>
d8
;
return
BitCast
(
d
ShiftRightBytes
<
kLanes
*
sizeof
(
T
)
>
(
d8
BitCast
(
d8
v
)
)
)
;
}
template
<
typename
T
>
HWY_API
Vec64
<
T
>
UpperHalf
(
Half
<
Full128
<
T
>
>
Vec128
<
T
>
v
)
{
return
Vec64
<
T
>
{
_mm_unpackhi_epi64
(
v
.
raw
v
.
raw
)
}
;
}
HWY_API
Vec128
<
float
2
>
UpperHalf
(
Full64
<
float
>
Vec128
<
float
>
v
)
{
return
Vec128
<
float
2
>
{
_mm_movehl_ps
(
v
.
raw
v
.
raw
)
}
;
}
HWY_API
Vec64
<
double
>
UpperHalf
(
Full64
<
double
>
Vec128
<
double
>
v
)
{
return
Vec64
<
double
>
{
_mm_unpackhi_pd
(
v
.
raw
v
.
raw
)
}
;
}
template
<
typename
T
size_t
N
HWY_IF_LE64
(
T
N
)
>
HWY_API
Vec128
<
T
(
N
+
1
)
/
2
>
UpperHalf
(
Half
<
Simd
<
T
N
0
>
>
Vec128
<
T
N
>
v
)
{
const
DFromV
<
decltype
(
v
)
>
d
;
const
RebindToUnsigned
<
decltype
(
d
)
>
du
;
const
auto
vu
=
BitCast
(
du
v
)
;
const
auto
upper
=
BitCast
(
d
ShiftRightBytes
<
N
*
sizeof
(
T
)
/
2
>
(
du
vu
)
)
;
return
Vec128
<
T
(
N
+
1
)
/
2
>
{
upper
.
raw
}
;
}
template
<
int
kBytes
typename
T
class
V
=
Vec128
<
T
>
>
HWY_API
V
CombineShiftRightBytes
(
Full128
<
T
>
d
V
hi
V
lo
)
{
const
Repartition
<
uint8_t
decltype
(
d
)
>
d8
;
return
BitCast
(
d
Vec128
<
uint8_t
>
{
_mm_alignr_epi8
(
BitCast
(
d8
hi
)
.
raw
BitCast
(
d8
lo
)
.
raw
kBytes
)
}
)
;
}
template
<
int
kBytes
typename
T
size_t
N
HWY_IF_LE64
(
T
N
)
class
V
=
Vec128
<
T
N
>
>
HWY_API
V
CombineShiftRightBytes
(
Simd
<
T
N
0
>
d
V
hi
V
lo
)
{
constexpr
size_t
kSize
=
N
*
sizeof
(
T
)
;
static_assert
(
0
<
kBytes
&
&
kBytes
<
kSize
"
kBytes
invalid
"
)
;
const
Repartition
<
uint8_t
decltype
(
d
)
>
d8
;
const
Full128
<
uint8_t
>
d_full8
;
using
V8
=
VFromD
<
decltype
(
d_full8
)
>
;
const
V8
hi8
{
BitCast
(
d8
hi
)
.
raw
}
;
const
V8
lo8
=
ShiftLeftBytes
<
16
-
kSize
>
(
V8
{
BitCast
(
d8
lo
)
.
raw
}
)
;
const
V8
r
=
CombineShiftRightBytes
<
16
-
kSize
+
kBytes
>
(
d_full8
hi8
lo8
)
;
return
V
{
BitCast
(
Full128
<
T
>
(
)
r
)
.
raw
}
;
}
template
<
int
kLane
size_t
N
>
HWY_API
Vec128
<
uint16_t
N
>
Broadcast
(
const
Vec128
<
uint16_t
N
>
v
)
{
static_assert
(
0
<
=
kLane
&
&
kLane
<
N
"
Invalid
lane
"
)
;
if
(
kLane
<
4
)
{
const
__m128i
lo
=
_mm_shufflelo_epi16
(
v
.
raw
(
0x55
*
kLane
)
&
0xFF
)
;
return
Vec128
<
uint16_t
N
>
{
_mm_unpacklo_epi64
(
lo
lo
)
}
;
}
else
{
const
__m128i
hi
=
_mm_shufflehi_epi16
(
v
.
raw
(
0x55
*
(
kLane
-
4
)
)
&
0xFF
)
;
return
Vec128
<
uint16_t
N
>
{
_mm_unpackhi_epi64
(
hi
hi
)
}
;
}
}
template
<
int
kLane
size_t
N
>
HWY_API
Vec128
<
uint32_t
N
>
Broadcast
(
const
Vec128
<
uint32_t
N
>
v
)
{
static_assert
(
0
<
=
kLane
&
&
kLane
<
N
"
Invalid
lane
"
)
;
return
Vec128
<
uint32_t
N
>
{
_mm_shuffle_epi32
(
v
.
raw
0x55
*
kLane
)
}
;
}
template
<
int
kLane
size_t
N
>
HWY_API
Vec128
<
uint64_t
N
>
Broadcast
(
const
Vec128
<
uint64_t
N
>
v
)
{
static_assert
(
0
<
=
kLane
&
&
kLane
<
N
"
Invalid
lane
"
)
;
return
Vec128
<
uint64_t
N
>
{
_mm_shuffle_epi32
(
v
.
raw
kLane
?
0xEE
:
0x44
)
}
;
}
template
<
int
kLane
size_t
N
>
HWY_API
Vec128
<
int16_t
N
>
Broadcast
(
const
Vec128
<
int16_t
N
>
v
)
{
static_assert
(
0
<
=
kLane
&
&
kLane
<
N
"
Invalid
lane
"
)
;
if
(
kLane
<
4
)
{
const
__m128i
lo
=
_mm_shufflelo_epi16
(
v
.
raw
(
0x55
*
kLane
)
&
0xFF
)
;
return
Vec128
<
int16_t
N
>
{
_mm_unpacklo_epi64
(
lo
lo
)
}
;
}
else
{
const
__m128i
hi
=
_mm_shufflehi_epi16
(
v
.
raw
(
0x55
*
(
kLane
-
4
)
)
&
0xFF
)
;
return
Vec128
<
int16_t
N
>
{
_mm_unpackhi_epi64
(
hi
hi
)
}
;
}
}
template
<
int
kLane
size_t
N
>
HWY_API
Vec128
<
int32_t
N
>
Broadcast
(
const
Vec128
<
int32_t
N
>
v
)
{
static_assert
(
0
<
=
kLane
&
&
kLane
<
N
"
Invalid
lane
"
)
;
return
Vec128
<
int32_t
N
>
{
_mm_shuffle_epi32
(
v
.
raw
0x55
*
kLane
)
}
;
}
template
<
int
kLane
size_t
N
>
HWY_API
Vec128
<
int64_t
N
>
Broadcast
(
const
Vec128
<
int64_t
N
>
v
)
{
static_assert
(
0
<
=
kLane
&
&
kLane
<
N
"
Invalid
lane
"
)
;
return
Vec128
<
int64_t
N
>
{
_mm_shuffle_epi32
(
v
.
raw
kLane
?
0xEE
:
0x44
)
}
;
}
template
<
int
kLane
size_t
N
>
HWY_API
Vec128
<
float
N
>
Broadcast
(
const
Vec128
<
float
N
>
v
)
{
static_assert
(
0
<
=
kLane
&
&
kLane
<
N
"
Invalid
lane
"
)
;
return
Vec128
<
float
N
>
{
_mm_shuffle_ps
(
v
.
raw
v
.
raw
0x55
*
kLane
)
}
;
}
template
<
int
kLane
size_t
N
>
HWY_API
Vec128
<
double
N
>
Broadcast
(
const
Vec128
<
double
N
>
v
)
{
static_assert
(
0
<
=
kLane
&
&
kLane
<
N
"
Invalid
lane
"
)
;
return
Vec128
<
double
N
>
{
_mm_shuffle_pd
(
v
.
raw
v
.
raw
3
*
kLane
)
}
;
}
template
<
typename
T
size_t
N
typename
TI
size_t
NI
>
HWY_API
Vec128
<
TI
NI
>
TableLookupBytes
(
const
Vec128
<
T
N
>
bytes
const
Vec128
<
TI
NI
>
from
)
{
return
Vec128
<
TI
NI
>
{
_mm_shuffle_epi8
(
bytes
.
raw
from
.
raw
)
}
;
}
template
<
class
V
class
VI
>
HWY_API
VI
TableLookupBytesOr0
(
const
V
bytes
const
VI
from
)
{
return
TableLookupBytes
(
bytes
from
)
;
}
template
<
typename
T
size_t
N
=
16
/
sizeof
(
T
)
>
struct
Indices128
{
__m128i
raw
;
}
;
template
<
typename
T
size_t
N
typename
TI
HWY_IF_LE128
(
T
N
)
HWY_IF_LANE_SIZE
(
T
4
)
>
HWY_API
Indices128
<
T
N
>
IndicesFromVec
(
Simd
<
T
N
0
>
d
Vec128
<
TI
N
>
vec
)
{
static_assert
(
sizeof
(
T
)
=
=
sizeof
(
TI
)
"
Index
size
must
match
lane
"
)
;
#
if
HWY_IS_DEBUG_BUILD
const
Rebind
<
TI
decltype
(
d
)
>
di
;
HWY_DASSERT
(
AllFalse
(
di
Lt
(
vec
Zero
(
di
)
)
)
&
&
AllTrue
(
di
Lt
(
vec
Set
(
di
N
)
)
)
)
;
#
endif
#
if
HWY_TARGET
<
=
HWY_AVX2
(
void
)
d
;
return
Indices128
<
T
N
>
{
vec
.
raw
}
;
#
else
const
Repartition
<
uint8_t
decltype
(
d
)
>
d8
;
using
V8
=
VFromD
<
decltype
(
d8
)
>
;
alignas
(
16
)
constexpr
uint8_t
kByteOffsets
[
16
]
=
{
0
1
2
3
0
1
2
3
0
1
2
3
0
1
2
3
}
;
alignas
(
16
)
constexpr
uint8_t
kBroadcastLaneBytes
[
16
]
=
{
0
0
0
0
4
4
4
4
8
8
8
8
12
12
12
12
}
;
const
V8
lane_indices
=
TableLookupBytes
(
vec
Load
(
d8
kBroadcastLaneBytes
)
)
;
const
Repartition
<
uint16_t
decltype
(
d
)
>
d16
;
const
V8
byte_indices
=
BitCast
(
d8
ShiftLeft
<
2
>
(
BitCast
(
d16
lane_indices
)
)
)
;
return
Indices128
<
T
N
>
{
Add
(
byte_indices
Load
(
d8
kByteOffsets
)
)
.
raw
}
;
#
endif
}
template
<
typename
T
size_t
N
typename
TI
HWY_IF_LE128
(
T
N
)
HWY_IF_LANE_SIZE
(
T
8
)
>
HWY_API
Indices128
<
T
N
>
IndicesFromVec
(
Simd
<
T
N
0
>
d
Vec128
<
TI
N
>
vec
)
{
static_assert
(
sizeof
(
T
)
=
=
sizeof
(
TI
)
"
Index
size
must
match
lane
"
)
;
#
if
HWY_IS_DEBUG_BUILD
const
Rebind
<
TI
decltype
(
d
)
>
di
;
HWY_DASSERT
(
AllFalse
(
di
Lt
(
vec
Zero
(
di
)
)
)
&
&
AllTrue
(
di
Lt
(
vec
Set
(
di
static_cast
<
TI
>
(
N
)
)
)
)
)
;
#
else
(
void
)
d
;
#
endif
return
Indices128
<
T
N
>
{
vec
.
raw
}
;
}
template
<
typename
T
size_t
N
typename
TI
HWY_IF_LE128
(
T
N
)
>
HWY_API
Indices128
<
T
N
>
SetTableIndices
(
Simd
<
T
N
0
>
d
const
TI
*
idx
)
{
const
Rebind
<
TI
decltype
(
d
)
>
di
;
return
IndicesFromVec
(
d
LoadU
(
di
idx
)
)
;
}
template
<
typename
T
size_t
N
HWY_IF_LANE_SIZE
(
T
4
)
>
HWY_API
Vec128
<
T
N
>
TableLookupLanes
(
Vec128
<
T
N
>
v
Indices128
<
T
N
>
idx
)
{
#
if
HWY_TARGET
<
=
HWY_AVX2
const
DFromV
<
decltype
(
v
)
>
d
;
const
RebindToFloat
<
decltype
(
d
)
>
df
;
const
Vec128
<
float
N
>
perm
{
_mm_permutevar_ps
(
BitCast
(
df
v
)
.
raw
idx
.
raw
)
}
;
return
BitCast
(
d
perm
)
;
#
else
return
TableLookupBytes
(
v
Vec128
<
T
N
>
{
idx
.
raw
}
)
;
#
endif
}
template
<
size_t
N
HWY_IF_GE64
(
float
N
)
>
HWY_API
Vec128
<
float
N
>
TableLookupLanes
(
Vec128
<
float
N
>
v
Indices128
<
float
N
>
idx
)
{
#
if
HWY_TARGET
<
=
HWY_AVX2
return
Vec128
<
float
N
>
{
_mm_permutevar_ps
(
v
.
raw
idx
.
raw
)
}
;
#
else
const
DFromV
<
decltype
(
v
)
>
df
;
const
RebindToSigned
<
decltype
(
df
)
>
di
;
return
BitCast
(
df
TableLookupBytes
(
BitCast
(
di
v
)
Vec128
<
int32_t
N
>
{
idx
.
raw
}
)
)
;
#
endif
}
template
<
typename
T
>
HWY_API
Vec128
<
T
1
>
TableLookupLanes
(
Vec128
<
T
1
>
v
Indices128
<
T
1
>
)
{
return
v
;
}
template
<
typename
T
HWY_IF_LANE_SIZE
(
T
8
)
>
HWY_API
Vec128
<
T
>
TableLookupLanes
(
Vec128
<
T
>
v
Indices128
<
T
>
idx
)
{
const
Full128
<
T
>
d
;
Vec128
<
int64_t
>
vidx
{
idx
.
raw
}
;
#
if
HWY_TARGET
<
=
HWY_AVX2
vidx
+
=
vidx
;
const
Full128
<
double
>
df
;
return
BitCast
(
d
Vec128
<
double
>
{
_mm_permutevar_pd
(
BitCast
(
df
v
)
.
raw
vidx
.
raw
)
}
)
;
#
else
const
Full128
<
int64_t
>
di
;
const
Vec128
<
int64_t
>
same
=
(
vidx
^
Iota
(
di
0
)
)
-
Set
(
di
1
)
;
const
Mask128
<
T
>
mask_same
=
RebindMask
(
d
MaskFromVec
(
same
)
)
;
return
IfThenElse
(
mask_same
v
Shuffle01
(
v
)
)
;
#
endif
}
HWY_API
Vec128
<
double
>
TableLookupLanes
(
Vec128
<
double
>
v
Indices128
<
double
>
idx
)
{
Vec128
<
int64_t
>
vidx
{
idx
.
raw
}
;
#
if
HWY_TARGET
<
=
HWY_AVX2
vidx
+
=
vidx
;
return
Vec128
<
double
>
{
_mm_permutevar_pd
(
v
.
raw
vidx
.
raw
)
}
;
#
else
const
Full128
<
double
>
d
;
const
Full128
<
int64_t
>
di
;
const
Vec128
<
int64_t
>
same
=
(
vidx
^
Iota
(
di
0
)
)
-
Set
(
di
1
)
;
const
Mask128
<
double
>
mask_same
=
RebindMask
(
d
MaskFromVec
(
same
)
)
;
return
IfThenElse
(
mask_same
v
Shuffle01
(
v
)
)
;
#
endif
}
template
<
typename
T
>
HWY_API
Vec128
<
T
>
ReverseBlocks
(
Full128
<
T
>
const
Vec128
<
T
>
v
)
{
return
v
;
}
template
<
typename
T
>
HWY_API
Vec128
<
T
1
>
Reverse
(
Simd
<
T
1
0
>
const
Vec128
<
T
1
>
v
)
{
return
v
;
}
template
<
typename
T
HWY_IF_LANE_SIZE
(
T
4
)
>
HWY_API
Vec128
<
T
2
>
Reverse
(
Full64
<
T
>
const
Vec128
<
T
2
>
v
)
{
return
Vec128
<
T
2
>
{
Shuffle2301
(
Vec128
<
T
>
{
v
.
raw
}
)
.
raw
}
;
}
template
<
typename
T
HWY_IF_LANE_SIZE
(
T
8
)
>
HWY_API
Vec128
<
T
>
Reverse
(
Full128
<
T
>
const
Vec128
<
T
>
v
)
{
return
Shuffle01
(
v
)
;
}
template
<
typename
T
HWY_IF_LANE_SIZE
(
T
4
)
>
HWY_API
Vec128
<
T
>
Reverse
(
Full128
<
T
>
const
Vec128
<
T
>
v
)
{
return
Shuffle0123
(
v
)
;
}
template
<
typename
T
size_t
N
HWY_IF_LANE_SIZE
(
T
2
)
>
HWY_API
Vec128
<
T
N
>
Reverse
(
Simd
<
T
N
0
>
d
const
Vec128
<
T
N
>
v
)
{
#
if
HWY_TARGET
<
=
HWY_AVX3
if
(
N
=
=
1
)
return
v
;
if
(
N
=
=
2
)
{
const
Repartition
<
uint32_t
decltype
(
d
)
>
du32
;
return
BitCast
(
d
RotateRight
<
16
>
(
BitCast
(
du32
v
)
)
)
;
}
const
RebindToSigned
<
decltype
(
d
)
>
di
;
alignas
(
16
)
constexpr
int16_t
kReverse
[
8
]
=
{
7
6
5
4
3
2
1
0
}
;
const
Vec128
<
int16_t
N
>
idx
=
Load
(
di
kReverse
+
(
N
=
=
8
?
0
:
4
)
)
;
return
BitCast
(
d
Vec128
<
int16_t
N
>
{
_mm_permutexvar_epi16
(
idx
.
raw
BitCast
(
di
v
)
.
raw
)
}
)
;
#
else
const
RepartitionToWide
<
RebindToUnsigned
<
decltype
(
d
)
>
>
du32
;
return
BitCast
(
d
RotateRight
<
16
>
(
Reverse
(
du32
BitCast
(
du32
v
)
)
)
)
;
#
endif
}
template
<
typename
T
size_t
N
HWY_IF_LANE_SIZE
(
T
2
)
>
HWY_API
Vec128
<
T
N
>
Reverse2
(
Simd
<
T
N
0
>
d
const
Vec128
<
T
N
>
v
)
{
const
Repartition
<
uint32_t
decltype
(
d
)
>
du32
;
return
BitCast
(
d
RotateRight
<
16
>
(
BitCast
(
du32
v
)
)
)
;
}
template
<
typename
T
size_t
N
HWY_IF_LANE_SIZE
(
T
4
)
>
HWY_API
Vec128
<
T
N
>
Reverse2
(
Simd
<
T
N
0
>
const
Vec128
<
T
N
>
v
)
{
return
Shuffle2301
(
v
)
;
}
template
<
typename
T
size_t
N
HWY_IF_LANE_SIZE
(
T
8
)
>
HWY_API
Vec128
<
T
N
>
Reverse2
(
Simd
<
T
N
0
>
const
Vec128
<
T
N
>
v
)
{
return
Shuffle01
(
v
)
;
}
template
<
typename
T
size_t
N
HWY_IF_LANE_SIZE
(
T
2
)
>
HWY_API
Vec128
<
T
N
>
Reverse4
(
Simd
<
T
N
0
>
d
const
Vec128
<
T
N
>
v
)
{
const
RebindToSigned
<
decltype
(
d
)
>
di
;
if
(
N
=
=
4
)
{
return
BitCast
(
d
Vec128
<
int16_t
N
>
{
_mm_shufflelo_epi16
(
BitCast
(
di
v
)
.
raw
_MM_SHUFFLE
(
0
1
2
3
)
)
}
)
;
}
#
if
HWY_TARGET
<
=
HWY_AVX3
alignas
(
16
)
constexpr
int16_t
kReverse4
[
8
]
=
{
3
2
1
0
7
6
5
4
}
;
const
Vec128
<
int16_t
N
>
idx
=
Load
(
di
kReverse4
)
;
return
BitCast
(
d
Vec128
<
int16_t
N
>
{
_mm_permutexvar_epi16
(
idx
.
raw
BitCast
(
di
v
)
.
raw
)
}
)
;
#
else
const
RepartitionToWide
<
decltype
(
di
)
>
dw
;
return
Reverse2
(
d
BitCast
(
d
Shuffle2301
(
BitCast
(
dw
v
)
)
)
)
;
#
endif
}
template
<
typename
T
HWY_IF_LANE_SIZE
(
T
4
)
>
HWY_API
Vec128
<
T
>
Reverse4
(
Full128
<
T
>
const
Vec128
<
T
>
v
)
{
return
Shuffle0123
(
v
)
;
}
template
<
typename
T
size_t
N
HWY_IF_LANE_SIZE
(
T
8
)
>
HWY_API
Vec128
<
T
N
>
Reverse4
(
Simd
<
T
N
0
>
Vec128
<
T
N
>
)
{
HWY_ASSERT
(
0
)
;
}
template
<
typename
T
size_t
N
HWY_IF_LANE_SIZE
(
T
2
)
>
HWY_API
Vec128
<
T
N
>
Reverse8
(
Simd
<
T
N
0
>
d
const
Vec128
<
T
N
>
v
)
{
#
if
HWY_TARGET
<
=
HWY_AVX3
const
RebindToSigned
<
decltype
(
d
)
>
di
;
alignas
(
32
)
constexpr
int16_t
kReverse8
[
16
]
=
{
7
6
5
4
3
2
1
0
15
14
13
12
11
10
9
8
}
;
const
Vec128
<
int16_t
N
>
idx
=
Load
(
di
kReverse8
)
;
return
BitCast
(
d
Vec128
<
int16_t
N
>
{
_mm_permutexvar_epi16
(
idx
.
raw
BitCast
(
di
v
)
.
raw
)
}
)
;
#
else
const
RepartitionToWide
<
decltype
(
d
)
>
dw
;
return
Reverse2
(
d
BitCast
(
d
Shuffle0123
(
BitCast
(
dw
v
)
)
)
)
;
#
endif
}
template
<
typename
T
size_t
N
HWY_IF_NOT_LANE_SIZE
(
T
2
)
>
HWY_API
Vec128
<
T
N
>
Reverse8
(
Simd
<
T
N
0
>
Vec128
<
T
N
>
)
{
HWY_ASSERT
(
0
)
;
}
template
<
size_t
N
HWY_IF_LE128
(
uint8_t
N
)
>
HWY_API
Vec128
<
uint8_t
N
>
InterleaveLower
(
const
Vec128
<
uint8_t
N
>
a
const
Vec128
<
uint8_t
N
>
b
)
{
return
Vec128
<
uint8_t
N
>
{
_mm_unpacklo_epi8
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
HWY_IF_LE128
(
uint16_t
N
)
>
HWY_API
Vec128
<
uint16_t
N
>
InterleaveLower
(
const
Vec128
<
uint16_t
N
>
a
const
Vec128
<
uint16_t
N
>
b
)
{
return
Vec128
<
uint16_t
N
>
{
_mm_unpacklo_epi16
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
HWY_IF_LE128
(
uint32_t
N
)
>
HWY_API
Vec128
<
uint32_t
N
>
InterleaveLower
(
const
Vec128
<
uint32_t
N
>
a
const
Vec128
<
uint32_t
N
>
b
)
{
return
Vec128
<
uint32_t
N
>
{
_mm_unpacklo_epi32
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
HWY_IF_LE128
(
uint64_t
N
)
>
HWY_API
Vec128
<
uint64_t
N
>
InterleaveLower
(
const
Vec128
<
uint64_t
N
>
a
const
Vec128
<
uint64_t
N
>
b
)
{
return
Vec128
<
uint64_t
N
>
{
_mm_unpacklo_epi64
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
HWY_IF_LE128
(
int8_t
N
)
>
HWY_API
Vec128
<
int8_t
N
>
InterleaveLower
(
const
Vec128
<
int8_t
N
>
a
const
Vec128
<
int8_t
N
>
b
)
{
return
Vec128
<
int8_t
N
>
{
_mm_unpacklo_epi8
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
HWY_IF_LE128
(
int16_t
N
)
>
HWY_API
Vec128
<
int16_t
N
>
InterleaveLower
(
const
Vec128
<
int16_t
N
>
a
const
Vec128
<
int16_t
N
>
b
)
{
return
Vec128
<
int16_t
N
>
{
_mm_unpacklo_epi16
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
HWY_IF_LE128
(
int32_t
N
)
>
HWY_API
Vec128
<
int32_t
N
>
InterleaveLower
(
const
Vec128
<
int32_t
N
>
a
const
Vec128
<
int32_t
N
>
b
)
{
return
Vec128
<
int32_t
N
>
{
_mm_unpacklo_epi32
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
HWY_IF_LE128
(
int64_t
N
)
>
HWY_API
Vec128
<
int64_t
N
>
InterleaveLower
(
const
Vec128
<
int64_t
N
>
a
const
Vec128
<
int64_t
N
>
b
)
{
return
Vec128
<
int64_t
N
>
{
_mm_unpacklo_epi64
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
HWY_IF_LE128
(
float
N
)
>
HWY_API
Vec128
<
float
N
>
InterleaveLower
(
const
Vec128
<
float
N
>
a
const
Vec128
<
float
N
>
b
)
{
return
Vec128
<
float
N
>
{
_mm_unpacklo_ps
(
a
.
raw
b
.
raw
)
}
;
}
template
<
size_t
N
HWY_IF_LE128
(
double
N
)
>
HWY_API
Vec128
<
double
N
>
InterleaveLower
(
const
Vec128
<
double
N
>
a
const
Vec128
<
double
N
>
b
)
{
return
Vec128
<
double
N
>
{
_mm_unpacklo_pd
(
a
.
raw
b
.
raw
)
}
;
}
template
<
class
V
>
HWY_API
V
InterleaveLower
(
DFromV
<
V
>
V
a
V
b
)
{
return
InterleaveLower
(
a
b
)
;
}
namespace
detail
{
HWY_API
Vec128
<
uint8_t
>
InterleaveUpper
(
const
Vec128
<
uint8_t
>
a
const
Vec128
<
uint8_t
>
b
)
{
return
Vec128
<
uint8_t
>
{
_mm_unpackhi_epi8
(
a
.
raw
b
.
raw
)
}
;
}
HWY_API
Vec128
<
uint16_t
>
InterleaveUpper
(
const
Vec128
<
uint16_t
>
a
const
Vec128
<
uint16_t
>
b
)
{
return
Vec128
<
uint16_t
>
{
_mm_unpackhi_epi16
(
a
.
raw
b
.
raw
)
}
;
}
HWY_API
Vec128
<
uint32_t
>
InterleaveUpper
(
const
Vec128
<
uint32_t
>
a
const
Vec128
<
uint32_t
>
b
)
{
return
Vec128
<
uint32_t
>
{
_mm_unpackhi_epi32
(
a
.
raw
b
.
raw
)
}
;
}
HWY_API
Vec128
<
uint64_t
>
InterleaveUpper
(
const
Vec128
<
uint64_t
>
a
const
Vec128
<
uint64_t
>
b
)
{
return
Vec128
<
uint64_t
>
{
_mm_unpackhi_epi64
(
a
.
raw
b
.
raw
)
}
;
}
HWY_API
Vec128
<
int8_t
>
InterleaveUpper
(
const
Vec128
<
int8_t
>
a
const
Vec128
<
int8_t
>
b
)
{
return
Vec128
<
int8_t
>
{
_mm_unpackhi_epi8
(
a
.
raw
b
.
raw
)
}
;
}
HWY_API
Vec128
<
int16_t
>
InterleaveUpper
(
const
Vec128
<
int16_t
>
a
const
Vec128
<
int16_t
>
b
)
{
return
Vec128
<
int16_t
>
{
_mm_unpackhi_epi16
(
a
.
raw
b
.
raw
)
}
;
}
HWY_API
Vec128
<
int32_t
>
InterleaveUpper
(
const
Vec128
<
int32_t
>
a
const
Vec128
<
int32_t
>
b
)
{
return
Vec128
<
int32_t
>
{
_mm_unpackhi_epi32
(
a
.
raw
b
.
raw
)
}
;
}
HWY_API
Vec128
<
int64_t
>
InterleaveUpper
(
const
Vec128
<
int64_t
>
a
const
Vec128
<
int64_t
>
b
)
{
return
Vec128
<
int64_t
>
{
_mm_unpackhi_epi64
(
a
.
raw
b
.
raw
)
}
;
}
HWY_API
Vec128
<
float
>
InterleaveUpper
(
const
Vec128
<
float
>
a
const
Vec128
<
float
>
b
)
{
return
Vec128
<
float
>
{
_mm_unpackhi_ps
(
a
.
raw
b
.
raw
)
}
;
}
HWY_API
Vec128
<
double
>
InterleaveUpper
(
const
Vec128
<
double
>
a
const
Vec128
<
double
>
b
)
{
return
Vec128
<
double
>
{
_mm_unpackhi_pd
(
a
.
raw
b
.
raw
)
}
;
}
}
template
<
typename
T
class
V
=
Vec128
<
T
>
>
HWY_API
V
InterleaveUpper
(
Full128
<
T
>
V
a
V
b
)
{
return
detail
:
:
InterleaveUpper
(
a
b
)
;
}
template
<
typename
T
size_t
N
HWY_IF_LE64
(
T
N
)
class
V
=
Vec128
<
T
N
>
>
HWY_API
V
InterleaveUpper
(
Simd
<
T
N
0
>
d
V
a
V
b
)
{
const
Half
<
decltype
(
d
)
>
d2
;
return
InterleaveLower
(
d
V
{
UpperHalf
(
d2
a
)
.
raw
}
V
{
UpperHalf
(
d2
b
)
.
raw
}
)
;
}
template
<
class
V
class
DW
=
RepartitionToWide
<
DFromV
<
V
>
>
>
HWY_API
VFromD
<
DW
>
ZipLower
(
V
a
V
b
)
{
return
BitCast
(
DW
(
)
InterleaveLower
(
a
b
)
)
;
}
template
<
class
V
class
D
=
DFromV
<
V
>
class
DW
=
RepartitionToWide
<
D
>
>
HWY_API
VFromD
<
DW
>
ZipLower
(
DW
dw
V
a
V
b
)
{
return
BitCast
(
dw
InterleaveLower
(
D
(
)
a
b
)
)
;
}
template
<
class
V
class
D
=
DFromV
<
V
>
class
DW
=
RepartitionToWide
<
D
>
>
HWY_API
VFromD
<
DW
>
ZipUpper
(
DW
dw
V
a
V
b
)
{
return
BitCast
(
dw
InterleaveUpper
(
D
(
)
a
b
)
)
;
}
template
<
typename
T
size_t
N
HWY_IF_LE128
(
T
N
)
>
HWY_API
Vec128
<
T
N
>
Combine
(
Simd
<
T
N
0
>
d
Vec128
<
T
N
/
2
>
hi_half
Vec128
<
T
N
/
2
>
lo_half
)
{
const
Half
<
decltype
(
d
)
>
d2
;
const
RebindToUnsigned
<
decltype
(
d2
)
>
du2
;
using
VU
=
Vec128
<
UnsignedFromSize
<
N
*
sizeof
(
T
)
/
2
>
2
>
;
const
VU
lo
{
BitCast
(
du2
lo_half
)
.
raw
}
;
const
VU
hi
{
BitCast
(
du2
hi_half
)
.
raw
}
;
return
BitCast
(
d
InterleaveLower
(
lo
hi
)
)
;
}
template
<
typename
T
HWY_IF_NOT_FLOAT
(
T
)
>
HWY_API
Vec128
<
T
>
ZeroExtendVector
(
Full128
<
T
>
Vec64
<
T
>
lo
)
{
return
Vec128
<
T
>
{
_mm_move_epi64
(
lo
.
raw
)
}
;
}
template
<
typename
T
HWY_IF_FLOAT
(
T
)
>
HWY_API
Vec128
<
T
>
ZeroExtendVector
(
Full128
<
T
>
d
Vec64
<
T
>
lo
)
{
const
RebindToUnsigned
<
decltype
(
d
)
>
du
;
return
BitCast
(
d
ZeroExtendVector
(
du
BitCast
(
Half
<
decltype
(
du
)
>
(
)
lo
)
)
)
;
}
template
<
typename
T
size_t
N
HWY_IF_LE64
(
T
N
)
>
HWY_API
Vec128
<
T
N
>
ZeroExtendVector
(
Simd
<
T
N
0
>
d
Vec128
<
T
N
/
2
>
lo
)
{
return
IfThenElseZero
(
FirstN
(
d
N
/
2
)
Vec128
<
T
N
>
{
lo
.
raw
}
)
;
}
template
<
typename
T
>
HWY_API
Vec128
<
T
>
ConcatLowerLower
(
Full128
<
T
>
d
Vec128
<
T
>
hi
Vec128
<
T
>
lo
)
{
const
Repartition
<
uint64_t
decltype
(
d
)
>
d64
;
return
BitCast
(
d
InterleaveLower
(
BitCast
(
d64
lo
)
BitCast
(
d64
hi
)
)
)
;
}
template
<
typename
T
>
HWY_API
Vec128
<
T
>
ConcatUpperUpper
(
Full128
<
T
>
d
Vec128
<
T
>
hi
Vec128
<
T
>
lo
)
{
const
Repartition
<
uint64_t
decltype
(
d
)
>
d64
;
return
BitCast
(
d
InterleaveUpper
(
d64
BitCast
(
d64
lo
)
BitCast
(
d64
hi
)
)
)
;
}
template
<
typename
T
>
HWY_API
Vec128
<
T
>
ConcatLowerUpper
(
Full128
<
T
>
d
const
Vec128
<
T
>
hi
const
Vec128
<
T
>
lo
)
{
return
CombineShiftRightBytes
<
8
>
(
d
hi
lo
)
;
}
template
<
typename
T
>
HWY_API
Vec128
<
T
>
ConcatUpperLower
(
Full128
<
T
>
d
Vec128
<
T
>
hi
Vec128
<
T
>
lo
)
{
#
if
HWY_TARGET
=
=
HWY_SSSE3
const
Full128
<
double
>
dd
;
const
__m128d
concat
=
_mm_move_sd
(
BitCast
(
dd
hi
)
.
raw
BitCast
(
dd
lo
)
.
raw
)
;
return
BitCast
(
d
Vec128
<
double
>
{
concat
}
)
;
#
else
(
void
)
d
;
return
Vec128
<
T
>
{
_mm_blend_epi16
(
hi
.
raw
lo
.
raw
0x0F
)
}
;
#
endif
}
HWY_API
Vec128
<
float
>
ConcatUpperLower
(
Full128
<
float
>
const
Vec128
<
float
>
hi
const
Vec128
<
float
>
lo
)
{
return
Vec128
<
float
>
{
_mm_shuffle_ps
(
lo
.
raw
hi
.
raw
_MM_SHUFFLE
(
3
2
1
0
)
)
}
;
}
HWY_API
Vec128
<
double
>
ConcatUpperLower
(
Full128
<
double
>
const
Vec128
<
double
>
hi
const
Vec128
<
double
>
lo
)
{
return
Vec128
<
double
>
{
_mm_shuffle_pd
(
lo
.
raw
hi
.
raw
_MM_SHUFFLE2
(
1
0
)
)
}
;
}
template
<
typename
T
size_t
N
HWY_IF_LE64
(
T
N
)
>
HWY_API
Vec128
<
T
N
>
ConcatLowerLower
(
Simd
<
T
N
0
>
d
Vec128
<
T
N
>
hi
Vec128
<
T
N
>
lo
)
{
const
Half
<
decltype
(
d
)
>
d2
;
return
Combine
(
d
LowerHalf
(
d2
hi
)
LowerHalf
(
d2
lo
)
)
;
}
template
<
typename
T
size_t
N
HWY_IF_LE64
(
T
N
)
>
HWY_API
Vec128
<
T
N
>
ConcatUpperUpper
(
Simd
<
T
N
0
>
d
Vec128
<
T
N
>
hi
Vec128
<
T
N
>
lo
)
{
const
Half
<
decltype
(
d
)
>
d2
;
return
Combine
(
d
UpperHalf
(
d2
hi
)
UpperHalf
(
d2
lo
)
)
;
}
template
<
typename
T
size_t
N
HWY_IF_LE64
(
T
N
)
>
HWY_API
Vec128
<
T
N
>
ConcatLowerUpper
(
Simd
<
T
N
0
>
d
const
Vec128
<
T
N
>
hi
const
Vec128
<
T
N
>
lo
)
{
const
Half
<
decltype
(
d
)
>
d2
;
return
Combine
(
d
LowerHalf
(
d2
hi
)
UpperHalf
(
d2
lo
)
)
;
}
template
<
typename
T
size_t
N
HWY_IF_LE64
(
T
N
)
>
HWY_API
Vec128
<
T
N
>
ConcatUpperLower
(
Simd
<
T
N
0
>
d
Vec128
<
T
N
>
hi
Vec128
<
T
N
>
lo
)
{
const
Half
<
decltype
(
d
)
>
d2
;
return
Combine
(
d
UpperHalf
(
d2
hi
)
LowerHalf
(
d2
lo
)
)
;
}
template
<
typename
T
HWY_IF_LANE_SIZE
(
T
4
)
>
HWY_API
Vec128
<
T
>
ConcatOdd
(
Full128
<
T
>
d
Vec128
<
T
>
hi
Vec128
<
T
>
lo
)
{
const
RebindToFloat
<
decltype
(
d
)
>
df
;
return
BitCast
(
d
Vec128
<
float
>
{
_mm_shuffle_ps
(
BitCast
(
df
lo
)
.
raw
BitCast
(
df
hi
)
.
raw
_MM_SHUFFLE
(
3
1
3
1
)
)
}
)
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
float
>
ConcatOdd
(
Full128
<
float
>
Vec128
<
float
>
hi
Vec128
<
float
>
lo
)
{
return
Vec128
<
float
>
{
_mm_shuffle_ps
(
lo
.
raw
hi
.
raw
_MM_SHUFFLE
(
3
1
3
1
)
)
}
;
}
template
<
typename
T
HWY_IF_LANE_SIZE
(
T
4
)
>
HWY_API
Vec128
<
T
2
>
ConcatOdd
(
Full64
<
T
>
d
Vec128
<
T
2
>
hi
Vec128
<
T
2
>
lo
)
{
return
InterleaveUpper
(
d
lo
hi
)
;
}
template
<
typename
T
HWY_IF_LANE_SIZE
(
T
8
)
>
HWY_API
Vec128
<
T
>
ConcatOdd
(
Full128
<
T
>
d
Vec128
<
T
>
hi
Vec128
<
T
>
lo
)
{
return
InterleaveUpper
(
d
lo
hi
)
;
}
template
<
typename
T
HWY_IF_LANE_SIZE
(
T
4
)
>
HWY_API
Vec128
<
T
>
ConcatEven
(
Full128
<
T
>
d
Vec128
<
T
>
hi
Vec128
<
T
>
lo
)
{
const
RebindToFloat
<
decltype
(
d
)
>
df
;
return
BitCast
(
d
Vec128
<
float
>
{
_mm_shuffle_ps
(
BitCast
(
df
lo
)
.
raw
BitCast
(
df
hi
)
.
raw
_MM_SHUFFLE
(
2
0
2
0
)
)
}
)
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
float
>
ConcatEven
(
Full128
<
float
>
Vec128
<
float
>
hi
Vec128
<
float
>
lo
)
{
return
Vec128
<
float
>
{
_mm_shuffle_ps
(
lo
.
raw
hi
.
raw
_MM_SHUFFLE
(
2
0
2
0
)
)
}
;
}
template
<
typename
T
HWY_IF_LANE_SIZE
(
T
4
)
>
HWY_API
Vec128
<
T
2
>
ConcatEven
(
Full64
<
T
>
d
Vec128
<
T
2
>
hi
Vec128
<
T
2
>
lo
)
{
return
InterleaveLower
(
d
lo
hi
)
;
}
template
<
typename
T
HWY_IF_LANE_SIZE
(
T
8
)
>
HWY_API
Vec128
<
T
>
ConcatEven
(
Full128
<
T
>
d
Vec128
<
T
>
hi
Vec128
<
T
>
lo
)
{
return
InterleaveLower
(
d
lo
hi
)
;
}
template
<
typename
T
size_t
N
HWY_IF_LANE_SIZE
(
T
4
)
>
HWY_API
Vec128
<
T
N
>
DupEven
(
Vec128
<
T
N
>
v
)
{
return
Vec128
<
T
N
>
{
_mm_shuffle_epi32
(
v
.
raw
_MM_SHUFFLE
(
2
2
0
0
)
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
float
N
>
DupEven
(
Vec128
<
float
N
>
v
)
{
return
Vec128
<
float
N
>
{
_mm_shuffle_ps
(
v
.
raw
v
.
raw
_MM_SHUFFLE
(
2
2
0
0
)
)
}
;
}
template
<
typename
T
size_t
N
HWY_IF_LANE_SIZE
(
T
8
)
>
HWY_API
Vec128
<
T
N
>
DupEven
(
const
Vec128
<
T
N
>
v
)
{
return
InterleaveLower
(
DFromV
<
decltype
(
v
)
>
(
)
v
v
)
;
}
template
<
typename
T
size_t
N
HWY_IF_LANE_SIZE
(
T
4
)
>
HWY_API
Vec128
<
T
N
>
DupOdd
(
Vec128
<
T
N
>
v
)
{
return
Vec128
<
T
N
>
{
_mm_shuffle_epi32
(
v
.
raw
_MM_SHUFFLE
(
3
3
1
1
)
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
float
N
>
DupOdd
(
Vec128
<
float
N
>
v
)
{
return
Vec128
<
float
N
>
{
_mm_shuffle_ps
(
v
.
raw
v
.
raw
_MM_SHUFFLE
(
3
3
1
1
)
)
}
;
}
template
<
typename
T
size_t
N
HWY_IF_LANE_SIZE
(
T
8
)
>
HWY_API
Vec128
<
T
N
>
DupOdd
(
const
Vec128
<
T
N
>
v
)
{
return
InterleaveUpper
(
DFromV
<
decltype
(
v
)
>
(
)
v
v
)
;
}
namespace
detail
{
template
<
typename
T
size_t
N
>
HWY_INLINE
Vec128
<
T
N
>
OddEven
(
hwy
:
:
SizeTag
<
1
>
const
Vec128
<
T
N
>
a
const
Vec128
<
T
N
>
b
)
{
const
DFromV
<
decltype
(
a
)
>
d
;
const
Repartition
<
uint8_t
decltype
(
d
)
>
d8
;
alignas
(
16
)
constexpr
uint8_t
mask
[
16
]
=
{
0xFF
0
0xFF
0
0xFF
0
0xFF
0
0xFF
0
0xFF
0
0xFF
0
0xFF
0
}
;
return
IfThenElse
(
MaskFromVec
(
BitCast
(
d
Load
(
d8
mask
)
)
)
b
a
)
;
}
template
<
typename
T
size_t
N
>
HWY_INLINE
Vec128
<
T
N
>
OddEven
(
hwy
:
:
SizeTag
<
2
>
const
Vec128
<
T
N
>
a
const
Vec128
<
T
N
>
b
)
{
#
if
HWY_TARGET
=
=
HWY_SSSE3
const
DFromV
<
decltype
(
a
)
>
d
;
const
Repartition
<
uint8_t
decltype
(
d
)
>
d8
;
alignas
(
16
)
constexpr
uint8_t
mask
[
16
]
=
{
0xFF
0xFF
0
0
0xFF
0xFF
0
0
0xFF
0xFF
0
0
0xFF
0xFF
0
0
}
;
return
IfThenElse
(
MaskFromVec
(
BitCast
(
d
Load
(
d8
mask
)
)
)
b
a
)
;
#
else
return
Vec128
<
T
N
>
{
_mm_blend_epi16
(
a
.
raw
b
.
raw
0x55
)
}
;
#
endif
}
template
<
typename
T
size_t
N
>
HWY_INLINE
Vec128
<
T
N
>
OddEven
(
hwy
:
:
SizeTag
<
4
>
const
Vec128
<
T
N
>
a
const
Vec128
<
T
N
>
b
)
{
#
if
HWY_TARGET
=
=
HWY_SSSE3
const
__m128i
odd
=
_mm_shuffle_epi32
(
a
.
raw
_MM_SHUFFLE
(
3
1
3
1
)
)
;
const
__m128i
even
=
_mm_shuffle_epi32
(
b
.
raw
_MM_SHUFFLE
(
2
0
2
0
)
)
;
return
Vec128
<
T
N
>
{
_mm_unpacklo_epi32
(
even
odd
)
}
;
#
else
return
Vec128
<
T
N
>
{
_mm_blend_epi16
(
a
.
raw
b
.
raw
0x33
)
}
;
#
endif
}
template
<
typename
T
size_t
N
>
HWY_INLINE
Vec128
<
T
N
>
OddEven
(
hwy
:
:
SizeTag
<
8
>
const
Vec128
<
T
N
>
a
const
Vec128
<
T
N
>
b
)
{
#
if
HWY_TARGET
=
=
HWY_SSSE3
const
Full128
<
double
>
dd
;
const
__m128d
concat
=
_mm_move_sd
(
BitCast
(
dd
a
)
.
raw
BitCast
(
dd
b
)
.
raw
)
;
return
BitCast
(
Full128
<
T
>
(
)
Vec128
<
double
>
{
concat
}
)
;
#
else
return
Vec128
<
T
N
>
{
_mm_blend_epi16
(
a
.
raw
b
.
raw
0x0F
)
}
;
#
endif
}
}
template
<
typename
T
size_t
N
>
HWY_API
Vec128
<
T
N
>
OddEven
(
const
Vec128
<
T
N
>
a
const
Vec128
<
T
N
>
b
)
{
return
detail
:
:
OddEven
(
hwy
:
:
SizeTag
<
sizeof
(
T
)
>
(
)
a
b
)
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
float
N
>
OddEven
(
const
Vec128
<
float
N
>
a
const
Vec128
<
float
N
>
b
)
{
#
if
HWY_TARGET
=
=
HWY_SSSE3
const
__m128
odd
=
_mm_shuffle_ps
(
a
.
raw
a
.
raw
_MM_SHUFFLE
(
3
1
3
1
)
)
;
const
__m128
even
=
_mm_shuffle_ps
(
b
.
raw
b
.
raw
_MM_SHUFFLE
(
2
0
2
0
)
)
;
return
Vec128
<
float
N
>
{
_mm_unpacklo_ps
(
even
odd
)
}
;
#
else
return
Vec128
<
float
N
>
{
_mm_blend_ps
(
a
.
raw
b
.
raw
5
)
}
;
#
endif
}
template
<
size_t
N
>
HWY_API
Vec128
<
double
N
>
OddEven
(
const
Vec128
<
double
N
>
a
const
Vec128
<
double
N
>
b
)
{
return
Vec128
<
double
>
{
_mm_shuffle_pd
(
b
.
raw
a
.
raw
_MM_SHUFFLE2
(
1
0
)
)
}
;
}
template
<
typename
T
size_t
N
>
HWY_API
Vec128
<
T
N
>
OddEvenBlocks
(
Vec128
<
T
N
>
Vec128
<
T
N
>
even
)
{
return
even
;
}
template
<
typename
T
size_t
N
>
HWY_API
Vec128
<
T
N
>
SwapAdjacentBlocks
(
Vec128
<
T
N
>
v
)
{
return
v
;
}
#
if
HWY_TARGET
>
HWY_AVX3
namespace
detail
{
template
<
typename
T
size_t
N
HWY_IF_LANE_SIZE
(
T
2
)
>
HWY_INLINE
Vec128
<
MakeUnsigned
<
T
>
N
>
Pow2
(
const
Vec128
<
T
N
>
v
)
{
const
DFromV
<
decltype
(
v
)
>
d
;
const
RepartitionToWide
<
decltype
(
d
)
>
dw
;
const
Rebind
<
float
decltype
(
dw
)
>
df
;
const
auto
zero
=
Zero
(
d
)
;
const
auto
exp
=
ShiftLeft
<
23
-
16
>
(
v
)
;
const
auto
upper
=
exp
+
Set
(
d
0x3F80
)
;
const
auto
f0
=
ZipLower
(
dw
zero
upper
)
;
const
auto
f1
=
ZipUpper
(
dw
zero
upper
)
;
const
Vec128
<
int32_t
N
>
bits0
{
_mm_cvtps_epi32
(
BitCast
(
df
f0
)
.
raw
)
}
;
const
Vec128
<
int32_t
N
>
bits1
{
_mm_cvtps_epi32
(
BitCast
(
df
f1
)
.
raw
)
}
;
return
Vec128
<
MakeUnsigned
<
T
>
N
>
{
_mm_packus_epi32
(
bits0
.
raw
bits1
.
raw
)
}
;
}
template
<
typename
T
size_t
N
HWY_IF_LANE_SIZE
(
T
4
)
>
HWY_INLINE
Vec128
<
MakeUnsigned
<
T
>
N
>
Pow2
(
const
Vec128
<
T
N
>
v
)
{
const
DFromV
<
decltype
(
v
)
>
d
;
const
auto
exp
=
ShiftLeft
<
23
>
(
v
)
;
const
auto
f
=
exp
+
Set
(
d
0x3F800000
)
;
return
Vec128
<
MakeUnsigned
<
T
>
N
>
{
_mm_cvtps_epi32
(
_mm_castsi128_ps
(
f
.
raw
)
)
}
;
}
}
#
endif
template
<
size_t
N
>
HWY_API
Vec128
<
uint16_t
N
>
operator
<
<
(
const
Vec128
<
uint16_t
N
>
v
const
Vec128
<
uint16_t
N
>
bits
)
{
#
if
HWY_TARGET
<
=
HWY_AVX3
return
Vec128
<
uint16_t
N
>
{
_mm_sllv_epi16
(
v
.
raw
bits
.
raw
)
}
;
#
else
return
v
*
detail
:
:
Pow2
(
bits
)
;
#
endif
}
HWY_API
Vec128
<
uint16_t
1
>
operator
<
<
(
const
Vec128
<
uint16_t
1
>
v
const
Vec128
<
uint16_t
1
>
bits
)
{
return
Vec128
<
uint16_t
1
>
{
_mm_sll_epi16
(
v
.
raw
bits
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint32_t
N
>
operator
<
<
(
const
Vec128
<
uint32_t
N
>
v
const
Vec128
<
uint32_t
N
>
bits
)
{
#
if
HWY_TARGET
=
=
HWY_SSSE3
|
|
HWY_TARGET
=
=
HWY_SSE4
return
v
*
detail
:
:
Pow2
(
bits
)
;
#
else
return
Vec128
<
uint32_t
N
>
{
_mm_sllv_epi32
(
v
.
raw
bits
.
raw
)
}
;
#
endif
}
HWY_API
Vec128
<
uint32_t
1
>
operator
<
<
(
const
Vec128
<
uint32_t
1
>
v
const
Vec128
<
uint32_t
1
>
bits
)
{
return
Vec128
<
uint32_t
1
>
{
_mm_sll_epi32
(
v
.
raw
bits
.
raw
)
}
;
}
HWY_API
Vec128
<
uint64_t
>
operator
<
<
(
const
Vec128
<
uint64_t
>
v
const
Vec128
<
uint64_t
>
bits
)
{
#
if
HWY_TARGET
=
=
HWY_SSSE3
|
|
HWY_TARGET
=
=
HWY_SSE4
const
Vec128
<
uint64_t
>
out0
{
_mm_sll_epi64
(
v
.
raw
bits
.
raw
)
}
;
const
__m128i
bits1
=
_mm_unpackhi_epi64
(
bits
.
raw
bits
.
raw
)
;
const
Vec128
<
uint64_t
>
out1
{
_mm_sll_epi64
(
v
.
raw
bits1
)
}
;
return
ConcatUpperLower
(
Full128
<
uint64_t
>
(
)
out1
out0
)
;
#
else
return
Vec128
<
uint64_t
>
{
_mm_sllv_epi64
(
v
.
raw
bits
.
raw
)
}
;
#
endif
}
HWY_API
Vec64
<
uint64_t
>
operator
<
<
(
const
Vec64
<
uint64_t
>
v
const
Vec64
<
uint64_t
>
bits
)
{
return
Vec64
<
uint64_t
>
{
_mm_sll_epi64
(
v
.
raw
bits
.
raw
)
}
;
}
template
<
typename
T
size_t
N
HWY_IF_SIGNED
(
T
)
>
HWY_API
Vec128
<
T
N
>
operator
<
<
(
const
Vec128
<
T
N
>
v
const
Vec128
<
T
N
>
bits
)
{
const
DFromV
<
decltype
(
v
)
>
di
;
const
RebindToUnsigned
<
decltype
(
di
)
>
du
;
return
BitCast
(
di
BitCast
(
du
v
)
<
<
BitCast
(
du
bits
)
)
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint16_t
N
>
operator
>
>
(
const
Vec128
<
uint16_t
N
>
in
const
Vec128
<
uint16_t
N
>
bits
)
{
#
if
HWY_TARGET
<
=
HWY_AVX3
return
Vec128
<
uint16_t
N
>
{
_mm_srlv_epi16
(
in
.
raw
bits
.
raw
)
}
;
#
else
const
Simd
<
uint16_t
N
0
>
d
;
const
auto
out
=
MulHigh
(
in
detail
:
:
Pow2
(
Set
(
d
16
)
-
bits
)
)
;
return
IfThenElse
(
bits
=
=
Zero
(
d
)
in
out
)
;
#
endif
}
HWY_API
Vec128
<
uint16_t
1
>
operator
>
>
(
const
Vec128
<
uint16_t
1
>
in
const
Vec128
<
uint16_t
1
>
bits
)
{
return
Vec128
<
uint16_t
1
>
{
_mm_srl_epi16
(
in
.
raw
bits
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint32_t
N
>
operator
>
>
(
const
Vec128
<
uint32_t
N
>
in
const
Vec128
<
uint32_t
N
>
bits
)
{
#
if
HWY_TARGET
=
=
HWY_SSSE3
|
|
HWY_TARGET
=
=
HWY_SSE4
const
Simd
<
uint32_t
N
0
>
d32
;
const
Vec128
<
uint32_t
N
>
in31
{
_mm_shuffle_epi32
(
in
.
raw
0x31
)
}
;
const
auto
mul
=
detail
:
:
Pow2
(
Set
(
d32
32
)
-
bits
)
;
const
auto
out20
=
ShiftRight
<
32
>
(
MulEven
(
in
mul
)
)
;
const
Vec128
<
uint32_t
N
>
mul31
{
_mm_shuffle_epi32
(
mul
.
raw
0x31
)
}
;
const
auto
out31
=
BitCast
(
d32
MulEven
(
in31
mul31
)
)
;
const
Vec128
<
uint32_t
N
>
out
=
OddEven
(
out31
BitCast
(
d32
out20
)
)
;
return
IfThenElse
(
bits
=
=
Zero
(
d32
)
in
out
)
;
#
else
return
Vec128
<
uint32_t
N
>
{
_mm_srlv_epi32
(
in
.
raw
bits
.
raw
)
}
;
#
endif
}
HWY_API
Vec128
<
uint32_t
1
>
operator
>
>
(
const
Vec128
<
uint32_t
1
>
in
const
Vec128
<
uint32_t
1
>
bits
)
{
return
Vec128
<
uint32_t
1
>
{
_mm_srl_epi32
(
in
.
raw
bits
.
raw
)
}
;
}
HWY_API
Vec128
<
uint64_t
>
operator
>
>
(
const
Vec128
<
uint64_t
>
v
const
Vec128
<
uint64_t
>
bits
)
{
#
if
HWY_TARGET
=
=
HWY_SSSE3
|
|
HWY_TARGET
=
=
HWY_SSE4
const
Vec128
<
uint64_t
>
out0
{
_mm_srl_epi64
(
v
.
raw
bits
.
raw
)
}
;
const
__m128i
bits1
=
_mm_unpackhi_epi64
(
bits
.
raw
bits
.
raw
)
;
const
Vec128
<
uint64_t
>
out1
{
_mm_srl_epi64
(
v
.
raw
bits1
)
}
;
return
ConcatUpperLower
(
Full128
<
uint64_t
>
(
)
out1
out0
)
;
#
else
return
Vec128
<
uint64_t
>
{
_mm_srlv_epi64
(
v
.
raw
bits
.
raw
)
}
;
#
endif
}
HWY_API
Vec64
<
uint64_t
>
operator
>
>
(
const
Vec64
<
uint64_t
>
v
const
Vec64
<
uint64_t
>
bits
)
{
return
Vec64
<
uint64_t
>
{
_mm_srl_epi64
(
v
.
raw
bits
.
raw
)
}
;
}
#
if
HWY_TARGET
>
HWY_AVX3
namespace
detail
{
template
<
class
DI
class
V
>
HWY_INLINE
V
SignedShr
(
const
DI
di
const
V
v
const
V
count_i
)
{
const
RebindToUnsigned
<
DI
>
du
;
const
auto
count
=
BitCast
(
du
count_i
)
;
const
auto
sign
=
BroadcastSignBit
(
v
)
;
const
auto
abs
=
BitCast
(
du
v
^
sign
)
;
return
BitCast
(
di
abs
>
>
count
)
^
sign
;
}
}
#
endif
template
<
size_t
N
>
HWY_API
Vec128
<
int16_t
N
>
operator
>
>
(
const
Vec128
<
int16_t
N
>
v
const
Vec128
<
int16_t
N
>
bits
)
{
#
if
HWY_TARGET
<
=
HWY_AVX3
return
Vec128
<
int16_t
N
>
{
_mm_srav_epi16
(
v
.
raw
bits
.
raw
)
}
;
#
else
return
detail
:
:
SignedShr
(
Simd
<
int16_t
N
0
>
(
)
v
bits
)
;
#
endif
}
HWY_API
Vec128
<
int16_t
1
>
operator
>
>
(
const
Vec128
<
int16_t
1
>
v
const
Vec128
<
int16_t
1
>
bits
)
{
return
Vec128
<
int16_t
1
>
{
_mm_sra_epi16
(
v
.
raw
bits
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
int32_t
N
>
operator
>
>
(
const
Vec128
<
int32_t
N
>
v
const
Vec128
<
int32_t
N
>
bits
)
{
#
if
HWY_TARGET
<
=
HWY_AVX3
return
Vec128
<
int32_t
N
>
{
_mm_srav_epi32
(
v
.
raw
bits
.
raw
)
}
;
#
else
return
detail
:
:
SignedShr
(
Simd
<
int32_t
N
0
>
(
)
v
bits
)
;
#
endif
}
HWY_API
Vec128
<
int32_t
1
>
operator
>
>
(
const
Vec128
<
int32_t
1
>
v
const
Vec128
<
int32_t
1
>
bits
)
{
return
Vec128
<
int32_t
1
>
{
_mm_sra_epi32
(
v
.
raw
bits
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
int64_t
N
>
operator
>
>
(
const
Vec128
<
int64_t
N
>
v
const
Vec128
<
int64_t
N
>
bits
)
{
#
if
HWY_TARGET
<
=
HWY_AVX3
return
Vec128
<
int64_t
N
>
{
_mm_srav_epi64
(
v
.
raw
bits
.
raw
)
}
;
#
else
return
detail
:
:
SignedShr
(
Simd
<
int64_t
N
0
>
(
)
v
bits
)
;
#
endif
}
HWY_INLINE
Vec128
<
uint64_t
>
MulEven
(
const
Vec128
<
uint64_t
>
a
const
Vec128
<
uint64_t
>
b
)
{
alignas
(
16
)
uint64_t
mul
[
2
]
;
mul
[
0
]
=
Mul128
(
GetLane
(
a
)
GetLane
(
b
)
&
mul
[
1
]
)
;
return
Load
(
Full128
<
uint64_t
>
(
)
mul
)
;
}
HWY_INLINE
Vec128
<
uint64_t
>
MulOdd
(
const
Vec128
<
uint64_t
>
a
const
Vec128
<
uint64_t
>
b
)
{
alignas
(
16
)
uint64_t
mul
[
2
]
;
const
Half
<
Full128
<
uint64_t
>
>
d2
;
mul
[
0
]
=
Mul128
(
GetLane
(
UpperHalf
(
d2
a
)
)
GetLane
(
UpperHalf
(
d2
b
)
)
&
mul
[
1
]
)
;
return
Load
(
Full128
<
uint64_t
>
(
)
mul
)
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
float
N
>
ReorderWidenMulAccumulate
(
Simd
<
float
N
0
>
df32
Vec128
<
bfloat16_t
2
*
N
>
a
Vec128
<
bfloat16_t
2
*
N
>
b
const
Vec128
<
float
N
>
sum0
Vec128
<
float
N
>
&
sum1
)
{
const
Repartition
<
uint16_t
decltype
(
df32
)
>
du16
;
const
RebindToUnsigned
<
decltype
(
df32
)
>
du32
;
const
Vec128
<
uint16_t
2
*
N
>
zero
=
Zero
(
du16
)
;
const
Vec128
<
uint32_t
N
>
a0
=
ZipLower
(
du32
zero
BitCast
(
du16
a
)
)
;
const
Vec128
<
uint32_t
N
>
a1
=
ZipUpper
(
du32
zero
BitCast
(
du16
a
)
)
;
const
Vec128
<
uint32_t
N
>
b0
=
ZipLower
(
du32
zero
BitCast
(
du16
b
)
)
;
const
Vec128
<
uint32_t
N
>
b1
=
ZipUpper
(
du32
zero
BitCast
(
du16
b
)
)
;
sum1
=
MulAdd
(
BitCast
(
df32
a1
)
BitCast
(
df32
b1
)
sum1
)
;
return
MulAdd
(
BitCast
(
df32
a0
)
BitCast
(
df32
b0
)
sum0
)
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint16_t
N
>
PromoteTo
(
Simd
<
uint16_t
N
0
>
const
Vec128
<
uint8_t
N
>
v
)
{
#
if
HWY_TARGET
=
=
HWY_SSSE3
const
__m128i
zero
=
_mm_setzero_si128
(
)
;
return
Vec128
<
uint16_t
N
>
{
_mm_unpacklo_epi8
(
v
.
raw
zero
)
}
;
#
else
return
Vec128
<
uint16_t
N
>
{
_mm_cvtepu8_epi16
(
v
.
raw
)
}
;
#
endif
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint32_t
N
>
PromoteTo
(
Simd
<
uint32_t
N
0
>
const
Vec128
<
uint16_t
N
>
v
)
{
#
if
HWY_TARGET
=
=
HWY_SSSE3
return
Vec128
<
uint32_t
N
>
{
_mm_unpacklo_epi16
(
v
.
raw
_mm_setzero_si128
(
)
)
}
;
#
else
return
Vec128
<
uint32_t
N
>
{
_mm_cvtepu16_epi32
(
v
.
raw
)
}
;
#
endif
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint64_t
N
>
PromoteTo
(
Simd
<
uint64_t
N
0
>
const
Vec128
<
uint32_t
N
>
v
)
{
#
if
HWY_TARGET
=
=
HWY_SSSE3
return
Vec128
<
uint64_t
N
>
{
_mm_unpacklo_epi32
(
v
.
raw
_mm_setzero_si128
(
)
)
}
;
#
else
return
Vec128
<
uint64_t
N
>
{
_mm_cvtepu32_epi64
(
v
.
raw
)
}
;
#
endif
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint32_t
N
>
PromoteTo
(
Simd
<
uint32_t
N
0
>
const
Vec128
<
uint8_t
N
>
v
)
{
#
if
HWY_TARGET
=
=
HWY_SSSE3
const
__m128i
zero
=
_mm_setzero_si128
(
)
;
const
__m128i
u16
=
_mm_unpacklo_epi8
(
v
.
raw
zero
)
;
return
Vec128
<
uint32_t
N
>
{
_mm_unpacklo_epi16
(
u16
zero
)
}
;
#
else
return
Vec128
<
uint32_t
N
>
{
_mm_cvtepu8_epi32
(
v
.
raw
)
}
;
#
endif
}
template
<
size_t
N
>
HWY_API
Vec128
<
int16_t
N
>
PromoteTo
(
Simd
<
int16_t
N
0
>
di
const
Vec128
<
uint8_t
N
>
v
)
{
return
BitCast
(
di
PromoteTo
(
Simd
<
uint16_t
N
0
>
(
)
v
)
)
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
int32_t
N
>
PromoteTo
(
Simd
<
int32_t
N
0
>
di
const
Vec128
<
uint16_t
N
>
v
)
{
return
BitCast
(
di
PromoteTo
(
Simd
<
uint32_t
N
0
>
(
)
v
)
)
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
int32_t
N
>
PromoteTo
(
Simd
<
int32_t
N
0
>
di
const
Vec128
<
uint8_t
N
>
v
)
{
return
BitCast
(
di
PromoteTo
(
Simd
<
uint32_t
N
0
>
(
)
v
)
)
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
int16_t
N
>
PromoteTo
(
Simd
<
int16_t
N
0
>
const
Vec128
<
int8_t
N
>
v
)
{
#
if
HWY_TARGET
=
=
HWY_SSSE3
return
ShiftRight
<
8
>
(
Vec128
<
int16_t
N
>
{
_mm_unpacklo_epi8
(
v
.
raw
v
.
raw
)
}
)
;
#
else
return
Vec128
<
int16_t
N
>
{
_mm_cvtepi8_epi16
(
v
.
raw
)
}
;
#
endif
}
template
<
size_t
N
>
HWY_API
Vec128
<
int32_t
N
>
PromoteTo
(
Simd
<
int32_t
N
0
>
const
Vec128
<
int16_t
N
>
v
)
{
#
if
HWY_TARGET
=
=
HWY_SSSE3
return
ShiftRight
<
16
>
(
Vec128
<
int32_t
N
>
{
_mm_unpacklo_epi16
(
v
.
raw
v
.
raw
)
}
)
;
#
else
return
Vec128
<
int32_t
N
>
{
_mm_cvtepi16_epi32
(
v
.
raw
)
}
;
#
endif
}
template
<
size_t
N
>
HWY_API
Vec128
<
int64_t
N
>
PromoteTo
(
Simd
<
int64_t
N
0
>
const
Vec128
<
int32_t
N
>
v
)
{
#
if
HWY_TARGET
=
=
HWY_SSSE3
return
ShiftRight
<
32
>
(
Vec128
<
int64_t
N
>
{
_mm_unpacklo_epi32
(
v
.
raw
v
.
raw
)
}
)
;
#
else
return
Vec128
<
int64_t
N
>
{
_mm_cvtepi32_epi64
(
v
.
raw
)
}
;
#
endif
}
template
<
size_t
N
>
HWY_API
Vec128
<
int32_t
N
>
PromoteTo
(
Simd
<
int32_t
N
0
>
const
Vec128
<
int8_t
N
>
v
)
{
#
if
HWY_TARGET
=
=
HWY_SSSE3
const
__m128i
x2
=
_mm_unpacklo_epi8
(
v
.
raw
v
.
raw
)
;
const
__m128i
x4
=
_mm_unpacklo_epi16
(
x2
x2
)
;
return
ShiftRight
<
24
>
(
Vec128
<
int32_t
N
>
{
x4
}
)
;
#
else
return
Vec128
<
int32_t
N
>
{
_mm_cvtepi8_epi32
(
v
.
raw
)
}
;
#
endif
}
#
if
defined
(
MEMORY_SANITIZER
)
&
&
\
(
HWY_COMPILER_CLANG
!
=
0
&
&
HWY_COMPILER_CLANG
<
1100
)
#
define
HWY_INLINE_F16
HWY_NOINLINE
#
else
#
define
HWY_INLINE_F16
HWY_INLINE
#
endif
template
<
size_t
N
>
HWY_INLINE_F16
Vec128
<
float
N
>
PromoteTo
(
Simd
<
float
N
0
>
df32
const
Vec128
<
float16_t
N
>
v
)
{
#
if
HWY_TARGET
>
=
HWY_SSE4
|
|
defined
(
HWY_DISABLE_F16C
)
const
RebindToSigned
<
decltype
(
df32
)
>
di32
;
const
RebindToUnsigned
<
decltype
(
df32
)
>
du32
;
const
auto
bits16
=
PromoteTo
(
du32
Vec128
<
uint16_t
N
>
{
v
.
raw
}
)
;
const
auto
sign
=
ShiftRight
<
15
>
(
bits16
)
;
const
auto
biased_exp
=
ShiftRight
<
10
>
(
bits16
)
&
Set
(
du32
0x1F
)
;
const
auto
mantissa
=
bits16
&
Set
(
du32
0x3FF
)
;
const
auto
subnormal
=
BitCast
(
du32
ConvertTo
(
df32
BitCast
(
di32
mantissa
)
)
*
Set
(
df32
1
.
0f
/
16384
/
1024
)
)
;
const
auto
biased_exp32
=
biased_exp
+
Set
(
du32
127
-
15
)
;
const
auto
mantissa32
=
ShiftLeft
<
23
-
10
>
(
mantissa
)
;
const
auto
normal
=
ShiftLeft
<
23
>
(
biased_exp32
)
|
mantissa32
;
const
auto
bits32
=
IfThenElse
(
biased_exp
=
=
Zero
(
du32
)
subnormal
normal
)
;
return
BitCast
(
df32
ShiftLeft
<
31
>
(
sign
)
|
bits32
)
;
#
else
(
void
)
df32
;
return
Vec128
<
float
N
>
{
_mm_cvtph_ps
(
v
.
raw
)
}
;
#
endif
}
template
<
size_t
N
>
HWY_API
Vec128
<
float
N
>
PromoteTo
(
Simd
<
float
N
0
>
df32
const
Vec128
<
bfloat16_t
N
>
v
)
{
const
Rebind
<
uint16_t
decltype
(
df32
)
>
du16
;
const
RebindToSigned
<
decltype
(
df32
)
>
di32
;
return
BitCast
(
df32
ShiftLeft
<
16
>
(
PromoteTo
(
di32
BitCast
(
du16
v
)
)
)
)
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
double
N
>
PromoteTo
(
Simd
<
double
N
0
>
const
Vec128
<
float
N
>
v
)
{
return
Vec128
<
double
N
>
{
_mm_cvtps_pd
(
v
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
double
N
>
PromoteTo
(
Simd
<
double
N
0
>
const
Vec128
<
int32_t
N
>
v
)
{
return
Vec128
<
double
N
>
{
_mm_cvtepi32_pd
(
v
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint16_t
N
>
DemoteTo
(
Simd
<
uint16_t
N
0
>
const
Vec128
<
int32_t
N
>
v
)
{
#
if
HWY_TARGET
=
=
HWY_SSSE3
const
Simd
<
int32_t
N
0
>
di32
;
const
Simd
<
uint16_t
N
*
2
0
>
du16
;
const
auto
zero_if_neg
=
AndNot
(
ShiftRight
<
31
>
(
v
)
v
)
;
const
auto
too_big
=
VecFromMask
(
di32
Gt
(
v
Set
(
di32
0xFFFF
)
)
)
;
const
auto
clamped
=
Or
(
zero_if_neg
too_big
)
;
alignas
(
16
)
constexpr
uint16_t
kLower2Bytes
[
16
]
=
{
0x0100
0x0504
0x0908
0x0D0C
0x8080
0x8080
0x8080
0x8080
}
;
const
auto
lo2
=
Load
(
du16
kLower2Bytes
)
;
return
Vec128
<
uint16_t
N
>
{
TableLookupBytes
(
BitCast
(
du16
clamped
)
lo2
)
.
raw
}
;
#
else
return
Vec128
<
uint16_t
N
>
{
_mm_packus_epi32
(
v
.
raw
v
.
raw
)
}
;
#
endif
}
template
<
size_t
N
>
HWY_API
Vec128
<
int16_t
N
>
DemoteTo
(
Simd
<
int16_t
N
0
>
const
Vec128
<
int32_t
N
>
v
)
{
return
Vec128
<
int16_t
N
>
{
_mm_packs_epi32
(
v
.
raw
v
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint8_t
N
>
DemoteTo
(
Simd
<
uint8_t
N
0
>
const
Vec128
<
int32_t
N
>
v
)
{
const
__m128i
i16
=
_mm_packs_epi32
(
v
.
raw
v
.
raw
)
;
return
Vec128
<
uint8_t
N
>
{
_mm_packus_epi16
(
i16
i16
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint8_t
N
>
DemoteTo
(
Simd
<
uint8_t
N
0
>
const
Vec128
<
int16_t
N
>
v
)
{
return
Vec128
<
uint8_t
N
>
{
_mm_packus_epi16
(
v
.
raw
v
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
int8_t
N
>
DemoteTo
(
Simd
<
int8_t
N
0
>
const
Vec128
<
int32_t
N
>
v
)
{
const
__m128i
i16
=
_mm_packs_epi32
(
v
.
raw
v
.
raw
)
;
return
Vec128
<
int8_t
N
>
{
_mm_packs_epi16
(
i16
i16
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
int8_t
N
>
DemoteTo
(
Simd
<
int8_t
N
0
>
const
Vec128
<
int16_t
N
>
v
)
{
return
Vec128
<
int8_t
N
>
{
_mm_packs_epi16
(
v
.
raw
v
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
float16_t
N
>
DemoteTo
(
Simd
<
float16_t
N
0
>
df16
const
Vec128
<
float
N
>
v
)
{
#
if
HWY_TARGET
>
=
HWY_SSE4
|
|
defined
(
HWY_DISABLE_F16C
)
const
RebindToUnsigned
<
decltype
(
df16
)
>
du16
;
const
Rebind
<
uint32_t
decltype
(
df16
)
>
du
;
const
RebindToSigned
<
decltype
(
du
)
>
di
;
const
auto
bits32
=
BitCast
(
du
v
)
;
const
auto
sign
=
ShiftRight
<
31
>
(
bits32
)
;
const
auto
biased_exp32
=
ShiftRight
<
23
>
(
bits32
)
&
Set
(
du
0xFF
)
;
const
auto
mantissa32
=
bits32
&
Set
(
du
0x7FFFFF
)
;
const
auto
k15
=
Set
(
di
15
)
;
const
auto
exp
=
Min
(
BitCast
(
di
biased_exp32
)
-
Set
(
di
127
)
k15
)
;
const
auto
is_tiny
=
exp
<
Set
(
di
-
24
)
;
const
auto
is_subnormal
=
exp
<
Set
(
di
-
14
)
;
const
auto
biased_exp16
=
BitCast
(
du
IfThenZeroElse
(
is_subnormal
exp
+
k15
)
)
;
const
auto
sub_exp
=
BitCast
(
du
Set
(
di
-
14
)
-
exp
)
;
const
auto
sub_m
=
(
Set
(
du
1
)
<
<
(
Set
(
du
10
)
-
sub_exp
)
)
+
(
mantissa32
>
>
(
Set
(
du
13
)
+
sub_exp
)
)
;
const
auto
mantissa16
=
IfThenElse
(
RebindMask
(
du
is_subnormal
)
sub_m
ShiftRight
<
13
>
(
mantissa32
)
)
;
const
auto
sign16
=
ShiftLeft
<
15
>
(
sign
)
;
const
auto
normal16
=
sign16
|
ShiftLeft
<
10
>
(
biased_exp16
)
|
mantissa16
;
const
auto
bits16
=
IfThenZeroElse
(
is_tiny
BitCast
(
di
normal16
)
)
;
return
BitCast
(
df16
DemoteTo
(
du16
bits16
)
)
;
#
else
(
void
)
df16
;
return
Vec128
<
float16_t
N
>
{
_mm_cvtps_ph
(
v
.
raw
_MM_FROUND_NO_EXC
)
}
;
#
endif
}
template
<
size_t
N
>
HWY_API
Vec128
<
bfloat16_t
N
>
DemoteTo
(
Simd
<
bfloat16_t
N
0
>
dbf16
const
Vec128
<
float
N
>
v
)
{
const
Rebind
<
int32_t
decltype
(
dbf16
)
>
di32
;
const
Rebind
<
uint32_t
decltype
(
dbf16
)
>
du32
;
const
Rebind
<
uint16_t
decltype
(
dbf16
)
>
du16
;
const
auto
bits_in_32
=
BitCast
(
di32
ShiftRight
<
16
>
(
BitCast
(
du32
v
)
)
)
;
return
BitCast
(
dbf16
DemoteTo
(
du16
bits_in_32
)
)
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
bfloat16_t
2
*
N
>
ReorderDemote2To
(
Simd
<
bfloat16_t
2
*
N
0
>
dbf16
Vec128
<
float
N
>
a
Vec128
<
float
N
>
b
)
{
const
RebindToUnsigned
<
decltype
(
dbf16
)
>
du16
;
const
Repartition
<
uint32_t
decltype
(
dbf16
)
>
du32
;
const
Vec128
<
uint32_t
N
>
b_in_even
=
ShiftRight
<
16
>
(
BitCast
(
du32
b
)
)
;
return
BitCast
(
dbf16
OddEven
(
BitCast
(
du16
a
)
BitCast
(
du16
b_in_even
)
)
)
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
float
N
>
DemoteTo
(
Simd
<
float
N
0
>
const
Vec128
<
double
N
>
v
)
{
return
Vec128
<
float
N
>
{
_mm_cvtpd_ps
(
v
.
raw
)
}
;
}
namespace
detail
{
template
<
size_t
N
>
HWY_INLINE
auto
ClampF64ToI32Max
(
Simd
<
double
N
0
>
d
decltype
(
Zero
(
d
)
)
v
)
-
>
decltype
(
Zero
(
d
)
)
{
return
Min
(
v
Set
(
d
2147483647
.
0
)
)
;
}
template
<
class
DI
class
DF
=
RebindToFloat
<
DI
>
>
HWY_INLINE
auto
FixConversionOverflow
(
DI
di
VFromD
<
DF
>
original
decltype
(
Zero
(
di
)
.
raw
)
converted_raw
)
-
>
VFromD
<
DI
>
{
const
auto
converted
=
VFromD
<
DI
>
{
converted_raw
}
;
const
auto
sign_wrong
=
AndNot
(
BitCast
(
di
original
)
converted
)
;
#
if
HWY_COMPILER_GCC
&
&
!
HWY_COMPILER_CLANG
const
RebindToUnsigned
<
DI
>
du
;
const
VFromD
<
DI
>
mask
=
BroadcastSignBit
(
sign_wrong
)
;
const
VFromD
<
DI
>
max
=
BitCast
(
di
ShiftRight
<
1
>
(
BitCast
(
du
mask
)
)
)
;
return
IfVecThenElse
(
mask
max
converted
)
;
#
else
return
Xor
(
converted
BroadcastSignBit
(
sign_wrong
)
)
;
#
endif
}
}
template
<
size_t
N
>
HWY_API
Vec128
<
int32_t
N
>
DemoteTo
(
Simd
<
int32_t
N
0
>
const
Vec128
<
double
N
>
v
)
{
const
auto
clamped
=
detail
:
:
ClampF64ToI32Max
(
Simd
<
double
N
0
>
(
)
v
)
;
return
Vec128
<
int32_t
N
>
{
_mm_cvttpd_epi32
(
clamped
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
uint8_t
N
>
U8FromU32
(
const
Vec128
<
uint32_t
N
>
v
)
{
const
Simd
<
uint32_t
N
0
>
d32
;
const
Simd
<
uint8_t
N
*
4
0
>
d8
;
alignas
(
16
)
static
constexpr
uint32_t
k8From32
[
4
]
=
{
0x0C080400u
0x0C080400u
0x0C080400u
0x0C080400u
}
;
const
auto
quad
=
TableLookupBytes
(
v
Load
(
d32
k8From32
)
)
;
return
LowerHalf
(
LowerHalf
(
BitCast
(
d8
quad
)
)
)
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
float
N
>
ConvertTo
(
Simd
<
float
N
0
>
const
Vec128
<
int32_t
N
>
v
)
{
return
Vec128
<
float
N
>
{
_mm_cvtepi32_ps
(
v
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
double
N
>
ConvertTo
(
Simd
<
double
N
0
>
dd
const
Vec128
<
int64_t
N
>
v
)
{
#
if
HWY_TARGET
<
=
HWY_AVX3
(
void
)
dd
;
return
Vec128
<
double
N
>
{
_mm_cvtepi64_pd
(
v
.
raw
)
}
;
#
else
const
Repartition
<
uint32_t
decltype
(
dd
)
>
d32
;
const
Repartition
<
uint64_t
decltype
(
dd
)
>
d64
;
const
auto
k84_63
=
Set
(
d64
0x4530000080000000ULL
)
;
const
auto
v_upper
=
BitCast
(
dd
ShiftRight
<
32
>
(
BitCast
(
d64
v
)
)
^
k84_63
)
;
const
auto
k52
=
Set
(
d32
0x43300000
)
;
const
auto
v_lower
=
BitCast
(
dd
OddEven
(
k52
BitCast
(
d32
v
)
)
)
;
const
auto
k84_63_52
=
BitCast
(
dd
Set
(
d64
0x4530000080100000ULL
)
)
;
return
(
v_upper
-
k84_63_52
)
+
v_lower
;
#
endif
}
template
<
size_t
N
>
HWY_API
Vec128
<
int32_t
N
>
ConvertTo
(
const
Simd
<
int32_t
N
0
>
di
const
Vec128
<
float
N
>
v
)
{
return
detail
:
:
FixConversionOverflow
(
di
v
_mm_cvttps_epi32
(
v
.
raw
)
)
;
}
HWY_API
Vec128
<
int64_t
>
ConvertTo
(
Full128
<
int64_t
>
di
const
Vec128
<
double
>
v
)
{
#
if
HWY_TARGET
<
=
HWY_AVX3
&
&
HWY_ARCH_X86_64
return
detail
:
:
FixConversionOverflow
(
di
v
_mm_cvttpd_epi64
(
v
.
raw
)
)
;
#
elif
HWY_ARCH_X86_64
const
__m128i
i0
=
_mm_cvtsi64_si128
(
_mm_cvttsd_si64
(
v
.
raw
)
)
;
const
Half
<
Full128
<
double
>
>
dd2
;
const
__m128i
i1
=
_mm_cvtsi64_si128
(
_mm_cvttsd_si64
(
UpperHalf
(
dd2
v
)
.
raw
)
)
;
return
detail
:
:
FixConversionOverflow
(
di
v
_mm_unpacklo_epi64
(
i0
i1
)
)
;
#
else
using
VI
=
VFromD
<
decltype
(
di
)
>
;
const
VI
k0
=
Zero
(
di
)
;
const
VI
k1
=
Set
(
di
1
)
;
const
VI
k51
=
Set
(
di
51
)
;
const
VI
biased_exp
=
ShiftRight
<
52
>
(
BitCast
(
di
v
)
)
&
Set
(
di
0x7FF
)
;
const
VI
exp
=
biased_exp
-
Set
(
di
0x3FF
)
;
const
auto
in_range
=
exp
<
Set
(
di
63
)
;
const
VI
shift_mnt
=
Max
(
k51
-
exp
k0
)
;
const
VI
shift_int
=
Max
(
exp
-
k51
k0
)
;
const
VI
mantissa
=
BitCast
(
di
v
)
&
Set
(
di
(
1ULL
<
<
52
)
-
1
)
;
const
VI
int52
=
(
mantissa
|
Set
(
di
1ULL
<
<
52
)
)
>
>
(
shift_mnt
+
k1
)
;
const
VI
shifted
=
int52
<
<
shift_int
;
const
VI
restored
=
shifted
|
(
(
mantissa
&
k1
)
<
<
(
shift_int
-
k1
)
)
;
const
VI
sign_mask
=
BroadcastSignBit
(
BitCast
(
di
v
)
)
;
const
VI
limit
=
Set
(
di
LimitsMax
<
int64_t
>
(
)
)
-
sign_mask
;
const
VI
magnitude
=
IfThenElse
(
in_range
restored
limit
)
;
return
(
magnitude
^
sign_mask
)
-
sign_mask
;
#
endif
}
HWY_API
Vec64
<
int64_t
>
ConvertTo
(
Full64
<
int64_t
>
di
const
Vec64
<
double
>
v
)
{
#
if
HWY_TARGET
>
HWY_AVX3
&
&
HWY_ARCH_X86_64
const
Vec64
<
int64_t
>
i0
{
_mm_cvtsi64_si128
(
_mm_cvttsd_si64
(
v
.
raw
)
)
}
;
return
detail
:
:
FixConversionOverflow
(
di
v
i0
.
raw
)
;
#
else
(
void
)
di
;
const
auto
full
=
ConvertTo
(
Full128
<
int64_t
>
(
)
Vec128
<
double
>
{
v
.
raw
}
)
;
return
Vec64
<
int64_t
>
{
full
.
raw
}
;
#
endif
}
template
<
size_t
N
>
HWY_API
Vec128
<
int32_t
N
>
NearestInt
(
const
Vec128
<
float
N
>
v
)
{
const
Simd
<
int32_t
N
0
>
di
;
return
detail
:
:
FixConversionOverflow
(
di
v
_mm_cvtps_epi32
(
v
.
raw
)
)
;
}
#
if
HWY_TARGET
=
=
HWY_SSSE3
template
<
typename
T
size_t
N
HWY_IF_FLOAT
(
T
)
>
HWY_API
Vec128
<
T
N
>
Round
(
const
Vec128
<
T
N
>
v
)
{
const
Simd
<
T
N
0
>
df
;
const
auto
max
=
Set
(
df
MantissaEnd
<
T
>
(
)
)
;
const
auto
large
=
CopySignToAbs
(
max
v
)
;
const
auto
added
=
large
+
v
;
const
auto
rounded
=
added
-
large
;
return
IfThenElse
(
Abs
(
v
)
<
max
rounded
v
)
;
}
namespace
detail
{
template
<
typename
T
size_t
N
HWY_IF_FLOAT
(
T
)
>
HWY_INLINE
Mask128
<
T
N
>
UseInt
(
const
Vec128
<
T
N
>
v
)
{
return
Abs
(
v
)
<
Set
(
Simd
<
T
N
0
>
(
)
MantissaEnd
<
T
>
(
)
)
;
}
}
template
<
typename
T
size_t
N
HWY_IF_FLOAT
(
T
)
>
HWY_API
Vec128
<
T
N
>
Trunc
(
const
Vec128
<
T
N
>
v
)
{
const
Simd
<
T
N
0
>
df
;
const
RebindToSigned
<
decltype
(
df
)
>
di
;
const
auto
integer
=
ConvertTo
(
di
v
)
;
const
auto
int_f
=
ConvertTo
(
df
integer
)
;
return
IfThenElse
(
detail
:
:
UseInt
(
v
)
CopySign
(
int_f
v
)
v
)
;
}
template
<
typename
T
size_t
N
HWY_IF_FLOAT
(
T
)
>
HWY_API
Vec128
<
T
N
>
Ceil
(
const
Vec128
<
T
N
>
v
)
{
const
Simd
<
T
N
0
>
df
;
const
RebindToSigned
<
decltype
(
df
)
>
di
;
const
auto
integer
=
ConvertTo
(
di
v
)
;
const
auto
int_f
=
ConvertTo
(
df
integer
)
;
const
auto
neg1
=
ConvertTo
(
df
VecFromMask
(
di
RebindMask
(
di
int_f
<
v
)
)
)
;
return
IfThenElse
(
detail
:
:
UseInt
(
v
)
int_f
-
neg1
v
)
;
}
template
<
typename
T
size_t
N
HWY_IF_FLOAT
(
T
)
>
HWY_API
Vec128
<
T
N
>
Floor
(
const
Vec128
<
T
N
>
v
)
{
const
Simd
<
T
N
0
>
df
;
const
RebindToSigned
<
decltype
(
df
)
>
di
;
const
auto
integer
=
ConvertTo
(
di
v
)
;
const
auto
int_f
=
ConvertTo
(
df
integer
)
;
const
auto
neg1
=
ConvertTo
(
df
VecFromMask
(
di
RebindMask
(
di
int_f
>
v
)
)
)
;
return
IfThenElse
(
detail
:
:
UseInt
(
v
)
int_f
+
neg1
v
)
;
}
#
else
template
<
size_t
N
>
HWY_API
Vec128
<
float
N
>
Round
(
const
Vec128
<
float
N
>
v
)
{
return
Vec128
<
float
N
>
{
_mm_round_ps
(
v
.
raw
_MM_FROUND_TO_NEAREST_INT
|
_MM_FROUND_NO_EXC
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
double
N
>
Round
(
const
Vec128
<
double
N
>
v
)
{
return
Vec128
<
double
N
>
{
_mm_round_pd
(
v
.
raw
_MM_FROUND_TO_NEAREST_INT
|
_MM_FROUND_NO_EXC
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
float
N
>
Trunc
(
const
Vec128
<
float
N
>
v
)
{
return
Vec128
<
float
N
>
{
_mm_round_ps
(
v
.
raw
_MM_FROUND_TO_ZERO
|
_MM_FROUND_NO_EXC
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
double
N
>
Trunc
(
const
Vec128
<
double
N
>
v
)
{
return
Vec128
<
double
N
>
{
_mm_round_pd
(
v
.
raw
_MM_FROUND_TO_ZERO
|
_MM_FROUND_NO_EXC
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
float
N
>
Ceil
(
const
Vec128
<
float
N
>
v
)
{
return
Vec128
<
float
N
>
{
_mm_round_ps
(
v
.
raw
_MM_FROUND_TO_POS_INF
|
_MM_FROUND_NO_EXC
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
double
N
>
Ceil
(
const
Vec128
<
double
N
>
v
)
{
return
Vec128
<
double
N
>
{
_mm_round_pd
(
v
.
raw
_MM_FROUND_TO_POS_INF
|
_MM_FROUND_NO_EXC
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
float
N
>
Floor
(
const
Vec128
<
float
N
>
v
)
{
return
Vec128
<
float
N
>
{
_mm_round_ps
(
v
.
raw
_MM_FROUND_TO_NEG_INF
|
_MM_FROUND_NO_EXC
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
double
N
>
Floor
(
const
Vec128
<
double
N
>
v
)
{
return
Vec128
<
double
N
>
{
_mm_round_pd
(
v
.
raw
_MM_FROUND_TO_NEG_INF
|
_MM_FROUND_NO_EXC
)
}
;
}
#
endif
#
if
!
defined
(
HWY_DISABLE_PCLMUL_AES
)
&
&
HWY_TARGET
!
=
HWY_SSSE3
#
ifdef
HWY_NATIVE_AES
#
undef
HWY_NATIVE_AES
#
else
#
define
HWY_NATIVE_AES
#
endif
HWY_API
Vec128
<
uint8_t
>
AESRound
(
Vec128
<
uint8_t
>
state
Vec128
<
uint8_t
>
round_key
)
{
return
Vec128
<
uint8_t
>
{
_mm_aesenc_si128
(
state
.
raw
round_key
.
raw
)
}
;
}
HWY_API
Vec128
<
uint8_t
>
AESLastRound
(
Vec128
<
uint8_t
>
state
Vec128
<
uint8_t
>
round_key
)
{
return
Vec128
<
uint8_t
>
{
_mm_aesenclast_si128
(
state
.
raw
round_key
.
raw
)
}
;
}
template
<
size_t
N
HWY_IF_LE128
(
uint64_t
N
)
>
HWY_API
Vec128
<
uint64_t
N
>
CLMulLower
(
Vec128
<
uint64_t
N
>
a
Vec128
<
uint64_t
N
>
b
)
{
return
Vec128
<
uint64_t
N
>
{
_mm_clmulepi64_si128
(
a
.
raw
b
.
raw
0x00
)
}
;
}
template
<
size_t
N
HWY_IF_LE128
(
uint64_t
N
)
>
HWY_API
Vec128
<
uint64_t
N
>
CLMulUpper
(
Vec128
<
uint64_t
N
>
a
Vec128
<
uint64_t
N
>
b
)
{
return
Vec128
<
uint64_t
N
>
{
_mm_clmulepi64_si128
(
a
.
raw
b
.
raw
0x11
)
}
;
}
#
endif
#
if
HWY_TARGET
<
=
HWY_AVX3
template
<
typename
T
size_t
N
HWY_IF_LE128
(
T
N
)
>
HWY_API
Mask128
<
T
N
>
LoadMaskBits
(
Simd
<
T
N
0
>
const
uint8_t
*
HWY_RESTRICT
bits
)
{
uint64_t
mask_bits
=
0
;
constexpr
size_t
kNumBytes
=
(
N
+
7
)
/
8
;
CopyBytes
<
kNumBytes
>
(
bits
&
mask_bits
)
;
if
(
N
<
8
)
{
mask_bits
&
=
(
1ull
<
<
N
)
-
1
;
}
return
Mask128
<
T
N
>
:
:
FromBits
(
mask_bits
)
;
}
template
<
typename
T
size_t
N
>
HWY_API
size_t
StoreMaskBits
(
const
Simd
<
T
N
0
>
const
Mask128
<
T
N
>
mask
uint8_t
*
bits
)
{
constexpr
size_t
kNumBytes
=
(
N
+
7
)
/
8
;
CopyBytes
<
kNumBytes
>
(
&
mask
.
raw
bits
)
;
if
(
N
<
8
)
{
const
int
mask
=
(
1
<
<
N
)
-
1
;
bits
[
0
]
=
static_cast
<
uint8_t
>
(
bits
[
0
]
&
mask
)
;
}
return
kNumBytes
;
}
template
<
typename
T
size_t
N
>
HWY_API
size_t
CountTrue
(
const
Simd
<
T
N
0
>
const
Mask128
<
T
N
>
mask
)
{
const
uint64_t
mask_bits
=
static_cast
<
uint64_t
>
(
mask
.
raw
)
&
(
(
1u
<
<
N
)
-
1
)
;
return
PopCount
(
mask_bits
)
;
}
template
<
typename
T
size_t
N
>
HWY_API
intptr_t
FindFirstTrue
(
const
Simd
<
T
N
0
>
const
Mask128
<
T
N
>
mask
)
{
const
uint32_t
mask_bits
=
static_cast
<
uint32_t
>
(
mask
.
raw
)
&
(
(
1u
<
<
N
)
-
1
)
;
return
mask
.
raw
?
intptr_t
(
Num0BitsBelowLS1Bit_Nonzero32
(
mask_bits
)
)
:
-
1
;
}
template
<
typename
T
size_t
N
>
HWY_API
bool
AllFalse
(
const
Simd
<
T
N
0
>
const
Mask128
<
T
N
>
mask
)
{
const
uint64_t
mask_bits
=
static_cast
<
uint64_t
>
(
mask
.
raw
)
&
(
(
1u
<
<
N
)
-
1
)
;
return
mask_bits
=
=
0
;
}
template
<
typename
T
size_t
N
>
HWY_API
bool
AllTrue
(
const
Simd
<
T
N
0
>
const
Mask128
<
T
N
>
mask
)
{
const
uint64_t
mask_bits
=
static_cast
<
uint64_t
>
(
mask
.
raw
)
&
(
(
1u
<
<
N
)
-
1
)
;
return
mask_bits
=
=
(
1u
<
<
N
)
-
1
;
}
#
if
HWY_TARGET
!
=
HWY_AVX3_DL
namespace
detail
{
HWY_INLINE
Vec128
<
uint16_t
>
IndicesForCompress16
(
uint64_t
mask_bits
)
{
Full128
<
uint16_t
>
du16
;
Rebind
<
uint8_t
decltype
(
du16
)
>
du8
;
alignas
(
16
)
constexpr
uint8_t
tbl
[
2048
]
=
{
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
1
0
0
0
0
0
0
0
0
1
0
0
0
0
0
0
2
0
0
0
0
0
0
0
0
2
0
0
0
0
0
0
1
2
0
0
0
0
0
0
0
1
2
0
0
0
0
0
3
0
0
0
0
0
0
0
0
3
0
0
0
0
0
0
1
3
0
0
0
0
0
0
0
1
3
0
0
0
0
0
2
3
0
0
0
0
0
0
0
2
3
0
0
0
0
0
1
2
3
0
0
0
0
0
0
1
2
3
0
0
0
0
4
0
0
0
0
0
0
0
0
4
0
0
0
0
0
0
1
4
0
0
0
0
0
0
0
1
4
0
0
0
0
0
2
4
0
0
0
0
0
0
0
2
4
0
0
0
0
0
1
2
4
0
0
0
0
0
0
1
2
4
0
0
0
0
3
4
0
0
0
0
0
0
0
3
4
0
0
0
0
0
1
3
4
0
0
0
0
0
0
1
3
4
0
0
0
0
2
3
4
0
0
0
0
0
0
2
3
4
0
0
0
0
1
2
3
4
0
0
0
0
0
1
2
3
4
0
0
0
5
0
0
0
0
0
0
0
0
5
0
0
0
0
0
0
1
5
0
0
0
0
0
0
0
1
5
0
0
0
0
0
2
5
0
0
0
0
0
0
0
2
5
0
0
0
0
0
1
2
5
0
0
0
0
0
0
1
2
5
0
0
0
0
3
5
0
0
0
0
0
0
0
3
5
0
0
0
0
0
1
3
5
0
0
0
0
0
0
1
3
5
0
0
0
0
2
3
5
0
0
0
0
0
0
2
3
5
0
0
0
0
1
2
3
5
0
0
0
0
0
1
2
3
5
0
0
0
4
5
0
0
0
0
0
0
0
4
5
0
0
0
0
0
1
4
5
0
0
0
0
0
0
1
4
5
0
0
0
0
2
4
5
0
0
0
0
0
0
2
4
5
0
0
0
0
1
2
4
5
0
0
0
0
0
1
2
4
5
0
0
0
3
4
5
0
0
0
0
0
0
3
4
5
0
0
0
0
1
3
4
5
0
0
0
0
0
1
3
4
5
0
0
0
2
3
4
5
0
0
0
0
0
2
3
4
5
0
0
0
1
2
3
4
5
0
0
0
0
1
2
3
4
5
0
0
6
0
0
0
0
0
0
0
0
6
0
0
0
0
0
0
1
6
0
0
0
0
0
0
0
1
6
0
0
0
0
0
2
6
0
0
0
0
0
0
0
2
6
0
0
0
0
0
1
2
6
0
0
0
0
0
0
1
2
6
0
0
0
0
3
6
0
0
0
0
0
0
0
3
6
0
0
0
0
0
1
3
6
0
0
0
0
0
0
1
3
6
0
0
0
0
2
3
6
0
0
0
0
0
0
2
3
6
0
0
0
0
1
2
3
6
0
0
0
0
0
1
2
3
6
0
0
0
4
6
0
0
0
0
0
0
0
4
6
0
0
0
0
0
1
4
6
0
0
0
0
0
0
1
4
6
0
0
0
0
2
4
6
0
0
0
0
0
0
2
4
6
0
0
0
0
1
2
4
6
0
0
0
0
0
1
2
4
6
0
0
0
3
4
6
0
0
0
0
0
0
3
4
6
0
0
0
0
1
3
4
6
0
0
0
0
0
1
3
4
6
0
0
0
2
3
4
6
0
0
0
0
0
2
3
4
6
0
0
0
1
2
3
4
6
0
0
0
0
1
2
3
4
6
0
0
5
6
0
0
0
0
0
0
0
5
6
0
0
0
0
0
1
5
6
0
0
0
0
0
0
1
5
6
0
0
0
0
2
5
6
0
0
0
0
0
0
2
5
6
0
0
0
0
1
2
5
6
0
0
0
0
0
1
2
5
6
0
0
0
3
5
6
0
0
0
0
0
0
3
5
6
0
0
0
0
1
3
5
6
0
0
0
0
0
1
3
5
6
0
0
0
2
3
5
6
0
0
0
0
0
2
3
5
6
0
0
0
1
2
3
5
6
0
0
0
0
1
2
3
5
6
0
0
4
5
6
0
0
0
0
0
0
4
5
6
0
0
0
0
1
4
5
6
0
0
0
0
0
1
4
5
6
0
0
0
2
4
5
6
0
0
0
0
0
2
4
5
6
0
0
0
1
2
4
5
6
0
0
0
0
1
2
4
5
6
0
0
3
4
5
6
0
0
0
0
0
3
4
5
6
0
0
0
1
3
4
5
6
0
0
0
0
1
3
4
5
6
0
0
2
3
4
5
6
0
0
0
0
2
3
4
5
6
0
0
1
2
3
4
5
6
0
0
0
1
2
3
4
5
6
0
7
0
0
0
0
0
0
0
0
7
0
0
0
0
0
0
1
7
0
0
0
0
0
0
0
1
7
0
0
0
0
0
2
7
0
0
0
0
0
0
0
2
7
0
0
0
0
0
1
2
7
0
0
0
0
0
0
1
2
7
0
0
0
0
3
7
0
0
0
0
0
0
0
3
7
0
0
0
0
0
1
3
7
0
0
0
0
0
0
1
3
7
0
0
0
0
2
3
7
0
0
0
0
0
0
2
3
7
0
0
0
0
1
2
3
7
0
0
0
0
0
1
2
3
7
0
0
0
4
7
0
0
0
0
0
0
0
4
7
0
0
0
0
0
1
4
7
0
0
0
0
0
0
1
4
7
0
0
0
0
2
4
7
0
0
0
0
0
0
2
4
7
0
0
0
0
1
2
4
7
0
0
0
0
0
1
2
4
7
0
0
0
3
4
7
0
0
0
0
0
0
3
4
7
0
0
0
0
1
3
4
7
0
0
0
0
0
1
3
4
7
0
0
0
2
3
4
7
0
0
0
0
0
2
3
4
7
0
0
0
1
2
3
4
7
0
0
0
0
1
2
3
4
7
0
0
5
7
0
0
0
0
0
0
0
5
7
0
0
0
0
0
1
5
7
0
0
0
0
0
0
1
5
7
0
0
0
0
2
5
7
0
0
0
0
0
0
2
5
7
0
0
0
0
1
2
5
7
0
0
0
0
0
1
2
5
7
0
0
0
3
5
7
0
0
0
0
0
0
3
5
7
0
0
0
0
1
3
5
7
0
0
0
0
0
1
3
5
7
0
0
0
2
3
5
7
0
0
0
0
0
2
3
5
7
0
0
0
1
2
3
5
7
0
0
0
0
1
2
3
5
7
0
0
4
5
7
0
0
0
0
0
0
4
5
7
0
0
0
0
1
4
5
7
0
0
0
0
0
1
4
5
7
0
0
0
2
4
5
7
0
0
0
0
0
2
4
5
7
0
0
0
1
2
4
5
7
0
0
0
0
1
2
4
5
7
0
0
3
4
5
7
0
0
0
0
0
3
4
5
7
0
0
0
1
3
4
5
7
0
0
0
0
1
3
4
5
7
0
0
2
3
4
5
7
0
0
0
0
2
3
4
5
7
0
0
1
2
3
4
5
7
0
0
0
1
2
3
4
5
7
0
6
7
0
0
0
0
0
0
0
6
7
0
0
0
0
0
1
6
7
0
0
0
0
0
0
1
6
7
0
0
0
0
2
6
7
0
0
0
0
0
0
2
6
7
0
0
0
0
1
2
6
7
0
0
0
0
0
1
2
6
7
0
0
0
3
6
7
0
0
0
0
0
0
3
6
7
0
0
0
0
1
3
6
7
0
0
0
0
0
1
3
6
7
0
0
0
2
3
6
7
0
0
0
0
0
2
3
6
7
0
0
0
1
2
3
6
7
0
0
0
0
1
2
3
6
7
0
0
4
6
7
0
0
0
0
0
0
4
6
7
0
0
0
0
1
4
6
7
0
0
0
0
0
1
4
6
7
0
0
0
2
4
6
7
0
0
0
0
0
2
4
6
7
0
0
0
1
2
4
6
7
0
0
0
0
1
2
4
6
7
0
0
3
4
6
7
0
0
0
0
0
3
4
6
7
0
0
0
1
3
4
6
7
0
0
0
0
1
3
4
6
7
0
0
2
3
4
6
7
0
0
0
0
2
3
4
6
7
0
0
1
2
3
4
6
7
0
0
0
1
2
3
4
6
7
0
5
6
7
0
0
0
0
0
0
5
6
7
0
0
0
0
1
5
6
7
0
0
0
0
0
1
5
6
7
0
0
0
2
5
6
7
0
0
0
0
0
2
5
6
7
0
0
0
1
2
5
6
7
0
0
0
0
1
2
5
6
7
0
0
3
5
6
7
0
0
0
0
0
3
5
6
7
0
0
0
1
3
5
6
7
0
0
0
0
1
3
5
6
7
0
0
2
3
5
6
7
0
0
0
0
2
3
5
6
7
0
0
1
2
3
5
6
7
0
0
0
1
2
3
5
6
7
0
4
5
6
7
0
0
0
0
0
4
5
6
7
0
0
0
1
4
5
6
7
0
0
0
0
1
4
5
6
7
0
0
2
4
5
6
7
0
0
0
0
2
4
5
6
7
0
0
1
2
4
5
6
7
0
0
0
1
2
4
5
6
7
0
3
4
5
6
7
0
0
0
0
3
4
5
6
7
0
0
1
3
4
5
6
7
0
0
0
1
3
4
5
6
7
0
2
3
4
5
6
7
0
0
0
2
3
4
5
6
7
0
1
2
3
4
5
6
7
0
0
1
2
3
4
5
6
7
}
;
return
PromoteTo
(
du16
Load
(
du8
tbl
+
mask_bits
*
8
)
)
;
}
}
#
endif
template
<
typename
T
size_t
N
HWY_IF_LANE_SIZE
(
T
2
)
>
HWY_API
Vec128
<
T
N
>
Compress
(
Vec128
<
T
N
>
v
Mask128
<
T
N
>
mask
)
{
const
Simd
<
T
N
0
>
d
;
const
Rebind
<
uint16_t
decltype
(
d
)
>
du
;
const
auto
vu
=
BitCast
(
du
v
)
;
#
if
HWY_TARGET
=
=
HWY_AVX3_DL
const
Vec128
<
uint16_t
N
>
cu
{
_mm_maskz_compress_epi16
(
mask
.
raw
vu
.
raw
)
}
;
#
else
const
auto
idx
=
detail
:
:
IndicesForCompress16
(
uint64_t
{
mask
.
raw
}
)
;
const
Vec128
<
uint16_t
N
>
cu
{
_mm_permutexvar_epi16
(
idx
.
raw
vu
.
raw
)
}
;
#
endif
return
BitCast
(
d
cu
)
;
}
template
<
typename
T
size_t
N
HWY_IF_LANE_SIZE
(
T
4
)
>
HWY_API
Vec128
<
T
N
>
Compress
(
Vec128
<
T
N
>
v
Mask128
<
T
N
>
mask
)
{
return
Vec128
<
T
N
>
{
_mm_maskz_compress_epi32
(
mask
.
raw
v
.
raw
)
}
;
}
template
<
typename
T
size_t
N
HWY_IF_LANE_SIZE
(
T
8
)
>
HWY_API
Vec128
<
T
N
>
Compress
(
Vec128
<
T
N
>
v
Mask128
<
T
N
>
mask
)
{
return
Vec128
<
T
N
>
{
_mm_maskz_compress_epi64
(
mask
.
raw
v
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
float
N
>
Compress
(
Vec128
<
float
N
>
v
Mask128
<
float
N
>
mask
)
{
return
Vec128
<
float
N
>
{
_mm_maskz_compress_ps
(
mask
.
raw
v
.
raw
)
}
;
}
template
<
size_t
N
>
HWY_API
Vec128
<
double
N
>
Compress
(
Vec128
<
double
N
>
v
Mask128
<
double
N
>
mask
)
{
return
Vec128
<
double
N
>
{
_mm_maskz_compress_pd
(
mask
.
raw
v
.
raw
)
}
;
}
template
<
typename
T
size_t
N
>
HWY_API
Vec128
<
T
N
>
CompressBits
(
Vec128
<
T
N
>
v
const
uint8_t
*
HWY_RESTRICT
bits
)
{
return
Compress
(
v
LoadMaskBits
(
Simd
<
T
N
0
>
(
)
bits
)
)
;
}
template
<
typename
T
size_t
N
HWY_IF_LANE_SIZE
(
T
2
)
>
HWY_API
size_t
CompressStore
(
Vec128
<
T
N
>
v
Mask128
<
T
N
>
mask
Simd
<
T
N
0
>
d
T
*
HWY_RESTRICT
unaligned
)
{
const
Rebind
<
uint16_t
decltype
(
d
)
>
du
;
const
auto
vu
=
BitCast
(
du
v
)
;
const
uint64_t
mask_bits
{
mask
.
raw
}
;
#
if
HWY_TARGET
=
=
HWY_AVX3_DL
_mm_mask_compressstoreu_epi16
(
unaligned
mask
.
raw
vu
.
raw
)
;
#
else
const
auto
idx
=
detail
:
:
IndicesForCompress16
(
mask_bits
)
;
const
Vec128
<
uint16_t
N
>
cu
{
_mm_permutexvar_epi16
(
idx
.
raw
vu
.
raw
)
}
;
StoreU
(
BitCast
(
d
cu
)
d
unaligned
)
;
#
endif
return
PopCount
(
uint64_t
{
mask
.
raw
}
&
(
(
1ull
<
<
N
)
-
1
)
)
;
}
template
<
typename
T
size_t
N
HWY_IF_LANE_SIZE
(
T
4
)
>
HWY_API
size_t
CompressStore
(
Vec128
<
T
N
>
v
Mask128
<
T
N
>
mask
Simd
<
T
N
0
>
T
*
HWY_RESTRICT
unaligned
)
{
_mm_mask_compressstoreu_epi32
(
unaligned
mask
.
raw
v
.
raw
)
;
return
PopCount
(
uint64_t
{
mask
.
raw
}
&
(
(
1ull
<
<
N
)
-
1
)
)
;
}
template
<
typename
T
size_t
N
HWY_IF_LANE_SIZE
(
T
8
)
>
HWY_API
size_t
CompressStore
(
Vec128
<
T
N
>
v
Mask128
<
T
N
>
mask
Simd
<
T
N
0
>
T
*
HWY_RESTRICT
unaligned
)
{
_mm_mask_compressstoreu_epi64
(
unaligned
mask
.
raw
v
.
raw
)
;
return
PopCount
(
uint64_t
{
mask
.
raw
}
&
(
(
1ull
<
<
N
)
-
1
)
)
;
}
template
<
size_t
N
HWY_IF_LE128
(
float
N
)
>
HWY_API
size_t
CompressStore
(
Vec128
<
float
N
>
v
Mask128
<
float
N
>
mask
Simd
<
float
N
0
>
float
*
HWY_RESTRICT
unaligned
)
{
_mm_mask_compressstoreu_ps
(
unaligned
mask
.
raw
v
.
raw
)
;
return
PopCount
(
uint64_t
{
mask
.
raw
}
&
(
(
1ull
<
<
N
)
-
1
)
)
;
}
template
<
size_t
N
HWY_IF_LE128
(
double
N
)
>
HWY_API
size_t
CompressStore
(
Vec128
<
double
N
>
v
Mask128
<
double
N
>
mask
Simd
<
double
N
0
>
double
*
HWY_RESTRICT
unaligned
)
{
_mm_mask_compressstoreu_pd
(
unaligned
mask
.
raw
v
.
raw
)
;
return
PopCount
(
uint64_t
{
mask
.
raw
}
&
(
(
1ull
<
<
N
)
-
1
)
)
;
}
template
<
typename
T
size_t
N
>
HWY_API
size_t
CompressBlendedStore
(
Vec128
<
T
N
>
v
Mask128
<
T
N
>
m
Simd
<
T
N
0
>
d
T
*
HWY_RESTRICT
unaligned
)
{
if
(
HWY_TARGET
=
=
HWY_AVX3_DL
|
|
sizeof
(
T
)
!
=
2
)
{
if
(
N
!
=
16
/
sizeof
(
T
)
)
{
m
=
And
(
m
FirstN
(
d
N
)
)
;
}
return
CompressStore
(
v
m
d
unaligned
)
;
}
else
{
const
size_t
count
=
CountTrue
(
d
m
)
;
const
Vec128
<
T
N
>
compressed
=
Compress
(
v
m
)
;
const
Vec128
<
T
N
>
prev
=
LoadU
(
d
unaligned
)
;
StoreU
(
IfThenElse
(
FirstN
(
d
count
)
compressed
prev
)
d
unaligned
)
;
return
count
;
}
}
template
<
typename
T
size_t
N
>
HWY_API
size_t
CompressBitsStore
(
Vec128
<
T
N
>
v
const
uint8_t
*
HWY_RESTRICT
bits
Simd
<
T
N
0
>
d
T
*
HWY_RESTRICT
unaligned
)
{
return
CompressStore
(
v
LoadMaskBits
(
d
bits
)
d
unaligned
)
;
}
#
else
namespace
detail
{
template
<
typename
T
size_t
N
HWY_IF_LANE_SIZE
(
T
1
)
>
HWY_INLINE
Mask128
<
T
N
>
LoadMaskBits
(
Simd
<
T
N
0
>
d
uint64_t
mask_bits
)
{
const
RebindToUnsigned
<
decltype
(
d
)
>
du
;
const
Vec128
<
T
N
>
vbits
{
_mm_cvtsi32_si128
(
static_cast
<
int
>
(
mask_bits
)
)
}
;
alignas
(
16
)
constexpr
uint8_t
kRep8
[
16
]
=
{
0
0
0
0
0
0
0
0
1
1
1
1
1
1
1
1
}
;
const
auto
rep8
=
TableLookupBytes
(
vbits
Load
(
du
kRep8
)
)
;
alignas
(
16
)
constexpr
uint8_t
kBit
[
16
]
=
{
1
2
4
8
16
32
64
128
1
2
4
8
16
32
64
128
}
;
return
RebindMask
(
d
TestBit
(
rep8
LoadDup128
(
du
kBit
)
)
)
;
}
template
<
typename
T
size_t
N
HWY_IF_LANE_SIZE
(
T
2
)
>
HWY_INLINE
Mask128
<
T
N
>
LoadMaskBits
(
Simd
<
T
N
0
>
d
uint64_t
mask_bits
)
{
const
RebindToUnsigned
<
decltype
(
d
)
>
du
;
alignas
(
16
)
constexpr
uint16_t
kBit
[
8
]
=
{
1
2
4
8
16
32
64
128
}
;
const
auto
vmask_bits
=
Set
(
du
static_cast
<
uint16_t
>
(
mask_bits
)
)
;
return
RebindMask
(
d
TestBit
(
vmask_bits
Load
(
du
kBit
)
)
)
;
}
template
<
typename
T
size_t
N
HWY_IF_LANE_SIZE
(
T
4
)
>
HWY_INLINE
Mask128
<
T
N
>
LoadMaskBits
(
Simd
<
T
N
0
>
d
uint64_t
mask_bits
)
{
const
RebindToUnsigned
<
decltype
(
d
)
>
du
;
alignas
(
16
)
constexpr
uint32_t
kBit
[
8
]
=
{
1
2
4
8
}
;
const
auto
vmask_bits
=
Set
(
du
static_cast
<
uint32_t
>
(
mask_bits
)
)
;
return
RebindMask
(
d
TestBit
(
vmask_bits
Load
(
du
kBit
)
)
)
;
}
template
<
typename
T
size_t
N
HWY_IF_LANE_SIZE
(
T
8
)
>
HWY_INLINE
Mask128
<
T
N
>
LoadMaskBits
(
Simd
<
T
N
0
>
d
uint64_t
mask_bits
)
{
const
RebindToUnsigned
<
decltype
(
d
)
>
du
;
alignas
(
16
)
constexpr
uint64_t
kBit
[
8
]
=
{
1
2
}
;
return
RebindMask
(
d
TestBit
(
Set
(
du
mask_bits
)
Load
(
du
kBit
)
)
)
;
}
}
template
<
typename
T
size_t
N
HWY_IF_LE128
(
T
N
)
>
HWY_API
Mask128
<
T
N
>
LoadMaskBits
(
Simd
<
T
N
0
>
d
const
uint8_t
*
HWY_RESTRICT
bits
)
{
uint64_t
mask_bits
=
0
;
constexpr
size_t
kNumBytes
=
(
N
+
7
)
/
8
;
CopyBytes
<
kNumBytes
>
(
bits
&
mask_bits
)
;
if
(
N
<
8
)
{
mask_bits
&
=
(
1ull
<
<
N
)
-
1
;
}
return
detail
:
:
LoadMaskBits
(
d
mask_bits
)
;
}
namespace
detail
{
constexpr
HWY_INLINE
uint64_t
U64FromInt
(
int
mask_bits
)
{
return
static_cast
<
uint64_t
>
(
static_cast
<
unsigned
>
(
mask_bits
)
)
;
}
template
<
typename
T
size_t
N
>
HWY_INLINE
uint64_t
BitsFromMask
(
hwy
:
:
SizeTag
<
1
>
const
Mask128
<
T
N
>
mask
)
{
const
Simd
<
T
N
0
>
d
;
const
auto
sign_bits
=
BitCast
(
d
VecFromMask
(
d
mask
)
)
.
raw
;
return
U64FromInt
(
_mm_movemask_epi8
(
sign_bits
)
)
;
}
template
<
typename
T
size_t
N
>
HWY_INLINE
uint64_t
BitsFromMask
(
hwy
:
:
SizeTag
<
2
>
const
Mask128
<
T
N
>
mask
)
{
const
auto
sign_bits
=
_mm_packs_epi16
(
mask
.
raw
_mm_setzero_si128
(
)
)
;
return
U64FromInt
(
_mm_movemask_epi8
(
sign_bits
)
)
;
}
template
<
typename
T
size_t
N
>
HWY_INLINE
uint64_t
BitsFromMask
(
hwy
:
:
SizeTag
<
4
>
const
Mask128
<
T
N
>
mask
)
{
const
Simd
<
T
N
0
>
d
;
const
Simd
<
float
N
0
>
df
;
const
auto
sign_bits
=
BitCast
(
df
VecFromMask
(
d
mask
)
)
;
return
U64FromInt
(
_mm_movemask_ps
(
sign_bits
.
raw
)
)
;
}
template
<
typename
T
size_t
N
>
HWY_INLINE
uint64_t
BitsFromMask
(
hwy
:
:
SizeTag
<
8
>
const
Mask128
<
T
N
>
mask
)
{
const
Simd
<
T
N
0
>
d
;
const
Simd
<
double
N
0
>
df
;
const
auto
sign_bits
=
BitCast
(
df
VecFromMask
(
d
mask
)
)
;
return
U64FromInt
(
_mm_movemask_pd
(
sign_bits
.
raw
)
)
;
}
template
<
typename
T
size_t
N
>
constexpr
uint64_t
OnlyActive
(
uint64_t
mask_bits
)
{
return
(
(
N
*
sizeof
(
T
)
)
=
=
16
)
?
mask_bits
:
mask_bits
&
(
(
1ull
<
<
N
)
-
1
)
;
}
template
<
typename
T
size_t
N
>
HWY_INLINE
uint64_t
BitsFromMask
(
const
Mask128
<
T
N
>
mask
)
{
return
OnlyActive
<
T
N
>
(
BitsFromMask
(
hwy
:
:
SizeTag
<
sizeof
(
T
)
>
(
)
mask
)
)
;
}
}
template
<
typename
T
size_t
N
>
HWY_API
size_t
StoreMaskBits
(
const
Simd
<
T
N
0
>
const
Mask128
<
T
N
>
mask
uint8_t
*
bits
)
{
constexpr
size_t
kNumBytes
=
(
N
+
7
)
/
8
;
const
uint64_t
mask_bits
=
detail
:
:
BitsFromMask
(
mask
)
;
CopyBytes
<
kNumBytes
>
(
&
mask_bits
bits
)
;
return
kNumBytes
;
}
template
<
typename
T
size_t
N
>
HWY_API
bool
AllFalse
(
const
Simd
<
T
N
0
>
const
Mask128
<
T
N
>
mask
)
{
return
detail
:
:
BitsFromMask
(
mask
)
=
=
0
;
}
template
<
typename
T
size_t
N
>
HWY_API
bool
AllTrue
(
const
Simd
<
T
N
0
>
const
Mask128
<
T
N
>
mask
)
{
constexpr
uint64_t
kAllBits
=
detail
:
:
OnlyActive
<
T
N
>
(
(
1ull
<
<
(
16
/
sizeof
(
T
)
)
)
-
1
)
;
return
detail
:
:
BitsFromMask
(
mask
)
=
=
kAllBits
;
}
template
<
typename
T
size_t
N
>
HWY_API
size_t
CountTrue
(
const
Simd
<
T
N
0
>
const
Mask128
<
T
N
>
mask
)
{
return
PopCount
(
detail
:
:
BitsFromMask
(
mask
)
)
;
}
template
<
typename
T
size_t
N
>
HWY_API
intptr_t
FindFirstTrue
(
const
Simd
<
T
N
0
>
const
Mask128
<
T
N
>
mask
)
{
const
uint64_t
mask_bits
=
detail
:
:
BitsFromMask
(
mask
)
;
return
mask_bits
?
intptr_t
(
Num0BitsBelowLS1Bit_Nonzero64
(
mask_bits
)
)
:
-
1
;
}
namespace
detail
{
template
<
typename
T
size_t
N
HWY_IF_LANE_SIZE
(
T
2
)
>
HWY_INLINE
Vec128
<
T
N
>
IndicesFromBits
(
Simd
<
T
N
0
>
d
uint64_t
mask_bits
)
{
HWY_DASSERT
(
mask_bits
<
256
)
;
const
Rebind
<
uint8_t
decltype
(
d
)
>
d8
;
const
Simd
<
uint16_t
N
0
>
du
;
alignas
(
16
)
constexpr
uint8_t
table
[
2048
]
=
{
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
2
0
0
0
0
0
0
0
0
2
0
0
0
0
0
0
4
0
0
0
0
0
0
0
0
4
0
0
0
0
0
0
2
4
0
0
0
0
0
0
0
2
4
0
0
0
0
0
6
0
0
0
0
0
0
0
0
6
0
0
0
0
0
0
2
6
0
0
0
0
0
0
0
2
6
0
0
0
0
0
4
6
0
0
0
0
0
0
0
4
6
0
0
0
0
0
2
4
6
0
0
0
0
0
0
2
4
6
0
0
0
0
8
0
0
0
0
0
0
0
0
8
0
0
0
0
0
0
2
8
0
0
0
0
0
0
0
2
8
0
0
0
0
0
4
8
0
0
0
0
0
0
0
4
8
0
0
0
0
0
2
4
8
0
0
0
0
0
0
2
4
8
0
0
0
0
6
8
0
0
0
0
0
0
0
6
8
0
0
0
0
0
2
6
8
0
0
0
0
0
0
2
6
8
0
0
0
0
4
6
8
0
0
0
0
0
0
4
6
8
0
0
0
0
2
4
6
8
0
0
0
0
0
2
4
6
8
0
0
0
10
0
0
0
0
0
0
0
0
10
0
0
0
0
0
0
2
10
0
0
0
0
0
0
0
2
10
0
0
0
0
0
4
10
0
0
0
0
0
0
0
4
10
0
0
0
0
0
2
4
10
0
0
0
0
0
0
2
4
10
0
0
0
0
6
10
0
0
0
0
0
0
0
6
10
0
0
0
0
0
2
6
10
0
0
0
0
0
0
2
6
10
0
0
0
0
4
6
10
0
0
0
0
0
0
4
6
10
0
0
0
0
2
4
6
10
0
0
0
0
0
2
4
6
10
0
0
0
8
10
0
0
0
0
0
0
0
8
10
0
0
0
0
0
2
8
10
0
0
0
0
0
0
2
8
10
0
0
0
0
4
8
10
0
0
0
0
0
0
4
8
10
0
0
0
0
2
4
8
10
0
0
0
0
0
2
4
8
10
0
0
0
6
8
10
0
0
0
0
0
0
6
8
10
0
0
0
0
2
6
8
10
0
0
0
0
0
2
6
8
10
0
0
0
4
6
8
10
0
0
0
0
0
4
6
8
10
0
0
0
2
4
6
8
10
0
0
0
0
2
4
6
8
10
0
0
12
0
0
0
0
0
0
0
0
12
0
0
0
0
0
0
2
12
0
0
0
0
0
0
0
2
12
0
0
0
0
0
4
12
0
0
0
0
0
0
0
4
12
0
0
0
0
0
2
4
12
0
0
0
0
0
0
2
4
12
0
0
0
0
6
12
0
0
0
0
0
0
0
6
12
0
0
0
0
0
2
6
12
0
0
0
0
0
0
2
6
12
0
0
0
0
4
6
12
0
0
0
0
0
0
4
6
12
0
0
0
0
2
4
6
12
0
0
0
0
0
2
4
6
12
0
0
0
8
12
0
0
0
0
0
0
0
8
12
0
0
0
0
0
2
8
12
0
0
0
0
0
0
2
8
12
0
0
0
0
4
8
12
0
0
0
0
0
0
4
8
12
0
0
0
0
2
4
8
12
0
0
0
0
0
2
4
8
12
0
0
0
6
8
12
0
0
0
0
0
0
6
8
12
0
0
0
0
2
6
8
12
0
0
0
0
0
2
6
8
12
0
0
0
4
6
8
12
0
0
0
0
0
4
6
8
12
0
0
0
2
4
6
8
12
0
0
0
0
2
4
6
8
12
0
0
10
12
0
0
0
0
0
0
0
10
12
0
0
0
0
0
2
10
12
0
0
0
0
0
0
2
10
12
0
0
0
0
4
10
12
0
0
0
0
0
0
4
10
12
0
0
0
0
2
4
10
12
0
0
0
0
0
2
4
10
12
0
0
0
6
10
12
0
0
0
0
0
0
6
10
12
0
0
0
0
2
6
10
12
0
0
0
0
0
2
6
10
12
0
0
0
4
6
10
12
0
0
0
0
0
4
6
10
12
0
0
0
2
4
6
10
12
0
0
0
0
2
4
6
10
12
0
0
8
10
12
0
0
0
0
0
0
8
10
12
0
0
0
0
2
8
10
12
0
0
0
0
0
2
8
10
12
0
0
0
4
8
10
12
0
0
0
0
0
4
8
10
12
0
0
0
2
4
8
10
12
0
0
0
0
2
4
8
10
12
0
0
6
8
10
12
0
0
0
0
0
6
8
10
12
0
0
0
2
6
8
10
12
0
0
0
0
2
6
8
10
12
0
0
4
6
8
10
12
0
0
0
0
4
6
8
10
12
0
0
2
4
6
8
10
12
0
0
0
2
4
6
8
10
12
0
14
0
0
0
0
0
0
0
0
14
0
0
0
0
0
0
2
14
0
0
0
0
0
0
0
2
14
0
0
0
0
0
4
14
0
0
0
0
0
0
0
4
14
0
0
0
0
0
2
4
14
0
0
0
0
0
0
2
4
14
0
0
0
0
6
14
0
0
0
0
0
0
0
6
14
0
0
0
0
0
2
6
14
0
0
0
0
0
0
2
6
14
0
0
0
0
4
6
14
0
0
0
0
0
0
4
6
14
0
0
0
0
2
4
6
14
0
0
0
0
0
2
4
6
14
0
0
0
8
14
0
0
0
0
0
0
0
8
14
0
0
0
0
0
2
8
14
0
0
0
0
0
0
2
8
14
0
0
0
0
4
8
14
0
0
0
0
0
0
4
8
14
0
0
0
0
2
4
8
14
0
0
0
0
0
2
4
8
14
0
0
0
6
8
14
0
0
0
0
0
0
6
8
14
0
0
0
0
2
6
8
14
0
0
0
0
0
2
6
8
14
0
0
0
4
6
8
14
0
0
0
0
0
4
6
8
14
0
0
0
2
4
6
8
14
0
0
0
0
2
4
6
8
14
0
0
10
14
0
0
0
0
0
0
0
10
14
0
0
0
0
0
2
10
14
0
0
0
0
0
0
2
10
14
0
0
0
0
4
10
14
0
0
0
0
0
0
4
10
14
0
0
0
0
2
4
10
14
0
0
0
0
0
2
4
10
14
0
0
0
6
10
14
0
0
0
0
0
0
6
10
14
0
0
0
0
2
6
10
14
0
0
0
0
0
2
6
10
14
0
0
0
4
6
10
14
0
0
0
0
0
4
6
10
14
0
0
0
2
4
6
10
14
0
0
0
0
2
4
6
10
14
0
0
8
10
14
0
0
0
0
0
0
8
10
14
0
0
0
0
2
8
10
14
0
0
0
0
0
2
8
10
14
0
0
0
4
8
10
14
0
0
0
0
0
4
8
10
14
0
0
0
2
4
8
10
14
0
0
0
0
2
4
8
10
14
0
0
6
8
10
14
0
0
0
0
0
6
8
10
14
0
0
0
2
6
8
10
14
0
0
0
0
2
6
8
10
14
0
0
4
6
8
10
14
0
0
0
0
4
6
8
10
14
0
0
2
4
6
8
10
14
0
0
0
2
4
6
8
10
14
0
12
14
0
0
0
0
0
0
0
12
14
0
0
0
0
0
2
12
14
0
0
0
0
0
0
2
12
14
0
0
0
0
4
12
14
0
0
0
0
0
0
4
12
14
0
0
0
0
2
4
12
14
0
0
0
0
0
2
4
12
14
0
0
0
6
12
14
0
0
0
0
0
0
6
12
14
0
0
0
0
2
6
12
14
0
0
0
0
0
2
6
12
14
0
0
0
4
6
12
14
0
0
0
0
0
4
6
12
14
0
0
0
2
4
6
12
14
0
0
0
0
2
4
6
12
14
0
0
8
12
14
0
0
0
0
0
0
8
12
14
0
0
0
0
2
8
12
14
0
0
0
0
0
2
8
12
14
0
0
0
4
8
12
14
0
0
0
0
0
4
8
12
14
0
0
0
2
4
8
12
14
0
0
0
0
2
4
8
12
14
0
0
6
8
12
14
0
0
0
0
0
6
8
12
14
0
0
0
2
6
8
12
14
0
0
0
0
2
6
8
12
14
0
0
4
6
8
12
14
0
0
0
0
4
6
8
12
14
0
0
2
4
6
8
12
14
0
0
0
2
4
6
8
12
14
0
10
12
14
0
0
0
0
0
0
10
12
14
0
0
0
0
2
10
12
14
0
0
0
0
0
2
10
12
14
0
0
0
4
10
12
14
0
0
0
0
0
4
10
12
14
0
0
0
2
4
10
12
14
0
0
0
0
2
4
10
12
14
0
0
6
10
12
14
0
0
0
0
0
6
10
12
14
0
0
0
2
6
10
12
14
0
0
0
0
2
6
10
12
14
0
0
4
6
10
12
14
0
0
0
0
4
6
10
12
14
0
0
2
4
6
10
12
14
0
0
0
2
4
6
10
12
14
0
8
10
12
14
0
0
0
0
0
8
10
12
14
0
0
0
2
8
10
12
14
0
0
0
0
2
8
10
12
14
0
0
4
8
10
12
14
0
0
0
0
4
8
10
12
14
0
0
2
4
8
10
12
14
0
0
0
2
4
8
10
12
14
0
6
8
10
12
14
0
0
0
0
6
8
10
12
14
0
0
2
6
8
10
12
14
0
0
0
2
6
8
10
12
14
0
4
6
8
10
12
14
0
0
0
4
6
8
10
12
14
0
2
4
6
8
10
12
14
0
0
2
4
6
8
10
12
14
}
;
const
Vec128
<
uint8_t
2
*
N
>
byte_idx
{
Load
(
d8
table
+
mask_bits
*
8
)
.
raw
}
;
const
Vec128
<
uint16_t
N
>
pairs
=
ZipLower
(
byte_idx
byte_idx
)
;
return
BitCast
(
d
pairs
+
Set
(
du
0x0100
)
)
;
}
template
<
typename
T
size_t
N
HWY_IF_LANE_SIZE
(
T
4
)
HWY_IF_LE128
(
T
N
)
>
HWY_INLINE
Vec128
<
T
N
>
IndicesFromBits
(
Simd
<
T
N
0
>
d
uint64_t
mask_bits
)
{
HWY_DASSERT
(
mask_bits
<
16
)
;
alignas
(
16
)
constexpr
uint8_t
packed_array
[
256
]
=
{
0
1
2
3
0
1
2
3
0
1
2
3
0
1
2
3
0
1
2
3
0
1
2
3
0
1
2
3
0
1
2
3
4
5
6
7
0
1
2
3
0
1
2
3
0
1
2
3
0
1
2
3
4
5
6
7
0
1
2
3
0
1
2
3
8
9
10
11
0
1
2
3
0
1
2
3
0
1
2
3
0
1
2
3
8
9
10
11
0
1
2
3
0
1
2
3
4
5
6
7
8
9
10
11
0
1
2
3
0
1
2
3
0
1
2
3
4
5
6
7
8
9
10
11
0
1
2
3
12
13
14
15
0
1
2
3
0
1
2
3
0
1
2
3
0
1
2
3
12
13
14
15
0
1
2
3
0
1
2
3
4
5
6
7
12
13
14
15
0
1
2
3
0
1
2
3
0
1
2
3
4
5
6
7
12
13
14
15
0
1
2
3
8
9
10
11
12
13
14
15
0
1
2
3
0
1
2
3
0
1
2
3
8
9
10
11
12
13
14
15
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
0
1
2
3
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
}
;
const
Repartition
<
uint8_t
decltype
(
d
)
>
d8
;
return
BitCast
(
d
Load
(
d8
packed_array
+
16
*
mask_bits
)
)
;
}
template
<
typename
T
size_t
N
HWY_IF_LANE_SIZE
(
T
8
)
HWY_IF_LE128
(
T
N
)
>
HWY_INLINE
Vec128
<
T
N
>
IndicesFromBits
(
Simd
<
T
N
0
>
d
uint64_t
mask_bits
)
{
HWY_DASSERT
(
mask_bits
<
4
)
;
alignas
(
16
)
constexpr
uint8_t
packed_array
[
64
]
=
{
0
1
2
3
4
5
6
7
0
1
2
3
4
5
6
7
0
1
2
3
4
5
6
7
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
0
1
2
3
4
5
6
7
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
}
;
const
Repartition
<
uint8_t
decltype
(
d
)
>
d8
;
return
BitCast
(
d
Load
(
d8
packed_array
+
16
*
mask_bits
)
)
;
}
}
template
<
typename
T
size_t
N
>
HWY_API
Vec128
<
T
N
>
Compress
(
Vec128
<
T
N
>
v
Mask128
<
T
N
>
m
)
{
const
Simd
<
T
N
0
>
d
;
const
RebindToUnsigned
<
decltype
(
d
)
>
du
;
const
uint64_t
mask_bits
=
detail
:
:
BitsFromMask
(
m
)
;
HWY_DASSERT
(
mask_bits
<
(
1ull
<
<
N
)
)
;
const
auto
indices
=
BitCast
(
du
detail
:
:
IndicesFromBits
(
d
mask_bits
)
)
;
return
BitCast
(
d
TableLookupBytes
(
BitCast
(
du
v
)
indices
)
)
;
}
template
<
typename
T
size_t
N
>
HWY_API
Vec128
<
T
N
>
CompressBits
(
Vec128
<
T
N
>
v
const
uint8_t
*
HWY_RESTRICT
bits
)
{
const
Simd
<
T
N
0
>
d
;
const
RebindToUnsigned
<
decltype
(
d
)
>
du
;
uint64_t
mask_bits
=
0
;
constexpr
size_t
kNumBytes
=
(
N
+
7
)
/
8
;
CopyBytes
<
kNumBytes
>
(
bits
&
mask_bits
)
;
if
(
N
<
8
)
{
mask_bits
&
=
(
1ull
<
<
N
)
-
1
;
}
const
auto
indices
=
BitCast
(
du
detail
:
:
IndicesFromBits
(
d
mask_bits
)
)
;
return
BitCast
(
d
TableLookupBytes
(
BitCast
(
du
v
)
indices
)
)
;
}
template
<
typename
T
size_t
N
>
HWY_API
size_t
CompressStore
(
Vec128
<
T
N
>
v
Mask128
<
T
N
>
m
Simd
<
T
N
0
>
d
T
*
HWY_RESTRICT
unaligned
)
{
const
RebindToUnsigned
<
decltype
(
d
)
>
du
;
const
uint64_t
mask_bits
=
detail
:
:
BitsFromMask
(
m
)
;
HWY_DASSERT
(
mask_bits
<
(
1ull
<
<
N
)
)
;
const
auto
indices
=
BitCast
(
du
detail
:
:
IndicesFromBits
(
d
mask_bits
)
)
;
const
auto
compressed
=
BitCast
(
d
TableLookupBytes
(
BitCast
(
du
v
)
indices
)
)
;
StoreU
(
compressed
d
unaligned
)
;
return
PopCount
(
mask_bits
)
;
}
template
<
typename
T
size_t
N
>
HWY_API
size_t
CompressBlendedStore
(
Vec128
<
T
N
>
v
Mask128
<
T
N
>
m
Simd
<
T
N
0
>
d
T
*
HWY_RESTRICT
unaligned
)
{
const
RebindToUnsigned
<
decltype
(
d
)
>
du
;
const
uint64_t
mask_bits
=
detail
:
:
BitsFromMask
(
m
)
;
HWY_DASSERT
(
mask_bits
<
(
1ull
<
<
N
)
)
;
const
size_t
count
=
PopCount
(
mask_bits
)
;
const
auto
indices
=
BitCast
(
du
detail
:
:
IndicesFromBits
(
d
mask_bits
)
)
;
const
auto
compressed
=
BitCast
(
d
TableLookupBytes
(
BitCast
(
du
v
)
indices
)
)
;
const
Vec128
<
T
N
>
prev
=
LoadU
(
d
unaligned
)
;
StoreU
(
IfThenElse
(
FirstN
(
d
count
)
compressed
prev
)
d
unaligned
)
;
return
count
;
}
template
<
typename
T
size_t
N
>
HWY_API
size_t
CompressBitsStore
(
Vec128
<
T
N
>
v
const
uint8_t
*
HWY_RESTRICT
bits
Simd
<
T
N
0
>
d
T
*
HWY_RESTRICT
unaligned
)
{
const
RebindToUnsigned
<
decltype
(
d
)
>
du
;
uint64_t
mask_bits
=
0
;
constexpr
size_t
kNumBytes
=
(
N
+
7
)
/
8
;
CopyBytes
<
kNumBytes
>
(
bits
&
mask_bits
)
;
if
(
N
<
8
)
{
mask_bits
&
=
(
1ull
<
<
N
)
-
1
;
}
const
auto
indices
=
BitCast
(
du
detail
:
:
IndicesFromBits
(
d
mask_bits
)
)
;
const
auto
compressed
=
BitCast
(
d
TableLookupBytes
(
BitCast
(
du
v
)
indices
)
)
;
StoreU
(
compressed
d
unaligned
)
;
return
PopCount
(
mask_bits
)
;
}
#
endif
HWY_API
void
StoreInterleaved3
(
const
Vec128
<
uint8_t
>
v0
const
Vec128
<
uint8_t
>
v1
const
Vec128
<
uint8_t
>
v2
Full128
<
uint8_t
>
d
uint8_t
*
HWY_RESTRICT
unaligned
)
{
const
auto
k5
=
Set
(
d
5
)
;
const
auto
k6
=
Set
(
d
6
)
;
alignas
(
16
)
static
constexpr
uint8_t
tbl_r0
[
16
]
=
{
0
0x80
0x80
1
0x80
0x80
2
0x80
0x80
3
0x80
0x80
4
0x80
0x80
5
}
;
alignas
(
16
)
static
constexpr
uint8_t
tbl_g0
[
16
]
=
{
0x80
0
0x80
0x80
1
0x80
0x80
2
0x80
0x80
3
0x80
0x80
4
0x80
0x80
}
;
const
auto
shuf_r0
=
Load
(
d
tbl_r0
)
;
const
auto
shuf_g0
=
Load
(
d
tbl_g0
)
;
const
auto
shuf_b0
=
CombineShiftRightBytes
<
15
>
(
d
shuf_g0
shuf_g0
)
;
const
auto
r0
=
TableLookupBytes
(
v0
shuf_r0
)
;
const
auto
g0
=
TableLookupBytes
(
v1
shuf_g0
)
;
const
auto
b0
=
TableLookupBytes
(
v2
shuf_b0
)
;
const
auto
int0
=
r0
|
g0
|
b0
;
StoreU
(
int0
d
unaligned
+
0
*
16
)
;
const
auto
shuf_r1
=
shuf_b0
+
k6
;
const
auto
shuf_g1
=
shuf_r0
+
k5
;
const
auto
shuf_b1
=
shuf_g0
+
k5
;
const
auto
r1
=
TableLookupBytes
(
v0
shuf_r1
)
;
const
auto
g1
=
TableLookupBytes
(
v1
shuf_g1
)
;
const
auto
b1
=
TableLookupBytes
(
v2
shuf_b1
)
;
const
auto
int1
=
r1
|
g1
|
b1
;
StoreU
(
int1
d
unaligned
+
1
*
16
)
;
const
auto
shuf_r2
=
shuf_b1
+
k6
;
const
auto
shuf_g2
=
shuf_r1
+
k5
;
const
auto
shuf_b2
=
shuf_g1
+
k5
;
const
auto
r2
=
TableLookupBytes
(
v0
shuf_r2
)
;
const
auto
g2
=
TableLookupBytes
(
v1
shuf_g2
)
;
const
auto
b2
=
TableLookupBytes
(
v2
shuf_b2
)
;
const
auto
int2
=
r2
|
g2
|
b2
;
StoreU
(
int2
d
unaligned
+
2
*
16
)
;
}
HWY_API
void
StoreInterleaved3
(
const
Vec64
<
uint8_t
>
v0
const
Vec64
<
uint8_t
>
v1
const
Vec64
<
uint8_t
>
v2
Full64
<
uint8_t
>
d
uint8_t
*
HWY_RESTRICT
unaligned
)
{
const
Full128
<
uint8_t
>
d_full
;
const
auto
k5
=
Set
(
d_full
5
)
;
const
auto
k6
=
Set
(
d_full
6
)
;
const
Vec128
<
uint8_t
>
full_a
{
v0
.
raw
}
;
const
Vec128
<
uint8_t
>
full_b
{
v1
.
raw
}
;
const
Vec128
<
uint8_t
>
full_c
{
v2
.
raw
}
;
alignas
(
16
)
static
constexpr
uint8_t
tbl_r0
[
16
]
=
{
0
0x80
0x80
1
0x80
0x80
2
0x80
0x80
3
0x80
0x80
4
0x80
0x80
5
}
;
alignas
(
16
)
static
constexpr
uint8_t
tbl_g0
[
16
]
=
{
0x80
0
0x80
0x80
1
0x80
0x80
2
0x80
0x80
3
0x80
0x80
4
0x80
0x80
}
;
const
auto
shuf_r0
=
Load
(
d_full
tbl_r0
)
;
const
auto
shuf_g0
=
Load
(
d_full
tbl_g0
)
;
const
auto
shuf_b0
=
CombineShiftRightBytes
<
15
>
(
d_full
shuf_g0
shuf_g0
)
;
const
auto
r0
=
TableLookupBytes
(
full_a
shuf_r0
)
;
const
auto
g0
=
TableLookupBytes
(
full_b
shuf_g0
)
;
const
auto
b0
=
TableLookupBytes
(
full_c
shuf_b0
)
;
const
auto
int0
=
r0
|
g0
|
b0
;
StoreU
(
int0
d_full
unaligned
+
0
*
16
)
;
const
auto
shuf_r1
=
shuf_b0
+
k6
;
const
auto
shuf_g1
=
shuf_r0
+
k5
;
const
auto
shuf_b1
=
shuf_g0
+
k5
;
const
auto
r1
=
TableLookupBytes
(
full_a
shuf_r1
)
;
const
auto
g1
=
TableLookupBytes
(
full_b
shuf_g1
)
;
const
auto
b1
=
TableLookupBytes
(
full_c
shuf_b1
)
;
const
decltype
(
Zero
(
d
)
)
int1
{
(
r1
|
g1
|
b1
)
.
raw
}
;
StoreU
(
int1
d
unaligned
+
1
*
16
)
;
}
template
<
size_t
N
HWY_IF_LE32
(
uint8_t
N
)
>
HWY_API
void
StoreInterleaved3
(
const
Vec128
<
uint8_t
N
>
v0
const
Vec128
<
uint8_t
N
>
v1
const
Vec128
<
uint8_t
N
>
v2
Simd
<
uint8_t
N
0
>
uint8_t
*
HWY_RESTRICT
unaligned
)
{
const
Full128
<
uint8_t
>
d_full
;
const
Vec128
<
uint8_t
>
full_a
{
v0
.
raw
}
;
const
Vec128
<
uint8_t
>
full_b
{
v1
.
raw
}
;
const
Vec128
<
uint8_t
>
full_c
{
v2
.
raw
}
;
alignas
(
16
)
static
constexpr
uint8_t
tbl_r0
[
16
]
=
{
0
0x80
0x80
1
0x80
0x80
2
0x80
0x80
3
0x80
0x80
0x80
0x80
0x80
0x80
}
;
const
auto
shuf_r0
=
Load
(
d_full
tbl_r0
)
;
const
auto
shuf_g0
=
CombineShiftRightBytes
<
15
>
(
d_full
shuf_r0
shuf_r0
)
;
const
auto
shuf_b0
=
CombineShiftRightBytes
<
14
>
(
d_full
shuf_r0
shuf_r0
)
;
const
auto
r0
=
TableLookupBytes
(
full_a
shuf_r0
)
;
const
auto
g0
=
TableLookupBytes
(
full_b
shuf_g0
)
;
const
auto
b0
=
TableLookupBytes
(
full_c
shuf_b0
)
;
const
auto
int0
=
r0
|
g0
|
b0
;
alignas
(
16
)
uint8_t
buf
[
16
]
;
StoreU
(
int0
d_full
buf
)
;
CopyBytes
<
N
*
3
>
(
buf
unaligned
)
;
}
HWY_API
void
StoreInterleaved4
(
const
Vec128
<
uint8_t
>
v0
const
Vec128
<
uint8_t
>
v1
const
Vec128
<
uint8_t
>
v2
const
Vec128
<
uint8_t
>
v3
Full128
<
uint8_t
>
d8
uint8_t
*
HWY_RESTRICT
unaligned
)
{
const
RepartitionToWide
<
decltype
(
d8
)
>
d16
;
const
RepartitionToWide
<
decltype
(
d16
)
>
d32
;
const
auto
ba0
=
ZipLower
(
d16
v0
v1
)
;
const
auto
dc0
=
ZipLower
(
d16
v2
v3
)
;
const
auto
ba8
=
ZipUpper
(
d16
v0
v1
)
;
const
auto
dc8
=
ZipUpper
(
d16
v2
v3
)
;
const
auto
dcba_0
=
ZipLower
(
d32
ba0
dc0
)
;
const
auto
dcba_4
=
ZipUpper
(
d32
ba0
dc0
)
;
const
auto
dcba_8
=
ZipLower
(
d32
ba8
dc8
)
;
const
auto
dcba_C
=
ZipUpper
(
d32
ba8
dc8
)
;
StoreU
(
BitCast
(
d8
dcba_0
)
d8
unaligned
+
0
*
16
)
;
StoreU
(
BitCast
(
d8
dcba_4
)
d8
unaligned
+
1
*
16
)
;
StoreU
(
BitCast
(
d8
dcba_8
)
d8
unaligned
+
2
*
16
)
;
StoreU
(
BitCast
(
d8
dcba_C
)
d8
unaligned
+
3
*
16
)
;
}
HWY_API
void
StoreInterleaved4
(
const
Vec64
<
uint8_t
>
in0
const
Vec64
<
uint8_t
>
in1
const
Vec64
<
uint8_t
>
in2
const
Vec64
<
uint8_t
>
in3
Full64
<
uint8_t
>
uint8_t
*
HWY_RESTRICT
unaligned
)
{
const
Full128
<
uint8_t
>
d_full8
;
const
RepartitionToWide
<
decltype
(
d_full8
)
>
d16
;
const
RepartitionToWide
<
decltype
(
d16
)
>
d32
;
const
Vec128
<
uint8_t
>
v0
{
in0
.
raw
}
;
const
Vec128
<
uint8_t
>
v1
{
in1
.
raw
}
;
const
Vec128
<
uint8_t
>
v2
{
in2
.
raw
}
;
const
Vec128
<
uint8_t
>
v3
{
in3
.
raw
}
;
const
auto
ba0
=
ZipLower
(
d16
v0
v1
)
;
const
auto
dc0
=
ZipLower
(
d16
v2
v3
)
;
const
auto
dcba_0
=
ZipLower
(
d32
ba0
dc0
)
;
const
auto
dcba_4
=
ZipUpper
(
d32
ba0
dc0
)
;
StoreU
(
BitCast
(
d_full8
dcba_0
)
d_full8
unaligned
+
0
*
16
)
;
StoreU
(
BitCast
(
d_full8
dcba_4
)
d_full8
unaligned
+
1
*
16
)
;
}
template
<
size_t
N
HWY_IF_LE32
(
uint8_t
N
)
>
HWY_API
void
StoreInterleaved4
(
const
Vec128
<
uint8_t
N
>
in0
const
Vec128
<
uint8_t
N
>
in1
const
Vec128
<
uint8_t
N
>
in2
const
Vec128
<
uint8_t
N
>
in3
Simd
<
uint8_t
N
0
>
uint8_t
*
HWY_RESTRICT
unaligned
)
{
const
Full128
<
uint8_t
>
d_full8
;
const
RepartitionToWide
<
decltype
(
d_full8
)
>
d16
;
const
RepartitionToWide
<
decltype
(
d16
)
>
d32
;
const
Vec128
<
uint8_t
>
v0
{
in0
.
raw
}
;
const
Vec128
<
uint8_t
>
v1
{
in1
.
raw
}
;
const
Vec128
<
uint8_t
>
v2
{
in2
.
raw
}
;
const
Vec128
<
uint8_t
>
v3
{
in3
.
raw
}
;
const
auto
ba0
=
ZipLower
(
d16
v0
v1
)
;
const
auto
dc0
=
ZipLower
(
d16
v2
v3
)
;
const
auto
dcba_0
=
ZipLower
(
d32
ba0
dc0
)
;
alignas
(
16
)
uint8_t
buf
[
16
]
;
StoreU
(
BitCast
(
d_full8
dcba_0
)
d_full8
buf
)
;
CopyBytes
<
4
*
N
>
(
buf
unaligned
)
;
}
namespace
detail
{
template
<
typename
T
>
HWY_INLINE
Vec128
<
T
1
>
SumOfLanes
(
hwy
:
:
SizeTag
<
sizeof
(
T
)
>
const
Vec128
<
T
1
>
v
)
{
return
v
;
}
template
<
typename
T
>
HWY_INLINE
Vec128
<
T
1
>
MinOfLanes
(
hwy
:
:
SizeTag
<
sizeof
(
T
)
>
const
Vec128
<
T
1
>
v
)
{
return
v
;
}
template
<
typename
T
>
HWY_INLINE
Vec128
<
T
1
>
MaxOfLanes
(
hwy
:
:
SizeTag
<
sizeof
(
T
)
>
const
Vec128
<
T
1
>
v
)
{
return
v
;
}
template
<
typename
T
>
HWY_INLINE
Vec128
<
T
2
>
SumOfLanes
(
hwy
:
:
SizeTag
<
4
>
const
Vec128
<
T
2
>
v10
)
{
return
v10
+
Shuffle2301
(
v10
)
;
}
template
<
typename
T
>
HWY_INLINE
Vec128
<
T
2
>
MinOfLanes
(
hwy
:
:
SizeTag
<
4
>
const
Vec128
<
T
2
>
v10
)
{
return
Min
(
v10
Shuffle2301
(
v10
)
)
;
}
template
<
typename
T
>
HWY_INLINE
Vec128
<
T
2
>
MaxOfLanes
(
hwy
:
:
SizeTag
<
4
>
const
Vec128
<
T
2
>
v10
)
{
return
Max
(
v10
Shuffle2301
(
v10
)
)
;
}
template
<
typename
T
>
HWY_INLINE
Vec128
<
T
>
SumOfLanes
(
hwy
:
:
SizeTag
<
4
>
const
Vec128
<
T
>
v3210
)
{
const
Vec128
<
T
>
v1032
=
Shuffle1032
(
v3210
)
;
const
Vec128
<
T
>
v31_20_31_20
=
v3210
+
v1032
;
const
Vec128
<
T
>
v20_31_20_31
=
Shuffle0321
(
v31_20_31_20
)
;
return
v20_31_20_31
+
v31_20_31_20
;
}
template
<
typename
T
>
HWY_INLINE
Vec128
<
T
>
MinOfLanes
(
hwy
:
:
SizeTag
<
4
>
const
Vec128
<
T
>
v3210
)
{
const
Vec128
<
T
>
v1032
=
Shuffle1032
(
v3210
)
;
const
Vec128
<
T
>
v31_20_31_20
=
Min
(
v3210
v1032
)
;
const
Vec128
<
T
>
v20_31_20_31
=
Shuffle0321
(
v31_20_31_20
)
;
return
Min
(
v20_31_20_31
v31_20_31_20
)
;
}
template
<
typename
T
>
HWY_INLINE
Vec128
<
T
>
MaxOfLanes
(
hwy
:
:
SizeTag
<
4
>
const
Vec128
<
T
>
v3210
)
{
const
Vec128
<
T
>
v1032
=
Shuffle1032
(
v3210
)
;
const
Vec128
<
T
>
v31_20_31_20
=
Max
(
v3210
v1032
)
;
const
Vec128
<
T
>
v20_31_20_31
=
Shuffle0321
(
v31_20_31_20
)
;
return
Max
(
v20_31_20_31
v31_20_31_20
)
;
}
template
<
typename
T
>
HWY_INLINE
Vec128
<
T
>
SumOfLanes
(
hwy
:
:
SizeTag
<
8
>
const
Vec128
<
T
>
v10
)
{
const
Vec128
<
T
>
v01
=
Shuffle01
(
v10
)
;
return
v10
+
v01
;
}
template
<
typename
T
>
HWY_INLINE
Vec128
<
T
>
MinOfLanes
(
hwy
:
:
SizeTag
<
8
>
const
Vec128
<
T
>
v10
)
{
const
Vec128
<
T
>
v01
=
Shuffle01
(
v10
)
;
return
Min
(
v10
v01
)
;
}
template
<
typename
T
>
HWY_INLINE
Vec128
<
T
>
MaxOfLanes
(
hwy
:
:
SizeTag
<
8
>
const
Vec128
<
T
>
v10
)
{
const
Vec128
<
T
>
v01
=
Shuffle01
(
v10
)
;
return
Max
(
v10
v01
)
;
}
template
<
typename
T
size_t
N
HWY_IF_LANE_SIZE
(
T
2
)
HWY_IF_GE32
(
T
N
)
>
HWY_API
Vec128
<
T
N
>
MinOfLanes
(
hwy
:
:
SizeTag
<
2
>
Vec128
<
T
N
>
v
)
{
const
Repartition
<
int32_t
Simd
<
T
N
0
>
>
d32
;
const
auto
even
=
And
(
BitCast
(
d32
v
)
Set
(
d32
0xFFFF
)
)
;
const
auto
odd
=
ShiftRight
<
16
>
(
BitCast
(
d32
v
)
)
;
const
auto
min
=
MinOfLanes
(
d32
Min
(
even
odd
)
)
;
return
BitCast
(
Simd
<
T
N
0
>
(
)
Or
(
min
ShiftLeft
<
16
>
(
min
)
)
)
;
}
template
<
typename
T
size_t
N
HWY_IF_LANE_SIZE
(
T
2
)
HWY_IF_GE32
(
T
N
)
>
HWY_API
Vec128
<
T
N
>
MaxOfLanes
(
hwy
:
:
SizeTag
<
2
>
Vec128
<
T
N
>
v
)
{
const
Repartition
<
int32_t
Simd
<
T
N
0
>
>
d32
;
const
auto
even
=
And
(
BitCast
(
d32
v
)
Set
(
d32
0xFFFF
)
)
;
const
auto
odd
=
ShiftRight
<
16
>
(
BitCast
(
d32
v
)
)
;
const
auto
min
=
MaxOfLanes
(
d32
Max
(
even
odd
)
)
;
return
BitCast
(
Simd
<
T
N
0
>
(
)
Or
(
min
ShiftLeft
<
16
>
(
min
)
)
)
;
}
}
template
<
typename
T
size_t
N
>
HWY_API
Vec128
<
T
N
>
SumOfLanes
(
Simd
<
T
N
0
>
const
Vec128
<
T
N
>
v
)
{
return
detail
:
:
SumOfLanes
(
hwy
:
:
SizeTag
<
sizeof
(
T
)
>
(
)
v
)
;
}
template
<
typename
T
size_t
N
>
HWY_API
Vec128
<
T
N
>
MinOfLanes
(
Simd
<
T
N
0
>
const
Vec128
<
T
N
>
v
)
{
return
detail
:
:
MinOfLanes
(
hwy
:
:
SizeTag
<
sizeof
(
T
)
>
(
)
v
)
;
}
template
<
typename
T
size_t
N
>
HWY_API
Vec128
<
T
N
>
MaxOfLanes
(
Simd
<
T
N
0
>
const
Vec128
<
T
N
>
v
)
{
return
detail
:
:
MaxOfLanes
(
hwy
:
:
SizeTag
<
sizeof
(
T
)
>
(
)
v
)
;
}
namespace
detail
{
template
<
class
D
class
V
=
VFromD
<
D
>
>
HWY_INLINE
V
Lt128Vec
(
const
D
d
const
V
a
const
V
b
)
{
static_assert
(
!
IsSigned
<
TFromD
<
D
>
>
(
)
&
&
sizeof
(
TFromD
<
D
>
)
=
=
8
"
Use
u64
"
)
;
const
V
eqHL
=
VecFromMask
(
d
Eq
(
a
b
)
)
;
const
V
ltHL
=
VecFromMask
(
d
Lt
(
a
b
)
)
;
const
V
ltLX
=
ShiftLeftLanes
<
1
>
(
ltHL
)
;
const
V
vecHx
=
OrAnd
(
ltHL
eqHL
ltLX
)
;
return
InterleaveUpper
(
d
vecHx
vecHx
)
;
}
}
template
<
class
D
class
V
=
VFromD
<
D
>
>
HWY_API
MFromD
<
D
>
Lt128
(
D
d
const
V
a
const
V
b
)
{
return
MaskFromVec
(
detail
:
:
Lt128Vec
(
d
a
b
)
)
;
}
template
<
class
D
class
V
=
VFromD
<
D
>
>
HWY_API
V
Min128
(
D
d
const
V
a
const
V
b
)
{
return
IfVecThenElse
(
detail
:
:
Lt128Vec
(
d
a
b
)
a
b
)
;
}
template
<
class
D
class
V
=
VFromD
<
D
>
>
HWY_API
V
Max128
(
D
d
const
V
a
const
V
b
)
{
return
IfVecThenElse
(
detail
:
:
Lt128Vec
(
d
a
b
)
b
a
)
;
}
template
<
class
V
>
HWY_API
V
Add
(
V
a
V
b
)
{
return
a
+
b
;
}
template
<
class
V
>
HWY_API
V
Sub
(
V
a
V
b
)
{
return
a
-
b
;
}
template
<
class
V
>
HWY_API
V
Mul
(
V
a
V
b
)
{
return
a
*
b
;
}
template
<
class
V
>
HWY_API
V
Div
(
V
a
V
b
)
{
return
a
/
b
;
}
template
<
class
V
>
V
Shl
(
V
a
V
b
)
{
return
a
<
<
b
;
}
template
<
class
V
>
V
Shr
(
V
a
V
b
)
{
return
a
>
>
b
;
}
template
<
class
V
>
HWY_API
auto
Eq
(
V
a
V
b
)
-
>
decltype
(
a
=
=
b
)
{
return
a
=
=
b
;
}
template
<
class
V
>
HWY_API
auto
Ne
(
V
a
V
b
)
-
>
decltype
(
a
=
=
b
)
{
return
a
!
=
b
;
}
template
<
class
V
>
HWY_API
auto
Lt
(
V
a
V
b
)
-
>
decltype
(
a
=
=
b
)
{
return
a
<
b
;
}
template
<
class
V
>
HWY_API
auto
Gt
(
V
a
V
b
)
-
>
decltype
(
a
=
=
b
)
{
return
a
>
b
;
}
template
<
class
V
>
HWY_API
auto
Ge
(
V
a
V
b
)
-
>
decltype
(
a
=
=
b
)
{
return
a
>
=
b
;
}
template
<
class
V
>
HWY_API
auto
Le
(
V
a
V
b
)
-
>
decltype
(
a
=
=
b
)
{
return
a
<
=
b
;
}
}
}
HWY_AFTER_NAMESPACE
(
)
;
