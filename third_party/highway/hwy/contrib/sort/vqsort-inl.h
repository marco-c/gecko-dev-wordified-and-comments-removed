#
ifndef
HIGHWAY_HWY_CONTRIB_SORT_VQSORT_INL_H_
#
define
HIGHWAY_HWY_CONTRIB_SORT_VQSORT_INL_H_
#
include
<
stdio
.
h
>
#
include
<
time
.
h
>
#
include
"
hwy
/
base
.
h
"
#
include
"
hwy
/
contrib
/
sort
/
order
.
h
"
#
include
"
hwy
/
cache_control
.
h
"
#
include
"
hwy
/
print
.
h
"
#
ifndef
VQSORT_ONLY_STATIC
#
define
VQSORT_ONLY_STATIC
0
#
endif
#
ifndef
VQSORT_PRINT
#
define
VQSORT_PRINT
0
#
endif
#
if
!
VQSORT_ONLY_STATIC
#
include
"
hwy
/
contrib
/
sort
/
vqsort
.
h
"
#
endif
namespace
hwy
{
namespace
detail
{
HWY_INLINE
void
Fill16BytesStatic
(
void
*
bytes
)
{
#
if
!
VQSORT_ONLY_STATIC
if
(
Fill16BytesSecure
(
bytes
)
)
return
;
#
endif
uint64_t
*
words
=
reinterpret_cast
<
uint64_t
*
>
(
bytes
)
;
uint64_t
*
*
seed_stack
=
&
words
;
void
(
*
seed_code
)
(
void
*
)
=
&
Fill16BytesStatic
;
const
uintptr_t
bits_stack
=
reinterpret_cast
<
uintptr_t
>
(
seed_stack
)
;
const
uintptr_t
bits_code
=
reinterpret_cast
<
uintptr_t
>
(
seed_code
)
;
const
uint64_t
bits_time
=
static_cast
<
uint64_t
>
(
clock
(
)
)
;
words
[
0
]
=
bits_stack
^
bits_time
^
0xFEDCBA98
;
words
[
1
]
=
bits_code
^
bits_time
^
0x01234567
;
}
HWY_INLINE
uint64_t
*
GetGeneratorStateStatic
(
)
{
thread_local
uint64_t
state
[
3
]
=
{
0
}
;
if
(
HWY_UNLIKELY
(
state
[
2
]
=
=
0
)
)
{
Fill16BytesStatic
(
state
)
;
state
[
2
]
=
1
;
}
return
state
;
}
}
}
#
endif
#
if
defined
(
HIGHWAY_HWY_CONTRIB_SORT_VQSORT_TOGGLE
)
=
=
\
defined
(
HWY_TARGET_TOGGLE
)
#
ifdef
HIGHWAY_HWY_CONTRIB_SORT_VQSORT_TOGGLE
#
undef
HIGHWAY_HWY_CONTRIB_SORT_VQSORT_TOGGLE
#
else
#
define
HIGHWAY_HWY_CONTRIB_SORT_VQSORT_TOGGLE
#
endif
#
if
VQSORT_PRINT
#
include
"
hwy
/
print
-
inl
.
h
"
#
endif
#
include
"
hwy
/
contrib
/
algo
/
copy
-
inl
.
h
"
#
include
"
hwy
/
contrib
/
sort
/
shared
-
inl
.
h
"
#
include
"
hwy
/
contrib
/
sort
/
sorting_networks
-
inl
.
h
"
#
include
"
hwy
/
contrib
/
sort
/
traits
-
inl
.
h
"
#
include
"
hwy
/
contrib
/
sort
/
traits128
-
inl
.
h
"
#
include
"
hwy
/
highway
.
h
"
HWY_BEFORE_NAMESPACE
(
)
;
namespace
hwy
{
namespace
HWY_NAMESPACE
{
namespace
detail
{
using
Constants
=
hwy
:
:
SortConstants
;
template
<
class
D
>
HWY_INLINE
void
MaybePrintVector
(
D
d
const
char
*
label
Vec
<
D
>
v
size_t
start
=
0
size_t
max_lanes
=
16
)
{
#
if
VQSORT_PRINT
>
=
2
Print
(
d
label
v
start
max_lanes
)
;
#
else
(
void
)
d
;
(
void
)
label
;
(
void
)
v
;
(
void
)
start
;
(
void
)
max_lanes
;
#
endif
}
template
<
class
Traits
typename
T
>
void
SiftDown
(
Traits
st
T
*
HWY_RESTRICT
lanes
const
size_t
num_lanes
size_t
start
)
{
constexpr
size_t
N1
=
st
.
LanesPerKey
(
)
;
const
FixedTag
<
T
N1
>
d
;
while
(
start
<
num_lanes
)
{
const
size_t
left
=
2
*
start
+
N1
;
const
size_t
right
=
2
*
start
+
2
*
N1
;
if
(
left
>
=
num_lanes
)
break
;
size_t
idx_larger
=
start
;
const
auto
key_j
=
st
.
SetKey
(
d
lanes
+
start
)
;
if
(
AllTrue
(
d
st
.
Compare
(
d
key_j
st
.
SetKey
(
d
lanes
+
left
)
)
)
)
{
idx_larger
=
left
;
}
if
(
right
<
num_lanes
&
&
AllTrue
(
d
st
.
Compare
(
d
st
.
SetKey
(
d
lanes
+
idx_larger
)
st
.
SetKey
(
d
lanes
+
right
)
)
)
)
{
idx_larger
=
right
;
}
if
(
idx_larger
=
=
start
)
break
;
st
.
Swap
(
lanes
+
start
lanes
+
idx_larger
)
;
start
=
idx_larger
;
}
}
template
<
class
Traits
typename
T
>
void
HeapSort
(
Traits
st
T
*
HWY_RESTRICT
lanes
const
size_t
num_lanes
)
{
constexpr
size_t
N1
=
st
.
LanesPerKey
(
)
;
if
(
num_lanes
<
2
*
N1
)
return
;
for
(
size_t
i
=
(
(
num_lanes
-
N1
)
/
N1
/
2
)
*
N1
;
i
!
=
(
~
N1
+
1
)
;
i
-
=
N1
)
{
SiftDown
(
st
lanes
num_lanes
i
)
;
}
for
(
size_t
i
=
num_lanes
-
N1
;
i
!
=
0
;
i
-
=
N1
)
{
st
.
Swap
(
lanes
+
0
lanes
+
i
)
;
SiftDown
(
st
lanes
i
0
)
;
}
}
#
if
VQSORT_ENABLED
|
|
HWY_IDE
template
<
class
Traits
typename
T
>
HWY_INLINE
void
Sort2To2
(
Traits
st
T
*
HWY_RESTRICT
keys
size_t
num_lanes
T
*
HWY_RESTRICT
)
{
constexpr
size_t
kLPK
=
st
.
LanesPerKey
(
)
;
const
size_t
num_keys
=
num_lanes
/
kLPK
;
HWY_DASSERT
(
num_keys
=
=
2
)
;
HWY_ASSUME
(
num_keys
=
=
2
)
;
const
CappedTag
<
T
kLPK
>
d
;
using
V
=
Vec
<
decltype
(
d
)
>
;
V
v0
=
LoadU
(
d
keys
+
0x0
*
kLPK
)
;
V
v1
=
LoadU
(
d
keys
+
0x1
*
kLPK
)
;
Sort2
(
d
st
v0
v1
)
;
StoreU
(
v0
d
keys
+
0x0
*
kLPK
)
;
StoreU
(
v1
d
keys
+
0x1
*
kLPK
)
;
}
template
<
class
Traits
typename
T
>
HWY_INLINE
void
Sort3To4
(
Traits
st
T
*
HWY_RESTRICT
keys
size_t
num_lanes
T
*
HWY_RESTRICT
buf
)
{
constexpr
size_t
kLPK
=
st
.
LanesPerKey
(
)
;
const
size_t
num_keys
=
num_lanes
/
kLPK
;
HWY_DASSERT
(
3
<
=
num_keys
&
&
num_keys
<
=
4
)
;
HWY_ASSUME
(
num_keys
>
=
3
)
;
HWY_ASSUME
(
num_keys
<
=
4
)
;
const
CappedTag
<
T
kLPK
>
d
;
using
V
=
Vec
<
decltype
(
d
)
>
;
Store
(
st
.
LastValue
(
d
)
d
buf
)
;
T
*
in_out3
=
num_keys
=
=
3
?
buf
:
keys
+
0x3
*
kLPK
;
V
v0
=
LoadU
(
d
keys
+
0x0
*
kLPK
)
;
V
v1
=
LoadU
(
d
keys
+
0x1
*
kLPK
)
;
V
v2
=
LoadU
(
d
keys
+
0x2
*
kLPK
)
;
V
v3
=
LoadU
(
d
in_out3
)
;
Sort4
(
d
st
v0
v1
v2
v3
)
;
StoreU
(
v0
d
keys
+
0x0
*
kLPK
)
;
StoreU
(
v1
d
keys
+
0x1
*
kLPK
)
;
StoreU
(
v2
d
keys
+
0x2
*
kLPK
)
;
StoreU
(
v3
d
in_out3
)
;
}
#
if
HWY_MEM_OPS_MIGHT_FAULT
template
<
size_t
kRows
size_t
kLanesPerRow
class
D
class
Traits
typename
T
=
TFromD
<
D
>
>
HWY_INLINE
void
CopyHalfToPaddedBuf
(
D
d
Traits
st
T
*
HWY_RESTRICT
keys
size_t
num_lanes
T
*
HWY_RESTRICT
buf
)
{
constexpr
size_t
kMinLanes
=
kRows
/
2
*
kLanesPerRow
;
const
CappedTag
<
T
kMinLanes
>
dmax
;
const
size_t
Nmax
=
Lanes
(
dmax
)
;
HWY_DASSERT
(
Nmax
<
num_lanes
)
;
HWY_ASSUME
(
Nmax
<
=
kMinLanes
)
;
const
Vec
<
decltype
(
dmax
)
>
kPadding
=
st
.
LastValue
(
dmax
)
;
size_t
i
=
num_lanes
&
~
(
Nmax
-
1
)
;
HWY_ASSUME
(
i
!
=
0
)
;
do
{
Store
(
kPadding
dmax
buf
+
i
)
;
i
+
=
Nmax
;
}
while
(
i
<
(
kRows
-
1
)
*
kLanesPerRow
+
Lanes
(
d
)
)
;
ptrdiff_t
end
=
static_cast
<
ptrdiff_t
>
(
num_lanes
)
;
do
{
end
-
=
static_cast
<
ptrdiff_t
>
(
Nmax
)
;
StoreU
(
LoadU
(
dmax
keys
+
end
)
dmax
buf
+
end
)
;
}
while
(
end
>
static_cast
<
ptrdiff_t
>
(
kRows
/
2
*
kLanesPerRow
)
)
;
}
#
endif
template
<
size_t
kKeysPerRow
class
Traits
typename
T
>
HWY_NOINLINE
void
Sort8Rows
(
Traits
st
T
*
HWY_RESTRICT
keys
size_t
num_lanes
T
*
HWY_RESTRICT
buf
)
{
static_assert
(
kKeysPerRow
<
=
4
"
"
)
;
constexpr
size_t
kLPK
=
st
.
LanesPerKey
(
)
;
constexpr
size_t
kRows
=
8
;
constexpr
size_t
kLanesPerRow
=
kKeysPerRow
*
kLPK
;
constexpr
size_t
kMinLanes
=
kRows
/
2
*
kLanesPerRow
;
HWY_DASSERT
(
kMinLanes
<
num_lanes
&
&
num_lanes
<
=
kRows
*
kLanesPerRow
)
;
const
CappedTag
<
T
kLanesPerRow
>
d
;
using
V
=
Vec
<
decltype
(
d
)
>
;
V
v4
v5
v6
v7
;
V
v0
=
LoadU
(
d
keys
+
0x0
*
kLanesPerRow
)
;
V
v1
=
LoadU
(
d
keys
+
0x1
*
kLanesPerRow
)
;
V
v2
=
LoadU
(
d
keys
+
0x2
*
kLanesPerRow
)
;
V
v3
=
LoadU
(
d
keys
+
0x3
*
kLanesPerRow
)
;
#
if
HWY_MEM_OPS_MIGHT_FAULT
CopyHalfToPaddedBuf
<
kRows
kLanesPerRow
>
(
d
st
keys
num_lanes
buf
)
;
v4
=
LoadU
(
d
buf
+
0x4
*
kLanesPerRow
)
;
v5
=
LoadU
(
d
buf
+
0x5
*
kLanesPerRow
)
;
v6
=
LoadU
(
d
buf
+
0x6
*
kLanesPerRow
)
;
v7
=
LoadU
(
d
buf
+
0x7
*
kLanesPerRow
)
;
#
endif
#
if
!
HWY_MEM_OPS_MIGHT_FAULT
|
|
HWY_IDE
(
void
)
buf
;
const
V
vnum_lanes
=
Set
(
d
ConvertScalarTo
<
T
>
(
num_lanes
)
)
;
const
V
kIota
=
Iota
(
d
static_cast
<
T
>
(
kMinLanes
)
)
;
const
V
k1
=
Set
(
d
static_cast
<
T
>
(
kLanesPerRow
)
)
;
const
V
k2
=
Add
(
k1
k1
)
;
using
M
=
Mask
<
decltype
(
d
)
>
;
const
M
m4
=
Gt
(
vnum_lanes
kIota
)
;
const
M
m5
=
Gt
(
vnum_lanes
Add
(
kIota
k1
)
)
;
const
M
m6
=
Gt
(
vnum_lanes
Add
(
kIota
k2
)
)
;
const
M
m7
=
Gt
(
vnum_lanes
Add
(
kIota
Add
(
k2
k1
)
)
)
;
const
V
kPadding
=
st
.
LastValue
(
d
)
;
v4
=
MaskedLoadOr
(
kPadding
m4
d
keys
+
0x4
*
kLanesPerRow
)
;
v5
=
MaskedLoadOr
(
kPadding
m5
d
keys
+
0x5
*
kLanesPerRow
)
;
v6
=
MaskedLoadOr
(
kPadding
m6
d
keys
+
0x6
*
kLanesPerRow
)
;
v7
=
MaskedLoadOr
(
kPadding
m7
d
keys
+
0x7
*
kLanesPerRow
)
;
#
endif
Sort8
(
d
st
v0
v1
v2
v3
v4
v5
v6
v7
)
;
Merge8x2
<
kKeysPerRow
>
(
d
st
v0
v1
v2
v3
v4
v5
v6
v7
)
;
Merge8x4
<
kKeysPerRow
>
(
d
st
v0
v1
v2
v3
v4
v5
v6
v7
)
;
StoreU
(
v0
d
keys
+
0x0
*
kLanesPerRow
)
;
StoreU
(
v1
d
keys
+
0x1
*
kLanesPerRow
)
;
StoreU
(
v2
d
keys
+
0x2
*
kLanesPerRow
)
;
StoreU
(
v3
d
keys
+
0x3
*
kLanesPerRow
)
;
#
if
HWY_MEM_OPS_MIGHT_FAULT
StoreU
(
v4
d
buf
+
0x4
*
kLanesPerRow
)
;
StoreU
(
v5
d
buf
+
0x5
*
kLanesPerRow
)
;
StoreU
(
v6
d
buf
+
0x6
*
kLanesPerRow
)
;
StoreU
(
v7
d
buf
+
0x7
*
kLanesPerRow
)
;
const
ScalableTag
<
T
>
dmax
;
const
size_t
Nmax
=
Lanes
(
dmax
)
;
size_t
i
=
kMinLanes
;
HWY_UNROLL
(
1
)
for
(
;
i
+
Nmax
<
=
num_lanes
;
i
+
=
Nmax
)
{
StoreU
(
LoadU
(
dmax
buf
+
i
)
dmax
keys
+
i
)
;
}
const
size_t
remaining
=
num_lanes
-
i
;
HWY_ASSUME
(
remaining
<
256
)
;
SafeCopyN
(
remaining
dmax
buf
+
i
keys
+
i
)
;
#
endif
#
if
!
HWY_MEM_OPS_MIGHT_FAULT
|
|
HWY_IDE
BlendedStore
(
v4
m4
d
keys
+
0x4
*
kLanesPerRow
)
;
BlendedStore
(
v5
m5
d
keys
+
0x5
*
kLanesPerRow
)
;
BlendedStore
(
v6
m6
d
keys
+
0x6
*
kLanesPerRow
)
;
BlendedStore
(
v7
m7
d
keys
+
0x7
*
kLanesPerRow
)
;
#
endif
}
template
<
size_t
kKeysPerRow
class
Traits
typename
T
>
HWY_NOINLINE
void
Sort16Rows
(
Traits
st
T
*
HWY_RESTRICT
keys
size_t
num_lanes
T
*
HWY_RESTRICT
buf
)
{
static_assert
(
kKeysPerRow
<
=
SortConstants
:
:
kMaxCols
"
"
)
;
constexpr
size_t
kLPK
=
st
.
LanesPerKey
(
)
;
constexpr
size_t
kRows
=
16
;
constexpr
size_t
kLanesPerRow
=
kKeysPerRow
*
kLPK
;
constexpr
size_t
kMinLanes
=
kRows
/
2
*
kLanesPerRow
;
HWY_DASSERT
(
kMinLanes
<
num_lanes
&
&
num_lanes
<
=
kRows
*
kLanesPerRow
)
;
const
CappedTag
<
T
kLanesPerRow
>
d
;
using
V
=
Vec
<
decltype
(
d
)
>
;
V
v8
v9
va
vb
vc
vd
ve
vf
;
V
v0
=
LoadU
(
d
keys
+
0x0
*
kLanesPerRow
)
;
V
v1
=
LoadU
(
d
keys
+
0x1
*
kLanesPerRow
)
;
V
v2
=
LoadU
(
d
keys
+
0x2
*
kLanesPerRow
)
;
V
v3
=
LoadU
(
d
keys
+
0x3
*
kLanesPerRow
)
;
V
v4
=
LoadU
(
d
keys
+
0x4
*
kLanesPerRow
)
;
V
v5
=
LoadU
(
d
keys
+
0x5
*
kLanesPerRow
)
;
V
v6
=
LoadU
(
d
keys
+
0x6
*
kLanesPerRow
)
;
V
v7
=
LoadU
(
d
keys
+
0x7
*
kLanesPerRow
)
;
#
if
HWY_MEM_OPS_MIGHT_FAULT
CopyHalfToPaddedBuf
<
kRows
kLanesPerRow
>
(
d
st
keys
num_lanes
buf
)
;
v8
=
LoadU
(
d
buf
+
0x8
*
kLanesPerRow
)
;
v9
=
LoadU
(
d
buf
+
0x9
*
kLanesPerRow
)
;
va
=
LoadU
(
d
buf
+
0xa
*
kLanesPerRow
)
;
vb
=
LoadU
(
d
buf
+
0xb
*
kLanesPerRow
)
;
vc
=
LoadU
(
d
buf
+
0xc
*
kLanesPerRow
)
;
vd
=
LoadU
(
d
buf
+
0xd
*
kLanesPerRow
)
;
ve
=
LoadU
(
d
buf
+
0xe
*
kLanesPerRow
)
;
vf
=
LoadU
(
d
buf
+
0xf
*
kLanesPerRow
)
;
#
endif
#
if
!
HWY_MEM_OPS_MIGHT_FAULT
|
|
HWY_IDE
(
void
)
buf
;
const
V
vnum_lanes
=
Set
(
d
ConvertScalarTo
<
T
>
(
num_lanes
)
)
;
const
V
kIota
=
Iota
(
d
static_cast
<
T
>
(
kMinLanes
)
)
;
const
V
k1
=
Set
(
d
static_cast
<
T
>
(
kLanesPerRow
)
)
;
const
V
k2
=
Add
(
k1
k1
)
;
const
V
k4
=
Add
(
k2
k2
)
;
const
V
k8
=
Add
(
k4
k4
)
;
using
M
=
Mask
<
decltype
(
d
)
>
;
const
M
m8
=
Gt
(
vnum_lanes
kIota
)
;
const
M
m9
=
Gt
(
vnum_lanes
Add
(
kIota
k1
)
)
;
const
M
ma
=
Gt
(
vnum_lanes
Add
(
kIota
k2
)
)
;
const
M
mb
=
Gt
(
vnum_lanes
Add
(
kIota
Sub
(
k4
k1
)
)
)
;
const
M
mc
=
Gt
(
vnum_lanes
Add
(
kIota
k4
)
)
;
const
M
md
=
Gt
(
vnum_lanes
Add
(
kIota
Add
(
k4
k1
)
)
)
;
const
M
me
=
Gt
(
vnum_lanes
Add
(
kIota
Add
(
k4
k2
)
)
)
;
const
M
mf
=
Gt
(
vnum_lanes
Add
(
kIota
Sub
(
k8
k1
)
)
)
;
const
V
kPadding
=
st
.
LastValue
(
d
)
;
v8
=
MaskedLoadOr
(
kPadding
m8
d
keys
+
0x8
*
kLanesPerRow
)
;
v9
=
MaskedLoadOr
(
kPadding
m9
d
keys
+
0x9
*
kLanesPerRow
)
;
va
=
MaskedLoadOr
(
kPadding
ma
d
keys
+
0xa
*
kLanesPerRow
)
;
vb
=
MaskedLoadOr
(
kPadding
mb
d
keys
+
0xb
*
kLanesPerRow
)
;
vc
=
MaskedLoadOr
(
kPadding
mc
d
keys
+
0xc
*
kLanesPerRow
)
;
vd
=
MaskedLoadOr
(
kPadding
md
d
keys
+
0xd
*
kLanesPerRow
)
;
ve
=
MaskedLoadOr
(
kPadding
me
d
keys
+
0xe
*
kLanesPerRow
)
;
vf
=
MaskedLoadOr
(
kPadding
mf
d
keys
+
0xf
*
kLanesPerRow
)
;
#
endif
Sort16
(
d
st
v0
v1
v2
v3
v4
v5
v6
v7
v8
v9
va
vb
vc
vd
ve
vf
)
;
Merge16x2
<
kKeysPerRow
>
(
d
st
v0
v1
v2
v3
v4
v5
v6
v7
v8
v9
va
vb
vc
vd
ve
vf
)
;
Merge16x4
<
kKeysPerRow
>
(
d
st
v0
v1
v2
v3
v4
v5
v6
v7
v8
v9
va
vb
vc
vd
ve
vf
)
;
Merge16x8
<
kKeysPerRow
>
(
d
st
v0
v1
v2
v3
v4
v5
v6
v7
v8
v9
va
vb
vc
vd
ve
vf
)
;
#
if
!
HWY_COMPILER_MSVC
&
&
!
HWY_IS_DEBUG_BUILD
Merge16x16
<
kKeysPerRow
>
(
d
st
v0
v1
v2
v3
v4
v5
v6
v7
v8
v9
va
vb
vc
vd
ve
vf
)
;
#
endif
StoreU
(
v0
d
keys
+
0x0
*
kLanesPerRow
)
;
StoreU
(
v1
d
keys
+
0x1
*
kLanesPerRow
)
;
StoreU
(
v2
d
keys
+
0x2
*
kLanesPerRow
)
;
StoreU
(
v3
d
keys
+
0x3
*
kLanesPerRow
)
;
StoreU
(
v4
d
keys
+
0x4
*
kLanesPerRow
)
;
StoreU
(
v5
d
keys
+
0x5
*
kLanesPerRow
)
;
StoreU
(
v6
d
keys
+
0x6
*
kLanesPerRow
)
;
StoreU
(
v7
d
keys
+
0x7
*
kLanesPerRow
)
;
#
if
HWY_MEM_OPS_MIGHT_FAULT
StoreU
(
v8
d
buf
+
0x8
*
kLanesPerRow
)
;
StoreU
(
v9
d
buf
+
0x9
*
kLanesPerRow
)
;
StoreU
(
va
d
buf
+
0xa
*
kLanesPerRow
)
;
StoreU
(
vb
d
buf
+
0xb
*
kLanesPerRow
)
;
StoreU
(
vc
d
buf
+
0xc
*
kLanesPerRow
)
;
StoreU
(
vd
d
buf
+
0xd
*
kLanesPerRow
)
;
StoreU
(
ve
d
buf
+
0xe
*
kLanesPerRow
)
;
StoreU
(
vf
d
buf
+
0xf
*
kLanesPerRow
)
;
const
ScalableTag
<
T
>
dmax
;
const
size_t
Nmax
=
Lanes
(
dmax
)
;
size_t
i
=
kMinLanes
;
HWY_UNROLL
(
1
)
for
(
;
i
+
Nmax
<
=
num_lanes
;
i
+
=
Nmax
)
{
StoreU
(
LoadU
(
dmax
buf
+
i
)
dmax
keys
+
i
)
;
}
const
size_t
remaining
=
num_lanes
-
i
;
HWY_ASSUME
(
remaining
<
256
)
;
SafeCopyN
(
remaining
dmax
buf
+
i
keys
+
i
)
;
#
endif
#
if
!
HWY_MEM_OPS_MIGHT_FAULT
|
|
HWY_IDE
BlendedStore
(
v8
m8
d
keys
+
0x8
*
kLanesPerRow
)
;
BlendedStore
(
v9
m9
d
keys
+
0x9
*
kLanesPerRow
)
;
BlendedStore
(
va
ma
d
keys
+
0xa
*
kLanesPerRow
)
;
BlendedStore
(
vb
mb
d
keys
+
0xb
*
kLanesPerRow
)
;
BlendedStore
(
vc
mc
d
keys
+
0xc
*
kLanesPerRow
)
;
BlendedStore
(
vd
md
d
keys
+
0xd
*
kLanesPerRow
)
;
BlendedStore
(
ve
me
d
keys
+
0xe
*
kLanesPerRow
)
;
BlendedStore
(
vf
mf
d
keys
+
0xf
*
kLanesPerRow
)
;
#
endif
}
template
<
class
D
class
TraitsKV
typename
T
>
HWY_NOINLINE
void
BaseCase
(
D
d
TraitsKV
T
*
HWY_RESTRICT
keys
size_t
num_lanes
T
*
buf
)
{
using
Traits
=
typename
TraitsKV
:
:
SharedTraitsForSortingNetwork
;
Traits
st
;
constexpr
size_t
kLPK
=
st
.
LanesPerKey
(
)
;
HWY_DASSERT
(
num_lanes
<
=
Constants
:
:
BaseCaseNumLanes
<
kLPK
>
(
Lanes
(
d
)
)
)
;
const
size_t
num_keys
=
num_lanes
/
kLPK
;
if
(
HWY_UNLIKELY
(
num_keys
<
=
1
)
)
return
;
const
size_t
ceil_log2
=
32
-
Num0BitsAboveMS1Bit_Nonzero32
(
static_cast
<
uint32_t
>
(
num_keys
-
1
)
)
;
constexpr
size_t
kMaxKeysPerVector
=
MaxLanes
(
d
)
/
kLPK
;
using
FuncPtr
=
decltype
(
&
Sort2To2
<
Traits
T
>
)
;
const
FuncPtr
funcs
[
9
]
=
{
nullptr
&
Sort2To2
<
Traits
T
>
&
Sort3To4
<
Traits
T
>
&
Sort8Rows
<
1
Traits
T
>
kMaxKeysPerVector
>
=
2
?
&
Sort8Rows
<
2
Traits
T
>
:
nullptr
kMaxKeysPerVector
>
=
4
?
&
Sort8Rows
<
4
Traits
T
>
:
nullptr
kMaxKeysPerVector
>
=
4
?
&
Sort16Rows
<
4
Traits
T
>
:
nullptr
kMaxKeysPerVector
>
=
8
?
&
Sort16Rows
<
8
Traits
T
>
:
nullptr
#
if
!
HWY_COMPILER_MSVC
&
&
!
HWY_IS_DEBUG_BUILD
kMaxKeysPerVector
>
=
16
?
&
Sort16Rows
<
16
Traits
T
>
:
nullptr
#
endif
}
;
funcs
[
ceil_log2
]
(
st
keys
num_lanes
buf
)
;
}
template
<
class
D
class
Traits
class
T
>
HWY_INLINE
size_t
PartitionRightmost
(
D
d
Traits
st
T
*
const
keys
const
size_t
num
const
Vec
<
D
>
pivot
size_t
&
bufL
size_t
&
writeR
T
*
HWY_RESTRICT
buf
)
{
const
size_t
N
=
Lanes
(
d
)
;
HWY_DASSERT
(
num
>
2
*
N
)
;
constexpr
size_t
kUnroll
=
Constants
:
:
kPartitionUnroll
;
size_t
num_here
;
size_t
num_main
;
{
const
size_t
remainder
=
num
&
(
kUnroll
*
N
-
1
)
;
const
size_t
min
=
remainder
+
(
remainder
<
N
?
kUnroll
*
N
:
0
)
;
num_here
=
HWY_MIN
(
min
num
)
;
num_main
=
num
-
num_here
;
if
(
num_main
<
2
*
kUnroll
*
N
)
{
num_here
=
num
;
num_main
=
0
;
}
}
HWY_DASSERT
(
num_here
>
=
N
)
;
T
*
pWriteR
=
keys
+
num
;
const
T
*
pReadR
=
pWriteR
;
bufL
=
0
;
size_t
i
=
0
;
for
(
;
i
<
=
num_here
-
N
;
i
+
=
N
)
{
pReadR
-
=
N
;
HWY_DASSERT
(
pReadR
>
=
keys
)
;
const
Vec
<
D
>
v
=
LoadU
(
d
pReadR
)
;
const
Mask
<
D
>
comp
=
st
.
Compare
(
d
pivot
v
)
;
const
size_t
numL
=
CompressStore
(
v
Not
(
comp
)
d
buf
+
bufL
)
;
bufL
+
=
numL
;
pWriteR
-
=
(
N
-
numL
)
;
HWY_DASSERT
(
pWriteR
>
=
pReadR
)
;
(
void
)
CompressBlendedStore
(
v
comp
d
pWriteR
)
;
}
const
size_t
remaining
=
num_here
-
i
;
if
(
HWY_LIKELY
(
remaining
!
=
0
)
)
{
const
Mask
<
D
>
mask
=
FirstN
(
d
remaining
)
;
pReadR
-
=
remaining
;
HWY_DASSERT
(
pReadR
>
=
keys
)
;
const
Vec
<
D
>
v
=
LoadN
(
d
pReadR
remaining
)
;
const
Mask
<
D
>
comp
=
st
.
Compare
(
d
pivot
v
)
;
const
size_t
numL
=
CompressStore
(
v
AndNot
(
comp
mask
)
d
buf
+
bufL
)
;
bufL
+
=
numL
;
pWriteR
-
=
(
remaining
-
numL
)
;
HWY_DASSERT
(
pWriteR
>
=
pReadR
)
;
(
void
)
CompressBlendedStore
(
v
And
(
comp
mask
)
d
pWriteR
)
;
}
HWY_DASSERT
(
bufL
<
=
num_here
)
;
detail
:
:
MaybeUnpoison
(
buf
bufL
)
;
writeR
=
static_cast
<
size_t
>
(
pWriteR
-
keys
)
;
const
size_t
numWrittenR
=
num
-
writeR
;
(
void
)
numWrittenR
;
HWY_DASSERT
(
numWrittenR
<
=
num_here
)
;
HWY_DASSERT
(
pReadR
=
=
keys
+
num_main
)
;
HWY_DASSERT
(
bufL
+
numWrittenR
=
=
num_here
)
;
return
num_main
;
}
template
<
class
D
class
Traits
typename
T
>
HWY_INLINE
void
StoreLeftRight
(
D
d
Traits
st
const
Vec
<
D
>
v
const
Vec
<
D
>
pivot
T
*
HWY_RESTRICT
keys
size_t
&
writeL
size_t
&
remaining
)
{
const
size_t
N
=
Lanes
(
d
)
;
const
Mask
<
D
>
comp
=
st
.
Compare
(
d
pivot
v
)
;
HWY_DASSERT
(
remaining
>
=
2
*
N
)
;
remaining
-
=
N
;
if
(
hwy
:
:
HWY_NAMESPACE
:
:
CompressIsPartition
<
T
>
:
:
value
|
|
(
HWY_MAX_BYTES
=
=
16
&
&
st
.
Is128
(
)
)
)
{
const
Vec
<
D
>
lr
=
st
.
CompressKeys
(
v
comp
)
;
const
size_t
num_left
=
N
-
CountTrue
(
d
comp
)
;
StoreU
(
lr
d
keys
+
writeL
)
;
StoreU
(
lr
d
keys
+
remaining
+
writeL
)
;
writeL
+
=
num_left
;
}
else
{
const
size_t
num_left
=
CompressStore
(
v
Not
(
comp
)
d
keys
+
writeL
)
;
writeL
+
=
num_left
;
(
void
)
CompressBlendedStore
(
v
comp
d
keys
+
remaining
+
writeL
)
;
}
}
template
<
class
D
class
Traits
typename
T
>
HWY_INLINE
void
StoreLeftRight4
(
D
d
Traits
st
const
Vec
<
D
>
v0
const
Vec
<
D
>
v1
const
Vec
<
D
>
v2
const
Vec
<
D
>
v3
const
Vec
<
D
>
pivot
T
*
HWY_RESTRICT
keys
size_t
&
writeL
size_t
&
remaining
)
{
StoreLeftRight
(
d
st
v0
pivot
keys
writeL
remaining
)
;
StoreLeftRight
(
d
st
v1
pivot
keys
writeL
remaining
)
;
StoreLeftRight
(
d
st
v2
pivot
keys
writeL
remaining
)
;
StoreLeftRight
(
d
st
v3
pivot
keys
writeL
remaining
)
;
}
template
<
class
D
class
Traits
typename
T
>
HWY_INLINE
void
StoreRightAndBuf
(
D
d
Traits
st
const
Vec
<
D
>
v
const
Vec
<
D
>
pivot
T
*
HWY_RESTRICT
keys
size_t
&
writeR
T
*
HWY_RESTRICT
buf
size_t
&
bufL
)
{
const
size_t
N
=
Lanes
(
d
)
;
const
Mask
<
D
>
comp
=
st
.
Compare
(
d
pivot
v
)
;
const
size_t
numL
=
CompressStore
(
v
Not
(
comp
)
d
buf
+
bufL
)
;
bufL
+
=
numL
;
writeR
-
=
(
N
-
numL
)
;
(
void
)
CompressBlendedStore
(
v
comp
d
keys
+
writeR
)
;
}
template
<
class
D
class
Traits
typename
T
>
HWY_INLINE
size_t
Partition
(
D
d
Traits
st
T
*
const
keys
const
size_t
num
const
Vec
<
D
>
pivot
T
*
HWY_RESTRICT
buf
)
{
using
V
=
decltype
(
Zero
(
d
)
)
;
const
size_t
N
=
Lanes
(
d
)
;
size_t
bufL
writeR
;
const
size_t
num_main
=
PartitionRightmost
(
d
st
keys
num
pivot
bufL
writeR
buf
)
;
HWY_DASSERT
(
num_main
<
=
num
&
&
writeR
<
=
num
)
;
HWY_DASSERT
(
bufL
<
=
Constants
:
:
PartitionBufNum
(
N
)
)
;
HWY_DASSERT
(
num_main
+
bufL
=
=
writeR
)
;
if
(
VQSORT_PRINT
>
=
3
)
{
fprintf
(
stderr
"
num_main
%
zu
bufL
%
zu
writeR
%
zu
\
n
"
num_main
bufL
writeR
)
;
}
constexpr
size_t
kUnroll
=
Constants
:
:
kPartitionUnroll
;
size_t
writeL
=
0
;
size_t
remaining
=
writeR
-
writeL
;
const
T
*
readL
=
keys
;
const
T
*
readR
=
keys
+
num_main
;
if
(
HWY_LIKELY
(
num_main
!
=
0
)
)
{
HWY_DASSERT
(
num_main
>
=
2
*
kUnroll
*
N
)
;
HWY_DASSERT
(
(
num_main
&
(
kUnroll
*
N
-
1
)
)
=
=
0
)
;
const
V
vL0
=
LoadU
(
d
readL
+
0
*
N
)
;
const
V
vL1
=
LoadU
(
d
readL
+
1
*
N
)
;
const
V
vL2
=
LoadU
(
d
readL
+
2
*
N
)
;
const
V
vL3
=
LoadU
(
d
readL
+
3
*
N
)
;
readL
+
=
kUnroll
*
N
;
readR
-
=
kUnroll
*
N
;
const
V
vR0
=
LoadU
(
d
readR
+
0
*
N
)
;
const
V
vR1
=
LoadU
(
d
readR
+
1
*
N
)
;
const
V
vR2
=
LoadU
(
d
readR
+
2
*
N
)
;
const
V
vR3
=
LoadU
(
d
readR
+
3
*
N
)
;
while
(
readL
!
=
readR
)
{
V
v0
v1
v2
v3
;
const
size_t
capacityL
=
static_cast
<
size_t
>
(
(
readL
-
keys
)
-
static_cast
<
ptrdiff_t
>
(
writeL
)
)
;
HWY_DASSERT
(
capacityL
<
=
num_main
)
;
if
(
capacityL
>
kUnroll
*
N
)
{
readR
-
=
kUnroll
*
N
;
v0
=
LoadU
(
d
readR
+
0
*
N
)
;
v1
=
LoadU
(
d
readR
+
1
*
N
)
;
v2
=
LoadU
(
d
readR
+
2
*
N
)
;
v3
=
LoadU
(
d
readR
+
3
*
N
)
;
hwy
:
:
Prefetch
(
readR
-
3
*
kUnroll
*
N
)
;
}
else
{
v0
=
LoadU
(
d
readL
+
0
*
N
)
;
v1
=
LoadU
(
d
readL
+
1
*
N
)
;
v2
=
LoadU
(
d
readL
+
2
*
N
)
;
v3
=
LoadU
(
d
readL
+
3
*
N
)
;
readL
+
=
kUnroll
*
N
;
hwy
:
:
Prefetch
(
readL
+
3
*
kUnroll
*
N
)
;
}
StoreLeftRight4
(
d
st
v0
v1
v2
v3
pivot
keys
writeL
remaining
)
;
}
StoreLeftRight4
(
d
st
vL0
vL1
vL2
vL3
pivot
keys
writeL
remaining
)
;
StoreLeftRight
(
d
st
vR0
pivot
keys
writeL
remaining
)
;
StoreLeftRight
(
d
st
vR1
pivot
keys
writeL
remaining
)
;
HWY_DASSERT
(
remaining
=
=
bufL
+
2
*
N
)
;
writeR
=
writeL
+
remaining
;
StoreRightAndBuf
(
d
st
vR2
pivot
keys
writeR
buf
bufL
)
;
StoreRightAndBuf
(
d
st
vR3
pivot
keys
writeR
buf
bufL
)
;
HWY_DASSERT
(
writeR
<
=
num
)
;
HWY_DASSERT
(
bufL
<
=
Constants
:
:
PartitionBufNum
(
N
)
)
;
}
HWY_DASSERT
(
writeL
+
bufL
=
=
writeR
)
;
CopyBytes
(
buf
keys
+
writeL
bufL
*
sizeof
(
T
)
)
;
return
writeL
+
bufL
;
}
template
<
class
D
class
Traits
typename
T
>
HWY_NOINLINE
bool
MaybePartitionTwoValue
(
D
d
Traits
st
T
*
HWY_RESTRICT
keys
size_t
num
const
Vec
<
D
>
valueL
const
Vec
<
D
>
valueR
Vec
<
D
>
&
third
T
*
HWY_RESTRICT
buf
)
{
const
size_t
N
=
Lanes
(
d
)
;
size_t
i
=
0
;
size_t
writeL
=
0
;
if
(
num
>
=
N
)
{
for
(
;
i
<
=
num
-
N
;
i
+
=
N
)
{
const
Vec
<
D
>
v
=
LoadU
(
d
keys
+
i
)
;
const
Mask
<
D
>
eqL
=
st
.
EqualKeys
(
d
v
valueL
)
;
const
Mask
<
D
>
eqR
=
st
.
EqualKeys
(
d
v
valueR
)
;
if
(
HWY_UNLIKELY
(
!
AllTrue
(
d
Or
(
eqL
eqR
)
)
)
)
{
const
size_t
lane
=
FindKnownFirstTrue
(
d
ExclusiveNeither
(
eqL
eqR
)
)
;
third
=
st
.
SetKey
(
d
keys
+
i
+
lane
)
;
if
(
VQSORT_PRINT
>
=
2
)
{
fprintf
(
stderr
"
found
3rd
value
at
vec
%
zu
;
writeL
%
zu
\
n
"
i
writeL
)
;
}
if
(
i
>
=
N
)
{
for
(
;
writeL
<
=
i
-
N
;
writeL
+
=
N
)
{
StoreU
(
valueR
d
keys
+
writeL
)
;
}
}
BlendedStore
(
valueR
FirstN
(
d
i
-
writeL
)
d
keys
+
writeL
)
;
return
false
;
}
StoreU
(
valueL
d
keys
+
writeL
)
;
writeL
+
=
CountTrue
(
d
eqL
)
;
}
}
const
size_t
remaining
=
num
-
i
;
SafeCopyN
(
remaining
d
keys
+
i
buf
)
;
const
Vec
<
D
>
v
=
Load
(
d
buf
)
;
const
Mask
<
D
>
valid
=
FirstN
(
d
remaining
)
;
const
Mask
<
D
>
eqL
=
And
(
st
.
EqualKeys
(
d
v
valueL
)
valid
)
;
const
Mask
<
D
>
eqR
=
st
.
EqualKeys
(
d
v
valueR
)
;
const
Mask
<
D
>
eq
=
Or
(
Or
(
eqL
eqR
)
Not
(
valid
)
)
;
if
(
HWY_UNLIKELY
(
!
AllTrue
(
d
eq
)
)
)
{
const
size_t
lane
=
FindKnownFirstTrue
(
d
Not
(
eq
)
)
;
third
=
st
.
SetKey
(
d
keys
+
i
+
lane
)
;
if
(
VQSORT_PRINT
>
=
2
)
{
fprintf
(
stderr
"
found
3rd
value
at
partial
vec
%
zu
;
writeL
%
zu
\
n
"
i
writeL
)
;
}
if
(
i
>
=
N
)
{
for
(
;
writeL
<
=
i
-
N
;
writeL
+
=
N
)
{
StoreU
(
valueR
d
keys
+
writeL
)
;
}
}
BlendedStore
(
valueR
FirstN
(
d
i
-
writeL
)
d
keys
+
writeL
)
;
return
false
;
}
BlendedStore
(
valueL
valid
d
keys
+
writeL
)
;
writeL
+
=
CountTrue
(
d
eqL
)
;
i
=
writeL
;
if
(
num
>
=
N
)
{
for
(
;
i
<
=
num
-
N
;
i
+
=
N
)
{
StoreU
(
valueR
d
keys
+
i
)
;
}
}
BlendedStore
(
valueR
FirstN
(
d
num
-
i
)
d
keys
+
i
)
;
if
(
VQSORT_PRINT
>
=
2
)
{
fprintf
(
stderr
"
Successful
MaybePartitionTwoValue
\
n
"
)
;
}
return
true
;
}
template
<
class
D
class
Traits
typename
T
>
HWY_INLINE
bool
MaybePartitionTwoValueR
(
D
d
Traits
st
T
*
HWY_RESTRICT
keys
size_t
num
const
Vec
<
D
>
valueL
const
Vec
<
D
>
valueR
Vec
<
D
>
&
third
T
*
HWY_RESTRICT
buf
)
{
const
size_t
N
=
Lanes
(
d
)
;
HWY_DASSERT
(
num
>
=
N
)
;
size_t
pos
=
num
-
N
;
size_t
countR
=
0
;
for
(
;
pos
<
num
;
pos
-
=
N
)
{
const
Vec
<
D
>
v
=
LoadU
(
d
keys
+
pos
)
;
const
Mask
<
D
>
eqL
=
st
.
EqualKeys
(
d
v
valueL
)
;
const
Mask
<
D
>
eqR
=
st
.
EqualKeys
(
d
v
valueR
)
;
if
(
HWY_UNLIKELY
(
!
AllTrue
(
d
Or
(
eqL
eqR
)
)
)
)
{
const
size_t
lane
=
FindKnownFirstTrue
(
d
ExclusiveNeither
(
eqL
eqR
)
)
;
third
=
st
.
SetKey
(
d
keys
+
pos
+
lane
)
;
if
(
VQSORT_PRINT
>
=
2
)
{
fprintf
(
stderr
"
found
3rd
value
at
vec
%
zu
;
countR
%
zu
\
n
"
pos
countR
)
;
MaybePrintVector
(
d
"
third
"
third
0
st
.
LanesPerKey
(
)
)
;
}
pos
+
=
N
;
HWY_DASSERT
(
countR
<
=
num
-
pos
)
;
const
size_t
endL
=
num
-
countR
;
if
(
endL
>
=
N
)
{
for
(
;
pos
<
=
endL
-
N
;
pos
+
=
N
)
{
StoreU
(
valueL
d
keys
+
pos
)
;
}
}
BlendedStore
(
valueL
FirstN
(
d
endL
-
pos
)
d
keys
+
pos
)
;
return
false
;
}
StoreU
(
valueR
d
keys
+
pos
)
;
countR
+
=
CountTrue
(
d
eqR
)
;
}
const
size_t
remaining
=
pos
+
N
;
HWY_DASSERT
(
remaining
<
=
N
)
;
const
Vec
<
D
>
v
=
LoadU
(
d
keys
)
;
const
Mask
<
D
>
valid
=
FirstN
(
d
remaining
)
;
const
Mask
<
D
>
eqL
=
st
.
EqualKeys
(
d
v
valueL
)
;
const
Mask
<
D
>
eqR
=
And
(
st
.
EqualKeys
(
d
v
valueR
)
valid
)
;
const
Mask
<
D
>
eq
=
Or
(
Or
(
eqL
eqR
)
Not
(
valid
)
)
;
if
(
HWY_UNLIKELY
(
!
AllTrue
(
d
eq
)
)
)
{
const
size_t
lane
=
FindKnownFirstTrue
(
d
Not
(
eq
)
)
;
third
=
st
.
SetKey
(
d
keys
+
lane
)
;
if
(
VQSORT_PRINT
>
=
2
)
{
fprintf
(
stderr
"
found
3rd
value
at
partial
vec
%
zu
;
writeR
%
zu
\
n
"
pos
countR
)
;
MaybePrintVector
(
d
"
third
"
third
0
st
.
LanesPerKey
(
)
)
;
}
pos
+
=
N
;
HWY_DASSERT
(
countR
<
=
num
-
pos
)
;
const
size_t
endL
=
num
-
countR
;
if
(
endL
>
=
N
)
{
for
(
;
pos
<
=
endL
-
N
;
pos
+
=
N
)
{
StoreU
(
valueL
d
keys
+
pos
)
;
}
}
BlendedStore
(
valueL
FirstN
(
d
endL
-
pos
)
d
keys
+
pos
)
;
return
false
;
}
const
size_t
lastR
=
CountTrue
(
d
eqR
)
;
countR
+
=
lastR
;
StoreU
(
valueR
d
keys
)
;
const
size_t
endL
=
num
-
countR
;
size_t
i
=
0
;
if
(
endL
>
=
N
)
{
for
(
;
i
<
=
endL
-
N
;
i
+
=
N
)
{
StoreU
(
valueL
d
keys
+
i
)
;
}
}
Store
(
valueL
d
buf
)
;
SafeCopyN
(
endL
-
i
d
buf
keys
+
i
)
;
if
(
VQSORT_PRINT
>
=
2
)
{
fprintf
(
stderr
"
MaybePartitionTwoValueR
countR
%
zu
pos
%
zu
i
%
zu
endL
%
zu
\
n
"
countR
pos
i
endL
)
;
}
return
true
;
}
template
<
class
D
class
Traits
typename
T
>
HWY_INLINE
bool
PartitionIfTwoKeys
(
D
d
Traits
st
const
Vec
<
D
>
pivot
T
*
HWY_RESTRICT
keys
size_t
num
const
size_t
idx_second
const
Vec
<
D
>
second
Vec
<
D
>
&
third
T
*
HWY_RESTRICT
buf
)
{
const
bool
is_pivotR
=
AllFalse
(
d
st
.
Compare
(
d
pivot
second
)
)
;
if
(
VQSORT_PRINT
>
=
1
)
{
fprintf
(
stderr
"
Samples
all
equal
diff
at
%
zu
isPivotR
%
d
\
n
"
idx_second
is_pivotR
)
;
}
HWY_DASSERT
(
AllFalse
(
d
st
.
EqualKeys
(
d
second
pivot
)
)
)
;
return
is_pivotR
?
MaybePartitionTwoValueR
(
d
st
keys
num
second
pivot
third
buf
)
:
MaybePartitionTwoValue
(
d
st
keys
+
idx_second
num
-
idx_second
pivot
second
third
buf
)
;
}
template
<
class
D
class
Traits
typename
T
>
HWY_INLINE
bool
PartitionIfTwoSamples
(
D
d
Traits
st
T
*
HWY_RESTRICT
keys
size_t
num
T
*
HWY_RESTRICT
samples
)
{
constexpr
size_t
kSampleLanes
=
Constants
:
:
SampleLanes
<
T
>
(
)
;
constexpr
size_t
N1
=
st
.
LanesPerKey
(
)
;
const
Vec
<
D
>
valueL
=
st
.
SetKey
(
d
samples
)
;
const
Vec
<
D
>
valueR
=
st
.
SetKey
(
d
samples
+
kSampleLanes
-
N1
)
;
HWY_DASSERT
(
AllTrue
(
d
st
.
Compare
(
d
valueL
valueR
)
)
)
;
HWY_DASSERT
(
AllFalse
(
d
st
.
EqualKeys
(
d
valueL
valueR
)
)
)
;
const
Vec
<
D
>
prev
=
st
.
PrevValue
(
d
valueR
)
;
if
(
HWY_UNLIKELY
(
!
AllTrue
(
d
st
.
EqualKeys
(
d
valueL
prev
)
)
)
)
{
return
false
;
}
T
*
HWY_RESTRICT
buf
=
samples
+
kSampleLanes
;
Vec
<
D
>
third
;
return
MaybePartitionTwoValue
(
d
st
keys
num
valueL
valueR
third
buf
)
;
}
template
<
class
Traits
class
V
>
HWY_INLINE
V
MedianOf3
(
Traits
st
V
v0
V
v1
V
v2
)
{
const
DFromV
<
V
>
d
;
if
(
st
.
Is128
(
)
)
{
const
V
sum
=
Xor
(
Xor
(
v0
v1
)
v2
)
;
const
V
first
=
st
.
First
(
d
st
.
First
(
d
v0
v1
)
v2
)
;
const
V
last
=
st
.
Last
(
d
st
.
Last
(
d
v0
v1
)
v2
)
;
return
Xor
(
Xor
(
sum
first
)
last
)
;
}
st
.
Sort2
(
d
v0
v2
)
;
v1
=
st
.
Last
(
d
v0
v1
)
;
v1
=
st
.
First
(
d
v1
v2
)
;
return
v1
;
}
HWY_INLINE
uint64_t
RandomBits
(
uint64_t
*
HWY_RESTRICT
state
)
{
const
uint64_t
a
=
state
[
0
]
;
const
uint64_t
b
=
state
[
1
]
;
const
uint64_t
w
=
state
[
2
]
+
1
;
const
uint64_t
next
=
a
^
w
;
state
[
0
]
=
(
b
+
(
b
<
<
3
)
)
^
(
b
>
>
11
)
;
const
uint64_t
rot
=
(
b
<
<
24
)
|
(
b
>
>
40
)
;
state
[
1
]
=
rot
+
next
;
state
[
2
]
=
w
;
return
next
;
}
HWY_INLINE
size_t
RandomChunkIndex
(
const
uint32_t
num_chunks
uint32_t
bits
)
{
const
uint64_t
chunk_index
=
(
static_cast
<
uint64_t
>
(
bits
)
*
num_chunks
)
>
>
32
;
HWY_DASSERT
(
chunk_index
<
num_chunks
)
;
return
static_cast
<
size_t
>
(
chunk_index
)
;
}
template
<
class
D
class
Traits
typename
T
>
HWY_INLINE
void
DrawSamples
(
D
d
Traits
st
T
*
HWY_RESTRICT
keys
size_t
num
T
*
HWY_RESTRICT
buf
uint64_t
*
HWY_RESTRICT
state
)
{
using
V
=
decltype
(
Zero
(
d
)
)
;
const
size_t
N
=
Lanes
(
d
)
;
constexpr
size_t
kLanesPerChunk
=
Constants
:
:
LanesPerChunk
(
sizeof
(
T
)
)
;
HWY_DASSERT
(
num
>
=
Constants
:
:
SampleLanes
<
T
>
(
)
)
;
const
size_t
misalign
=
(
reinterpret_cast
<
uintptr_t
>
(
keys
)
/
sizeof
(
T
)
)
&
(
kLanesPerChunk
-
1
)
;
if
(
misalign
!
=
0
)
{
const
size_t
consume
=
kLanesPerChunk
-
misalign
;
keys
+
=
consume
;
num
-
=
consume
;
}
uint32_t
bits
[
6
]
;
for
(
size_t
i
=
0
;
i
<
6
;
i
+
=
2
)
{
const
uint64_t
bits64
=
RandomBits
(
state
)
;
CopyBytes
<
8
>
(
&
bits64
bits
+
i
)
;
}
const
size_t
num_chunks64
=
num
/
kLanesPerChunk
;
const
uint32_t
num_chunks
=
static_cast
<
uint32_t
>
(
HWY_MIN
(
num_chunks64
0xFFFFFFFFull
)
)
;
const
size_t
offset0
=
RandomChunkIndex
(
num_chunks
bits
[
0
]
)
*
kLanesPerChunk
;
const
size_t
offset1
=
RandomChunkIndex
(
num_chunks
bits
[
1
]
)
*
kLanesPerChunk
;
const
size_t
offset2
=
RandomChunkIndex
(
num_chunks
bits
[
2
]
)
*
kLanesPerChunk
;
const
size_t
offset3
=
RandomChunkIndex
(
num_chunks
bits
[
3
]
)
*
kLanesPerChunk
;
const
size_t
offset4
=
RandomChunkIndex
(
num_chunks
bits
[
4
]
)
*
kLanesPerChunk
;
const
size_t
offset5
=
RandomChunkIndex
(
num_chunks
bits
[
5
]
)
*
kLanesPerChunk
;
for
(
size_t
i
=
0
;
i
<
kLanesPerChunk
;
i
+
=
N
)
{
const
V
v0
=
Load
(
d
keys
+
offset0
+
i
)
;
const
V
v1
=
Load
(
d
keys
+
offset1
+
i
)
;
const
V
v2
=
Load
(
d
keys
+
offset2
+
i
)
;
const
V
medians0
=
MedianOf3
(
st
v0
v1
v2
)
;
Store
(
medians0
d
buf
+
i
)
;
const
V
v3
=
Load
(
d
keys
+
offset3
+
i
)
;
const
V
v4
=
Load
(
d
keys
+
offset4
+
i
)
;
const
V
v5
=
Load
(
d
keys
+
offset5
+
i
)
;
const
V
medians1
=
MedianOf3
(
st
v3
v4
v5
)
;
Store
(
medians1
d
buf
+
i
+
kLanesPerChunk
)
;
}
}
template
<
class
V
>
V
OrXor
(
const
V
o
const
V
x1
const
V
x2
)
{
return
Or
(
o
Xor
(
x1
x2
)
)
;
}
template
<
class
D
class
Traits
>
HWY_INLINE
bool
UnsortedSampleEqual
(
D
d
Traits
st
const
TFromD
<
D
>
*
HWY_RESTRICT
samples
)
{
constexpr
size_t
kSampleLanes
=
Constants
:
:
SampleLanes
<
TFromD
<
D
>
>
(
)
;
const
size_t
N
=
Lanes
(
d
)
;
HWY_DASSERT
(
N
<
kSampleLanes
)
;
using
V
=
Vec
<
D
>
;
const
V
first
=
st
.
SetKey
(
d
samples
)
;
if
(
!
hwy
:
:
IsFloat
<
TFromD
<
D
>
>
(
)
)
{
V
diff
=
Zero
(
d
)
;
for
(
size_t
i
=
0
;
i
<
kSampleLanes
;
i
+
=
N
)
{
const
V
v
=
Load
(
d
samples
+
i
)
;
diff
=
OrXor
(
diff
first
v
)
;
}
return
st
.
NoKeyDifference
(
d
diff
)
;
}
else
{
for
(
size_t
i
=
0
;
i
<
kSampleLanes
;
i
+
=
N
)
{
const
V
v
=
Load
(
d
samples
+
i
)
;
if
(
!
AllTrue
(
d
st
.
EqualKeys
(
d
v
first
)
)
)
{
return
false
;
}
}
return
true
;
}
}
template
<
class
D
class
Traits
typename
T
>
HWY_INLINE
void
SortSamples
(
D
d
Traits
st
T
*
HWY_RESTRICT
buf
)
{
const
size_t
N
=
Lanes
(
d
)
;
constexpr
size_t
kSampleLanes
=
Constants
:
:
SampleLanes
<
T
>
(
)
;
HWY_DASSERT
(
Constants
:
:
BaseCaseNumLanes
<
st
.
LanesPerKey
(
)
>
(
N
)
>
=
kSampleLanes
)
;
BaseCase
(
d
st
buf
kSampleLanes
buf
+
kSampleLanes
)
;
if
(
VQSORT_PRINT
>
=
2
)
{
fprintf
(
stderr
"
Samples
:
\
n
"
)
;
for
(
size_t
i
=
0
;
i
<
kSampleLanes
;
i
+
=
N
)
{
MaybePrintVector
(
d
"
"
Load
(
d
buf
+
i
)
0
N
)
;
}
}
}
enum
class
PivotResult
{
kDone
kNormal
kIsFirst
kWasLast
}
;
HWY_INLINE
const
char
*
PivotResultString
(
PivotResult
result
)
{
switch
(
result
)
{
case
PivotResult
:
:
kDone
:
return
"
done
"
;
case
PivotResult
:
:
kNormal
:
return
"
normal
"
;
case
PivotResult
:
:
kIsFirst
:
return
"
first
"
;
case
PivotResult
:
:
kWasLast
:
return
"
last
"
;
}
return
"
unknown
"
;
}
template
<
class
Traits
typename
T
>
HWY_INLINE
size_t
PivotRank
(
Traits
st
const
T
*
HWY_RESTRICT
samples
)
{
constexpr
size_t
kSampleLanes
=
Constants
:
:
SampleLanes
<
T
>
(
)
;
constexpr
size_t
N1
=
st
.
LanesPerKey
(
)
;
constexpr
size_t
kRankMid
=
kSampleLanes
/
2
;
static_assert
(
kRankMid
%
N1
=
=
0
"
Mid
is
not
an
aligned
key
"
)
;
size_t
rank_prev
=
kRankMid
-
N1
;
for
(
;
st
.
Equal1
(
samples
+
rank_prev
samples
+
kRankMid
)
;
rank_prev
-
=
N1
)
{
if
(
rank_prev
=
=
0
)
return
0
;
}
size_t
rank_next
=
rank_prev
+
N1
;
for
(
;
st
.
Equal1
(
samples
+
rank_next
samples
+
kRankMid
)
;
rank_next
+
=
N1
)
{
if
(
rank_next
=
=
kSampleLanes
-
N1
)
return
rank_prev
;
}
const
size_t
excess_if_median
=
rank_next
-
kRankMid
;
const
size_t
excess_if_prev
=
kRankMid
-
rank_prev
;
return
excess_if_median
<
excess_if_prev
?
kRankMid
:
rank_prev
;
}
template
<
class
D
class
Traits
typename
T
>
HWY_INLINE
Vec
<
D
>
ChoosePivotByRank
(
D
d
Traits
st
const
T
*
HWY_RESTRICT
samples
)
{
const
size_t
pivot_rank
=
PivotRank
(
st
samples
)
;
const
Vec
<
D
>
pivot
=
st
.
SetKey
(
d
samples
+
pivot_rank
)
;
if
(
VQSORT_PRINT
>
=
2
)
{
fprintf
(
stderr
"
Pivot
rank
%
3zu
\
n
"
pivot_rank
)
;
HWY_ALIGN
T
pivot_lanes
[
MaxLanes
(
d
)
]
;
Store
(
pivot
d
pivot_lanes
)
;
using
KeyType
=
typename
Traits
:
:
KeyType
;
KeyType
key
;
CopyBytes
<
sizeof
(
KeyType
)
>
(
pivot_lanes
&
key
)
;
PrintValue
(
key
)
;
}
constexpr
size_t
kSampleLanes
=
Constants
:
:
SampleLanes
<
T
>
(
)
;
constexpr
size_t
N1
=
st
.
LanesPerKey
(
)
;
const
Vec
<
D
>
last
=
st
.
SetKey
(
d
samples
+
kSampleLanes
-
N1
)
;
const
bool
all_neq
=
AllTrue
(
d
st
.
NotEqualKeys
(
d
pivot
last
)
)
;
(
void
)
all_neq
;
HWY_DASSERT
(
all_neq
)
;
return
pivot
;
}
template
<
class
D
class
Traits
typename
T
>
HWY_INLINE
bool
AllEqual
(
D
d
Traits
st
const
Vec
<
D
>
pivot
const
T
*
HWY_RESTRICT
keys
size_t
num
size_t
*
HWY_RESTRICT
first_mismatch
)
{
const
size_t
N
=
Lanes
(
d
)
;
HWY_DASSERT
(
num
>
=
N
)
;
const
Vec
<
D
>
zero
=
Zero
(
d
)
;
const
size_t
misalign
=
(
reinterpret_cast
<
uintptr_t
>
(
keys
)
/
sizeof
(
T
)
)
&
(
N
-
1
)
;
HWY_DASSERT
(
misalign
%
st
.
LanesPerKey
(
)
=
=
0
)
;
const
size_t
consume
=
N
-
misalign
;
{
const
Vec
<
D
>
v
=
LoadU
(
d
keys
)
;
const
Mask
<
D
>
diff
=
And
(
FirstN
(
d
consume
)
st
.
NotEqualKeys
(
d
v
pivot
)
)
;
if
(
HWY_UNLIKELY
(
!
AllFalse
(
d
diff
)
)
)
{
const
size_t
lane
=
FindKnownFirstTrue
(
d
diff
)
;
*
first_mismatch
=
lane
;
return
false
;
}
}
size_t
i
=
consume
;
HWY_DASSERT
(
(
(
reinterpret_cast
<
uintptr_t
>
(
keys
+
i
)
/
sizeof
(
T
)
)
&
(
N
-
1
)
)
=
=
0
)
;
if
(
!
hwy
:
:
IsFloat
<
T
>
(
)
)
{
Vec
<
D
>
diff0
=
zero
;
Vec
<
D
>
diff1
=
zero
;
constexpr
size_t
kLoops
=
8
;
const
size_t
lanes_per_group
=
kLoops
*
2
*
N
;
if
(
num
>
=
lanes_per_group
)
{
for
(
;
i
<
=
num
-
lanes_per_group
;
i
+
=
lanes_per_group
)
{
HWY_DEFAULT_UNROLL
for
(
size_t
loop
=
0
;
loop
<
kLoops
;
+
+
loop
)
{
const
Vec
<
D
>
v0
=
Load
(
d
keys
+
i
+
loop
*
2
*
N
)
;
const
Vec
<
D
>
v1
=
Load
(
d
keys
+
i
+
loop
*
2
*
N
+
N
)
;
diff0
=
OrXor
(
diff0
v0
pivot
)
;
diff1
=
OrXor
(
diff1
v1
pivot
)
;
}
if
(
HWY_UNLIKELY
(
!
st
.
NoKeyDifference
(
d
Or
(
diff0
diff1
)
)
)
)
{
for
(
;
;
i
+
=
N
)
{
const
Vec
<
D
>
v
=
Load
(
d
keys
+
i
)
;
const
Mask
<
D
>
diff
=
st
.
NotEqualKeys
(
d
v
pivot
)
;
if
(
HWY_UNLIKELY
(
!
AllFalse
(
d
diff
)
)
)
{
const
size_t
lane
=
FindKnownFirstTrue
(
d
diff
)
;
*
first_mismatch
=
i
+
lane
;
return
false
;
}
}
}
}
}
}
for
(
;
i
<
=
num
-
N
;
i
+
=
N
)
{
const
Vec
<
D
>
v
=
Load
(
d
keys
+
i
)
;
const
Mask
<
D
>
diff
=
st
.
NotEqualKeys
(
d
v
pivot
)
;
if
(
HWY_UNLIKELY
(
!
AllFalse
(
d
diff
)
)
)
{
const
size_t
lane
=
FindKnownFirstTrue
(
d
diff
)
;
*
first_mismatch
=
i
+
lane
;
return
false
;
}
}
i
=
num
-
N
;
const
Vec
<
D
>
v
=
LoadU
(
d
keys
+
i
)
;
const
Mask
<
D
>
diff
=
st
.
NotEqualKeys
(
d
v
pivot
)
;
if
(
HWY_UNLIKELY
(
!
AllFalse
(
d
diff
)
)
)
{
const
size_t
lane
=
FindKnownFirstTrue
(
d
diff
)
;
*
first_mismatch
=
i
+
lane
;
return
false
;
}
if
(
VQSORT_PRINT
>
=
1
)
{
fprintf
(
stderr
"
All
keys
equal
\
n
"
)
;
}
return
true
;
}
template
<
class
D
class
Traits
typename
T
>
HWY_INLINE
bool
ExistsAnyBefore
(
D
d
Traits
st
const
T
*
HWY_RESTRICT
keys
size_t
num
const
Vec
<
D
>
pivot
)
{
const
size_t
N
=
Lanes
(
d
)
;
HWY_DASSERT
(
num
>
=
N
)
;
if
(
VQSORT_PRINT
>
=
2
)
{
fprintf
(
stderr
"
Scanning
for
before
\
n
"
)
;
}
size_t
i
=
0
;
constexpr
size_t
kLoops
=
16
;
const
size_t
lanes_per_group
=
kLoops
*
N
;
Vec
<
D
>
first
=
pivot
;
if
(
num
>
=
lanes_per_group
)
{
for
(
;
i
<
=
num
-
lanes_per_group
;
i
+
=
lanes_per_group
)
{
HWY_DEFAULT_UNROLL
for
(
size_t
loop
=
0
;
loop
<
kLoops
;
+
+
loop
)
{
const
Vec
<
D
>
curr
=
LoadU
(
d
keys
+
i
+
loop
*
N
)
;
first
=
st
.
First
(
d
first
curr
)
;
}
if
(
HWY_UNLIKELY
(
!
AllFalse
(
d
st
.
Compare
(
d
first
pivot
)
)
)
)
{
if
(
VQSORT_PRINT
>
=
2
)
{
fprintf
(
stderr
"
Stopped
scanning
at
end
of
group
%
zu
\
n
"
i
+
lanes_per_group
)
;
}
return
true
;
}
}
}
for
(
;
i
<
=
num
-
N
;
i
+
=
N
)
{
const
Vec
<
D
>
curr
=
LoadU
(
d
keys
+
i
)
;
if
(
HWY_UNLIKELY
(
!
AllFalse
(
d
st
.
Compare
(
d
curr
pivot
)
)
)
)
{
if
(
VQSORT_PRINT
>
=
2
)
{
fprintf
(
stderr
"
Stopped
scanning
at
%
zu
\
n
"
i
)
;
}
return
true
;
}
}
if
(
HWY_LIKELY
(
i
!
=
num
)
)
{
const
Vec
<
D
>
curr
=
LoadU
(
d
keys
+
num
-
N
)
;
if
(
HWY_UNLIKELY
(
!
AllFalse
(
d
st
.
Compare
(
d
curr
pivot
)
)
)
)
{
if
(
VQSORT_PRINT
>
=
2
)
{
fprintf
(
stderr
"
Stopped
scanning
at
last
%
zu
\
n
"
num
-
N
)
;
}
return
true
;
}
}
return
false
;
}
template
<
class
D
class
Traits
typename
T
>
HWY_INLINE
bool
ExistsAnyAfter
(
D
d
Traits
st
const
T
*
HWY_RESTRICT
keys
size_t
num
const
Vec
<
D
>
pivot
)
{
const
size_t
N
=
Lanes
(
d
)
;
HWY_DASSERT
(
num
>
=
N
)
;
if
(
VQSORT_PRINT
>
=
2
)
{
fprintf
(
stderr
"
Scanning
for
after
\
n
"
)
;
}
size_t
i
=
0
;
constexpr
size_t
kLoops
=
16
;
const
size_t
lanes_per_group
=
kLoops
*
N
;
Vec
<
D
>
last
=
pivot
;
if
(
num
>
=
lanes_per_group
)
{
for
(
;
i
+
lanes_per_group
<
=
num
;
i
+
=
lanes_per_group
)
{
HWY_DEFAULT_UNROLL
for
(
size_t
loop
=
0
;
loop
<
kLoops
;
+
+
loop
)
{
const
Vec
<
D
>
curr
=
LoadU
(
d
keys
+
i
+
loop
*
N
)
;
last
=
st
.
Last
(
d
last
curr
)
;
}
if
(
HWY_UNLIKELY
(
!
AllFalse
(
d
st
.
Compare
(
d
pivot
last
)
)
)
)
{
if
(
VQSORT_PRINT
>
=
2
)
{
fprintf
(
stderr
"
Stopped
scanning
at
end
of
group
%
zu
\
n
"
i
+
lanes_per_group
)
;
}
return
true
;
}
}
}
for
(
;
i
<
=
num
-
N
;
i
+
=
N
)
{
const
Vec
<
D
>
curr
=
LoadU
(
d
keys
+
i
)
;
if
(
HWY_UNLIKELY
(
!
AllFalse
(
d
st
.
Compare
(
d
pivot
curr
)
)
)
)
{
if
(
VQSORT_PRINT
>
=
2
)
{
fprintf
(
stderr
"
Stopped
scanning
at
%
zu
\
n
"
i
)
;
}
return
true
;
}
}
if
(
HWY_LIKELY
(
i
!
=
num
)
)
{
const
Vec
<
D
>
curr
=
LoadU
(
d
keys
+
num
-
N
)
;
if
(
HWY_UNLIKELY
(
!
AllFalse
(
d
st
.
Compare
(
d
pivot
curr
)
)
)
)
{
if
(
VQSORT_PRINT
>
=
2
)
{
fprintf
(
stderr
"
Stopped
scanning
at
last
%
zu
\
n
"
num
-
N
)
;
}
return
true
;
}
}
return
false
;
}
template
<
class
D
class
Traits
typename
T
>
HWY_INLINE
Vec
<
D
>
ChoosePivotForEqualSamples
(
D
d
Traits
st
T
*
HWY_RESTRICT
keys
size_t
num
T
*
HWY_RESTRICT
samples
Vec
<
D
>
second
Vec
<
D
>
third
PivotResult
&
result
)
{
const
Vec
<
D
>
pivot
=
st
.
SetKey
(
d
samples
)
;
if
(
HWY_UNLIKELY
(
AllTrue
(
d
st
.
EqualKeys
(
d
pivot
st
.
FirstValue
(
d
)
)
)
)
)
{
result
=
PivotResult
:
:
kIsFirst
;
if
(
VQSORT_PRINT
>
=
2
)
{
fprintf
(
stderr
"
Pivot
equals
first
possible
value
\
n
"
)
;
}
return
pivot
;
}
if
(
HWY_UNLIKELY
(
AllTrue
(
d
st
.
EqualKeys
(
d
pivot
st
.
LastValue
(
d
)
)
)
)
)
{
if
(
VQSORT_PRINT
>
=
2
)
{
fprintf
(
stderr
"
Pivot
equals
last
possible
value
\
n
"
)
;
}
result
=
PivotResult
:
:
kWasLast
;
return
st
.
PrevValue
(
d
pivot
)
;
}
if
(
st
.
IsKV
(
)
)
{
const
bool
before
=
!
AllFalse
(
d
st
.
Compare
(
d
second
pivot
)
)
;
if
(
HWY_UNLIKELY
(
before
)
)
{
if
(
HWY_UNLIKELY
(
ExistsAnyAfter
(
d
st
keys
num
pivot
)
)
)
{
result
=
PivotResult
:
:
kNormal
;
return
pivot
;
}
result
=
PivotResult
:
:
kWasLast
;
return
st
.
PrevValue
(
d
pivot
)
;
}
if
(
HWY_UNLIKELY
(
ExistsAnyBefore
(
d
st
keys
num
pivot
)
)
)
{
result
=
PivotResult
:
:
kNormal
;
return
pivot
;
}
}
else
{
st
.
Sort2
(
d
second
third
)
;
HWY_DASSERT
(
AllTrue
(
d
st
.
Compare
(
d
second
third
)
)
)
;
const
bool
before
=
!
AllFalse
(
d
st
.
Compare
(
d
second
pivot
)
)
;
const
bool
after
=
!
AllFalse
(
d
st
.
Compare
(
d
pivot
third
)
)
;
HWY_DASSERT
(
before
|
|
after
)
;
if
(
HWY_UNLIKELY
(
before
)
)
{
if
(
HWY_UNLIKELY
(
after
|
|
ExistsAnyAfter
(
d
st
keys
num
pivot
)
)
)
{
result
=
PivotResult
:
:
kNormal
;
return
pivot
;
}
result
=
PivotResult
:
:
kWasLast
;
return
st
.
PrevValue
(
d
pivot
)
;
}
if
(
HWY_UNLIKELY
(
ExistsAnyBefore
(
d
st
keys
num
pivot
)
)
)
{
result
=
PivotResult
:
:
kNormal
;
return
pivot
;
}
}
result
=
PivotResult
:
:
kIsFirst
;
return
pivot
;
}
template
<
class
D
class
Traits
typename
T
>
HWY_NOINLINE
void
PrintMinMax
(
D
d
Traits
st
const
T
*
HWY_RESTRICT
keys
size_t
num
T
*
HWY_RESTRICT
buf
)
{
if
(
VQSORT_PRINT
>
=
2
)
{
const
size_t
N
=
Lanes
(
d
)
;
if
(
num
<
N
)
return
;
Vec
<
D
>
first
=
st
.
LastValue
(
d
)
;
Vec
<
D
>
last
=
st
.
FirstValue
(
d
)
;
size_t
i
=
0
;
for
(
;
i
<
=
num
-
N
;
i
+
=
N
)
{
const
Vec
<
D
>
v
=
LoadU
(
d
keys
+
i
)
;
first
=
st
.
First
(
d
v
first
)
;
last
=
st
.
Last
(
d
v
last
)
;
}
if
(
HWY_LIKELY
(
i
!
=
num
)
)
{
HWY_DASSERT
(
num
>
=
N
)
;
const
Vec
<
D
>
v
=
LoadU
(
d
keys
+
num
-
N
)
;
first
=
st
.
First
(
d
v
first
)
;
last
=
st
.
Last
(
d
v
last
)
;
}
first
=
st
.
FirstOfLanes
(
d
first
buf
)
;
last
=
st
.
LastOfLanes
(
d
last
buf
)
;
MaybePrintVector
(
d
"
first
"
first
0
st
.
LanesPerKey
(
)
)
;
MaybePrintVector
(
d
"
last
"
last
0
st
.
LanesPerKey
(
)
)
;
}
}
template
<
class
D
class
Traits
typename
T
>
HWY_NOINLINE
void
Recurse
(
D
d
Traits
st
T
*
HWY_RESTRICT
keys
const
size_t
num
T
*
HWY_RESTRICT
buf
uint64_t
*
HWY_RESTRICT
state
const
size_t
remaining_levels
)
{
HWY_DASSERT
(
num
!
=
0
)
;
const
size_t
N
=
Lanes
(
d
)
;
constexpr
size_t
kLPK
=
st
.
LanesPerKey
(
)
;
if
(
HWY_UNLIKELY
(
num
<
=
Constants
:
:
BaseCaseNumLanes
<
kLPK
>
(
N
)
)
)
{
BaseCase
(
d
st
keys
num
buf
)
;
return
;
}
if
(
VQSORT_PRINT
>
=
1
)
{
fprintf
(
stderr
"
\
n
\
n
=
=
=
Recurse
depth
=
%
zu
len
=
%
zu
\
n
"
remaining_levels
num
)
;
PrintMinMax
(
d
st
keys
num
buf
)
;
}
DrawSamples
(
d
st
keys
num
buf
state
)
;
Vec
<
D
>
pivot
;
PivotResult
result
=
PivotResult
:
:
kNormal
;
if
(
HWY_UNLIKELY
(
UnsortedSampleEqual
(
d
st
buf
)
)
)
{
pivot
=
st
.
SetKey
(
d
buf
)
;
size_t
idx_second
=
0
;
if
(
HWY_UNLIKELY
(
AllEqual
(
d
st
pivot
keys
num
&
idx_second
)
)
)
{
return
;
}
HWY_DASSERT
(
idx_second
%
st
.
LanesPerKey
(
)
=
=
0
)
;
const
Vec
<
D
>
second
=
st
.
SetKey
(
d
keys
+
idx_second
)
;
MaybePrintVector
(
d
"
pivot
"
pivot
0
st
.
LanesPerKey
(
)
)
;
MaybePrintVector
(
d
"
second
"
second
0
st
.
LanesPerKey
(
)
)
;
Vec
<
D
>
third
;
if
(
HWY_UNLIKELY
(
!
st
.
IsKV
(
)
&
&
PartitionIfTwoKeys
(
d
st
pivot
keys
num
idx_second
second
third
buf
)
)
)
{
return
;
}
pivot
=
ChoosePivotForEqualSamples
(
d
st
keys
num
buf
second
third
result
)
;
}
else
{
SortSamples
(
d
st
buf
)
;
if
(
HWY_UNLIKELY
(
!
st
.
IsKV
(
)
&
&
PartitionIfTwoSamples
(
d
st
keys
num
buf
)
)
)
{
return
;
}
pivot
=
ChoosePivotByRank
(
d
st
buf
)
;
}
if
(
HWY_UNLIKELY
(
remaining_levels
=
=
0
)
)
{
if
(
VQSORT_PRINT
>
=
1
)
{
fprintf
(
stderr
"
HeapSort
reached
size
=
%
zu
\
n
"
num
)
;
}
HeapSort
(
st
keys
num
)
;
return
;
}
const
size_t
bound
=
Partition
(
d
st
keys
num
pivot
buf
)
;
if
(
VQSORT_PRINT
>
=
2
)
{
fprintf
(
stderr
"
bound
%
zu
num
%
zu
result
%
s
\
n
"
bound
num
PivotResultString
(
result
)
)
;
}
HWY_DASSERT
(
bound
!
=
0
)
;
HWY_DASSERT
(
bound
!
=
num
|
|
result
=
=
PivotResult
:
:
kWasLast
)
;
if
(
HWY_LIKELY
(
result
!
=
PivotResult
:
:
kIsFirst
)
)
{
Recurse
(
d
st
keys
bound
buf
state
remaining_levels
-
1
)
;
}
if
(
HWY_LIKELY
(
result
!
=
PivotResult
:
:
kWasLast
)
)
{
Recurse
(
d
st
keys
+
bound
num
-
bound
buf
state
remaining_levels
-
1
)
;
}
}
template
<
class
D
class
Traits
typename
T
>
HWY_INLINE
bool
HandleSpecialCases
(
D
d
Traits
st
T
*
HWY_RESTRICT
keys
size_t
num
T
*
HWY_RESTRICT
buf
)
{
const
size_t
N
=
Lanes
(
d
)
;
constexpr
size_t
kLPK
=
st
.
LanesPerKey
(
)
;
const
size_t
base_case_num
=
Constants
:
:
BaseCaseNumLanes
<
kLPK
>
(
N
)
;
if
(
HWY_UNLIKELY
(
num
<
=
base_case_num
)
)
{
if
(
VQSORT_PRINT
>
=
1
)
{
fprintf
(
stderr
"
Special
-
casing
small
%
d
lanes
\
n
"
static_cast
<
int
>
(
num
)
)
;
}
BaseCase
(
d
st
keys
num
buf
)
;
return
true
;
}
const
bool
partial_128
=
!
IsFull
(
d
)
&
&
N
<
2
&
&
st
.
Is128
(
)
;
constexpr
bool
kPotentiallyHuge
=
HWY_MAX_BYTES
/
sizeof
(
T
)
>
Constants
:
:
kMaxRows
*
Constants
:
:
kMaxCols
;
const
bool
huge_vec
=
kPotentiallyHuge
&
&
(
2
*
N
>
base_case_num
)
;
if
(
partial_128
|
|
huge_vec
)
{
if
(
VQSORT_PRINT
>
=
1
)
{
fprintf
(
stderr
"
WARNING
:
using
slow
HeapSort
:
partial
%
d
huge
%
d
\
n
"
partial_128
huge_vec
)
;
}
HeapSort
(
st
keys
num
)
;
return
true
;
}
return
false
;
}
#
endif
template
<
class
D
class
Traits
typename
T
HWY_IF_FLOAT
(
T
)
>
HWY_INLINE
size_t
CountAndReplaceNaN
(
D
d
Traits
st
T
*
HWY_RESTRICT
keys
size_t
num
)
{
const
size_t
N
=
Lanes
(
d
)
;
const
Vec
<
D
>
sentinel
=
st
.
LastValue
(
d
)
;
size_t
num_nan
=
0
;
size_t
i
=
0
;
if
(
num
>
=
N
)
{
for
(
;
i
<
=
num
-
N
;
i
+
=
N
)
{
const
Mask
<
D
>
is_nan
=
IsNaN
(
LoadU
(
d
keys
+
i
)
)
;
BlendedStore
(
sentinel
is_nan
d
keys
+
i
)
;
num_nan
+
=
CountTrue
(
d
is_nan
)
;
}
}
const
size_t
remaining
=
num
-
i
;
HWY_DASSERT
(
remaining
<
N
)
;
const
Vec
<
D
>
v
=
LoadN
(
d
keys
+
i
remaining
)
;
const
Mask
<
D
>
is_nan
=
IsNaN
(
v
)
;
StoreN
(
IfThenElse
(
is_nan
sentinel
v
)
d
keys
+
i
remaining
)
;
num_nan
+
=
CountTrue
(
d
is_nan
)
;
return
num_nan
;
}
template
<
class
D
class
Traits
typename
T
HWY_IF_NOT_FLOAT
(
T
)
>
HWY_INLINE
size_t
CountAndReplaceNaN
(
D
Traits
T
*
HWY_RESTRICT
size_t
)
{
return
0
;
}
}
template
<
class
D
class
Traits
typename
T
>
void
Sort
(
D
d
Traits
st
T
*
HWY_RESTRICT
keys
size_t
num
T
*
HWY_RESTRICT
buf
)
{
if
(
VQSORT_PRINT
>
=
1
)
{
fprintf
(
stderr
"
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
Sort
num
%
zu
is128
%
d
isKV
%
d
vec
bytes
%
d
\
n
"
num
st
.
Is128
(
)
st
.
IsKV
(
)
static_cast
<
int
>
(
sizeof
(
T
)
*
Lanes
(
d
)
)
)
;
}
#
if
HWY_MAX_BYTES
>
64
if
(
HWY_UNLIKELY
(
Lanes
(
d
)
>
64
/
sizeof
(
T
)
)
)
{
return
Sort
(
CappedTag
<
T
64
/
sizeof
(
T
)
>
(
)
st
keys
num
buf
)
;
}
#
endif
const
size_t
num_nan
=
detail
:
:
CountAndReplaceNaN
(
d
st
keys
num
)
;
#
if
VQSORT_ENABLED
|
|
HWY_IDE
if
(
!
detail
:
:
HandleSpecialCases
(
d
st
keys
num
buf
)
)
{
uint64_t
*
HWY_RESTRICT
state
=
hwy
:
:
detail
:
:
GetGeneratorStateStatic
(
)
;
const
size_t
max_levels
=
50
;
detail
:
:
Recurse
(
d
st
keys
num
buf
state
max_levels
)
;
}
#
else
(
void
)
d
;
(
void
)
buf
;
if
(
VQSORT_PRINT
>
=
1
)
{
fprintf
(
stderr
"
WARNING
:
using
slow
HeapSort
because
vqsort
disabled
\
n
"
)
;
}
detail
:
:
HeapSort
(
st
keys
num
)
;
#
endif
if
(
num_nan
!
=
0
)
{
Fill
(
d
GetLane
(
NaN
(
d
)
)
num_nan
keys
+
num
-
num_nan
)
;
}
}
template
<
class
D
class
Traits
typename
T
>
HWY_API
void
Sort
(
D
d
Traits
st
T
*
HWY_RESTRICT
keys
size_t
num
)
{
constexpr
size_t
kLPK
=
st
.
LanesPerKey
(
)
;
HWY_ALIGN
T
buf
[
SortConstants
:
:
BufBytes
<
T
kLPK
>
(
HWY_MAX_BYTES
)
/
sizeof
(
T
)
]
;
return
Sort
(
d
st
keys
num
buf
)
;
}
#
if
VQSORT_ENABLED
namespace
detail
{
template
<
typename
T
>
struct
KeyAdapter
{
using
Ascending
=
OrderAscending
<
T
>
;
using
Descending
=
OrderDescending
<
T
>
;
template
<
class
Order
>
using
Traits
=
TraitsLane
<
Order
>
;
}
;
template
<
>
struct
KeyAdapter
<
hwy
:
:
uint128_t
>
{
using
Ascending
=
OrderAscending128
;
using
Descending
=
OrderDescending128
;
template
<
class
Order
>
using
Traits
=
Traits128
<
Order
>
;
}
;
template
<
>
struct
KeyAdapter
<
hwy
:
:
K64V64
>
{
using
Ascending
=
OrderAscendingKV128
;
using
Descending
=
OrderDescendingKV128
;
template
<
class
Order
>
using
Traits
=
Traits128
<
Order
>
;
}
;
template
<
>
struct
KeyAdapter
<
hwy
:
:
K32V32
>
{
using
Ascending
=
OrderAscendingKV64
;
using
Descending
=
OrderDescendingKV64
;
template
<
class
Order
>
using
Traits
=
TraitsLane
<
Order
>
;
}
;
}
#
endif
template
<
typename
T
>
void
VQSortStatic
(
T
*
HWY_RESTRICT
keys
size_t
num
SortAscending
)
{
#
if
VQSORT_ENABLED
using
Adapter
=
detail
:
:
KeyAdapter
<
T
>
;
using
Order
=
typename
Adapter
:
:
Ascending
;
const
detail
:
:
SharedTraits
<
typename
Adapter
:
:
template
Traits
<
Order
>
>
st
;
using
LaneType
=
typename
decltype
(
st
)
:
:
LaneType
;
const
SortTag
<
LaneType
>
d
;
Sort
(
d
st
reinterpret_cast
<
LaneType
*
>
(
keys
)
num
*
st
.
LanesPerKey
(
)
)
;
#
else
(
void
)
keys
;
(
void
)
num
;
HWY_ASSERT
(
0
)
;
#
endif
}
template
<
typename
T
>
void
VQSortStatic
(
T
*
HWY_RESTRICT
keys
size_t
num
SortDescending
)
{
#
if
VQSORT_ENABLED
using
Adapter
=
detail
:
:
KeyAdapter
<
T
>
;
using
Order
=
typename
Adapter
:
:
Descending
;
const
detail
:
:
SharedTraits
<
typename
Adapter
:
:
template
Traits
<
Order
>
>
st
;
using
LaneType
=
typename
decltype
(
st
)
:
:
LaneType
;
const
SortTag
<
LaneType
>
d
;
Sort
(
d
st
reinterpret_cast
<
LaneType
*
>
(
keys
)
num
*
st
.
LanesPerKey
(
)
)
;
#
else
(
void
)
keys
;
(
void
)
num
;
HWY_ASSERT
(
0
)
;
#
endif
}
}
}
HWY_AFTER_NAMESPACE
(
)
;
#
endif
