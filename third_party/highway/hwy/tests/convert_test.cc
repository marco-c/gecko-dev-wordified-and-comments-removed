#
include
<
stddef
.
h
>
#
include
<
stdint
.
h
>
#
include
<
string
.
h
>
#
undef
HWY_TARGET_INCLUDE
#
define
HWY_TARGET_INCLUDE
"
tests
/
convert_test
.
cc
"
#
include
"
hwy
/
foreach_target
.
h
"
#
include
"
hwy
/
highway
.
h
"
#
include
"
hwy
/
tests
/
test_util
-
inl
.
h
"
HWY_BEFORE_NAMESPACE
(
)
;
namespace
hwy
{
namespace
HWY_NAMESPACE
{
template
<
typename
ToT
>
struct
TestBitCast
{
template
<
typename
T
class
D
>
HWY_NOINLINE
void
operator
(
)
(
T
D
d
)
{
const
Repartition
<
ToT
D
>
dto
;
HWY_ASSERT_EQ
(
Lanes
(
d
)
*
sizeof
(
T
)
Lanes
(
dto
)
*
sizeof
(
ToT
)
)
;
const
auto
vf
=
Iota
(
d
1
)
;
const
auto
vt
=
BitCast
(
dto
vf
)
;
auto
from_lanes
=
AllocateAligned
<
T
>
(
Lanes
(
d
)
)
;
auto
to_lanes
=
AllocateAligned
<
ToT
>
(
Lanes
(
dto
)
)
;
Store
(
vf
d
from_lanes
.
get
(
)
)
;
Store
(
vt
dto
to_lanes
.
get
(
)
)
;
HWY_ASSERT
(
BytesEqual
(
from_lanes
.
get
(
)
to_lanes
.
get
(
)
Lanes
(
d
)
*
sizeof
(
T
)
)
)
;
}
}
;
struct
TestBitCastFrom
{
template
<
typename
T
class
D
>
HWY_NOINLINE
void
operator
(
)
(
T
t
D
d
)
{
TestBitCast
<
uint8_t
>
(
)
(
t
d
)
;
TestBitCast
<
uint16_t
>
(
)
(
t
d
)
;
TestBitCast
<
uint32_t
>
(
)
(
t
d
)
;
#
if
HWY_CAP_INTEGER64
TestBitCast
<
uint64_t
>
(
)
(
t
d
)
;
#
endif
TestBitCast
<
int8_t
>
(
)
(
t
d
)
;
TestBitCast
<
int16_t
>
(
)
(
t
d
)
;
TestBitCast
<
int32_t
>
(
)
(
t
d
)
;
#
if
HWY_CAP_INTEGER64
TestBitCast
<
int64_t
>
(
)
(
t
d
)
;
#
endif
TestBitCast
<
float
>
(
)
(
t
d
)
;
#
if
HWY_CAP_FLOAT64
TestBitCast
<
double
>
(
)
(
t
d
)
;
#
endif
}
}
;
HWY_NOINLINE
void
TestAllBitCast
(
)
{
const
ForPartialVectors
<
TestBitCast
<
uint8_t
>
>
to_u8
;
to_u8
(
uint8_t
(
)
)
;
to_u8
(
int8_t
(
)
)
;
const
ForPartialVectors
<
TestBitCast
<
int8_t
>
>
to_i8
;
to_i8
(
uint8_t
(
)
)
;
to_i8
(
int8_t
(
)
)
;
const
ForPartialVectors
<
TestBitCast
<
uint16_t
>
>
to_u16
;
to_u16
(
uint16_t
(
)
)
;
to_u16
(
int16_t
(
)
)
;
const
ForPartialVectors
<
TestBitCast
<
int16_t
>
>
to_i16
;
to_i16
(
uint16_t
(
)
)
;
to_i16
(
int16_t
(
)
)
;
const
ForPartialVectors
<
TestBitCast
<
uint32_t
>
>
to_u32
;
to_u32
(
uint32_t
(
)
)
;
to_u32
(
int32_t
(
)
)
;
to_u32
(
float
(
)
)
;
const
ForPartialVectors
<
TestBitCast
<
int32_t
>
>
to_i32
;
to_i32
(
uint32_t
(
)
)
;
to_i32
(
int32_t
(
)
)
;
to_i32
(
float
(
)
)
;
#
if
HWY_CAP_INTEGER64
const
ForPartialVectors
<
TestBitCast
<
uint64_t
>
>
to_u64
;
to_u64
(
uint64_t
(
)
)
;
to_u64
(
int64_t
(
)
)
;
#
if
HWY_CAP_FLOAT64
to_u64
(
double
(
)
)
;
#
endif
const
ForPartialVectors
<
TestBitCast
<
int64_t
>
>
to_i64
;
to_i64
(
uint64_t
(
)
)
;
to_i64
(
int64_t
(
)
)
;
#
if
HWY_CAP_FLOAT64
to_i64
(
double
(
)
)
;
#
endif
#
endif
const
ForPartialVectors
<
TestBitCast
<
float
>
>
to_float
;
to_float
(
uint32_t
(
)
)
;
to_float
(
int32_t
(
)
)
;
to_float
(
float
(
)
)
;
#
if
HWY_CAP_FLOAT64
const
ForPartialVectors
<
TestBitCast
<
double
>
>
to_double
;
to_double
(
double
(
)
)
;
#
if
HWY_CAP_INTEGER64
to_double
(
uint64_t
(
)
)
;
to_double
(
int64_t
(
)
)
;
#
endif
#
endif
ForAllTypes
(
ForGE128Vectors
<
TestBitCastFrom
>
(
)
)
;
}
template
<
typename
ToT
>
struct
TestPromoteTo
{
template
<
typename
T
class
D
>
HWY_NOINLINE
void
operator
(
)
(
T
D
from_d
)
{
static_assert
(
sizeof
(
T
)
<
sizeof
(
ToT
)
"
Input
type
must
be
narrower
"
)
;
const
Rebind
<
ToT
D
>
to_d
;
const
size_t
N
=
Lanes
(
from_d
)
;
auto
from
=
AllocateAligned
<
T
>
(
N
)
;
auto
expected
=
AllocateAligned
<
ToT
>
(
N
)
;
RandomState
rng
;
for
(
size_t
rep
=
0
;
rep
<
200
;
+
+
rep
)
{
for
(
size_t
i
=
0
;
i
<
N
;
+
+
i
)
{
const
uint64_t
bits
=
rng
(
)
;
memcpy
(
&
from
[
i
]
&
bits
sizeof
(
T
)
)
;
expected
[
i
]
=
from
[
i
]
;
}
HWY_ASSERT_VEC_EQ
(
to_d
expected
.
get
(
)
PromoteTo
(
to_d
Load
(
from_d
from
.
get
(
)
)
)
)
;
}
}
}
;
HWY_NOINLINE
void
TestAllPromoteTo
(
)
{
const
ForPartialVectors
<
TestPromoteTo
<
uint16_t
>
2
>
to_u16div2
;
to_u16div2
(
uint8_t
(
)
)
;
const
ForPartialVectors
<
TestPromoteTo
<
uint32_t
>
4
>
to_u32div4
;
to_u32div4
(
uint8_t
(
)
)
;
const
ForPartialVectors
<
TestPromoteTo
<
uint32_t
>
2
>
to_u32div2
;
to_u32div2
(
uint16_t
(
)
)
;
const
ForPartialVectors
<
TestPromoteTo
<
int16_t
>
2
>
to_i16div2
;
to_i16div2
(
uint8_t
(
)
)
;
to_i16div2
(
int8_t
(
)
)
;
const
ForPartialVectors
<
TestPromoteTo
<
int32_t
>
2
>
to_i32div2
;
to_i32div2
(
uint16_t
(
)
)
;
to_i32div2
(
int16_t
(
)
)
;
const
ForPartialVectors
<
TestPromoteTo
<
int32_t
>
4
>
to_i32div4
;
to_i32div4
(
uint8_t
(
)
)
;
to_i32div4
(
int8_t
(
)
)
;
#
if
HWY_CAP_INTEGER64
const
ForPartialVectors
<
TestPromoteTo
<
uint64_t
>
2
>
to_u64div2
;
to_u64div2
(
uint32_t
(
)
)
;
const
ForPartialVectors
<
TestPromoteTo
<
int64_t
>
2
>
to_i64div2
;
to_i64div2
(
int32_t
(
)
)
;
#
endif
#
if
HWY_CAP_FLOAT64
const
ForPartialVectors
<
TestPromoteTo
<
double
>
2
>
to_f64div2
;
to_f64div2
(
int32_t
(
)
)
;
to_f64div2
(
float
(
)
)
;
#
endif
}
template
<
typename
T
HWY_IF_FLOAT
(
T
)
>
bool
IsFinite
(
T
t
)
{
return
std
:
:
isfinite
(
t
)
;
}
template
<
typename
T
HWY_IF_NOT_FLOAT
(
T
)
>
bool
IsFinite
(
T
)
{
return
true
;
}
template
<
typename
ToT
>
struct
TestDemoteTo
{
template
<
typename
T
class
D
>
HWY_NOINLINE
void
operator
(
)
(
T
D
from_d
)
{
static_assert
(
!
IsFloat
<
ToT
>
(
)
"
Use
TestDemoteToFloat
for
float
output
"
)
;
static_assert
(
sizeof
(
T
)
>
sizeof
(
ToT
)
"
Input
type
must
be
wider
"
)
;
const
Rebind
<
ToT
D
>
to_d
;
const
size_t
N
=
Lanes
(
from_d
)
;
auto
from
=
AllocateAligned
<
T
>
(
N
)
;
auto
expected
=
AllocateAligned
<
ToT
>
(
N
)
;
const
T
min
=
LimitsMin
<
ToT
>
(
)
;
const
T
max
=
LimitsMax
<
ToT
>
(
)
;
RandomState
rng
;
for
(
size_t
rep
=
0
;
rep
<
1000
;
+
+
rep
)
{
for
(
size_t
i
=
0
;
i
<
N
;
+
+
i
)
{
do
{
const
uint64_t
bits
=
rng
(
)
;
memcpy
(
&
from
[
i
]
&
bits
sizeof
(
T
)
)
;
}
while
(
!
IsFinite
(
from
[
i
]
)
)
;
expected
[
i
]
=
static_cast
<
ToT
>
(
std
:
:
min
(
std
:
:
max
(
min
from
[
i
]
)
max
)
)
;
}
HWY_ASSERT_VEC_EQ
(
to_d
expected
.
get
(
)
DemoteTo
(
to_d
Load
(
from_d
from
.
get
(
)
)
)
)
;
}
}
}
;
HWY_NOINLINE
void
TestAllDemoteToInt
(
)
{
ForDemoteVectors
<
TestDemoteTo
<
uint8_t
>
2
>
(
)
(
int16_t
(
)
)
;
ForDemoteVectors
<
TestDemoteTo
<
uint8_t
>
4
>
(
)
(
int32_t
(
)
)
;
ForDemoteVectors
<
TestDemoteTo
<
int8_t
>
2
>
(
)
(
int16_t
(
)
)
;
ForDemoteVectors
<
TestDemoteTo
<
int8_t
>
4
>
(
)
(
int32_t
(
)
)
;
const
ForDemoteVectors
<
TestDemoteTo
<
uint16_t
>
2
>
to_u16
;
to_u16
(
int32_t
(
)
)
;
const
ForDemoteVectors
<
TestDemoteTo
<
int16_t
>
2
>
to_i16
;
to_i16
(
int32_t
(
)
)
;
}
HWY_NOINLINE
void
TestAllDemoteToMixed
(
)
{
#
if
HWY_CAP_FLOAT64
const
ForDemoteVectors
<
TestDemoteTo
<
int32_t
>
2
>
to_i32
;
to_i32
(
double
(
)
)
;
#
endif
}
template
<
typename
ToT
>
struct
TestDemoteToFloat
{
template
<
typename
T
class
D
>
HWY_NOINLINE
void
operator
(
)
(
T
D
from_d
)
{
static_assert
(
IsFloat
<
ToT
>
(
)
"
Use
TestDemoteTo
for
integer
output
"
)
;
static_assert
(
sizeof
(
T
)
>
sizeof
(
ToT
)
"
Input
type
must
be
wider
"
)
;
const
Rebind
<
ToT
D
>
to_d
;
const
size_t
N
=
Lanes
(
from_d
)
;
auto
from
=
AllocateAligned
<
T
>
(
N
)
;
auto
expected
=
AllocateAligned
<
ToT
>
(
N
)
;
RandomState
rng
;
for
(
size_t
rep
=
0
;
rep
<
1000
;
+
+
rep
)
{
for
(
size_t
i
=
0
;
i
<
N
;
+
+
i
)
{
do
{
const
uint64_t
bits
=
rng
(
)
;
memcpy
(
&
from
[
i
]
&
bits
sizeof
(
T
)
)
;
}
while
(
!
IsFinite
(
from
[
i
]
)
)
;
const
T
magn
=
std
:
:
abs
(
from
[
i
]
)
;
const
T
max_abs
=
HighestValue
<
ToT
>
(
)
;
const
T
clipped
=
copysign
(
std
:
:
min
(
magn
max_abs
)
from
[
i
]
)
;
expected
[
i
]
=
static_cast
<
ToT
>
(
clipped
)
;
}
HWY_ASSERT_VEC_EQ
(
to_d
expected
.
get
(
)
DemoteTo
(
to_d
Load
(
from_d
from
.
get
(
)
)
)
)
;
}
}
}
;
HWY_NOINLINE
void
TestAllDemoteToFloat
(
)
{
#
if
HWY_CAP_FLOAT64
const
ForDemoteVectors
<
TestDemoteToFloat
<
float
>
2
>
to_float
;
to_float
(
double
(
)
)
;
#
endif
}
template
<
class
D
>
AlignedFreeUniquePtr
<
float
[
]
>
F16TestCases
(
D
d
size_t
&
padded
)
{
const
float
test_cases
[
]
=
{
1
.
0f
-
1
.
0f
0
.
0f
-
0
.
0f
0
.
25f
-
0
.
25f
4
.
0f
-
32
.
0f
65472
.
0f
65504
.
0f
-
65472
.
0f
-
65504
.
0f
2
.
00390625f
3
.
99609375f
-
2
.
00390625f
-
3
.
99609375f
}
;
const
size_t
kNumTestCases
=
sizeof
(
test_cases
)
/
sizeof
(
test_cases
[
0
]
)
;
const
size_t
N
=
Lanes
(
d
)
;
padded
=
RoundUpTo
(
kNumTestCases
N
)
;
auto
in
=
AllocateAligned
<
float
>
(
padded
)
;
auto
expected
=
AllocateAligned
<
float
>
(
padded
)
;
std
:
:
copy
(
test_cases
test_cases
+
kNumTestCases
in
.
get
(
)
)
;
std
:
:
fill
(
in
.
get
(
)
+
kNumTestCases
in
.
get
(
)
+
padded
0
.
0f
)
;
return
in
;
}
struct
TestF16
{
template
<
typename
TF32
class
DF32
>
HWY_NOINLINE
void
operator
(
)
(
TF32
DF32
d32
)
{
size_t
padded
;
auto
in
=
F16TestCases
(
d32
padded
)
;
using
TF16
=
float16_t
;
const
Rebind
<
TF16
DF32
>
d16
;
const
size_t
N
=
Lanes
(
d32
)
;
auto
temp16
=
AllocateAligned
<
TF16
>
(
N
)
;
for
(
size_t
i
=
0
;
i
<
padded
;
i
+
=
N
)
{
const
auto
loaded
=
Load
(
d32
&
in
[
i
]
)
;
Store
(
DemoteTo
(
d16
loaded
)
d16
temp16
.
get
(
)
)
;
HWY_ASSERT_VEC_EQ
(
d32
loaded
PromoteTo
(
d32
Load
(
d16
temp16
.
get
(
)
)
)
)
;
}
}
}
;
HWY_NOINLINE
void
TestAllF16
(
)
{
ForDemoteVectors
<
TestF16
2
>
(
)
(
float
(
)
)
;
}
struct
TestConvertU8
{
template
<
typename
T
class
D
>
HWY_NOINLINE
void
operator
(
)
(
T
const
D
du32
)
{
const
Rebind
<
uint8_t
D
>
du8
;
auto
lanes8
=
AllocateAligned
<
uint8_t
>
(
Lanes
(
du8
)
)
;
Store
(
Iota
(
du8
0
)
du8
lanes8
.
get
(
)
)
;
HWY_ASSERT_VEC_EQ
(
du8
Iota
(
du8
0
)
U8FromU32
(
Iota
(
du32
0
)
)
)
;
HWY_ASSERT_VEC_EQ
(
du8
Iota
(
du8
0x7F
)
U8FromU32
(
Iota
(
du32
0x7F
)
)
)
;
}
}
;
HWY_NOINLINE
void
TestAllConvertU8
(
)
{
ForDemoteVectors
<
TestConvertU8
4
>
(
)
(
uint32_t
(
)
)
;
}
struct
TestIntFromFloatHuge
{
template
<
typename
TF
class
DF
>
HWY_NOINLINE
void
operator
(
)
(
TF
const
DF
df
)
{
#
if
HWY_TARGET
!
=
HWY_NEON
using
TI
=
MakeSigned
<
TF
>
;
const
Rebind
<
TI
DF
>
di
;
const
auto
expected_max
=
Set
(
di
LimitsMax
<
TI
>
(
)
)
;
HWY_ASSERT_VEC_EQ
(
di
expected_max
ConvertTo
(
di
Set
(
df
TF
(
1E20
)
)
)
)
;
const
auto
expected_min
=
Set
(
di
LimitsMin
<
TI
>
(
)
)
;
HWY_ASSERT_VEC_EQ
(
di
expected_min
ConvertTo
(
di
Set
(
df
TF
(
-
1E20
)
)
)
)
;
#
else
(
void
)
df
;
#
endif
}
}
;
struct
TestIntFromFloat
{
template
<
typename
TF
class
DF
>
HWY_NOINLINE
void
operator
(
)
(
TF
const
DF
df
)
{
using
TI
=
MakeSigned
<
TF
>
;
const
Rebind
<
TI
DF
>
di
;
const
size_t
N
=
Lanes
(
df
)
;
HWY_ASSERT_VEC_EQ
(
di
Iota
(
di
TI
(
4
)
)
ConvertTo
(
di
Iota
(
df
TF
(
4
.
0
)
)
)
)
;
HWY_ASSERT_VEC_EQ
(
di
Iota
(
di
-
TI
(
N
)
)
ConvertTo
(
di
Iota
(
df
-
TF
(
N
)
)
)
)
;
HWY_ASSERT_VEC_EQ
(
di
Iota
(
di
TI
(
2
)
)
ConvertTo
(
di
Iota
(
df
TF
(
2
.
001
)
)
)
)
;
HWY_ASSERT_VEC_EQ
(
di
Iota
(
di
TI
(
3
)
)
ConvertTo
(
di
Iota
(
df
TF
(
3
.
9999
)
)
)
)
;
const
TF
eps
=
static_cast
<
TF
>
(
0
.
0001
)
;
HWY_ASSERT_VEC_EQ
(
di
Iota
(
di
-
TI
(
N
)
)
ConvertTo
(
di
Iota
(
df
-
TF
(
N
+
1
)
+
eps
)
)
)
;
HWY_ASSERT_VEC_EQ
(
di
Iota
(
di
-
TI
(
N
+
1
)
)
ConvertTo
(
di
Iota
(
df
-
TF
(
N
+
1
)
-
eps
)
)
)
;
const
double
min
=
static_cast
<
double
>
(
LimitsMin
<
TI
>
(
)
)
;
const
double
max
=
static_cast
<
double
>
(
LimitsMax
<
TI
>
(
)
)
;
auto
from
=
AllocateAligned
<
TF
>
(
N
)
;
auto
expected
=
AllocateAligned
<
TI
>
(
N
)
;
RandomState
rng
;
for
(
size_t
rep
=
0
;
rep
<
1000
;
+
+
rep
)
{
for
(
size_t
i
=
0
;
i
<
N
;
+
+
i
)
{
do
{
const
uint64_t
bits
=
rng
(
)
;
memcpy
(
&
from
[
i
]
&
bits
sizeof
(
TF
)
)
;
}
while
(
!
std
:
:
isfinite
(
from
[
i
]
)
)
;
if
(
from
[
i
]
>
=
max
)
{
expected
[
i
]
=
LimitsMax
<
TI
>
(
)
;
}
else
if
(
from
[
i
]
<
=
min
)
{
expected
[
i
]
=
LimitsMin
<
TI
>
(
)
;
}
else
{
expected
[
i
]
=
static_cast
<
TI
>
(
from
[
i
]
)
;
}
}
HWY_ASSERT_VEC_EQ
(
di
expected
.
get
(
)
ConvertTo
(
di
Load
(
df
from
.
get
(
)
)
)
)
;
}
}
}
;
HWY_NOINLINE
void
TestAllIntFromFloat
(
)
{
ForFloatTypes
(
ForPartialVectors
<
TestIntFromFloatHuge
>
(
)
)
;
ForFloatTypes
(
ForPartialVectors
<
TestIntFromFloat
>
(
)
)
;
}
struct
TestFloatFromInt
{
template
<
typename
TI
class
DI
>
HWY_NOINLINE
void
operator
(
)
(
TI
const
DI
di
)
{
using
TF
=
MakeFloat
<
TI
>
;
const
Rebind
<
TF
DI
>
df
;
const
size_t
N
=
Lanes
(
df
)
;
HWY_ASSERT_VEC_EQ
(
df
Iota
(
df
TF
(
4
.
0
)
)
ConvertTo
(
df
Iota
(
di
TI
(
4
)
)
)
)
;
HWY_ASSERT_VEC_EQ
(
df
Iota
(
df
-
TF
(
N
)
)
ConvertTo
(
df
Iota
(
di
-
TI
(
N
)
)
)
)
;
HWY_ASSERT_VEC_EQ
(
df
Set
(
df
TF
(
LimitsMax
<
TI
>
(
)
)
)
ConvertTo
(
df
Set
(
di
LimitsMax
<
TI
>
(
)
)
)
)
;
HWY_ASSERT_VEC_EQ
(
df
Set
(
df
TF
(
LimitsMin
<
TI
>
(
)
)
)
ConvertTo
(
df
Set
(
di
LimitsMin
<
TI
>
(
)
)
)
)
;
}
}
;
HWY_NOINLINE
void
TestAllFloatFromInt
(
)
{
ForPartialVectors
<
TestFloatFromInt
>
(
)
(
int32_t
(
)
)
;
#
if
HWY_CAP_FLOAT64
&
&
HWY_CAP_INTEGER64
ForPartialVectors
<
TestFloatFromInt
>
(
)
(
int64_t
(
)
)
;
#
endif
}
struct
TestI32F64
{
template
<
typename
TF
class
DF
>
HWY_NOINLINE
void
operator
(
)
(
TF
const
DF
df
)
{
using
TI
=
int32_t
;
const
Rebind
<
TI
DF
>
di
;
const
size_t
N
=
Lanes
(
df
)
;
HWY_ASSERT_VEC_EQ
(
di
Iota
(
di
TI
(
4
)
)
DemoteTo
(
di
Iota
(
df
TF
(
4
.
0
)
)
)
)
;
HWY_ASSERT_VEC_EQ
(
df
Iota
(
df
TF
(
4
.
0
)
)
PromoteTo
(
df
Iota
(
di
TI
(
4
)
)
)
)
;
HWY_ASSERT_VEC_EQ
(
di
Iota
(
di
-
TI
(
N
)
)
DemoteTo
(
di
Iota
(
df
-
TF
(
N
)
)
)
)
;
HWY_ASSERT_VEC_EQ
(
df
Iota
(
df
-
TF
(
N
)
)
PromoteTo
(
df
Iota
(
di
-
TI
(
N
)
)
)
)
;
HWY_ASSERT_VEC_EQ
(
di
Iota
(
di
TI
(
2
)
)
DemoteTo
(
di
Iota
(
df
TF
(
2
.
001
)
)
)
)
;
HWY_ASSERT_VEC_EQ
(
df
Iota
(
df
TF
(
2
.
0
)
)
PromoteTo
(
df
Iota
(
di
TI
(
2
)
)
)
)
;
HWY_ASSERT_VEC_EQ
(
di
Iota
(
di
TI
(
3
)
)
DemoteTo
(
di
Iota
(
df
TF
(
3
.
9999
)
)
)
)
;
HWY_ASSERT_VEC_EQ
(
df
Iota
(
df
TF
(
4
.
0
)
)
PromoteTo
(
df
Iota
(
di
TI
(
4
)
)
)
)
;
const
TF
eps
=
static_cast
<
TF
>
(
0
.
0001
)
;
HWY_ASSERT_VEC_EQ
(
di
Iota
(
di
-
TI
(
N
)
)
DemoteTo
(
di
Iota
(
df
-
TF
(
N
+
1
)
+
eps
)
)
)
;
HWY_ASSERT_VEC_EQ
(
df
Iota
(
df
TF
(
-
4
.
0
)
)
PromoteTo
(
df
Iota
(
di
TI
(
-
4
)
)
)
)
;
HWY_ASSERT_VEC_EQ
(
di
Iota
(
di
-
TI
(
N
+
1
)
)
DemoteTo
(
di
Iota
(
df
-
TF
(
N
+
1
)
-
eps
)
)
)
;
HWY_ASSERT_VEC_EQ
(
df
Iota
(
df
TF
(
-
2
.
0
)
)
PromoteTo
(
df
Iota
(
di
TI
(
-
2
)
)
)
)
;
HWY_ASSERT_VEC_EQ
(
di
Set
(
di
LimitsMax
<
TI
>
(
)
)
DemoteTo
(
di
Set
(
df
TF
(
1E12
)
)
)
)
;
HWY_ASSERT_VEC_EQ
(
di
Set
(
di
LimitsMin
<
TI
>
(
)
)
DemoteTo
(
di
Set
(
df
TF
(
-
1E12
)
)
)
)
;
HWY_ASSERT_VEC_EQ
(
df
Set
(
df
TF
(
LimitsMax
<
TI
>
(
)
)
)
PromoteTo
(
df
Set
(
di
LimitsMax
<
TI
>
(
)
)
)
)
;
HWY_ASSERT_VEC_EQ
(
df
Set
(
df
TF
(
LimitsMin
<
TI
>
(
)
)
)
PromoteTo
(
df
Set
(
di
LimitsMin
<
TI
>
(
)
)
)
)
;
}
}
;
HWY_NOINLINE
void
TestAllI32F64
(
)
{
#
if
HWY_CAP_FLOAT64
ForDemoteVectors
<
TestI32F64
2
>
(
)
(
double
(
)
)
;
#
endif
}
}
}
HWY_AFTER_NAMESPACE
(
)
;
#
if
HWY_ONCE
namespace
hwy
{
HWY_BEFORE_TEST
(
HwyConvertTest
)
;
HWY_EXPORT_AND_TEST_P
(
HwyConvertTest
TestAllBitCast
)
;
HWY_EXPORT_AND_TEST_P
(
HwyConvertTest
TestAllPromoteTo
)
;
HWY_EXPORT_AND_TEST_P
(
HwyConvertTest
TestAllDemoteToInt
)
;
HWY_EXPORT_AND_TEST_P
(
HwyConvertTest
TestAllDemoteToMixed
)
;
HWY_EXPORT_AND_TEST_P
(
HwyConvertTest
TestAllDemoteToFloat
)
;
HWY_EXPORT_AND_TEST_P
(
HwyConvertTest
TestAllF16
)
;
HWY_EXPORT_AND_TEST_P
(
HwyConvertTest
TestAllConvertU8
)
;
HWY_EXPORT_AND_TEST_P
(
HwyConvertTest
TestAllIntFromFloat
)
;
HWY_EXPORT_AND_TEST_P
(
HwyConvertTest
TestAllFloatFromInt
)
;
HWY_EXPORT_AND_TEST_P
(
HwyConvertTest
TestAllI32F64
)
;
}
#
endif
