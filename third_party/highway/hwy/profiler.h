#
ifndef
HIGHWAY_HWY_PROFILER_H_
#
define
HIGHWAY_HWY_PROFILER_H_
#
include
"
hwy
/
base
.
h
"
#
ifndef
PROFILER_ENABLED
#
define
PROFILER_ENABLED
0
#
endif
#
ifndef
PROFILER_THREAD_STORAGE
#
define
PROFILER_THREAD_STORAGE
200ULL
#
endif
#
if
PROFILER_ENABLED
|
|
HWY_IDE
#
include
<
stddef
.
h
>
#
include
<
stdint
.
h
>
#
include
<
stdio
.
h
>
#
include
<
string
.
h
>
#
include
<
algorithm
>
#
include
<
atomic
>
#
include
"
hwy
/
aligned_allocator
.
h
"
#
include
"
hwy
/
cache_control
.
h
"
#
include
"
hwy
/
highway
.
h
"
#
include
"
hwy
/
robust_statistics
.
h
"
#
include
"
hwy
/
timer
-
inl
.
h
"
#
include
"
hwy
/
timer
.
h
"
#
define
PROFILER_PRINT_OVERHEAD
0
namespace
hwy
{
static
constexpr
size_t
kMaxThreads
=
256
;
static
constexpr
size_t
kMaxDepth
=
64
;
static
constexpr
size_t
kMaxZones
=
256
;
HWY_ATTR
static
void
StreamCacheLine
(
const
uint64_t
*
HWY_RESTRICT
from
uint64_t
*
HWY_RESTRICT
to
)
{
namespace
hn
=
HWY_NAMESPACE
;
const
hn
:
:
ScalableTag
<
uint64_t
>
d
;
for
(
size_t
i
=
0
;
i
<
HWY_ALIGNMENT
/
sizeof
(
uint64_t
)
;
i
+
=
Lanes
(
d
)
)
{
hn
:
:
Stream
(
hn
:
:
Load
(
d
from
+
i
)
d
to
+
i
)
;
}
}
#
pragma
pack
(
push
1
)
class
Packet
{
public
:
static
constexpr
size_t
kOffsetBits
=
25
;
static
constexpr
uint64_t
kOffsetBias
=
1ULL
<
<
(
kOffsetBits
-
1
)
;
static
constexpr
size_t
kTimestampBits
=
64
-
kOffsetBits
;
static
constexpr
uint64_t
kTimestampMask
=
(
1ULL
<
<
kTimestampBits
)
-
1
;
static
Packet
Make
(
const
size_t
biased_offset
const
uint64_t
timestamp
)
{
HWY_DASSERT
(
biased_offset
<
(
1ULL
<
<
kOffsetBits
)
)
;
Packet
packet
;
packet
.
bits_
=
(
biased_offset
<
<
kTimestampBits
)
+
(
timestamp
&
kTimestampMask
)
;
return
packet
;
}
uint64_t
Timestamp
(
)
const
{
return
bits_
&
kTimestampMask
;
}
size_t
BiasedOffset
(
)
const
{
return
(
bits_
>
>
kTimestampBits
)
;
}
private
:
uint64_t
bits_
;
}
;
static_assert
(
sizeof
(
Packet
)
=
=
8
"
Wrong
Packet
size
"
)
;
inline
const
char
*
StringOrigin
(
)
{
static
const
char
*
string_origin
=
"
__
#
__
"
;
return
string_origin
-
Packet
:
:
kOffsetBias
;
}
struct
Node
{
Packet
packet
;
uint64_t
child_total
;
}
;
static_assert
(
sizeof
(
Node
)
=
=
16
"
Wrong
Node
size
"
)
;
struct
Accumulator
{
static
constexpr
size_t
kNumCallBits
=
64
-
Packet
:
:
kOffsetBits
;
uint64_t
BiasedOffset
(
)
const
{
return
u128
.
lo
>
>
kNumCallBits
;
}
uint64_t
NumCalls
(
)
const
{
return
u128
.
lo
&
(
(
1ULL
<
<
kNumCallBits
)
-
1
)
;
}
uint64_t
Duration
(
)
const
{
return
u128
.
hi
;
}
void
Set
(
uint64_t
biased_offset
uint64_t
num_calls
uint64_t
duration
)
{
u128
.
hi
=
duration
;
u128
.
lo
=
(
biased_offset
<
<
kNumCallBits
)
+
num_calls
;
}
void
Add
(
uint64_t
num_calls
uint64_t
duration
)
{
u128
.
lo
+
=
num_calls
;
u128
.
hi
+
=
duration
;
}
uint128_t
u128
;
}
;
static_assert
(
sizeof
(
Accumulator
)
=
=
16
"
Wrong
Accumulator
size
"
)
;
template
<
typename
T
>
inline
T
ClampedSubtract
(
const
T
minuend
const
T
subtrahend
)
{
if
(
subtrahend
>
minuend
)
{
return
0
;
}
return
minuend
-
subtrahend
;
}
class
Results
{
public
:
Results
(
)
{
ZeroBytes
(
zones_
sizeof
(
zones_
)
)
;
}
uint64_t
ZoneDuration
(
const
Packet
*
packets
)
{
HWY_DASSERT
(
depth_
=
=
0
)
;
HWY_DASSERT
(
num_zones_
=
=
0
)
;
AnalyzePackets
(
packets
2
)
;
const
uint64_t
duration
=
zones_
[
0
]
.
Duration
(
)
;
zones_
[
0
]
.
Set
(
0
0
0
)
;
HWY_DASSERT
(
depth_
=
=
0
)
;
num_zones_
=
0
;
return
duration
;
}
void
SetSelfOverhead
(
const
uint64_t
self_overhead
)
{
self_overhead_
=
self_overhead
;
}
void
SetChildOverhead
(
const
uint64_t
child_overhead
)
{
child_overhead_
=
child_overhead
;
}
void
AnalyzePackets
(
const
Packet
*
packets
const
size_t
num_packets
)
{
namespace
hn
=
HWY_NAMESPACE
;
const
uint64_t
t0
=
hn
:
:
timer
:
:
Start
(
)
;
for
(
size_t
i
=
0
;
i
<
num_packets
;
+
+
i
)
{
const
Packet
p
=
packets
[
i
]
;
if
(
p
.
BiasedOffset
(
)
!
=
Packet
:
:
kOffsetBias
)
{
HWY_DASSERT
(
depth_
<
kMaxDepth
)
;
nodes_
[
depth_
]
.
packet
=
p
;
nodes_
[
depth_
]
.
child_total
=
0
;
+
+
depth_
;
continue
;
}
HWY_DASSERT
(
depth_
!
=
0
)
;
const
Node
&
node
=
nodes_
[
depth_
-
1
]
;
const
uint64_t
duration
=
(
p
.
Timestamp
(
)
-
node
.
packet
.
Timestamp
(
)
)
&
Packet
:
:
kTimestampMask
;
const
uint64_t
self_duration
=
ClampedSubtract
(
duration
self_overhead_
+
child_overhead_
+
node
.
child_total
)
;
UpdateOrAdd
(
node
.
packet
.
BiasedOffset
(
)
1
self_duration
)
;
-
-
depth_
;
if
(
depth_
!
=
0
)
{
nodes_
[
depth_
-
1
]
.
child_total
+
=
duration
+
child_overhead_
;
}
}
const
uint64_t
t1
=
hn
:
:
timer
:
:
Stop
(
)
;
analyze_elapsed_
+
=
t1
-
t0
;
}
void
Assimilate
(
const
Results
&
other
)
{
namespace
hn
=
HWY_NAMESPACE
;
const
uint64_t
t0
=
hn
:
:
timer
:
:
Start
(
)
;
HWY_DASSERT
(
depth_
=
=
0
)
;
HWY_DASSERT
(
other
.
depth_
=
=
0
)
;
for
(
size_t
i
=
0
;
i
<
other
.
num_zones_
;
+
+
i
)
{
const
Accumulator
&
zone
=
other
.
zones_
[
i
]
;
UpdateOrAdd
(
zone
.
BiasedOffset
(
)
zone
.
NumCalls
(
)
zone
.
Duration
(
)
)
;
}
const
uint64_t
t1
=
hn
:
:
timer
:
:
Stop
(
)
;
analyze_elapsed_
+
=
t1
-
t0
+
other
.
analyze_elapsed_
;
}
void
Print
(
)
{
namespace
hn
=
HWY_NAMESPACE
;
const
uint64_t
t0
=
hn
:
:
timer
:
:
Start
(
)
;
MergeDuplicates
(
)
;
std
:
:
sort
(
zones_
zones_
+
num_zones_
[
]
(
const
Accumulator
&
r1
const
Accumulator
&
r2
)
{
return
r1
.
Duration
(
)
>
r2
.
Duration
(
)
;
}
)
;
const
double
inv_freq
=
1
.
0
/
platform
:
:
InvariantTicksPerSecond
(
)
;
const
char
*
string_origin
=
StringOrigin
(
)
;
for
(
size_t
i
=
0
;
i
<
num_zones_
;
+
+
i
)
{
const
Accumulator
&
r
=
zones_
[
i
]
;
const
uint64_t
num_calls
=
r
.
NumCalls
(
)
;
printf
(
"
%
-
40s
:
%
10zu
x
%
15zu
=
%
9
.
6f
\
n
"
string_origin
+
r
.
BiasedOffset
(
)
num_calls
r
.
Duration
(
)
/
num_calls
static_cast
<
double
>
(
r
.
Duration
(
)
)
*
inv_freq
)
;
}
const
uint64_t
t1
=
hn
:
:
timer
:
:
Stop
(
)
;
analyze_elapsed_
+
=
t1
-
t0
;
printf
(
"
Total
analysis
[
s
]
:
%
f
\
n
"
static_cast
<
double
>
(
analyze_elapsed_
)
*
inv_freq
)
;
}
private
:
void
UpdateOrAdd
(
const
size_t
biased_offset
const
uint64_t
num_calls
const
uint64_t
duration
)
{
HWY_DASSERT
(
biased_offset
<
(
1ULL
<
<
Packet
:
:
kOffsetBits
)
)
;
if
(
zones_
[
0
]
.
BiasedOffset
(
)
=
=
biased_offset
)
{
zones_
[
0
]
.
Add
(
num_calls
duration
)
;
HWY_DASSERT
(
zones_
[
0
]
.
BiasedOffset
(
)
=
=
biased_offset
)
;
return
;
}
for
(
size_t
i
=
1
;
i
<
num_zones_
;
+
+
i
)
{
if
(
zones_
[
i
]
.
BiasedOffset
(
)
=
=
biased_offset
)
{
zones_
[
i
]
.
Add
(
num_calls
duration
)
;
HWY_DASSERT
(
zones_
[
i
]
.
BiasedOffset
(
)
=
=
biased_offset
)
;
const
Accumulator
prev
=
zones_
[
i
-
1
]
;
zones_
[
i
-
1
]
=
zones_
[
i
]
;
zones_
[
i
]
=
prev
;
return
;
}
}
HWY_DASSERT
(
num_zones_
<
kMaxZones
)
;
Accumulator
*
HWY_RESTRICT
zone
=
zones_
+
num_zones_
;
zone
-
>
Set
(
biased_offset
num_calls
duration
)
;
HWY_DASSERT
(
zone
-
>
BiasedOffset
(
)
=
=
biased_offset
)
;
+
+
num_zones_
;
}
void
MergeDuplicates
(
)
{
const
char
*
string_origin
=
StringOrigin
(
)
;
for
(
size_t
i
=
0
;
i
<
num_zones_
;
+
+
i
)
{
const
size_t
biased_offset
=
zones_
[
i
]
.
BiasedOffset
(
)
;
const
char
*
name
=
string_origin
+
biased_offset
;
uint64_t
num_calls
=
zones_
[
i
]
.
NumCalls
(
)
;
for
(
size_t
j
=
i
+
1
;
j
<
num_zones_
;
)
{
if
(
!
strcmp
(
name
string_origin
+
zones_
[
j
]
.
BiasedOffset
(
)
)
)
{
num_calls
+
=
zones_
[
j
]
.
NumCalls
(
)
;
zones_
[
i
]
.
Add
(
0
zones_
[
j
]
.
Duration
(
)
)
;
zones_
[
j
]
=
zones_
[
-
-
num_zones_
]
;
}
else
{
+
+
j
;
}
}
HWY_DASSERT
(
num_calls
<
(
1ULL
<
<
Accumulator
:
:
kNumCallBits
)
)
;
zones_
[
i
]
.
Set
(
biased_offset
num_calls
zones_
[
i
]
.
Duration
(
)
)
;
}
}
uint64_t
analyze_elapsed_
=
0
;
uint64_t
self_overhead_
=
0
;
uint64_t
child_overhead_
=
0
;
size_t
depth_
=
0
;
size_t
num_zones_
=
0
;
alignas
(
HWY_ALIGNMENT
)
Node
nodes_
[
kMaxDepth
]
;
alignas
(
HWY_ALIGNMENT
)
Accumulator
zones_
[
kMaxZones
]
;
}
;
class
ThreadSpecific
{
static
constexpr
size_t
kBufferCapacity
=
HWY_ALIGNMENT
/
sizeof
(
Packet
)
;
public
:
explicit
ThreadSpecific
(
const
char
*
name
)
:
max_packets_
(
(
PROFILER_THREAD_STORAGE
<
<
20
)
/
sizeof
(
Packet
)
)
packets_
(
AllocateAligned
<
Packet
>
(
max_packets_
)
)
num_packets_
(
0
)
string_origin_
(
StringOrigin
(
)
)
{
const
size_t
biased_offset
=
name
-
string_origin_
;
HWY_ASSERT
(
biased_offset
<
=
(
1ULL
<
<
Packet
:
:
kOffsetBits
)
)
;
}
void
ComputeOverhead
(
)
;
void
WriteEntry
(
const
char
*
name
const
uint64_t
timestamp
)
{
const
size_t
biased_offset
=
name
-
string_origin_
;
Write
(
Packet
:
:
Make
(
biased_offset
timestamp
)
)
;
}
void
WriteExit
(
const
uint64_t
timestamp
)
{
const
size_t
biased_offset
=
Packet
:
:
kOffsetBias
;
Write
(
Packet
:
:
Make
(
biased_offset
timestamp
)
)
;
}
void
AnalyzeRemainingPackets
(
)
{
FlushStream
(
)
;
if
(
num_packets_
+
buffer_size_
>
max_packets_
)
{
results_
.
AnalyzePackets
(
packets_
.
get
(
)
num_packets_
)
;
num_packets_
=
0
;
}
CopyBytes
(
buffer_
packets_
.
get
(
)
+
num_packets_
buffer_size_
*
sizeof
(
Packet
)
)
;
num_packets_
+
=
buffer_size_
;
results_
.
AnalyzePackets
(
packets_
.
get
(
)
num_packets_
)
;
num_packets_
=
0
;
}
Results
&
GetResults
(
)
{
return
results_
;
}
private
:
void
Write
(
const
Packet
packet
)
{
if
(
buffer_size_
=
=
kBufferCapacity
)
{
if
(
num_packets_
+
kBufferCapacity
>
max_packets_
)
{
results_
.
AnalyzePackets
(
packets_
.
get
(
)
num_packets_
)
;
num_packets_
=
0
;
}
StreamCacheLine
(
reinterpret_cast
<
const
uint64_t
*
>
(
buffer_
)
reinterpret_cast
<
uint64_t
*
>
(
packets_
.
get
(
)
+
num_packets_
)
)
;
num_packets_
+
=
kBufferCapacity
;
buffer_size_
=
0
;
}
buffer_
[
buffer_size_
]
=
packet
;
+
+
buffer_size_
;
}
Packet
buffer_
[
kBufferCapacity
]
;
size_t
buffer_size_
=
0
;
const
size_t
max_packets_
;
AlignedFreeUniquePtr
<
Packet
[
]
>
packets_
;
size_t
num_packets_
;
const
char
*
HWY_RESTRICT
string_origin_
;
Results
results_
;
}
;
class
ThreadList
{
public
:
ThreadSpecific
*
Add
(
const
char
*
name
)
{
const
size_t
index
=
num_threads_
.
fetch_add
(
1
std
:
:
memory_order_relaxed
)
;
HWY_DASSERT
(
index
<
kMaxThreads
)
;
ThreadSpecific
*
ts
=
MakeUniqueAligned
<
ThreadSpecific
>
(
name
)
.
release
(
)
;
threads_
[
index
]
.
store
(
ts
std
:
:
memory_order_release
)
;
return
ts
;
}
void
PrintResults
(
)
{
const
auto
acq
=
std
:
:
memory_order_acquire
;
const
size_t
num_threads
=
num_threads_
.
load
(
acq
)
;
ThreadSpecific
*
main
=
threads_
[
0
]
.
load
(
acq
)
;
main
-
>
AnalyzeRemainingPackets
(
)
;
for
(
size_t
i
=
1
;
i
<
num_threads
;
+
+
i
)
{
ThreadSpecific
*
ts
=
threads_
[
i
]
.
load
(
acq
)
;
ts
-
>
AnalyzeRemainingPackets
(
)
;
main
-
>
GetResults
(
)
.
Assimilate
(
ts
-
>
GetResults
(
)
)
;
}
if
(
num_threads
!
=
0
)
{
main
-
>
GetResults
(
)
.
Print
(
)
;
}
}
private
:
alignas
(
64
)
std
:
:
atomic
<
ThreadSpecific
*
>
threads_
[
kMaxThreads
]
;
std
:
:
atomic
<
size_t
>
num_threads_
{
0
}
;
}
;
class
Zone
{
public
:
HWY_NOINLINE
explicit
Zone
(
const
char
*
name
)
{
HWY_FENCE
;
ThreadSpecific
*
HWY_RESTRICT
thread_specific
=
StaticThreadSpecific
(
)
;
if
(
HWY_UNLIKELY
(
thread_specific
=
=
nullptr
)
)
{
char
cpu
[
100
]
;
if
(
!
platform
:
:
HaveTimerStop
(
cpu
)
)
{
HWY_ABORT
(
"
CPU
%
s
is
too
old
for
PROFILER_ENABLED
=
1
exiting
"
cpu
)
;
}
thread_specific
=
StaticThreadSpecific
(
)
=
Threads
(
)
.
Add
(
name
)
;
thread_specific
-
>
ComputeOverhead
(
)
;
}
HWY_FENCE
;
const
uint64_t
timestamp
=
HWY_NAMESPACE
:
:
timer
:
:
Start
(
)
;
thread_specific
-
>
WriteEntry
(
name
timestamp
)
;
}
HWY_NOINLINE
~
Zone
(
)
{
HWY_FENCE
;
const
uint64_t
timestamp
=
HWY_NAMESPACE
:
:
timer
:
:
Stop
(
)
;
StaticThreadSpecific
(
)
-
>
WriteExit
(
timestamp
)
;
HWY_FENCE
;
}
static
void
PrintResults
(
)
{
Threads
(
)
.
PrintResults
(
)
;
}
private
:
static
ThreadSpecific
*
&
StaticThreadSpecific
(
)
{
static
thread_local
ThreadSpecific
*
thread_specific
;
return
thread_specific
;
}
static
ThreadList
&
Threads
(
)
{
static
ThreadList
threads_
;
return
threads_
;
}
}
;
#
define
PROFILER_ZONE
(
name
)
\
HWY_FENCE
;
\
const
hwy
:
:
Zone
zone
(
"
"
name
)
;
\
HWY_FENCE
#
define
PROFILER_FUNC
\
HWY_FENCE
;
\
const
hwy
:
:
Zone
zone
(
__func__
)
;
\
HWY_FENCE
#
define
PROFILER_PRINT_RESULTS
hwy
:
:
Zone
:
:
PrintResults
inline
void
ThreadSpecific
:
:
ComputeOverhead
(
)
{
namespace
hn
=
HWY_NAMESPACE
;
uint64_t
self_overhead
;
{
const
size_t
kNumSamples
=
32
;
uint32_t
samples
[
kNumSamples
]
;
for
(
size_t
idx_sample
=
0
;
idx_sample
<
kNumSamples
;
+
+
idx_sample
)
{
const
size_t
kNumDurations
=
1024
;
uint32_t
durations
[
kNumDurations
]
;
for
(
size_t
idx_duration
=
0
;
idx_duration
<
kNumDurations
;
+
+
idx_duration
)
{
{
PROFILER_ZONE
(
"
Dummy
Zone
(
never
shown
)
"
)
;
}
const
uint64_t
duration
=
results_
.
ZoneDuration
(
buffer_
)
;
buffer_size_
=
0
;
durations
[
idx_duration
]
=
static_cast
<
uint32_t
>
(
duration
)
;
HWY_DASSERT
(
num_packets_
=
=
0
)
;
}
robust_statistics
:
:
CountingSort
(
durations
kNumDurations
)
;
samples
[
idx_sample
]
=
robust_statistics
:
:
Mode
(
durations
kNumDurations
)
;
}
robust_statistics
:
:
CountingSort
(
samples
kNumSamples
)
;
self_overhead
=
samples
[
kNumSamples
/
2
]
;
if
(
PROFILER_PRINT_OVERHEAD
)
{
printf
(
"
Overhead
:
%
zu
\
n
"
self_overhead
)
;
}
results_
.
SetSelfOverhead
(
self_overhead
)
;
}
const
size_t
kNumSamples
=
32
;
uint32_t
samples
[
kNumSamples
]
;
for
(
size_t
idx_sample
=
0
;
idx_sample
<
kNumSamples
;
+
+
idx_sample
)
{
const
size_t
kNumDurations
=
16
;
uint32_t
durations
[
kNumDurations
]
;
for
(
size_t
idx_duration
=
0
;
idx_duration
<
kNumDurations
;
+
+
idx_duration
)
{
const
size_t
kReps
=
10000
;
HWY_DASSERT
(
kReps
*
2
<
max_packets_
)
;
std
:
:
atomic_thread_fence
(
std
:
:
memory_order_seq_cst
)
;
const
uint64_t
t0
=
hn
:
:
timer
:
:
Start
(
)
;
for
(
size_t
i
=
0
;
i
<
kReps
;
+
+
i
)
{
PROFILER_ZONE
(
"
Dummy
"
)
;
}
FlushStream
(
)
;
const
uint64_t
t1
=
hn
:
:
timer
:
:
Stop
(
)
;
HWY_DASSERT
(
num_packets_
+
buffer_size_
=
=
kReps
*
2
)
;
buffer_size_
=
0
;
num_packets_
=
0
;
const
uint64_t
avg_duration
=
(
t1
-
t0
+
kReps
/
2
)
/
kReps
;
durations
[
idx_duration
]
=
static_cast
<
uint32_t
>
(
ClampedSubtract
(
avg_duration
self_overhead
)
)
;
}
robust_statistics
:
:
CountingSort
(
durations
kNumDurations
)
;
samples
[
idx_sample
]
=
robust_statistics
:
:
Mode
(
durations
kNumDurations
)
;
}
robust_statistics
:
:
CountingSort
(
samples
kNumSamples
)
;
const
uint64_t
child_overhead
=
samples
[
9
*
kNumSamples
/
10
]
;
if
(
PROFILER_PRINT_OVERHEAD
)
{
printf
(
"
Child
overhead
:
%
zu
\
n
"
child_overhead
)
;
}
results_
.
SetChildOverhead
(
child_overhead
)
;
}
#
pragma
pack
(
pop
)
}
#
endif
#
if
!
PROFILER_ENABLED
&
&
!
HWY_IDE
#
define
PROFILER_ZONE
(
name
)
#
define
PROFILER_FUNC
#
define
PROFILER_PRINT_RESULTS
(
)
#
endif
#
endif
