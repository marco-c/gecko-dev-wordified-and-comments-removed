import
buildconfig
import
errno
import
sys
import
platform
import
os
import
re
import
shutil
import
textwrap
import
fnmatch
import
subprocess
import
time
import
ctypes
import
urlparse
import
concurrent
.
futures
import
multiprocessing
from
optparse
import
OptionParser
from
xml
.
dom
.
minidom
import
parse
from
mozpack
.
copier
import
FileRegistry
from
mozpack
.
manifests
import
(
    
InstallManifest
    
UnreadableInstallManifest
)
class
VCSFileInfo
:
    
"
"
"
A
base
class
for
version
-
controlled
file
information
.
Ensures
that
the
        
following
attributes
are
generated
only
once
(
successfully
)
:
            
self
.
root
            
self
.
clean_root
            
self
.
revision
            
self
.
filename
        
The
attributes
are
generated
by
a
single
call
to
the
GetRoot
        
GetRevision
and
GetFilename
methods
.
Those
methods
are
explicitly
not
        
implemented
here
and
must
be
implemented
in
derived
classes
.
"
"
"
    
def
__init__
(
self
file
)
:
        
if
not
file
:
            
raise
ValueError
        
self
.
file
=
file
    
def
__getattr__
(
self
name
)
:
        
"
"
"
__getattr__
is
only
called
for
attributes
that
are
not
set
on
self
            
so
setting
self
.
[
attr
]
will
prevent
future
calls
to
the
GetRoot
            
GetRevision
and
GetFilename
methods
.
We
don
'
t
set
the
values
on
            
failure
on
the
off
chance
that
a
future
call
might
succeed
.
"
"
"
        
if
name
=
=
"
root
"
:
            
root
=
self
.
GetRoot
(
)
            
if
root
:
                
self
.
root
=
root
            
return
root
        
elif
name
=
=
"
clean_root
"
:
            
clean_root
=
self
.
GetCleanRoot
(
)
            
if
clean_root
:
                
self
.
clean_root
=
clean_root
            
return
clean_root
        
elif
name
=
=
"
revision
"
:
            
revision
=
self
.
GetRevision
(
)
            
if
revision
:
                
self
.
revision
=
revision
            
return
revision
        
elif
name
=
=
"
filename
"
:
            
filename
=
self
.
GetFilename
(
)
            
if
filename
:
                
self
.
filename
=
filename
            
return
filename
        
raise
AttributeError
    
def
GetRoot
(
self
)
:
        
"
"
"
This
method
should
return
the
unmodified
root
for
the
file
or
'
None
'
            
on
failure
.
"
"
"
        
raise
NotImplementedError
    
def
GetCleanRoot
(
self
)
:
        
"
"
"
This
method
should
return
the
repository
root
for
the
file
or
'
None
'
            
on
failure
.
"
"
"
        
raise
NotImplementedError
    
def
GetRevision
(
self
)
:
        
"
"
"
This
method
should
return
the
revision
number
for
the
file
or
'
None
'
            
on
failure
.
"
"
"
        
raise
NotImplementedError
    
def
GetFilename
(
self
)
:
        
"
"
"
This
method
should
return
the
repository
-
specific
filename
for
the
            
file
or
'
None
'
on
failure
.
"
"
"
        
raise
NotImplementedError
rootRegex
=
re
.
compile
(
r
'
^
\
S
+
?
:
/
+
(
?
:
[
^
\
s
/
]
*
)
?
(
\
S
+
)
'
)
def
read_output
(
*
args
)
:
    
(
stdout
_
)
=
subprocess
.
Popen
(
args
=
args
stdout
=
subprocess
.
PIPE
)
.
communicate
(
)
    
return
stdout
.
rstrip
(
)
class
HGRepoInfo
:
    
def
__init__
(
self
path
)
:
        
self
.
path
=
path
        
rev
=
read_output
(
'
hg
'
'
-
R
'
path
                          
'
parent
'
'
-
-
template
=
{
node
|
short
}
'
)
        
hg_root
=
os
.
environ
.
get
(
"
SRCSRV_ROOT
"
)
        
if
hg_root
:
            
root
=
hg_root
        
else
:
            
root
=
read_output
(
'
hg
'
'
-
R
'
path
                               
'
showconfig
'
'
paths
.
default
'
)
            
if
not
root
:
                
print
>
>
sys
.
stderr
"
Failed
to
get
HG
Repo
for
%
s
"
%
path
        
cleanroot
=
None
        
if
root
:
            
match
=
rootRegex
.
match
(
root
)
            
if
match
:
                
cleanroot
=
match
.
group
(
1
)
                
if
cleanroot
.
endswith
(
'
/
'
)
:
                    
cleanroot
=
cleanroot
[
:
-
1
]
        
if
cleanroot
is
None
:
            
print
>
>
sys
.
stderr
textwrap
.
dedent
(
"
"
"
\
                
Could
not
determine
repo
info
for
%
s
.
This
is
either
not
a
clone
of
the
web
-
based
                
repository
or
you
have
not
specified
SRCSRV_ROOT
or
the
clone
is
corrupt
.
"
"
"
)
%
path
            
sys
.
exit
(
1
)
        
self
.
rev
=
rev
        
self
.
root
=
root
        
self
.
cleanroot
=
cleanroot
    
def
GetFileInfo
(
self
file
)
:
        
return
HGFileInfo
(
file
self
)
class
HGFileInfo
(
VCSFileInfo
)
:
    
def
__init__
(
self
file
repo
)
:
        
VCSFileInfo
.
__init__
(
self
file
)
        
self
.
repo
=
repo
        
self
.
file
=
os
.
path
.
relpath
(
file
repo
.
path
)
    
def
GetRoot
(
self
)
:
        
return
self
.
repo
.
root
    
def
GetCleanRoot
(
self
)
:
        
return
self
.
repo
.
cleanroot
    
def
GetRevision
(
self
)
:
        
return
self
.
repo
.
rev
    
def
GetFilename
(
self
)
:
        
if
self
.
revision
and
self
.
clean_root
:
            
return
"
hg
:
%
s
:
%
s
:
%
s
"
%
(
self
.
clean_root
self
.
file
self
.
revision
)
        
return
self
.
file
class
GitRepoInfo
:
    
"
"
"
    
Info
about
a
local
git
repository
.
Does
not
currently
    
support
discovering
info
about
a
git
clone
the
info
must
be
    
provided
out
-
of
-
band
.
    
"
"
"
    
def
__init__
(
self
path
rev
root
)
:
        
self
.
path
=
path
        
cleanroot
=
None
        
if
root
:
            
match
=
rootRegex
.
match
(
root
)
            
if
match
:
                
cleanroot
=
match
.
group
(
1
)
                
if
cleanroot
.
endswith
(
'
/
'
)
:
                    
cleanroot
=
cleanroot
[
:
-
1
]
        
if
cleanroot
is
None
:
            
print
>
>
sys
.
stderr
textwrap
.
dedent
(
"
"
"
\
                
Could
not
determine
repo
info
for
%
s
(
%
s
)
.
This
is
either
not
a
clone
of
a
web
-
based
                
repository
or
you
have
not
specified
SRCSRV_ROOT
or
the
clone
is
corrupt
.
"
"
"
)
%
(
path
root
)
            
sys
.
exit
(
1
)
        
self
.
rev
=
rev
        
self
.
cleanroot
=
cleanroot
    
def
GetFileInfo
(
self
file
)
:
        
return
GitFileInfo
(
file
self
)
class
GitFileInfo
(
VCSFileInfo
)
:
    
def
__init__
(
self
file
repo
)
:
        
VCSFileInfo
.
__init__
(
self
file
)
        
self
.
repo
=
repo
        
self
.
file
=
os
.
path
.
relpath
(
file
repo
.
path
)
    
def
GetRoot
(
self
)
:
        
return
self
.
repo
.
path
    
def
GetCleanRoot
(
self
)
:
        
return
self
.
repo
.
cleanroot
    
def
GetRevision
(
self
)
:
        
return
self
.
repo
.
rev
    
def
GetFilename
(
self
)
:
        
if
self
.
revision
and
self
.
clean_root
:
            
return
"
git
:
%
s
:
%
s
:
%
s
"
%
(
self
.
clean_root
self
.
file
self
.
revision
)
        
return
self
.
file
vcsFileInfoCache
=
{
}
def
IsInDir
(
file
dir
)
:
    
return
os
.
path
.
abspath
(
file
)
.
lower
(
)
.
startswith
(
os
.
path
.
abspath
(
dir
)
.
lower
(
)
)
def
GetVCSFilenameFromSrcdir
(
file
srcdir
)
:
    
if
srcdir
not
in
Dumper
.
srcdirRepoInfo
:
        
if
os
.
path
.
isdir
(
os
.
path
.
join
(
srcdir
'
.
hg
'
)
)
:
            
Dumper
.
srcdirRepoInfo
[
srcdir
]
=
HGRepoInfo
(
srcdir
)
        
else
:
            
return
None
    
return
Dumper
.
srcdirRepoInfo
[
srcdir
]
.
GetFileInfo
(
file
)
def
GetVCSFilename
(
file
srcdirs
)
:
    
"
"
"
Given
a
full
path
to
a
file
and
the
top
source
directory
    
look
for
version
control
information
about
this
file
and
return
    
a
tuple
containing
    
1
)
a
specially
formatted
filename
that
contains
the
VCS
type
    
VCS
location
relative
filename
and
revision
number
formatted
like
:
    
vcs
:
vcs
location
:
filename
:
revision
    
For
example
:
    
cvs
:
cvs
.
mozilla
.
org
/
cvsroot
:
mozilla
/
browser
/
app
/
nsBrowserApp
.
cpp
:
1
.
36
    
2
)
the
unmodified
root
information
if
it
exists
"
"
"
    
(
path
filename
)
=
os
.
path
.
split
(
file
)
    
if
path
=
=
'
'
or
filename
=
=
'
'
:
        
return
(
file
None
)
    
fileInfo
=
None
    
root
=
'
'
    
if
file
in
vcsFileInfoCache
:
        
fileInfo
=
vcsFileInfoCache
[
file
]
    
else
:
        
for
srcdir
in
srcdirs
:
            
if
not
IsInDir
(
file
srcdir
)
:
                
continue
            
fileInfo
=
GetVCSFilenameFromSrcdir
(
file
srcdir
)
            
if
fileInfo
:
                
vcsFileInfoCache
[
file
]
=
fileInfo
                
break
    
if
fileInfo
:
        
file
=
fileInfo
.
filename
        
root
=
fileInfo
.
root
    
return
(
file
.
replace
(
"
\
\
"
"
/
"
)
root
)
def
validate_install_manifests
(
install_manifest_args
)
:
    
args
=
[
]
    
for
arg
in
install_manifest_args
:
        
bits
=
arg
.
split
(
'
'
)
        
if
len
(
bits
)
!
=
2
:
            
raise
ValueError
(
'
Invalid
format
for
-
-
install
-
manifest
:
'
                             
'
specify
manifest
target_dir
'
)
        
manifest_file
destination
=
map
(
os
.
path
.
abspath
bits
)
        
if
not
os
.
path
.
isfile
(
manifest_file
)
:
            
raise
IOError
(
errno
.
ENOENT
'
Manifest
file
not
found
'
                          
manifest_file
)
        
if
not
os
.
path
.
isdir
(
destination
)
:
            
raise
IOError
(
errno
.
ENOENT
'
Install
directory
not
found
'
                          
destination
)
        
try
:
            
manifest
=
InstallManifest
(
manifest_file
)
        
except
UnreadableInstallManifest
:
            
raise
IOError
(
errno
.
EINVAL
'
Error
parsing
manifest
file
'
                          
manifest_file
)
        
args
.
append
(
(
manifest
destination
)
)
    
return
args
def
make_file_mapping
(
install_manifests
)
:
    
file_mapping
=
{
}
    
for
manifest
destination
in
install_manifests
:
        
destination
=
os
.
path
.
abspath
(
destination
)
        
reg
=
FileRegistry
(
)
        
manifest
.
populate_registry
(
reg
)
        
for
dst
src
in
reg
:
            
if
hasattr
(
src
'
path
'
)
:
                
abs_dest
=
os
.
path
.
normpath
(
os
.
path
.
join
(
destination
dst
)
)
                
file_mapping
[
abs_dest
]
=
src
.
path
    
return
file_mapping
def
GetPlatformSpecificDumper
(
*
*
kwargs
)
:
    
"
"
"
This
function
simply
returns
a
instance
of
a
subclass
of
Dumper
    
that
is
appropriate
for
the
current
platform
.
"
"
"
    
return
{
'
WINNT
'
:
Dumper_Win32
            
'
Linux
'
:
Dumper_Linux
            
'
Darwin
'
:
Dumper_Mac
}
[
buildconfig
.
substs
[
'
OS_ARCH
'
]
]
(
*
*
kwargs
)
def
SourceIndex
(
fileStream
outputPath
vcs_root
)
:
    
"
"
"
Takes
a
list
of
files
writes
info
to
a
data
block
in
a
.
stream
file
"
"
"
    
result
=
True
    
pdbStreamFile
=
open
(
outputPath
"
w
"
)
    
pdbStreamFile
.
write
(
'
'
'
SRCSRV
:
ini
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
\
r
\
nVERSION
=
2
\
r
\
nINDEXVERSION
=
2
\
r
\
nVERCTRL
=
http
\
r
\
nSRCSRV
:
variables
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
\
r
\
nHGSERVER
=
'
'
'
)
    
pdbStreamFile
.
write
(
vcs_root
)
    
pdbStreamFile
.
write
(
'
'
'
\
r
\
nSRCSRVVERCTRL
=
http
\
r
\
nHTTP_EXTRACT_TARGET
=
%
hgserver
%
/
raw
-
file
/
%
var3
%
/
%
var2
%
\
r
\
nSRCSRVTRG
=
%
http_extract_target
%
\
r
\
nSRCSRV
:
source
files
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
\
r
\
n
'
'
'
)
    
pdbStreamFile
.
write
(
fileStream
)
    
pdbStreamFile
.
write
(
"
SRCSRV
:
end
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
\
r
\
n
\
n
"
)
    
pdbStreamFile
.
close
(
)
    
return
result
def
StartJob
(
dumper
lock
srcdirRepoInfo
func_name
args
)
:
    
Dumper
.
lock
=
lock
    
Dumper
.
srcdirRepoInfo
=
srcdirRepoInfo
    
return
getattr
(
dumper
func_name
)
(
*
args
)
class
JobPool
(
object
)
:
    
jobs
=
{
}
    
executor
=
None
    
classmethod
    
def
init
(
cls
executor
)
:
        
cls
.
executor
=
executor
    
classmethod
    
def
shutdown
(
cls
)
:
        
cls
.
executor
.
shutdown
(
)
    
classmethod
    
def
submit
(
cls
args
callback
)
:
        
cls
.
jobs
[
cls
.
executor
.
submit
(
StartJob
*
args
)
]
=
callback
    
classmethod
    
def
as_completed
(
cls
)
:
        
'
'
'
Like
concurrent
.
futures
.
as_completed
but
allows
adding
new
futures
        
between
generator
steps
.
Iteration
will
end
when
the
generator
has
        
yielded
all
completed
futures
and
JobQueue
.
jobs
is
empty
.
        
Yields
(
future
callback
)
pairs
.
        
'
'
'
        
while
cls
.
jobs
:
            
completed
_
=
concurrent
.
futures
.
wait
(
cls
.
jobs
.
keys
(
)
return_when
=
concurrent
.
futures
.
FIRST_COMPLETED
)
            
for
f
in
completed
:
                
callback
=
cls
.
jobs
[
f
]
                
del
cls
.
jobs
[
f
]
                
yield
f
callback
class
Dumper
:
    
"
"
"
This
class
can
dump
symbols
from
a
file
with
debug
info
and
    
store
the
output
in
a
directory
structure
that
is
valid
for
use
as
    
a
Breakpad
symbol
server
.
Requires
a
path
to
a
dump_syms
binary
-
-
    
|
dump_syms
|
and
a
directory
to
store
symbols
in
-
-
|
symbol_path
|
.
    
Optionally
takes
a
list
of
processor
architectures
to
process
from
    
each
debug
file
-
-
|
archs
|
the
full
path
to
the
top
source
    
directory
-
-
|
srcdir
|
for
generating
relative
source
file
names
    
and
an
option
to
copy
debug
info
files
alongside
the
dumped
    
symbol
files
-
-
|
copy_debug
|
mostly
useful
for
creating
a
    
Microsoft
Symbol
Server
from
the
resulting
output
.
    
You
don
'
t
want
to
use
this
directly
if
you
intend
to
process
files
.
    
Instead
call
GetPlatformSpecificDumper
to
get
an
instance
of
a
    
subclass
.
    
Processing
is
performed
asynchronously
via
worker
processes
;
in
    
order
to
wait
for
processing
to
finish
and
cleanup
correctly
you
    
must
call
Finish
after
all
ProcessFiles
calls
have
been
made
.
    
You
must
also
call
Dumper
.
GlobalInit
before
creating
or
using
any
    
instances
.
"
"
"
    
def
__init__
(
self
dump_syms
symbol_path
                 
archs
=
None
                 
srcdirs
=
[
]
                 
copy_debug
=
False
                 
vcsinfo
=
False
                 
srcsrv
=
False
                 
exclude
=
[
]
                 
repo_manifest
=
None
                 
file_mapping
=
None
)
:
        
self
.
dump_syms
=
os
.
path
.
abspath
(
dump_syms
)
        
self
.
symbol_path
=
symbol_path
        
if
archs
is
None
:
            
self
.
archs
=
[
'
'
]
        
else
:
            
self
.
archs
=
[
'
-
a
%
s
'
%
a
for
a
in
archs
.
split
(
)
]
        
self
.
srcdirs
=
[
os
.
path
.
normpath
(
a
)
for
a
in
srcdirs
]
        
self
.
copy_debug
=
copy_debug
        
self
.
vcsinfo
=
vcsinfo
        
self
.
srcsrv
=
srcsrv
        
self
.
exclude
=
exclude
[
:
]
        
if
repo_manifest
:
            
self
.
parse_repo_manifest
(
repo_manifest
)
        
self
.
file_mapping
=
file_mapping
or
{
}
        
self
.
files_record
=
{
}
    
classmethod
    
def
GlobalInit
(
cls
executor
=
concurrent
.
futures
.
ProcessPoolExecutor
)
:
        
"
"
"
Initialize
the
class
globals
for
the
multiprocessing
setup
;
must
        
be
called
before
any
Dumper
instances
are
created
and
used
.
Test
cases
        
may
pass
in
a
different
executor
to
use
usually
        
concurrent
.
futures
.
ThreadPoolExecutor
.
"
"
"
        
num_cpus
=
multiprocessing
.
cpu_count
(
)
        
if
num_cpus
is
None
:
            
num_cpus
=
2
        
manager
=
multiprocessing
.
Manager
(
)
        
cls
.
lock
=
manager
.
RLock
(
)
        
cls
.
srcdirRepoInfo
=
manager
.
dict
(
)
        
JobPool
.
init
(
executor
(
max_workers
=
num_cpus
)
)
    
def
output
(
self
dest
output_str
)
:
        
"
"
"
Writes
|
output_str
|
to
|
dest
|
holding
|
lock
|
;
        
terminates
with
a
newline
.
"
"
"
        
with
Dumper
.
lock
:
            
dest
.
write
(
output_str
+
"
\
n
"
)
            
dest
.
flush
(
)
    
def
output_pid
(
self
dest
output_str
)
:
        
"
"
"
Debugging
output
;
prepends
the
pid
to
the
string
.
"
"
"
        
self
.
output
(
dest
"
%
d
:
%
s
"
%
(
os
.
getpid
(
)
output_str
)
)
    
def
parse_repo_manifest
(
self
repo_manifest
)
:
        
"
"
"
        
Parse
an
XML
manifest
of
repository
info
as
produced
        
by
the
repo
manifest
-
r
command
.
        
"
"
"
        
doc
=
parse
(
repo_manifest
)
        
if
doc
.
firstChild
.
tagName
!
=
"
manifest
"
:
            
return
        
def
ensure_slash
(
u
)
:
            
if
not
u
.
endswith
(
"
/
"
)
:
                
return
u
+
"
/
"
            
return
u
        
remotes
=
dict
(
[
(
r
.
getAttribute
(
"
name
"
)
ensure_slash
(
r
.
getAttribute
(
"
fetch
"
)
)
)
for
r
in
doc
.
getElementsByTagName
(
"
remote
"
)
]
)
        
default_remote
=
None
        
if
doc
.
getElementsByTagName
(
"
default
"
)
:
            
default_remote
=
doc
.
getElementsByTagName
(
"
default
"
)
[
0
]
.
getAttribute
(
"
remote
"
)
        
base_dir
=
os
.
path
.
abspath
(
os
.
path
.
dirname
(
repo_manifest
)
)
        
for
proj
in
doc
.
getElementsByTagName
(
"
project
"
)
:
            
name
=
proj
.
getAttribute
(
"
name
"
)
            
path
=
proj
.
getAttribute
(
"
path
"
)
            
rev
=
proj
.
getAttribute
(
"
revision
"
)
            
remote
=
proj
.
getAttribute
(
"
remote
"
)
            
if
not
remote
:
                
remote
=
default_remote
            
if
not
path
:
                
path
=
name
            
if
not
(
name
and
path
and
rev
and
remote
)
:
                
print
"
Skipping
project
%
s
"
%
proj
.
toxml
(
)
                
continue
            
remote
=
remotes
[
remote
]
            
if
remote
.
startswith
(
"
git
:
"
)
:
                
remote
=
"
http
"
+
remote
[
3
:
]
            
srcdir
=
os
.
path
.
join
(
base_dir
path
)
            
self
.
srcdirs
.
append
(
srcdir
)
            
root
=
urlparse
.
urljoin
(
remote
name
)
            
Dumper
.
srcdirRepoInfo
[
srcdir
]
=
GitRepoInfo
(
srcdir
rev
root
)
    
def
ShouldProcess
(
self
file
)
:
        
return
not
any
(
fnmatch
.
fnmatch
(
os
.
path
.
basename
(
file
)
exclude
)
for
exclude
in
self
.
exclude
)
    
def
ShouldSkipDir
(
self
dir
)
:
        
return
False
    
def
RunFileCommand
(
self
file
)
:
        
"
"
"
Utility
function
returns
the
output
of
file
(
1
)
"
"
"
        
try
:
            
return
os
.
popen
(
"
file
-
Lb
"
+
file
)
.
read
(
)
        
except
:
            
return
"
"
    
def
FixFilenameCase
(
self
file
)
:
        
return
file
    
def
SourceServerIndexing
(
self
debug_file
guid
sourceFileStream
vcs_root
)
:
        
return
"
"
    
def
CopyDebug
(
self
file
debug_file
guid
code_file
code_id
)
:
        
pass
    
def
Finish
(
self
stop_pool
=
True
)
:
        
'
'
'
Process
all
pending
jobs
and
any
jobs
their
callbacks
submit
.
        
By
default
will
shutdown
the
executor
but
for
testcases
that
        
need
multiple
runs
pass
stop_pool
=
False
.
'
'
'
        
for
job
callback
in
JobPool
.
as_completed
(
)
:
            
try
:
                
res
=
job
.
result
(
)
            
except
Exception
as
e
:
                
self
.
output
(
sys
.
stderr
'
Job
raised
exception
:
%
s
'
%
e
)
                
continue
            
callback
(
res
)
        
if
stop_pool
:
            
JobPool
.
shutdown
(
)
    
def
Process
(
self
*
args
)
:
        
"
"
"
Process
files
recursively
in
args
.
"
"
"
        
files
=
set
(
)
        
for
arg
in
args
:
            
for
f
in
self
.
get_files_to_process
(
arg
)
:
                
files
.
add
(
f
)
        
for
f
in
sorted
(
files
key
=
os
.
path
.
getsize
reverse
=
True
)
:
            
self
.
ProcessFiles
(
(
f
)
)
    
def
get_files_to_process
(
self
file_or_dir
)
:
        
"
"
"
Generate
the
files
to
process
from
an
input
.
"
"
"
        
if
os
.
path
.
isdir
(
file_or_dir
)
and
not
self
.
ShouldSkipDir
(
file_or_dir
)
:
            
for
f
in
self
.
get_files_to_process_in_dir
(
file_or_dir
)
:
                
yield
f
        
elif
os
.
path
.
isfile
(
file_or_dir
)
:
            
yield
file_or_dir
    
def
get_files_to_process_in_dir
(
self
path
)
:
        
"
"
"
Generate
the
files
to
process
in
a
directory
.
        
Valid
files
are
are
determined
by
calling
ShouldProcess
.
        
"
"
"
        
for
root
dirs
files
in
os
.
walk
(
path
)
:
            
for
d
in
dirs
[
:
]
:
                
if
self
.
ShouldSkipDir
(
d
)
:
                    
dirs
.
remove
(
d
)
            
for
f
in
files
:
                
fullpath
=
os
.
path
.
join
(
root
f
)
                
if
self
.
ShouldProcess
(
fullpath
)
:
                    
yield
fullpath
    
def
SubmitJob
(
self
file_key
func_name
args
callback
)
:
        
"
"
"
Submits
a
job
to
the
pool
of
workers
"
"
"
        
JobPool
.
submit
(
(
self
Dumper
.
lock
Dumper
.
srcdirRepoInfo
func_name
args
)
callback
)
    
def
ProcessFilesFinished
(
self
res
)
:
        
"
"
"
Callback
from
multiprocesing
when
ProcessFilesWork
finishes
;
        
run
the
cleanup
work
if
any
"
"
"
        
self
.
files_record
[
res
[
'
files
'
]
]
+
=
1
        
if
self
.
files_record
[
res
[
'
files
'
]
]
=
=
len
(
self
.
archs
)
:
            
del
self
.
files_record
[
res
[
'
files
'
]
]
            
if
res
[
'
after
'
]
:
                
res
[
'
after
'
]
(
res
[
'
status
'
]
res
[
'
after_arg
'
]
)
    
def
ProcessFiles
(
self
files
after
=
None
after_arg
=
None
)
:
        
"
"
"
Dump
symbols
from
these
files
into
a
symbol
file
stored
        
in
the
proper
directory
structure
in
|
symbol_path
|
;
processing
is
performed
        
asynchronously
and
Finish
must
be
called
to
wait
for
it
complete
and
cleanup
.
        
All
files
after
the
first
are
fallbacks
in
case
the
first
file
does
not
process
        
successfully
;
if
it
does
no
other
files
will
be
touched
.
"
"
"
        
self
.
output_pid
(
sys
.
stderr
"
Submitting
jobs
for
files
:
%
s
"
%
str
(
files
)
)
        
vcs_root
=
os
.
environ
.
get
(
"
SRCSRV_ROOT
"
)
        
for
arch_num
arch
in
enumerate
(
self
.
archs
)
:
            
self
.
files_record
[
files
]
=
0
            
self
.
SubmitJob
(
files
[
-
1
]
'
ProcessFilesWork
'
args
=
(
files
arch_num
arch
vcs_root
after
after_arg
)
callback
=
self
.
ProcessFilesFinished
)
    
def
dump_syms_cmdline
(
self
file
arch
files
)
:
        
'
'
'
        
Get
the
commandline
used
to
invoke
dump_syms
.
        
'
'
'
        
return
[
self
.
dump_syms
file
]
    
def
ProcessFilesWork
(
self
files
arch_num
arch
vcs_root
after
after_arg
)
:
        
t_start
=
time
.
time
(
)
        
self
.
output_pid
(
sys
.
stderr
"
Worker
processing
files
:
%
s
"
%
(
files
)
)
        
result
=
{
'
status
'
:
False
'
after
'
:
after
'
after_arg
'
:
after_arg
'
files
'
:
files
}
        
sourceFileStream
=
'
'
        
code_id
code_file
=
None
None
        
for
file
in
files
:
            
try
:
                
cmd
=
self
.
dump_syms_cmdline
(
file
arch
files
)
                
self
.
output_pid
(
sys
.
stderr
'
'
.
join
(
cmd
)
)
                
proc
=
subprocess
.
Popen
(
cmd
stdout
=
subprocess
.
PIPE
                                        
stderr
=
open
(
os
.
devnull
'
wb
'
)
)
                
module_line
=
proc
.
stdout
.
next
(
)
                
if
module_line
.
startswith
(
"
MODULE
"
)
:
                    
(
guid
debug_file
)
=
(
module_line
.
split
(
)
)
[
3
:
5
]
                    
sym_file
=
re
.
sub
(
"
\
.
pdb
"
"
"
debug_file
)
+
"
.
sym
"
                    
rel_path
=
os
.
path
.
join
(
debug_file
                                            
guid
                                            
sym_file
)
.
replace
(
"
\
\
"
"
/
"
)
                    
full_path
=
os
.
path
.
normpath
(
os
.
path
.
join
(
self
.
symbol_path
                                                              
rel_path
)
)
                    
try
:
                        
os
.
makedirs
(
os
.
path
.
dirname
(
full_path
)
)
                    
except
OSError
:
                        
pass
                    
f
=
open
(
full_path
"
w
"
)
                    
f
.
write
(
module_line
)
                    
for
line
in
proc
.
stdout
:
                        
if
line
.
startswith
(
"
FILE
"
)
:
                            
(
x
index
filename
)
=
line
.
rstrip
(
)
.
split
(
None
2
)
                            
filename
=
os
.
path
.
normpath
(
self
.
FixFilenameCase
(
filename
)
)
                            
sourcepath
=
filename
                            
if
filename
in
self
.
file_mapping
:
                                
filename
=
self
.
file_mapping
[
filename
]
                            
if
self
.
vcsinfo
:
                                
(
filename
rootname
)
=
GetVCSFilename
(
filename
self
.
srcdirs
)
                                
if
vcs_root
is
None
:
                                  
if
rootname
:
                                     
vcs_root
=
rootname
                            
if
filename
.
startswith
(
"
hg
"
)
:
                                
(
ver
checkout
source_file
revision
)
=
filename
.
split
(
"
:
"
3
)
                                
sourceFileStream
+
=
sourcepath
+
"
*
"
+
source_file
+
'
*
'
+
revision
+
"
\
r
\
n
"
                            
f
.
write
(
"
FILE
%
s
%
s
\
n
"
%
(
index
filename
)
)
                        
elif
line
.
startswith
(
"
INFO
CODE_ID
"
)
:
                            
bits
=
line
.
rstrip
(
)
.
split
(
None
3
)
                            
if
len
(
bits
)
=
=
4
:
                                
code_id
code_file
=
bits
[
2
:
]
                            
f
.
write
(
line
)
                        
else
:
                            
f
.
write
(
line
)
                            
result
[
'
status
'
]
=
True
                    
f
.
close
(
)
                    
proc
.
wait
(
)
                    
self
.
output
(
sys
.
stdout
rel_path
)
                    
if
self
.
srcsrv
and
vcs_root
:
                        
self
.
SourceServerIndexing
(
file
guid
sourceFileStream
vcs_root
)
                    
if
self
.
copy_debug
and
arch_num
=
=
0
:
                        
self
.
CopyDebug
(
file
debug_file
guid
                                       
code_file
code_id
)
            
except
StopIteration
:
                
pass
            
except
Exception
as
e
:
                
self
.
output
(
sys
.
stderr
"
Unexpected
error
:
%
s
"
%
(
str
(
e
)
)
)
                
raise
            
if
result
[
'
status
'
]
:
                
break
        
elapsed
=
time
.
time
(
)
-
t_start
        
self
.
output_pid
(
sys
.
stderr
'
Worker
finished
processing
%
s
in
%
.
2fs
'
%
                        
(
files
elapsed
)
)
        
return
result
class
Dumper_Win32
(
Dumper
)
:
    
fixedFilenameCaseCache
=
{
}
    
def
ShouldProcess
(
self
file
)
:
        
"
"
"
This
function
will
allow
processing
of
pdb
files
that
have
dll
        
or
exe
files
with
the
same
base
name
next
to
them
.
"
"
"
        
if
not
Dumper
.
ShouldProcess
(
self
file
)
:
            
return
False
        
if
file
.
endswith
(
"
.
pdb
"
)
:
            
(
path
ext
)
=
os
.
path
.
splitext
(
file
)
            
if
os
.
path
.
isfile
(
path
+
"
.
exe
"
)
or
os
.
path
.
isfile
(
path
+
"
.
dll
"
)
:
                
return
True
        
return
False
    
def
FixFilenameCase
(
self
file
)
:
        
"
"
"
Recent
versions
of
Visual
C
+
+
put
filenames
into
        
PDB
files
as
all
lowercase
.
If
the
file
exists
        
on
the
local
filesystem
fix
it
.
"
"
"
        
if
file
in
self
.
fixedFilenameCaseCache
:
            
return
self
.
fixedFilenameCaseCache
[
file
]
        
result
=
file
        
ctypes
.
windll
.
kernel32
.
SetErrorMode
(
ctypes
.
c_uint
(
1
)
)
        
(
path
filename
)
=
os
.
path
.
split
(
file
)
        
if
os
.
path
.
isdir
(
path
)
:
            
lc_filename
=
filename
.
lower
(
)
            
for
f
in
os
.
listdir
(
path
)
:
                
if
f
.
lower
(
)
=
=
lc_filename
:
                    
result
=
os
.
path
.
join
(
path
f
)
                    
break
        
self
.
fixedFilenameCaseCache
[
file
]
=
result
        
return
result
    
def
CopyDebug
(
self
file
debug_file
guid
code_file
code_id
)
:
        
def
compress
(
path
)
:
            
compressed_file
=
path
[
:
-
1
]
+
'
_
'
            
success
=
subprocess
.
call
(
[
"
makecab
.
exe
"
"
/
D
"
                                       
"
CompressionType
=
LZX
"
"
/
D
"
                                       
"
CompressionMemory
=
21
"
                                       
path
compressed_file
]
                                      
stdout
=
open
(
os
.
devnull
'
w
'
)
                                      
stderr
=
subprocess
.
STDOUT
)
            
if
success
=
=
0
and
os
.
path
.
exists
(
compressed_file
)
:
                
os
.
unlink
(
path
)
                
return
True
            
return
False
        
rel_path
=
os
.
path
.
join
(
debug_file
                                
guid
                                
debug_file
)
.
replace
(
"
\
\
"
"
/
"
)
        
full_path
=
os
.
path
.
normpath
(
os
.
path
.
join
(
self
.
symbol_path
                                                  
rel_path
)
)
        
shutil
.
copyfile
(
file
full_path
)
        
if
compress
(
full_path
)
:
            
self
.
output
(
sys
.
stdout
rel_path
[
:
-
1
]
+
'
_
'
)
        
else
:
            
self
.
output
(
sys
.
stdout
rel_path
)
        
if
code_file
and
code_id
:
            
full_code_path
=
os
.
path
.
join
(
os
.
path
.
dirname
(
file
)
                                          
code_file
)
            
if
os
.
path
.
exists
(
full_code_path
)
:
                
rel_path
=
os
.
path
.
join
(
code_file
                                        
code_id
                                        
code_file
)
.
replace
(
"
\
\
"
"
/
"
)
                
full_path
=
os
.
path
.
normpath
(
os
.
path
.
join
(
self
.
symbol_path
                                                          
rel_path
)
)
                
try
:
                    
os
.
makedirs
(
os
.
path
.
dirname
(
full_path
)
)
                
except
OSError
as
e
:
                    
if
e
.
errno
!
=
errno
.
EEXIST
:
                        
raise
                
shutil
.
copyfile
(
full_code_path
full_path
)
                
if
compress
(
full_path
)
:
                    
self
.
output
(
sys
.
stdout
rel_path
[
:
-
1
]
+
'
_
'
)
                
else
:
                    
self
.
output
(
sys
.
stdout
rel_path
)
    
def
SourceServerIndexing
(
self
debug_file
guid
sourceFileStream
vcs_root
)
:
        
debug_file
=
os
.
path
.
abspath
(
debug_file
)
        
streamFilename
=
debug_file
+
"
.
stream
"
        
stream_output_path
=
os
.
path
.
abspath
(
streamFilename
)
        
result
=
SourceIndex
(
sourceFileStream
stream_output_path
vcs_root
)
        
if
self
.
copy_debug
:
            
pdbstr_path
=
os
.
environ
.
get
(
"
PDBSTR_PATH
"
)
            
pdbstr
=
os
.
path
.
normpath
(
pdbstr_path
)
            
subprocess
.
call
(
[
pdbstr
"
-
w
"
"
-
p
:
"
+
os
.
path
.
basename
(
debug_file
)
                             
"
-
i
:
"
+
os
.
path
.
basename
(
streamFilename
)
"
-
s
:
srcsrv
"
]
                            
cwd
=
os
.
path
.
dirname
(
stream_output_path
)
)
            
os
.
remove
(
stream_output_path
)
        
return
result
class
Dumper_Linux
(
Dumper
)
:
    
objcopy
=
os
.
environ
[
'
OBJCOPY
'
]
if
'
OBJCOPY
'
in
os
.
environ
else
'
objcopy
'
    
def
ShouldProcess
(
self
file
)
:
        
"
"
"
This
function
will
allow
processing
of
files
that
are
        
executable
or
end
with
the
.
so
extension
and
additionally
        
file
(
1
)
reports
as
being
ELF
files
.
It
expects
to
find
the
file
        
command
in
PATH
.
"
"
"
        
if
not
Dumper
.
ShouldProcess
(
self
file
)
:
            
return
False
        
if
file
.
endswith
(
"
.
so
"
)
or
os
.
access
(
file
os
.
X_OK
)
:
            
return
self
.
RunFileCommand
(
file
)
.
startswith
(
"
ELF
"
)
        
return
False
    
def
CopyDebug
(
self
file
debug_file
guid
code_file
code_id
)
:
        
file_dbg
=
file
+
"
.
dbg
"
        
if
subprocess
.
call
(
[
self
.
objcopy
'
-
-
only
-
keep
-
debug
'
file
file_dbg
]
)
=
=
0
and
\
           
subprocess
.
call
(
[
self
.
objcopy
'
-
-
add
-
gnu
-
debuglink
=
%
s
'
%
file_dbg
file
]
)
=
=
0
:
            
rel_path
=
os
.
path
.
join
(
debug_file
                                    
guid
                                    
debug_file
+
"
.
dbg
"
)
            
full_path
=
os
.
path
.
normpath
(
os
.
path
.
join
(
self
.
symbol_path
                                                      
rel_path
)
)
            
shutil
.
move
(
file_dbg
full_path
)
            
os
.
system
(
"
gzip
-
f
%
s
"
%
full_path
)
            
self
.
output
(
sys
.
stdout
rel_path
+
"
.
gz
"
)
        
else
:
            
if
os
.
path
.
isfile
(
file_dbg
)
:
                
os
.
unlink
(
file_dbg
)
class
Dumper_Solaris
(
Dumper
)
:
    
def
RunFileCommand
(
self
file
)
:
        
"
"
"
Utility
function
returns
the
output
of
file
(
1
)
"
"
"
        
try
:
            
output
=
os
.
popen
(
"
file
"
+
file
)
.
read
(
)
            
return
output
.
split
(
'
\
t
'
)
[
1
]
;
        
except
:
            
return
"
"
    
def
ShouldProcess
(
self
file
)
:
        
"
"
"
This
function
will
allow
processing
of
files
that
are
        
executable
or
end
with
the
.
so
extension
and
additionally
        
file
(
1
)
reports
as
being
ELF
files
.
It
expects
to
find
the
file
        
command
in
PATH
.
"
"
"
        
if
not
Dumper
.
ShouldProcess
(
self
file
)
:
            
return
False
        
if
file
.
endswith
(
"
.
so
"
)
or
os
.
access
(
file
os
.
X_OK
)
:
            
return
self
.
RunFileCommand
(
file
)
.
startswith
(
"
ELF
"
)
        
return
False
def
AfterMac
(
status
dsymbundle
)
:
    
"
"
"
Cleanup
function
to
run
on
Macs
after
we
process
the
file
(
s
)
.
"
"
"
    
shutil
.
rmtree
(
dsymbundle
)
class
Dumper_Mac
(
Dumper
)
:
    
def
ShouldProcess
(
self
file
)
:
        
"
"
"
This
function
will
allow
processing
of
files
that
are
        
executable
or
end
with
the
.
dylib
extension
and
additionally
        
file
(
1
)
reports
as
being
Mach
-
O
files
.
It
expects
to
find
the
file
        
command
in
PATH
.
"
"
"
        
if
not
Dumper
.
ShouldProcess
(
self
file
)
:
            
return
False
        
if
file
.
endswith
(
"
.
dylib
"
)
or
os
.
access
(
file
os
.
X_OK
)
:
            
return
self
.
RunFileCommand
(
file
)
.
startswith
(
"
Mach
-
O
"
)
        
return
False
    
def
ShouldSkipDir
(
self
dir
)
:
        
"
"
"
We
create
.
dSYM
bundles
on
the
fly
but
if
someone
runs
        
buildsymbols
twice
we
should
skip
any
bundles
we
created
        
previously
otherwise
we
'
ll
recurse
into
them
and
try
to
        
dump
the
inner
bits
again
.
"
"
"
        
if
dir
.
endswith
(
"
.
dSYM
"
)
:
            
return
True
        
return
False
    
def
ProcessFiles
(
self
files
after
=
None
after_arg
=
None
)
:
        
self
.
output_pid
(
sys
.
stderr
"
Submitting
job
for
Mac
pre
-
processing
on
file
:
%
s
"
%
(
files
[
0
]
)
)
        
self
.
SubmitJob
(
files
[
0
]
'
ProcessFilesWorkMac
'
args
=
(
files
[
0
]
)
callback
=
self
.
ProcessFilesMacFinished
)
    
def
ProcessFilesMacFinished
(
self
result
)
:
        
if
result
[
'
status
'
]
:
            
Dumper
.
ProcessFiles
(
self
result
[
'
files
'
]
after
=
AfterMac
after_arg
=
result
[
'
files
'
]
[
0
]
)
    
def
dump_syms_cmdline
(
self
file
arch
files
)
:
        
'
'
'
        
Get
the
commandline
used
to
invoke
dump_syms
.
        
'
'
'
        
if
len
(
files
)
=
=
2
and
file
=
=
files
[
0
]
and
file
.
endswith
(
'
.
dSYM
'
)
:
            
return
[
self
.
dump_syms
]
+
arch
.
split
(
)
+
[
'
-
g
'
file
files
[
1
]
]
        
return
Dumper
.
dump_syms_cmdline
(
self
file
arch
files
)
    
def
ProcessFilesWorkMac
(
self
file
)
:
        
"
"
"
dump_syms
on
Mac
needs
to
be
run
on
a
dSYM
bundle
produced
        
by
dsymutil
(
1
)
so
run
dsymutil
here
and
pass
the
bundle
name
        
down
to
the
superclass
method
instead
.
"
"
"
        
t_start
=
time
.
time
(
)
        
self
.
output_pid
(
sys
.
stderr
"
Worker
running
Mac
pre
-
processing
on
file
:
%
s
"
%
(
file
)
)
        
result
=
{
'
status
'
:
False
'
files
'
:
None
'
file_key
'
:
file
}
        
dsymbundle
=
file
+
"
.
dSYM
"
        
if
os
.
path
.
exists
(
dsymbundle
)
:
            
shutil
.
rmtree
(
dsymbundle
)
        
dsymutil
=
buildconfig
.
substs
[
'
DSYMUTIL
'
]
        
try
:
            
cmd
=
(
[
dsymutil
]
+
                   
[
a
.
replace
(
'
-
a
'
'
-
-
arch
=
'
)
for
a
in
self
.
archs
if
a
]
+
                   
[
file
]
)
            
self
.
output_pid
(
sys
.
stderr
'
'
.
join
(
cmd
)
)
            
subprocess
.
check_call
(
cmd
stdout
=
open
(
os
.
devnull
'
w
'
)
)
        
except
subprocess
.
CalledProcessError
as
e
:
            
self
.
output_pid
(
sys
.
stderr
'
Error
running
dsymutil
:
%
s
'
%
str
(
e
)
)
        
if
not
os
.
path
.
exists
(
dsymbundle
)
:
            
self
.
output_pid
(
sys
.
stderr
"
No
symbols
found
in
file
:
%
s
"
%
(
file
)
)
            
result
[
'
status
'
]
=
False
            
result
[
'
files
'
]
=
(
file
)
            
return
result
        
result
[
'
status
'
]
=
True
        
result
[
'
files
'
]
=
(
dsymbundle
file
)
        
elapsed
=
time
.
time
(
)
-
t_start
        
self
.
output_pid
(
sys
.
stderr
'
Worker
finished
processing
%
s
in
%
.
2fs
'
%
                        
(
file
elapsed
)
)
        
return
result
    
def
CopyDebug
(
self
file
debug_file
guid
code_file
code_id
)
:
        
"
"
"
ProcessFiles
has
already
produced
a
dSYM
bundle
so
we
should
just
        
copy
that
to
the
destination
directory
.
However
we
'
ll
package
it
        
into
a
.
tar
.
bz2
because
the
debug
symbols
are
pretty
huge
and
        
also
because
it
'
s
a
bundle
so
it
'
s
a
directory
.
|
file
|
here
is
the
        
dSYM
bundle
and
|
debug_file
|
is
the
original
filename
.
"
"
"
        
rel_path
=
os
.
path
.
join
(
debug_file
                                
guid
                                
os
.
path
.
basename
(
file
)
+
"
.
tar
.
bz2
"
)
        
full_path
=
os
.
path
.
abspath
(
os
.
path
.
join
(
self
.
symbol_path
                                                  
rel_path
)
)
        
success
=
subprocess
.
call
(
[
"
tar
"
"
cjf
"
full_path
os
.
path
.
basename
(
file
)
]
                                  
cwd
=
os
.
path
.
dirname
(
file
)
                                  
stdout
=
open
(
os
.
devnull
'
w
'
)
stderr
=
subprocess
.
STDOUT
)
        
if
success
=
=
0
and
os
.
path
.
exists
(
full_path
)
:
            
self
.
output
(
sys
.
stdout
rel_path
)
def
main
(
)
:
    
parser
=
OptionParser
(
usage
=
"
usage
:
%
prog
[
options
]
<
dump_syms
binary
>
<
symbol
store
path
>
<
debug
info
files
>
"
)
    
parser
.
add_option
(
"
-
c
"
"
-
-
copy
"
                      
action
=
"
store_true
"
dest
=
"
copy_debug
"
default
=
False
                      
help
=
"
Copy
debug
info
files
into
the
same
directory
structure
as
symbol
files
"
)
    
parser
.
add_option
(
"
-
a
"
"
-
-
archs
"
                      
action
=
"
store
"
dest
=
"
archs
"
                      
help
=
"
Run
dump_syms
-
a
<
arch
>
for
each
space
separated
cpu
architecture
in
ARCHS
(
only
on
OS
X
)
"
)
    
parser
.
add_option
(
"
-
s
"
"
-
-
srcdir
"
                      
action
=
"
append
"
dest
=
"
srcdir
"
default
=
[
]
                      
help
=
"
Use
SRCDIR
to
determine
relative
paths
to
source
files
"
)
    
parser
.
add_option
(
"
-
v
"
"
-
-
vcs
-
info
"
                      
action
=
"
store_true
"
dest
=
"
vcsinfo
"
                      
help
=
"
Try
to
retrieve
VCS
info
for
each
FILE
listed
in
the
output
"
)
    
parser
.
add_option
(
"
-
i
"
"
-
-
source
-
index
"
                      
action
=
"
store_true
"
dest
=
"
srcsrv
"
default
=
False
                      
help
=
"
Add
source
index
information
to
debug
files
making
them
suitable
for
use
in
a
source
server
.
"
)
    
parser
.
add_option
(
"
-
x
"
"
-
-
exclude
"
                      
action
=
"
append
"
dest
=
"
exclude
"
default
=
[
]
metavar
=
"
PATTERN
"
                      
help
=
"
Skip
processing
files
matching
PATTERN
.
"
)
    
parser
.
add_option
(
"
-
-
repo
-
manifest
"
                      
action
=
"
store
"
dest
=
"
repo_manifest
"
                      
help
=
"
"
"
Get
source
information
from
this
XML
manifest
produced
by
the
repo
manifest
-
r
command
.
"
"
"
)
    
parser
.
add_option
(
"
-
-
install
-
manifest
"
                      
action
=
"
append
"
dest
=
"
install_manifests
"
                      
default
=
[
]
                      
help
=
"
"
"
Use
this
install
manifest
to
map
filenames
back
to
canonical
locations
in
the
source
repository
.
Specify
<
install
manifest
filename
>
<
install
destination
>
as
a
comma
-
separated
pair
.
"
"
"
)
    
(
options
args
)
=
parser
.
parse_args
(
)
    
if
options
.
srcsrv
:
        
pdbstr
=
os
.
environ
.
get
(
"
PDBSTR_PATH
"
)
        
if
not
os
.
path
.
exists
(
pdbstr
)
:
            
print
>
>
sys
.
stderr
"
Invalid
path
to
pdbstr
.
exe
-
please
set
/
check
PDBSTR_PATH
.
\
n
"
            
sys
.
exit
(
1
)
    
if
len
(
args
)
<
3
:
        
parser
.
error
(
"
not
enough
arguments
"
)
        
exit
(
1
)
    
try
:
        
manifests
=
validate_install_manifests
(
options
.
install_manifests
)
    
except
(
IOError
ValueError
)
as
e
:
        
parser
.
error
(
str
(
e
)
)
        
exit
(
1
)
    
file_mapping
=
make_file_mapping
(
manifests
)
    
dumper
=
GetPlatformSpecificDumper
(
dump_syms
=
args
[
0
]
                                       
symbol_path
=
args
[
1
]
                                       
copy_debug
=
options
.
copy_debug
                                       
archs
=
options
.
archs
                                       
srcdirs
=
options
.
srcdir
                                       
vcsinfo
=
options
.
vcsinfo
                                       
srcsrv
=
options
.
srcsrv
                                       
exclude
=
options
.
exclude
                                       
repo_manifest
=
options
.
repo_manifest
                                       
file_mapping
=
file_mapping
)
    
dumper
.
Process
(
*
args
[
2
:
]
)
    
dumper
.
Finish
(
)
if
__name__
=
=
"
__main__
"
:
    
Dumper
.
GlobalInit
(
)
    
main
(
)
