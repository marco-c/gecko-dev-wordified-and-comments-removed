import
*
as
__WEBPACK_EXTERNAL_MODULE_chrome_global_content_ml_ort_webgpu_dev_mjs_a2210ba4__
from
"
chrome
:
/
/
global
/
content
/
ml
/
ort
.
webgpu
-
dev
.
mjs
"
;
var
__webpack_modules__
=
(
{
"
#
onnxruntime
-
webgpu
"
:
(
(
module
)
=
>
{
module
.
exports
=
__WEBPACK_EXTERNAL_MODULE_chrome_global_content_ml_ort_webgpu_dev_mjs_a2210ba4__
;
}
)
"
?
7a2c
"
:
(
(
)
=
>
{
}
)
"
?
a42a
"
:
(
(
)
=
>
{
}
)
"
?
2b25
"
:
(
(
)
=
>
{
}
)
"
?
569f
"
:
(
(
)
=
>
{
}
)
"
?
3f59
"
:
(
(
)
=
>
{
}
)
"
?
154a
"
:
(
(
)
=
>
{
}
)
"
.
/
node_modules
/
huggingface
/
jinja
/
dist
/
index
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
Environment
:
(
)
=
>
(
Environment
)
Interpreter
:
(
)
=
>
(
Interpreter
)
Template
:
(
)
=
>
(
Template
)
parse
:
(
)
=
>
(
parse
)
tokenize
:
(
)
=
>
(
tokenize
)
}
)
;
var
TOKEN_TYPES
=
Object
.
freeze
(
{
Text
:
"
Text
"
NumericLiteral
:
"
NumericLiteral
"
BooleanLiteral
:
"
BooleanLiteral
"
NullLiteral
:
"
NullLiteral
"
StringLiteral
:
"
StringLiteral
"
Identifier
:
"
Identifier
"
Equals
:
"
Equals
"
OpenParen
:
"
OpenParen
"
CloseParen
:
"
CloseParen
"
OpenStatement
:
"
OpenStatement
"
CloseStatement
:
"
CloseStatement
"
OpenExpression
:
"
OpenExpression
"
CloseExpression
:
"
CloseExpression
"
OpenSquareBracket
:
"
OpenSquareBracket
"
CloseSquareBracket
:
"
CloseSquareBracket
"
OpenCurlyBracket
:
"
OpenCurlyBracket
"
CloseCurlyBracket
:
"
CloseCurlyBracket
"
Comma
:
"
Comma
"
Dot
:
"
Dot
"
Colon
:
"
Colon
"
Pipe
:
"
Pipe
"
CallOperator
:
"
CallOperator
"
AdditiveBinaryOperator
:
"
AdditiveBinaryOperator
"
MultiplicativeBinaryOperator
:
"
MultiplicativeBinaryOperator
"
ComparisonBinaryOperator
:
"
ComparisonBinaryOperator
"
UnaryOperator
:
"
UnaryOperator
"
Set
:
"
Set
"
If
:
"
If
"
For
:
"
For
"
In
:
"
In
"
Is
:
"
Is
"
NotIn
:
"
NotIn
"
Else
:
"
Else
"
EndIf
:
"
EndIf
"
ElseIf
:
"
ElseIf
"
EndFor
:
"
EndFor
"
And
:
"
And
"
Or
:
"
Or
"
Not
:
"
UnaryOperator
"
Macro
:
"
Macro
"
EndMacro
:
"
EndMacro
"
}
)
;
var
KEYWORDS
=
Object
.
freeze
(
{
set
:
TOKEN_TYPES
.
Set
for
:
TOKEN_TYPES
.
For
in
:
TOKEN_TYPES
.
In
is
:
TOKEN_TYPES
.
Is
if
:
TOKEN_TYPES
.
If
else
:
TOKEN_TYPES
.
Else
endif
:
TOKEN_TYPES
.
EndIf
elif
:
TOKEN_TYPES
.
ElseIf
endfor
:
TOKEN_TYPES
.
EndFor
and
:
TOKEN_TYPES
.
And
or
:
TOKEN_TYPES
.
Or
not
:
TOKEN_TYPES
.
Not
"
not
in
"
:
TOKEN_TYPES
.
NotIn
macro
:
TOKEN_TYPES
.
Macro
endmacro
:
TOKEN_TYPES
.
EndMacro
true
:
TOKEN_TYPES
.
BooleanLiteral
false
:
TOKEN_TYPES
.
BooleanLiteral
none
:
TOKEN_TYPES
.
NullLiteral
True
:
TOKEN_TYPES
.
BooleanLiteral
False
:
TOKEN_TYPES
.
BooleanLiteral
None
:
TOKEN_TYPES
.
NullLiteral
}
)
;
var
Token
=
class
{
constructor
(
value
type
)
{
this
.
value
=
value
;
this
.
type
=
type
;
}
}
;
function
isWord
(
char
)
{
return
/
\
w
/
.
test
(
char
)
;
}
function
isInteger
(
char
)
{
return
/
[
0
-
9
]
/
.
test
(
char
)
;
}
var
ORDERED_MAPPING_TABLE
=
[
[
"
{
%
"
TOKEN_TYPES
.
OpenStatement
]
[
"
%
}
"
TOKEN_TYPES
.
CloseStatement
]
[
"
{
{
"
TOKEN_TYPES
.
OpenExpression
]
[
"
}
}
"
TOKEN_TYPES
.
CloseExpression
]
[
"
(
"
TOKEN_TYPES
.
OpenParen
]
[
"
)
"
TOKEN_TYPES
.
CloseParen
]
[
"
{
"
TOKEN_TYPES
.
OpenCurlyBracket
]
[
"
}
"
TOKEN_TYPES
.
CloseCurlyBracket
]
[
"
[
"
TOKEN_TYPES
.
OpenSquareBracket
]
[
"
]
"
TOKEN_TYPES
.
CloseSquareBracket
]
[
"
"
TOKEN_TYPES
.
Comma
]
[
"
.
"
TOKEN_TYPES
.
Dot
]
[
"
:
"
TOKEN_TYPES
.
Colon
]
[
"
|
"
TOKEN_TYPES
.
Pipe
]
[
"
<
=
"
TOKEN_TYPES
.
ComparisonBinaryOperator
]
[
"
>
=
"
TOKEN_TYPES
.
ComparisonBinaryOperator
]
[
"
=
=
"
TOKEN_TYPES
.
ComparisonBinaryOperator
]
[
"
!
=
"
TOKEN_TYPES
.
ComparisonBinaryOperator
]
[
"
<
"
TOKEN_TYPES
.
ComparisonBinaryOperator
]
[
"
>
"
TOKEN_TYPES
.
ComparisonBinaryOperator
]
[
"
+
"
TOKEN_TYPES
.
AdditiveBinaryOperator
]
[
"
-
"
TOKEN_TYPES
.
AdditiveBinaryOperator
]
[
"
*
"
TOKEN_TYPES
.
MultiplicativeBinaryOperator
]
[
"
/
"
TOKEN_TYPES
.
MultiplicativeBinaryOperator
]
[
"
%
"
TOKEN_TYPES
.
MultiplicativeBinaryOperator
]
[
"
=
"
TOKEN_TYPES
.
Equals
]
]
;
var
ESCAPE_CHARACTERS
=
new
Map
(
[
[
"
n
"
"
\
n
"
]
[
"
t
"
"
"
]
[
"
r
"
"
\
r
"
]
[
"
b
"
"
\
b
"
]
[
"
f
"
"
\
f
"
]
[
"
v
"
"
\
v
"
]
[
"
'
"
"
'
"
]
[
'
"
'
'
"
'
]
[
"
\
\
"
"
\
\
"
]
]
)
;
function
preprocess
(
template
options
=
{
}
)
{
if
(
template
.
endsWith
(
"
\
n
"
)
)
{
template
=
template
.
slice
(
0
-
1
)
;
}
template
=
template
.
replace
(
/
{
#
.
*
?
#
}
/
gs
"
{
#
#
}
"
)
;
if
(
options
.
lstrip_blocks
)
{
template
=
template
.
replace
(
/
^
[
\
t
]
*
(
{
[
#
%
]
)
/
gm
"
1
"
)
;
}
if
(
options
.
trim_blocks
)
{
template
=
template
.
replace
(
/
(
[
#
%
]
}
)
\
n
/
g
"
1
"
)
;
}
return
template
.
replace
(
/
{
#
#
}
/
g
"
"
)
.
replace
(
/
-
%
}
\
s
*
/
g
"
%
}
"
)
.
replace
(
/
\
s
*
{
%
-
/
g
"
{
%
"
)
.
replace
(
/
-
}
}
\
s
*
/
g
"
}
}
"
)
.
replace
(
/
\
s
*
{
{
-
/
g
"
{
{
"
)
;
}
function
tokenize
(
source
options
=
{
}
)
{
const
tokens
=
[
]
;
const
src
=
preprocess
(
source
options
)
;
let
cursorPosition
=
0
;
const
consumeWhile
=
(
predicate
)
=
>
{
let
str
=
"
"
;
while
(
predicate
(
src
[
cursorPosition
]
)
)
{
if
(
src
[
cursorPosition
]
=
=
=
"
\
\
"
)
{
+
+
cursorPosition
;
if
(
cursorPosition
>
=
src
.
length
)
throw
new
SyntaxError
(
"
Unexpected
end
of
input
"
)
;
const
escaped
=
src
[
cursorPosition
+
+
]
;
const
unescaped
=
ESCAPE_CHARACTERS
.
get
(
escaped
)
;
if
(
unescaped
=
=
=
void
0
)
{
throw
new
SyntaxError
(
Unexpected
escaped
character
:
{
escaped
}
)
;
}
str
+
=
unescaped
;
continue
;
}
str
+
=
src
[
cursorPosition
+
+
]
;
if
(
cursorPosition
>
=
src
.
length
)
throw
new
SyntaxError
(
"
Unexpected
end
of
input
"
)
;
}
return
str
;
}
;
main
:
while
(
cursorPosition
<
src
.
length
)
{
const
lastTokenType
=
tokens
.
at
(
-
1
)
?
.
type
;
if
(
lastTokenType
=
=
=
void
0
|
|
lastTokenType
=
=
=
TOKEN_TYPES
.
CloseStatement
|
|
lastTokenType
=
=
=
TOKEN_TYPES
.
CloseExpression
)
{
let
text
=
"
"
;
while
(
cursorPosition
<
src
.
length
&
&
!
(
src
[
cursorPosition
]
=
=
=
"
{
"
&
&
(
src
[
cursorPosition
+
1
]
=
=
=
"
%
"
|
|
src
[
cursorPosition
+
1
]
=
=
=
"
{
"
)
)
)
{
text
+
=
src
[
cursorPosition
+
+
]
;
}
if
(
text
.
length
>
0
)
{
tokens
.
push
(
new
Token
(
text
TOKEN_TYPES
.
Text
)
)
;
continue
;
}
}
consumeWhile
(
(
char2
)
=
>
/
\
s
/
.
test
(
char2
)
)
;
const
char
=
src
[
cursorPosition
]
;
if
(
char
=
=
=
"
-
"
|
|
char
=
=
=
"
+
"
)
{
const
lastTokenType2
=
tokens
.
at
(
-
1
)
?
.
type
;
if
(
lastTokenType2
=
=
=
TOKEN_TYPES
.
Text
|
|
lastTokenType2
=
=
=
void
0
)
{
throw
new
SyntaxError
(
Unexpected
character
:
{
char
}
)
;
}
switch
(
lastTokenType2
)
{
case
TOKEN_TYPES
.
Identifier
:
case
TOKEN_TYPES
.
NumericLiteral
:
case
TOKEN_TYPES
.
BooleanLiteral
:
case
TOKEN_TYPES
.
NullLiteral
:
case
TOKEN_TYPES
.
StringLiteral
:
case
TOKEN_TYPES
.
CloseParen
:
case
TOKEN_TYPES
.
CloseSquareBracket
:
break
;
default
:
{
+
+
cursorPosition
;
const
num
=
consumeWhile
(
isInteger
)
;
tokens
.
push
(
new
Token
(
{
char
}
{
num
}
num
.
length
>
0
?
TOKEN_TYPES
.
NumericLiteral
:
TOKEN_TYPES
.
UnaryOperator
)
)
;
continue
;
}
}
}
for
(
const
[
char2
token
]
of
ORDERED_MAPPING_TABLE
)
{
const
slice2
=
src
.
slice
(
cursorPosition
cursorPosition
+
char2
.
length
)
;
if
(
slice2
=
=
=
char2
)
{
tokens
.
push
(
new
Token
(
char2
token
)
)
;
cursorPosition
+
=
char2
.
length
;
continue
main
;
}
}
if
(
char
=
=
=
"
'
"
|
|
char
=
=
=
'
"
'
)
{
+
+
cursorPosition
;
const
str
=
consumeWhile
(
(
c
)
=
>
c
!
=
=
char
)
;
tokens
.
push
(
new
Token
(
str
TOKEN_TYPES
.
StringLiteral
)
)
;
+
+
cursorPosition
;
continue
;
}
if
(
isInteger
(
char
)
)
{
const
num
=
consumeWhile
(
isInteger
)
;
tokens
.
push
(
new
Token
(
num
TOKEN_TYPES
.
NumericLiteral
)
)
;
continue
;
}
if
(
isWord
(
char
)
)
{
const
word
=
consumeWhile
(
isWord
)
;
const
type
=
Object
.
hasOwn
(
KEYWORDS
word
)
?
KEYWORDS
[
word
]
:
TOKEN_TYPES
.
Identifier
;
if
(
type
=
=
=
TOKEN_TYPES
.
In
&
&
tokens
.
at
(
-
1
)
?
.
type
=
=
=
TOKEN_TYPES
.
Not
)
{
tokens
.
pop
(
)
;
tokens
.
push
(
new
Token
(
"
not
in
"
TOKEN_TYPES
.
NotIn
)
)
;
}
else
{
tokens
.
push
(
new
Token
(
word
type
)
)
;
}
continue
;
}
throw
new
SyntaxError
(
Unexpected
character
:
{
char
}
)
;
}
return
tokens
;
}
var
Statement
=
class
{
type
=
"
Statement
"
;
}
;
var
Program
=
class
extends
Statement
{
constructor
(
body
)
{
super
(
)
;
this
.
body
=
body
;
}
type
=
"
Program
"
;
}
;
var
If
=
class
extends
Statement
{
constructor
(
test
body
alternate
)
{
super
(
)
;
this
.
test
=
test
;
this
.
body
=
body
;
this
.
alternate
=
alternate
;
}
type
=
"
If
"
;
}
;
var
For
=
class
extends
Statement
{
constructor
(
loopvar
iterable
body
defaultBlock
)
{
super
(
)
;
this
.
loopvar
=
loopvar
;
this
.
iterable
=
iterable
;
this
.
body
=
body
;
this
.
defaultBlock
=
defaultBlock
;
}
type
=
"
For
"
;
}
;
var
SetStatement
=
class
extends
Statement
{
constructor
(
assignee
value
)
{
super
(
)
;
this
.
assignee
=
assignee
;
this
.
value
=
value
;
}
type
=
"
Set
"
;
}
;
var
Macro
=
class
extends
Statement
{
constructor
(
name
args
body
)
{
super
(
)
;
this
.
name
=
name
;
this
.
args
=
args
;
this
.
body
=
body
;
}
type
=
"
Macro
"
;
}
;
var
Expression
=
class
extends
Statement
{
type
=
"
Expression
"
;
}
;
var
MemberExpression
=
class
extends
Expression
{
constructor
(
object
property
computed
)
{
super
(
)
;
this
.
object
=
object
;
this
.
property
=
property
;
this
.
computed
=
computed
;
}
type
=
"
MemberExpression
"
;
}
;
var
CallExpression
=
class
extends
Expression
{
constructor
(
callee
args
)
{
super
(
)
;
this
.
callee
=
callee
;
this
.
args
=
args
;
}
type
=
"
CallExpression
"
;
}
;
var
Identifier
=
class
extends
Expression
{
constructor
(
value
)
{
super
(
)
;
this
.
value
=
value
;
}
type
=
"
Identifier
"
;
}
;
var
Literal
=
class
extends
Expression
{
constructor
(
value
)
{
super
(
)
;
this
.
value
=
value
;
}
type
=
"
Literal
"
;
}
;
var
NumericLiteral
=
class
extends
Literal
{
type
=
"
NumericLiteral
"
;
}
;
var
StringLiteral
=
class
extends
Literal
{
type
=
"
StringLiteral
"
;
}
;
var
BooleanLiteral
=
class
extends
Literal
{
type
=
"
BooleanLiteral
"
;
}
;
var
NullLiteral
=
class
extends
Literal
{
type
=
"
NullLiteral
"
;
}
;
var
ArrayLiteral
=
class
extends
Literal
{
type
=
"
ArrayLiteral
"
;
}
;
var
TupleLiteral
=
class
extends
Literal
{
type
=
"
TupleLiteral
"
;
}
;
var
ObjectLiteral
=
class
extends
Literal
{
type
=
"
ObjectLiteral
"
;
}
;
var
BinaryExpression
=
class
extends
Expression
{
constructor
(
operator
left
right
)
{
super
(
)
;
this
.
operator
=
operator
;
this
.
left
=
left
;
this
.
right
=
right
;
}
type
=
"
BinaryExpression
"
;
}
;
var
FilterExpression
=
class
extends
Expression
{
constructor
(
operand
filter
)
{
super
(
)
;
this
.
operand
=
operand
;
this
.
filter
=
filter
;
}
type
=
"
FilterExpression
"
;
}
;
var
SelectExpression
=
class
extends
Expression
{
constructor
(
iterable
test
)
{
super
(
)
;
this
.
iterable
=
iterable
;
this
.
test
=
test
;
}
type
=
"
SelectExpression
"
;
}
;
var
TestExpression
=
class
extends
Expression
{
constructor
(
operand
negate
test
)
{
super
(
)
;
this
.
operand
=
operand
;
this
.
negate
=
negate
;
this
.
test
=
test
;
}
type
=
"
TestExpression
"
;
}
;
var
UnaryExpression
=
class
extends
Expression
{
constructor
(
operator
argument
)
{
super
(
)
;
this
.
operator
=
operator
;
this
.
argument
=
argument
;
}
type
=
"
UnaryExpression
"
;
}
;
var
SliceExpression
=
class
extends
Expression
{
constructor
(
start
=
void
0
stop
=
void
0
step
=
void
0
)
{
super
(
)
;
this
.
start
=
start
;
this
.
stop
=
stop
;
this
.
step
=
step
;
}
type
=
"
SliceExpression
"
;
}
;
var
KeywordArgumentExpression
=
class
extends
Expression
{
constructor
(
key
value
)
{
super
(
)
;
this
.
key
=
key
;
this
.
value
=
value
;
}
type
=
"
KeywordArgumentExpression
"
;
}
;
function
parse
(
tokens
)
{
const
program
=
new
Program
(
[
]
)
;
let
current
=
0
;
function
expect
(
type
error
)
{
const
prev
=
tokens
[
current
+
+
]
;
if
(
!
prev
|
|
prev
.
type
!
=
=
type
)
{
throw
new
Error
(
Parser
Error
:
{
error
}
.
{
prev
.
type
}
!
=
=
{
type
}
.
)
;
}
return
prev
;
}
function
parseAny
(
)
{
switch
(
tokens
[
current
]
.
type
)
{
case
TOKEN_TYPES
.
Text
:
return
parseText
(
)
;
case
TOKEN_TYPES
.
OpenStatement
:
return
parseJinjaStatement
(
)
;
case
TOKEN_TYPES
.
OpenExpression
:
return
parseJinjaExpression
(
)
;
default
:
throw
new
SyntaxError
(
Unexpected
token
type
:
{
tokens
[
current
]
.
type
}
)
;
}
}
function
not
(
.
.
.
types
)
{
return
current
+
types
.
length
<
=
tokens
.
length
&
&
types
.
some
(
(
type
i
)
=
>
type
!
=
=
tokens
[
current
+
i
]
.
type
)
;
}
function
is
(
.
.
.
types
)
{
return
current
+
types
.
length
<
=
tokens
.
length
&
&
types
.
every
(
(
type
i
)
=
>
type
=
=
=
tokens
[
current
+
i
]
.
type
)
;
}
function
parseText
(
)
{
return
new
StringLiteral
(
expect
(
TOKEN_TYPES
.
Text
"
Expected
text
token
"
)
.
value
)
;
}
function
parseJinjaStatement
(
)
{
expect
(
TOKEN_TYPES
.
OpenStatement
"
Expected
opening
statement
token
"
)
;
let
result
;
switch
(
tokens
[
current
]
.
type
)
{
case
TOKEN_TYPES
.
Set
:
+
+
current
;
result
=
parseSetStatement
(
)
;
expect
(
TOKEN_TYPES
.
CloseStatement
"
Expected
closing
statement
token
"
)
;
break
;
case
TOKEN_TYPES
.
If
:
+
+
current
;
result
=
parseIfStatement
(
)
;
expect
(
TOKEN_TYPES
.
OpenStatement
"
Expected
{
%
token
"
)
;
expect
(
TOKEN_TYPES
.
EndIf
"
Expected
endif
token
"
)
;
expect
(
TOKEN_TYPES
.
CloseStatement
"
Expected
%
}
token
"
)
;
break
;
case
TOKEN_TYPES
.
Macro
:
+
+
current
;
result
=
parseMacroStatement
(
)
;
expect
(
TOKEN_TYPES
.
OpenStatement
"
Expected
{
%
token
"
)
;
expect
(
TOKEN_TYPES
.
EndMacro
"
Expected
endmacro
token
"
)
;
expect
(
TOKEN_TYPES
.
CloseStatement
"
Expected
%
}
token
"
)
;
break
;
case
TOKEN_TYPES
.
For
:
+
+
current
;
result
=
parseForStatement
(
)
;
expect
(
TOKEN_TYPES
.
OpenStatement
"
Expected
{
%
token
"
)
;
expect
(
TOKEN_TYPES
.
EndFor
"
Expected
endfor
token
"
)
;
expect
(
TOKEN_TYPES
.
CloseStatement
"
Expected
%
}
token
"
)
;
break
;
default
:
throw
new
SyntaxError
(
Unknown
statement
type
:
{
tokens
[
current
]
.
type
}
)
;
}
return
result
;
}
function
parseJinjaExpression
(
)
{
expect
(
TOKEN_TYPES
.
OpenExpression
"
Expected
opening
expression
token
"
)
;
const
result
=
parseExpression
(
)
;
expect
(
TOKEN_TYPES
.
CloseExpression
"
Expected
closing
expression
token
"
)
;
return
result
;
}
function
parseSetStatement
(
)
{
const
left
=
parseExpression
(
)
;
if
(
is
(
TOKEN_TYPES
.
Equals
)
)
{
+
+
current
;
const
value
=
parseSetStatement
(
)
;
return
new
SetStatement
(
left
value
)
;
}
return
left
;
}
function
parseIfStatement
(
)
{
const
test
=
parseExpression
(
)
;
expect
(
TOKEN_TYPES
.
CloseStatement
"
Expected
closing
statement
token
"
)
;
const
body
=
[
]
;
const
alternate
=
[
]
;
while
(
!
(
tokens
[
current
]
?
.
type
=
=
=
TOKEN_TYPES
.
OpenStatement
&
&
(
tokens
[
current
+
1
]
?
.
type
=
=
=
TOKEN_TYPES
.
ElseIf
|
|
tokens
[
current
+
1
]
?
.
type
=
=
=
TOKEN_TYPES
.
Else
|
|
tokens
[
current
+
1
]
?
.
type
=
=
=
TOKEN_TYPES
.
EndIf
)
)
)
{
body
.
push
(
parseAny
(
)
)
;
}
if
(
tokens
[
current
]
?
.
type
=
=
=
TOKEN_TYPES
.
OpenStatement
&
&
tokens
[
current
+
1
]
?
.
type
!
=
=
TOKEN_TYPES
.
EndIf
)
{
+
+
current
;
if
(
is
(
TOKEN_TYPES
.
ElseIf
)
)
{
expect
(
TOKEN_TYPES
.
ElseIf
"
Expected
elseif
token
"
)
;
alternate
.
push
(
parseIfStatement
(
)
)
;
}
else
{
expect
(
TOKEN_TYPES
.
Else
"
Expected
else
token
"
)
;
expect
(
TOKEN_TYPES
.
CloseStatement
"
Expected
closing
statement
token
"
)
;
while
(
!
(
tokens
[
current
]
?
.
type
=
=
=
TOKEN_TYPES
.
OpenStatement
&
&
tokens
[
current
+
1
]
?
.
type
=
=
=
TOKEN_TYPES
.
EndIf
)
)
{
alternate
.
push
(
parseAny
(
)
)
;
}
}
}
return
new
If
(
test
body
alternate
)
;
}
function
parseMacroStatement
(
)
{
const
name
=
parsePrimaryExpression
(
)
;
if
(
name
.
type
!
=
=
"
Identifier
"
)
{
throw
new
SyntaxError
(
Expected
identifier
following
macro
statement
)
;
}
const
args
=
parseArgs
(
)
;
expect
(
TOKEN_TYPES
.
CloseStatement
"
Expected
closing
statement
token
"
)
;
const
body
=
[
]
;
while
(
not
(
TOKEN_TYPES
.
OpenStatement
TOKEN_TYPES
.
EndMacro
)
)
{
body
.
push
(
parseAny
(
)
)
;
}
return
new
Macro
(
name
args
body
)
;
}
function
parseExpressionSequence
(
primary
=
false
)
{
const
fn
=
primary
?
parsePrimaryExpression
:
parseExpression
;
const
expressions
=
[
fn
(
)
]
;
const
isTuple
=
is
(
TOKEN_TYPES
.
Comma
)
;
while
(
isTuple
)
{
+
+
current
;
expressions
.
push
(
fn
(
)
)
;
if
(
!
is
(
TOKEN_TYPES
.
Comma
)
)
{
break
;
}
}
return
isTuple
?
new
TupleLiteral
(
expressions
)
:
expressions
[
0
]
;
}
function
parseForStatement
(
)
{
const
loopVariable
=
parseExpressionSequence
(
true
)
;
if
(
!
(
loopVariable
instanceof
Identifier
|
|
loopVariable
instanceof
TupleLiteral
)
)
{
throw
new
SyntaxError
(
Expected
identifier
/
tuple
for
the
loop
variable
got
{
loopVariable
.
type
}
instead
)
;
}
expect
(
TOKEN_TYPES
.
In
"
Expected
in
keyword
following
loop
variable
"
)
;
const
iterable
=
parseExpression
(
)
;
expect
(
TOKEN_TYPES
.
CloseStatement
"
Expected
closing
statement
token
"
)
;
const
body
=
[
]
;
while
(
not
(
TOKEN_TYPES
.
OpenStatement
TOKEN_TYPES
.
EndFor
)
&
&
not
(
TOKEN_TYPES
.
OpenStatement
TOKEN_TYPES
.
Else
)
)
{
body
.
push
(
parseAny
(
)
)
;
}
const
alternative
=
[
]
;
if
(
is
(
TOKEN_TYPES
.
OpenStatement
TOKEN_TYPES
.
Else
)
)
{
+
+
current
;
+
+
current
;
expect
(
TOKEN_TYPES
.
CloseStatement
"
Expected
closing
statement
token
"
)
;
while
(
not
(
TOKEN_TYPES
.
OpenStatement
TOKEN_TYPES
.
EndFor
)
)
{
alternative
.
push
(
parseAny
(
)
)
;
}
}
return
new
For
(
loopVariable
iterable
body
alternative
)
;
}
function
parseExpression
(
)
{
return
parseIfExpression
(
)
;
}
function
parseIfExpression
(
)
{
const
a
=
parseLogicalOrExpression
(
)
;
if
(
is
(
TOKEN_TYPES
.
If
)
)
{
+
+
current
;
const
predicate
=
parseLogicalOrExpression
(
)
;
if
(
is
(
TOKEN_TYPES
.
Else
)
)
{
+
+
current
;
const
b
=
parseLogicalOrExpression
(
)
;
return
new
If
(
predicate
[
a
]
[
b
]
)
;
}
else
{
return
new
SelectExpression
(
a
predicate
)
;
}
}
return
a
;
}
function
parseLogicalOrExpression
(
)
{
let
left
=
parseLogicalAndExpression
(
)
;
while
(
is
(
TOKEN_TYPES
.
Or
)
)
{
const
operator
=
tokens
[
current
]
;
+
+
current
;
const
right
=
parseLogicalAndExpression
(
)
;
left
=
new
BinaryExpression
(
operator
left
right
)
;
}
return
left
;
}
function
parseLogicalAndExpression
(
)
{
let
left
=
parseLogicalNegationExpression
(
)
;
while
(
is
(
TOKEN_TYPES
.
And
)
)
{
const
operator
=
tokens
[
current
]
;
+
+
current
;
const
right
=
parseLogicalNegationExpression
(
)
;
left
=
new
BinaryExpression
(
operator
left
right
)
;
}
return
left
;
}
function
parseLogicalNegationExpression
(
)
{
let
right
;
while
(
is
(
TOKEN_TYPES
.
Not
)
)
{
const
operator
=
tokens
[
current
]
;
+
+
current
;
const
arg
=
parseLogicalNegationExpression
(
)
;
right
=
new
UnaryExpression
(
operator
arg
)
;
}
return
right
?
?
parseComparisonExpression
(
)
;
}
function
parseComparisonExpression
(
)
{
let
left
=
parseAdditiveExpression
(
)
;
while
(
is
(
TOKEN_TYPES
.
ComparisonBinaryOperator
)
|
|
is
(
TOKEN_TYPES
.
In
)
|
|
is
(
TOKEN_TYPES
.
NotIn
)
)
{
const
operator
=
tokens
[
current
]
;
+
+
current
;
const
right
=
parseAdditiveExpression
(
)
;
left
=
new
BinaryExpression
(
operator
left
right
)
;
}
return
left
;
}
function
parseAdditiveExpression
(
)
{
let
left
=
parseMultiplicativeExpression
(
)
;
while
(
is
(
TOKEN_TYPES
.
AdditiveBinaryOperator
)
)
{
const
operator
=
tokens
[
current
]
;
+
+
current
;
const
right
=
parseMultiplicativeExpression
(
)
;
left
=
new
BinaryExpression
(
operator
left
right
)
;
}
return
left
;
}
function
parseCallMemberExpression
(
)
{
const
member
=
parseMemberExpression
(
)
;
if
(
is
(
TOKEN_TYPES
.
OpenParen
)
)
{
return
parseCallExpression
(
member
)
;
}
return
member
;
}
function
parseCallExpression
(
callee
)
{
let
callExpression
=
new
CallExpression
(
callee
parseArgs
(
)
)
;
if
(
is
(
TOKEN_TYPES
.
OpenParen
)
)
{
callExpression
=
parseCallExpression
(
callExpression
)
;
}
return
callExpression
;
}
function
parseArgs
(
)
{
expect
(
TOKEN_TYPES
.
OpenParen
"
Expected
opening
parenthesis
for
arguments
list
"
)
;
const
args
=
parseArgumentsList
(
)
;
expect
(
TOKEN_TYPES
.
CloseParen
"
Expected
closing
parenthesis
for
arguments
list
"
)
;
return
args
;
}
function
parseArgumentsList
(
)
{
const
args
=
[
]
;
while
(
!
is
(
TOKEN_TYPES
.
CloseParen
)
)
{
let
argument
=
parseExpression
(
)
;
if
(
is
(
TOKEN_TYPES
.
Equals
)
)
{
+
+
current
;
if
(
!
(
argument
instanceof
Identifier
)
)
{
throw
new
SyntaxError
(
Expected
identifier
for
keyword
argument
)
;
}
const
value
=
parseExpression
(
)
;
argument
=
new
KeywordArgumentExpression
(
argument
value
)
;
}
args
.
push
(
argument
)
;
if
(
is
(
TOKEN_TYPES
.
Comma
)
)
{
+
+
current
;
}
}
return
args
;
}
function
parseMemberExpressionArgumentsList
(
)
{
const
slices
=
[
]
;
let
isSlice
=
false
;
while
(
!
is
(
TOKEN_TYPES
.
CloseSquareBracket
)
)
{
if
(
is
(
TOKEN_TYPES
.
Colon
)
)
{
slices
.
push
(
void
0
)
;
+
+
current
;
isSlice
=
true
;
}
else
{
slices
.
push
(
parseExpression
(
)
)
;
if
(
is
(
TOKEN_TYPES
.
Colon
)
)
{
+
+
current
;
isSlice
=
true
;
}
}
}
if
(
slices
.
length
=
=
=
0
)
{
throw
new
SyntaxError
(
Expected
at
least
one
argument
for
member
/
slice
expression
)
;
}
if
(
isSlice
)
{
if
(
slices
.
length
>
3
)
{
throw
new
SyntaxError
(
Expected
0
-
3
arguments
for
slice
expression
)
;
}
return
new
SliceExpression
(
.
.
.
slices
)
;
}
return
slices
[
0
]
;
}
function
parseMemberExpression
(
)
{
let
object
=
parsePrimaryExpression
(
)
;
while
(
is
(
TOKEN_TYPES
.
Dot
)
|
|
is
(
TOKEN_TYPES
.
OpenSquareBracket
)
)
{
const
operator
=
tokens
[
current
]
;
+
+
current
;
let
property
;
const
computed
=
operator
.
type
!
=
=
TOKEN_TYPES
.
Dot
;
if
(
computed
)
{
property
=
parseMemberExpressionArgumentsList
(
)
;
expect
(
TOKEN_TYPES
.
CloseSquareBracket
"
Expected
closing
square
bracket
"
)
;
}
else
{
property
=
parsePrimaryExpression
(
)
;
if
(
property
.
type
!
=
=
"
Identifier
"
)
{
throw
new
SyntaxError
(
Expected
identifier
following
dot
operator
)
;
}
}
object
=
new
MemberExpression
(
object
property
computed
)
;
}
return
object
;
}
function
parseMultiplicativeExpression
(
)
{
let
left
=
parseTestExpression
(
)
;
while
(
is
(
TOKEN_TYPES
.
MultiplicativeBinaryOperator
)
)
{
const
operator
=
tokens
[
current
]
;
+
+
current
;
const
right
=
parseTestExpression
(
)
;
left
=
new
BinaryExpression
(
operator
left
right
)
;
}
return
left
;
}
function
parseTestExpression
(
)
{
let
operand
=
parseFilterExpression
(
)
;
while
(
is
(
TOKEN_TYPES
.
Is
)
)
{
+
+
current
;
const
negate
=
is
(
TOKEN_TYPES
.
Not
)
;
if
(
negate
)
{
+
+
current
;
}
let
filter
=
parsePrimaryExpression
(
)
;
if
(
filter
instanceof
BooleanLiteral
)
{
filter
=
new
Identifier
(
filter
.
value
.
toString
(
)
)
;
}
else
if
(
filter
instanceof
NullLiteral
)
{
filter
=
new
Identifier
(
"
none
"
)
;
}
if
(
!
(
filter
instanceof
Identifier
)
)
{
throw
new
SyntaxError
(
Expected
identifier
for
the
test
)
;
}
operand
=
new
TestExpression
(
operand
negate
filter
)
;
}
return
operand
;
}
function
parseFilterExpression
(
)
{
let
operand
=
parseCallMemberExpression
(
)
;
while
(
is
(
TOKEN_TYPES
.
Pipe
)
)
{
+
+
current
;
let
filter
=
parsePrimaryExpression
(
)
;
if
(
!
(
filter
instanceof
Identifier
)
)
{
throw
new
SyntaxError
(
Expected
identifier
for
the
filter
)
;
}
if
(
is
(
TOKEN_TYPES
.
OpenParen
)
)
{
filter
=
parseCallExpression
(
filter
)
;
}
operand
=
new
FilterExpression
(
operand
filter
)
;
}
return
operand
;
}
function
parsePrimaryExpression
(
)
{
const
token
=
tokens
[
current
]
;
switch
(
token
.
type
)
{
case
TOKEN_TYPES
.
NumericLiteral
:
+
+
current
;
return
new
NumericLiteral
(
Number
(
token
.
value
)
)
;
case
TOKEN_TYPES
.
StringLiteral
:
+
+
current
;
return
new
StringLiteral
(
token
.
value
)
;
case
TOKEN_TYPES
.
BooleanLiteral
:
+
+
current
;
return
new
BooleanLiteral
(
token
.
value
.
toLowerCase
(
)
=
=
=
"
true
"
)
;
case
TOKEN_TYPES
.
NullLiteral
:
+
+
current
;
return
new
NullLiteral
(
null
)
;
case
TOKEN_TYPES
.
Identifier
:
+
+
current
;
return
new
Identifier
(
token
.
value
)
;
case
TOKEN_TYPES
.
OpenParen
:
{
+
+
current
;
const
expression
=
parseExpressionSequence
(
)
;
if
(
tokens
[
current
]
.
type
!
=
=
TOKEN_TYPES
.
CloseParen
)
{
throw
new
SyntaxError
(
Expected
closing
parenthesis
got
{
tokens
[
current
]
.
type
}
instead
)
;
}
+
+
current
;
return
expression
;
}
case
TOKEN_TYPES
.
OpenSquareBracket
:
{
+
+
current
;
const
values
=
[
]
;
while
(
!
is
(
TOKEN_TYPES
.
CloseSquareBracket
)
)
{
values
.
push
(
parseExpression
(
)
)
;
if
(
is
(
TOKEN_TYPES
.
Comma
)
)
{
+
+
current
;
}
}
+
+
current
;
return
new
ArrayLiteral
(
values
)
;
}
case
TOKEN_TYPES
.
OpenCurlyBracket
:
{
+
+
current
;
const
values
=
new
Map
(
)
;
while
(
!
is
(
TOKEN_TYPES
.
CloseCurlyBracket
)
)
{
const
key
=
parseExpression
(
)
;
expect
(
TOKEN_TYPES
.
Colon
"
Expected
colon
between
key
and
value
in
object
literal
"
)
;
const
value
=
parseExpression
(
)
;
values
.
set
(
key
value
)
;
if
(
is
(
TOKEN_TYPES
.
Comma
)
)
{
+
+
current
;
}
}
+
+
current
;
return
new
ObjectLiteral
(
values
)
;
}
default
:
throw
new
SyntaxError
(
Unexpected
token
:
{
token
.
type
}
)
;
}
}
while
(
current
<
tokens
.
length
)
{
program
.
body
.
push
(
parseAny
(
)
)
;
}
return
program
;
}
function
range
(
start
stop
step
=
1
)
{
if
(
stop
=
=
=
void
0
)
{
stop
=
start
;
start
=
0
;
}
const
result
=
[
]
;
for
(
let
i
=
start
;
i
<
stop
;
i
+
=
step
)
{
result
.
push
(
i
)
;
}
return
result
;
}
function
slice
(
array
start
stop
step
=
1
)
{
const
direction
=
Math
.
sign
(
step
)
;
if
(
direction
>
=
0
)
{
start
=
(
start
?
?
=
0
)
<
0
?
Math
.
max
(
array
.
length
+
start
0
)
:
Math
.
min
(
start
array
.
length
)
;
stop
=
(
stop
?
?
=
array
.
length
)
<
0
?
Math
.
max
(
array
.
length
+
stop
0
)
:
Math
.
min
(
stop
array
.
length
)
;
}
else
{
start
=
(
start
?
?
=
array
.
length
-
1
)
<
0
?
Math
.
max
(
array
.
length
+
start
-
1
)
:
Math
.
min
(
start
array
.
length
-
1
)
;
stop
=
(
stop
?
?
=
-
1
)
<
-
1
?
Math
.
max
(
array
.
length
+
stop
-
1
)
:
Math
.
min
(
stop
array
.
length
-
1
)
;
}
const
result
=
[
]
;
for
(
let
i
=
start
;
direction
*
i
<
direction
*
stop
;
i
+
=
step
)
{
result
.
push
(
array
[
i
]
)
;
}
return
result
;
}
function
titleCase
(
value
)
{
return
value
.
replace
(
/
\
b
\
w
/
g
(
c
)
=
>
c
.
toUpperCase
(
)
)
;
}
var
RuntimeValue
=
class
{
type
=
"
RuntimeValue
"
;
value
;
builtins
=
new
Map
(
)
;
constructor
(
value
=
void
0
)
{
this
.
value
=
value
;
}
__bool__
(
)
{
return
new
BooleanValue
(
!
!
this
.
value
)
;
}
}
;
var
NumericValue
=
class
extends
RuntimeValue
{
type
=
"
NumericValue
"
;
}
;
var
StringValue
=
class
extends
RuntimeValue
{
type
=
"
StringValue
"
;
builtins
=
new
Map
(
[
[
"
upper
"
new
FunctionValue
(
(
)
=
>
{
return
new
StringValue
(
this
.
value
.
toUpperCase
(
)
)
;
}
)
]
[
"
lower
"
new
FunctionValue
(
(
)
=
>
{
return
new
StringValue
(
this
.
value
.
toLowerCase
(
)
)
;
}
)
]
[
"
strip
"
new
FunctionValue
(
(
)
=
>
{
return
new
StringValue
(
this
.
value
.
trim
(
)
)
;
}
)
]
[
"
title
"
new
FunctionValue
(
(
)
=
>
{
return
new
StringValue
(
titleCase
(
this
.
value
)
)
;
}
)
]
[
"
length
"
new
NumericValue
(
this
.
value
.
length
)
]
[
"
rstrip
"
new
FunctionValue
(
(
)
=
>
{
return
new
StringValue
(
this
.
value
.
trimEnd
(
)
)
;
}
)
]
[
"
lstrip
"
new
FunctionValue
(
(
)
=
>
{
return
new
StringValue
(
this
.
value
.
trimStart
(
)
)
;
}
)
]
]
)
;
}
;
var
BooleanValue
=
class
extends
RuntimeValue
{
type
=
"
BooleanValue
"
;
}
;
var
ObjectValue
=
class
extends
RuntimeValue
{
type
=
"
ObjectValue
"
;
__bool__
(
)
{
return
new
BooleanValue
(
this
.
value
.
size
>
0
)
;
}
builtins
=
new
Map
(
[
[
"
get
"
new
FunctionValue
(
(
[
key
defaultValue
]
)
=
>
{
if
(
!
(
key
instanceof
StringValue
)
)
{
throw
new
Error
(
Object
key
must
be
a
string
:
got
{
key
.
type
}
)
;
}
return
this
.
value
.
get
(
key
.
value
)
?
?
defaultValue
?
?
new
NullValue
(
)
;
}
)
]
[
"
items
"
new
FunctionValue
(
(
)
=
>
{
return
new
ArrayValue
(
Array
.
from
(
this
.
value
.
entries
(
)
)
.
map
(
(
[
key
value
]
)
=
>
new
ArrayValue
(
[
new
StringValue
(
key
)
value
]
)
)
)
;
}
)
]
]
)
;
}
;
var
KeywordArgumentsValue
=
class
extends
ObjectValue
{
type
=
"
KeywordArgumentsValue
"
;
}
;
var
ArrayValue
=
class
extends
RuntimeValue
{
type
=
"
ArrayValue
"
;
builtins
=
new
Map
(
[
[
"
length
"
new
NumericValue
(
this
.
value
.
length
)
]
]
)
;
__bool__
(
)
{
return
new
BooleanValue
(
this
.
value
.
length
>
0
)
;
}
}
;
var
TupleValue
=
class
extends
ArrayValue
{
type
=
"
TupleValue
"
;
}
;
var
FunctionValue
=
class
extends
RuntimeValue
{
type
=
"
FunctionValue
"
;
}
;
var
NullValue
=
class
extends
RuntimeValue
{
type
=
"
NullValue
"
;
}
;
var
UndefinedValue
=
class
extends
RuntimeValue
{
type
=
"
UndefinedValue
"
;
}
;
var
Environment
=
class
{
constructor
(
parent
)
{
this
.
parent
=
parent
;
}
variables
=
new
Map
(
[
[
"
namespace
"
new
FunctionValue
(
(
args
)
=
>
{
if
(
args
.
length
=
=
=
0
)
{
return
new
ObjectValue
(
new
Map
(
)
)
;
}
if
(
args
.
length
!
=
=
1
|
|
!
(
args
[
0
]
instanceof
ObjectValue
)
)
{
throw
new
Error
(
"
namespace
expects
either
zero
arguments
or
a
single
object
argument
"
)
;
}
return
args
[
0
]
;
}
)
]
]
)
;
tests
=
new
Map
(
[
[
"
boolean
"
(
operand
)
=
>
operand
.
type
=
=
=
"
BooleanValue
"
]
[
"
callable
"
(
operand
)
=
>
operand
instanceof
FunctionValue
]
[
"
odd
"
(
operand
)
=
>
{
if
(
operand
.
type
!
=
=
"
NumericValue
"
)
{
throw
new
Error
(
Cannot
apply
test
"
odd
"
to
type
:
{
operand
.
type
}
)
;
}
return
operand
.
value
%
2
!
=
=
0
;
}
]
[
"
even
"
(
operand
)
=
>
{
if
(
operand
.
type
!
=
=
"
NumericValue
"
)
{
throw
new
Error
(
Cannot
apply
test
"
even
"
to
type
:
{
operand
.
type
}
)
;
}
return
operand
.
value
%
2
=
=
=
0
;
}
]
[
"
false
"
(
operand
)
=
>
operand
.
type
=
=
=
"
BooleanValue
"
&
&
!
operand
.
value
]
[
"
true
"
(
operand
)
=
>
operand
.
type
=
=
=
"
BooleanValue
"
&
&
operand
.
value
]
[
"
none
"
(
operand
)
=
>
operand
.
type
=
=
=
"
NullValue
"
]
[
"
string
"
(
operand
)
=
>
operand
.
type
=
=
=
"
StringValue
"
]
[
"
number
"
(
operand
)
=
>
operand
.
type
=
=
=
"
NumericValue
"
]
[
"
integer
"
(
operand
)
=
>
operand
.
type
=
=
=
"
NumericValue
"
&
&
Number
.
isInteger
(
operand
.
value
)
]
[
"
iterable
"
(
operand
)
=
>
operand
.
type
=
=
=
"
ArrayValue
"
|
|
operand
.
type
=
=
=
"
StringValue
"
]
[
"
mapping
"
(
operand
)
=
>
operand
.
type
=
=
=
"
ObjectValue
"
]
[
"
lower
"
(
operand
)
=
>
{
const
str
=
operand
.
value
;
return
operand
.
type
=
=
=
"
StringValue
"
&
&
str
=
=
=
str
.
toLowerCase
(
)
;
}
]
[
"
upper
"
(
operand
)
=
>
{
const
str
=
operand
.
value
;
return
operand
.
type
=
=
=
"
StringValue
"
&
&
str
=
=
=
str
.
toUpperCase
(
)
;
}
]
[
"
none
"
(
operand
)
=
>
operand
.
type
=
=
=
"
NullValue
"
]
[
"
defined
"
(
operand
)
=
>
operand
.
type
!
=
=
"
UndefinedValue
"
]
[
"
undefined
"
(
operand
)
=
>
operand
.
type
=
=
=
"
UndefinedValue
"
]
[
"
equalto
"
(
a
b
)
=
>
a
.
value
=
=
=
b
.
value
]
[
"
eq
"
(
a
b
)
=
>
a
.
value
=
=
=
b
.
value
]
]
)
;
set
(
name
value
)
{
return
this
.
declareVariable
(
name
convertToRuntimeValues
(
value
)
)
;
}
declareVariable
(
name
value
)
{
if
(
this
.
variables
.
has
(
name
)
)
{
throw
new
SyntaxError
(
Variable
already
declared
:
{
name
}
)
;
}
this
.
variables
.
set
(
name
value
)
;
return
value
;
}
setVariable
(
name
value
)
{
this
.
variables
.
set
(
name
value
)
;
return
value
;
}
resolve
(
name
)
{
if
(
this
.
variables
.
has
(
name
)
)
{
return
this
;
}
if
(
this
.
parent
)
{
return
this
.
parent
.
resolve
(
name
)
;
}
throw
new
Error
(
Unknown
variable
:
{
name
}
)
;
}
lookupVariable
(
name
)
{
try
{
return
this
.
resolve
(
name
)
.
variables
.
get
(
name
)
?
?
new
UndefinedValue
(
)
;
}
catch
{
return
new
UndefinedValue
(
)
;
}
}
}
;
var
Interpreter
=
class
{
global
;
constructor
(
env
)
{
this
.
global
=
env
?
?
new
Environment
(
)
;
}
run
(
program
)
{
return
this
.
evaluate
(
program
this
.
global
)
;
}
evaluateBinaryExpression
(
node
environment
)
{
const
left
=
this
.
evaluate
(
node
.
left
environment
)
;
switch
(
node
.
operator
.
value
)
{
case
"
and
"
:
return
left
.
__bool__
(
)
.
value
?
this
.
evaluate
(
node
.
right
environment
)
:
left
;
case
"
or
"
:
return
left
.
__bool__
(
)
.
value
?
left
:
this
.
evaluate
(
node
.
right
environment
)
;
}
const
right
=
this
.
evaluate
(
node
.
right
environment
)
;
switch
(
node
.
operator
.
value
)
{
case
"
=
=
"
:
return
new
BooleanValue
(
left
.
value
=
=
right
.
value
)
;
case
"
!
=
"
:
return
new
BooleanValue
(
left
.
value
!
=
right
.
value
)
;
}
if
(
left
instanceof
UndefinedValue
|
|
right
instanceof
UndefinedValue
)
{
throw
new
Error
(
"
Cannot
perform
operation
on
undefined
values
"
)
;
}
else
if
(
left
instanceof
NullValue
|
|
right
instanceof
NullValue
)
{
throw
new
Error
(
"
Cannot
perform
operation
on
null
values
"
)
;
}
else
if
(
left
instanceof
NumericValue
&
&
right
instanceof
NumericValue
)
{
switch
(
node
.
operator
.
value
)
{
case
"
+
"
:
return
new
NumericValue
(
left
.
value
+
right
.
value
)
;
case
"
-
"
:
return
new
NumericValue
(
left
.
value
-
right
.
value
)
;
case
"
*
"
:
return
new
NumericValue
(
left
.
value
*
right
.
value
)
;
case
"
/
"
:
return
new
NumericValue
(
left
.
value
/
right
.
value
)
;
case
"
%
"
:
return
new
NumericValue
(
left
.
value
%
right
.
value
)
;
case
"
<
"
:
return
new
BooleanValue
(
left
.
value
<
right
.
value
)
;
case
"
>
"
:
return
new
BooleanValue
(
left
.
value
>
right
.
value
)
;
case
"
>
=
"
:
return
new
BooleanValue
(
left
.
value
>
=
right
.
value
)
;
case
"
<
=
"
:
return
new
BooleanValue
(
left
.
value
<
=
right
.
value
)
;
}
}
else
if
(
left
instanceof
ArrayValue
&
&
right
instanceof
ArrayValue
)
{
switch
(
node
.
operator
.
value
)
{
case
"
+
"
:
return
new
ArrayValue
(
left
.
value
.
concat
(
right
.
value
)
)
;
}
}
else
if
(
right
instanceof
ArrayValue
)
{
const
member
=
right
.
value
.
find
(
(
x
)
=
>
x
.
value
=
=
=
left
.
value
)
!
=
=
void
0
;
switch
(
node
.
operator
.
value
)
{
case
"
in
"
:
return
new
BooleanValue
(
member
)
;
case
"
not
in
"
:
return
new
BooleanValue
(
!
member
)
;
}
}
if
(
left
instanceof
StringValue
|
|
right
instanceof
StringValue
)
{
switch
(
node
.
operator
.
value
)
{
case
"
+
"
:
return
new
StringValue
(
left
.
value
.
toString
(
)
+
right
.
value
.
toString
(
)
)
;
}
}
if
(
left
instanceof
StringValue
&
&
right
instanceof
StringValue
)
{
switch
(
node
.
operator
.
value
)
{
case
"
in
"
:
return
new
BooleanValue
(
right
.
value
.
includes
(
left
.
value
)
)
;
case
"
not
in
"
:
return
new
BooleanValue
(
!
right
.
value
.
includes
(
left
.
value
)
)
;
}
}
if
(
left
instanceof
StringValue
&
&
right
instanceof
ObjectValue
)
{
switch
(
node
.
operator
.
value
)
{
case
"
in
"
:
return
new
BooleanValue
(
right
.
value
.
has
(
left
.
value
)
)
;
case
"
not
in
"
:
return
new
BooleanValue
(
!
right
.
value
.
has
(
left
.
value
)
)
;
}
}
throw
new
SyntaxError
(
Unknown
operator
"
{
node
.
operator
.
value
}
"
between
{
left
.
type
}
and
{
right
.
type
}
)
;
}
evaluateArguments
(
args
environment
)
{
const
positionalArguments
=
[
]
;
const
keywordArguments
=
new
Map
(
)
;
for
(
const
argument
of
args
)
{
if
(
argument
.
type
=
=
=
"
KeywordArgumentExpression
"
)
{
const
kwarg
=
argument
;
keywordArguments
.
set
(
kwarg
.
key
.
value
this
.
evaluate
(
kwarg
.
value
environment
)
)
;
}
else
{
if
(
keywordArguments
.
size
>
0
)
{
throw
new
Error
(
"
Positional
arguments
must
come
before
keyword
arguments
"
)
;
}
positionalArguments
.
push
(
this
.
evaluate
(
argument
environment
)
)
;
}
}
return
[
positionalArguments
keywordArguments
]
;
}
evaluateFilterExpression
(
node
environment
)
{
const
operand
=
this
.
evaluate
(
node
.
operand
environment
)
;
if
(
node
.
filter
.
type
=
=
=
"
Identifier
"
)
{
const
filter
=
node
.
filter
;
if
(
filter
.
value
=
=
=
"
tojson
"
)
{
return
new
StringValue
(
toJSON
(
operand
)
)
;
}
if
(
operand
instanceof
ArrayValue
)
{
switch
(
filter
.
value
)
{
case
"
list
"
:
return
operand
;
case
"
first
"
:
return
operand
.
value
[
0
]
;
case
"
last
"
:
return
operand
.
value
[
operand
.
value
.
length
-
1
]
;
case
"
length
"
:
return
new
NumericValue
(
operand
.
value
.
length
)
;
case
"
reverse
"
:
return
new
ArrayValue
(
operand
.
value
.
reverse
(
)
)
;
case
"
sort
"
:
return
new
ArrayValue
(
operand
.
value
.
sort
(
(
a
b
)
=
>
{
if
(
a
.
type
!
=
=
b
.
type
)
{
throw
new
Error
(
Cannot
compare
different
types
:
{
a
.
type
}
and
{
b
.
type
}
)
;
}
switch
(
a
.
type
)
{
case
"
NumericValue
"
:
return
a
.
value
-
b
.
value
;
case
"
StringValue
"
:
return
a
.
value
.
localeCompare
(
b
.
value
)
;
default
:
throw
new
Error
(
Cannot
compare
type
:
{
a
.
type
}
)
;
}
}
)
)
;
default
:
throw
new
Error
(
Unknown
ArrayValue
filter
:
{
filter
.
value
}
)
;
}
}
else
if
(
operand
instanceof
StringValue
)
{
switch
(
filter
.
value
)
{
case
"
length
"
:
return
new
NumericValue
(
operand
.
value
.
length
)
;
case
"
upper
"
:
return
new
StringValue
(
operand
.
value
.
toUpperCase
(
)
)
;
case
"
lower
"
:
return
new
StringValue
(
operand
.
value
.
toLowerCase
(
)
)
;
case
"
title
"
:
return
new
StringValue
(
titleCase
(
operand
.
value
)
)
;
case
"
capitalize
"
:
return
new
StringValue
(
operand
.
value
.
charAt
(
0
)
.
toUpperCase
(
)
+
operand
.
value
.
slice
(
1
)
)
;
case
"
trim
"
:
return
new
StringValue
(
operand
.
value
.
trim
(
)
)
;
case
"
indent
"
:
return
new
StringValue
(
operand
.
value
.
split
(
"
\
n
"
)
.
map
(
(
x
i
)
=
>
(
i
=
=
=
0
|
|
x
.
length
=
=
=
0
?
x
:
"
"
+
x
)
)
.
join
(
"
\
n
"
)
)
;
case
"
string
"
:
return
operand
;
default
:
throw
new
Error
(
Unknown
StringValue
filter
:
{
filter
.
value
}
)
;
}
}
else
if
(
operand
instanceof
NumericValue
)
{
switch
(
filter
.
value
)
{
case
"
abs
"
:
return
new
NumericValue
(
Math
.
abs
(
operand
.
value
)
)
;
default
:
throw
new
Error
(
Unknown
NumericValue
filter
:
{
filter
.
value
}
)
;
}
}
else
if
(
operand
instanceof
ObjectValue
)
{
switch
(
filter
.
value
)
{
case
"
items
"
:
return
new
ArrayValue
(
Array
.
from
(
operand
.
value
.
entries
(
)
)
.
map
(
(
[
key
value
]
)
=
>
new
ArrayValue
(
[
new
StringValue
(
key
)
value
]
)
)
)
;
case
"
length
"
:
return
new
NumericValue
(
operand
.
value
.
size
)
;
default
:
throw
new
Error
(
Unknown
ObjectValue
filter
:
{
filter
.
value
}
)
;
}
}
throw
new
Error
(
Cannot
apply
filter
"
{
filter
.
value
}
"
to
type
:
{
operand
.
type
}
)
;
}
else
if
(
node
.
filter
.
type
=
=
=
"
CallExpression
"
)
{
const
filter
=
node
.
filter
;
if
(
filter
.
callee
.
type
!
=
=
"
Identifier
"
)
{
throw
new
Error
(
Unknown
filter
:
{
filter
.
callee
.
type
}
)
;
}
const
filterName
=
filter
.
callee
.
value
;
if
(
filterName
=
=
=
"
tojson
"
)
{
const
[
kwargs
]
=
this
.
evaluateArguments
(
filter
.
args
environment
)
;
const
indent
=
kwargs
.
get
(
"
indent
"
)
?
?
new
NullValue
(
)
;
if
(
!
(
indent
instanceof
NumericValue
|
|
indent
instanceof
NullValue
)
)
{
throw
new
Error
(
"
If
set
indent
must
be
a
number
"
)
;
}
return
new
StringValue
(
toJSON
(
operand
indent
.
value
)
)
;
}
if
(
operand
instanceof
ArrayValue
)
{
switch
(
filterName
)
{
case
"
selectattr
"
:
case
"
rejectattr
"
:
{
const
select
=
filterName
=
=
=
"
selectattr
"
;
if
(
operand
.
value
.
some
(
(
x
)
=
>
!
(
x
instanceof
ObjectValue
)
)
)
{
throw
new
Error
(
\
{
filterName
}
\
can
only
be
applied
to
array
of
objects
)
;
}
if
(
filter
.
args
.
some
(
(
x
)
=
>
x
.
type
!
=
=
"
StringLiteral
"
)
)
{
throw
new
Error
(
arguments
of
\
{
filterName
}
\
must
be
strings
)
;
}
const
[
attr
testName
value
]
=
filter
.
args
.
map
(
(
x
)
=
>
this
.
evaluate
(
x
environment
)
)
;
let
testFunction
;
if
(
testName
)
{
const
test
=
environment
.
tests
.
get
(
testName
.
value
)
;
if
(
!
test
)
{
throw
new
Error
(
Unknown
test
:
{
testName
.
value
}
)
;
}
testFunction
=
test
;
}
else
{
testFunction
=
(
.
.
.
x
)
=
>
x
[
0
]
.
__bool__
(
)
.
value
;
}
const
filtered
=
operand
.
value
.
filter
(
(
item
)
=
>
{
const
a
=
item
.
value
.
get
(
attr
.
value
)
;
const
result
=
a
?
testFunction
(
a
value
)
:
false
;
return
select
?
result
:
!
result
;
}
)
;
return
new
ArrayValue
(
filtered
)
;
}
case
"
map
"
:
{
const
[
kwargs
]
=
this
.
evaluateArguments
(
filter
.
args
environment
)
;
if
(
kwargs
.
has
(
"
attribute
"
)
)
{
const
attr
=
kwargs
.
get
(
"
attribute
"
)
;
if
(
!
(
attr
instanceof
StringValue
)
)
{
throw
new
Error
(
"
attribute
must
be
a
string
"
)
;
}
const
defaultValue
=
kwargs
.
get
(
"
default
"
)
;
const
mapped
=
operand
.
value
.
map
(
(
item
)
=
>
{
if
(
!
(
item
instanceof
ObjectValue
)
)
{
throw
new
Error
(
"
items
in
map
must
be
an
object
"
)
;
}
return
item
.
value
.
get
(
attr
.
value
)
?
?
defaultValue
?
?
new
UndefinedValue
(
)
;
}
)
;
return
new
ArrayValue
(
mapped
)
;
}
else
{
throw
new
Error
(
"
map
expressions
without
attribute
set
are
not
currently
supported
.
"
)
;
}
}
}
throw
new
Error
(
Unknown
ArrayValue
filter
:
{
filterName
}
)
;
}
else
if
(
operand
instanceof
StringValue
)
{
switch
(
filterName
)
{
case
"
indent
"
:
{
const
[
args
kwargs
]
=
this
.
evaluateArguments
(
filter
.
args
environment
)
;
const
width
=
args
.
at
(
0
)
?
?
kwargs
.
get
(
"
width
"
)
?
?
new
NumericValue
(
4
)
;
if
(
!
(
width
instanceof
NumericValue
)
)
{
throw
new
Error
(
"
width
must
be
a
number
"
)
;
}
const
first
=
args
.
at
(
1
)
?
?
kwargs
.
get
(
"
first
"
)
?
?
new
BooleanValue
(
false
)
;
const
blank
=
args
.
at
(
2
)
?
?
kwargs
.
get
(
"
blank
"
)
?
?
new
BooleanValue
(
false
)
;
const
lines
=
operand
.
value
.
split
(
"
\
n
"
)
;
const
indent
=
"
"
.
repeat
(
width
.
value
)
;
const
indented
=
lines
.
map
(
(
x
i
)
=
>
!
first
.
value
&
&
i
=
=
=
0
|
|
!
blank
.
value
&
&
x
.
length
=
=
=
0
?
x
:
indent
+
x
)
;
return
new
StringValue
(
indented
.
join
(
"
\
n
"
)
)
;
}
}
throw
new
Error
(
Unknown
StringValue
filter
:
{
filterName
}
)
;
}
else
{
throw
new
Error
(
Cannot
apply
filter
"
{
filterName
}
"
to
type
:
{
operand
.
type
}
)
;
}
}
throw
new
Error
(
Unknown
filter
:
{
node
.
filter
.
type
}
)
;
}
evaluateTestExpression
(
node
environment
)
{
const
operand
=
this
.
evaluate
(
node
.
operand
environment
)
;
const
test
=
environment
.
tests
.
get
(
node
.
test
.
value
)
;
if
(
!
test
)
{
throw
new
Error
(
Unknown
test
:
{
node
.
test
.
value
}
)
;
}
const
result
=
test
(
operand
)
;
return
new
BooleanValue
(
node
.
negate
?
!
result
:
result
)
;
}
evaluateUnaryExpression
(
node
environment
)
{
const
argument
=
this
.
evaluate
(
node
.
argument
environment
)
;
switch
(
node
.
operator
.
value
)
{
case
"
not
"
:
return
new
BooleanValue
(
!
argument
.
value
)
;
default
:
throw
new
SyntaxError
(
Unknown
operator
:
{
node
.
operator
.
value
}
)
;
}
}
evalProgram
(
program
environment
)
{
return
this
.
evaluateBlock
(
program
.
body
environment
)
;
}
evaluateBlock
(
statements
environment
)
{
let
result
=
"
"
;
for
(
const
statement
of
statements
)
{
const
lastEvaluated
=
this
.
evaluate
(
statement
environment
)
;
if
(
lastEvaluated
.
type
!
=
=
"
NullValue
"
&
&
lastEvaluated
.
type
!
=
=
"
UndefinedValue
"
)
{
result
+
=
lastEvaluated
.
value
;
}
}
return
new
StringValue
(
result
)
;
}
evaluateIdentifier
(
node
environment
)
{
return
environment
.
lookupVariable
(
node
.
value
)
;
}
evaluateCallExpression
(
expr
environment
)
{
const
[
args
kwargs
]
=
this
.
evaluateArguments
(
expr
.
args
environment
)
;
if
(
kwargs
.
size
>
0
)
{
args
.
push
(
new
KeywordArgumentsValue
(
kwargs
)
)
;
}
const
fn
=
this
.
evaluate
(
expr
.
callee
environment
)
;
if
(
fn
.
type
!
=
=
"
FunctionValue
"
)
{
throw
new
Error
(
Cannot
call
something
that
is
not
a
function
:
got
{
fn
.
type
}
)
;
}
return
fn
.
value
(
args
environment
)
;
}
evaluateSliceExpression
(
object
expr
environment
)
{
if
(
!
(
object
instanceof
ArrayValue
|
|
object
instanceof
StringValue
)
)
{
throw
new
Error
(
"
Slice
object
must
be
an
array
or
string
"
)
;
}
const
start
=
this
.
evaluate
(
expr
.
start
environment
)
;
const
stop
=
this
.
evaluate
(
expr
.
stop
environment
)
;
const
step
=
this
.
evaluate
(
expr
.
step
environment
)
;
if
(
!
(
start
instanceof
NumericValue
|
|
start
instanceof
UndefinedValue
)
)
{
throw
new
Error
(
"
Slice
start
must
be
numeric
or
undefined
"
)
;
}
if
(
!
(
stop
instanceof
NumericValue
|
|
stop
instanceof
UndefinedValue
)
)
{
throw
new
Error
(
"
Slice
stop
must
be
numeric
or
undefined
"
)
;
}
if
(
!
(
step
instanceof
NumericValue
|
|
step
instanceof
UndefinedValue
)
)
{
throw
new
Error
(
"
Slice
step
must
be
numeric
or
undefined
"
)
;
}
if
(
object
instanceof
ArrayValue
)
{
return
new
ArrayValue
(
slice
(
object
.
value
start
.
value
stop
.
value
step
.
value
)
)
;
}
else
{
return
new
StringValue
(
slice
(
Array
.
from
(
object
.
value
)
start
.
value
stop
.
value
step
.
value
)
.
join
(
"
"
)
)
;
}
}
evaluateMemberExpression
(
expr
environment
)
{
const
object
=
this
.
evaluate
(
expr
.
object
environment
)
;
let
property
;
if
(
expr
.
computed
)
{
if
(
expr
.
property
.
type
=
=
=
"
SliceExpression
"
)
{
return
this
.
evaluateSliceExpression
(
object
expr
.
property
environment
)
;
}
else
{
property
=
this
.
evaluate
(
expr
.
property
environment
)
;
}
}
else
{
property
=
new
StringValue
(
expr
.
property
.
value
)
;
}
let
value
;
if
(
object
instanceof
ObjectValue
)
{
if
(
!
(
property
instanceof
StringValue
)
)
{
throw
new
Error
(
Cannot
access
property
with
non
-
string
:
got
{
property
.
type
}
)
;
}
value
=
object
.
value
.
get
(
property
.
value
)
?
?
object
.
builtins
.
get
(
property
.
value
)
;
}
else
if
(
object
instanceof
ArrayValue
|
|
object
instanceof
StringValue
)
{
if
(
property
instanceof
NumericValue
)
{
value
=
object
.
value
.
at
(
property
.
value
)
;
if
(
object
instanceof
StringValue
)
{
value
=
new
StringValue
(
object
.
value
.
at
(
property
.
value
)
)
;
}
}
else
if
(
property
instanceof
StringValue
)
{
value
=
object
.
builtins
.
get
(
property
.
value
)
;
}
else
{
throw
new
Error
(
Cannot
access
property
with
non
-
string
/
non
-
number
:
got
{
property
.
type
}
)
;
}
}
else
{
if
(
!
(
property
instanceof
StringValue
)
)
{
throw
new
Error
(
Cannot
access
property
with
non
-
string
:
got
{
property
.
type
}
)
;
}
value
=
object
.
builtins
.
get
(
property
.
value
)
;
}
return
value
instanceof
RuntimeValue
?
value
:
new
UndefinedValue
(
)
;
}
evaluateSet
(
node
environment
)
{
const
rhs
=
this
.
evaluate
(
node
.
value
environment
)
;
if
(
node
.
assignee
.
type
=
=
=
"
Identifier
"
)
{
const
variableName
=
node
.
assignee
.
value
;
environment
.
setVariable
(
variableName
rhs
)
;
}
else
if
(
node
.
assignee
.
type
=
=
=
"
MemberExpression
"
)
{
const
member
=
node
.
assignee
;
const
object
=
this
.
evaluate
(
member
.
object
environment
)
;
if
(
!
(
object
instanceof
ObjectValue
)
)
{
throw
new
Error
(
"
Cannot
assign
to
member
of
non
-
object
"
)
;
}
if
(
member
.
property
.
type
!
=
=
"
Identifier
"
)
{
throw
new
Error
(
"
Cannot
assign
to
member
with
non
-
identifier
property
"
)
;
}
object
.
value
.
set
(
member
.
property
.
value
rhs
)
;
}
else
{
throw
new
Error
(
Invalid
LHS
inside
assignment
expression
:
{
JSON
.
stringify
(
node
.
assignee
)
}
)
;
}
return
new
NullValue
(
)
;
}
evaluateIf
(
node
environment
)
{
const
test
=
this
.
evaluate
(
node
.
test
environment
)
;
return
this
.
evaluateBlock
(
test
.
__bool__
(
)
.
value
?
node
.
body
:
node
.
alternate
environment
)
;
}
evaluateFor
(
node
environment
)
{
const
scope
=
new
Environment
(
environment
)
;
let
test
iterable
;
if
(
node
.
iterable
.
type
=
=
=
"
SelectExpression
"
)
{
const
select
=
node
.
iterable
;
iterable
=
this
.
evaluate
(
select
.
iterable
scope
)
;
test
=
select
.
test
;
}
else
{
iterable
=
this
.
evaluate
(
node
.
iterable
scope
)
;
}
if
(
!
(
iterable
instanceof
ArrayValue
)
)
{
throw
new
Error
(
Expected
iterable
type
in
for
loop
:
got
{
iterable
.
type
}
)
;
}
const
items
=
[
]
;
const
scopeUpdateFunctions
=
[
]
;
for
(
let
i
=
0
;
i
<
iterable
.
value
.
length
;
+
+
i
)
{
const
loopScope
=
new
Environment
(
scope
)
;
const
current
=
iterable
.
value
[
i
]
;
let
scopeUpdateFunction
;
if
(
node
.
loopvar
.
type
=
=
=
"
Identifier
"
)
{
scopeUpdateFunction
=
(
scope2
)
=
>
scope2
.
setVariable
(
node
.
loopvar
.
value
current
)
;
}
else
if
(
node
.
loopvar
.
type
=
=
=
"
TupleLiteral
"
)
{
const
loopvar
=
node
.
loopvar
;
if
(
current
.
type
!
=
=
"
ArrayValue
"
)
{
throw
new
Error
(
Cannot
unpack
non
-
iterable
type
:
{
current
.
type
}
)
;
}
const
c
=
current
;
if
(
loopvar
.
value
.
length
!
=
=
c
.
value
.
length
)
{
throw
new
Error
(
Too
{
loopvar
.
value
.
length
>
c
.
value
.
length
?
"
few
"
:
"
many
"
}
items
to
unpack
)
;
}
scopeUpdateFunction
=
(
scope2
)
=
>
{
for
(
let
j
=
0
;
j
<
loopvar
.
value
.
length
;
+
+
j
)
{
if
(
loopvar
.
value
[
j
]
.
type
!
=
=
"
Identifier
"
)
{
throw
new
Error
(
Cannot
unpack
non
-
identifier
type
:
{
loopvar
.
value
[
j
]
.
type
}
)
;
}
scope2
.
setVariable
(
loopvar
.
value
[
j
]
.
value
c
.
value
[
j
]
)
;
}
}
;
}
else
{
throw
new
Error
(
Invalid
loop
variable
(
s
)
:
{
node
.
loopvar
.
type
}
)
;
}
if
(
test
)
{
scopeUpdateFunction
(
loopScope
)
;
const
testValue
=
this
.
evaluate
(
test
loopScope
)
;
if
(
!
testValue
.
__bool__
(
)
.
value
)
{
continue
;
}
}
items
.
push
(
current
)
;
scopeUpdateFunctions
.
push
(
scopeUpdateFunction
)
;
}
let
result
=
"
"
;
let
noIteration
=
true
;
for
(
let
i
=
0
;
i
<
items
.
length
;
+
+
i
)
{
const
loop
=
new
Map
(
[
[
"
index
"
new
NumericValue
(
i
+
1
)
]
[
"
index0
"
new
NumericValue
(
i
)
]
[
"
revindex
"
new
NumericValue
(
items
.
length
-
i
)
]
[
"
revindex0
"
new
NumericValue
(
items
.
length
-
i
-
1
)
]
[
"
first
"
new
BooleanValue
(
i
=
=
=
0
)
]
[
"
last
"
new
BooleanValue
(
i
=
=
=
items
.
length
-
1
)
]
[
"
length
"
new
NumericValue
(
items
.
length
)
]
[
"
previtem
"
i
>
0
?
items
[
i
-
1
]
:
new
UndefinedValue
(
)
]
[
"
nextitem
"
i
<
items
.
length
-
1
?
items
[
i
+
1
]
:
new
UndefinedValue
(
)
]
]
)
;
scope
.
setVariable
(
"
loop
"
new
ObjectValue
(
loop
)
)
;
scopeUpdateFunctions
[
i
]
(
scope
)
;
const
evaluated
=
this
.
evaluateBlock
(
node
.
body
scope
)
;
result
+
=
evaluated
.
value
;
noIteration
=
false
;
}
if
(
noIteration
)
{
const
defaultEvaluated
=
this
.
evaluateBlock
(
node
.
defaultBlock
scope
)
;
result
+
=
defaultEvaluated
.
value
;
}
return
new
StringValue
(
result
)
;
}
evaluateMacro
(
node
environment
)
{
environment
.
setVariable
(
node
.
name
.
value
new
FunctionValue
(
(
args
scope
)
=
>
{
const
macroScope
=
new
Environment
(
scope
)
;
args
=
args
.
slice
(
)
;
let
kwargs
;
if
(
args
.
at
(
-
1
)
?
.
type
=
=
=
"
KeywordArgumentsValue
"
)
{
kwargs
=
args
.
pop
(
)
;
}
for
(
let
i
=
0
;
i
<
node
.
args
.
length
;
+
+
i
)
{
const
nodeArg
=
node
.
args
[
i
]
;
const
passedArg
=
args
[
i
]
;
if
(
nodeArg
.
type
=
=
=
"
Identifier
"
)
{
const
identifier
=
nodeArg
;
if
(
!
passedArg
)
{
throw
new
Error
(
Missing
positional
argument
:
{
identifier
.
value
}
)
;
}
macroScope
.
setVariable
(
identifier
.
value
passedArg
)
;
}
else
if
(
nodeArg
.
type
=
=
=
"
KeywordArgumentExpression
"
)
{
const
kwarg
=
nodeArg
;
const
value
=
passedArg
?
?
kwargs
?
.
value
.
get
(
kwarg
.
key
.
value
)
?
?
this
.
evaluate
(
kwarg
.
value
macroScope
)
;
macroScope
.
setVariable
(
kwarg
.
key
.
value
value
)
;
}
else
{
throw
new
Error
(
Unknown
argument
type
:
{
nodeArg
.
type
}
)
;
}
}
return
this
.
evaluateBlock
(
node
.
body
macroScope
)
;
}
)
)
;
return
new
NullValue
(
)
;
}
evaluate
(
statement
environment
)
{
if
(
statement
=
=
=
void
0
)
return
new
UndefinedValue
(
)
;
switch
(
statement
.
type
)
{
case
"
Program
"
:
return
this
.
evalProgram
(
statement
environment
)
;
case
"
Set
"
:
return
this
.
evaluateSet
(
statement
environment
)
;
case
"
If
"
:
return
this
.
evaluateIf
(
statement
environment
)
;
case
"
For
"
:
return
this
.
evaluateFor
(
statement
environment
)
;
case
"
Macro
"
:
return
this
.
evaluateMacro
(
statement
environment
)
;
case
"
NumericLiteral
"
:
return
new
NumericValue
(
Number
(
statement
.
value
)
)
;
case
"
StringLiteral
"
:
return
new
StringValue
(
statement
.
value
)
;
case
"
BooleanLiteral
"
:
return
new
BooleanValue
(
statement
.
value
)
;
case
"
NullLiteral
"
:
return
new
NullValue
(
statement
.
value
)
;
case
"
ArrayLiteral
"
:
return
new
ArrayValue
(
statement
.
value
.
map
(
(
x
)
=
>
this
.
evaluate
(
x
environment
)
)
)
;
case
"
TupleLiteral
"
:
return
new
TupleValue
(
statement
.
value
.
map
(
(
x
)
=
>
this
.
evaluate
(
x
environment
)
)
)
;
case
"
ObjectLiteral
"
:
{
const
mapping
=
new
Map
(
)
;
for
(
const
[
key
value
]
of
statement
.
value
)
{
const
evaluatedKey
=
this
.
evaluate
(
key
environment
)
;
if
(
!
(
evaluatedKey
instanceof
StringValue
)
)
{
throw
new
Error
(
Object
keys
must
be
strings
:
got
{
evaluatedKey
.
type
}
)
;
}
mapping
.
set
(
evaluatedKey
.
value
this
.
evaluate
(
value
environment
)
)
;
}
return
new
ObjectValue
(
mapping
)
;
}
case
"
Identifier
"
:
return
this
.
evaluateIdentifier
(
statement
environment
)
;
case
"
CallExpression
"
:
return
this
.
evaluateCallExpression
(
statement
environment
)
;
case
"
MemberExpression
"
:
return
this
.
evaluateMemberExpression
(
statement
environment
)
;
case
"
UnaryExpression
"
:
return
this
.
evaluateUnaryExpression
(
statement
environment
)
;
case
"
BinaryExpression
"
:
return
this
.
evaluateBinaryExpression
(
statement
environment
)
;
case
"
FilterExpression
"
:
return
this
.
evaluateFilterExpression
(
statement
environment
)
;
case
"
TestExpression
"
:
return
this
.
evaluateTestExpression
(
statement
environment
)
;
default
:
throw
new
SyntaxError
(
Unknown
node
type
:
{
statement
.
type
}
)
;
}
}
}
;
function
convertToRuntimeValues
(
input
)
{
switch
(
typeof
input
)
{
case
"
number
"
:
return
new
NumericValue
(
input
)
;
case
"
string
"
:
return
new
StringValue
(
input
)
;
case
"
boolean
"
:
return
new
BooleanValue
(
input
)
;
case
"
undefined
"
:
return
new
UndefinedValue
(
)
;
case
"
object
"
:
if
(
input
=
=
=
null
)
{
return
new
NullValue
(
)
;
}
else
if
(
Array
.
isArray
(
input
)
)
{
return
new
ArrayValue
(
input
.
map
(
convertToRuntimeValues
)
)
;
}
else
{
return
new
ObjectValue
(
new
Map
(
Object
.
entries
(
input
)
.
map
(
(
[
key
value
]
)
=
>
[
key
convertToRuntimeValues
(
value
)
]
)
)
)
;
}
case
"
function
"
:
return
new
FunctionValue
(
(
args
_scope
)
=
>
{
const
result
=
input
(
.
.
.
args
.
map
(
(
x
)
=
>
x
.
value
)
)
?
?
null
;
return
convertToRuntimeValues
(
result
)
;
}
)
;
default
:
throw
new
Error
(
Cannot
convert
to
runtime
value
:
{
input
}
)
;
}
}
function
toJSON
(
input
indent
depth
)
{
const
currentDepth
=
depth
?
?
0
;
switch
(
input
.
type
)
{
case
"
NullValue
"
:
case
"
UndefinedValue
"
:
return
"
null
"
;
case
"
NumericValue
"
:
case
"
StringValue
"
:
case
"
BooleanValue
"
:
return
JSON
.
stringify
(
input
.
value
)
;
case
"
ArrayValue
"
:
case
"
ObjectValue
"
:
{
const
indentValue
=
indent
?
"
"
.
repeat
(
indent
)
:
"
"
;
const
basePadding
=
"
\
n
"
+
indentValue
.
repeat
(
currentDepth
)
;
const
childrenPadding
=
basePadding
+
indentValue
;
if
(
input
.
type
=
=
=
"
ArrayValue
"
)
{
const
core
=
input
.
value
.
map
(
(
x
)
=
>
toJSON
(
x
indent
currentDepth
+
1
)
)
;
return
indent
?
[
{
childrenPadding
}
{
core
.
join
(
{
childrenPadding
}
)
}
{
basePadding
}
]
:
[
{
core
.
join
(
"
"
)
}
]
;
}
else
{
const
core
=
Array
.
from
(
input
.
value
.
entries
(
)
)
.
map
(
(
[
key
value
]
)
=
>
{
const
v
=
"
{
key
}
"
:
{
toJSON
(
value
indent
currentDepth
+
1
)
}
;
return
indent
?
{
childrenPadding
}
{
v
}
:
v
;
}
)
;
return
indent
?
{
{
core
.
join
(
"
"
)
}
{
basePadding
}
}
:
{
{
core
.
join
(
"
"
)
}
}
;
}
}
default
:
throw
new
Error
(
Cannot
convert
to
JSON
:
{
input
.
type
}
)
;
}
}
var
Template
=
class
{
parsed
;
constructor
(
template
)
{
const
tokens
=
tokenize
(
template
{
lstrip_blocks
:
true
trim_blocks
:
true
}
)
;
this
.
parsed
=
parse
(
tokens
)
;
}
render
(
items
)
{
const
env
=
new
Environment
(
)
;
env
.
set
(
"
false
"
false
)
;
env
.
set
(
"
true
"
true
)
;
env
.
set
(
"
raise_exception
"
(
args
)
=
>
{
throw
new
Error
(
args
)
;
}
)
;
env
.
set
(
"
range
"
range
)
;
for
(
const
[
key
value
]
of
Object
.
entries
(
items
)
)
{
env
.
set
(
key
value
)
;
}
const
interpreter
=
new
Interpreter
(
env
)
;
const
result
=
interpreter
.
run
(
this
.
parsed
)
;
return
result
.
value
;
}
}
;
}
)
"
.
/
node_modules
/
onnxruntime
-
common
/
dist
/
esm
/
backend
-
impl
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
registerBackend
:
(
)
=
>
(
registerBackend
)
resolveBackendAndExecutionProviders
:
(
)
=
>
(
resolveBackendAndExecutionProviders
)
}
)
;
const
backends
=
new
Map
(
)
;
const
backendsSortedByPriority
=
[
]
;
const
registerBackend
=
(
name
backend
priority
)
=
>
{
if
(
backend
&
&
typeof
backend
.
init
=
=
=
'
function
'
&
&
typeof
backend
.
createInferenceSessionHandler
=
=
=
'
function
'
)
{
const
currentBackend
=
backends
.
get
(
name
)
;
if
(
currentBackend
=
=
=
undefined
)
{
backends
.
set
(
name
{
backend
priority
}
)
;
}
else
if
(
currentBackend
.
priority
>
priority
)
{
return
;
}
else
if
(
currentBackend
.
priority
=
=
=
priority
)
{
if
(
currentBackend
.
backend
!
=
=
backend
)
{
throw
new
Error
(
cannot
register
backend
"
{
name
}
"
using
priority
{
priority
}
)
;
}
}
if
(
priority
>
=
0
)
{
const
i
=
backendsSortedByPriority
.
indexOf
(
name
)
;
if
(
i
!
=
=
-
1
)
{
backendsSortedByPriority
.
splice
(
i
1
)
;
}
for
(
let
i
=
0
;
i
<
backendsSortedByPriority
.
length
;
i
+
+
)
{
if
(
backends
.
get
(
backendsSortedByPriority
[
i
]
)
.
priority
<
=
priority
)
{
backendsSortedByPriority
.
splice
(
i
0
name
)
;
return
;
}
}
backendsSortedByPriority
.
push
(
name
)
;
}
return
;
}
throw
new
TypeError
(
'
not
a
valid
backend
'
)
;
}
;
const
tryResolveAndInitializeBackend
=
async
(
backendName
)
=
>
{
const
backendInfo
=
backends
.
get
(
backendName
)
;
if
(
!
backendInfo
)
{
return
'
backend
not
found
.
'
;
}
if
(
backendInfo
.
initialized
)
{
return
backendInfo
.
backend
;
}
else
if
(
backendInfo
.
aborted
)
{
return
backendInfo
.
error
;
}
else
{
const
isInitializing
=
!
!
backendInfo
.
initPromise
;
try
{
if
(
!
isInitializing
)
{
backendInfo
.
initPromise
=
backendInfo
.
backend
.
init
(
backendName
)
;
}
await
backendInfo
.
initPromise
;
backendInfo
.
initialized
=
true
;
return
backendInfo
.
backend
;
}
catch
(
e
)
{
if
(
!
isInitializing
)
{
backendInfo
.
error
=
{
e
}
;
backendInfo
.
aborted
=
true
;
}
return
backendInfo
.
error
;
}
finally
{
delete
backendInfo
.
initPromise
;
}
}
}
;
const
resolveBackendAndExecutionProviders
=
async
(
options
)
=
>
{
const
eps
=
options
.
executionProviders
|
|
[
]
;
const
backendHints
=
eps
.
map
(
(
i
)
=
>
(
typeof
i
=
=
=
'
string
'
?
i
:
i
.
name
)
)
;
const
backendNames
=
backendHints
.
length
=
=
=
0
?
backendsSortedByPriority
:
backendHints
;
let
backend
;
const
errors
=
[
]
;
const
availableBackendNames
=
new
Set
(
)
;
for
(
const
backendName
of
backendNames
)
{
const
resolveResult
=
await
tryResolveAndInitializeBackend
(
backendName
)
;
if
(
typeof
resolveResult
=
=
=
'
string
'
)
{
errors
.
push
(
{
name
:
backendName
err
:
resolveResult
}
)
;
}
else
{
if
(
!
backend
)
{
backend
=
resolveResult
;
}
if
(
backend
=
=
=
resolveResult
)
{
availableBackendNames
.
add
(
backendName
)
;
}
}
}
if
(
!
backend
)
{
throw
new
Error
(
no
available
backend
found
.
ERR
:
{
errors
.
map
(
(
e
)
=
>
[
{
e
.
name
}
]
{
e
.
err
}
)
.
join
(
'
'
)
}
)
;
}
for
(
const
{
name
err
}
of
errors
)
{
if
(
backendHints
.
includes
(
name
)
)
{
console
.
warn
(
removing
requested
execution
provider
"
{
name
}
"
from
session
options
because
it
is
not
available
:
{
err
}
)
;
}
}
const
filteredEps
=
eps
.
filter
(
(
i
)
=
>
availableBackendNames
.
has
(
typeof
i
=
=
=
'
string
'
?
i
:
i
.
name
)
)
;
return
[
backend
new
Proxy
(
options
{
get
:
(
target
prop
)
=
>
{
if
(
prop
=
=
=
'
executionProviders
'
)
{
return
filteredEps
;
}
return
Reflect
.
get
(
target
prop
)
;
}
}
)
]
;
}
;
}
)
"
.
/
node_modules
/
onnxruntime
-
common
/
dist
/
esm
/
backend
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
registerBackend
:
(
)
=
>
(
_backend_impl_js__WEBPACK_IMPORTED_MODULE_0__
.
registerBackend
)
}
)
;
var
_backend_impl_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
node_modules
/
onnxruntime
-
common
/
dist
/
esm
/
backend
-
impl
.
js
"
)
;
}
)
"
.
/
node_modules
/
onnxruntime
-
common
/
dist
/
esm
/
env
-
impl
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
env
:
(
)
=
>
(
env
)
}
)
;
var
_version_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
node_modules
/
onnxruntime
-
common
/
dist
/
esm
/
version
.
js
"
)
;
let
logLevelValue
=
'
warning
'
;
const
env
=
{
wasm
:
{
}
webgl
:
{
}
webgpu
:
{
}
versions
:
{
common
:
_version_js__WEBPACK_IMPORTED_MODULE_0__
.
version
}
set
logLevel
(
value
)
{
if
(
value
=
=
=
undefined
)
{
return
;
}
if
(
typeof
value
!
=
=
'
string
'
|
|
[
'
verbose
'
'
info
'
'
warning
'
'
error
'
'
fatal
'
]
.
indexOf
(
value
)
=
=
=
-
1
)
{
throw
new
Error
(
Unsupported
logging
level
:
{
value
}
)
;
}
logLevelValue
=
value
;
}
get
logLevel
(
)
{
return
logLevelValue
;
}
}
;
Object
.
defineProperty
(
env
'
logLevel
'
{
enumerable
:
true
}
)
;
}
)
"
.
/
node_modules
/
onnxruntime
-
common
/
dist
/
esm
/
env
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
env
:
(
)
=
>
(
env
)
}
)
;
var
_env_impl_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
node_modules
/
onnxruntime
-
common
/
dist
/
esm
/
env
-
impl
.
js
"
)
;
const
env
=
_env_impl_js__WEBPACK_IMPORTED_MODULE_0__
.
env
;
}
)
"
.
/
node_modules
/
onnxruntime
-
common
/
dist
/
esm
/
index
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
InferenceSession
:
(
)
=
>
(
_inference_session_js__WEBPACK_IMPORTED_MODULE_2__
.
InferenceSession
)
TRACE
:
(
)
=
>
(
_trace_js__WEBPACK_IMPORTED_MODULE_6__
.
TRACE
)
TRACE_FUNC_BEGIN
:
(
)
=
>
(
_trace_js__WEBPACK_IMPORTED_MODULE_6__
.
TRACE_FUNC_BEGIN
)
TRACE_FUNC_END
:
(
)
=
>
(
_trace_js__WEBPACK_IMPORTED_MODULE_6__
.
TRACE_FUNC_END
)
Tensor
:
(
)
=
>
(
_tensor_js__WEBPACK_IMPORTED_MODULE_3__
.
Tensor
)
TrainingSession
:
(
)
=
>
(
_training_session_js__WEBPACK_IMPORTED_MODULE_9__
.
TrainingSession
)
env
:
(
)
=
>
(
_env_js__WEBPACK_IMPORTED_MODULE_1__
.
env
)
registerBackend
:
(
)
=
>
(
_backend_js__WEBPACK_IMPORTED_MODULE_0__
.
registerBackend
)
}
)
;
var
_backend_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
node_modules
/
onnxruntime
-
common
/
dist
/
esm
/
backend
.
js
"
)
;
var
_env_js__WEBPACK_IMPORTED_MODULE_1__
=
__webpack_require__
(
"
.
/
node_modules
/
onnxruntime
-
common
/
dist
/
esm
/
env
.
js
"
)
;
var
_inference_session_js__WEBPACK_IMPORTED_MODULE_2__
=
__webpack_require__
(
"
.
/
node_modules
/
onnxruntime
-
common
/
dist
/
esm
/
inference
-
session
.
js
"
)
;
var
_tensor_js__WEBPACK_IMPORTED_MODULE_3__
=
__webpack_require__
(
"
.
/
node_modules
/
onnxruntime
-
common
/
dist
/
esm
/
tensor
.
js
"
)
;
var
_tensor_conversion_js__WEBPACK_IMPORTED_MODULE_4__
=
__webpack_require__
(
"
.
/
node_modules
/
onnxruntime
-
common
/
dist
/
esm
/
tensor
-
conversion
.
js
"
)
;
var
_tensor_factory_js__WEBPACK_IMPORTED_MODULE_5__
=
__webpack_require__
(
"
.
/
node_modules
/
onnxruntime
-
common
/
dist
/
esm
/
tensor
-
factory
.
js
"
)
;
var
_trace_js__WEBPACK_IMPORTED_MODULE_6__
=
__webpack_require__
(
"
.
/
node_modules
/
onnxruntime
-
common
/
dist
/
esm
/
trace
.
js
"
)
;
var
_onnx_model_js__WEBPACK_IMPORTED_MODULE_7__
=
__webpack_require__
(
"
.
/
node_modules
/
onnxruntime
-
common
/
dist
/
esm
/
onnx
-
model
.
js
"
)
;
var
_onnx_value_js__WEBPACK_IMPORTED_MODULE_8__
=
__webpack_require__
(
"
.
/
node_modules
/
onnxruntime
-
common
/
dist
/
esm
/
onnx
-
value
.
js
"
)
;
var
_training_session_js__WEBPACK_IMPORTED_MODULE_9__
=
__webpack_require__
(
"
.
/
node_modules
/
onnxruntime
-
common
/
dist
/
esm
/
training
-
session
.
js
"
)
;
}
)
"
.
/
node_modules
/
onnxruntime
-
common
/
dist
/
esm
/
inference
-
session
-
impl
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
InferenceSession
:
(
)
=
>
(
InferenceSession
)
}
)
;
var
_backend_impl_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
node_modules
/
onnxruntime
-
common
/
dist
/
esm
/
backend
-
impl
.
js
"
)
;
var
_tensor_js__WEBPACK_IMPORTED_MODULE_1__
=
__webpack_require__
(
"
.
/
node_modules
/
onnxruntime
-
common
/
dist
/
esm
/
tensor
.
js
"
)
;
var
_trace_js__WEBPACK_IMPORTED_MODULE_2__
=
__webpack_require__
(
"
.
/
node_modules
/
onnxruntime
-
common
/
dist
/
esm
/
trace
.
js
"
)
;
class
InferenceSession
{
constructor
(
handler
)
{
this
.
handler
=
handler
;
}
async
run
(
feeds
arg1
arg2
)
{
(
0
_trace_js__WEBPACK_IMPORTED_MODULE_2__
.
TRACE_FUNC_BEGIN
)
(
)
;
const
fetches
=
{
}
;
let
options
=
{
}
;
if
(
typeof
feeds
!
=
=
'
object
'
|
|
feeds
=
=
=
null
|
|
feeds
instanceof
_tensor_js__WEBPACK_IMPORTED_MODULE_1__
.
Tensor
|
|
Array
.
isArray
(
feeds
)
)
{
throw
new
TypeError
(
"
'
feeds
'
must
be
an
object
that
use
input
names
as
keys
and
OnnxValue
as
corresponding
values
.
"
)
;
}
let
isFetchesEmpty
=
true
;
if
(
typeof
arg1
=
=
=
'
object
'
)
{
if
(
arg1
=
=
=
null
)
{
throw
new
TypeError
(
'
Unexpected
argument
[
1
]
:
cannot
be
null
.
'
)
;
}
if
(
arg1
instanceof
_tensor_js__WEBPACK_IMPORTED_MODULE_1__
.
Tensor
)
{
throw
new
TypeError
(
"
'
fetches
'
cannot
be
a
Tensor
"
)
;
}
if
(
Array
.
isArray
(
arg1
)
)
{
if
(
arg1
.
length
=
=
=
0
)
{
throw
new
TypeError
(
"
'
fetches
'
cannot
be
an
empty
array
.
"
)
;
}
isFetchesEmpty
=
false
;
for
(
const
name
of
arg1
)
{
if
(
typeof
name
!
=
=
'
string
'
)
{
throw
new
TypeError
(
"
'
fetches
'
must
be
a
string
array
or
an
object
.
"
)
;
}
if
(
this
.
outputNames
.
indexOf
(
name
)
=
=
=
-
1
)
{
throw
new
RangeError
(
'
fetches
'
contains
invalid
output
name
:
{
name
}
.
)
;
}
fetches
[
name
]
=
null
;
}
if
(
typeof
arg2
=
=
=
'
object
'
&
&
arg2
!
=
=
null
)
{
options
=
arg2
;
}
else
if
(
typeof
arg2
!
=
=
'
undefined
'
)
{
throw
new
TypeError
(
"
'
options
'
must
be
an
object
.
"
)
;
}
}
else
{
let
isFetches
=
false
;
const
arg1Keys
=
Object
.
getOwnPropertyNames
(
arg1
)
;
for
(
const
name
of
this
.
outputNames
)
{
if
(
arg1Keys
.
indexOf
(
name
)
!
=
=
-
1
)
{
const
v
=
arg1
[
name
]
;
if
(
v
=
=
=
null
|
|
v
instanceof
_tensor_js__WEBPACK_IMPORTED_MODULE_1__
.
Tensor
)
{
isFetches
=
true
;
isFetchesEmpty
=
false
;
fetches
[
name
]
=
v
;
}
}
}
if
(
isFetches
)
{
if
(
typeof
arg2
=
=
=
'
object
'
&
&
arg2
!
=
=
null
)
{
options
=
arg2
;
}
else
if
(
typeof
arg2
!
=
=
'
undefined
'
)
{
throw
new
TypeError
(
"
'
options
'
must
be
an
object
.
"
)
;
}
}
else
{
options
=
arg1
;
}
}
}
else
if
(
typeof
arg1
!
=
=
'
undefined
'
)
{
throw
new
TypeError
(
"
Unexpected
argument
[
1
]
:
must
be
'
fetches
'
or
'
options
'
.
"
)
;
}
for
(
const
name
of
this
.
inputNames
)
{
if
(
typeof
feeds
[
name
]
=
=
=
'
undefined
'
)
{
throw
new
Error
(
input
'
{
name
}
'
is
missing
in
'
feeds
'
.
)
;
}
}
if
(
isFetchesEmpty
)
{
for
(
const
name
of
this
.
outputNames
)
{
fetches
[
name
]
=
null
;
}
}
const
results
=
await
this
.
handler
.
run
(
feeds
fetches
options
)
;
const
returnValue
=
{
}
;
for
(
const
key
in
results
)
{
if
(
Object
.
hasOwnProperty
.
call
(
results
key
)
)
{
const
result
=
results
[
key
]
;
if
(
result
instanceof
_tensor_js__WEBPACK_IMPORTED_MODULE_1__
.
Tensor
)
{
returnValue
[
key
]
=
result
;
}
else
{
returnValue
[
key
]
=
new
_tensor_js__WEBPACK_IMPORTED_MODULE_1__
.
Tensor
(
result
.
type
result
.
data
result
.
dims
)
;
}
}
}
(
0
_trace_js__WEBPACK_IMPORTED_MODULE_2__
.
TRACE_FUNC_END
)
(
)
;
return
returnValue
;
}
async
release
(
)
{
return
this
.
handler
.
dispose
(
)
;
}
static
async
create
(
arg0
arg1
arg2
arg3
)
{
(
0
_trace_js__WEBPACK_IMPORTED_MODULE_2__
.
TRACE_FUNC_BEGIN
)
(
)
;
let
filePathOrUint8Array
;
let
options
=
{
}
;
if
(
typeof
arg0
=
=
=
'
string
'
)
{
filePathOrUint8Array
=
arg0
;
if
(
typeof
arg1
=
=
=
'
object
'
&
&
arg1
!
=
=
null
)
{
options
=
arg1
;
}
else
if
(
typeof
arg1
!
=
=
'
undefined
'
)
{
throw
new
TypeError
(
"
'
options
'
must
be
an
object
.
"
)
;
}
}
else
if
(
arg0
instanceof
Uint8Array
)
{
filePathOrUint8Array
=
arg0
;
if
(
typeof
arg1
=
=
=
'
object
'
&
&
arg1
!
=
=
null
)
{
options
=
arg1
;
}
else
if
(
typeof
arg1
!
=
=
'
undefined
'
)
{
throw
new
TypeError
(
"
'
options
'
must
be
an
object
.
"
)
;
}
}
else
if
(
arg0
instanceof
ArrayBuffer
|
|
(
typeof
SharedArrayBuffer
!
=
=
'
undefined
'
&
&
arg0
instanceof
SharedArrayBuffer
)
)
{
const
buffer
=
arg0
;
let
byteOffset
=
0
;
let
byteLength
=
arg0
.
byteLength
;
if
(
typeof
arg1
=
=
=
'
object
'
&
&
arg1
!
=
=
null
)
{
options
=
arg1
;
}
else
if
(
typeof
arg1
=
=
=
'
number
'
)
{
byteOffset
=
arg1
;
if
(
!
Number
.
isSafeInteger
(
byteOffset
)
)
{
throw
new
RangeError
(
"
'
byteOffset
'
must
be
an
integer
.
"
)
;
}
if
(
byteOffset
<
0
|
|
byteOffset
>
=
buffer
.
byteLength
)
{
throw
new
RangeError
(
'
byteOffset
'
is
out
of
range
[
0
{
buffer
.
byteLength
}
)
.
)
;
}
byteLength
=
arg0
.
byteLength
-
byteOffset
;
if
(
typeof
arg2
=
=
=
'
number
'
)
{
byteLength
=
arg2
;
if
(
!
Number
.
isSafeInteger
(
byteLength
)
)
{
throw
new
RangeError
(
"
'
byteLength
'
must
be
an
integer
.
"
)
;
}
if
(
byteLength
<
=
0
|
|
byteOffset
+
byteLength
>
buffer
.
byteLength
)
{
throw
new
RangeError
(
'
byteLength
'
is
out
of
range
(
0
{
buffer
.
byteLength
-
byteOffset
}
]
.
)
;
}
if
(
typeof
arg3
=
=
=
'
object
'
&
&
arg3
!
=
=
null
)
{
options
=
arg3
;
}
else
if
(
typeof
arg3
!
=
=
'
undefined
'
)
{
throw
new
TypeError
(
"
'
options
'
must
be
an
object
.
"
)
;
}
}
else
if
(
typeof
arg2
!
=
=
'
undefined
'
)
{
throw
new
TypeError
(
"
'
byteLength
'
must
be
a
number
.
"
)
;
}
}
else
if
(
typeof
arg1
!
=
=
'
undefined
'
)
{
throw
new
TypeError
(
"
'
options
'
must
be
an
object
.
"
)
;
}
filePathOrUint8Array
=
new
Uint8Array
(
buffer
byteOffset
byteLength
)
;
}
else
{
throw
new
TypeError
(
"
Unexpected
argument
[
0
]
:
must
be
'
path
'
or
'
buffer
'
.
"
)
;
}
const
[
backend
optionsWithValidatedEPs
]
=
await
(
0
_backend_impl_js__WEBPACK_IMPORTED_MODULE_0__
.
resolveBackendAndExecutionProviders
)
(
options
)
;
const
handler
=
await
backend
.
createInferenceSessionHandler
(
filePathOrUint8Array
optionsWithValidatedEPs
)
;
(
0
_trace_js__WEBPACK_IMPORTED_MODULE_2__
.
TRACE_FUNC_END
)
(
)
;
return
new
InferenceSession
(
handler
)
;
}
startProfiling
(
)
{
this
.
handler
.
startProfiling
(
)
;
}
endProfiling
(
)
{
this
.
handler
.
endProfiling
(
)
;
}
get
inputNames
(
)
{
return
this
.
handler
.
inputNames
;
}
get
outputNames
(
)
{
return
this
.
handler
.
outputNames
;
}
}
}
)
"
.
/
node_modules
/
onnxruntime
-
common
/
dist
/
esm
/
inference
-
session
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
InferenceSession
:
(
)
=
>
(
InferenceSession
)
}
)
;
var
_inference_session_impl_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
node_modules
/
onnxruntime
-
common
/
dist
/
esm
/
inference
-
session
-
impl
.
js
"
)
;
const
InferenceSession
=
_inference_session_impl_js__WEBPACK_IMPORTED_MODULE_0__
.
InferenceSession
;
}
)
"
.
/
node_modules
/
onnxruntime
-
common
/
dist
/
esm
/
onnx
-
model
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
}
)
"
.
/
node_modules
/
onnxruntime
-
common
/
dist
/
esm
/
onnx
-
value
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
}
)
"
.
/
node_modules
/
onnxruntime
-
common
/
dist
/
esm
/
tensor
-
conversion
-
impl
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
tensorToDataURL
:
(
)
=
>
(
tensorToDataURL
)
tensorToImageData
:
(
)
=
>
(
tensorToImageData
)
}
)
;
const
tensorToDataURL
=
(
tensor
options
)
=
>
{
const
canvas
=
typeof
document
!
=
=
'
undefined
'
?
document
.
createElement
(
'
canvas
'
)
:
new
OffscreenCanvas
(
1
1
)
;
canvas
.
width
=
tensor
.
dims
[
3
]
;
canvas
.
height
=
tensor
.
dims
[
2
]
;
const
pixels2DContext
=
canvas
.
getContext
(
'
2d
'
)
;
if
(
pixels2DContext
!
=
null
)
{
let
width
;
let
height
;
if
(
options
?
.
tensorLayout
!
=
=
undefined
&
&
options
.
tensorLayout
=
=
=
'
NHWC
'
)
{
width
=
tensor
.
dims
[
2
]
;
height
=
tensor
.
dims
[
3
]
;
}
else
{
width
=
tensor
.
dims
[
3
]
;
height
=
tensor
.
dims
[
2
]
;
}
const
inputformat
=
options
?
.
format
!
=
=
undefined
?
options
.
format
:
'
RGB
'
;
const
norm
=
options
?
.
norm
;
let
normMean
;
let
normBias
;
if
(
norm
=
=
=
undefined
|
|
norm
.
mean
=
=
=
undefined
)
{
normMean
=
[
255
255
255
255
]
;
}
else
{
if
(
typeof
norm
.
mean
=
=
=
'
number
'
)
{
normMean
=
[
norm
.
mean
norm
.
mean
norm
.
mean
norm
.
mean
]
;
}
else
{
normMean
=
[
norm
.
mean
[
0
]
norm
.
mean
[
1
]
norm
.
mean
[
2
]
0
]
;
if
(
norm
.
mean
[
3
]
!
=
=
undefined
)
{
normMean
[
3
]
=
norm
.
mean
[
3
]
;
}
}
}
if
(
norm
=
=
=
undefined
|
|
norm
.
bias
=
=
=
undefined
)
{
normBias
=
[
0
0
0
0
]
;
}
else
{
if
(
typeof
norm
.
bias
=
=
=
'
number
'
)
{
normBias
=
[
norm
.
bias
norm
.
bias
norm
.
bias
norm
.
bias
]
;
}
else
{
normBias
=
[
norm
.
bias
[
0
]
norm
.
bias
[
1
]
norm
.
bias
[
2
]
0
]
;
if
(
norm
.
bias
[
3
]
!
=
=
undefined
)
{
normBias
[
3
]
=
norm
.
bias
[
3
]
;
}
}
}
const
stride
=
height
*
width
;
let
rTensorPointer
=
0
gTensorPointer
=
stride
bTensorPointer
=
stride
*
2
aTensorPointer
=
-
1
;
if
(
inputformat
=
=
=
'
RGBA
'
)
{
rTensorPointer
=
0
;
gTensorPointer
=
stride
;
bTensorPointer
=
stride
*
2
;
aTensorPointer
=
stride
*
3
;
}
else
if
(
inputformat
=
=
=
'
RGB
'
)
{
rTensorPointer
=
0
;
gTensorPointer
=
stride
;
bTensorPointer
=
stride
*
2
;
}
else
if
(
inputformat
=
=
=
'
RBG
'
)
{
rTensorPointer
=
0
;
bTensorPointer
=
stride
;
gTensorPointer
=
stride
*
2
;
}
for
(
let
i
=
0
;
i
<
height
;
i
+
+
)
{
for
(
let
j
=
0
;
j
<
width
;
j
+
+
)
{
const
R
=
(
tensor
.
data
[
rTensorPointer
+
+
]
-
normBias
[
0
]
)
*
normMean
[
0
]
;
const
G
=
(
tensor
.
data
[
gTensorPointer
+
+
]
-
normBias
[
1
]
)
*
normMean
[
1
]
;
const
B
=
(
tensor
.
data
[
bTensorPointer
+
+
]
-
normBias
[
2
]
)
*
normMean
[
2
]
;
const
A
=
aTensorPointer
=
=
=
-
1
?
255
:
(
tensor
.
data
[
aTensorPointer
+
+
]
-
normBias
[
3
]
)
*
normMean
[
3
]
;
pixels2DContext
.
fillStyle
=
'
rgba
(
'
+
R
+
'
'
+
G
+
'
'
+
B
+
'
'
+
A
+
'
)
'
;
pixels2DContext
.
fillRect
(
j
i
1
1
)
;
}
}
if
(
'
toDataURL
'
in
canvas
)
{
return
canvas
.
toDataURL
(
)
;
}
else
{
throw
new
Error
(
'
toDataURL
is
not
supported
'
)
;
}
}
else
{
throw
new
Error
(
'
Can
not
access
image
data
'
)
;
}
}
;
const
tensorToImageData
=
(
tensor
options
)
=
>
{
const
pixels2DContext
=
typeof
document
!
=
=
'
undefined
'
?
document
.
createElement
(
'
canvas
'
)
.
getContext
(
'
2d
'
)
:
new
OffscreenCanvas
(
1
1
)
.
getContext
(
'
2d
'
)
;
let
image
;
if
(
pixels2DContext
!
=
null
)
{
let
width
;
let
height
;
let
channels
;
if
(
options
?
.
tensorLayout
!
=
=
undefined
&
&
options
.
tensorLayout
=
=
=
'
NHWC
'
)
{
width
=
tensor
.
dims
[
2
]
;
height
=
tensor
.
dims
[
1
]
;
channels
=
tensor
.
dims
[
3
]
;
}
else
{
width
=
tensor
.
dims
[
3
]
;
height
=
tensor
.
dims
[
2
]
;
channels
=
tensor
.
dims
[
1
]
;
}
const
inputformat
=
options
!
=
=
undefined
?
(
options
.
format
!
=
=
undefined
?
options
.
format
:
'
RGB
'
)
:
'
RGB
'
;
const
norm
=
options
?
.
norm
;
let
normMean
;
let
normBias
;
if
(
norm
=
=
=
undefined
|
|
norm
.
mean
=
=
=
undefined
)
{
normMean
=
[
255
255
255
255
]
;
}
else
{
if
(
typeof
norm
.
mean
=
=
=
'
number
'
)
{
normMean
=
[
norm
.
mean
norm
.
mean
norm
.
mean
norm
.
mean
]
;
}
else
{
normMean
=
[
norm
.
mean
[
0
]
norm
.
mean
[
1
]
norm
.
mean
[
2
]
255
]
;
if
(
norm
.
mean
[
3
]
!
=
=
undefined
)
{
normMean
[
3
]
=
norm
.
mean
[
3
]
;
}
}
}
if
(
norm
=
=
=
undefined
|
|
norm
.
bias
=
=
=
undefined
)
{
normBias
=
[
0
0
0
0
]
;
}
else
{
if
(
typeof
norm
.
bias
=
=
=
'
number
'
)
{
normBias
=
[
norm
.
bias
norm
.
bias
norm
.
bias
norm
.
bias
]
;
}
else
{
normBias
=
[
norm
.
bias
[
0
]
norm
.
bias
[
1
]
norm
.
bias
[
2
]
0
]
;
if
(
norm
.
bias
[
3
]
!
=
=
undefined
)
{
normBias
[
3
]
=
norm
.
bias
[
3
]
;
}
}
}
const
stride
=
height
*
width
;
if
(
options
!
=
=
undefined
)
{
if
(
(
options
.
format
!
=
=
undefined
&
&
channels
=
=
=
4
&
&
options
.
format
!
=
=
'
RGBA
'
)
|
|
(
channels
=
=
=
3
&
&
options
.
format
!
=
=
'
RGB
'
&
&
options
.
format
!
=
=
'
BGR
'
)
)
{
throw
new
Error
(
"
Tensor
format
doesn
'
t
match
input
tensor
dims
"
)
;
}
}
const
step
=
4
;
let
rImagePointer
=
0
gImagePointer
=
1
bImagePointer
=
2
aImagePointer
=
3
;
let
rTensorPointer
=
0
gTensorPointer
=
stride
bTensorPointer
=
stride
*
2
aTensorPointer
=
-
1
;
if
(
inputformat
=
=
=
'
RGBA
'
)
{
rTensorPointer
=
0
;
gTensorPointer
=
stride
;
bTensorPointer
=
stride
*
2
;
aTensorPointer
=
stride
*
3
;
}
else
if
(
inputformat
=
=
=
'
RGB
'
)
{
rTensorPointer
=
0
;
gTensorPointer
=
stride
;
bTensorPointer
=
stride
*
2
;
}
else
if
(
inputformat
=
=
=
'
RBG
'
)
{
rTensorPointer
=
0
;
bTensorPointer
=
stride
;
gTensorPointer
=
stride
*
2
;
}
image
=
pixels2DContext
.
createImageData
(
width
height
)
;
for
(
let
i
=
0
;
i
<
height
*
width
;
rImagePointer
+
=
step
gImagePointer
+
=
step
bImagePointer
+
=
step
aImagePointer
+
=
step
i
+
+
)
{
image
.
data
[
rImagePointer
]
=
(
tensor
.
data
[
rTensorPointer
+
+
]
-
normBias
[
0
]
)
*
normMean
[
0
]
;
image
.
data
[
gImagePointer
]
=
(
tensor
.
data
[
gTensorPointer
+
+
]
-
normBias
[
1
]
)
*
normMean
[
1
]
;
image
.
data
[
bImagePointer
]
=
(
tensor
.
data
[
bTensorPointer
+
+
]
-
normBias
[
2
]
)
*
normMean
[
2
]
;
image
.
data
[
aImagePointer
]
=
aTensorPointer
=
=
=
-
1
?
255
:
(
tensor
.
data
[
aTensorPointer
+
+
]
-
normBias
[
3
]
)
*
normMean
[
3
]
;
}
}
else
{
throw
new
Error
(
'
Can
not
access
image
data
'
)
;
}
return
image
;
}
;
}
)
"
.
/
node_modules
/
onnxruntime
-
common
/
dist
/
esm
/
tensor
-
conversion
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
}
)
"
.
/
node_modules
/
onnxruntime
-
common
/
dist
/
esm
/
tensor
-
factory
-
impl
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
bufferToTensor
:
(
)
=
>
(
bufferToTensor
)
tensorFromGpuBuffer
:
(
)
=
>
(
tensorFromGpuBuffer
)
tensorFromImage
:
(
)
=
>
(
tensorFromImage
)
tensorFromMLTensor
:
(
)
=
>
(
tensorFromMLTensor
)
tensorFromPinnedBuffer
:
(
)
=
>
(
tensorFromPinnedBuffer
)
tensorFromTexture
:
(
)
=
>
(
tensorFromTexture
)
}
)
;
var
_tensor_impl_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
node_modules
/
onnxruntime
-
common
/
dist
/
esm
/
tensor
-
impl
.
js
"
)
;
const
bufferToTensor
=
(
buffer
options
)
=
>
{
if
(
buffer
=
=
=
undefined
)
{
throw
new
Error
(
'
Image
buffer
must
be
defined
'
)
;
}
if
(
options
.
height
=
=
=
undefined
|
|
options
.
width
=
=
=
undefined
)
{
throw
new
Error
(
'
Image
height
and
width
must
be
defined
'
)
;
}
if
(
options
.
tensorLayout
=
=
=
'
NHWC
'
)
{
throw
new
Error
(
'
NHWC
Tensor
layout
is
not
supported
yet
'
)
;
}
const
{
height
width
}
=
options
;
const
norm
=
options
.
norm
?
?
{
mean
:
255
bias
:
0
}
;
let
normMean
;
let
normBias
;
if
(
typeof
norm
.
mean
=
=
=
'
number
'
)
{
normMean
=
[
norm
.
mean
norm
.
mean
norm
.
mean
norm
.
mean
]
;
}
else
{
normMean
=
[
norm
.
mean
[
0
]
norm
.
mean
[
1
]
norm
.
mean
[
2
]
norm
.
mean
[
3
]
?
?
255
]
;
}
if
(
typeof
norm
.
bias
=
=
=
'
number
'
)
{
normBias
=
[
norm
.
bias
norm
.
bias
norm
.
bias
norm
.
bias
]
;
}
else
{
normBias
=
[
norm
.
bias
[
0
]
norm
.
bias
[
1
]
norm
.
bias
[
2
]
norm
.
bias
[
3
]
?
?
0
]
;
}
const
inputformat
=
options
.
format
!
=
=
undefined
?
options
.
format
:
'
RGBA
'
;
const
outputformat
=
options
.
tensorFormat
!
=
=
undefined
?
(
options
.
tensorFormat
!
=
=
undefined
?
options
.
tensorFormat
:
'
RGB
'
)
:
'
RGB
'
;
const
stride
=
height
*
width
;
const
float32Data
=
outputformat
=
=
=
'
RGBA
'
?
new
Float32Array
(
stride
*
4
)
:
new
Float32Array
(
stride
*
3
)
;
let
step
=
4
rImagePointer
=
0
gImagePointer
=
1
bImagePointer
=
2
aImagePointer
=
3
;
let
rTensorPointer
=
0
gTensorPointer
=
stride
bTensorPointer
=
stride
*
2
aTensorPointer
=
-
1
;
if
(
inputformat
=
=
=
'
RGB
'
)
{
step
=
3
;
rImagePointer
=
0
;
gImagePointer
=
1
;
bImagePointer
=
2
;
aImagePointer
=
-
1
;
}
if
(
outputformat
=
=
=
'
RGBA
'
)
{
aTensorPointer
=
stride
*
3
;
}
else
if
(
outputformat
=
=
=
'
RBG
'
)
{
rTensorPointer
=
0
;
bTensorPointer
=
stride
;
gTensorPointer
=
stride
*
2
;
}
else
if
(
outputformat
=
=
=
'
BGR
'
)
{
bTensorPointer
=
0
;
gTensorPointer
=
stride
;
rTensorPointer
=
stride
*
2
;
}
for
(
let
i
=
0
;
i
<
stride
;
i
+
+
rImagePointer
+
=
step
bImagePointer
+
=
step
gImagePointer
+
=
step
aImagePointer
+
=
step
)
{
float32Data
[
rTensorPointer
+
+
]
=
(
buffer
[
rImagePointer
]
+
normBias
[
0
]
)
/
normMean
[
0
]
;
float32Data
[
gTensorPointer
+
+
]
=
(
buffer
[
gImagePointer
]
+
normBias
[
1
]
)
/
normMean
[
1
]
;
float32Data
[
bTensorPointer
+
+
]
=
(
buffer
[
bImagePointer
]
+
normBias
[
2
]
)
/
normMean
[
2
]
;
if
(
aTensorPointer
!
=
=
-
1
&
&
aImagePointer
!
=
=
-
1
)
{
float32Data
[
aTensorPointer
+
+
]
=
(
buffer
[
aImagePointer
]
+
normBias
[
3
]
)
/
normMean
[
3
]
;
}
}
const
outputTensor
=
outputformat
=
=
=
'
RGBA
'
?
new
_tensor_impl_js__WEBPACK_IMPORTED_MODULE_0__
.
Tensor
(
'
float32
'
float32Data
[
1
4
height
width
]
)
:
new
_tensor_impl_js__WEBPACK_IMPORTED_MODULE_0__
.
Tensor
(
'
float32
'
float32Data
[
1
3
height
width
]
)
;
return
outputTensor
;
}
;
const
tensorFromImage
=
async
(
image
options
)
=
>
{
const
isHTMLImageEle
=
typeof
HTMLImageElement
!
=
=
'
undefined
'
&
&
image
instanceof
HTMLImageElement
;
const
isImageDataEle
=
typeof
ImageData
!
=
=
'
undefined
'
&
&
image
instanceof
ImageData
;
const
isImageBitmap
=
typeof
ImageBitmap
!
=
=
'
undefined
'
&
&
image
instanceof
ImageBitmap
;
const
isString
=
typeof
image
=
=
=
'
string
'
;
let
data
;
let
bufferToTensorOptions
=
options
?
?
{
}
;
const
createCanvas
=
(
)
=
>
{
if
(
typeof
document
!
=
=
'
undefined
'
)
{
return
document
.
createElement
(
'
canvas
'
)
;
}
else
if
(
typeof
OffscreenCanvas
!
=
=
'
undefined
'
)
{
return
new
OffscreenCanvas
(
1
1
)
;
}
else
{
throw
new
Error
(
'
Canvas
is
not
supported
'
)
;
}
}
;
const
createCanvasContext
=
(
canvas
)
=
>
{
if
(
typeof
HTMLCanvasElement
!
=
=
'
undefined
'
&
&
canvas
instanceof
HTMLCanvasElement
)
{
return
canvas
.
getContext
(
'
2d
'
)
;
}
else
if
(
canvas
instanceof
OffscreenCanvas
)
{
return
canvas
.
getContext
(
'
2d
'
)
;
}
else
{
return
null
;
}
}
;
if
(
isHTMLImageEle
)
{
const
canvas
=
createCanvas
(
)
;
canvas
.
width
=
image
.
width
;
canvas
.
height
=
image
.
height
;
const
pixels2DContext
=
createCanvasContext
(
canvas
)
;
if
(
pixels2DContext
!
=
null
)
{
let
height
=
image
.
height
;
let
width
=
image
.
width
;
if
(
options
!
=
=
undefined
&
&
options
.
resizedHeight
!
=
=
undefined
&
&
options
.
resizedWidth
!
=
=
undefined
)
{
height
=
options
.
resizedHeight
;
width
=
options
.
resizedWidth
;
}
if
(
options
!
=
=
undefined
)
{
bufferToTensorOptions
=
options
;
if
(
options
.
tensorFormat
!
=
=
undefined
)
{
throw
new
Error
(
'
Image
input
config
format
must
be
RGBA
for
HTMLImageElement
'
)
;
}
else
{
bufferToTensorOptions
.
tensorFormat
=
'
RGBA
'
;
}
bufferToTensorOptions
.
height
=
height
;
bufferToTensorOptions
.
width
=
width
;
}
else
{
bufferToTensorOptions
.
tensorFormat
=
'
RGBA
'
;
bufferToTensorOptions
.
height
=
height
;
bufferToTensorOptions
.
width
=
width
;
}
pixels2DContext
.
drawImage
(
image
0
0
)
;
data
=
pixels2DContext
.
getImageData
(
0
0
width
height
)
.
data
;
}
else
{
throw
new
Error
(
'
Can
not
access
image
data
'
)
;
}
}
else
if
(
isImageDataEle
)
{
let
height
;
let
width
;
if
(
options
!
=
=
undefined
&
&
options
.
resizedWidth
!
=
=
undefined
&
&
options
.
resizedHeight
!
=
=
undefined
)
{
height
=
options
.
resizedHeight
;
width
=
options
.
resizedWidth
;
}
else
{
height
=
image
.
height
;
width
=
image
.
width
;
}
if
(
options
!
=
=
undefined
)
{
bufferToTensorOptions
=
options
;
}
bufferToTensorOptions
.
format
=
'
RGBA
'
;
bufferToTensorOptions
.
height
=
height
;
bufferToTensorOptions
.
width
=
width
;
if
(
options
!
=
=
undefined
)
{
const
tempCanvas
=
createCanvas
(
)
;
tempCanvas
.
width
=
width
;
tempCanvas
.
height
=
height
;
const
pixels2DContext
=
createCanvasContext
(
tempCanvas
)
;
if
(
pixels2DContext
!
=
null
)
{
pixels2DContext
.
putImageData
(
image
0
0
)
;
data
=
pixels2DContext
.
getImageData
(
0
0
width
height
)
.
data
;
}
else
{
throw
new
Error
(
'
Can
not
access
image
data
'
)
;
}
}
else
{
data
=
image
.
data
;
}
}
else
if
(
isImageBitmap
)
{
if
(
options
=
=
=
undefined
)
{
throw
new
Error
(
'
Please
provide
image
config
with
format
for
Imagebitmap
'
)
;
}
const
canvas
=
createCanvas
(
)
;
canvas
.
width
=
image
.
width
;
canvas
.
height
=
image
.
height
;
const
pixels2DContext
=
createCanvasContext
(
canvas
)
;
if
(
pixels2DContext
!
=
null
)
{
const
height
=
image
.
height
;
const
width
=
image
.
width
;
pixels2DContext
.
drawImage
(
image
0
0
width
height
)
;
data
=
pixels2DContext
.
getImageData
(
0
0
width
height
)
.
data
;
bufferToTensorOptions
.
height
=
height
;
bufferToTensorOptions
.
width
=
width
;
return
bufferToTensor
(
data
bufferToTensorOptions
)
;
}
else
{
throw
new
Error
(
'
Can
not
access
image
data
'
)
;
}
}
else
if
(
isString
)
{
return
new
Promise
(
(
resolve
reject
)
=
>
{
const
canvas
=
createCanvas
(
)
;
const
context
=
createCanvasContext
(
canvas
)
;
if
(
!
image
|
|
!
context
)
{
return
reject
(
)
;
}
const
newImage
=
new
Image
(
)
;
newImage
.
crossOrigin
=
'
Anonymous
'
;
newImage
.
src
=
image
;
newImage
.
onload
=
(
)
=
>
{
canvas
.
width
=
newImage
.
width
;
canvas
.
height
=
newImage
.
height
;
context
.
drawImage
(
newImage
0
0
canvas
.
width
canvas
.
height
)
;
const
img
=
context
.
getImageData
(
0
0
canvas
.
width
canvas
.
height
)
;
bufferToTensorOptions
.
height
=
canvas
.
height
;
bufferToTensorOptions
.
width
=
canvas
.
width
;
resolve
(
bufferToTensor
(
img
.
data
bufferToTensorOptions
)
)
;
}
;
}
)
;
}
else
{
throw
new
Error
(
'
Input
data
provided
is
not
supported
-
aborted
tensor
creation
'
)
;
}
if
(
data
!
=
=
undefined
)
{
return
bufferToTensor
(
data
bufferToTensorOptions
)
;
}
else
{
throw
new
Error
(
'
Input
data
provided
is
not
supported
-
aborted
tensor
creation
'
)
;
}
}
;
const
tensorFromTexture
=
(
texture
options
)
=
>
{
const
{
width
height
download
dispose
}
=
options
;
const
dims
=
[
1
height
width
4
]
;
return
new
_tensor_impl_js__WEBPACK_IMPORTED_MODULE_0__
.
Tensor
(
{
location
:
'
texture
'
type
:
'
float32
'
texture
dims
download
dispose
}
)
;
}
;
const
tensorFromGpuBuffer
=
(
gpuBuffer
options
)
=
>
{
const
{
dataType
dims
download
dispose
}
=
options
;
return
new
_tensor_impl_js__WEBPACK_IMPORTED_MODULE_0__
.
Tensor
(
{
location
:
'
gpu
-
buffer
'
type
:
dataType
?
?
'
float32
'
gpuBuffer
dims
download
dispose
}
)
;
}
;
const
tensorFromMLTensor
=
(
mlTensor
options
)
=
>
{
const
{
dataType
dims
download
dispose
}
=
options
;
return
new
_tensor_impl_js__WEBPACK_IMPORTED_MODULE_0__
.
Tensor
(
{
location
:
'
ml
-
tensor
'
type
:
dataType
?
?
'
float32
'
mlTensor
dims
download
dispose
}
)
;
}
;
const
tensorFromPinnedBuffer
=
(
type
buffer
dims
)
=
>
new
_tensor_impl_js__WEBPACK_IMPORTED_MODULE_0__
.
Tensor
(
{
location
:
'
cpu
-
pinned
'
type
data
:
buffer
dims
:
dims
?
?
[
buffer
.
length
]
}
)
;
}
)
"
.
/
node_modules
/
onnxruntime
-
common
/
dist
/
esm
/
tensor
-
factory
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
}
)
"
.
/
node_modules
/
onnxruntime
-
common
/
dist
/
esm
/
tensor
-
impl
-
type
-
mapping
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP
:
(
)
=
>
(
NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP
)
NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP
:
(
)
=
>
(
NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP
)
checkTypedArray
:
(
)
=
>
(
checkTypedArray
)
}
)
;
const
NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP
=
new
Map
(
[
[
'
float32
'
Float32Array
]
[
'
uint8
'
Uint8Array
]
[
'
int8
'
Int8Array
]
[
'
uint16
'
Uint16Array
]
[
'
int16
'
Int16Array
]
[
'
int32
'
Int32Array
]
[
'
bool
'
Uint8Array
]
[
'
float64
'
Float64Array
]
[
'
uint32
'
Uint32Array
]
[
'
int4
'
Uint8Array
]
[
'
uint4
'
Uint8Array
]
]
)
;
const
NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP
=
new
Map
(
[
[
Float32Array
'
float32
'
]
[
Uint8Array
'
uint8
'
]
[
Int8Array
'
int8
'
]
[
Uint16Array
'
uint16
'
]
[
Int16Array
'
int16
'
]
[
Int32Array
'
int32
'
]
[
Float64Array
'
float64
'
]
[
Uint32Array
'
uint32
'
]
]
)
;
let
isTypedArrayChecked
=
false
;
const
checkTypedArray
=
(
)
=
>
{
if
(
!
isTypedArrayChecked
)
{
isTypedArrayChecked
=
true
;
const
isBigInt64ArrayAvailable
=
typeof
BigInt64Array
!
=
=
'
undefined
'
&
&
BigInt64Array
.
from
;
const
isBigUint64ArrayAvailable
=
typeof
BigUint64Array
!
=
=
'
undefined
'
&
&
BigUint64Array
.
from
;
const
isFloat16ArrayAvailable
=
typeof
Float16Array
!
=
=
'
undefined
'
&
&
Float16Array
.
from
;
if
(
isBigInt64ArrayAvailable
)
{
NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP
.
set
(
'
int64
'
BigInt64Array
)
;
NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP
.
set
(
BigInt64Array
'
int64
'
)
;
}
if
(
isBigUint64ArrayAvailable
)
{
NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP
.
set
(
'
uint64
'
BigUint64Array
)
;
NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP
.
set
(
BigUint64Array
'
uint64
'
)
;
}
if
(
isFloat16ArrayAvailable
)
{
NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP
.
set
(
'
float16
'
Float16Array
)
;
NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP
.
set
(
Float16Array
'
float16
'
)
;
}
else
{
NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP
.
set
(
'
float16
'
Uint16Array
)
;
}
}
}
;
}
)
"
.
/
node_modules
/
onnxruntime
-
common
/
dist
/
esm
/
tensor
-
impl
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
Tensor
:
(
)
=
>
(
Tensor
)
}
)
;
var
_tensor_conversion_impl_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
node_modules
/
onnxruntime
-
common
/
dist
/
esm
/
tensor
-
conversion
-
impl
.
js
"
)
;
var
_tensor_factory_impl_js__WEBPACK_IMPORTED_MODULE_1__
=
__webpack_require__
(
"
.
/
node_modules
/
onnxruntime
-
common
/
dist
/
esm
/
tensor
-
factory
-
impl
.
js
"
)
;
var
_tensor_impl_type_mapping_js__WEBPACK_IMPORTED_MODULE_2__
=
__webpack_require__
(
"
.
/
node_modules
/
onnxruntime
-
common
/
dist
/
esm
/
tensor
-
impl
-
type
-
mapping
.
js
"
)
;
var
_tensor_utils_impl_js__WEBPACK_IMPORTED_MODULE_3__
=
__webpack_require__
(
"
.
/
node_modules
/
onnxruntime
-
common
/
dist
/
esm
/
tensor
-
utils
-
impl
.
js
"
)
;
class
Tensor
{
constructor
(
arg0
arg1
arg2
)
{
(
0
_tensor_impl_type_mapping_js__WEBPACK_IMPORTED_MODULE_2__
.
checkTypedArray
)
(
)
;
let
type
;
let
dims
;
if
(
typeof
arg0
=
=
=
'
object
'
&
&
'
location
'
in
arg0
)
{
this
.
dataLocation
=
arg0
.
location
;
type
=
arg0
.
type
;
dims
=
arg0
.
dims
;
switch
(
arg0
.
location
)
{
case
'
cpu
-
pinned
'
:
{
const
expectedTypedArrayConstructor
=
_tensor_impl_type_mapping_js__WEBPACK_IMPORTED_MODULE_2__
.
NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP
.
get
(
type
)
;
if
(
!
expectedTypedArrayConstructor
)
{
throw
new
TypeError
(
unsupported
type
"
{
type
}
"
to
create
tensor
from
pinned
buffer
)
;
}
if
(
!
(
arg0
.
data
instanceof
expectedTypedArrayConstructor
)
)
{
throw
new
TypeError
(
buffer
should
be
of
type
{
expectedTypedArrayConstructor
.
name
}
)
;
}
this
.
cpuData
=
arg0
.
data
;
break
;
}
case
'
texture
'
:
{
if
(
type
!
=
=
'
float32
'
)
{
throw
new
TypeError
(
unsupported
type
"
{
type
}
"
to
create
tensor
from
texture
)
;
}
this
.
gpuTextureData
=
arg0
.
texture
;
this
.
downloader
=
arg0
.
download
;
this
.
disposer
=
arg0
.
dispose
;
break
;
}
case
'
gpu
-
buffer
'
:
{
if
(
type
!
=
=
'
float32
'
&
&
type
!
=
=
'
float16
'
&
&
type
!
=
=
'
int32
'
&
&
type
!
=
=
'
int64
'
&
&
type
!
=
=
'
uint32
'
&
&
type
!
=
=
'
uint8
'
&
&
type
!
=
=
'
bool
'
&
&
type
!
=
=
'
uint4
'
&
&
type
!
=
=
'
int4
'
)
{
throw
new
TypeError
(
unsupported
type
"
{
type
}
"
to
create
tensor
from
gpu
buffer
)
;
}
this
.
gpuBufferData
=
arg0
.
gpuBuffer
;
this
.
downloader
=
arg0
.
download
;
this
.
disposer
=
arg0
.
dispose
;
break
;
}
case
'
ml
-
tensor
'
:
{
if
(
type
!
=
=
'
float32
'
&
&
type
!
=
=
'
float16
'
&
&
type
!
=
=
'
int32
'
&
&
type
!
=
=
'
int64
'
&
&
type
!
=
=
'
uint32
'
&
&
type
!
=
=
'
uint64
'
&
&
type
!
=
=
'
int8
'
&
&
type
!
=
=
'
uint8
'
&
&
type
!
=
=
'
bool
'
)
{
throw
new
TypeError
(
unsupported
type
"
{
type
}
"
to
create
tensor
from
MLTensor
)
;
}
this
.
mlTensorData
=
arg0
.
mlTensor
;
this
.
downloader
=
arg0
.
download
;
this
.
disposer
=
arg0
.
dispose
;
break
;
}
default
:
throw
new
Error
(
Tensor
constructor
:
unsupported
location
'
{
this
.
dataLocation
}
'
)
;
}
}
else
{
let
data
;
let
maybeDims
;
if
(
typeof
arg0
=
=
=
'
string
'
)
{
type
=
arg0
;
maybeDims
=
arg2
;
if
(
arg0
=
=
=
'
string
'
)
{
if
(
!
Array
.
isArray
(
arg1
)
)
{
throw
new
TypeError
(
"
A
string
tensor
'
s
data
must
be
a
string
array
.
"
)
;
}
data
=
arg1
;
}
else
{
const
typedArrayConstructor
=
_tensor_impl_type_mapping_js__WEBPACK_IMPORTED_MODULE_2__
.
NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP
.
get
(
arg0
)
;
if
(
typedArrayConstructor
=
=
=
undefined
)
{
throw
new
TypeError
(
Unsupported
tensor
type
:
{
arg0
}
.
)
;
}
if
(
Array
.
isArray
(
arg1
)
)
{
if
(
(
arg0
=
=
=
'
float16
'
&
&
typedArrayConstructor
=
=
=
Uint16Array
)
|
|
arg0
=
=
=
'
uint4
'
|
|
arg0
=
=
=
'
int4
'
)
{
throw
new
TypeError
(
Creating
a
{
arg0
}
tensor
from
number
array
is
not
supported
.
Please
use
{
typedArrayConstructor
.
name
}
as
data
.
)
;
}
else
if
(
arg0
=
=
=
'
uint64
'
|
|
arg0
=
=
=
'
int64
'
)
{
data
=
typedArrayConstructor
.
from
(
arg1
BigInt
)
;
}
else
{
data
=
typedArrayConstructor
.
from
(
arg1
)
;
}
}
else
if
(
arg1
instanceof
typedArrayConstructor
)
{
data
=
arg1
;
}
else
if
(
arg1
instanceof
Uint8ClampedArray
)
{
if
(
arg0
=
=
=
'
uint8
'
)
{
data
=
Uint8Array
.
from
(
arg1
)
;
}
else
{
throw
new
TypeError
(
A
Uint8ClampedArray
tensor
'
s
data
must
be
type
of
uint8
)
;
}
}
else
{
throw
new
TypeError
(
A
{
type
}
tensor
'
s
data
must
be
type
of
{
typedArrayConstructor
}
)
;
}
}
}
else
{
maybeDims
=
arg1
;
if
(
Array
.
isArray
(
arg0
)
)
{
if
(
arg0
.
length
=
=
=
0
)
{
throw
new
TypeError
(
'
Tensor
type
cannot
be
inferred
from
an
empty
array
.
'
)
;
}
const
firstElementType
=
typeof
arg0
[
0
]
;
if
(
firstElementType
=
=
=
'
string
'
)
{
type
=
'
string
'
;
data
=
arg0
;
}
else
if
(
firstElementType
=
=
=
'
boolean
'
)
{
type
=
'
bool
'
;
data
=
Uint8Array
.
from
(
arg0
)
;
}
else
{
throw
new
TypeError
(
Invalid
element
type
of
data
array
:
{
firstElementType
}
.
)
;
}
}
else
if
(
arg0
instanceof
Uint8ClampedArray
)
{
type
=
'
uint8
'
;
data
=
Uint8Array
.
from
(
arg0
)
;
}
else
{
const
mappedType
=
_tensor_impl_type_mapping_js__WEBPACK_IMPORTED_MODULE_2__
.
NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP
.
get
(
arg0
.
constructor
)
;
if
(
mappedType
=
=
=
undefined
)
{
throw
new
TypeError
(
Unsupported
type
for
tensor
data
:
{
arg0
.
constructor
}
.
)
;
}
type
=
mappedType
;
data
=
arg0
;
}
}
if
(
maybeDims
=
=
=
undefined
)
{
maybeDims
=
[
data
.
length
]
;
}
else
if
(
!
Array
.
isArray
(
maybeDims
)
)
{
throw
new
TypeError
(
"
A
tensor
'
s
dims
must
be
a
number
array
"
)
;
}
dims
=
maybeDims
;
this
.
cpuData
=
data
;
this
.
dataLocation
=
'
cpu
'
;
}
const
size
=
(
0
_tensor_utils_impl_js__WEBPACK_IMPORTED_MODULE_3__
.
calculateSize
)
(
dims
)
;
if
(
this
.
cpuData
&
&
size
!
=
=
this
.
cpuData
.
length
)
{
if
(
(
type
=
=
=
'
uint4
'
|
|
type
=
=
=
'
int4
'
)
&
&
Math
.
ceil
(
size
/
2
)
=
=
=
this
.
cpuData
.
length
)
{
}
else
{
throw
new
Error
(
Tensor
'
s
size
(
{
size
}
)
does
not
match
data
length
(
{
this
.
cpuData
.
length
}
)
.
)
;
}
}
this
.
type
=
type
;
this
.
dims
=
dims
;
this
.
size
=
size
;
}
static
async
fromImage
(
image
options
)
{
return
(
0
_tensor_factory_impl_js__WEBPACK_IMPORTED_MODULE_1__
.
tensorFromImage
)
(
image
options
)
;
}
static
fromTexture
(
texture
options
)
{
return
(
0
_tensor_factory_impl_js__WEBPACK_IMPORTED_MODULE_1__
.
tensorFromTexture
)
(
texture
options
)
;
}
static
fromGpuBuffer
(
gpuBuffer
options
)
{
return
(
0
_tensor_factory_impl_js__WEBPACK_IMPORTED_MODULE_1__
.
tensorFromGpuBuffer
)
(
gpuBuffer
options
)
;
}
static
fromMLTensor
(
mlTensor
options
)
{
return
(
0
_tensor_factory_impl_js__WEBPACK_IMPORTED_MODULE_1__
.
tensorFromMLTensor
)
(
mlTensor
options
)
;
}
static
fromPinnedBuffer
(
type
buffer
dims
)
{
return
(
0
_tensor_factory_impl_js__WEBPACK_IMPORTED_MODULE_1__
.
tensorFromPinnedBuffer
)
(
type
buffer
dims
)
;
}
toDataURL
(
options
)
{
return
(
0
_tensor_conversion_impl_js__WEBPACK_IMPORTED_MODULE_0__
.
tensorToDataURL
)
(
this
options
)
;
}
toImageData
(
options
)
{
return
(
0
_tensor_conversion_impl_js__WEBPACK_IMPORTED_MODULE_0__
.
tensorToImageData
)
(
this
options
)
;
}
get
data
(
)
{
this
.
ensureValid
(
)
;
if
(
!
this
.
cpuData
)
{
throw
new
Error
(
'
The
data
is
not
on
CPU
.
Use
getData
(
)
to
download
GPU
data
to
CPU
'
+
'
or
use
texture
or
gpuBuffer
property
to
access
the
GPU
data
directly
.
'
)
;
}
return
this
.
cpuData
;
}
get
location
(
)
{
return
this
.
dataLocation
;
}
get
texture
(
)
{
this
.
ensureValid
(
)
;
if
(
!
this
.
gpuTextureData
)
{
throw
new
Error
(
'
The
data
is
not
stored
as
a
WebGL
texture
.
'
)
;
}
return
this
.
gpuTextureData
;
}
get
gpuBuffer
(
)
{
this
.
ensureValid
(
)
;
if
(
!
this
.
gpuBufferData
)
{
throw
new
Error
(
'
The
data
is
not
stored
as
a
WebGPU
buffer
.
'
)
;
}
return
this
.
gpuBufferData
;
}
get
mlTensor
(
)
{
this
.
ensureValid
(
)
;
if
(
!
this
.
mlTensorData
)
{
throw
new
Error
(
'
The
data
is
not
stored
as
a
WebNN
MLTensor
.
'
)
;
}
return
this
.
mlTensorData
;
}
async
getData
(
releaseData
)
{
this
.
ensureValid
(
)
;
switch
(
this
.
dataLocation
)
{
case
'
cpu
'
:
case
'
cpu
-
pinned
'
:
return
this
.
data
;
case
'
texture
'
:
case
'
gpu
-
buffer
'
:
case
'
ml
-
tensor
'
:
{
if
(
!
this
.
downloader
)
{
throw
new
Error
(
'
The
current
tensor
is
not
created
with
a
specified
data
downloader
.
'
)
;
}
if
(
this
.
isDownloading
)
{
throw
new
Error
(
'
The
current
tensor
is
being
downloaded
.
'
)
;
}
try
{
this
.
isDownloading
=
true
;
const
data
=
await
this
.
downloader
(
)
;
this
.
downloader
=
undefined
;
this
.
dataLocation
=
'
cpu
'
;
this
.
cpuData
=
data
;
if
(
releaseData
&
&
this
.
disposer
)
{
this
.
disposer
(
)
;
this
.
disposer
=
undefined
;
}
return
data
;
}
finally
{
this
.
isDownloading
=
false
;
}
}
default
:
throw
new
Error
(
cannot
get
data
from
location
:
{
this
.
dataLocation
}
)
;
}
}
dispose
(
)
{
if
(
this
.
isDownloading
)
{
throw
new
Error
(
'
The
current
tensor
is
being
downloaded
.
'
)
;
}
if
(
this
.
disposer
)
{
this
.
disposer
(
)
;
this
.
disposer
=
undefined
;
}
this
.
cpuData
=
undefined
;
this
.
gpuTextureData
=
undefined
;
this
.
gpuBufferData
=
undefined
;
this
.
mlTensorData
=
undefined
;
this
.
downloader
=
undefined
;
this
.
isDownloading
=
undefined
;
this
.
dataLocation
=
'
none
'
;
}
ensureValid
(
)
{
if
(
this
.
dataLocation
=
=
=
'
none
'
)
{
throw
new
Error
(
'
The
tensor
is
disposed
.
'
)
;
}
}
reshape
(
dims
)
{
this
.
ensureValid
(
)
;
if
(
this
.
downloader
|
|
this
.
disposer
)
{
throw
new
Error
(
'
Cannot
reshape
a
tensor
that
owns
GPU
resource
.
'
)
;
}
return
(
0
_tensor_utils_impl_js__WEBPACK_IMPORTED_MODULE_3__
.
tensorReshape
)
(
this
dims
)
;
}
}
}
)
"
.
/
node_modules
/
onnxruntime
-
common
/
dist
/
esm
/
tensor
-
utils
-
impl
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
calculateSize
:
(
)
=
>
(
calculateSize
)
tensorReshape
:
(
)
=
>
(
tensorReshape
)
}
)
;
var
_tensor_impl_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
node_modules
/
onnxruntime
-
common
/
dist
/
esm
/
tensor
-
impl
.
js
"
)
;
const
calculateSize
=
(
dims
)
=
>
{
let
size
=
1
;
for
(
let
i
=
0
;
i
<
dims
.
length
;
i
+
+
)
{
const
dim
=
dims
[
i
]
;
if
(
typeof
dim
!
=
=
'
number
'
|
|
!
Number
.
isSafeInteger
(
dim
)
)
{
throw
new
TypeError
(
dims
[
{
i
}
]
must
be
an
integer
got
:
{
dim
}
)
;
}
if
(
dim
<
0
)
{
throw
new
RangeError
(
dims
[
{
i
}
]
must
be
a
non
-
negative
integer
got
:
{
dim
}
)
;
}
size
*
=
dim
;
}
return
size
;
}
;
const
tensorReshape
=
(
tensor
dims
)
=
>
{
switch
(
tensor
.
location
)
{
case
'
cpu
'
:
return
new
_tensor_impl_js__WEBPACK_IMPORTED_MODULE_0__
.
Tensor
(
tensor
.
type
tensor
.
data
dims
)
;
case
'
cpu
-
pinned
'
:
return
new
_tensor_impl_js__WEBPACK_IMPORTED_MODULE_0__
.
Tensor
(
{
location
:
'
cpu
-
pinned
'
data
:
tensor
.
data
type
:
tensor
.
type
dims
}
)
;
case
'
texture
'
:
return
new
_tensor_impl_js__WEBPACK_IMPORTED_MODULE_0__
.
Tensor
(
{
location
:
'
texture
'
texture
:
tensor
.
texture
type
:
tensor
.
type
dims
}
)
;
case
'
gpu
-
buffer
'
:
return
new
_tensor_impl_js__WEBPACK_IMPORTED_MODULE_0__
.
Tensor
(
{
location
:
'
gpu
-
buffer
'
gpuBuffer
:
tensor
.
gpuBuffer
type
:
tensor
.
type
dims
}
)
;
case
'
ml
-
tensor
'
:
return
new
_tensor_impl_js__WEBPACK_IMPORTED_MODULE_0__
.
Tensor
(
{
location
:
'
ml
-
tensor
'
mlTensor
:
tensor
.
mlTensor
type
:
tensor
.
type
dims
}
)
;
default
:
throw
new
Error
(
tensorReshape
:
tensor
location
{
tensor
.
location
}
is
not
supported
)
;
}
}
;
}
)
"
.
/
node_modules
/
onnxruntime
-
common
/
dist
/
esm
/
tensor
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
Tensor
:
(
)
=
>
(
Tensor
)
}
)
;
var
_tensor_impl_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
node_modules
/
onnxruntime
-
common
/
dist
/
esm
/
tensor
-
impl
.
js
"
)
;
const
Tensor
=
_tensor_impl_js__WEBPACK_IMPORTED_MODULE_0__
.
Tensor
;
}
)
"
.
/
node_modules
/
onnxruntime
-
common
/
dist
/
esm
/
trace
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
TRACE
:
(
)
=
>
(
TRACE
)
TRACE_FUNC_BEGIN
:
(
)
=
>
(
TRACE_FUNC_BEGIN
)
TRACE_FUNC_END
:
(
)
=
>
(
TRACE_FUNC_END
)
}
)
;
var
_env_impl_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
node_modules
/
onnxruntime
-
common
/
dist
/
esm
/
env
-
impl
.
js
"
)
;
const
TRACE
=
(
deviceType
label
)
=
>
{
if
(
typeof
_env_impl_js__WEBPACK_IMPORTED_MODULE_0__
.
env
.
trace
=
=
=
'
undefined
'
?
!
_env_impl_js__WEBPACK_IMPORTED_MODULE_0__
.
env
.
wasm
.
trace
:
!
_env_impl_js__WEBPACK_IMPORTED_MODULE_0__
.
env
.
trace
)
{
return
;
}
console
.
timeStamp
(
{
deviceType
}
:
:
ORT
:
:
{
label
}
)
;
}
;
const
TRACE_FUNC
=
(
msg
extraMsg
)
=
>
{
const
stack
=
new
Error
(
)
.
stack
?
.
split
(
/
\
r
\
n
|
\
r
|
\
n
/
g
)
|
|
[
]
;
let
hasTraceFunc
=
false
;
for
(
let
i
=
0
;
i
<
stack
.
length
;
i
+
+
)
{
if
(
hasTraceFunc
&
&
!
stack
[
i
]
.
includes
(
'
TRACE_FUNC
'
)
)
{
let
label
=
FUNC_
{
msg
}
:
:
{
stack
[
i
]
.
trim
(
)
.
split
(
'
'
)
[
1
]
}
;
if
(
extraMsg
)
{
label
+
=
:
:
{
extraMsg
}
;
}
TRACE
(
'
CPU
'
label
)
;
return
;
}
if
(
stack
[
i
]
.
includes
(
'
TRACE_FUNC
'
)
)
{
hasTraceFunc
=
true
;
}
}
}
;
const
TRACE_FUNC_BEGIN
=
(
extraMsg
)
=
>
{
if
(
typeof
_env_impl_js__WEBPACK_IMPORTED_MODULE_0__
.
env
.
trace
=
=
=
'
undefined
'
?
!
_env_impl_js__WEBPACK_IMPORTED_MODULE_0__
.
env
.
wasm
.
trace
:
!
_env_impl_js__WEBPACK_IMPORTED_MODULE_0__
.
env
.
trace
)
{
return
;
}
TRACE_FUNC
(
'
BEGIN
'
extraMsg
)
;
}
;
const
TRACE_FUNC_END
=
(
extraMsg
)
=
>
{
if
(
typeof
_env_impl_js__WEBPACK_IMPORTED_MODULE_0__
.
env
.
trace
=
=
=
'
undefined
'
?
!
_env_impl_js__WEBPACK_IMPORTED_MODULE_0__
.
env
.
wasm
.
trace
:
!
_env_impl_js__WEBPACK_IMPORTED_MODULE_0__
.
env
.
trace
)
{
return
;
}
TRACE_FUNC
(
'
END
'
extraMsg
)
;
}
;
}
)
"
.
/
node_modules
/
onnxruntime
-
common
/
dist
/
esm
/
training
-
session
-
impl
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
TrainingSession
:
(
)
=
>
(
TrainingSession
)
}
)
;
var
_backend_impl_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
node_modules
/
onnxruntime
-
common
/
dist
/
esm
/
backend
-
impl
.
js
"
)
;
var
_tensor_js__WEBPACK_IMPORTED_MODULE_1__
=
__webpack_require__
(
"
.
/
node_modules
/
onnxruntime
-
common
/
dist
/
esm
/
tensor
.
js
"
)
;
const
noBackendErrMsg
=
'
Training
backend
could
not
be
resolved
.
'
+
"
Make
sure
you
'
re
using
the
correct
configuration
&
WebAssembly
files
.
"
;
class
TrainingSession
{
constructor
(
handler
hasOptimizerModel
hasEvalModel
)
{
this
.
handler
=
handler
;
this
.
hasOptimizerModel
=
hasOptimizerModel
;
this
.
hasEvalModel
=
hasEvalModel
;
}
get
trainingInputNames
(
)
{
return
this
.
handler
.
inputNames
;
}
get
trainingOutputNames
(
)
{
return
this
.
handler
.
outputNames
;
}
get
evalInputNames
(
)
{
if
(
this
.
hasEvalModel
)
{
return
this
.
handler
.
evalInputNames
;
}
else
{
throw
new
Error
(
'
This
training
session
has
no
evalModel
loaded
.
'
)
;
}
}
get
evalOutputNames
(
)
{
if
(
this
.
hasEvalModel
)
{
return
this
.
handler
.
evalOutputNames
;
}
else
{
throw
new
Error
(
'
This
training
session
has
no
evalModel
loaded
.
'
)
;
}
}
static
async
create
(
trainingOptions
sessionOptions
)
{
const
evalModel
=
trainingOptions
.
evalModel
|
|
'
'
;
const
optimizerModel
=
trainingOptions
.
optimizerModel
|
|
'
'
;
const
options
=
sessionOptions
|
|
{
}
;
const
[
backend
optionsWithValidatedEPs
]
=
await
(
0
_backend_impl_js__WEBPACK_IMPORTED_MODULE_0__
.
resolveBackendAndExecutionProviders
)
(
options
)
;
if
(
backend
.
createTrainingSessionHandler
)
{
const
handler
=
await
backend
.
createTrainingSessionHandler
(
trainingOptions
.
checkpointState
trainingOptions
.
trainModel
evalModel
optimizerModel
optionsWithValidatedEPs
)
;
return
new
TrainingSession
(
handler
!
!
trainingOptions
.
optimizerModel
!
!
trainingOptions
.
evalModel
)
;
}
else
{
throw
new
Error
(
noBackendErrMsg
)
;
}
}
typeNarrowingForRunStep
(
inputNames
outputNames
feeds
arg1
arg2
)
{
const
fetches
=
{
}
;
let
options
=
{
}
;
if
(
typeof
feeds
!
=
=
'
object
'
|
|
feeds
=
=
=
null
|
|
feeds
instanceof
_tensor_js__WEBPACK_IMPORTED_MODULE_1__
.
Tensor
|
|
Array
.
isArray
(
feeds
)
)
{
throw
new
TypeError
(
"
'
feeds
'
must
be
an
object
that
use
input
names
as
keys
and
OnnxValue
as
corresponding
values
.
"
)
;
}
let
isFetchesEmpty
=
true
;
if
(
typeof
arg1
=
=
=
'
object
'
)
{
if
(
arg1
=
=
=
null
)
{
throw
new
TypeError
(
'
Unexpected
argument
[
1
]
:
cannot
be
null
.
'
)
;
}
if
(
arg1
instanceof
_tensor_js__WEBPACK_IMPORTED_MODULE_1__
.
Tensor
)
{
throw
new
TypeError
(
"
'
fetches
'
cannot
be
a
Tensor
"
)
;
}
if
(
Array
.
isArray
(
arg1
)
)
{
if
(
arg1
.
length
=
=
=
0
)
{
throw
new
TypeError
(
"
'
fetches
'
cannot
be
an
empty
array
.
"
)
;
}
isFetchesEmpty
=
false
;
for
(
const
name
of
arg1
)
{
if
(
typeof
name
!
=
=
'
string
'
)
{
throw
new
TypeError
(
"
'
fetches
'
must
be
a
string
array
or
an
object
.
"
)
;
}
if
(
outputNames
.
indexOf
(
name
)
=
=
=
-
1
)
{
throw
new
RangeError
(
'
fetches
'
contains
invalid
output
name
:
{
name
}
.
)
;
}
fetches
[
name
]
=
null
;
}
if
(
typeof
arg2
=
=
=
'
object
'
&
&
arg2
!
=
=
null
)
{
options
=
arg2
;
}
else
if
(
typeof
arg2
!
=
=
'
undefined
'
)
{
throw
new
TypeError
(
"
'
options
'
must
be
an
object
.
"
)
;
}
}
else
{
let
isFetches
=
false
;
const
arg1Keys
=
Object
.
getOwnPropertyNames
(
arg1
)
;
for
(
const
name
of
outputNames
)
{
if
(
arg1Keys
.
indexOf
(
name
)
!
=
=
-
1
)
{
const
v
=
arg1
[
name
]
;
if
(
v
=
=
=
null
|
|
v
instanceof
_tensor_js__WEBPACK_IMPORTED_MODULE_1__
.
Tensor
)
{
isFetches
=
true
;
isFetchesEmpty
=
false
;
fetches
[
name
]
=
v
;
}
}
}
if
(
isFetches
)
{
if
(
typeof
arg2
=
=
=
'
object
'
&
&
arg2
!
=
=
null
)
{
options
=
arg2
;
}
else
if
(
typeof
arg2
!
=
=
'
undefined
'
)
{
throw
new
TypeError
(
"
'
options
'
must
be
an
object
.
"
)
;
}
}
else
{
options
=
arg1
;
}
}
}
else
if
(
typeof
arg1
!
=
=
'
undefined
'
)
{
throw
new
TypeError
(
"
Unexpected
argument
[
1
]
:
must
be
'
fetches
'
or
'
options
'
.
"
)
;
}
for
(
const
name
of
inputNames
)
{
if
(
typeof
feeds
[
name
]
=
=
=
'
undefined
'
)
{
throw
new
Error
(
input
'
{
name
}
'
is
missing
in
'
feeds
'
.
)
;
}
}
if
(
isFetchesEmpty
)
{
for
(
const
name
of
outputNames
)
{
fetches
[
name
]
=
null
;
}
}
return
[
fetches
options
]
;
}
convertHandlerReturnTypeToMapOfTensors
(
results
)
{
const
returnValue
=
{
}
;
for
(
const
key
in
results
)
{
if
(
Object
.
hasOwnProperty
.
call
(
results
key
)
)
{
const
result
=
results
[
key
]
;
if
(
result
instanceof
_tensor_js__WEBPACK_IMPORTED_MODULE_1__
.
Tensor
)
{
returnValue
[
key
]
=
result
;
}
else
{
returnValue
[
key
]
=
new
_tensor_js__WEBPACK_IMPORTED_MODULE_1__
.
Tensor
(
result
.
type
result
.
data
result
.
dims
)
;
}
}
}
return
returnValue
;
}
async
lazyResetGrad
(
)
{
await
this
.
handler
.
lazyResetGrad
(
)
;
}
async
runTrainStep
(
feeds
arg1
arg2
)
{
const
[
fetches
options
]
=
this
.
typeNarrowingForRunStep
(
this
.
trainingInputNames
this
.
trainingOutputNames
feeds
arg1
arg2
)
;
const
results
=
await
this
.
handler
.
runTrainStep
(
feeds
fetches
options
)
;
return
this
.
convertHandlerReturnTypeToMapOfTensors
(
results
)
;
}
async
runOptimizerStep
(
options
)
{
if
(
this
.
hasOptimizerModel
)
{
await
this
.
handler
.
runOptimizerStep
(
options
|
|
{
}
)
;
}
else
{
throw
new
Error
(
'
This
TrainingSession
has
no
OptimizerModel
loaded
.
'
)
;
}
}
async
runEvalStep
(
feeds
arg1
arg2
)
{
if
(
this
.
hasEvalModel
)
{
const
[
fetches
options
]
=
this
.
typeNarrowingForRunStep
(
this
.
evalInputNames
this
.
evalOutputNames
feeds
arg1
arg2
)
;
const
results
=
await
this
.
handler
.
runEvalStep
(
feeds
fetches
options
)
;
return
this
.
convertHandlerReturnTypeToMapOfTensors
(
results
)
;
}
else
{
throw
new
Error
(
'
This
TrainingSession
has
no
EvalModel
loaded
.
'
)
;
}
}
async
getParametersSize
(
trainableOnly
=
true
)
{
return
this
.
handler
.
getParametersSize
(
trainableOnly
)
;
}
async
loadParametersBuffer
(
array
trainableOnly
=
true
)
{
const
paramsSize
=
await
this
.
getParametersSize
(
trainableOnly
)
;
if
(
array
.
length
!
=
=
4
*
paramsSize
)
{
throw
new
Error
(
'
Size
of
the
buffer
passed
into
loadParametersBuffer
must
match
the
number
of
parameters
in
'
+
'
the
model
.
Please
use
getParametersSize
method
to
check
.
'
)
;
}
return
this
.
handler
.
loadParametersBuffer
(
array
trainableOnly
)
;
}
async
getContiguousParameters
(
trainableOnly
=
true
)
{
return
this
.
handler
.
getContiguousParameters
(
trainableOnly
)
;
}
async
release
(
)
{
return
this
.
handler
.
dispose
(
)
;
}
}
}
)
"
.
/
node_modules
/
onnxruntime
-
common
/
dist
/
esm
/
training
-
session
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
TrainingSession
:
(
)
=
>
(
TrainingSession
)
}
)
;
var
_training_session_impl_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
node_modules
/
onnxruntime
-
common
/
dist
/
esm
/
training
-
session
-
impl
.
js
"
)
;
const
TrainingSession
=
_training_session_impl_js__WEBPACK_IMPORTED_MODULE_0__
.
TrainingSession
;
}
)
"
.
/
node_modules
/
onnxruntime
-
common
/
dist
/
esm
/
version
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
version
:
(
)
=
>
(
version
)
}
)
;
const
version
=
'
1
.
20
.
1
'
;
}
)
"
.
/
src
/
backends
/
onnx
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
Tensor
:
(
)
=
>
(
onnxruntime_common__WEBPACK_IMPORTED_MODULE_2__
.
Tensor
)
createInferenceSession
:
(
)
=
>
(
createInferenceSession
)
deviceToExecutionProviders
:
(
)
=
>
(
deviceToExecutionProviders
)
isONNXProxy
:
(
)
=
>
(
isONNXProxy
)
isONNXTensor
:
(
)
=
>
(
isONNXTensor
)
}
)
;
var
_env_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
src
/
env
.
js
"
)
;
var
_onnxruntime_webgpu__WEBPACK_IMPORTED_MODULE_1__
=
__webpack_require__
(
"
#
onnxruntime
-
webgpu
"
)
;
var
onnxruntime_common__WEBPACK_IMPORTED_MODULE_2__
=
__webpack_require__
(
"
.
/
node_modules
/
onnxruntime
-
common
/
dist
/
esm
/
index
.
js
"
)
;
const
ONNX_NODE
=
null
;
const
DEVICE_TO_EXECUTION_PROVIDER_MAPPING
=
Object
.
freeze
(
{
auto
:
null
gpu
:
null
cpu
:
'
cpu
'
wasm
:
'
wasm
'
webgpu
:
'
webgpu
'
cuda
:
'
cuda
'
dml
:
'
dml
'
webnn
:
{
name
:
'
webnn
'
deviceType
:
'
cpu
'
}
'
webnn
-
npu
'
:
{
name
:
'
webnn
'
deviceType
:
'
npu
'
}
'
webnn
-
gpu
'
:
{
name
:
'
webnn
'
deviceType
:
'
gpu
'
}
'
webnn
-
cpu
'
:
{
name
:
'
webnn
'
deviceType
:
'
cpu
'
}
}
)
;
const
supportedDevices
=
[
]
;
let
defaultDevices
;
let
ONNX
;
const
ORT_SYMBOL
=
Symbol
.
for
(
'
onnxruntime
'
)
;
if
(
ORT_SYMBOL
in
globalThis
)
{
ONNX
=
globalThis
[
ORT_SYMBOL
]
;
}
else
if
(
_env_js__WEBPACK_IMPORTED_MODULE_0__
.
apis
.
IS_NODE_ENV
)
{
ONNX
=
ONNX_NODE
.
default
?
?
ONNX_NODE
;
switch
(
process
.
platform
)
{
case
'
win32
'
:
supportedDevices
.
push
(
'
dml
'
)
;
break
;
case
'
linux
'
:
if
(
process
.
arch
=
=
=
'
x64
'
)
{
supportedDevices
.
push
(
'
cuda
'
)
;
}
break
;
case
'
darwin
'
:
break
;
}
supportedDevices
.
push
(
'
cpu
'
)
;
defaultDevices
=
[
'
cpu
'
]
;
}
else
{
ONNX
=
_onnxruntime_webgpu__WEBPACK_IMPORTED_MODULE_1__
;
if
(
_env_js__WEBPACK_IMPORTED_MODULE_0__
.
apis
.
IS_WEBNN_AVAILABLE
)
{
supportedDevices
.
push
(
'
webnn
-
npu
'
'
webnn
-
gpu
'
'
webnn
-
cpu
'
'
webnn
'
)
;
}
if
(
_env_js__WEBPACK_IMPORTED_MODULE_0__
.
apis
.
IS_WEBGPU_AVAILABLE
)
{
supportedDevices
.
push
(
'
webgpu
'
)
;
}
supportedDevices
.
push
(
'
wasm
'
)
;
defaultDevices
=
[
'
wasm
'
]
;
}
const
InferenceSession
=
ONNX
.
InferenceSession
;
function
deviceToExecutionProviders
(
device
=
null
)
{
if
(
!
device
)
return
defaultDevices
;
switch
(
device
)
{
case
"
auto
"
:
return
supportedDevices
;
case
"
gpu
"
:
return
supportedDevices
.
filter
(
x
=
>
[
"
webgpu
"
"
cuda
"
"
dml
"
"
webnn
-
gpu
"
]
.
includes
(
x
)
)
;
}
if
(
supportedDevices
.
includes
(
device
)
)
{
return
[
DEVICE_TO_EXECUTION_PROVIDER_MAPPING
[
device
]
?
?
device
]
;
}
throw
new
Error
(
Unsupported
device
:
"
{
device
}
"
.
Should
be
one
of
:
{
supportedDevices
.
join
(
'
'
)
}
.
)
}
let
wasmInitPromise
=
null
;
async
function
createInferenceSession
(
buffer
session_options
session_config
)
{
if
(
wasmInitPromise
)
{
await
wasmInitPromise
;
}
const
sessionPromise
=
InferenceSession
.
create
(
buffer
session_options
)
;
wasmInitPromise
?
?
=
sessionPromise
;
const
session
=
await
sessionPromise
;
session
.
config
=
session_config
;
return
session
;
}
function
isONNXTensor
(
x
)
{
return
x
instanceof
ONNX
.
Tensor
;
}
const
ONNX_ENV
=
ONNX
?
.
env
;
if
(
ONNX_ENV
?
.
wasm
)
{
ONNX_ENV
.
wasm
.
wasmPaths
=
https
:
/
/
cdn
.
jsdelivr
.
net
/
npm
/
huggingface
/
transformers
{
_env_js__WEBPACK_IMPORTED_MODULE_0__
.
env
.
version
}
/
dist
/
;
ONNX_ENV
.
wasm
.
proxy
=
false
;
if
(
typeof
crossOriginIsolated
=
=
=
'
undefined
'
|
|
!
crossOriginIsolated
)
{
ONNX_ENV
.
wasm
.
numThreads
=
1
;
}
}
if
(
ONNX_ENV
?
.
webgpu
)
{
ONNX_ENV
.
webgpu
.
powerPreference
=
'
high
-
performance
'
;
}
function
isONNXProxy
(
)
{
return
ONNX_ENV
?
.
wasm
?
.
proxy
;
}
_env_js__WEBPACK_IMPORTED_MODULE_0__
.
env
.
backends
.
onnx
=
ONNX_ENV
;
}
)
"
.
/
src
/
base
/
feature_extraction_utils
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
FeatureExtractor
:
(
)
=
>
(
FeatureExtractor
)
validate_audio_inputs
:
(
)
=
>
(
validate_audio_inputs
)
}
)
;
var
_utils_constants_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
src
/
utils
/
constants
.
js
"
)
;
var
_utils_generic_js__WEBPACK_IMPORTED_MODULE_1__
=
__webpack_require__
(
"
.
/
src
/
utils
/
generic
.
js
"
)
;
var
_utils_hub_js__WEBPACK_IMPORTED_MODULE_2__
=
__webpack_require__
(
"
.
/
src
/
utils
/
hub
.
js
"
)
;
class
FeatureExtractor
extends
_utils_generic_js__WEBPACK_IMPORTED_MODULE_1__
.
Callable
{
constructor
(
config
)
{
super
(
)
;
this
.
config
=
config
}
static
async
from_pretrained
(
pretrained_model_name_or_path
options
)
{
const
preprocessorConfig
=
await
(
0
_utils_hub_js__WEBPACK_IMPORTED_MODULE_2__
.
getModelJSON
)
(
pretrained_model_name_or_path
_utils_constants_js__WEBPACK_IMPORTED_MODULE_0__
.
FEATURE_EXTRACTOR_NAME
true
options
)
;
return
new
this
(
preprocessorConfig
)
;
}
}
function
validate_audio_inputs
(
audio
feature_extractor
)
{
if
(
!
(
audio
instanceof
Float32Array
|
|
audio
instanceof
Float64Array
)
)
{
throw
new
Error
(
{
feature_extractor
}
expects
input
to
be
a
Float32Array
or
a
Float64Array
but
got
{
audio
?
.
constructor
?
.
name
?
?
typeof
audio
}
instead
.
+
If
using
the
feature
extractor
directly
remember
to
use
\
read_audio
(
url
sampling_rate
)
\
to
obtain
the
raw
audio
data
of
the
file
/
url
.
)
}
}
}
)
"
.
/
src
/
base
/
image_processors_utils
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
ImageProcessor
:
(
)
=
>
(
ImageProcessor
)
post_process_instance_segmentation
:
(
)
=
>
(
post_process_instance_segmentation
)
post_process_object_detection
:
(
)
=
>
(
post_process_object_detection
)
post_process_panoptic_segmentation
:
(
)
=
>
(
post_process_panoptic_segmentation
)
post_process_semantic_segmentation
:
(
)
=
>
(
post_process_semantic_segmentation
)
}
)
;
var
_utils_generic_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
src
/
utils
/
generic
.
js
"
)
;
var
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_1__
=
__webpack_require__
(
"
.
/
src
/
utils
/
tensor
.
js
"
)
;
var
_utils_maths_js__WEBPACK_IMPORTED_MODULE_2__
=
__webpack_require__
(
"
.
/
src
/
utils
/
maths
.
js
"
)
;
var
_utils_image_js__WEBPACK_IMPORTED_MODULE_3__
=
__webpack_require__
(
"
.
/
src
/
utils
/
image
.
js
"
)
;
var
_utils_core_js__WEBPACK_IMPORTED_MODULE_4__
=
__webpack_require__
(
"
.
/
src
/
utils
/
core
.
js
"
)
;
var
_utils_hub_js__WEBPACK_IMPORTED_MODULE_5__
=
__webpack_require__
(
"
.
/
src
/
utils
/
hub
.
js
"
)
;
var
_utils_constants_js__WEBPACK_IMPORTED_MODULE_6__
=
__webpack_require__
(
"
.
/
src
/
utils
/
constants
.
js
"
)
;
function
constraint_to_multiple_of
(
val
multiple
minVal
=
0
maxVal
=
null
)
{
const
a
=
val
/
multiple
;
let
x
=
(
0
_utils_maths_js__WEBPACK_IMPORTED_MODULE_2__
.
bankers_round
)
(
a
)
*
multiple
;
if
(
maxVal
!
=
=
null
&
&
x
>
maxVal
)
{
x
=
Math
.
floor
(
a
)
*
multiple
;
}
if
(
x
<
minVal
)
{
x
=
Math
.
ceil
(
a
)
*
multiple
;
}
return
x
;
}
function
enforce_size_divisibility
(
[
width
height
]
divisor
)
{
return
[
Math
.
max
(
Math
.
floor
(
width
/
divisor
)
1
)
*
divisor
Math
.
max
(
Math
.
floor
(
height
/
divisor
)
1
)
*
divisor
]
;
}
function
center_to_corners_format
(
[
centerX
centerY
width
height
]
)
{
return
[
centerX
-
width
/
2
centerY
-
height
/
2
centerX
+
width
/
2
centerY
+
height
/
2
]
;
}
function
post_process_object_detection
(
outputs
threshold
=
0
.
5
target_sizes
=
null
is_zero_shot
=
false
)
{
const
out_logits
=
outputs
.
logits
;
const
out_bbox
=
outputs
.
pred_boxes
;
const
[
batch_size
num_boxes
num_classes
]
=
out_logits
.
dims
;
if
(
target_sizes
!
=
=
null
&
&
target_sizes
.
length
!
=
=
batch_size
)
{
throw
Error
(
"
Make
sure
that
you
pass
in
as
many
target
sizes
as
the
batch
dimension
of
the
logits
"
)
}
let
toReturn
=
[
]
;
for
(
let
i
=
0
;
i
<
batch_size
;
+
+
i
)
{
let
target_size
=
target_sizes
!
=
=
null
?
target_sizes
[
i
]
:
null
;
let
info
=
{
boxes
:
[
]
classes
:
[
]
scores
:
[
]
}
let
logits
=
out_logits
[
i
]
;
let
bbox
=
out_bbox
[
i
]
;
for
(
let
j
=
0
;
j
<
num_boxes
;
+
+
j
)
{
let
logit
=
logits
[
j
]
;
let
indices
=
[
]
;
let
probs
;
if
(
is_zero_shot
)
{
probs
=
logit
.
sigmoid
(
)
.
data
;
for
(
let
k
=
0
;
k
<
probs
.
length
;
+
+
k
)
{
if
(
probs
[
k
]
>
threshold
)
{
indices
.
push
(
k
)
;
}
}
}
else
{
let
maxIndex
=
(
0
_utils_maths_js__WEBPACK_IMPORTED_MODULE_2__
.
max
)
(
logit
.
data
)
[
1
]
;
if
(
maxIndex
=
=
=
num_classes
-
1
)
{
continue
;
}
probs
=
(
0
_utils_maths_js__WEBPACK_IMPORTED_MODULE_2__
.
softmax
)
(
logit
.
data
)
;
if
(
probs
[
maxIndex
]
<
threshold
)
{
continue
;
}
indices
.
push
(
maxIndex
)
;
}
for
(
const
index
of
indices
)
{
let
box
=
bbox
[
j
]
.
data
;
box
=
center_to_corners_format
(
box
)
if
(
target_size
!
=
=
null
)
{
box
=
box
.
map
(
(
x
i
)
=
>
x
*
target_size
[
(
i
+
1
)
%
2
]
)
}
info
.
boxes
.
push
(
box
)
;
info
.
classes
.
push
(
index
)
;
info
.
scores
.
push
(
probs
[
index
]
)
;
}
}
toReturn
.
push
(
info
)
;
}
return
toReturn
;
}
function
post_process_semantic_segmentation
(
outputs
target_sizes
=
null
)
{
const
logits
=
outputs
.
logits
;
const
batch_size
=
logits
.
dims
[
0
]
;
if
(
target_sizes
!
=
=
null
&
&
target_sizes
.
length
!
=
=
batch_size
)
{
throw
Error
(
"
Make
sure
that
you
pass
in
as
many
target
sizes
as
the
batch
dimension
of
the
logits
"
)
}
const
toReturn
=
[
]
;
for
(
let
i
=
0
;
i
<
batch_size
;
+
+
i
)
{
const
target_size
=
target_sizes
!
=
=
null
?
target_sizes
[
i
]
:
null
;
let
data
=
logits
[
i
]
;
if
(
target_size
!
=
=
null
)
{
data
=
(
0
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_1__
.
interpolate
)
(
data
target_size
'
bilinear
'
false
)
;
}
const
[
height
width
]
=
target_size
?
?
data
.
dims
.
slice
(
-
2
)
;
const
segmentation
=
new
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_1__
.
Tensor
(
'
int32
'
new
Int32Array
(
height
*
width
)
[
height
width
]
)
;
const
buffer
=
data
[
0
]
.
data
;
const
segmentation_data
=
segmentation
.
data
;
for
(
let
j
=
1
;
j
<
data
.
dims
[
0
]
;
+
+
j
)
{
const
row
=
data
[
j
]
.
data
;
for
(
let
k
=
0
;
k
<
row
.
length
;
+
+
k
)
{
if
(
row
[
k
]
>
buffer
[
k
]
)
{
buffer
[
k
]
=
row
[
k
]
;
segmentation_data
[
k
]
=
j
;
}
}
}
const
hasLabel
=
new
Array
(
data
.
dims
[
0
]
)
;
for
(
let
j
=
0
;
j
<
segmentation_data
.
length
;
+
+
j
)
{
const
index
=
segmentation_data
[
j
]
;
hasLabel
[
index
]
=
index
;
}
const
labels
=
hasLabel
.
filter
(
x
=
>
x
!
=
=
undefined
)
;
toReturn
.
push
(
{
segmentation
labels
}
)
;
}
return
toReturn
;
}
function
remove_low_and_no_objects
(
class_logits
mask_logits
object_mask_threshold
num_labels
)
{
const
mask_probs_item
=
[
]
;
const
pred_scores_item
=
[
]
;
const
pred_labels_item
=
[
]
;
for
(
let
j
=
0
;
j
<
class_logits
.
dims
[
0
]
;
+
+
j
)
{
const
cls
=
class_logits
[
j
]
;
const
mask
=
mask_logits
[
j
]
;
const
pred_label
=
(
0
_utils_maths_js__WEBPACK_IMPORTED_MODULE_2__
.
max
)
(
cls
.
data
)
[
1
]
;
if
(
pred_label
=
=
=
num_labels
)
{
continue
;
}
const
scores
=
(
0
_utils_maths_js__WEBPACK_IMPORTED_MODULE_2__
.
softmax
)
(
cls
.
data
)
;
const
pred_score
=
scores
[
pred_label
]
;
if
(
pred_score
>
object_mask_threshold
)
{
mask_probs_item
.
push
(
mask
)
;
pred_scores_item
.
push
(
pred_score
)
;
pred_labels_item
.
push
(
pred_label
)
;
}
}
return
[
mask_probs_item
pred_scores_item
pred_labels_item
]
;
}
function
check_segment_validity
(
mask_labels
mask_probs
k
mask_threshold
=
0
.
5
overlap_mask_area_threshold
=
0
.
8
)
{
const
mask_k
=
[
]
;
let
mask_k_area
=
0
;
let
original_area
=
0
;
const
mask_probs_k_data
=
mask_probs
[
k
]
.
data
;
for
(
let
i
=
0
;
i
<
mask_labels
.
length
;
+
+
i
)
{
if
(
mask_labels
[
i
]
=
=
=
k
)
{
mask_k
.
push
(
i
)
;
+
+
mask_k_area
;
}
if
(
mask_probs_k_data
[
i
]
>
=
mask_threshold
)
{
+
+
original_area
;
}
}
let
mask_exists
=
mask_k_area
>
0
&
&
original_area
>
0
;
if
(
mask_exists
)
{
let
area_ratio
=
mask_k_area
/
original_area
;
mask_exists
=
area_ratio
>
overlap_mask_area_threshold
;
}
return
[
mask_exists
mask_k
]
}
function
compute_segments
(
mask_probs
pred_scores
pred_labels
mask_threshold
overlap_mask_area_threshold
label_ids_to_fuse
=
null
target_size
=
null
)
{
const
[
height
width
]
=
target_size
?
?
mask_probs
[
0
]
.
dims
;
const
segmentation
=
new
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_1__
.
Tensor
(
'
int32
'
new
Int32Array
(
height
*
width
)
[
height
width
]
)
;
const
segments
=
[
]
;
if
(
target_size
!
=
=
null
)
{
for
(
let
i
=
0
;
i
<
mask_probs
.
length
;
+
+
i
)
{
mask_probs
[
i
]
=
(
0
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_1__
.
interpolate
)
(
mask_probs
[
i
]
target_size
'
bilinear
'
false
)
;
}
}
const
mask_labels
=
new
Int32Array
(
mask_probs
[
0
]
.
data
.
length
)
;
const
bestScores
=
new
Float32Array
(
mask_probs
[
0
]
.
data
.
length
)
;
for
(
let
i
=
0
;
i
<
mask_probs
.
length
;
+
+
i
)
{
let
score
=
pred_scores
[
i
]
;
const
mask_probs_i_data
=
mask_probs
[
i
]
.
data
;
for
(
let
j
=
0
;
j
<
mask_probs_i_data
.
length
;
+
+
j
)
{
mask_probs_i_data
[
j
]
*
=
score
if
(
mask_probs_i_data
[
j
]
>
bestScores
[
j
]
)
{
mask_labels
[
j
]
=
i
;
bestScores
[
j
]
=
mask_probs_i_data
[
j
]
;
}
}
}
let
current_segment_id
=
0
;
const
segmentation_data
=
segmentation
.
data
;
for
(
let
k
=
0
;
k
<
pred_labels
.
length
;
+
+
k
)
{
const
pred_class
=
pred_labels
[
k
]
;
const
[
mask_exists
mask_k
]
=
check_segment_validity
(
mask_labels
mask_probs
k
mask_threshold
overlap_mask_area_threshold
)
if
(
!
mask_exists
)
{
continue
;
}
+
+
current_segment_id
;
for
(
const
index
of
mask_k
)
{
segmentation_data
[
index
]
=
current_segment_id
;
}
segments
.
push
(
{
id
:
current_segment_id
label_id
:
pred_class
score
:
pred_scores
[
k
]
}
)
}
return
[
segmentation
segments
]
;
}
function
smart_resize
(
height
width
factor
=
28
min_pixels
=
56
*
56
max_pixels
=
14
*
14
*
4
*
1280
)
{
if
(
height
<
factor
|
|
width
<
factor
)
{
throw
new
Error
(
height
:
{
height
}
or
width
:
{
width
}
must
be
larger
than
factor
:
{
factor
}
)
;
}
else
if
(
Math
.
max
(
height
width
)
/
Math
.
min
(
height
width
)
>
200
)
{
throw
new
Error
(
absolute
aspect
ratio
must
be
smaller
than
200
got
{
Math
.
max
(
height
width
)
/
Math
.
min
(
height
width
)
}
)
;
}
let
h_bar
=
Math
.
round
(
height
/
factor
)
*
factor
;
let
w_bar
=
Math
.
round
(
width
/
factor
)
*
factor
;
if
(
h_bar
*
w_bar
>
max_pixels
)
{
const
beta
=
Math
.
sqrt
(
(
height
*
width
)
/
max_pixels
)
;
h_bar
=
Math
.
floor
(
(
height
/
beta
)
/
factor
)
*
factor
;
w_bar
=
Math
.
floor
(
(
width
/
beta
)
/
factor
)
*
factor
;
}
else
if
(
h_bar
*
w_bar
<
min_pixels
)
{
const
beta
=
Math
.
sqrt
(
min_pixels
/
(
height
*
width
)
)
;
h_bar
=
Math
.
ceil
(
(
height
*
beta
)
/
factor
)
*
factor
;
w_bar
=
Math
.
ceil
(
(
width
*
beta
)
/
factor
)
*
factor
;
}
return
[
h_bar
w_bar
]
;
}
function
post_process_panoptic_segmentation
(
outputs
threshold
=
0
.
5
mask_threshold
=
0
.
5
overlap_mask_area_threshold
=
0
.
8
label_ids_to_fuse
=
null
target_sizes
=
null
)
{
if
(
label_ids_to_fuse
=
=
=
null
)
{
console
.
warn
(
"
label_ids_to_fuse
unset
.
No
instance
will
be
fused
.
"
)
label_ids_to_fuse
=
new
Set
(
)
;
}
const
class_queries_logits
=
outputs
.
class_queries_logits
?
?
outputs
.
logits
;
const
masks_queries_logits
=
outputs
.
masks_queries_logits
?
?
outputs
.
pred_masks
;
const
mask_probs
=
masks_queries_logits
.
sigmoid
(
)
let
[
batch_size
num_queries
num_labels
]
=
class_queries_logits
.
dims
;
num_labels
-
=
1
;
if
(
target_sizes
!
=
=
null
&
&
target_sizes
.
length
!
=
=
batch_size
)
{
throw
Error
(
"
Make
sure
that
you
pass
in
as
many
target
sizes
as
the
batch
dimension
of
the
logits
"
)
}
let
toReturn
=
[
]
;
for
(
let
i
=
0
;
i
<
batch_size
;
+
+
i
)
{
let
target_size
=
target_sizes
!
=
=
null
?
target_sizes
[
i
]
:
null
;
let
class_logits
=
class_queries_logits
[
i
]
;
let
mask_logits
=
mask_probs
[
i
]
;
let
[
mask_probs_item
pred_scores_item
pred_labels_item
]
=
remove_low_and_no_objects
(
class_logits
mask_logits
threshold
num_labels
)
;
if
(
pred_labels_item
.
length
=
=
=
0
)
{
let
[
height
width
]
=
target_size
?
?
mask_logits
.
dims
.
slice
(
-
2
)
;
let
segmentation
=
new
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_1__
.
Tensor
(
'
int32
'
new
Int32Array
(
height
*
width
)
.
fill
(
-
1
)
[
height
width
]
)
toReturn
.
push
(
{
segmentation
:
segmentation
segments_info
:
[
]
}
)
;
continue
;
}
let
[
segmentation
segments
]
=
compute_segments
(
mask_probs_item
pred_scores_item
pred_labels_item
mask_threshold
overlap_mask_area_threshold
label_ids_to_fuse
target_size
)
toReturn
.
push
(
{
segmentation
:
segmentation
segments_info
:
segments
}
)
}
return
toReturn
;
}
function
post_process_instance_segmentation
(
outputs
threshold
=
0
.
5
target_sizes
=
null
)
{
throw
new
Error
(
'
post_process_instance_segmentation
is
not
yet
implemented
.
'
)
;
}
class
ImageProcessor
extends
_utils_generic_js__WEBPACK_IMPORTED_MODULE_0__
.
Callable
{
constructor
(
config
)
{
super
(
)
;
this
.
image_mean
=
config
.
image_mean
?
?
config
.
mean
;
this
.
image_std
=
config
.
image_std
?
?
config
.
std
;
this
.
resample
=
config
.
resample
?
?
2
;
this
.
do_rescale
=
config
.
do_rescale
?
?
true
;
this
.
rescale_factor
=
config
.
rescale_factor
?
?
(
1
/
255
)
;
this
.
do_normalize
=
config
.
do_normalize
;
this
.
do_thumbnail
=
config
.
do_thumbnail
;
this
.
size
=
config
.
size
?
?
config
.
image_size
;
this
.
do_resize
=
config
.
do_resize
?
?
(
this
.
size
!
=
=
undefined
)
;
this
.
size_divisibility
=
config
.
size_divisibility
?
?
config
.
size_divisor
;
this
.
do_center_crop
=
config
.
do_center_crop
;
this
.
crop_size
=
config
.
crop_size
;
this
.
do_convert_rgb
=
config
.
do_convert_rgb
?
?
true
;
this
.
do_crop_margin
=
config
.
do_crop_margin
;
this
.
pad_size
=
config
.
pad_size
;
this
.
do_pad
=
config
.
do_pad
;
if
(
this
.
do_pad
&
&
!
this
.
pad_size
&
&
this
.
size
&
&
this
.
size
.
width
!
=
=
undefined
&
&
this
.
size
.
height
!
=
=
undefined
)
{
this
.
pad_size
=
this
.
size
}
this
.
do_flip_channel_order
=
config
.
do_flip_channel_order
?
?
false
;
this
.
config
=
config
;
}
async
thumbnail
(
image
size
resample
=
2
)
{
const
input_height
=
image
.
height
;
const
input_width
=
image
.
width
;
const
output_height
=
size
.
height
;
const
output_width
=
size
.
width
;
let
height
=
Math
.
min
(
input_height
output_height
)
let
width
=
Math
.
min
(
input_width
output_width
)
if
(
height
=
=
=
input_height
&
&
width
=
=
=
input_width
)
{
return
image
;
}
if
(
input_height
>
input_width
)
{
width
=
Math
.
floor
(
input_width
*
height
/
input_height
)
;
}
else
if
(
input_width
>
input_height
)
{
height
=
Math
.
floor
(
input_height
*
width
/
input_width
)
;
}
return
await
image
.
resize
(
width
height
{
resample
}
)
;
}
async
crop_margin
(
image
gray_threshold
=
200
)
{
const
gray_image
=
image
.
clone
(
)
.
grayscale
(
)
;
const
minValue
=
(
0
_utils_maths_js__WEBPACK_IMPORTED_MODULE_2__
.
min
)
(
gray_image
.
data
)
[
0
]
;
const
maxValue
=
(
0
_utils_maths_js__WEBPACK_IMPORTED_MODULE_2__
.
max
)
(
gray_image
.
data
)
[
0
]
;
const
diff
=
maxValue
-
minValue
;
if
(
diff
=
=
=
0
)
{
return
image
;
}
const
threshold
=
gray_threshold
/
255
;
let
x_min
=
gray_image
.
width
y_min
=
gray_image
.
height
x_max
=
0
y_max
=
0
;
const
gray_image_data
=
gray_image
.
data
;
for
(
let
j
=
0
;
j
<
gray_image
.
height
;
+
+
j
)
{
const
row
=
j
*
gray_image
.
width
;
for
(
let
i
=
0
;
i
<
gray_image
.
width
;
+
+
i
)
{
if
(
(
gray_image_data
[
row
+
i
]
-
minValue
)
/
diff
<
threshold
)
{
x_min
=
Math
.
min
(
x_min
i
)
;
y_min
=
Math
.
min
(
y_min
j
)
;
x_max
=
Math
.
max
(
x_max
i
)
;
y_max
=
Math
.
max
(
y_max
j
)
;
}
}
}
image
=
await
image
.
crop
(
[
x_min
y_min
x_max
y_max
]
)
;
return
image
;
}
pad_image
(
pixelData
imgDims
padSize
{
mode
=
'
constant
'
center
=
false
constant_values
=
0
}
=
{
}
)
{
const
[
imageHeight
imageWidth
imageChannels
]
=
imgDims
;
let
paddedImageWidth
paddedImageHeight
;
if
(
typeof
padSize
=
=
=
'
number
'
)
{
paddedImageWidth
=
padSize
;
paddedImageHeight
=
padSize
;
}
else
{
paddedImageWidth
=
padSize
.
width
;
paddedImageHeight
=
padSize
.
height
;
}
if
(
paddedImageWidth
!
=
=
imageWidth
|
|
paddedImageHeight
!
=
=
imageHeight
)
{
const
paddedPixelData
=
new
Float32Array
(
paddedImageWidth
*
paddedImageHeight
*
imageChannels
)
;
if
(
Array
.
isArray
(
constant_values
)
)
{
for
(
let
i
=
0
;
i
<
paddedPixelData
.
length
;
+
+
i
)
{
paddedPixelData
[
i
]
=
constant_values
[
i
%
imageChannels
]
;
}
}
else
if
(
constant_values
!
=
=
0
)
{
paddedPixelData
.
fill
(
constant_values
)
;
}
const
[
left
top
]
=
center
?
[
Math
.
floor
(
(
paddedImageWidth
-
imageWidth
)
/
2
)
Math
.
floor
(
(
paddedImageHeight
-
imageHeight
)
/
2
)
]
:
[
0
0
]
;
for
(
let
i
=
0
;
i
<
imageHeight
;
+
+
i
)
{
const
a
=
(
i
+
top
)
*
paddedImageWidth
;
const
b
=
i
*
imageWidth
;
for
(
let
j
=
0
;
j
<
imageWidth
;
+
+
j
)
{
const
c
=
(
a
+
j
+
left
)
*
imageChannels
;
const
d
=
(
b
+
j
)
*
imageChannels
;
for
(
let
k
=
0
;
k
<
imageChannels
;
+
+
k
)
{
paddedPixelData
[
c
+
k
]
=
pixelData
[
d
+
k
]
;
}
}
}
if
(
mode
=
=
=
'
symmetric
'
)
{
if
(
center
)
{
throw
new
Error
(
'
center
padding
is
not
supported
when
mode
is
set
to
symmetric
.
'
)
;
}
const
h1
=
imageHeight
-
1
;
const
w1
=
imageWidth
-
1
;
for
(
let
i
=
0
;
i
<
paddedImageHeight
;
+
+
i
)
{
const
a
=
i
*
paddedImageWidth
;
const
b
=
(
0
_utils_core_js__WEBPACK_IMPORTED_MODULE_4__
.
calculateReflectOffset
)
(
i
h1
)
*
imageWidth
;
for
(
let
j
=
0
;
j
<
paddedImageWidth
;
+
+
j
)
{
if
(
i
<
imageHeight
&
&
j
<
imageWidth
)
continue
;
const
c
=
(
a
+
j
)
*
imageChannels
;
const
d
=
(
b
+
(
0
_utils_core_js__WEBPACK_IMPORTED_MODULE_4__
.
calculateReflectOffset
)
(
j
w1
)
)
*
imageChannels
;
for
(
let
k
=
0
;
k
<
imageChannels
;
+
+
k
)
{
paddedPixelData
[
c
+
k
]
=
pixelData
[
d
+
k
]
;
}
}
}
}
pixelData
=
paddedPixelData
;
imgDims
=
[
paddedImageHeight
paddedImageWidth
imageChannels
]
}
return
[
pixelData
imgDims
]
;
}
rescale
(
pixelData
)
{
for
(
let
i
=
0
;
i
<
pixelData
.
length
;
+
+
i
)
{
pixelData
[
i
]
=
this
.
rescale_factor
*
pixelData
[
i
]
;
}
}
get_resize_output_image_size
(
image
size
)
{
const
[
srcWidth
srcHeight
]
=
image
.
size
;
let
shortest_edge
;
let
longest_edge
;
if
(
this
.
do_thumbnail
)
{
const
{
height
width
}
=
size
;
shortest_edge
=
Math
.
min
(
height
width
)
}
else
if
(
Number
.
isInteger
(
size
)
)
{
shortest_edge
=
size
;
longest_edge
=
this
.
config
.
max_size
?
?
shortest_edge
;
}
else
if
(
size
!
=
=
undefined
)
{
shortest_edge
=
size
.
shortest_edge
;
longest_edge
=
size
.
longest_edge
;
}
if
(
shortest_edge
!
=
=
undefined
|
|
longest_edge
!
=
=
undefined
)
{
const
shortResizeFactor
=
shortest_edge
=
=
=
undefined
?
1
:
Math
.
max
(
shortest_edge
/
srcWidth
shortest_edge
/
srcHeight
)
;
const
newWidth
=
srcWidth
*
shortResizeFactor
;
const
newHeight
=
srcHeight
*
shortResizeFactor
;
const
longResizeFactor
=
longest_edge
=
=
=
undefined
?
1
:
Math
.
min
(
longest_edge
/
newWidth
longest_edge
/
newHeight
)
;
let
finalWidth
=
Math
.
floor
(
Number
(
(
newWidth
*
longResizeFactor
)
.
toFixed
(
2
)
)
)
;
let
finalHeight
=
Math
.
floor
(
Number
(
(
newHeight
*
longResizeFactor
)
.
toFixed
(
2
)
)
)
;
if
(
this
.
size_divisibility
!
=
=
undefined
)
{
[
finalWidth
finalHeight
]
=
enforce_size_divisibility
(
[
finalWidth
finalHeight
]
this
.
size_divisibility
)
}
return
[
finalWidth
finalHeight
]
;
}
else
if
(
size
!
=
=
undefined
&
&
size
.
width
!
=
=
undefined
&
&
size
.
height
!
=
=
undefined
)
{
let
newWidth
=
size
.
width
;
let
newHeight
=
size
.
height
;
if
(
this
.
config
.
keep_aspect_ratio
&
&
this
.
config
.
ensure_multiple_of
)
{
let
scale_height
=
newHeight
/
srcHeight
;
let
scale_width
=
newWidth
/
srcWidth
;
if
(
Math
.
abs
(
1
-
scale_width
)
<
Math
.
abs
(
1
-
scale_height
)
)
{
scale_height
=
scale_width
;
}
else
{
scale_width
=
scale_height
;
}
newHeight
=
constraint_to_multiple_of
(
scale_height
*
srcHeight
this
.
config
.
ensure_multiple_of
)
;
newWidth
=
constraint_to_multiple_of
(
scale_width
*
srcWidth
this
.
config
.
ensure_multiple_of
)
;
}
return
[
newWidth
newHeight
]
;
}
else
if
(
this
.
size_divisibility
!
=
=
undefined
)
{
return
enforce_size_divisibility
(
[
srcWidth
srcHeight
]
this
.
size_divisibility
)
;
}
else
if
(
size
.
min_pixels
!
=
=
undefined
&
&
size
.
max_pixels
!
=
=
undefined
)
{
const
{
min_pixels
max_pixels
}
=
size
;
const
factor
=
this
.
config
.
patch_size
*
this
.
config
.
merge_size
;
return
smart_resize
(
srcHeight
srcWidth
factor
min_pixels
max_pixels
)
;
}
else
{
throw
new
Error
(
Could
not
resize
image
due
to
unsupported
\
this
.
size
\
option
in
config
:
{
JSON
.
stringify
(
size
)
}
)
;
}
}
async
resize
(
image
)
{
const
[
newWidth
newHeight
]
=
this
.
get_resize_output_image_size
(
image
this
.
size
)
;
return
await
image
.
resize
(
newWidth
newHeight
{
resample
:
this
.
resample
}
)
;
}
async
preprocess
(
image
{
do_normalize
=
null
do_pad
=
null
do_convert_rgb
=
null
do_convert_grayscale
=
null
do_flip_channel_order
=
null
}
=
{
}
)
{
if
(
this
.
do_crop_margin
)
{
image
=
await
this
.
crop_margin
(
image
)
;
}
const
[
srcWidth
srcHeight
]
=
image
.
size
;
if
(
do_convert_rgb
?
?
this
.
do_convert_rgb
)
{
image
=
image
.
rgb
(
)
;
}
else
if
(
do_convert_grayscale
)
{
image
=
image
.
grayscale
(
)
;
}
if
(
this
.
do_resize
)
{
image
=
await
this
.
resize
(
image
)
;
}
if
(
this
.
do_thumbnail
)
{
image
=
await
this
.
thumbnail
(
image
this
.
size
this
.
resample
)
;
}
if
(
this
.
do_center_crop
)
{
let
crop_width
;
let
crop_height
;
if
(
Number
.
isInteger
(
this
.
crop_size
)
)
{
crop_width
=
this
.
crop_size
;
crop_height
=
this
.
crop_size
;
}
else
{
crop_width
=
this
.
crop_size
.
width
;
crop_height
=
this
.
crop_size
.
height
;
}
image
=
await
image
.
center_crop
(
crop_width
crop_height
)
;
}
const
reshaped_input_size
=
[
image
.
height
image
.
width
]
;
let
pixelData
=
Float32Array
.
from
(
image
.
data
)
;
let
imgDims
=
[
image
.
height
image
.
width
image
.
channels
]
;
if
(
this
.
do_rescale
)
{
this
.
rescale
(
pixelData
)
;
}
if
(
do_normalize
?
?
this
.
do_normalize
)
{
let
image_mean
=
this
.
image_mean
;
if
(
!
Array
.
isArray
(
this
.
image_mean
)
)
{
image_mean
=
new
Array
(
image
.
channels
)
.
fill
(
image_mean
)
;
}
let
image_std
=
this
.
image_std
;
if
(
!
Array
.
isArray
(
this
.
image_std
)
)
{
image_std
=
new
Array
(
image
.
channels
)
.
fill
(
image_mean
)
;
}
if
(
image_mean
.
length
!
=
=
image
.
channels
|
|
image_std
.
length
!
=
=
image
.
channels
)
{
throw
new
Error
(
When
set
to
arrays
the
length
of
\
image_mean
\
(
{
image_mean
.
length
}
)
and
\
image_std
\
(
{
image_std
.
length
}
)
must
match
the
number
of
channels
in
the
image
(
{
image
.
channels
}
)
.
)
;
}
for
(
let
i
=
0
;
i
<
pixelData
.
length
;
i
+
=
image
.
channels
)
{
for
(
let
j
=
0
;
j
<
image
.
channels
;
+
+
j
)
{
pixelData
[
i
+
j
]
=
(
pixelData
[
i
+
j
]
-
image_mean
[
j
]
)
/
image_std
[
j
]
;
}
}
}
if
(
do_pad
?
?
this
.
do_pad
)
{
if
(
this
.
pad_size
)
{
const
padded
=
this
.
pad_image
(
pixelData
[
image
.
height
image
.
width
image
.
channels
]
this
.
pad_size
)
;
[
pixelData
imgDims
]
=
padded
;
}
else
if
(
this
.
size_divisibility
)
{
const
[
paddedWidth
paddedHeight
]
=
enforce_size_divisibility
(
[
imgDims
[
1
]
imgDims
[
0
]
]
this
.
size_divisibility
)
;
[
pixelData
imgDims
]
=
this
.
pad_image
(
pixelData
imgDims
{
width
:
paddedWidth
height
:
paddedHeight
}
)
;
}
}
if
(
do_flip_channel_order
?
?
this
.
do_flip_channel_order
)
{
if
(
imgDims
[
2
]
!
=
=
3
)
{
throw
new
Error
(
'
Flipping
channel
order
is
only
supported
for
RGB
images
.
'
)
;
}
for
(
let
i
=
0
;
i
<
pixelData
.
length
;
i
+
=
3
)
{
const
temp
=
pixelData
[
i
]
;
pixelData
[
i
]
=
pixelData
[
i
+
2
]
;
pixelData
[
i
+
2
]
=
temp
;
}
}
const
pixel_values
=
new
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_1__
.
Tensor
(
'
float32
'
pixelData
imgDims
)
.
permute
(
2
0
1
)
;
return
{
original_size
:
[
srcHeight
srcWidth
]
reshaped_input_size
:
reshaped_input_size
pixel_values
}
}
async
_call
(
images
.
.
.
args
)
{
if
(
!
Array
.
isArray
(
images
)
)
{
images
=
[
images
]
;
}
const
imageData
=
await
Promise
.
all
(
images
.
map
(
x
=
>
this
.
preprocess
(
x
)
)
)
;
const
pixel_values
=
(
0
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_1__
.
stack
)
(
imageData
.
map
(
x
=
>
x
.
pixel_values
)
0
)
;
return
{
pixel_values
original_sizes
:
imageData
.
map
(
x
=
>
x
.
original_size
)
reshaped_input_sizes
:
imageData
.
map
(
x
=
>
x
.
reshaped_input_size
)
}
}
static
async
from_pretrained
(
pretrained_model_name_or_path
options
)
{
const
preprocessorConfig
=
await
(
0
_utils_hub_js__WEBPACK_IMPORTED_MODULE_5__
.
getModelJSON
)
(
pretrained_model_name_or_path
_utils_constants_js__WEBPACK_IMPORTED_MODULE_6__
.
IMAGE_PROCESSOR_NAME
true
options
)
;
return
new
this
(
preprocessorConfig
)
;
}
}
}
)
"
.
/
src
/
base
/
processing_utils
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
Processor
:
(
)
=
>
(
Processor
)
}
)
;
var
_utils_constants_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
src
/
utils
/
constants
.
js
"
)
;
var
_utils_generic_js__WEBPACK_IMPORTED_MODULE_1__
=
__webpack_require__
(
"
.
/
src
/
utils
/
generic
.
js
"
)
;
var
_utils_hub_js__WEBPACK_IMPORTED_MODULE_2__
=
__webpack_require__
(
"
.
/
src
/
utils
/
hub
.
js
"
)
;
class
Processor
extends
_utils_generic_js__WEBPACK_IMPORTED_MODULE_1__
.
Callable
{
static
classes
=
[
'
image_processor_class
'
'
tokenizer_class
'
'
feature_extractor_class
'
]
static
uses_processor_config
=
false
;
constructor
(
config
components
)
{
super
(
)
;
this
.
config
=
config
;
this
.
components
=
components
;
}
get
image_processor
(
)
{
return
this
.
components
.
image_processor
;
}
get
tokenizer
(
)
{
return
this
.
components
.
tokenizer
;
}
get
feature_extractor
(
)
{
return
this
.
components
.
feature_extractor
;
}
apply_chat_template
(
messages
options
=
{
}
)
{
if
(
!
this
.
tokenizer
)
{
throw
new
Error
(
'
Unable
to
apply
chat
template
without
a
tokenizer
.
'
)
;
}
return
this
.
tokenizer
.
apply_chat_template
(
messages
{
tokenize
:
false
.
.
.
options
}
)
;
}
batch_decode
(
.
.
.
args
)
{
if
(
!
this
.
tokenizer
)
{
throw
new
Error
(
'
Unable
to
decode
without
a
tokenizer
.
'
)
;
}
return
this
.
tokenizer
.
batch_decode
(
.
.
.
args
)
;
}
async
_call
(
input
.
.
.
args
)
{
for
(
const
item
of
[
this
.
image_processor
this
.
feature_extractor
this
.
tokenizer
]
)
{
if
(
item
)
{
return
item
(
input
.
.
.
args
)
;
}
}
throw
new
Error
(
'
No
image
processor
feature
extractor
or
tokenizer
found
.
'
)
;
}
static
async
from_pretrained
(
pretrained_model_name_or_path
options
)
{
const
[
config
components
]
=
await
Promise
.
all
(
[
this
.
uses_processor_config
?
(
0
_utils_hub_js__WEBPACK_IMPORTED_MODULE_2__
.
getModelJSON
)
(
pretrained_model_name_or_path
_utils_constants_js__WEBPACK_IMPORTED_MODULE_0__
.
PROCESSOR_NAME
true
options
)
:
{
}
Promise
.
all
(
this
.
classes
.
filter
(
(
cls
)
=
>
cls
in
this
)
.
map
(
async
(
cls
)
=
>
{
const
component
=
await
this
[
cls
]
.
from_pretrained
(
pretrained_model_name_or_path
options
)
;
return
[
cls
.
replace
(
/
_class
/
'
'
)
component
]
;
}
)
)
.
then
(
Object
.
fromEntries
)
]
)
;
return
new
this
(
config
components
)
;
}
}
}
)
"
.
/
src
/
configs
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
AutoConfig
:
(
)
=
>
(
AutoConfig
)
PretrainedConfig
:
(
)
=
>
(
PretrainedConfig
)
getKeyValueShapes
:
(
)
=
>
(
getKeyValueShapes
)
}
)
;
var
_utils_core_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
src
/
utils
/
core
.
js
"
)
;
var
_utils_hub_js__WEBPACK_IMPORTED_MODULE_1__
=
__webpack_require__
(
"
.
/
src
/
utils
/
hub
.
js
"
)
;
async
function
loadConfig
(
pretrained_model_name_or_path
options
)
{
return
await
(
0
_utils_hub_js__WEBPACK_IMPORTED_MODULE_1__
.
getModelJSON
)
(
pretrained_model_name_or_path
'
config
.
json
'
true
options
)
;
}
function
getNormalizedConfig
(
config
)
{
const
mapping
=
{
}
;
let
init_normalized_config
=
{
}
;
switch
(
config
.
model_type
)
{
case
'
llava
'
:
case
'
paligemma
'
:
case
'
florence2
'
:
case
'
llava_onevision
'
:
init_normalized_config
=
getNormalizedConfig
(
config
.
text_config
)
;
break
;
case
'
moondream1
'
:
init_normalized_config
=
getNormalizedConfig
(
config
.
phi_config
)
;
break
;
case
'
musicgen
'
:
init_normalized_config
=
getNormalizedConfig
(
config
.
decoder
)
;
break
;
case
'
multi_modality
'
:
init_normalized_config
=
getNormalizedConfig
(
config
.
language_config
)
;
break
;
case
'
gpt2
'
:
case
'
gptj
'
:
case
'
jais
'
:
case
'
codegen
'
:
case
'
gpt_bigcode
'
:
mapping
[
'
num_heads
'
]
=
'
n_head
'
;
mapping
[
'
num_layers
'
]
=
'
n_layer
'
;
mapping
[
'
hidden_size
'
]
=
'
n_embd
'
;
break
;
case
'
gpt_neox
'
:
case
'
stablelm
'
:
case
'
opt
'
:
case
'
phi
'
:
case
'
phi3
'
:
case
'
falcon
'
:
mapping
[
'
num_heads
'
]
=
'
num_attention_heads
'
;
mapping
[
'
num_layers
'
]
=
'
num_hidden_layers
'
;
mapping
[
'
hidden_size
'
]
=
'
hidden_size
'
;
break
;
case
'
llama
'
:
case
'
olmo
'
:
case
'
mobilellm
'
:
case
'
granite
'
:
case
'
cohere
'
:
case
'
mistral
'
:
case
'
starcoder2
'
:
case
'
qwen2
'
:
case
'
qwen2_vl
'
:
mapping
[
'
num_heads
'
]
=
'
num_key_value_heads
'
;
mapping
[
'
num_layers
'
]
=
'
num_hidden_layers
'
;
mapping
[
'
hidden_size
'
]
=
'
hidden_size
'
;
mapping
[
'
num_attention_heads
'
]
=
'
num_attention_heads
'
;
break
;
case
'
gemma
'
:
case
'
gemma2
'
:
mapping
[
'
num_heads
'
]
=
'
num_key_value_heads
'
;
mapping
[
'
num_layers
'
]
=
'
num_hidden_layers
'
;
mapping
[
'
dim_kv
'
]
=
'
head_dim
'
;
break
;
case
'
openelm
'
:
mapping
[
'
num_heads
'
]
=
'
num_kv_heads
'
;
mapping
[
'
num_layers
'
]
=
'
num_transformer_layers
'
;
mapping
[
'
dim_kv
'
]
=
'
head_dim
'
;
break
;
case
'
gpt_neo
'
:
case
'
donut
-
swin
'
:
mapping
[
'
num_heads
'
]
=
'
num_heads
'
;
mapping
[
'
num_layers
'
]
=
'
num_layers
'
;
mapping
[
'
hidden_size
'
]
=
'
hidden_size
'
;
break
;
case
'
bloom
'
:
mapping
[
'
num_heads
'
]
=
'
n_head
'
;
mapping
[
'
num_layers
'
]
=
'
n_layer
'
;
mapping
[
'
hidden_size
'
]
=
'
hidden_size
'
;
break
;
case
'
mpt
'
:
mapping
[
'
num_heads
'
]
=
'
n_heads
'
;
mapping
[
'
num_layers
'
]
=
'
n_layers
'
;
mapping
[
'
hidden_size
'
]
=
'
d_model
'
;
break
;
case
'
t5
'
:
case
'
mt5
'
:
case
'
longt5
'
:
mapping
[
'
num_decoder_layers
'
]
=
'
num_decoder_layers
'
;
mapping
[
'
num_decoder_heads
'
]
=
'
num_heads
'
;
mapping
[
'
decoder_dim_kv
'
]
=
'
d_kv
'
;
mapping
[
'
num_encoder_layers
'
]
=
'
num_layers
'
;
mapping
[
'
num_encoder_heads
'
]
=
'
num_heads
'
;
mapping
[
'
encoder_dim_kv
'
]
=
'
d_kv
'
;
break
;
case
'
bart
'
:
case
'
mbart
'
:
case
'
marian
'
:
case
'
whisper
'
:
case
'
m2m_100
'
:
case
'
blenderbot
'
:
case
'
blenderbot
-
small
'
:
case
'
florence2_language
'
:
mapping
[
'
num_decoder_layers
'
]
=
'
decoder_layers
'
;
mapping
[
'
num_decoder_heads
'
]
=
'
decoder_attention_heads
'
;
mapping
[
'
decoder_hidden_size
'
]
=
'
d_model
'
;
mapping
[
'
num_encoder_layers
'
]
=
'
encoder_layers
'
;
mapping
[
'
num_encoder_heads
'
]
=
'
encoder_attention_heads
'
;
mapping
[
'
encoder_hidden_size
'
]
=
'
d_model
'
;
break
;
case
'
speecht5
'
:
mapping
[
'
num_decoder_layers
'
]
=
'
decoder_layers
'
;
mapping
[
'
num_decoder_heads
'
]
=
'
decoder_attention_heads
'
;
mapping
[
'
decoder_hidden_size
'
]
=
'
hidden_size
'
;
mapping
[
'
num_encoder_layers
'
]
=
'
encoder_layers
'
;
mapping
[
'
num_encoder_heads
'
]
=
'
encoder_attention_heads
'
;
mapping
[
'
encoder_hidden_size
'
]
=
'
hidden_size
'
;
break
;
case
'
trocr
'
:
mapping
[
'
num_encoder_layers
'
]
=
mapping
[
'
num_decoder_layers
'
]
=
'
decoder_layers
'
;
mapping
[
'
num_encoder_heads
'
]
=
mapping
[
'
num_decoder_heads
'
]
=
'
decoder_attention_heads
'
;
mapping
[
'
encoder_hidden_size
'
]
=
mapping
[
'
decoder_hidden_size
'
]
=
'
d_model
'
;
break
;
case
'
musicgen_decoder
'
:
mapping
[
'
num_encoder_layers
'
]
=
mapping
[
'
num_decoder_layers
'
]
=
'
num_hidden_layers
'
;
mapping
[
'
num_encoder_heads
'
]
=
mapping
[
'
num_decoder_heads
'
]
=
'
num_attention_heads
'
;
mapping
[
'
encoder_hidden_size
'
]
=
mapping
[
'
decoder_hidden_size
'
]
=
'
hidden_size
'
;
break
;
case
'
vision
-
encoder
-
decoder
'
:
const
decoderConfig
=
getNormalizedConfig
(
config
.
decoder
)
;
const
add_encoder_pkv
=
'
num_decoder_layers
'
in
decoderConfig
;
const
result
=
(
0
_utils_core_js__WEBPACK_IMPORTED_MODULE_0__
.
pick
)
(
config
[
'
model_type
'
'
is_encoder_decoder
'
]
)
;
if
(
add_encoder_pkv
)
{
result
.
num_decoder_layers
=
decoderConfig
.
num_decoder_layers
;
result
.
num_decoder_heads
=
decoderConfig
.
num_decoder_heads
;
result
.
decoder_hidden_size
=
decoderConfig
.
decoder_hidden_size
;
result
.
num_encoder_layers
=
decoderConfig
.
num_encoder_layers
;
result
.
num_encoder_heads
=
decoderConfig
.
num_encoder_heads
;
result
.
encoder_hidden_size
=
decoderConfig
.
encoder_hidden_size
;
}
else
{
result
.
num_layers
=
decoderConfig
.
num_layers
;
result
.
num_heads
=
decoderConfig
.
num_heads
;
result
.
hidden_size
=
decoderConfig
.
hidden_size
;
}
return
result
;
}
const
normalized_config
=
{
.
.
.
init_normalized_config
.
.
.
(
0
_utils_core_js__WEBPACK_IMPORTED_MODULE_0__
.
pick
)
(
config
[
'
model_type
'
'
multi_query
'
'
is_encoder_decoder
'
]
)
}
;
for
(
const
key
in
mapping
)
{
normalized_config
[
key
]
=
config
[
mapping
[
key
]
]
;
}
return
normalized_config
;
}
function
getKeyValueShapes
(
config
{
prefix
=
'
past_key_values
'
batch_size
=
1
}
=
{
}
)
{
const
decoderFeeds
=
{
}
;
const
normalized_config
=
config
.
normalized_config
;
if
(
normalized_config
.
is_encoder_decoder
&
&
(
'
num_encoder_heads
'
in
normalized_config
&
&
'
num_decoder_heads
'
in
normalized_config
)
)
{
const
encoder_dim_kv
=
normalized_config
.
encoder_dim_kv
?
?
(
normalized_config
.
encoder_hidden_size
/
normalized_config
.
num_encoder_heads
)
;
const
decoder_dim_kv
=
normalized_config
.
decoder_dim_kv
?
?
(
normalized_config
.
decoder_hidden_size
/
normalized_config
.
num_decoder_heads
)
;
const
encoder_dims
=
[
batch_size
normalized_config
.
num_encoder_heads
0
encoder_dim_kv
]
;
const
decoder_dims
=
[
batch_size
normalized_config
.
num_decoder_heads
0
decoder_dim_kv
]
;
for
(
let
i
=
0
;
i
<
normalized_config
.
num_decoder_layers
;
+
+
i
)
{
decoderFeeds
[
{
prefix
}
.
{
i
}
.
encoder
.
key
]
=
encoder_dims
;
decoderFeeds
[
{
prefix
}
.
{
i
}
.
encoder
.
value
]
=
encoder_dims
;
decoderFeeds
[
{
prefix
}
.
{
i
}
.
decoder
.
key
]
=
decoder_dims
;
decoderFeeds
[
{
prefix
}
.
{
i
}
.
decoder
.
value
]
=
decoder_dims
;
}
}
else
{
const
num_heads
=
normalized_config
.
num_heads
;
const
num_layers
=
normalized_config
.
num_layers
;
const
dim_kv
=
normalized_config
.
dim_kv
?
?
(
normalized_config
.
hidden_size
/
(
normalized_config
.
num_attention_heads
?
?
num_heads
)
)
;
if
(
normalized_config
.
model_type
=
=
=
'
falcon
'
)
{
const
dims
=
[
batch_size
*
num_heads
0
dim_kv
]
for
(
let
i
=
0
;
i
<
num_layers
;
+
+
i
)
{
decoderFeeds
[
{
prefix
}
.
{
i
}
.
key
]
=
dims
;
decoderFeeds
[
{
prefix
}
.
{
i
}
.
value
]
=
dims
;
}
}
else
if
(
normalized_config
.
multi_query
)
{
const
dims
=
[
batch_size
*
num_heads
0
2
*
dim_kv
]
for
(
let
i
=
0
;
i
<
num_layers
;
+
+
i
)
{
decoderFeeds
[
{
prefix
}
.
{
i
}
.
key_value
]
=
dims
;
}
}
else
if
(
normalized_config
.
model_type
=
=
=
'
bloom
'
)
{
const
keyDims
=
[
batch_size
*
num_heads
dim_kv
0
]
const
valueDims
=
[
batch_size
*
num_heads
0
dim_kv
]
for
(
let
i
=
0
;
i
<
num_layers
;
+
+
i
)
{
decoderFeeds
[
{
prefix
}
.
{
i
}
.
key
]
=
keyDims
;
decoderFeeds
[
{
prefix
}
.
{
i
}
.
value
]
=
valueDims
;
}
}
else
if
(
normalized_config
.
model_type
=
=
=
'
openelm
'
)
{
for
(
let
i
=
0
;
i
<
num_layers
;
+
+
i
)
{
const
dims
=
[
batch_size
num_heads
[
i
]
0
dim_kv
]
decoderFeeds
[
{
prefix
}
.
{
i
}
.
key
]
=
dims
;
decoderFeeds
[
{
prefix
}
.
{
i
}
.
value
]
=
dims
;
}
}
else
{
const
dims
=
[
batch_size
num_heads
0
dim_kv
]
for
(
let
i
=
0
;
i
<
num_layers
;
+
+
i
)
{
decoderFeeds
[
{
prefix
}
.
{
i
}
.
key
]
=
dims
;
decoderFeeds
[
{
prefix
}
.
{
i
}
.
value
]
=
dims
;
}
}
}
return
decoderFeeds
;
}
class
PretrainedConfig
{
model_type
=
null
;
is_encoder_decoder
=
false
;
max_position_embeddings
;
'
transformers
.
js_config
'
;
constructor
(
configJSON
)
{
Object
.
assign
(
this
configJSON
)
;
this
.
normalized_config
=
getNormalizedConfig
(
this
)
;
}
static
async
from_pretrained
(
pretrained_model_name_or_path
{
progress_callback
=
null
config
=
null
cache_dir
=
null
local_files_only
=
false
revision
=
'
main
'
}
=
{
}
)
{
if
(
config
&
&
!
(
config
instanceof
PretrainedConfig
)
)
{
config
=
new
PretrainedConfig
(
config
)
;
}
const
data
=
config
?
?
await
loadConfig
(
pretrained_model_name_or_path
{
progress_callback
config
cache_dir
local_files_only
revision
}
)
return
new
this
(
data
)
;
}
}
class
AutoConfig
{
static
async
from_pretrained
(
.
.
.
args
)
{
return
PretrainedConfig
.
from_pretrained
(
.
.
.
args
)
;
}
}
}
)
"
.
/
src
/
env
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
apis
:
(
)
=
>
(
apis
)
env
:
(
)
=
>
(
env
)
}
)
;
var
fs__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
?
569f
"
)
;
var
path__WEBPACK_IMPORTED_MODULE_1__
=
__webpack_require__
(
"
?
3f59
"
)
;
var
url__WEBPACK_IMPORTED_MODULE_2__
=
__webpack_require__
(
"
?
154a
"
)
;
const
VERSION
=
'
3
.
1
.
0
'
;
const
IS_BROWSER_ENV
=
typeof
self
!
=
=
'
undefined
'
;
const
IS_WEBWORKER_ENV
=
IS_BROWSER_ENV
&
&
self
.
constructor
.
name
=
=
=
'
DedicatedWorkerGlobalScope
'
;
const
IS_WEB_CACHE_AVAILABLE
=
IS_BROWSER_ENV
&
&
'
caches
'
in
self
;
const
IS_WEBGPU_AVAILABLE
=
typeof
navigator
!
=
=
'
undefined
'
&
&
'
gpu
'
in
navigator
;
const
IS_WEBNN_AVAILABLE
=
typeof
navigator
!
=
=
'
undefined
'
&
&
'
ml
'
in
navigator
;
const
IS_PROCESS_AVAILABLE
=
typeof
process
!
=
=
'
undefined
'
;
const
IS_NODE_ENV
=
IS_PROCESS_AVAILABLE
&
&
process
?
.
release
?
.
name
=
=
=
'
node
'
;
const
IS_FS_AVAILABLE
=
!
isEmpty
(
fs__WEBPACK_IMPORTED_MODULE_0__
)
;
const
IS_PATH_AVAILABLE
=
!
isEmpty
(
path__WEBPACK_IMPORTED_MODULE_1__
)
;
const
apis
=
Object
.
freeze
(
{
IS_BROWSER_ENV
IS_WEBWORKER_ENV
IS_WEB_CACHE_AVAILABLE
IS_WEBGPU_AVAILABLE
IS_WEBNN_AVAILABLE
IS_PROCESS_AVAILABLE
IS_NODE_ENV
IS_FS_AVAILABLE
IS_PATH_AVAILABLE
}
)
;
const
RUNNING_LOCALLY
=
IS_FS_AVAILABLE
&
&
IS_PATH_AVAILABLE
;
let
dirname__
=
'
.
/
'
;
if
(
RUNNING_LOCALLY
)
{
const
_import_meta_url
=
Object
(
import
.
meta
)
.
url
;
if
(
_import_meta_url
)
{
dirname__
=
path__WEBPACK_IMPORTED_MODULE_1__
.
dirname
(
path__WEBPACK_IMPORTED_MODULE_1__
.
dirname
(
url__WEBPACK_IMPORTED_MODULE_2__
.
fileURLToPath
(
_import_meta_url
)
)
)
}
else
if
(
typeof
__dirname
!
=
=
'
undefined
'
)
{
dirname__
=
path__WEBPACK_IMPORTED_MODULE_1__
.
dirname
(
__dirname
)
}
}
const
DEFAULT_CACHE_DIR
=
RUNNING_LOCALLY
?
path__WEBPACK_IMPORTED_MODULE_1__
.
join
(
dirname__
'
/
.
cache
/
'
)
:
null
;
const
DEFAULT_LOCAL_MODEL_PATH
=
'
/
models
/
'
;
const
localModelPath
=
RUNNING_LOCALLY
?
path__WEBPACK_IMPORTED_MODULE_1__
.
join
(
dirname__
DEFAULT_LOCAL_MODEL_PATH
)
:
DEFAULT_LOCAL_MODEL_PATH
;
const
env
=
{
version
:
VERSION
backends
:
{
onnx
:
{
}
}
allowRemoteModels
:
true
remoteHost
:
'
https
:
/
/
huggingface
.
co
/
'
remotePathTemplate
:
'
{
model
}
/
resolve
/
{
revision
}
/
'
allowLocalModels
:
!
IS_BROWSER_ENV
localModelPath
:
localModelPath
useFS
:
IS_FS_AVAILABLE
useBrowserCache
:
IS_WEB_CACHE_AVAILABLE
useFSCache
:
IS_FS_AVAILABLE
cacheDir
:
DEFAULT_CACHE_DIR
useCustomCache
:
false
customCache
:
null
}
function
isEmpty
(
obj
)
{
return
Object
.
keys
(
obj
)
.
length
=
=
=
0
;
}
}
)
"
.
/
src
/
generation
/
configuration_utils
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
GenerationConfig
:
(
)
=
>
(
GenerationConfig
)
}
)
;
var
_utils_core_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
src
/
utils
/
core
.
js
"
)
;
class
GenerationConfig
{
max_length
=
20
;
max_new_tokens
=
null
;
min_length
=
0
;
min_new_tokens
=
null
;
early_stopping
=
false
;
max_time
=
null
;
do_sample
=
false
;
num_beams
=
1
;
num_beam_groups
=
1
;
penalty_alpha
=
null
;
use_cache
=
true
;
temperature
=
1
.
0
;
top_k
=
50
;
top_p
=
1
.
0
;
typical_p
=
1
.
0
;
epsilon_cutoff
=
0
.
0
;
eta_cutoff
=
0
.
0
;
diversity_penalty
=
0
.
0
;
repetition_penalty
=
1
.
0
;
encoder_repetition_penalty
=
1
.
0
;
length_penalty
=
1
.
0
;
no_repeat_ngram_size
=
0
;
bad_words_ids
=
null
;
force_words_ids
=
null
;
renormalize_logits
=
false
;
constraints
=
null
;
forced_bos_token_id
=
null
;
forced_eos_token_id
=
null
;
remove_invalid_values
=
false
;
exponential_decay_length_penalty
=
null
;
suppress_tokens
=
null
;
begin_suppress_tokens
=
null
;
forced_decoder_ids
=
null
;
guidance_scale
=
null
;
num_return_sequences
=
1
;
output_attentions
=
false
;
output_hidden_states
=
false
;
output_scores
=
false
;
return_dict_in_generate
=
false
;
pad_token_id
=
null
;
bos_token_id
=
null
;
eos_token_id
=
null
;
encoder_no_repeat_ngram_size
=
0
;
decoder_start_token_id
=
null
;
generation_kwargs
=
{
}
;
constructor
(
config
)
{
Object
.
assign
(
this
(
0
_utils_core_js__WEBPACK_IMPORTED_MODULE_0__
.
pick
)
(
config
Object
.
getOwnPropertyNames
(
this
)
)
)
;
}
}
}
)
"
.
/
src
/
generation
/
logits_process
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
ClassifierFreeGuidanceLogitsProcessor
:
(
)
=
>
(
ClassifierFreeGuidanceLogitsProcessor
)
ForcedBOSTokenLogitsProcessor
:
(
)
=
>
(
ForcedBOSTokenLogitsProcessor
)
ForcedEOSTokenLogitsProcessor
:
(
)
=
>
(
ForcedEOSTokenLogitsProcessor
)
LogitsProcessor
:
(
)
=
>
(
LogitsProcessor
)
LogitsProcessorList
:
(
)
=
>
(
LogitsProcessorList
)
LogitsWarper
:
(
)
=
>
(
LogitsWarper
)
MinLengthLogitsProcessor
:
(
)
=
>
(
MinLengthLogitsProcessor
)
MinNewTokensLengthLogitsProcessor
:
(
)
=
>
(
MinNewTokensLengthLogitsProcessor
)
NoBadWordsLogitsProcessor
:
(
)
=
>
(
NoBadWordsLogitsProcessor
)
NoRepeatNGramLogitsProcessor
:
(
)
=
>
(
NoRepeatNGramLogitsProcessor
)
RepetitionPenaltyLogitsProcessor
:
(
)
=
>
(
RepetitionPenaltyLogitsProcessor
)
SuppressTokensAtBeginLogitsProcessor
:
(
)
=
>
(
SuppressTokensAtBeginLogitsProcessor
)
TemperatureLogitsWarper
:
(
)
=
>
(
TemperatureLogitsWarper
)
TopKLogitsWarper
:
(
)
=
>
(
TopKLogitsWarper
)
TopPLogitsWarper
:
(
)
=
>
(
TopPLogitsWarper
)
WhisperTimeStampLogitsProcessor
:
(
)
=
>
(
WhisperTimeStampLogitsProcessor
)
}
)
;
var
_utils_generic_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
src
/
utils
/
generic
.
js
"
)
;
var
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_1__
=
__webpack_require__
(
"
.
/
src
/
utils
/
tensor
.
js
"
)
;
var
_utils_maths_js__WEBPACK_IMPORTED_MODULE_2__
=
__webpack_require__
(
"
.
/
src
/
utils
/
maths
.
js
"
)
;
class
LogitsProcessor
extends
_utils_generic_js__WEBPACK_IMPORTED_MODULE_0__
.
Callable
{
_call
(
input_ids
logits
)
{
throw
Error
(
"
_call
should
be
implemented
in
a
subclass
"
)
}
}
class
LogitsWarper
extends
_utils_generic_js__WEBPACK_IMPORTED_MODULE_0__
.
Callable
{
_call
(
input_ids
logits
)
{
throw
Error
(
"
_call
should
be
implemented
in
a
subclass
"
)
}
}
class
LogitsProcessorList
extends
_utils_generic_js__WEBPACK_IMPORTED_MODULE_0__
.
Callable
{
constructor
(
)
{
super
(
)
;
this
.
processors
=
[
]
;
}
push
(
item
)
{
this
.
processors
.
push
(
item
)
;
}
extend
(
items
)
{
this
.
processors
.
push
(
.
.
.
items
)
;
}
_call
(
input_ids
logits
)
{
let
toReturn
=
logits
;
for
(
const
processor
of
this
.
processors
)
{
toReturn
=
processor
(
input_ids
toReturn
)
;
}
return
toReturn
;
}
[
Symbol
.
iterator
]
(
)
{
return
this
.
processors
.
values
(
)
;
}
}
class
ForcedBOSTokenLogitsProcessor
extends
LogitsProcessor
{
constructor
(
bos_token_id
)
{
super
(
)
;
this
.
bos_token_id
=
bos_token_id
;
}
_call
(
input_ids
logits
)
{
for
(
let
i
=
0
;
i
<
input_ids
.
length
;
+
+
i
)
{
if
(
input_ids
[
i
]
.
length
=
=
=
1
)
{
const
batch_logits_data
=
(
logits
[
i
]
.
data
)
;
batch_logits_data
.
fill
(
-
Infinity
)
;
batch_logits_data
[
this
.
bos_token_id
]
=
0
;
}
}
return
logits
;
}
}
class
ForcedEOSTokenLogitsProcessor
extends
LogitsProcessor
{
constructor
(
max_length
eos_token_id
)
{
super
(
)
;
this
.
max_length
=
max_length
;
this
.
eos_token_id
=
Array
.
isArray
(
eos_token_id
)
?
eos_token_id
:
[
eos_token_id
]
;
}
_call
(
input_ids
logits
)
{
for
(
let
i
=
0
;
i
<
input_ids
.
length
;
+
+
i
)
{
if
(
input_ids
[
i
]
.
length
=
=
=
this
.
max_length
-
1
)
{
const
batch_logits_data
=
(
logits
[
i
]
.
data
)
;
batch_logits_data
.
fill
(
-
Infinity
)
;
for
(
const
eos_token
of
this
.
eos_token_id
)
{
batch_logits_data
[
eos_token
]
=
0
;
}
}
}
return
logits
;
}
}
class
SuppressTokensAtBeginLogitsProcessor
extends
LogitsProcessor
{
constructor
(
begin_suppress_tokens
begin_index
)
{
super
(
)
;
this
.
begin_suppress_tokens
=
begin_suppress_tokens
;
this
.
begin_index
=
begin_index
;
}
_call
(
input_ids
logits
)
{
for
(
let
i
=
0
;
i
<
input_ids
.
length
;
+
+
i
)
{
if
(
input_ids
[
i
]
.
length
=
=
=
this
.
begin_index
)
{
const
batch_logits_data
=
(
logits
[
i
]
.
data
)
;
for
(
const
token_id
of
this
.
begin_suppress_tokens
)
{
batch_logits_data
[
token_id
]
=
-
Infinity
;
}
}
}
return
logits
;
}
}
class
WhisperTimeStampLogitsProcessor
extends
LogitsProcessor
{
constructor
(
generate_config
init_tokens
)
{
super
(
)
;
this
.
eos_token_id
=
Array
.
isArray
(
generate_config
.
eos_token_id
)
?
generate_config
.
eos_token_id
[
0
]
:
generate_config
.
eos_token_id
;
this
.
no_timestamps_token_id
=
generate_config
.
no_timestamps_token_id
;
this
.
timestamp_begin
=
this
.
no_timestamps_token_id
+
1
;
this
.
begin_index
=
init_tokens
.
length
;
if
(
init_tokens
.
at
(
-
1
)
=
=
=
this
.
no_timestamps_token_id
)
{
this
.
begin_index
-
=
1
;
}
this
.
max_initial_timestamp_index
=
generate_config
.
max_initial_timestamp_index
;
}
_call
(
input_ids
logits
)
{
for
(
let
i
=
0
;
i
<
input_ids
.
length
;
+
+
i
)
{
const
batch_logits_data
=
(
logits
[
i
]
.
data
)
;
batch_logits_data
[
this
.
no_timestamps_token_id
]
=
-
Infinity
;
if
(
input_ids
[
i
]
.
length
=
=
=
this
.
begin_index
-
1
)
{
batch_logits_data
.
fill
(
-
Infinity
)
;
batch_logits_data
[
this
.
timestamp_begin
]
=
0
;
continue
;
}
const
seq
=
input_ids
[
i
]
.
slice
(
this
.
begin_index
)
;
const
last_was_timestamp
=
seq
.
length
>
=
1
&
&
seq
[
seq
.
length
-
1
]
>
=
this
.
timestamp_begin
;
const
penultimate_was_timestamp
=
seq
.
length
<
2
|
|
seq
[
seq
.
length
-
2
]
>
=
this
.
timestamp_begin
;
if
(
last_was_timestamp
)
{
if
(
penultimate_was_timestamp
)
{
batch_logits_data
.
subarray
(
this
.
timestamp_begin
)
.
fill
(
-
Infinity
)
;
}
else
{
batch_logits_data
.
subarray
(
0
this
.
eos_token_id
)
.
fill
(
-
Infinity
)
;
}
}
if
(
input_ids
[
i
]
.
length
=
=
=
this
.
begin_index
&
&
this
.
max_initial_timestamp_index
!
=
=
null
)
{
const
last_allowed
=
this
.
timestamp_begin
+
this
.
max_initial_timestamp_index
;
batch_logits_data
.
subarray
(
last_allowed
+
1
)
.
fill
(
-
Infinity
)
;
}
const
logprobs
=
(
0
_utils_maths_js__WEBPACK_IMPORTED_MODULE_2__
.
log_softmax
)
(
batch_logits_data
)
;
const
timestamp_logprob
=
Math
.
log
(
logprobs
.
subarray
(
this
.
timestamp_begin
)
.
map
(
Math
.
exp
)
.
reduce
(
(
a
b
)
=
>
a
+
b
)
)
;
const
max_text_token_logprob
=
(
0
_utils_maths_js__WEBPACK_IMPORTED_MODULE_2__
.
max
)
(
logprobs
.
subarray
(
0
this
.
timestamp_begin
)
)
[
0
]
;
if
(
timestamp_logprob
>
max_text_token_logprob
)
{
batch_logits_data
.
subarray
(
0
this
.
timestamp_begin
)
.
fill
(
-
Infinity
)
;
}
}
return
logits
;
}
}
class
NoRepeatNGramLogitsProcessor
extends
LogitsProcessor
{
constructor
(
no_repeat_ngram_size
)
{
super
(
)
;
this
.
no_repeat_ngram_size
=
no_repeat_ngram_size
;
}
getNgrams
(
prevInputIds
)
{
const
curLen
=
prevInputIds
.
length
;
const
ngrams
=
[
]
;
for
(
let
j
=
0
;
j
<
curLen
+
1
-
this
.
no_repeat_ngram_size
;
+
+
j
)
{
const
ngram
=
[
]
;
for
(
let
k
=
0
;
k
<
this
.
no_repeat_ngram_size
;
+
+
k
)
{
ngram
.
push
(
prevInputIds
[
j
+
k
]
)
;
}
ngrams
.
push
(
ngram
.
map
(
Number
)
)
;
}
const
generatedNgram
=
new
Map
(
)
;
for
(
const
ngram
of
ngrams
)
{
const
prevNgram
=
ngram
.
slice
(
0
ngram
.
length
-
1
)
;
const
prevNgramKey
=
JSON
.
stringify
(
prevNgram
)
;
const
prevNgramValue
=
generatedNgram
.
get
(
prevNgramKey
)
?
?
[
]
;
prevNgramValue
.
push
(
ngram
[
ngram
.
length
-
1
]
)
;
generatedNgram
.
set
(
prevNgramKey
prevNgramValue
)
;
}
return
generatedNgram
;
}
getGeneratedNgrams
(
bannedNgrams
prevInputIds
)
{
const
ngramIdx
=
prevInputIds
.
slice
(
prevInputIds
.
length
+
1
-
this
.
no_repeat_ngram_size
prevInputIds
.
length
)
;
const
banned
=
bannedNgrams
.
get
(
JSON
.
stringify
(
ngramIdx
.
map
(
Number
)
)
)
?
?
[
]
;
return
banned
;
}
calcBannedNgramTokens
(
prevInputIds
)
{
const
bannedTokens
=
[
]
;
if
(
prevInputIds
.
length
+
1
<
this
.
no_repeat_ngram_size
)
{
return
bannedTokens
;
}
else
{
const
generatedNgrams
=
this
.
getNgrams
(
prevInputIds
)
;
const
bannedTokens
=
this
.
getGeneratedNgrams
(
generatedNgrams
prevInputIds
)
;
return
bannedTokens
;
}
}
_call
(
input_ids
logits
)
{
for
(
let
i
=
0
;
i
<
input_ids
.
length
;
+
+
i
)
{
const
batch_logits_data
=
(
logits
[
i
]
.
data
)
;
const
bannedTokens
=
this
.
calcBannedNgramTokens
(
input_ids
[
i
]
)
;
for
(
const
token
of
bannedTokens
)
{
batch_logits_data
[
token
]
=
-
Infinity
;
}
}
return
logits
;
}
}
class
RepetitionPenaltyLogitsProcessor
extends
LogitsProcessor
{
constructor
(
penalty
)
{
super
(
)
;
this
.
penalty
=
penalty
;
}
_call
(
input_ids
logits
)
{
for
(
let
i
=
0
;
i
<
input_ids
.
length
;
+
+
i
)
{
const
batch_logits_data
=
(
logits
[
i
]
.
data
)
;
for
(
const
input_id
of
input_ids
[
i
]
)
{
const
token
=
Number
(
input_id
)
;
if
(
batch_logits_data
[
token
]
<
0
)
{
batch_logits_data
[
token
]
*
=
this
.
penalty
;
}
else
{
batch_logits_data
[
token
]
/
=
this
.
penalty
;
}
}
}
return
logits
}
}
class
MinLengthLogitsProcessor
extends
LogitsProcessor
{
constructor
(
min_length
eos_token_id
)
{
super
(
)
;
this
.
min_length
=
min_length
;
this
.
eos_token_id
=
Array
.
isArray
(
eos_token_id
)
?
eos_token_id
:
[
eos_token_id
]
;
}
_call
(
input_ids
logits
)
{
for
(
let
i
=
0
;
i
<
input_ids
.
length
;
+
+
i
)
{
if
(
input_ids
[
i
]
.
length
<
this
.
min_length
)
{
const
batch_logits_data
=
(
logits
[
i
]
.
data
)
;
for
(
const
eos_token
of
this
.
eos_token_id
)
{
batch_logits_data
[
eos_token
]
=
-
Infinity
;
}
}
}
return
logits
}
}
class
MinNewTokensLengthLogitsProcessor
extends
LogitsProcessor
{
constructor
(
prompt_length_to_skip
min_new_tokens
eos_token_id
)
{
super
(
)
;
this
.
prompt_length_to_skip
=
prompt_length_to_skip
;
this
.
min_new_tokens
=
min_new_tokens
;
this
.
eos_token_id
=
Array
.
isArray
(
eos_token_id
)
?
eos_token_id
:
[
eos_token_id
]
;
}
_call
(
input_ids
logits
)
{
for
(
let
i
=
0
;
i
<
input_ids
.
length
;
+
+
i
)
{
const
new_tokens_length
=
input_ids
[
i
]
.
length
-
this
.
prompt_length_to_skip
;
if
(
new_tokens_length
<
this
.
min_new_tokens
)
{
const
batch_logits_data
=
(
logits
[
i
]
.
data
)
;
for
(
const
eos_token
of
this
.
eos_token_id
)
{
batch_logits_data
[
eos_token
]
=
-
Infinity
;
}
}
}
return
logits
}
}
class
NoBadWordsLogitsProcessor
extends
LogitsProcessor
{
constructor
(
bad_words_ids
eos_token_id
)
{
super
(
)
;
this
.
bad_words_ids
=
bad_words_ids
;
this
.
eos_token_id
=
Array
.
isArray
(
eos_token_id
)
?
eos_token_id
:
[
eos_token_id
]
;
}
_call
(
input_ids
logits
)
{
for
(
let
i
=
0
;
i
<
input_ids
.
length
;
+
+
i
)
{
const
batch_logits_data
=
(
logits
[
i
]
.
data
)
;
const
ids
=
input_ids
[
i
]
;
for
(
const
bad_word_ids
of
this
.
bad_words_ids
)
{
let
mark
=
true
;
for
(
let
j
=
1
;
j
<
=
bad_word_ids
.
length
-
1
&
&
bad_word_ids
.
length
<
ids
.
length
;
+
+
j
)
{
if
(
bad_word_ids
.
at
(
-
j
-
1
)
!
=
ids
.
at
(
-
j
)
)
{
mark
=
false
;
break
;
}
}
if
(
mark
)
{
batch_logits_data
[
bad_word_ids
.
at
(
-
1
)
]
=
-
Infinity
;
}
}
}
return
logits
}
}
class
ClassifierFreeGuidanceLogitsProcessor
extends
LogitsProcessor
{
constructor
(
guidance_scale
)
{
super
(
)
;
if
(
guidance_scale
<
=
1
)
{
throw
new
Error
(
Require
guidance
scale
>
1
to
use
the
classifier
free
guidance
processor
got
guidance
scale
{
guidance_scale
}
.
)
}
this
.
guidance_scale
=
guidance_scale
;
}
_call
(
input_ids
logits
)
{
if
(
logits
.
dims
[
0
]
!
=
=
2
*
input_ids
.
length
)
{
throw
new
Error
(
Logits
should
have
twice
the
batch
size
of
the
input
ids
the
first
half
of
batches
corresponding
to
+
the
conditional
inputs
and
the
second
half
of
batches
corresponding
to
the
unconditional
inputs
.
Got
+
batch
size
{
logits
.
dims
[
0
]
}
for
the
logits
and
{
input_ids
.
length
}
for
the
input
ids
.
)
}
const
unguided_bsz
=
input_ids
.
length
;
const
cond_logits
=
logits
.
slice
(
[
0
unguided_bsz
]
null
)
;
const
uncond_logits
=
logits
.
slice
(
[
unguided_bsz
logits
.
dims
[
0
]
]
null
)
;
for
(
let
i
=
0
;
i
<
uncond_logits
.
data
.
length
;
+
+
i
)
{
uncond_logits
.
data
[
i
]
+
=
(
cond_logits
.
data
[
i
]
-
uncond_logits
.
data
[
i
]
)
*
this
.
guidance_scale
;
}
return
uncond_logits
;
}
}
class
TemperatureLogitsWarper
extends
LogitsWarper
{
constructor
(
temperature
)
{
super
(
)
;
if
(
typeof
temperature
!
=
=
'
number
'
|
|
temperature
<
=
0
)
{
let
errorMessage
=
\
temperature
\
(
=
{
temperature
}
)
must
be
a
strictly
positive
float
otherwise
your
next
token
scores
will
be
invalid
.
;
if
(
temperature
=
=
=
0
)
{
errorMessage
+
=
"
If
you
'
re
looking
for
greedy
decoding
strategies
set
do_sample
=
false
.
"
}
}
this
.
temperature
=
temperature
;
}
_call
(
input_ids
logits
)
{
const
batch_logits_data
=
(
logits
.
data
)
;
for
(
let
i
=
0
;
i
<
batch_logits_data
.
length
;
+
+
i
)
{
batch_logits_data
[
i
]
/
=
this
.
temperature
;
}
return
logits
;
}
}
class
TopPLogitsWarper
extends
LogitsWarper
{
constructor
(
top_p
{
filter_value
=
-
Infinity
min_tokens_to_keep
=
1
}
=
{
}
)
{
super
(
)
;
if
(
top_p
<
0
|
|
top_p
>
1
.
0
)
{
throw
new
Error
(
\
top_p
\
must
be
a
float
>
0
and
<
1
but
is
{
top_p
}
)
}
if
(
!
Number
.
isInteger
(
min_tokens_to_keep
)
|
|
min_tokens_to_keep
<
1
)
{
throw
new
Error
(
\
min_tokens_to_keep
\
must
be
a
positive
integer
but
is
{
min_tokens_to_keep
}
)
}
this
.
top_p
=
top_p
this
.
filter_value
=
filter_value
this
.
min_tokens_to_keep
=
min_tokens_to_keep
}
}
class
TopKLogitsWarper
extends
LogitsWarper
{
constructor
(
top_k
{
filter_value
=
-
Infinity
min_tokens_to_keep
=
1
}
=
{
}
)
{
super
(
)
;
if
(
!
Number
.
isInteger
(
top_k
)
|
|
top_k
<
0
)
{
throw
new
Error
(
\
top_k
\
must
be
a
positive
integer
but
is
{
top_k
}
)
}
this
.
top_k
=
Math
.
max
(
top_k
min_tokens_to_keep
)
this
.
filter_value
=
filter_value
}
}
}
)
"
.
/
src
/
generation
/
logits_sampler
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
LogitsSampler
:
(
)
=
>
(
LogitsSampler
)
}
)
;
var
_utils_generic_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
src
/
utils
/
generic
.
js
"
)
;
var
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_1__
=
__webpack_require__
(
"
.
/
src
/
utils
/
tensor
.
js
"
)
;
var
_utils_maths_js__WEBPACK_IMPORTED_MODULE_2__
=
__webpack_require__
(
"
.
/
src
/
utils
/
maths
.
js
"
)
;
var
_generation_configuration_utils_js__WEBPACK_IMPORTED_MODULE_3__
=
__webpack_require__
(
"
.
/
src
/
generation
/
configuration_utils
.
js
"
)
;
class
LogitsSampler
extends
_utils_generic_js__WEBPACK_IMPORTED_MODULE_0__
.
Callable
{
constructor
(
generation_config
)
{
super
(
)
;
this
.
generation_config
=
generation_config
;
}
async
_call
(
logits
)
{
return
this
.
sample
(
logits
)
;
}
async
sample
(
logits
)
{
throw
Error
(
"
sample
should
be
implemented
in
subclasses
.
"
)
}
getLogits
(
logits
index
)
{
let
vocabSize
=
logits
.
dims
.
at
(
-
1
)
;
let
logs
=
(
logits
.
data
)
;
if
(
index
=
=
=
-
1
)
{
logs
=
logs
.
slice
(
-
vocabSize
)
;
}
else
{
let
startIndex
=
index
*
vocabSize
;
logs
=
logs
.
slice
(
startIndex
startIndex
+
vocabSize
)
;
}
return
logs
;
}
randomSelect
(
probabilities
)
{
let
sumProbabilities
=
0
;
for
(
let
i
=
0
;
i
<
probabilities
.
length
;
+
+
i
)
{
sumProbabilities
+
=
probabilities
[
i
]
;
}
let
r
=
Math
.
random
(
)
*
sumProbabilities
;
for
(
let
i
=
0
;
i
<
probabilities
.
length
;
+
+
i
)
{
r
-
=
probabilities
[
i
]
;
if
(
r
<
=
0
)
{
return
i
;
}
}
return
0
;
}
static
getSampler
(
generation_config
)
{
if
(
generation_config
.
do_sample
)
{
return
new
MultinomialSampler
(
generation_config
)
;
}
else
if
(
generation_config
.
num_beams
>
1
)
{
return
new
BeamSearchSampler
(
generation_config
)
;
}
else
{
if
(
generation_config
.
num_return_sequences
>
1
)
{
throw
Error
(
num_return_sequences
has
to
be
1
when
doing
greedy
search
but
is
{
generation_config
.
num_return_sequences
}
.
)
}
return
new
GreedySampler
(
generation_config
)
;
}
}
}
class
GreedySampler
extends
LogitsSampler
{
async
sample
(
logits
)
{
const
argmax
=
(
0
_utils_maths_js__WEBPACK_IMPORTED_MODULE_2__
.
max
)
(
logits
.
data
)
[
1
]
;
return
[
[
BigInt
(
argmax
)
0
]
]
;
}
}
class
MultinomialSampler
extends
LogitsSampler
{
async
sample
(
logits
)
{
let
k
=
logits
.
dims
.
at
(
-
1
)
;
if
(
this
.
generation_config
.
top_k
>
0
)
{
k
=
Math
.
min
(
this
.
generation_config
.
top_k
k
)
;
}
const
[
v
i
]
=
await
(
0
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_1__
.
topk
)
(
logits
k
)
;
const
probabilities
=
(
0
_utils_maths_js__WEBPACK_IMPORTED_MODULE_2__
.
softmax
)
(
(
v
.
data
)
)
;
return
Array
.
from
(
{
length
:
this
.
generation_config
.
num_beams
}
(
)
=
>
{
const
sampledIndex
=
this
.
randomSelect
(
probabilities
)
;
return
[
i
.
data
[
sampledIndex
]
Math
.
log
(
probabilities
[
sampledIndex
]
)
]
;
}
)
;
}
}
class
BeamSearchSampler
extends
LogitsSampler
{
async
sample
(
logits
)
{
let
k
=
logits
.
dims
.
at
(
-
1
)
;
if
(
this
.
generation_config
.
top_k
>
0
)
{
k
=
Math
.
min
(
this
.
generation_config
.
top_k
k
)
;
}
const
[
v
i
]
=
await
(
0
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_1__
.
topk
)
(
logits
k
)
;
const
probabilities
=
(
0
_utils_maths_js__WEBPACK_IMPORTED_MODULE_2__
.
softmax
)
(
(
v
.
data
)
)
;
return
Array
.
from
(
{
length
:
this
.
generation_config
.
num_beams
}
(
_
x
)
=
>
{
return
[
i
.
data
[
x
]
Math
.
log
(
probabilities
[
x
]
)
]
;
}
)
;
}
}
}
)
"
.
/
src
/
generation
/
stopping_criteria
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
EosTokenCriteria
:
(
)
=
>
(
EosTokenCriteria
)
InterruptableStoppingCriteria
:
(
)
=
>
(
InterruptableStoppingCriteria
)
MaxLengthCriteria
:
(
)
=
>
(
MaxLengthCriteria
)
StoppingCriteria
:
(
)
=
>
(
StoppingCriteria
)
StoppingCriteriaList
:
(
)
=
>
(
StoppingCriteriaList
)
}
)
;
var
_utils_generic_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
src
/
utils
/
generic
.
js
"
)
;
class
StoppingCriteria
extends
_utils_generic_js__WEBPACK_IMPORTED_MODULE_0__
.
Callable
{
_call
(
input_ids
scores
)
{
throw
Error
(
"
StoppingCriteria
needs
to
be
subclassed
"
)
;
}
}
class
StoppingCriteriaList
extends
_utils_generic_js__WEBPACK_IMPORTED_MODULE_0__
.
Callable
{
constructor
(
)
{
super
(
)
;
this
.
criteria
=
[
]
;
}
push
(
item
)
{
this
.
criteria
.
push
(
item
)
;
}
extend
(
items
)
{
if
(
items
instanceof
StoppingCriteriaList
)
{
items
=
items
.
criteria
;
}
else
if
(
items
instanceof
StoppingCriteria
)
{
items
=
[
items
]
;
}
this
.
criteria
.
push
(
.
.
.
items
)
;
}
_call
(
input_ids
scores
)
{
const
is_done
=
new
Array
(
input_ids
.
length
)
.
fill
(
false
)
;
for
(
const
criterion
of
this
.
criteria
)
{
const
criterion_done
=
criterion
(
input_ids
scores
)
;
for
(
let
i
=
0
;
i
<
is_done
.
length
;
+
+
i
)
{
is_done
[
i
]
|
|
=
criterion_done
[
i
]
;
}
}
return
is_done
;
}
[
Symbol
.
iterator
]
(
)
{
return
this
.
criteria
.
values
(
)
;
}
}
class
MaxLengthCriteria
extends
StoppingCriteria
{
constructor
(
max_length
max_position_embeddings
=
null
)
{
super
(
)
;
this
.
max_length
=
max_length
;
this
.
max_position_embeddings
=
max_position_embeddings
;
}
_call
(
input_ids
)
{
return
input_ids
.
map
(
ids
=
>
ids
.
length
>
=
this
.
max_length
)
;
}
}
class
EosTokenCriteria
extends
StoppingCriteria
{
constructor
(
eos_token_id
)
{
super
(
)
;
if
(
!
Array
.
isArray
(
eos_token_id
)
)
{
eos_token_id
=
[
eos_token_id
]
;
}
this
.
eos_token_id
=
eos_token_id
;
}
_call
(
input_ids
scores
)
{
return
input_ids
.
map
(
ids
=
>
{
const
last
=
ids
.
at
(
-
1
)
;
return
this
.
eos_token_id
.
some
(
eos_id
=
>
last
=
=
eos_id
)
;
}
)
;
}
}
class
InterruptableStoppingCriteria
extends
StoppingCriteria
{
constructor
(
)
{
super
(
)
;
this
.
interrupted
=
false
;
}
interrupt
(
)
{
this
.
interrupted
=
true
;
}
reset
(
)
{
this
.
interrupted
=
false
;
}
_call
(
input_ids
scores
)
{
return
new
Array
(
input_ids
.
length
)
.
fill
(
this
.
interrupted
)
;
}
}
}
)
"
.
/
src
/
generation
/
streamers
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
BaseStreamer
:
(
)
=
>
(
BaseStreamer
)
TextStreamer
:
(
)
=
>
(
TextStreamer
)
WhisperTextStreamer
:
(
)
=
>
(
WhisperTextStreamer
)
}
)
;
var
_utils_core_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
src
/
utils
/
core
.
js
"
)
;
var
_tokenizers_js__WEBPACK_IMPORTED_MODULE_1__
=
__webpack_require__
(
"
.
/
src
/
tokenizers
.
js
"
)
;
var
_env_js__WEBPACK_IMPORTED_MODULE_2__
=
__webpack_require__
(
"
.
/
src
/
env
.
js
"
)
;
class
BaseStreamer
{
put
(
value
)
{
throw
Error
(
'
Not
implemented
'
)
;
}
end
(
)
{
throw
Error
(
'
Not
implemented
'
)
;
}
}
const
stdout_write
=
_env_js__WEBPACK_IMPORTED_MODULE_2__
.
apis
.
IS_PROCESS_AVAILABLE
?
x
=
>
process
.
stdout
.
write
(
x
)
:
x
=
>
console
.
log
(
x
)
;
class
TextStreamer
extends
BaseStreamer
{
constructor
(
tokenizer
{
skip_prompt
=
false
callback_function
=
null
token_callback_function
=
null
decode_kwargs
=
{
}
.
.
.
kwargs
}
=
{
}
)
{
super
(
)
;
this
.
tokenizer
=
tokenizer
;
this
.
skip_prompt
=
skip_prompt
;
this
.
callback_function
=
callback_function
?
?
stdout_write
;
this
.
token_callback_function
=
token_callback_function
;
this
.
decode_kwargs
=
{
.
.
.
decode_kwargs
.
.
.
kwargs
}
;
this
.
token_cache
=
[
]
;
this
.
print_len
=
0
;
this
.
next_tokens_are_prompt
=
true
;
}
put
(
value
)
{
if
(
value
.
length
>
1
)
{
throw
Error
(
'
TextStreamer
only
supports
batch
size
of
1
'
)
;
}
if
(
this
.
skip_prompt
&
&
this
.
next_tokens_are_prompt
)
{
this
.
next_tokens_are_prompt
=
false
;
return
;
}
const
tokens
=
value
[
0
]
;
this
.
token_callback_function
?
.
(
tokens
)
this
.
token_cache
=
(
0
_utils_core_js__WEBPACK_IMPORTED_MODULE_0__
.
mergeArrays
)
(
this
.
token_cache
tokens
)
;
const
text
=
this
.
tokenizer
.
decode
(
this
.
token_cache
this
.
decode_kwargs
)
;
let
printable_text
;
if
(
text
.
endsWith
(
'
\
n
'
)
)
{
printable_text
=
text
.
slice
(
this
.
print_len
)
;
this
.
token_cache
=
[
]
;
this
.
print_len
=
0
;
}
else
if
(
text
.
length
>
0
&
&
(
0
_tokenizers_js__WEBPACK_IMPORTED_MODULE_1__
.
is_chinese_char
)
(
text
.
charCodeAt
(
text
.
length
-
1
)
)
)
{
printable_text
=
text
.
slice
(
this
.
print_len
)
;
this
.
print_len
+
=
printable_text
.
length
;
}
else
{
printable_text
=
text
.
slice
(
this
.
print_len
text
.
lastIndexOf
(
'
'
)
+
1
)
;
this
.
print_len
+
=
printable_text
.
length
;
}
this
.
on_finalized_text
(
printable_text
false
)
;
}
end
(
)
{
let
printable_text
;
if
(
this
.
token_cache
.
length
>
0
)
{
const
text
=
this
.
tokenizer
.
decode
(
this
.
token_cache
this
.
decode_kwargs
)
;
printable_text
=
text
.
slice
(
this
.
print_len
)
;
this
.
token_cache
=
[
]
;
this
.
print_len
=
0
;
}
else
{
printable_text
=
'
'
;
}
this
.
next_tokens_are_prompt
=
true
;
this
.
on_finalized_text
(
printable_text
true
)
;
}
on_finalized_text
(
text
stream_end
)
{
if
(
text
.
length
>
0
)
{
this
.
callback_function
?
.
(
text
)
;
}
if
(
stream_end
&
&
this
.
callback_function
=
=
=
stdout_write
&
&
_env_js__WEBPACK_IMPORTED_MODULE_2__
.
apis
.
IS_PROCESS_AVAILABLE
)
{
this
.
callback_function
?
.
(
'
\
n
'
)
;
}
}
}
class
WhisperTextStreamer
extends
TextStreamer
{
constructor
(
tokenizer
{
skip_prompt
=
false
callback_function
=
null
token_callback_function
=
null
on_chunk_start
=
null
on_chunk_end
=
null
on_finalize
=
null
time_precision
=
0
.
02
skip_special_tokens
=
true
decode_kwargs
=
{
}
}
=
{
}
)
{
super
(
tokenizer
{
skip_prompt
callback_function
token_callback_function
decode_kwargs
:
{
skip_special_tokens
.
.
.
decode_kwargs
}
}
)
;
this
.
timestamp_begin
=
tokenizer
.
timestamp_begin
;
this
.
on_chunk_start
=
on_chunk_start
;
this
.
on_chunk_end
=
on_chunk_end
;
this
.
on_finalize
=
on_finalize
;
this
.
time_precision
=
time_precision
;
this
.
waiting_for_timestamp
=
false
;
}
put
(
value
)
{
if
(
value
.
length
>
1
)
{
throw
Error
(
'
WhisperTextStreamer
only
supports
batch
size
of
1
'
)
;
}
const
tokens
=
value
[
0
]
;
if
(
tokens
.
length
=
=
=
1
)
{
const
offset
=
Number
(
tokens
[
0
]
)
-
this
.
timestamp_begin
;
if
(
offset
>
=
0
)
{
const
time
=
offset
*
this
.
time_precision
;
if
(
this
.
waiting_for_timestamp
)
{
this
.
on_chunk_end
?
.
(
time
)
;
}
else
{
this
.
on_chunk_start
?
.
(
time
)
;
}
this
.
waiting_for_timestamp
=
!
this
.
waiting_for_timestamp
;
value
=
[
[
]
]
;
}
}
return
super
.
put
(
value
)
;
}
end
(
)
{
super
.
end
(
)
;
this
.
on_finalize
?
.
(
)
;
}
}
}
)
"
.
/
src
/
models
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
ASTForAudioClassification
:
(
)
=
>
(
ASTForAudioClassification
)
ASTModel
:
(
)
=
>
(
ASTModel
)
ASTPreTrainedModel
:
(
)
=
>
(
ASTPreTrainedModel
)
AlbertForMaskedLM
:
(
)
=
>
(
AlbertForMaskedLM
)
AlbertForQuestionAnswering
:
(
)
=
>
(
AlbertForQuestionAnswering
)
AlbertForSequenceClassification
:
(
)
=
>
(
AlbertForSequenceClassification
)
AlbertModel
:
(
)
=
>
(
AlbertModel
)
AlbertPreTrainedModel
:
(
)
=
>
(
AlbertPreTrainedModel
)
AutoModel
:
(
)
=
>
(
AutoModel
)
AutoModelForAudioClassification
:
(
)
=
>
(
AutoModelForAudioClassification
)
AutoModelForAudioFrameClassification
:
(
)
=
>
(
AutoModelForAudioFrameClassification
)
AutoModelForCTC
:
(
)
=
>
(
AutoModelForCTC
)
AutoModelForCausalLM
:
(
)
=
>
(
AutoModelForCausalLM
)
AutoModelForDepthEstimation
:
(
)
=
>
(
AutoModelForDepthEstimation
)
AutoModelForDocumentQuestionAnswering
:
(
)
=
>
(
AutoModelForDocumentQuestionAnswering
)
AutoModelForImageClassification
:
(
)
=
>
(
AutoModelForImageClassification
)
AutoModelForImageFeatureExtraction
:
(
)
=
>
(
AutoModelForImageFeatureExtraction
)
AutoModelForImageMatting
:
(
)
=
>
(
AutoModelForImageMatting
)
AutoModelForImageSegmentation
:
(
)
=
>
(
AutoModelForImageSegmentation
)
AutoModelForImageToImage
:
(
)
=
>
(
AutoModelForImageToImage
)
AutoModelForMaskGeneration
:
(
)
=
>
(
AutoModelForMaskGeneration
)
AutoModelForMaskedLM
:
(
)
=
>
(
AutoModelForMaskedLM
)
AutoModelForNormalEstimation
:
(
)
=
>
(
AutoModelForNormalEstimation
)
AutoModelForObjectDetection
:
(
)
=
>
(
AutoModelForObjectDetection
)
AutoModelForPoseEstimation
:
(
)
=
>
(
AutoModelForPoseEstimation
)
AutoModelForQuestionAnswering
:
(
)
=
>
(
AutoModelForQuestionAnswering
)
AutoModelForSemanticSegmentation
:
(
)
=
>
(
AutoModelForSemanticSegmentation
)
AutoModelForSeq2SeqLM
:
(
)
=
>
(
AutoModelForSeq2SeqLM
)
AutoModelForSequenceClassification
:
(
)
=
>
(
AutoModelForSequenceClassification
)
AutoModelForSpeechSeq2Seq
:
(
)
=
>
(
AutoModelForSpeechSeq2Seq
)
AutoModelForTextToSpectrogram
:
(
)
=
>
(
AutoModelForTextToSpectrogram
)
AutoModelForTextToWaveform
:
(
)
=
>
(
AutoModelForTextToWaveform
)
AutoModelForTokenClassification
:
(
)
=
>
(
AutoModelForTokenClassification
)
AutoModelForUniversalSegmentation
:
(
)
=
>
(
AutoModelForUniversalSegmentation
)
AutoModelForVision2Seq
:
(
)
=
>
(
AutoModelForVision2Seq
)
AutoModelForXVector
:
(
)
=
>
(
AutoModelForXVector
)
AutoModelForZeroShotObjectDetection
:
(
)
=
>
(
AutoModelForZeroShotObjectDetection
)
BartForConditionalGeneration
:
(
)
=
>
(
BartForConditionalGeneration
)
BartForSequenceClassification
:
(
)
=
>
(
BartForSequenceClassification
)
BartModel
:
(
)
=
>
(
BartModel
)
BartPretrainedModel
:
(
)
=
>
(
BartPretrainedModel
)
BaseModelOutput
:
(
)
=
>
(
BaseModelOutput
)
BeitForImageClassification
:
(
)
=
>
(
BeitForImageClassification
)
BeitModel
:
(
)
=
>
(
BeitModel
)
BeitPreTrainedModel
:
(
)
=
>
(
BeitPreTrainedModel
)
BertForMaskedLM
:
(
)
=
>
(
BertForMaskedLM
)
BertForQuestionAnswering
:
(
)
=
>
(
BertForQuestionAnswering
)
BertForSequenceClassification
:
(
)
=
>
(
BertForSequenceClassification
)
BertForTokenClassification
:
(
)
=
>
(
BertForTokenClassification
)
BertModel
:
(
)
=
>
(
BertModel
)
BertPreTrainedModel
:
(
)
=
>
(
BertPreTrainedModel
)
BlenderbotForConditionalGeneration
:
(
)
=
>
(
BlenderbotForConditionalGeneration
)
BlenderbotModel
:
(
)
=
>
(
BlenderbotModel
)
BlenderbotPreTrainedModel
:
(
)
=
>
(
BlenderbotPreTrainedModel
)
BlenderbotSmallForConditionalGeneration
:
(
)
=
>
(
BlenderbotSmallForConditionalGeneration
)
BlenderbotSmallModel
:
(
)
=
>
(
BlenderbotSmallModel
)
BlenderbotSmallPreTrainedModel
:
(
)
=
>
(
BlenderbotSmallPreTrainedModel
)
BloomForCausalLM
:
(
)
=
>
(
BloomForCausalLM
)
BloomModel
:
(
)
=
>
(
BloomModel
)
BloomPreTrainedModel
:
(
)
=
>
(
BloomPreTrainedModel
)
CLIPModel
:
(
)
=
>
(
CLIPModel
)
CLIPPreTrainedModel
:
(
)
=
>
(
CLIPPreTrainedModel
)
CLIPSegForImageSegmentation
:
(
)
=
>
(
CLIPSegForImageSegmentation
)
CLIPSegModel
:
(
)
=
>
(
CLIPSegModel
)
CLIPSegPreTrainedModel
:
(
)
=
>
(
CLIPSegPreTrainedModel
)
CLIPTextModel
:
(
)
=
>
(
CLIPTextModel
)
CLIPTextModelWithProjection
:
(
)
=
>
(
CLIPTextModelWithProjection
)
CLIPVisionModel
:
(
)
=
>
(
CLIPVisionModel
)
CLIPVisionModelWithProjection
:
(
)
=
>
(
CLIPVisionModelWithProjection
)
CamembertForMaskedLM
:
(
)
=
>
(
CamembertForMaskedLM
)
CamembertForQuestionAnswering
:
(
)
=
>
(
CamembertForQuestionAnswering
)
CamembertForSequenceClassification
:
(
)
=
>
(
CamembertForSequenceClassification
)
CamembertForTokenClassification
:
(
)
=
>
(
CamembertForTokenClassification
)
CamembertModel
:
(
)
=
>
(
CamembertModel
)
CamembertPreTrainedModel
:
(
)
=
>
(
CamembertPreTrainedModel
)
CausalLMOutput
:
(
)
=
>
(
CausalLMOutput
)
CausalLMOutputWithPast
:
(
)
=
>
(
CausalLMOutputWithPast
)
ChineseCLIPModel
:
(
)
=
>
(
ChineseCLIPModel
)
ChineseCLIPPreTrainedModel
:
(
)
=
>
(
ChineseCLIPPreTrainedModel
)
ClapAudioModelWithProjection
:
(
)
=
>
(
ClapAudioModelWithProjection
)
ClapModel
:
(
)
=
>
(
ClapModel
)
ClapPreTrainedModel
:
(
)
=
>
(
ClapPreTrainedModel
)
ClapTextModelWithProjection
:
(
)
=
>
(
ClapTextModelWithProjection
)
CodeGenForCausalLM
:
(
)
=
>
(
CodeGenForCausalLM
)
CodeGenModel
:
(
)
=
>
(
CodeGenModel
)
CodeGenPreTrainedModel
:
(
)
=
>
(
CodeGenPreTrainedModel
)
CohereForCausalLM
:
(
)
=
>
(
CohereForCausalLM
)
CohereModel
:
(
)
=
>
(
CohereModel
)
CoherePreTrainedModel
:
(
)
=
>
(
CoherePreTrainedModel
)
ConvBertForMaskedLM
:
(
)
=
>
(
ConvBertForMaskedLM
)
ConvBertForQuestionAnswering
:
(
)
=
>
(
ConvBertForQuestionAnswering
)
ConvBertForSequenceClassification
:
(
)
=
>
(
ConvBertForSequenceClassification
)
ConvBertForTokenClassification
:
(
)
=
>
(
ConvBertForTokenClassification
)
ConvBertModel
:
(
)
=
>
(
ConvBertModel
)
ConvBertPreTrainedModel
:
(
)
=
>
(
ConvBertPreTrainedModel
)
ConvNextForImageClassification
:
(
)
=
>
(
ConvNextForImageClassification
)
ConvNextModel
:
(
)
=
>
(
ConvNextModel
)
ConvNextPreTrainedModel
:
(
)
=
>
(
ConvNextPreTrainedModel
)
ConvNextV2ForImageClassification
:
(
)
=
>
(
ConvNextV2ForImageClassification
)
ConvNextV2Model
:
(
)
=
>
(
ConvNextV2Model
)
ConvNextV2PreTrainedModel
:
(
)
=
>
(
ConvNextV2PreTrainedModel
)
DPTForDepthEstimation
:
(
)
=
>
(
DPTForDepthEstimation
)
DPTModel
:
(
)
=
>
(
DPTModel
)
DPTPreTrainedModel
:
(
)
=
>
(
DPTPreTrainedModel
)
DebertaForMaskedLM
:
(
)
=
>
(
DebertaForMaskedLM
)
DebertaForQuestionAnswering
:
(
)
=
>
(
DebertaForQuestionAnswering
)
DebertaForSequenceClassification
:
(
)
=
>
(
DebertaForSequenceClassification
)
DebertaForTokenClassification
:
(
)
=
>
(
DebertaForTokenClassification
)
DebertaModel
:
(
)
=
>
(
DebertaModel
)
DebertaPreTrainedModel
:
(
)
=
>
(
DebertaPreTrainedModel
)
DebertaV2ForMaskedLM
:
(
)
=
>
(
DebertaV2ForMaskedLM
)
DebertaV2ForQuestionAnswering
:
(
)
=
>
(
DebertaV2ForQuestionAnswering
)
DebertaV2ForSequenceClassification
:
(
)
=
>
(
DebertaV2ForSequenceClassification
)
DebertaV2ForTokenClassification
:
(
)
=
>
(
DebertaV2ForTokenClassification
)
DebertaV2Model
:
(
)
=
>
(
DebertaV2Model
)
DebertaV2PreTrainedModel
:
(
)
=
>
(
DebertaV2PreTrainedModel
)
DecisionTransformerModel
:
(
)
=
>
(
DecisionTransformerModel
)
DecisionTransformerPreTrainedModel
:
(
)
=
>
(
DecisionTransformerPreTrainedModel
)
DeiTForImageClassification
:
(
)
=
>
(
DeiTForImageClassification
)
DeiTModel
:
(
)
=
>
(
DeiTModel
)
DeiTPreTrainedModel
:
(
)
=
>
(
DeiTPreTrainedModel
)
DepthAnythingForDepthEstimation
:
(
)
=
>
(
DepthAnythingForDepthEstimation
)
DepthAnythingPreTrainedModel
:
(
)
=
>
(
DepthAnythingPreTrainedModel
)
DepthProForDepthEstimation
:
(
)
=
>
(
DepthProForDepthEstimation
)
DepthProPreTrainedModel
:
(
)
=
>
(
DepthProPreTrainedModel
)
DetrForObjectDetection
:
(
)
=
>
(
DetrForObjectDetection
)
DetrForSegmentation
:
(
)
=
>
(
DetrForSegmentation
)
DetrModel
:
(
)
=
>
(
DetrModel
)
DetrObjectDetectionOutput
:
(
)
=
>
(
DetrObjectDetectionOutput
)
DetrPreTrainedModel
:
(
)
=
>
(
DetrPreTrainedModel
)
DetrSegmentationOutput
:
(
)
=
>
(
DetrSegmentationOutput
)
Dinov2ForImageClassification
:
(
)
=
>
(
Dinov2ForImageClassification
)
Dinov2Model
:
(
)
=
>
(
Dinov2Model
)
Dinov2PreTrainedModel
:
(
)
=
>
(
Dinov2PreTrainedModel
)
DistilBertForMaskedLM
:
(
)
=
>
(
DistilBertForMaskedLM
)
DistilBertForQuestionAnswering
:
(
)
=
>
(
DistilBertForQuestionAnswering
)
DistilBertForSequenceClassification
:
(
)
=
>
(
DistilBertForSequenceClassification
)
DistilBertForTokenClassification
:
(
)
=
>
(
DistilBertForTokenClassification
)
DistilBertModel
:
(
)
=
>
(
DistilBertModel
)
DistilBertPreTrainedModel
:
(
)
=
>
(
DistilBertPreTrainedModel
)
DonutSwinModel
:
(
)
=
>
(
DonutSwinModel
)
DonutSwinPreTrainedModel
:
(
)
=
>
(
DonutSwinPreTrainedModel
)
EfficientNetForImageClassification
:
(
)
=
>
(
EfficientNetForImageClassification
)
EfficientNetModel
:
(
)
=
>
(
EfficientNetModel
)
EfficientNetPreTrainedModel
:
(
)
=
>
(
EfficientNetPreTrainedModel
)
ElectraForMaskedLM
:
(
)
=
>
(
ElectraForMaskedLM
)
ElectraForQuestionAnswering
:
(
)
=
>
(
ElectraForQuestionAnswering
)
ElectraForSequenceClassification
:
(
)
=
>
(
ElectraForSequenceClassification
)
ElectraForTokenClassification
:
(
)
=
>
(
ElectraForTokenClassification
)
ElectraModel
:
(
)
=
>
(
ElectraModel
)
ElectraPreTrainedModel
:
(
)
=
>
(
ElectraPreTrainedModel
)
EsmForMaskedLM
:
(
)
=
>
(
EsmForMaskedLM
)
EsmForSequenceClassification
:
(
)
=
>
(
EsmForSequenceClassification
)
EsmForTokenClassification
:
(
)
=
>
(
EsmForTokenClassification
)
EsmModel
:
(
)
=
>
(
EsmModel
)
EsmPreTrainedModel
:
(
)
=
>
(
EsmPreTrainedModel
)
FalconForCausalLM
:
(
)
=
>
(
FalconForCausalLM
)
FalconModel
:
(
)
=
>
(
FalconModel
)
FalconPreTrainedModel
:
(
)
=
>
(
FalconPreTrainedModel
)
FastViTForImageClassification
:
(
)
=
>
(
FastViTForImageClassification
)
FastViTModel
:
(
)
=
>
(
FastViTModel
)
FastViTPreTrainedModel
:
(
)
=
>
(
FastViTPreTrainedModel
)
Florence2ForConditionalGeneration
:
(
)
=
>
(
Florence2ForConditionalGeneration
)
Florence2PreTrainedModel
:
(
)
=
>
(
Florence2PreTrainedModel
)
GLPNForDepthEstimation
:
(
)
=
>
(
GLPNForDepthEstimation
)
GLPNModel
:
(
)
=
>
(
GLPNModel
)
GLPNPreTrainedModel
:
(
)
=
>
(
GLPNPreTrainedModel
)
GPT2LMHeadModel
:
(
)
=
>
(
GPT2LMHeadModel
)
GPT2Model
:
(
)
=
>
(
GPT2Model
)
GPT2PreTrainedModel
:
(
)
=
>
(
GPT2PreTrainedModel
)
GPTBigCodeForCausalLM
:
(
)
=
>
(
GPTBigCodeForCausalLM
)
GPTBigCodeModel
:
(
)
=
>
(
GPTBigCodeModel
)
GPTBigCodePreTrainedModel
:
(
)
=
>
(
GPTBigCodePreTrainedModel
)
GPTJForCausalLM
:
(
)
=
>
(
GPTJForCausalLM
)
GPTJModel
:
(
)
=
>
(
GPTJModel
)
GPTJPreTrainedModel
:
(
)
=
>
(
GPTJPreTrainedModel
)
GPTNeoForCausalLM
:
(
)
=
>
(
GPTNeoForCausalLM
)
GPTNeoModel
:
(
)
=
>
(
GPTNeoModel
)
GPTNeoPreTrainedModel
:
(
)
=
>
(
GPTNeoPreTrainedModel
)
GPTNeoXForCausalLM
:
(
)
=
>
(
GPTNeoXForCausalLM
)
GPTNeoXModel
:
(
)
=
>
(
GPTNeoXModel
)
GPTNeoXPreTrainedModel
:
(
)
=
>
(
GPTNeoXPreTrainedModel
)
Gemma2ForCausalLM
:
(
)
=
>
(
Gemma2ForCausalLM
)
Gemma2Model
:
(
)
=
>
(
Gemma2Model
)
Gemma2PreTrainedModel
:
(
)
=
>
(
Gemma2PreTrainedModel
)
GemmaForCausalLM
:
(
)
=
>
(
GemmaForCausalLM
)
GemmaModel
:
(
)
=
>
(
GemmaModel
)
GemmaPreTrainedModel
:
(
)
=
>
(
GemmaPreTrainedModel
)
GraniteForCausalLM
:
(
)
=
>
(
GraniteForCausalLM
)
GraniteModel
:
(
)
=
>
(
GraniteModel
)
GranitePreTrainedModel
:
(
)
=
>
(
GranitePreTrainedModel
)
GroupViTModel
:
(
)
=
>
(
GroupViTModel
)
GroupViTPreTrainedModel
:
(
)
=
>
(
GroupViTPreTrainedModel
)
HieraForImageClassification
:
(
)
=
>
(
HieraForImageClassification
)
HieraModel
:
(
)
=
>
(
HieraModel
)
HieraPreTrainedModel
:
(
)
=
>
(
HieraPreTrainedModel
)
HubertForCTC
:
(
)
=
>
(
HubertForCTC
)
HubertForSequenceClassification
:
(
)
=
>
(
HubertForSequenceClassification
)
HubertModel
:
(
)
=
>
(
HubertModel
)
HubertPreTrainedModel
:
(
)
=
>
(
HubertPreTrainedModel
)
ImageMattingOutput
:
(
)
=
>
(
ImageMattingOutput
)
JAISLMHeadModel
:
(
)
=
>
(
JAISLMHeadModel
)
JAISModel
:
(
)
=
>
(
JAISModel
)
JAISPreTrainedModel
:
(
)
=
>
(
JAISPreTrainedModel
)
JinaCLIPModel
:
(
)
=
>
(
JinaCLIPModel
)
JinaCLIPPreTrainedModel
:
(
)
=
>
(
JinaCLIPPreTrainedModel
)
JinaCLIPTextModel
:
(
)
=
>
(
JinaCLIPTextModel
)
JinaCLIPVisionModel
:
(
)
=
>
(
JinaCLIPVisionModel
)
LlamaForCausalLM
:
(
)
=
>
(
LlamaForCausalLM
)
LlamaModel
:
(
)
=
>
(
LlamaModel
)
LlamaPreTrainedModel
:
(
)
=
>
(
LlamaPreTrainedModel
)
LlavaForConditionalGeneration
:
(
)
=
>
(
LlavaForConditionalGeneration
)
LlavaOnevisionForConditionalGeneration
:
(
)
=
>
(
LlavaOnevisionForConditionalGeneration
)
LlavaPreTrainedModel
:
(
)
=
>
(
LlavaPreTrainedModel
)
LongT5ForConditionalGeneration
:
(
)
=
>
(
LongT5ForConditionalGeneration
)
LongT5Model
:
(
)
=
>
(
LongT5Model
)
LongT5PreTrainedModel
:
(
)
=
>
(
LongT5PreTrainedModel
)
M2M100ForConditionalGeneration
:
(
)
=
>
(
M2M100ForConditionalGeneration
)
M2M100Model
:
(
)
=
>
(
M2M100Model
)
M2M100PreTrainedModel
:
(
)
=
>
(
M2M100PreTrainedModel
)
MBartForCausalLM
:
(
)
=
>
(
MBartForCausalLM
)
MBartForConditionalGeneration
:
(
)
=
>
(
MBartForConditionalGeneration
)
MBartForSequenceClassification
:
(
)
=
>
(
MBartForSequenceClassification
)
MBartModel
:
(
)
=
>
(
MBartModel
)
MBartPreTrainedModel
:
(
)
=
>
(
MBartPreTrainedModel
)
MPNetForMaskedLM
:
(
)
=
>
(
MPNetForMaskedLM
)
MPNetForQuestionAnswering
:
(
)
=
>
(
MPNetForQuestionAnswering
)
MPNetForSequenceClassification
:
(
)
=
>
(
MPNetForSequenceClassification
)
MPNetForTokenClassification
:
(
)
=
>
(
MPNetForTokenClassification
)
MPNetModel
:
(
)
=
>
(
MPNetModel
)
MPNetPreTrainedModel
:
(
)
=
>
(
MPNetPreTrainedModel
)
MT5ForConditionalGeneration
:
(
)
=
>
(
MT5ForConditionalGeneration
)
MT5Model
:
(
)
=
>
(
MT5Model
)
MT5PreTrainedModel
:
(
)
=
>
(
MT5PreTrainedModel
)
MarianMTModel
:
(
)
=
>
(
MarianMTModel
)
MarianModel
:
(
)
=
>
(
MarianModel
)
MarianPreTrainedModel
:
(
)
=
>
(
MarianPreTrainedModel
)
MaskFormerForInstanceSegmentation
:
(
)
=
>
(
MaskFormerForInstanceSegmentation
)
MaskFormerModel
:
(
)
=
>
(
MaskFormerModel
)
MaskFormerPreTrainedModel
:
(
)
=
>
(
MaskFormerPreTrainedModel
)
MaskedLMOutput
:
(
)
=
>
(
MaskedLMOutput
)
MgpstrForSceneTextRecognition
:
(
)
=
>
(
MgpstrForSceneTextRecognition
)
MgpstrModelOutput
:
(
)
=
>
(
MgpstrModelOutput
)
MgpstrPreTrainedModel
:
(
)
=
>
(
MgpstrPreTrainedModel
)
MistralForCausalLM
:
(
)
=
>
(
MistralForCausalLM
)
MistralModel
:
(
)
=
>
(
MistralModel
)
MistralPreTrainedModel
:
(
)
=
>
(
MistralPreTrainedModel
)
MobileBertForMaskedLM
:
(
)
=
>
(
MobileBertForMaskedLM
)
MobileBertForQuestionAnswering
:
(
)
=
>
(
MobileBertForQuestionAnswering
)
MobileBertForSequenceClassification
:
(
)
=
>
(
MobileBertForSequenceClassification
)
MobileBertModel
:
(
)
=
>
(
MobileBertModel
)
MobileBertPreTrainedModel
:
(
)
=
>
(
MobileBertPreTrainedModel
)
MobileLLMForCausalLM
:
(
)
=
>
(
MobileLLMForCausalLM
)
MobileLLMModel
:
(
)
=
>
(
MobileLLMModel
)
MobileLLMPreTrainedModel
:
(
)
=
>
(
MobileLLMPreTrainedModel
)
MobileNetV1ForImageClassification
:
(
)
=
>
(
MobileNetV1ForImageClassification
)
MobileNetV1Model
:
(
)
=
>
(
MobileNetV1Model
)
MobileNetV1PreTrainedModel
:
(
)
=
>
(
MobileNetV1PreTrainedModel
)
MobileNetV2ForImageClassification
:
(
)
=
>
(
MobileNetV2ForImageClassification
)
MobileNetV2Model
:
(
)
=
>
(
MobileNetV2Model
)
MobileNetV2PreTrainedModel
:
(
)
=
>
(
MobileNetV2PreTrainedModel
)
MobileNetV3ForImageClassification
:
(
)
=
>
(
MobileNetV3ForImageClassification
)
MobileNetV3Model
:
(
)
=
>
(
MobileNetV3Model
)
MobileNetV3PreTrainedModel
:
(
)
=
>
(
MobileNetV3PreTrainedModel
)
MobileNetV4ForImageClassification
:
(
)
=
>
(
MobileNetV4ForImageClassification
)
MobileNetV4Model
:
(
)
=
>
(
MobileNetV4Model
)
MobileNetV4PreTrainedModel
:
(
)
=
>
(
MobileNetV4PreTrainedModel
)
MobileViTForImageClassification
:
(
)
=
>
(
MobileViTForImageClassification
)
MobileViTModel
:
(
)
=
>
(
MobileViTModel
)
MobileViTPreTrainedModel
:
(
)
=
>
(
MobileViTPreTrainedModel
)
MobileViTV2ForImageClassification
:
(
)
=
>
(
MobileViTV2ForImageClassification
)
MobileViTV2Model
:
(
)
=
>
(
MobileViTV2Model
)
MobileViTV2PreTrainedModel
:
(
)
=
>
(
MobileViTV2PreTrainedModel
)
ModelOutput
:
(
)
=
>
(
ModelOutput
)
Moondream1ForConditionalGeneration
:
(
)
=
>
(
Moondream1ForConditionalGeneration
)
MptForCausalLM
:
(
)
=
>
(
MptForCausalLM
)
MptModel
:
(
)
=
>
(
MptModel
)
MptPreTrainedModel
:
(
)
=
>
(
MptPreTrainedModel
)
MultiModalityCausalLM
:
(
)
=
>
(
MultiModalityCausalLM
)
MultiModalityPreTrainedModel
:
(
)
=
>
(
MultiModalityPreTrainedModel
)
MusicgenForCausalLM
:
(
)
=
>
(
MusicgenForCausalLM
)
MusicgenForConditionalGeneration
:
(
)
=
>
(
MusicgenForConditionalGeneration
)
MusicgenModel
:
(
)
=
>
(
MusicgenModel
)
MusicgenPreTrainedModel
:
(
)
=
>
(
MusicgenPreTrainedModel
)
NomicBertModel
:
(
)
=
>
(
NomicBertModel
)
NomicBertPreTrainedModel
:
(
)
=
>
(
NomicBertPreTrainedModel
)
OPTForCausalLM
:
(
)
=
>
(
OPTForCausalLM
)
OPTModel
:
(
)
=
>
(
OPTModel
)
OPTPreTrainedModel
:
(
)
=
>
(
OPTPreTrainedModel
)
OlmoForCausalLM
:
(
)
=
>
(
OlmoForCausalLM
)
OlmoModel
:
(
)
=
>
(
OlmoModel
)
OlmoPreTrainedModel
:
(
)
=
>
(
OlmoPreTrainedModel
)
OpenELMForCausalLM
:
(
)
=
>
(
OpenELMForCausalLM
)
OpenELMModel
:
(
)
=
>
(
OpenELMModel
)
OpenELMPreTrainedModel
:
(
)
=
>
(
OpenELMPreTrainedModel
)
OwlViTForObjectDetection
:
(
)
=
>
(
OwlViTForObjectDetection
)
OwlViTModel
:
(
)
=
>
(
OwlViTModel
)
OwlViTPreTrainedModel
:
(
)
=
>
(
OwlViTPreTrainedModel
)
Owlv2ForObjectDetection
:
(
)
=
>
(
Owlv2ForObjectDetection
)
Owlv2Model
:
(
)
=
>
(
Owlv2Model
)
Owlv2PreTrainedModel
:
(
)
=
>
(
Owlv2PreTrainedModel
)
PatchTSMixerForPrediction
:
(
)
=
>
(
PatchTSMixerForPrediction
)
PatchTSMixerModel
:
(
)
=
>
(
PatchTSMixerModel
)
PatchTSMixerPreTrainedModel
:
(
)
=
>
(
PatchTSMixerPreTrainedModel
)
PatchTSTForPrediction
:
(
)
=
>
(
PatchTSTForPrediction
)
PatchTSTModel
:
(
)
=
>
(
PatchTSTModel
)
PatchTSTPreTrainedModel
:
(
)
=
>
(
PatchTSTPreTrainedModel
)
Phi3ForCausalLM
:
(
)
=
>
(
Phi3ForCausalLM
)
Phi3Model
:
(
)
=
>
(
Phi3Model
)
Phi3PreTrainedModel
:
(
)
=
>
(
Phi3PreTrainedModel
)
PhiForCausalLM
:
(
)
=
>
(
PhiForCausalLM
)
PhiModel
:
(
)
=
>
(
PhiModel
)
PhiPreTrainedModel
:
(
)
=
>
(
PhiPreTrainedModel
)
PreTrainedModel
:
(
)
=
>
(
PreTrainedModel
)
PretrainedMixin
:
(
)
=
>
(
PretrainedMixin
)
PvtForImageClassification
:
(
)
=
>
(
PvtForImageClassification
)
PvtModel
:
(
)
=
>
(
PvtModel
)
PvtPreTrainedModel
:
(
)
=
>
(
PvtPreTrainedModel
)
PyAnnoteForAudioFrameClassification
:
(
)
=
>
(
PyAnnoteForAudioFrameClassification
)
PyAnnoteModel
:
(
)
=
>
(
PyAnnoteModel
)
PyAnnotePreTrainedModel
:
(
)
=
>
(
PyAnnotePreTrainedModel
)
QuestionAnsweringModelOutput
:
(
)
=
>
(
QuestionAnsweringModelOutput
)
Qwen2ForCausalLM
:
(
)
=
>
(
Qwen2ForCausalLM
)
Qwen2Model
:
(
)
=
>
(
Qwen2Model
)
Qwen2PreTrainedModel
:
(
)
=
>
(
Qwen2PreTrainedModel
)
Qwen2VLForConditionalGeneration
:
(
)
=
>
(
Qwen2VLForConditionalGeneration
)
Qwen2VLPreTrainedModel
:
(
)
=
>
(
Qwen2VLPreTrainedModel
)
RTDetrForObjectDetection
:
(
)
=
>
(
RTDetrForObjectDetection
)
RTDetrModel
:
(
)
=
>
(
RTDetrModel
)
RTDetrObjectDetectionOutput
:
(
)
=
>
(
RTDetrObjectDetectionOutput
)
RTDetrPreTrainedModel
:
(
)
=
>
(
RTDetrPreTrainedModel
)
ResNetForImageClassification
:
(
)
=
>
(
ResNetForImageClassification
)
ResNetModel
:
(
)
=
>
(
ResNetModel
)
ResNetPreTrainedModel
:
(
)
=
>
(
ResNetPreTrainedModel
)
RoFormerForMaskedLM
:
(
)
=
>
(
RoFormerForMaskedLM
)
RoFormerForQuestionAnswering
:
(
)
=
>
(
RoFormerForQuestionAnswering
)
RoFormerForSequenceClassification
:
(
)
=
>
(
RoFormerForSequenceClassification
)
RoFormerForTokenClassification
:
(
)
=
>
(
RoFormerForTokenClassification
)
RoFormerModel
:
(
)
=
>
(
RoFormerModel
)
RoFormerPreTrainedModel
:
(
)
=
>
(
RoFormerPreTrainedModel
)
RobertaForMaskedLM
:
(
)
=
>
(
RobertaForMaskedLM
)
RobertaForQuestionAnswering
:
(
)
=
>
(
RobertaForQuestionAnswering
)
RobertaForSequenceClassification
:
(
)
=
>
(
RobertaForSequenceClassification
)
RobertaForTokenClassification
:
(
)
=
>
(
RobertaForTokenClassification
)
RobertaModel
:
(
)
=
>
(
RobertaModel
)
RobertaPreTrainedModel
:
(
)
=
>
(
RobertaPreTrainedModel
)
SamImageSegmentationOutput
:
(
)
=
>
(
SamImageSegmentationOutput
)
SamModel
:
(
)
=
>
(
SamModel
)
SamPreTrainedModel
:
(
)
=
>
(
SamPreTrainedModel
)
SapiensForDepthEstimation
:
(
)
=
>
(
SapiensForDepthEstimation
)
SapiensForNormalEstimation
:
(
)
=
>
(
SapiensForNormalEstimation
)
SapiensForSemanticSegmentation
:
(
)
=
>
(
SapiensForSemanticSegmentation
)
SapiensPreTrainedModel
:
(
)
=
>
(
SapiensPreTrainedModel
)
SegformerForImageClassification
:
(
)
=
>
(
SegformerForImageClassification
)
SegformerForSemanticSegmentation
:
(
)
=
>
(
SegformerForSemanticSegmentation
)
SegformerModel
:
(
)
=
>
(
SegformerModel
)
SegformerPreTrainedModel
:
(
)
=
>
(
SegformerPreTrainedModel
)
Seq2SeqLMOutput
:
(
)
=
>
(
Seq2SeqLMOutput
)
SequenceClassifierOutput
:
(
)
=
>
(
SequenceClassifierOutput
)
SiglipModel
:
(
)
=
>
(
SiglipModel
)
SiglipPreTrainedModel
:
(
)
=
>
(
SiglipPreTrainedModel
)
SiglipTextModel
:
(
)
=
>
(
SiglipTextModel
)
SiglipVisionModel
:
(
)
=
>
(
SiglipVisionModel
)
SpeechT5ForSpeechToText
:
(
)
=
>
(
SpeechT5ForSpeechToText
)
SpeechT5ForTextToSpeech
:
(
)
=
>
(
SpeechT5ForTextToSpeech
)
SpeechT5HifiGan
:
(
)
=
>
(
SpeechT5HifiGan
)
SpeechT5Model
:
(
)
=
>
(
SpeechT5Model
)
SpeechT5PreTrainedModel
:
(
)
=
>
(
SpeechT5PreTrainedModel
)
SqueezeBertForMaskedLM
:
(
)
=
>
(
SqueezeBertForMaskedLM
)
SqueezeBertForQuestionAnswering
:
(
)
=
>
(
SqueezeBertForQuestionAnswering
)
SqueezeBertForSequenceClassification
:
(
)
=
>
(
SqueezeBertForSequenceClassification
)
SqueezeBertModel
:
(
)
=
>
(
SqueezeBertModel
)
SqueezeBertPreTrainedModel
:
(
)
=
>
(
SqueezeBertPreTrainedModel
)
StableLmForCausalLM
:
(
)
=
>
(
StableLmForCausalLM
)
StableLmModel
:
(
)
=
>
(
StableLmModel
)
StableLmPreTrainedModel
:
(
)
=
>
(
StableLmPreTrainedModel
)
Starcoder2ForCausalLM
:
(
)
=
>
(
Starcoder2ForCausalLM
)
Starcoder2Model
:
(
)
=
>
(
Starcoder2Model
)
Starcoder2PreTrainedModel
:
(
)
=
>
(
Starcoder2PreTrainedModel
)
Swin2SRForImageSuperResolution
:
(
)
=
>
(
Swin2SRForImageSuperResolution
)
Swin2SRModel
:
(
)
=
>
(
Swin2SRModel
)
Swin2SRPreTrainedModel
:
(
)
=
>
(
Swin2SRPreTrainedModel
)
SwinForImageClassification
:
(
)
=
>
(
SwinForImageClassification
)
SwinModel
:
(
)
=
>
(
SwinModel
)
SwinPreTrainedModel
:
(
)
=
>
(
SwinPreTrainedModel
)
T5ForConditionalGeneration
:
(
)
=
>
(
T5ForConditionalGeneration
)
T5Model
:
(
)
=
>
(
T5Model
)
T5PreTrainedModel
:
(
)
=
>
(
T5PreTrainedModel
)
TableTransformerForObjectDetection
:
(
)
=
>
(
TableTransformerForObjectDetection
)
TableTransformerModel
:
(
)
=
>
(
TableTransformerModel
)
TableTransformerObjectDetectionOutput
:
(
)
=
>
(
TableTransformerObjectDetectionOutput
)
TableTransformerPreTrainedModel
:
(
)
=
>
(
TableTransformerPreTrainedModel
)
TokenClassifierOutput
:
(
)
=
>
(
TokenClassifierOutput
)
TrOCRForCausalLM
:
(
)
=
>
(
TrOCRForCausalLM
)
TrOCRPreTrainedModel
:
(
)
=
>
(
TrOCRPreTrainedModel
)
UniSpeechForCTC
:
(
)
=
>
(
UniSpeechForCTC
)
UniSpeechForSequenceClassification
:
(
)
=
>
(
UniSpeechForSequenceClassification
)
UniSpeechModel
:
(
)
=
>
(
UniSpeechModel
)
UniSpeechPreTrainedModel
:
(
)
=
>
(
UniSpeechPreTrainedModel
)
UniSpeechSatForAudioFrameClassification
:
(
)
=
>
(
UniSpeechSatForAudioFrameClassification
)
UniSpeechSatForCTC
:
(
)
=
>
(
UniSpeechSatForCTC
)
UniSpeechSatForSequenceClassification
:
(
)
=
>
(
UniSpeechSatForSequenceClassification
)
UniSpeechSatModel
:
(
)
=
>
(
UniSpeechSatModel
)
UniSpeechSatPreTrainedModel
:
(
)
=
>
(
UniSpeechSatPreTrainedModel
)
ViTForImageClassification
:
(
)
=
>
(
ViTForImageClassification
)
ViTMAEModel
:
(
)
=
>
(
ViTMAEModel
)
ViTMAEPreTrainedModel
:
(
)
=
>
(
ViTMAEPreTrainedModel
)
ViTMSNForImageClassification
:
(
)
=
>
(
ViTMSNForImageClassification
)
ViTMSNModel
:
(
)
=
>
(
ViTMSNModel
)
ViTMSNPreTrainedModel
:
(
)
=
>
(
ViTMSNPreTrainedModel
)
ViTModel
:
(
)
=
>
(
ViTModel
)
ViTPreTrainedModel
:
(
)
=
>
(
ViTPreTrainedModel
)
VisionEncoderDecoderModel
:
(
)
=
>
(
VisionEncoderDecoderModel
)
VitMatteForImageMatting
:
(
)
=
>
(
VitMatteForImageMatting
)
VitMattePreTrainedModel
:
(
)
=
>
(
VitMattePreTrainedModel
)
VitPoseForPoseEstimation
:
(
)
=
>
(
VitPoseForPoseEstimation
)
VitPosePreTrainedModel
:
(
)
=
>
(
VitPosePreTrainedModel
)
VitsModel
:
(
)
=
>
(
VitsModel
)
VitsModelOutput
:
(
)
=
>
(
VitsModelOutput
)
VitsPreTrainedModel
:
(
)
=
>
(
VitsPreTrainedModel
)
Wav2Vec2BertForCTC
:
(
)
=
>
(
Wav2Vec2BertForCTC
)
Wav2Vec2BertForSequenceClassification
:
(
)
=
>
(
Wav2Vec2BertForSequenceClassification
)
Wav2Vec2BertModel
:
(
)
=
>
(
Wav2Vec2BertModel
)
Wav2Vec2BertPreTrainedModel
:
(
)
=
>
(
Wav2Vec2BertPreTrainedModel
)
Wav2Vec2ForAudioFrameClassification
:
(
)
=
>
(
Wav2Vec2ForAudioFrameClassification
)
Wav2Vec2ForCTC
:
(
)
=
>
(
Wav2Vec2ForCTC
)
Wav2Vec2ForSequenceClassification
:
(
)
=
>
(
Wav2Vec2ForSequenceClassification
)
Wav2Vec2Model
:
(
)
=
>
(
Wav2Vec2Model
)
Wav2Vec2PreTrainedModel
:
(
)
=
>
(
Wav2Vec2PreTrainedModel
)
WavLMForAudioFrameClassification
:
(
)
=
>
(
WavLMForAudioFrameClassification
)
WavLMForCTC
:
(
)
=
>
(
WavLMForCTC
)
WavLMForSequenceClassification
:
(
)
=
>
(
WavLMForSequenceClassification
)
WavLMForXVector
:
(
)
=
>
(
WavLMForXVector
)
WavLMModel
:
(
)
=
>
(
WavLMModel
)
WavLMPreTrainedModel
:
(
)
=
>
(
WavLMPreTrainedModel
)
WeSpeakerResNetModel
:
(
)
=
>
(
WeSpeakerResNetModel
)
WeSpeakerResNetPreTrainedModel
:
(
)
=
>
(
WeSpeakerResNetPreTrainedModel
)
WhisperForConditionalGeneration
:
(
)
=
>
(
WhisperForConditionalGeneration
)
WhisperModel
:
(
)
=
>
(
WhisperModel
)
WhisperPreTrainedModel
:
(
)
=
>
(
WhisperPreTrainedModel
)
XLMForQuestionAnswering
:
(
)
=
>
(
XLMForQuestionAnswering
)
XLMForSequenceClassification
:
(
)
=
>
(
XLMForSequenceClassification
)
XLMForTokenClassification
:
(
)
=
>
(
XLMForTokenClassification
)
XLMModel
:
(
)
=
>
(
XLMModel
)
XLMPreTrainedModel
:
(
)
=
>
(
XLMPreTrainedModel
)
XLMRobertaForMaskedLM
:
(
)
=
>
(
XLMRobertaForMaskedLM
)
XLMRobertaForQuestionAnswering
:
(
)
=
>
(
XLMRobertaForQuestionAnswering
)
XLMRobertaForSequenceClassification
:
(
)
=
>
(
XLMRobertaForSequenceClassification
)
XLMRobertaForTokenClassification
:
(
)
=
>
(
XLMRobertaForTokenClassification
)
XLMRobertaModel
:
(
)
=
>
(
XLMRobertaModel
)
XLMRobertaPreTrainedModel
:
(
)
=
>
(
XLMRobertaPreTrainedModel
)
XLMWithLMHeadModel
:
(
)
=
>
(
XLMWithLMHeadModel
)
XVectorOutput
:
(
)
=
>
(
XVectorOutput
)
YolosForObjectDetection
:
(
)
=
>
(
YolosForObjectDetection
)
YolosModel
:
(
)
=
>
(
YolosModel
)
YolosObjectDetectionOutput
:
(
)
=
>
(
YolosObjectDetectionOutput
)
YolosPreTrainedModel
:
(
)
=
>
(
YolosPreTrainedModel
)
}
)
;
var
_configs_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
src
/
configs
.
js
"
)
;
var
_backends_onnx_js__WEBPACK_IMPORTED_MODULE_1__
=
__webpack_require__
(
"
.
/
src
/
backends
/
onnx
.
js
"
)
;
var
_utils_dtypes_js__WEBPACK_IMPORTED_MODULE_2__
=
__webpack_require__
(
"
.
/
src
/
utils
/
dtypes
.
js
"
)
;
var
_utils_generic_js__WEBPACK_IMPORTED_MODULE_3__
=
__webpack_require__
(
"
.
/
src
/
utils
/
generic
.
js
"
)
;
var
_utils_core_js__WEBPACK_IMPORTED_MODULE_4__
=
__webpack_require__
(
"
.
/
src
/
utils
/
core
.
js
"
)
;
var
_utils_hub_js__WEBPACK_IMPORTED_MODULE_5__
=
__webpack_require__
(
"
.
/
src
/
utils
/
hub
.
js
"
)
;
var
_utils_constants_js__WEBPACK_IMPORTED_MODULE_6__
=
__webpack_require__
(
"
.
/
src
/
utils
/
constants
.
js
"
)
;
var
_generation_logits_process_js__WEBPACK_IMPORTED_MODULE_7__
=
__webpack_require__
(
"
.
/
src
/
generation
/
logits_process
.
js
"
)
;
var
_generation_configuration_utils_js__WEBPACK_IMPORTED_MODULE_8__
=
__webpack_require__
(
"
.
/
src
/
generation
/
configuration_utils
.
js
"
)
;
var
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_9__
=
__webpack_require__
(
"
.
/
src
/
utils
/
tensor
.
js
"
)
;
var
_utils_image_js__WEBPACK_IMPORTED_MODULE_10__
=
__webpack_require__
(
"
.
/
src
/
utils
/
image
.
js
"
)
;
var
_utils_maths_js__WEBPACK_IMPORTED_MODULE_11__
=
__webpack_require__
(
"
.
/
src
/
utils
/
maths
.
js
"
)
;
var
_generation_stopping_criteria_js__WEBPACK_IMPORTED_MODULE_12__
=
__webpack_require__
(
"
.
/
src
/
generation
/
stopping_criteria
.
js
"
)
;
var
_generation_logits_sampler_js__WEBPACK_IMPORTED_MODULE_13__
=
__webpack_require__
(
"
.
/
src
/
generation
/
logits_sampler
.
js
"
)
;
var
_env_js__WEBPACK_IMPORTED_MODULE_14__
=
__webpack_require__
(
"
.
/
src
/
env
.
js
"
)
;
var
_models_whisper_generation_whisper_js__WEBPACK_IMPORTED_MODULE_15__
=
__webpack_require__
(
"
.
/
src
/
models
/
whisper
/
generation_whisper
.
js
"
)
;
var
_models_whisper_common_whisper_js__WEBPACK_IMPORTED_MODULE_16__
=
__webpack_require__
(
"
.
/
src
/
models
/
whisper
/
common_whisper
.
js
"
)
;
const
MODEL_TYPES
=
{
EncoderOnly
:
0
EncoderDecoder
:
1
Seq2Seq
:
2
Vision2Seq
:
3
DecoderOnly
:
4
MaskGeneration
:
5
ImageTextToText
:
6
Musicgen
:
7
MultiModality
:
8
}
const
MODEL_TYPE_MAPPING
=
new
Map
(
)
;
const
MODEL_NAME_TO_CLASS_MAPPING
=
new
Map
(
)
;
const
MODEL_CLASS_TO_NAME_MAPPING
=
new
Map
(
)
;
async
function
getSession
(
pretrained_model_name_or_path
fileName
options
)
{
const
custom_config
=
options
.
config
?
.
[
'
transformers
.
js_config
'
]
?
?
{
}
;
let
device
=
options
.
device
?
?
custom_config
.
device
;
if
(
device
&
&
typeof
device
!
=
=
'
string
'
)
{
if
(
device
.
hasOwnProperty
(
fileName
)
)
{
device
=
device
[
fileName
]
;
}
else
{
console
.
warn
(
device
not
specified
for
"
{
fileName
}
"
.
Using
the
default
device
.
)
;
device
=
null
;
}
}
const
selectedDevice
=
(
device
?
?
(
_env_js__WEBPACK_IMPORTED_MODULE_14__
.
apis
.
IS_NODE_ENV
?
'
cpu
'
:
'
wasm
'
)
)
;
const
executionProviders
=
(
0
_backends_onnx_js__WEBPACK_IMPORTED_MODULE_1__
.
deviceToExecutionProviders
)
(
selectedDevice
)
;
let
dtype
=
options
.
dtype
?
?
custom_config
.
dtype
;
if
(
typeof
dtype
!
=
=
'
string
'
)
{
if
(
dtype
&
&
dtype
.
hasOwnProperty
(
fileName
)
)
{
dtype
=
dtype
[
fileName
]
;
}
else
{
dtype
=
_utils_dtypes_js__WEBPACK_IMPORTED_MODULE_2__
.
DEFAULT_DEVICE_DTYPE_MAPPING
[
selectedDevice
]
?
?
_utils_dtypes_js__WEBPACK_IMPORTED_MODULE_2__
.
DATA_TYPES
.
fp32
;
console
.
warn
(
dtype
not
specified
for
"
{
fileName
}
"
.
Using
the
default
dtype
(
{
dtype
}
)
for
this
device
(
{
selectedDevice
}
)
.
)
;
}
}
const
selectedDtype
=
(
dtype
)
;
if
(
!
_utils_dtypes_js__WEBPACK_IMPORTED_MODULE_2__
.
DEFAULT_DTYPE_SUFFIX_MAPPING
.
hasOwnProperty
(
selectedDtype
)
)
{
throw
new
Error
(
Invalid
dtype
:
{
selectedDtype
}
.
Should
be
one
of
:
{
Object
.
keys
(
_utils_dtypes_js__WEBPACK_IMPORTED_MODULE_2__
.
DATA_TYPES
)
.
join
(
'
'
)
}
)
;
}
else
if
(
selectedDtype
=
=
=
_utils_dtypes_js__WEBPACK_IMPORTED_MODULE_2__
.
DATA_TYPES
.
fp16
&
&
selectedDevice
=
=
=
'
webgpu
'
&
&
!
(
await
(
0
_utils_dtypes_js__WEBPACK_IMPORTED_MODULE_2__
.
isWebGpuFp16Supported
)
(
)
)
)
{
throw
new
Error
(
The
device
(
{
selectedDevice
}
)
does
not
support
fp16
.
)
;
}
const
kv_cache_dtype
=
custom_config
.
kv_cache_dtype
?
(
typeof
custom_config
.
kv_cache_dtype
=
=
=
'
string
'
?
custom_config
.
kv_cache_dtype
:
custom_config
.
kv_cache_dtype
[
selectedDtype
]
?
?
'
float32
'
)
:
undefined
;
if
(
kv_cache_dtype
&
&
!
[
'
float32
'
'
float16
'
]
.
includes
(
kv_cache_dtype
)
)
{
throw
new
Error
(
Invalid
kv_cache_dtype
:
{
kv_cache_dtype
}
.
Should
be
one
of
:
float32
float16
)
;
}
const
session_config
=
{
dtype
:
selectedDtype
kv_cache_dtype
}
const
suffix
=
_utils_dtypes_js__WEBPACK_IMPORTED_MODULE_2__
.
DEFAULT_DTYPE_SUFFIX_MAPPING
[
selectedDtype
]
;
const
modelFileName
=
{
options
.
subfolder
?
?
'
'
}
/
{
fileName
}
{
suffix
}
.
onnx
;
const
session_options
=
{
.
.
.
options
.
session_options
}
;
session_options
.
executionProviders
?
?
=
executionProviders
;
const
free_dimension_overrides
=
custom_config
.
free_dimension_overrides
;
if
(
free_dimension_overrides
)
{
session_options
.
freeDimensionOverrides
?
?
=
free_dimension_overrides
;
}
else
if
(
selectedDevice
.
startsWith
(
'
webnn
'
)
&
&
!
session_options
.
freeDimensionOverrides
)
{
console
.
warn
(
'
WebNN
does
not
currently
support
dynamic
shapes
and
requires
free_dimension_overrides
to
be
set
in
config
.
json
as
a
field
within
"
transformers
.
js_config
"
.
'
+
'
When
free_dimension_overrides
is
not
set
you
may
experience
significant
performance
degradation
.
'
)
;
}
const
bufferPromise
=
(
0
_utils_hub_js__WEBPACK_IMPORTED_MODULE_5__
.
getModelFile
)
(
pretrained_model_name_or_path
modelFileName
true
options
)
;
const
use_external_data_format
=
options
.
use_external_data_format
?
?
custom_config
.
use_external_data_format
;
let
externalDataPromises
=
[
]
;
if
(
use_external_data_format
&
&
(
use_external_data_format
=
=
=
true
|
|
(
typeof
use_external_data_format
=
=
=
'
object
'
&
&
use_external_data_format
.
hasOwnProperty
(
fileName
)
&
&
use_external_data_format
[
fileName
]
=
=
=
true
)
)
)
{
if
(
_env_js__WEBPACK_IMPORTED_MODULE_14__
.
apis
.
IS_NODE_ENV
)
{
throw
new
Error
(
'
External
data
format
is
not
yet
supported
in
Node
.
js
'
)
;
}
const
path
=
{
fileName
}
{
suffix
}
.
onnx_data
;
const
fullPath
=
{
options
.
subfolder
?
?
'
'
}
/
{
path
}
;
externalDataPromises
.
push
(
new
Promise
(
async
(
resolve
reject
)
=
>
{
const
data
=
await
(
0
_utils_hub_js__WEBPACK_IMPORTED_MODULE_5__
.
getModelFile
)
(
pretrained_model_name_or_path
fullPath
true
options
)
;
resolve
(
{
path
data
}
)
}
)
)
;
}
else
if
(
session_options
.
externalData
!
=
=
undefined
)
{
externalDataPromises
=
session_options
.
externalData
.
map
(
async
(
ext
)
=
>
{
if
(
typeof
ext
.
data
=
=
=
"
string
"
)
{
const
ext_buffer
=
await
(
0
_utils_hub_js__WEBPACK_IMPORTED_MODULE_5__
.
getModelFile
)
(
pretrained_model_name_or_path
ext
.
data
true
options
)
;
return
{
.
.
.
ext
data
:
ext_buffer
}
;
}
return
ext
;
}
)
;
}
if
(
externalDataPromises
.
length
>
0
)
{
session_options
.
externalData
=
await
Promise
.
all
(
externalDataPromises
)
;
}
if
(
selectedDevice
=
=
=
'
webgpu
'
)
{
const
shapes
=
(
0
_configs_js__WEBPACK_IMPORTED_MODULE_0__
.
getKeyValueShapes
)
(
options
.
config
{
prefix
:
'
present
'
}
)
;
if
(
Object
.
keys
(
shapes
)
.
length
>
0
&
&
!
(
0
_backends_onnx_js__WEBPACK_IMPORTED_MODULE_1__
.
isONNXProxy
)
(
)
)
{
const
preferredOutputLocation
=
{
}
;
for
(
const
key
in
shapes
)
{
preferredOutputLocation
[
key
]
=
'
gpu
-
buffer
'
;
}
session_options
.
preferredOutputLocation
=
preferredOutputLocation
;
}
}
const
buffer
=
await
bufferPromise
;
return
{
buffer
session_options
session_config
}
;
}
async
function
constructSessions
(
pretrained_model_name_or_path
names
options
)
{
return
Object
.
fromEntries
(
await
Promise
.
all
(
Object
.
keys
(
names
)
.
map
(
async
(
name
)
=
>
{
const
{
buffer
session_options
session_config
}
=
await
getSession
(
pretrained_model_name_or_path
names
[
name
]
options
)
;
const
session
=
await
(
0
_backends_onnx_js__WEBPACK_IMPORTED_MODULE_1__
.
createInferenceSession
)
(
buffer
session_options
session_config
)
;
return
[
name
session
]
;
}
)
)
)
;
}
async
function
getOptionalConfigs
(
pretrained_model_name_or_path
names
options
)
{
return
Object
.
fromEntries
(
await
Promise
.
all
(
Object
.
keys
(
names
)
.
map
(
async
(
name
)
=
>
{
const
config
=
await
(
0
_utils_hub_js__WEBPACK_IMPORTED_MODULE_5__
.
getModelJSON
)
(
pretrained_model_name_or_path
names
[
name
]
false
options
)
;
return
[
name
config
]
;
}
)
)
)
;
}
function
validateInputs
(
session
inputs
)
{
const
checkedInputs
=
Object
.
create
(
null
)
;
const
missingInputs
=
[
]
;
for
(
const
inputName
of
session
.
inputNames
)
{
const
tensor
=
inputs
[
inputName
]
;
if
(
!
(
tensor
instanceof
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_9__
.
Tensor
)
)
{
missingInputs
.
push
(
inputName
)
;
continue
;
}
checkedInputs
[
inputName
]
=
(
0
_backends_onnx_js__WEBPACK_IMPORTED_MODULE_1__
.
isONNXProxy
)
(
)
?
tensor
.
clone
(
)
:
tensor
;
}
if
(
missingInputs
.
length
>
0
)
{
throw
new
Error
(
An
error
occurred
during
model
execution
:
"
Missing
the
following
inputs
:
{
missingInputs
.
join
(
'
'
)
}
.
)
;
}
const
numInputsProvided
=
Object
.
keys
(
inputs
)
.
length
;
const
numInputsNeeded
=
session
.
inputNames
.
length
;
if
(
numInputsProvided
>
numInputsNeeded
)
{
let
ignored
=
Object
.
keys
(
inputs
)
.
filter
(
inputName
=
>
!
session
.
inputNames
.
includes
(
inputName
)
)
;
console
.
warn
(
WARNING
:
Too
many
inputs
were
provided
(
{
numInputsProvided
}
>
{
numInputsNeeded
}
)
.
The
following
inputs
will
be
ignored
:
"
{
ignored
.
join
(
'
'
)
}
"
.
)
;
}
return
checkedInputs
;
}
async
function
sessionRun
(
session
inputs
)
{
const
checkedInputs
=
validateInputs
(
session
inputs
)
;
try
{
const
ortFeed
=
Object
.
fromEntries
(
Object
.
entries
(
checkedInputs
)
.
map
(
(
[
k
v
]
)
=
>
[
k
v
.
ort_tensor
]
)
)
;
let
output
=
await
session
.
run
(
ortFeed
)
;
output
=
replaceTensors
(
output
)
;
return
output
;
}
catch
(
e
)
{
console
.
error
(
An
error
occurred
during
model
execution
:
"
{
e
}
"
.
)
;
console
.
error
(
'
Inputs
given
to
model
:
'
checkedInputs
)
throw
e
;
}
}
function
replaceTensors
(
obj
)
{
for
(
let
prop
in
obj
)
{
if
(
(
0
_backends_onnx_js__WEBPACK_IMPORTED_MODULE_1__
.
isONNXTensor
)
(
obj
[
prop
]
)
)
{
obj
[
prop
]
=
new
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_9__
.
Tensor
(
obj
[
prop
]
)
;
}
else
if
(
typeof
obj
[
prop
]
=
=
=
'
object
'
)
{
replaceTensors
(
obj
[
prop
]
)
;
}
}
return
obj
;
}
function
toI64Tensor
(
items
)
{
if
(
items
instanceof
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_9__
.
Tensor
)
{
return
items
;
}
if
(
items
.
length
=
=
=
0
)
{
throw
Error
(
"
items
must
be
non
-
empty
"
)
;
}
if
(
Array
.
isArray
(
items
[
0
]
)
)
{
if
(
items
.
some
(
x
=
>
x
.
length
!
=
=
items
[
0
]
.
length
)
)
{
throw
Error
(
"
Unable
to
create
tensor
you
should
probably
activate
truncation
and
/
or
padding
with
'
padding
=
True
'
and
/
or
'
truncation
=
True
'
to
have
batched
tensors
with
the
same
length
.
"
)
}
return
new
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_9__
.
Tensor
(
'
int64
'
BigInt64Array
.
from
(
items
.
flat
(
)
.
map
(
x
=
>
BigInt
(
x
)
)
)
[
items
.
length
items
[
0
]
.
length
]
)
;
}
else
{
return
new
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_9__
.
Tensor
(
'
int64
'
BigInt64Array
.
from
(
items
.
map
(
x
=
>
BigInt
(
x
)
)
)
[
1
items
.
length
]
)
;
}
}
function
boolTensor
(
value
)
{
return
new
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_9__
.
Tensor
(
'
bool
'
[
value
]
[
1
]
)
;
}
async
function
seq2seqForward
(
self
model_inputs
)
{
let
{
encoder_outputs
input_ids
decoder_input_ids
.
.
.
other_decoder_inputs
}
=
model_inputs
;
if
(
!
encoder_outputs
)
{
const
encoder_inputs
=
(
0
_utils_core_js__WEBPACK_IMPORTED_MODULE_4__
.
pick
)
(
model_inputs
self
.
sessions
[
'
model
'
]
.
inputNames
)
;
encoder_outputs
=
(
await
encoderForward
(
self
encoder_inputs
)
)
.
last_hidden_state
;
}
other_decoder_inputs
.
input_ids
=
decoder_input_ids
;
other_decoder_inputs
.
encoder_hidden_states
=
encoder_outputs
;
if
(
self
.
sessions
[
'
decoder_model_merged
'
]
.
inputNames
.
includes
(
'
encoder_attention_mask
'
)
)
{
other_decoder_inputs
.
encoder_attention_mask
=
model_inputs
.
attention_mask
}
const
decoderResults
=
await
decoderForward
(
self
other_decoder_inputs
true
)
;
return
decoderResults
;
}
async
function
encoderForward
(
self
model_inputs
)
{
const
session
=
self
.
sessions
[
'
model
'
]
;
const
encoderFeeds
=
(
0
_utils_core_js__WEBPACK_IMPORTED_MODULE_4__
.
pick
)
(
model_inputs
session
.
inputNames
)
;
if
(
session
.
inputNames
.
includes
(
'
inputs_embeds
'
)
&
&
!
encoderFeeds
.
inputs_embeds
)
{
if
(
!
model_inputs
.
input_ids
)
{
throw
new
Error
(
'
Both
input_ids
and
inputs_embeds
are
missing
in
the
model
inputs
.
'
)
;
}
encoderFeeds
.
inputs_embeds
=
await
self
.
encode_text
(
{
input_ids
:
model_inputs
.
input_ids
}
)
;
}
if
(
session
.
inputNames
.
includes
(
'
token_type_ids
'
)
&
&
!
encoderFeeds
.
token_type_ids
)
{
encoderFeeds
.
token_type_ids
=
new
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_9__
.
Tensor
(
'
int64
'
new
BigInt64Array
(
encoderFeeds
.
input_ids
.
data
.
length
)
encoderFeeds
.
input_ids
.
dims
)
}
return
await
sessionRun
(
session
encoderFeeds
)
;
}
async
function
decoderForward
(
self
model_inputs
is_encoder_decoder
=
false
)
{
const
session
=
self
.
sessions
[
is_encoder_decoder
?
'
decoder_model_merged
'
:
'
model
'
]
const
{
past_key_values
.
.
.
new_model_inputs
}
=
model_inputs
;
if
(
session
.
inputNames
.
includes
(
'
use_cache_branch
'
)
)
{
new_model_inputs
.
use_cache_branch
=
boolTensor
(
!
!
past_key_values
)
;
}
if
(
session
.
inputNames
.
includes
(
'
position_ids
'
)
&
&
new_model_inputs
.
attention_mask
&
&
!
new_model_inputs
.
position_ids
)
{
new_model_inputs
.
position_ids
=
createPositionIds
(
new_model_inputs
past_key_values
)
;
}
self
.
addPastKeyValues
(
new_model_inputs
past_key_values
)
;
const
fixed
=
(
0
_utils_core_js__WEBPACK_IMPORTED_MODULE_4__
.
pick
)
(
new_model_inputs
session
.
inputNames
)
;
return
await
sessionRun
(
session
fixed
)
;
}
async
function
imageTextToTextForward
(
self
{
input_ids
=
null
attention_mask
=
null
pixel_values
=
null
position_ids
=
null
inputs_embeds
=
null
past_key_values
=
null
generation_config
=
null
logits_processor
=
null
.
.
.
kwargs
}
)
{
if
(
!
inputs_embeds
)
{
inputs_embeds
=
await
self
.
encode_text
(
{
input_ids
.
.
.
kwargs
}
)
;
if
(
pixel_values
&
&
input_ids
.
dims
[
1
]
!
=
=
1
)
{
const
image_features
=
await
self
.
encode_image
(
{
pixel_values
.
.
.
kwargs
}
)
;
(
{
inputs_embeds
attention_mask
}
=
self
.
_merge_input_ids_with_image_features
(
{
image_features
inputs_embeds
input_ids
attention_mask
}
)
)
;
}
else
if
(
past_key_values
&
&
pixel_values
&
&
input_ids
.
dims
[
1
]
=
=
=
1
)
{
const
target_length
=
input_ids
.
dims
[
1
]
;
const
past_length
=
Object
.
values
(
past_key_values
)
[
0
]
.
dims
.
at
(
-
2
)
;
attention_mask
=
(
0
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_9__
.
cat
)
(
[
(
0
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_9__
.
ones
)
(
[
input_ids
.
dims
[
0
]
past_length
]
)
attention_mask
.
slice
(
null
[
attention_mask
.
dims
[
1
]
-
target_length
attention_mask
.
dims
[
1
]
]
)
]
1
)
;
}
}
if
(
!
position_ids
)
{
if
(
self
.
config
.
model_type
=
=
=
'
qwen2_vl
'
)
{
const
{
image_grid_thw
video_grid_thw
}
=
kwargs
;
[
position_ids
]
=
self
.
get_rope_index
(
input_ids
image_grid_thw
video_grid_thw
attention_mask
)
}
}
const
outputs
=
await
decoderForward
(
self
{
inputs_embeds
past_key_values
attention_mask
position_ids
generation_config
logits_processor
}
true
)
;
return
outputs
;
}
function
cumsum_masked_fill
(
attention_mask
)
{
const
[
bz
seq_len
]
=
attention_mask
.
dims
;
const
attn_mask_data
=
attention_mask
.
data
;
const
data
=
new
BigInt64Array
(
attn_mask_data
.
length
)
;
for
(
let
i
=
0
;
i
<
bz
;
+
+
i
)
{
const
start
=
i
*
seq_len
;
let
sum
=
BigInt
(
0
)
;
for
(
let
j
=
0
;
j
<
seq_len
;
+
+
j
)
{
const
index
=
start
+
j
;
if
(
attn_mask_data
[
index
]
=
=
=
0n
)
{
data
[
index
]
=
BigInt
(
1
)
;
}
else
{
data
[
index
]
=
sum
;
sum
+
=
attn_mask_data
[
index
]
;
}
}
}
return
{
data
dims
:
attention_mask
.
dims
}
;
}
function
createPositionIds
(
model_inputs
past_key_values
=
null
)
{
const
{
input_ids
inputs_embeds
attention_mask
}
=
model_inputs
;
const
{
data
dims
}
=
cumsum_masked_fill
(
attention_mask
)
;
let
position_ids
=
new
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_9__
.
Tensor
(
'
int64
'
data
dims
)
;
if
(
past_key_values
)
{
const
offset
=
-
(
input_ids
?
?
inputs_embeds
)
.
dims
.
at
(
1
)
;
position_ids
=
position_ids
.
slice
(
null
[
offset
null
]
)
;
}
return
position_ids
;
}
function
decoder_prepare_inputs_for_generation
(
self
input_ids
model_inputs
generation_config
)
{
if
(
model_inputs
.
past_key_values
)
{
const
past_length
=
Object
.
values
(
model_inputs
.
past_key_values
)
[
0
]
.
dims
.
at
(
-
2
)
;
const
{
input_ids
attention_mask
}
=
model_inputs
;
if
(
attention_mask
&
&
attention_mask
.
dims
[
1
]
>
input_ids
.
dims
[
1
]
)
{
}
else
if
(
past_length
<
input_ids
.
dims
[
1
]
)
{
model_inputs
.
input_ids
=
input_ids
.
slice
(
null
[
past_length
null
]
)
;
}
else
{
if
(
self
.
config
.
image_token_index
!
=
null
&
&
input_ids
.
data
.
some
(
x
=
>
x
=
=
self
.
config
.
image_token_index
)
)
{
const
num_image_tokens
=
self
.
config
.
num_image_tokens
;
if
(
!
num_image_tokens
)
{
throw
new
Error
(
'
num_image_tokens
is
missing
in
the
model
configuration
.
'
)
;
}
const
num_new_tokens
=
input_ids
.
dims
[
1
]
-
(
past_length
-
num_image_tokens
)
;
model_inputs
.
input_ids
=
input_ids
.
slice
(
null
[
-
num_new_tokens
null
]
)
;
model_inputs
.
attention_mask
=
(
0
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_9__
.
ones
)
(
[
1
past_length
+
num_new_tokens
]
)
;
}
}
}
return
model_inputs
;
}
function
encoder_decoder_prepare_inputs_for_generation
(
self
input_ids
model_inputs
generation_config
)
{
if
(
model_inputs
.
past_key_values
)
{
input_ids
=
input_ids
.
map
(
x
=
>
[
x
.
at
(
-
1
)
]
)
;
}
return
{
.
.
.
model_inputs
decoder_input_ids
:
toI64Tensor
(
input_ids
)
}
;
}
function
image_text_to_text_prepare_inputs_for_generation
(
self
.
.
.
args
)
{
if
(
self
.
config
.
is_encoder_decoder
)
{
return
encoder_decoder_prepare_inputs_for_generation
(
self
.
.
.
args
)
;
}
else
{
return
decoder_prepare_inputs_for_generation
(
self
.
.
.
args
)
;
}
}
function
multimodality_prepare_inputs_for_generation
(
self
input_ids
model_inputs
generation_config
)
{
const
has_past_key_values
=
!
!
model_inputs
.
past_key_values
;
if
(
generation_config
.
guidance_scale
!
=
=
null
&
&
generation_config
.
guidance_scale
>
1
)
{
if
(
has_past_key_values
)
{
model_inputs
.
input_ids
=
(
0
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_9__
.
cat
)
(
[
model_inputs
.
input_ids
model_inputs
.
input_ids
]
0
)
}
else
{
model_inputs
.
input_ids
=
(
0
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_9__
.
cat
)
(
[
model_inputs
.
input_ids
(
0
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_9__
.
full_like
)
(
model_inputs
.
input_ids
BigInt
(
generation_config
.
pad_token_id
)
)
]
0
)
;
model_inputs
.
attention_mask
=
(
0
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_9__
.
cat
)
(
[
model_inputs
.
attention_mask
(
0
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_9__
.
full_like
)
(
model_inputs
.
attention_mask
0n
)
]
0
)
;
}
}
if
(
has_past_key_values
|
|
!
model_inputs
.
pixel_values
)
{
model_inputs
.
pixel_values
=
(
0
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_9__
.
full
)
(
[
0
0
3
384
384
]
1
.
0
)
;
}
if
(
has_past_key_values
)
{
const
num_img_tokens
=
0
;
const
num_text_tokens
=
1
;
const
has_image
=
num_img_tokens
>
0
?
1
:
0
;
const
batch_size
=
1
;
model_inputs
.
images_seq_mask
=
new
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_9__
.
Tensor
(
'
bool
'
new
Array
(
num_img_tokens
+
num_text_tokens
)
.
fill
(
true
)
.
fill
(
false
0
num_text_tokens
)
[
batch_size
num_img_tokens
+
num_text_tokens
]
)
;
model_inputs
.
images_emb_mask
=
new
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_9__
.
Tensor
(
'
bool
'
new
Array
(
num_img_tokens
)
.
fill
(
!
!
has_image
)
[
batch_size
1
num_img_tokens
]
)
;
}
return
model_inputs
;
}
class
PreTrainedModel
extends
_utils_generic_js__WEBPACK_IMPORTED_MODULE_3__
.
Callable
{
main_input_name
=
'
input_ids
'
;
forward_params
=
[
'
input_ids
'
'
attention_mask
'
]
;
constructor
(
config
sessions
configs
)
{
super
(
)
;
this
.
config
=
config
;
this
.
sessions
=
sessions
;
this
.
configs
=
configs
;
const
modelName
=
MODEL_CLASS_TO_NAME_MAPPING
.
get
(
this
.
constructor
)
;
const
modelType
=
MODEL_TYPE_MAPPING
.
get
(
modelName
)
;
this
.
can_generate
=
false
;
this
.
_forward
=
null
;
this
.
_prepare_inputs_for_generation
=
null
;
switch
(
modelType
)
{
case
MODEL_TYPES
.
DecoderOnly
:
this
.
can_generate
=
true
;
this
.
_forward
=
decoderForward
;
this
.
_prepare_inputs_for_generation
=
decoder_prepare_inputs_for_generation
;
break
;
case
MODEL_TYPES
.
Seq2Seq
:
case
MODEL_TYPES
.
Vision2Seq
:
case
MODEL_TYPES
.
Musicgen
:
this
.
can_generate
=
true
;
this
.
_forward
=
seq2seqForward
;
this
.
_prepare_inputs_for_generation
=
encoder_decoder_prepare_inputs_for_generation
;
break
;
case
MODEL_TYPES
.
EncoderDecoder
:
this
.
_forward
=
seq2seqForward
;
break
;
case
MODEL_TYPES
.
ImageTextToText
:
this
.
can_generate
=
true
;
this
.
_forward
=
imageTextToTextForward
;
this
.
_prepare_inputs_for_generation
=
image_text_to_text_prepare_inputs_for_generation
;
break
;
case
MODEL_TYPES
.
MultiModality
:
this
.
can_generate
=
true
;
this
.
_prepare_inputs_for_generation
=
multimodality_prepare_inputs_for_generation
;
break
;
default
:
this
.
_forward
=
encoderForward
;
break
;
}
if
(
this
.
can_generate
)
{
this
.
forward_params
.
push
(
'
past_key_values
'
)
;
}
this
.
custom_config
=
this
.
config
[
'
transformers
.
js_config
'
]
?
?
{
}
;
}
async
dispose
(
)
{
const
promises
=
[
]
;
for
(
const
session
of
Object
.
values
(
this
.
sessions
)
)
{
if
(
session
?
.
handler
?
.
dispose
)
{
promises
.
push
(
session
.
handler
.
dispose
(
)
)
}
}
return
await
Promise
.
all
(
promises
)
;
}
static
async
from_pretrained
(
pretrained_model_name_or_path
{
progress_callback
=
null
config
=
null
cache_dir
=
null
local_files_only
=
false
revision
=
'
main
'
model_file_name
=
null
subfolder
=
'
onnx
'
device
=
null
dtype
=
null
use_external_data_format
=
null
session_options
=
{
}
}
=
{
}
)
{
let
options
=
{
progress_callback
config
cache_dir
local_files_only
revision
model_file_name
subfolder
device
dtype
use_external_data_format
session_options
}
const
modelName
=
MODEL_CLASS_TO_NAME_MAPPING
.
get
(
this
)
;
const
modelType
=
MODEL_TYPE_MAPPING
.
get
(
modelName
)
;
config
=
options
.
config
=
await
_configs_js__WEBPACK_IMPORTED_MODULE_0__
.
AutoConfig
.
from_pretrained
(
pretrained_model_name_or_path
options
)
;
let
info
;
if
(
modelType
=
=
=
MODEL_TYPES
.
DecoderOnly
)
{
info
=
await
Promise
.
all
(
[
constructSessions
(
pretrained_model_name_or_path
{
model
:
options
.
model_file_name
?
?
'
model
'
}
options
)
getOptionalConfigs
(
pretrained_model_name_or_path
{
generation_config
:
'
generation_config
.
json
'
}
options
)
]
)
;
}
else
if
(
modelType
=
=
=
MODEL_TYPES
.
Seq2Seq
|
|
modelType
=
=
=
MODEL_TYPES
.
Vision2Seq
)
{
info
=
await
Promise
.
all
(
[
constructSessions
(
pretrained_model_name_or_path
{
model
:
'
encoder_model
'
decoder_model_merged
:
'
decoder_model_merged
'
}
options
)
getOptionalConfigs
(
pretrained_model_name_or_path
{
generation_config
:
'
generation_config
.
json
'
}
options
)
]
)
;
}
else
if
(
modelType
=
=
=
MODEL_TYPES
.
MaskGeneration
)
{
info
=
await
Promise
.
all
(
[
constructSessions
(
pretrained_model_name_or_path
{
model
:
'
vision_encoder
'
prompt_encoder_mask_decoder
:
'
prompt_encoder_mask_decoder
'
}
options
)
]
)
;
}
else
if
(
modelType
=
=
=
MODEL_TYPES
.
EncoderDecoder
)
{
info
=
await
Promise
.
all
(
[
constructSessions
(
pretrained_model_name_or_path
{
model
:
'
encoder_model
'
decoder_model_merged
:
'
decoder_model_merged
'
}
options
)
]
)
;
}
else
if
(
modelType
=
=
=
MODEL_TYPES
.
ImageTextToText
)
{
const
sessions
=
{
embed_tokens
:
'
embed_tokens
'
vision_encoder
:
'
vision_encoder
'
decoder_model_merged
:
'
decoder_model_merged
'
}
if
(
config
.
is_encoder_decoder
)
{
sessions
[
'
model
'
]
=
'
encoder_model
'
;
}
info
=
await
Promise
.
all
(
[
constructSessions
(
pretrained_model_name_or_path
sessions
options
)
getOptionalConfigs
(
pretrained_model_name_or_path
{
generation_config
:
'
generation_config
.
json
'
}
options
)
]
)
;
}
else
if
(
modelType
=
=
=
MODEL_TYPES
.
Musicgen
)
{
info
=
await
Promise
.
all
(
[
constructSessions
(
pretrained_model_name_or_path
{
model
:
'
text_encoder
'
decoder_model_merged
:
'
decoder_model_merged
'
encodec_decode
:
'
encodec_decode
'
}
options
)
getOptionalConfigs
(
pretrained_model_name_or_path
{
generation_config
:
'
generation_config
.
json
'
}
options
)
]
)
;
}
else
if
(
modelType
=
=
=
MODEL_TYPES
.
MultiModality
)
{
info
=
await
Promise
.
all
(
[
constructSessions
(
pretrained_model_name_or_path
{
prepare_inputs_embeds
:
'
prepare_inputs_embeds
'
model
:
'
language_model
'
lm_head
:
'
lm_head
'
gen_head
:
'
gen_head
'
gen_img_embeds
:
'
gen_img_embeds
'
image_decode
:
'
image_decode
'
}
options
)
getOptionalConfigs
(
pretrained_model_name_or_path
{
generation_config
:
'
generation_config
.
json
'
}
options
)
]
)
;
}
else
{
if
(
modelType
!
=
=
MODEL_TYPES
.
EncoderOnly
)
{
console
.
warn
(
Model
type
for
'
{
modelName
?
?
config
?
.
model_type
}
'
not
found
assuming
encoder
-
only
architecture
.
Please
report
this
at
{
_utils_constants_js__WEBPACK_IMPORTED_MODULE_6__
.
GITHUB_ISSUE_URL
}
.
)
}
info
=
await
Promise
.
all
(
[
constructSessions
(
pretrained_model_name_or_path
{
model
:
options
.
model_file_name
?
?
'
model
'
}
options
)
]
)
;
}
return
new
this
(
config
.
.
.
info
)
;
}
async
_call
(
model_inputs
)
{
return
await
this
.
forward
(
model_inputs
)
;
}
async
forward
(
model_inputs
)
{
return
await
this
.
_forward
(
this
model_inputs
)
;
}
get
generation_config
(
)
{
return
this
.
configs
?
.
generation_config
?
?
null
;
}
_get_logits_warper
(
generation_config
)
{
const
warpers
=
new
_generation_logits_process_js__WEBPACK_IMPORTED_MODULE_7__
.
LogitsProcessorList
(
)
;
if
(
generation_config
.
temperature
!
=
=
null
&
&
generation_config
.
temperature
!
=
=
1
.
0
)
{
warpers
.
push
(
new
_generation_logits_process_js__WEBPACK_IMPORTED_MODULE_7__
.
TemperatureLogitsWarper
(
generation_config
.
temperature
)
)
;
}
if
(
generation_config
.
top_k
!
=
=
null
&
&
generation_config
.
top_k
!
=
=
0
)
{
warpers
.
push
(
new
_generation_logits_process_js__WEBPACK_IMPORTED_MODULE_7__
.
TopKLogitsWarper
(
generation_config
.
top_k
)
)
;
}
if
(
generation_config
.
top_p
!
=
=
null
&
&
generation_config
.
top_p
<
1
.
0
)
{
warpers
.
push
(
new
_generation_logits_process_js__WEBPACK_IMPORTED_MODULE_7__
.
TopPLogitsWarper
(
generation_config
.
top_p
)
)
;
}
return
warpers
;
}
_get_logits_processor
(
generation_config
input_ids_seq_length
logits_processor
=
null
)
{
const
processors
=
new
_generation_logits_process_js__WEBPACK_IMPORTED_MODULE_7__
.
LogitsProcessorList
(
)
;
if
(
generation_config
.
repetition_penalty
!
=
=
null
&
&
generation_config
.
repetition_penalty
!
=
=
1
.
0
)
{
processors
.
push
(
new
_generation_logits_process_js__WEBPACK_IMPORTED_MODULE_7__
.
RepetitionPenaltyLogitsProcessor
(
generation_config
.
repetition_penalty
)
)
;
}
if
(
generation_config
.
no_repeat_ngram_size
!
=
=
null
&
&
generation_config
.
no_repeat_ngram_size
>
0
)
{
processors
.
push
(
new
_generation_logits_process_js__WEBPACK_IMPORTED_MODULE_7__
.
NoRepeatNGramLogitsProcessor
(
generation_config
.
no_repeat_ngram_size
)
)
;
}
if
(
generation_config
.
bad_words_ids
!
=
=
null
)
{
processors
.
push
(
new
_generation_logits_process_js__WEBPACK_IMPORTED_MODULE_7__
.
NoBadWordsLogitsProcessor
(
generation_config
.
bad_words_ids
generation_config
.
eos_token_id
)
)
;
}
if
(
generation_config
.
min_length
!
=
=
null
&
&
generation_config
.
eos_token_id
!
=
=
null
&
&
generation_config
.
min_length
>
0
)
{
processors
.
push
(
new
_generation_logits_process_js__WEBPACK_IMPORTED_MODULE_7__
.
MinLengthLogitsProcessor
(
generation_config
.
min_length
generation_config
.
eos_token_id
)
)
;
}
if
(
generation_config
.
min_new_tokens
!
=
=
null
&
&
generation_config
.
eos_token_id
!
=
=
null
&
&
generation_config
.
min_new_tokens
>
0
)
{
processors
.
push
(
new
_generation_logits_process_js__WEBPACK_IMPORTED_MODULE_7__
.
MinNewTokensLengthLogitsProcessor
(
input_ids_seq_length
generation_config
.
min_new_tokens
generation_config
.
eos_token_id
)
)
;
}
if
(
generation_config
.
forced_bos_token_id
!
=
=
null
)
{
processors
.
push
(
new
_generation_logits_process_js__WEBPACK_IMPORTED_MODULE_7__
.
ForcedBOSTokenLogitsProcessor
(
generation_config
.
forced_bos_token_id
)
)
;
}
if
(
generation_config
.
forced_eos_token_id
!
=
=
null
)
{
processors
.
push
(
new
_generation_logits_process_js__WEBPACK_IMPORTED_MODULE_7__
.
ForcedEOSTokenLogitsProcessor
(
generation_config
.
max_length
generation_config
.
forced_eos_token_id
)
)
;
}
if
(
generation_config
.
begin_suppress_tokens
!
=
=
null
)
{
const
begin_index
=
(
input_ids_seq_length
>
1
|
|
generation_config
.
forced_bos_token_id
=
=
=
null
)
?
input_ids_seq_length
:
input_ids_seq_length
+
1
;
processors
.
push
(
new
_generation_logits_process_js__WEBPACK_IMPORTED_MODULE_7__
.
SuppressTokensAtBeginLogitsProcessor
(
generation_config
.
begin_suppress_tokens
begin_index
)
)
;
}
if
(
generation_config
.
guidance_scale
!
=
=
null
&
&
generation_config
.
guidance_scale
>
1
)
{
processors
.
push
(
new
_generation_logits_process_js__WEBPACK_IMPORTED_MODULE_7__
.
ClassifierFreeGuidanceLogitsProcessor
(
generation_config
.
guidance_scale
)
)
;
}
if
(
logits_processor
!
=
=
null
)
{
processors
.
extend
(
logits_processor
)
}
return
processors
;
}
_prepare_generation_config
(
generation_config
kwargs
cls
=
_generation_configuration_utils_js__WEBPACK_IMPORTED_MODULE_8__
.
GenerationConfig
)
{
const
config
=
{
.
.
.
this
.
config
}
;
for
(
const
key
of
[
"
decoder
"
"
generator
"
"
text_config
"
]
)
{
if
(
key
in
config
)
{
Object
.
assign
(
config
config
[
key
]
)
;
}
}
const
gen_config
=
new
cls
(
config
)
;
Object
.
assign
(
gen_config
this
.
generation_config
?
?
{
}
)
;
if
(
generation_config
)
{
Object
.
assign
(
gen_config
generation_config
)
;
}
if
(
kwargs
)
{
Object
.
assign
(
gen_config
(
0
_utils_core_js__WEBPACK_IMPORTED_MODULE_4__
.
pick
)
(
kwargs
Object
.
getOwnPropertyNames
(
gen_config
)
)
)
;
}
return
gen_config
;
}
_get_stopping_criteria
(
generation_config
stopping_criteria
=
null
)
{
const
criteria
=
new
_generation_stopping_criteria_js__WEBPACK_IMPORTED_MODULE_12__
.
StoppingCriteriaList
(
)
;
if
(
generation_config
.
max_length
!
=
=
null
)
{
criteria
.
push
(
new
_generation_stopping_criteria_js__WEBPACK_IMPORTED_MODULE_12__
.
MaxLengthCriteria
(
generation_config
.
max_length
this
.
config
.
max_position_embeddings
?
?
null
)
)
;
}
if
(
generation_config
.
eos_token_id
!
=
=
null
)
{
criteria
.
push
(
new
_generation_stopping_criteria_js__WEBPACK_IMPORTED_MODULE_12__
.
EosTokenCriteria
(
generation_config
.
eos_token_id
)
)
;
}
if
(
stopping_criteria
)
{
criteria
.
extend
(
stopping_criteria
)
;
}
return
criteria
;
}
_validate_model_class
(
)
{
if
(
!
this
.
can_generate
)
{
const
generate_compatible_mappings
=
[
MODEL_FOR_CAUSAL_LM_MAPPING_NAMES
MODEL_FOR_VISION_2_SEQ_MAPPING_NAMES
MODEL_FOR_SEQ_TO_SEQ_CAUSAL_LM_MAPPING_NAMES
MODEL_FOR_SPEECH_SEQ_2_SEQ_MAPPING_NAMES
]
;
const
modelName
=
MODEL_CLASS_TO_NAME_MAPPING
.
get
(
this
.
constructor
)
;
const
generate_compatible_classes
=
new
Set
(
)
;
const
modelType
=
this
.
config
.
model_type
;
for
(
const
model_mapping
of
generate_compatible_mappings
)
{
const
supported_models
=
model_mapping
.
get
(
modelType
)
;
if
(
supported_models
)
{
generate_compatible_classes
.
add
(
supported_models
[
0
]
)
;
}
}
let
errorMessage
=
The
current
model
class
(
{
modelName
}
)
is
not
compatible
with
\
.
generate
(
)
\
as
it
doesn
'
t
have
a
language
model
head
.
if
(
generate_compatible_classes
.
size
>
0
)
{
errorMessage
+
=
Please
use
the
following
class
instead
:
{
[
.
.
.
generate_compatible_classes
]
.
join
(
'
'
)
}
;
}
throw
Error
(
errorMessage
)
;
}
}
prepare_inputs_for_generation
(
.
.
.
args
)
{
return
this
.
_prepare_inputs_for_generation
(
this
.
.
.
args
)
;
}
_update_model_kwargs_for_generation
(
{
generated_input_ids
outputs
model_inputs
is_encoder_decoder
}
)
{
model_inputs
[
'
past_key_values
'
]
=
this
.
getPastKeyValues
(
outputs
model_inputs
.
past_key_values
)
;
model_inputs
[
'
input_ids
'
]
=
new
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_9__
.
Tensor
(
'
int64
'
generated_input_ids
.
flat
(
)
[
generated_input_ids
.
length
1
]
)
;
if
(
!
is_encoder_decoder
)
{
model_inputs
.
attention_mask
=
(
0
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_9__
.
cat
)
(
[
model_inputs
.
attention_mask
(
0
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_9__
.
ones
)
(
[
model_inputs
.
attention_mask
.
dims
[
0
]
1
]
)
]
1
)
;
}
else
if
(
'
decoder_attention_mask
'
in
model_inputs
)
{
}
model_inputs
[
'
position_ids
'
]
=
null
;
return
model_inputs
;
}
_prepare_model_inputs
(
{
inputs
bos_token_id
model_kwargs
}
)
{
const
model_inputs
=
(
0
_utils_core_js__WEBPACK_IMPORTED_MODULE_4__
.
pick
)
(
model_kwargs
this
.
forward_params
)
;
const
input_name
=
this
.
main_input_name
;
if
(
input_name
in
model_inputs
)
{
if
(
inputs
)
{
throw
new
Error
(
"
inputs
:
{
inputs
}
were
passed
alongside
{
input_name
}
which
is
not
allowed
.
"
+
"
Make
sure
to
either
pass
{
inputs
}
or
{
input_name
}
=
.
.
.
"
)
;
}
}
else
{
model_inputs
[
input_name
]
=
inputs
;
}
const
inputs_tensor
=
model_inputs
[
input_name
]
;
return
{
inputs_tensor
model_inputs
model_input_name
:
input_name
}
;
}
async
_prepare_encoder_decoder_kwargs_for_generation
(
{
inputs_tensor
model_inputs
model_input_name
generation_config
}
)
{
if
(
this
.
sessions
[
'
model
'
]
.
inputNames
.
includes
(
'
inputs_embeds
'
)
&
&
!
model_inputs
.
inputs_embeds
&
&
'
_prepare_inputs_embeds
'
in
this
)
{
const
{
input_ids
pixel_values
attention_mask
.
.
.
kwargs
}
=
model_inputs
;
const
prepared_inputs
=
await
this
.
_prepare_inputs_embeds
(
model_inputs
)
;
model_inputs
=
{
.
.
.
kwargs
.
.
.
(
0
_utils_core_js__WEBPACK_IMPORTED_MODULE_4__
.
pick
)
(
prepared_inputs
[
'
inputs_embeds
'
'
attention_mask
'
]
)
}
;
}
let
{
last_hidden_state
}
=
await
encoderForward
(
this
model_inputs
)
;
if
(
generation_config
.
guidance_scale
!
=
=
null
&
&
generation_config
.
guidance_scale
>
1
)
{
last_hidden_state
=
(
0
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_9__
.
cat
)
(
[
last_hidden_state
(
0
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_9__
.
full_like
)
(
last_hidden_state
0
.
0
)
]
0
)
;
if
(
'
attention_mask
'
in
model_inputs
)
{
model_inputs
[
'
attention_mask
'
]
=
(
0
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_9__
.
cat
)
(
[
model_inputs
[
'
attention_mask
'
]
(
0
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_9__
.
zeros_like
)
(
model_inputs
[
'
attention_mask
'
]
)
]
0
)
;
}
}
else
if
(
model_inputs
.
decoder_input_ids
)
{
const
decoder_input_ids_batch_size
=
toI64Tensor
(
model_inputs
.
decoder_input_ids
)
.
dims
[
0
]
;
if
(
decoder_input_ids_batch_size
!
=
=
last_hidden_state
.
dims
[
0
]
)
{
if
(
last_hidden_state
.
dims
[
0
]
!
=
=
1
)
{
throw
new
Error
(
The
encoder
outputs
have
a
different
batch
size
(
{
last_hidden_state
.
dims
[
0
]
}
)
than
the
decoder
inputs
(
{
decoder_input_ids_batch_size
}
)
.
)
}
last_hidden_state
=
(
0
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_9__
.
cat
)
(
Array
.
from
(
{
length
:
decoder_input_ids_batch_size
}
(
)
=
>
last_hidden_state
)
0
)
;
}
}
model_inputs
[
'
encoder_outputs
'
]
=
last_hidden_state
;
return
model_inputs
;
}
_prepare_decoder_input_ids_for_generation
(
{
batch_size
model_input_name
model_kwargs
decoder_start_token_id
bos_token_id
generation_config
}
)
{
let
{
decoder_input_ids
.
.
.
model_inputs
}
=
model_kwargs
;
if
(
!
(
decoder_input_ids
instanceof
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_9__
.
Tensor
)
)
{
if
(
!
decoder_input_ids
)
{
decoder_start_token_id
?
?
=
bos_token_id
;
if
(
this
.
config
.
model_type
=
=
=
'
musicgen
'
)
{
decoder_input_ids
=
Array
.
from
(
{
length
:
batch_size
*
this
.
config
.
decoder
.
num_codebooks
}
(
)
=
>
[
decoder_start_token_id
]
)
;
}
else
if
(
Array
.
isArray
(
decoder_start_token_id
)
)
{
if
(
decoder_start_token_id
.
length
!
=
=
batch_size
)
{
throw
new
Error
(
\
decoder_start_token_id
\
expcted
to
have
length
{
batch_size
}
but
got
{
decoder_start_token_id
.
length
}
)
}
decoder_input_ids
=
decoder_start_token_id
;
}
else
{
decoder_input_ids
=
Array
.
from
(
{
length
:
batch_size
}
(
)
=
>
[
decoder_start_token_id
]
)
;
}
}
else
if
(
!
Array
.
isArray
(
decoder_input_ids
[
0
]
)
)
{
decoder_input_ids
=
Array
.
from
(
{
length
:
batch_size
}
(
)
=
>
decoder_input_ids
)
;
}
decoder_input_ids
=
toI64Tensor
(
decoder_input_ids
)
;
}
model_kwargs
[
'
decoder_attention_mask
'
]
=
(
0
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_9__
.
ones_like
)
(
decoder_input_ids
)
;
return
{
input_ids
:
decoder_input_ids
model_inputs
}
;
}
async
generate
(
{
inputs
=
null
generation_config
=
null
logits_processor
=
null
stopping_criteria
=
null
streamer
=
null
.
.
.
kwargs
}
)
{
this
.
_validate_model_class
(
)
;
generation_config
=
this
.
_prepare_generation_config
(
generation_config
kwargs
)
;
let
{
inputs_tensor
model_inputs
model_input_name
}
=
this
.
_prepare_model_inputs
(
{
inputs
model_kwargs
:
kwargs
}
)
;
const
is_encoder_decoder
=
this
.
config
.
is_encoder_decoder
;
if
(
!
is_encoder_decoder
)
{
}
else
if
(
!
(
'
encoder_outputs
'
in
model_inputs
)
)
{
model_inputs
=
await
this
.
_prepare_encoder_decoder_kwargs_for_generation
(
{
inputs_tensor
model_inputs
model_input_name
generation_config
}
)
}
let
input_ids
;
if
(
is_encoder_decoder
)
{
(
{
input_ids
model_inputs
}
=
this
.
_prepare_decoder_input_ids_for_generation
(
{
batch_size
:
model_inputs
[
model_input_name
]
.
dims
.
at
(
0
)
model_input_name
model_kwargs
:
model_inputs
decoder_start_token_id
:
generation_config
.
decoder_start_token_id
bos_token_id
:
generation_config
.
bos_token_id
generation_config
}
)
)
;
}
else
{
input_ids
=
model_inputs
[
model_input_name
]
}
let
input_ids_length
=
input_ids
.
dims
.
at
(
-
1
)
;
if
(
generation_config
.
max_new_tokens
!
=
=
null
)
{
generation_config
.
max_length
=
input_ids_length
+
generation_config
.
max_new_tokens
;
}
const
prepared_logits_processor
=
this
.
_get_logits_processor
(
generation_config
input_ids_length
logits_processor
)
const
prepared_stopping_criteria
=
this
.
_get_stopping_criteria
(
generation_config
stopping_criteria
)
const
numInputs
=
model_inputs
[
model_input_name
]
.
dims
.
at
(
0
)
;
const
sampler
=
_generation_logits_sampler_js__WEBPACK_IMPORTED_MODULE_13__
.
LogitsSampler
.
getSampler
(
generation_config
)
;
const
scores
=
new
Array
(
numInputs
)
.
fill
(
0
)
;
const
all_input_ids
=
input_ids
.
tolist
(
)
;
if
(
streamer
)
{
streamer
.
put
(
all_input_ids
)
;
}
let
outputs
;
let
attentions
=
{
}
;
while
(
true
)
{
model_inputs
=
this
.
prepare_inputs_for_generation
(
all_input_ids
model_inputs
generation_config
)
;
outputs
=
await
this
.
forward
(
model_inputs
)
;
if
(
generation_config
.
output_attentions
&
&
generation_config
.
return_dict_in_generate
)
{
const
token_attentions
=
this
.
getAttentions
(
outputs
)
;
for
(
const
key
in
token_attentions
)
{
if
(
!
(
key
in
attentions
)
)
{
attentions
[
key
]
=
[
]
;
}
attentions
[
key
]
.
push
(
token_attentions
[
key
]
)
;
}
}
const
logits
=
outputs
.
logits
.
slice
(
null
-
1
null
)
;
const
next_tokens_scores
=
prepared_logits_processor
(
all_input_ids
logits
)
;
const
generated_input_ids
=
[
]
;
for
(
let
batch_idx
=
0
;
batch_idx
<
next_tokens_scores
.
dims
.
at
(
0
)
;
+
+
batch_idx
)
{
const
logs
=
next_tokens_scores
[
batch_idx
]
;
const
sampledTokens
=
await
sampler
(
logs
)
;
for
(
const
[
newTokenId
logProb
]
of
sampledTokens
)
{
const
bigint
=
BigInt
(
newTokenId
)
;
scores
[
batch_idx
]
+
=
logProb
;
all_input_ids
[
batch_idx
]
.
push
(
bigint
)
;
generated_input_ids
.
push
(
[
bigint
]
)
;
break
;
}
}
if
(
streamer
)
{
streamer
.
put
(
generated_input_ids
)
;
}
const
stop
=
prepared_stopping_criteria
(
all_input_ids
)
;
if
(
stop
.
every
(
x
=
>
x
)
)
{
break
;
}
model_inputs
=
this
.
_update_model_kwargs_for_generation
(
{
generated_input_ids
outputs
model_inputs
is_encoder_decoder
}
)
;
}
if
(
streamer
)
{
streamer
.
end
(
)
;
}
const
past_key_values
=
this
.
getPastKeyValues
(
outputs
model_inputs
.
past_key_values
true
)
;
const
sequences
=
new
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_9__
.
Tensor
(
'
int64
'
all_input_ids
.
flat
(
)
[
all_input_ids
.
length
all_input_ids
[
0
]
.
length
]
)
;
if
(
generation_config
.
return_dict_in_generate
)
{
return
{
sequences
past_key_values
.
.
.
attentions
}
}
else
{
for
(
const
tensor
of
Object
.
values
(
outputs
)
)
{
if
(
tensor
.
location
=
=
=
'
gpu
-
buffer
'
)
{
tensor
.
dispose
(
)
;
}
}
return
sequences
;
}
}
getPastKeyValues
(
decoderResults
pastKeyValues
disposeEncoderPKVs
=
false
)
{
const
pkvs
=
Object
.
create
(
null
)
;
for
(
const
name
in
decoderResults
)
{
if
(
name
.
startsWith
(
'
present
'
)
)
{
const
newName
=
name
.
replace
(
'
present
'
'
past_key_values
'
)
;
const
is_encoder_pkv
=
name
.
includes
(
'
encoder
'
)
;
if
(
is_encoder_pkv
&
&
pastKeyValues
)
{
pkvs
[
newName
]
=
pastKeyValues
[
newName
]
;
}
else
{
pkvs
[
newName
]
=
decoderResults
[
name
]
;
}
if
(
pastKeyValues
&
&
(
!
is_encoder_pkv
|
|
disposeEncoderPKVs
)
)
{
const
t
=
pastKeyValues
[
newName
]
;
if
(
t
.
location
=
=
=
'
gpu
-
buffer
'
)
{
t
.
dispose
(
)
;
}
}
}
}
return
pkvs
;
}
getAttentions
(
model_output
)
{
const
attentions
=
{
}
;
for
(
const
attnName
of
[
'
cross_attentions
'
'
encoder_attentions
'
'
decoder_attentions
'
]
)
{
for
(
const
name
in
model_output
)
{
if
(
name
.
startsWith
(
attnName
)
)
{
if
(
!
(
attnName
in
attentions
)
)
{
attentions
[
attnName
]
=
[
]
;
}
attentions
[
attnName
]
.
push
(
model_output
[
name
]
)
;
}
}
}
return
attentions
;
}
addPastKeyValues
(
decoderFeeds
pastKeyValues
)
{
if
(
pastKeyValues
)
{
Object
.
assign
(
decoderFeeds
pastKeyValues
)
}
else
{
const
session
=
this
.
sessions
[
'
decoder_model_merged
'
]
?
?
this
.
sessions
[
'
model
'
]
;
const
dtype
=
session
?
.
config
?
.
kv_cache_dtype
?
?
'
float32
'
;
const
empty
=
(
dtype
=
=
=
'
float16
'
)
?
new
Uint16Array
(
)
:
[
]
;
const
batch_size
=
(
decoderFeeds
[
this
.
main_input_name
]
?
?
decoderFeeds
.
attention_mask
)
.
dims
?
.
[
0
]
?
?
1
;
const
shapes
=
(
0
_configs_js__WEBPACK_IMPORTED_MODULE_0__
.
getKeyValueShapes
)
(
this
.
config
{
batch_size
}
)
;
for
(
const
name
in
shapes
)
{
decoderFeeds
[
name
]
=
new
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_9__
.
Tensor
(
dtype
empty
shapes
[
name
]
)
;
}
}
}
async
encode_image
(
{
pixel_values
}
)
{
const
features
=
(
await
sessionRun
(
this
.
sessions
[
'
vision_encoder
'
]
{
pixel_values
}
)
)
.
image_features
;
if
(
!
this
.
config
.
num_image_tokens
)
{
console
.
warn
(
'
The
number
of
image
tokens
was
not
set
in
the
model
configuration
.
'
+
Setting
it
to
the
number
of
features
detected
by
the
vision
encoder
(
{
features
.
dims
[
1
]
}
)
.
)
this
.
config
.
num_image_tokens
=
features
.
dims
[
1
]
;
}
return
features
;
}
async
encode_text
(
{
input_ids
}
)
{
return
(
await
sessionRun
(
this
.
sessions
[
'
embed_tokens
'
]
{
input_ids
}
)
)
.
inputs_embeds
;
}
}
class
ModelOutput
{
}
class
BaseModelOutput
extends
ModelOutput
{
constructor
(
{
last_hidden_state
hidden_states
=
null
attentions
=
null
}
)
{
super
(
)
;
this
.
last_hidden_state
=
last_hidden_state
;
this
.
hidden_states
=
hidden_states
;
this
.
attentions
=
attentions
;
}
}
class
BertPreTrainedModel
extends
PreTrainedModel
{
}
class
BertModel
extends
BertPreTrainedModel
{
}
class
BertForMaskedLM
extends
BertPreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
MaskedLMOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
BertForSequenceClassification
extends
BertPreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
SequenceClassifierOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
BertForTokenClassification
extends
BertPreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
TokenClassifierOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
BertForQuestionAnswering
extends
BertPreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
QuestionAnsweringModelOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
NomicBertPreTrainedModel
extends
PreTrainedModel
{
}
class
NomicBertModel
extends
NomicBertPreTrainedModel
{
}
class
RoFormerPreTrainedModel
extends
PreTrainedModel
{
}
class
RoFormerModel
extends
RoFormerPreTrainedModel
{
}
class
RoFormerForMaskedLM
extends
RoFormerPreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
MaskedLMOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
RoFormerForSequenceClassification
extends
RoFormerPreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
SequenceClassifierOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
RoFormerForTokenClassification
extends
RoFormerPreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
TokenClassifierOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
RoFormerForQuestionAnswering
extends
RoFormerPreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
QuestionAnsweringModelOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
ConvBertPreTrainedModel
extends
PreTrainedModel
{
}
class
ConvBertModel
extends
ConvBertPreTrainedModel
{
}
class
ConvBertForMaskedLM
extends
ConvBertPreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
MaskedLMOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
ConvBertForSequenceClassification
extends
ConvBertPreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
SequenceClassifierOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
ConvBertForTokenClassification
extends
ConvBertPreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
TokenClassifierOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
ConvBertForQuestionAnswering
extends
ConvBertPreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
QuestionAnsweringModelOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
ElectraPreTrainedModel
extends
PreTrainedModel
{
}
class
ElectraModel
extends
ElectraPreTrainedModel
{
}
class
ElectraForMaskedLM
extends
ElectraPreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
MaskedLMOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
ElectraForSequenceClassification
extends
ElectraPreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
SequenceClassifierOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
ElectraForTokenClassification
extends
ElectraPreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
TokenClassifierOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
ElectraForQuestionAnswering
extends
ElectraPreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
QuestionAnsweringModelOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
CamembertPreTrainedModel
extends
PreTrainedModel
{
}
class
CamembertModel
extends
CamembertPreTrainedModel
{
}
class
CamembertForMaskedLM
extends
CamembertPreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
MaskedLMOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
CamembertForSequenceClassification
extends
CamembertPreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
SequenceClassifierOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
CamembertForTokenClassification
extends
CamembertPreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
TokenClassifierOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
CamembertForQuestionAnswering
extends
CamembertPreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
QuestionAnsweringModelOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
DebertaPreTrainedModel
extends
PreTrainedModel
{
}
class
DebertaModel
extends
DebertaPreTrainedModel
{
}
class
DebertaForMaskedLM
extends
DebertaPreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
MaskedLMOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
DebertaForSequenceClassification
extends
DebertaPreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
SequenceClassifierOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
DebertaForTokenClassification
extends
DebertaPreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
TokenClassifierOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
DebertaForQuestionAnswering
extends
DebertaPreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
QuestionAnsweringModelOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
DebertaV2PreTrainedModel
extends
PreTrainedModel
{
}
class
DebertaV2Model
extends
DebertaV2PreTrainedModel
{
}
class
DebertaV2ForMaskedLM
extends
DebertaV2PreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
MaskedLMOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
DebertaV2ForSequenceClassification
extends
DebertaV2PreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
SequenceClassifierOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
DebertaV2ForTokenClassification
extends
DebertaV2PreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
TokenClassifierOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
DebertaV2ForQuestionAnswering
extends
DebertaV2PreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
QuestionAnsweringModelOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
DistilBertPreTrainedModel
extends
PreTrainedModel
{
}
class
DistilBertModel
extends
DistilBertPreTrainedModel
{
}
class
DistilBertForSequenceClassification
extends
DistilBertPreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
SequenceClassifierOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
DistilBertForTokenClassification
extends
DistilBertPreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
TokenClassifierOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
DistilBertForQuestionAnswering
extends
DistilBertPreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
QuestionAnsweringModelOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
DistilBertForMaskedLM
extends
DistilBertPreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
MaskedLMOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
EsmPreTrainedModel
extends
PreTrainedModel
{
}
class
EsmModel
extends
EsmPreTrainedModel
{
}
class
EsmForMaskedLM
extends
EsmPreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
MaskedLMOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
EsmForSequenceClassification
extends
EsmPreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
SequenceClassifierOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
EsmForTokenClassification
extends
EsmPreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
TokenClassifierOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
MobileBertPreTrainedModel
extends
PreTrainedModel
{
}
class
MobileBertModel
extends
MobileBertPreTrainedModel
{
}
class
MobileBertForMaskedLM
extends
MobileBertPreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
MaskedLMOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
MobileBertForSequenceClassification
extends
MobileBertPreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
SequenceClassifierOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
MobileBertForQuestionAnswering
extends
MobileBertPreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
QuestionAnsweringModelOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
MPNetPreTrainedModel
extends
PreTrainedModel
{
}
class
MPNetModel
extends
MPNetPreTrainedModel
{
}
class
MPNetForMaskedLM
extends
MPNetPreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
MaskedLMOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
MPNetForSequenceClassification
extends
MPNetPreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
SequenceClassifierOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
MPNetForTokenClassification
extends
MPNetPreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
TokenClassifierOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
MPNetForQuestionAnswering
extends
MPNetPreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
QuestionAnsweringModelOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
SqueezeBertPreTrainedModel
extends
PreTrainedModel
{
}
class
SqueezeBertModel
extends
SqueezeBertPreTrainedModel
{
}
class
SqueezeBertForMaskedLM
extends
SqueezeBertPreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
MaskedLMOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
SqueezeBertForSequenceClassification
extends
SqueezeBertPreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
SequenceClassifierOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
SqueezeBertForQuestionAnswering
extends
SqueezeBertPreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
QuestionAnsweringModelOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
AlbertPreTrainedModel
extends
PreTrainedModel
{
}
class
AlbertModel
extends
AlbertPreTrainedModel
{
}
class
AlbertForSequenceClassification
extends
AlbertPreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
SequenceClassifierOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
AlbertForQuestionAnswering
extends
AlbertPreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
QuestionAnsweringModelOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
AlbertForMaskedLM
extends
AlbertPreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
MaskedLMOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
T5PreTrainedModel
extends
PreTrainedModel
{
forward_params
=
[
'
input_ids
'
'
attention_mask
'
'
encoder_outputs
'
'
decoder_input_ids
'
'
decoder_attention_mask
'
'
past_key_values
'
]
;
}
;
class
T5Model
extends
T5PreTrainedModel
{
}
class
T5ForConditionalGeneration
extends
T5PreTrainedModel
{
}
class
LongT5PreTrainedModel
extends
PreTrainedModel
{
}
;
class
LongT5Model
extends
LongT5PreTrainedModel
{
}
class
LongT5ForConditionalGeneration
extends
LongT5PreTrainedModel
{
}
class
MT5PreTrainedModel
extends
PreTrainedModel
{
}
;
class
MT5Model
extends
MT5PreTrainedModel
{
}
class
MT5ForConditionalGeneration
extends
MT5PreTrainedModel
{
}
class
BartPretrainedModel
extends
PreTrainedModel
{
}
;
class
BartModel
extends
BartPretrainedModel
{
}
class
BartForConditionalGeneration
extends
BartPretrainedModel
{
}
class
BartForSequenceClassification
extends
BartPretrainedModel
{
async
_call
(
model_inputs
)
{
return
new
SequenceClassifierOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
MBartPreTrainedModel
extends
PreTrainedModel
{
}
;
class
MBartModel
extends
MBartPreTrainedModel
{
}
class
MBartForConditionalGeneration
extends
MBartPreTrainedModel
{
}
class
MBartForSequenceClassification
extends
MBartPreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
SequenceClassifierOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
MBartForCausalLM
extends
MBartPreTrainedModel
{
}
class
BlenderbotPreTrainedModel
extends
PreTrainedModel
{
}
;
class
BlenderbotModel
extends
BlenderbotPreTrainedModel
{
}
class
BlenderbotForConditionalGeneration
extends
BlenderbotPreTrainedModel
{
}
class
BlenderbotSmallPreTrainedModel
extends
PreTrainedModel
{
}
;
class
BlenderbotSmallModel
extends
BlenderbotSmallPreTrainedModel
{
}
class
BlenderbotSmallForConditionalGeneration
extends
BlenderbotSmallPreTrainedModel
{
}
class
RobertaPreTrainedModel
extends
PreTrainedModel
{
}
class
RobertaModel
extends
RobertaPreTrainedModel
{
}
class
RobertaForMaskedLM
extends
RobertaPreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
MaskedLMOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
RobertaForSequenceClassification
extends
RobertaPreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
SequenceClassifierOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
RobertaForTokenClassification
extends
RobertaPreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
TokenClassifierOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
RobertaForQuestionAnswering
extends
RobertaPreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
QuestionAnsweringModelOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
XLMPreTrainedModel
extends
PreTrainedModel
{
}
class
XLMModel
extends
XLMPreTrainedModel
{
}
class
XLMWithLMHeadModel
extends
XLMPreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
MaskedLMOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
XLMForSequenceClassification
extends
XLMPreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
SequenceClassifierOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
XLMForTokenClassification
extends
XLMPreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
TokenClassifierOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
XLMForQuestionAnswering
extends
XLMPreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
QuestionAnsweringModelOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
XLMRobertaPreTrainedModel
extends
PreTrainedModel
{
}
class
XLMRobertaModel
extends
XLMRobertaPreTrainedModel
{
}
class
XLMRobertaForMaskedLM
extends
XLMRobertaPreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
MaskedLMOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
XLMRobertaForSequenceClassification
extends
XLMRobertaPreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
SequenceClassifierOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
XLMRobertaForTokenClassification
extends
XLMRobertaPreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
TokenClassifierOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
XLMRobertaForQuestionAnswering
extends
XLMRobertaPreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
QuestionAnsweringModelOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
ASTPreTrainedModel
extends
PreTrainedModel
{
}
;
class
ASTModel
extends
ASTPreTrainedModel
{
}
class
ASTForAudioClassification
extends
ASTPreTrainedModel
{
}
class
WhisperPreTrainedModel
extends
PreTrainedModel
{
requires_attention_mask
=
false
;
main_input_name
=
'
input_features
'
;
forward_params
=
[
'
input_features
'
'
attention_mask
'
'
decoder_input_ids
'
'
decoder_attention_mask
'
'
past_key_values
'
]
;
}
;
class
WhisperModel
extends
WhisperPreTrainedModel
{
}
class
WhisperForConditionalGeneration
extends
WhisperPreTrainedModel
{
_prepare_generation_config
(
generation_config
kwargs
)
{
return
(
super
.
_prepare_generation_config
(
generation_config
kwargs
_models_whisper_generation_whisper_js__WEBPACK_IMPORTED_MODULE_15__
.
WhisperGenerationConfig
)
)
;
}
_retrieve_init_tokens
(
generation_config
)
{
const
init_tokens
=
[
generation_config
.
decoder_start_token_id
]
;
let
language
=
generation_config
.
language
;
const
task
=
generation_config
.
task
;
if
(
generation_config
.
is_multilingual
)
{
if
(
!
language
)
{
console
.
warn
(
'
No
language
specified
-
defaulting
to
English
(
en
)
.
'
)
;
language
=
'
en
'
;
}
const
language_code
=
(
0
_models_whisper_common_whisper_js__WEBPACK_IMPORTED_MODULE_16__
.
whisper_language_to_code
)
(
language
)
;
const
language_token
=
<
|
{
language_code
}
|
>
;
init_tokens
.
push
(
generation_config
.
lang_to_id
[
language_token
]
)
init_tokens
.
push
(
generation_config
.
task_to_id
[
task
?
?
'
transcribe
'
]
)
;
}
else
if
(
language
|
|
task
)
{
throw
new
Error
(
"
Cannot
specify
task
or
language
for
an
English
-
only
model
.
If
the
model
is
intended
to
be
multilingual
pass
is_multilingual
=
true
to
generate
or
update
the
generation
config
.
"
)
}
if
(
!
generation_config
.
return_timestamps
&
&
generation_config
.
no_timestamps_token_id
&
&
init_tokens
.
at
(
-
1
)
!
=
=
generation_config
.
no_timestamps_token_id
)
{
init_tokens
.
push
(
generation_config
.
no_timestamps_token_id
)
;
}
else
if
(
generation_config
.
return_timestamps
&
&
init_tokens
.
at
(
-
1
)
=
=
=
generation_config
.
no_timestamps_token_id
)
{
console
.
warn
(
"
<
|
notimestamps
|
>
prompt
token
is
removed
from
generation_config
since
return_timestamps
is
set
to
true
.
"
)
;
init_tokens
.
pop
(
)
;
}
return
init_tokens
.
filter
(
token
=
>
token
!
=
null
)
;
}
async
generate
(
{
inputs
=
null
generation_config
=
null
logits_processor
=
null
stopping_criteria
=
null
.
.
.
kwargs
}
)
{
generation_config
=
this
.
_prepare_generation_config
(
generation_config
kwargs
)
;
const
init_tokens
=
kwargs
.
decoder_input_ids
?
?
this
.
_retrieve_init_tokens
(
generation_config
)
;
if
(
generation_config
.
return_timestamps
)
{
logits_processor
?
?
=
new
_generation_logits_process_js__WEBPACK_IMPORTED_MODULE_7__
.
LogitsProcessorList
(
)
;
logits_processor
.
push
(
new
_generation_logits_process_js__WEBPACK_IMPORTED_MODULE_7__
.
WhisperTimeStampLogitsProcessor
(
generation_config
init_tokens
)
)
;
}
if
(
generation_config
.
begin_suppress_tokens
)
{
logits_processor
?
?
=
new
_generation_logits_process_js__WEBPACK_IMPORTED_MODULE_7__
.
LogitsProcessorList
(
)
;
logits_processor
.
push
(
new
_generation_logits_process_js__WEBPACK_IMPORTED_MODULE_7__
.
SuppressTokensAtBeginLogitsProcessor
(
generation_config
.
begin_suppress_tokens
init_tokens
.
length
)
)
;
}
if
(
generation_config
.
return_token_timestamps
)
{
if
(
!
generation_config
.
alignment_heads
)
{
throw
new
Error
(
"
Model
generation
config
has
no
alignment_heads
token
-
level
timestamps
not
available
.
"
+
"
See
https
:
/
/
gist
.
github
.
com
/
hollance
/
42e32852f24243b748ae6bc1f985b13a
on
how
to
add
this
property
to
the
generation
config
.
"
)
}
if
(
generation_config
.
task
=
=
=
'
translate
'
)
{
console
.
warn
(
"
Token
-
level
timestamps
may
not
be
reliable
for
task
'
translate
'
.
"
)
}
generation_config
.
output_attentions
=
true
;
generation_config
.
return_dict_in_generate
=
true
;
}
const
outputs
=
await
super
.
generate
(
{
inputs
generation_config
logits_processor
decoder_input_ids
:
init_tokens
.
.
.
kwargs
}
)
;
if
(
generation_config
.
return_token_timestamps
)
{
outputs
[
"
token_timestamps
"
]
=
this
.
_extract_token_timestamps
(
outputs
generation_config
.
alignment_heads
generation_config
.
num_frames
)
;
}
return
outputs
;
}
_extract_token_timestamps
(
generate_outputs
alignment_heads
num_frames
=
null
time_precision
=
0
.
02
)
{
if
(
!
generate_outputs
.
cross_attentions
)
{
throw
new
Error
(
"
Model
outputs
must
contain
cross
attentions
to
extract
timestamps
.
"
+
"
This
is
most
likely
because
the
model
was
not
exported
with
output_attentions
=
True
.
"
)
}
if
(
num_frames
=
=
null
)
{
console
.
warn
(
"
num_frames
has
not
been
set
meaning
the
entire
audio
will
be
analyzed
.
"
+
"
This
may
lead
to
inaccurate
token
-
level
timestamps
for
short
audios
(
<
30
seconds
)
.
"
)
;
}
let
median_filter_width
=
this
.
config
.
median_filter_width
;
if
(
median_filter_width
=
=
=
undefined
)
{
console
.
warn
(
"
Model
config
has
no
median_filter_width
using
default
value
of
7
.
"
)
median_filter_width
=
7
;
}
const
batch
=
generate_outputs
.
cross_attentions
;
const
cross_attentions
=
Array
.
from
(
{
length
:
this
.
config
.
decoder_layers
}
(
_
i
)
=
>
(
0
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_9__
.
cat
)
(
batch
.
map
(
x
=
>
x
[
i
]
)
2
)
)
;
const
weights
=
(
0
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_9__
.
stack
)
(
alignment_heads
.
map
(
(
[
l
h
]
)
=
>
{
if
(
l
>
=
cross_attentions
.
length
)
{
throw
new
Error
(
Layer
index
{
l
}
is
out
of
bounds
for
cross
attentions
(
length
{
cross_attentions
.
length
}
)
.
)
}
return
num_frames
?
cross_attentions
[
l
]
.
slice
(
null
h
null
[
0
num_frames
]
)
:
cross_attentions
[
l
]
.
slice
(
null
h
)
;
}
)
)
.
transpose
(
1
0
2
3
)
;
const
[
std
calculatedMean
]
=
(
0
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_9__
.
std_mean
)
(
weights
-
2
0
true
)
;
const
smoothedWeights
=
weights
.
clone
(
)
;
for
(
let
a
=
0
;
a
<
smoothedWeights
.
dims
[
0
]
;
+
+
a
)
{
const
aTensor
=
smoothedWeights
[
a
]
;
for
(
let
b
=
0
;
b
<
aTensor
.
dims
[
0
]
;
+
+
b
)
{
const
bTensor
=
aTensor
[
b
]
;
const
stdTensorData
=
std
[
a
]
[
b
]
[
0
]
.
data
;
const
meanTensorData
=
calculatedMean
[
a
]
[
b
]
[
0
]
.
data
;
for
(
let
c
=
0
;
c
<
bTensor
.
dims
[
0
]
;
+
+
c
)
{
let
cTensorData
=
bTensor
[
c
]
.
data
;
for
(
let
d
=
0
;
d
<
cTensorData
.
length
;
+
+
d
)
{
cTensorData
[
d
]
=
(
cTensorData
[
d
]
-
meanTensorData
[
d
]
)
/
stdTensorData
[
d
]
}
cTensorData
.
set
(
(
0
_utils_maths_js__WEBPACK_IMPORTED_MODULE_11__
.
medianFilter
)
(
cTensorData
median_filter_width
)
)
}
}
}
const
batchedMatrices
=
[
(
0
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_9__
.
mean
)
(
smoothedWeights
1
)
]
;
const
timestampsShape
=
generate_outputs
.
sequences
.
dims
;
const
timestamps
=
new
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_9__
.
Tensor
(
'
float32
'
new
Float32Array
(
timestampsShape
[
0
]
*
timestampsShape
[
1
]
)
timestampsShape
)
;
for
(
let
batch_idx
=
0
;
batch_idx
<
timestampsShape
[
0
]
;
+
+
batch_idx
)
{
const
matrix
=
batchedMatrices
[
batch_idx
]
.
neg
(
)
.
squeeze_
(
0
)
;
const
[
text_indices
time_indices
]
=
(
0
_utils_maths_js__WEBPACK_IMPORTED_MODULE_11__
.
dynamic_time_warping
)
(
matrix
.
tolist
(
)
)
;
const
diffs
=
Array
.
from
(
{
length
:
text_indices
.
length
-
1
}
(
v
i
)
=
>
text_indices
[
i
+
1
]
-
text_indices
[
i
]
)
;
const
jumps
=
(
0
_utils_core_js__WEBPACK_IMPORTED_MODULE_4__
.
mergeArrays
)
(
[
1
]
diffs
)
.
map
(
x
=
>
!
!
x
)
;
const
jump_times
=
[
]
;
for
(
let
i
=
0
;
i
<
jumps
.
length
;
+
+
i
)
{
if
(
jumps
[
i
]
)
{
jump_times
.
push
(
time_indices
[
i
]
*
time_precision
)
;
}
}
timestamps
[
batch_idx
]
.
data
.
set
(
jump_times
1
)
}
return
timestamps
;
}
}
class
VisionEncoderDecoderModel
extends
PreTrainedModel
{
main_input_name
=
'
pixel_values
'
;
forward_params
=
[
'
pixel_values
'
'
decoder_input_ids
'
'
encoder_hidden_states
'
'
past_key_values
'
]
;
}
class
LlavaPreTrainedModel
extends
PreTrainedModel
{
forward_params
=
[
'
input_ids
'
'
pixel_values
'
'
attention_mask
'
'
position_ids
'
'
past_key_values
'
]
;
}
class
LlavaForConditionalGeneration
extends
LlavaPreTrainedModel
{
_merge_input_ids_with_image_features
(
{
inputs_embeds
image_features
input_ids
attention_mask
}
)
{
const
image_token_index
=
this
.
config
.
image_token_index
;
const
idsList
=
input_ids
.
tolist
(
)
;
const
indexOfImage
=
idsList
.
map
(
x
=
>
x
.
findIndex
(
x
=
>
x
=
=
image_token_index
)
)
;
const
noImages
=
indexOfImage
.
every
(
x
=
>
x
=
=
=
-
1
)
;
const
allImages
=
indexOfImage
.
every
(
x
=
>
x
!
=
=
-
1
)
;
if
(
!
noImages
&
&
!
allImages
)
{
throw
new
Error
(
'
Every
input
should
contain
either
0
or
1
image
token
.
'
)
;
}
if
(
noImages
)
{
return
{
inputs_embeds
attention_mask
}
}
const
stacked
=
[
]
;
const
stacked_attention_mask
=
[
]
;
for
(
let
i
=
0
;
i
<
indexOfImage
.
length
;
+
+
i
)
{
const
index
=
indexOfImage
[
i
]
;
const
e
=
inputs_embeds
[
i
]
;
const
im
=
image_features
[
i
]
;
const
am
=
attention_mask
[
i
]
;
stacked
.
push
(
(
0
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_9__
.
cat
)
(
[
e
.
slice
(
[
0
index
]
)
im
e
.
slice
(
[
index
+
1
e
.
dims
[
0
]
]
)
]
0
)
)
;
stacked_attention_mask
.
push
(
(
0
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_9__
.
cat
)
(
[
am
.
slice
(
[
0
index
]
)
(
0
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_9__
.
ones
)
(
[
im
.
dims
[
0
]
]
)
am
.
slice
(
[
index
+
1
am
.
dims
[
0
]
]
)
]
0
)
)
}
return
{
inputs_embeds
:
(
0
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_9__
.
stack
)
(
stacked
0
)
attention_mask
:
(
0
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_9__
.
stack
)
(
stacked_attention_mask
0
)
}
}
}
class
LlavaOnevisionForConditionalGeneration
extends
LlavaForConditionalGeneration
{
}
class
Moondream1ForConditionalGeneration
extends
LlavaForConditionalGeneration
{
}
class
Florence2PreTrainedModel
extends
PreTrainedModel
{
forward_params
=
[
'
input_ids
'
'
inputs_embeds
'
'
attention_mask
'
'
pixel_values
'
'
encoder_outputs
'
'
decoder_input_ids
'
'
decoder_inputs_embeds
'
'
decoder_attention_mask
'
'
past_key_values
'
]
;
main_input_name
=
'
inputs_embeds
'
;
}
class
Florence2ForConditionalGeneration
extends
Florence2PreTrainedModel
{
_merge_input_ids_with_image_features
(
{
inputs_embeds
image_features
input_ids
attention_mask
}
)
{
return
{
inputs_embeds
:
(
0
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_9__
.
cat
)
(
[
image_features
inputs_embeds
]
1
)
attention_mask
:
(
0
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_9__
.
cat
)
(
[
(
0
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_9__
.
ones
)
(
image_features
.
dims
.
slice
(
0
2
)
)
attention_mask
]
1
)
}
}
async
_prepare_inputs_embeds
(
{
input_ids
pixel_values
inputs_embeds
attention_mask
}
)
{
if
(
!
input_ids
&
&
!
pixel_values
)
{
throw
new
Error
(
'
Either
input_ids
or
pixel_values
should
be
provided
.
'
)
;
}
let
text_features
image_features
;
if
(
input_ids
)
{
text_features
=
await
this
.
encode_text
(
{
input_ids
}
)
;
}
if
(
pixel_values
)
{
image_features
=
await
this
.
encode_image
(
{
pixel_values
}
)
;
}
if
(
text_features
&
&
image_features
)
{
(
{
inputs_embeds
attention_mask
}
=
this
.
_merge_input_ids_with_image_features
(
{
inputs_embeds
:
text_features
image_features
input_ids
attention_mask
}
)
)
;
}
else
{
inputs_embeds
=
text_features
|
|
image_features
;
}
return
{
inputs_embeds
attention_mask
}
;
}
async
forward
(
{
input_ids
pixel_values
attention_mask
decoder_input_ids
decoder_attention_mask
encoder_outputs
past_key_values
inputs_embeds
decoder_inputs_embeds
}
)
{
if
(
!
inputs_embeds
)
{
(
{
inputs_embeds
attention_mask
}
=
await
this
.
_prepare_inputs_embeds
(
{
input_ids
pixel_values
inputs_embeds
attention_mask
}
)
)
;
}
if
(
!
encoder_outputs
)
{
let
{
last_hidden_state
}
=
await
encoderForward
(
this
{
inputs_embeds
attention_mask
}
)
;
encoder_outputs
=
last_hidden_state
;
}
if
(
!
decoder_inputs_embeds
)
{
if
(
!
decoder_input_ids
)
{
throw
new
Error
(
'
Either
decoder_input_ids
or
decoder_inputs_embeds
should
be
provided
.
'
)
;
}
decoder_inputs_embeds
=
await
this
.
encode_text
(
{
input_ids
:
decoder_input_ids
}
)
;
}
const
decoderFeeds
=
{
inputs_embeds
:
decoder_inputs_embeds
attention_mask
:
decoder_attention_mask
encoder_attention_mask
:
attention_mask
encoder_hidden_states
:
encoder_outputs
past_key_values
}
;
const
decoder_outputs
=
await
decoderForward
(
this
decoderFeeds
true
)
;
return
decoder_outputs
;
}
}
class
CLIPPreTrainedModel
extends
PreTrainedModel
{
}
class
CLIPModel
extends
CLIPPreTrainedModel
{
}
class
CLIPTextModel
extends
CLIPPreTrainedModel
{
static
async
from_pretrained
(
pretrained_model_name_or_path
options
=
{
}
)
{
options
.
model_file_name
?
?
=
'
text_model
'
;
return
super
.
from_pretrained
(
pretrained_model_name_or_path
options
)
;
}
}
class
CLIPTextModelWithProjection
extends
CLIPPreTrainedModel
{
static
async
from_pretrained
(
pretrained_model_name_or_path
options
=
{
}
)
{
options
.
model_file_name
?
?
=
'
text_model
'
;
return
super
.
from_pretrained
(
pretrained_model_name_or_path
options
)
;
}
}
class
CLIPVisionModel
extends
CLIPPreTrainedModel
{
static
async
from_pretrained
(
pretrained_model_name_or_path
options
=
{
}
)
{
options
.
model_file_name
?
?
=
'
vision_model
'
;
return
super
.
from_pretrained
(
pretrained_model_name_or_path
options
)
;
}
}
class
CLIPVisionModelWithProjection
extends
CLIPPreTrainedModel
{
static
async
from_pretrained
(
pretrained_model_name_or_path
options
=
{
}
)
{
options
.
model_file_name
?
?
=
'
vision_model
'
;
return
super
.
from_pretrained
(
pretrained_model_name_or_path
options
)
;
}
}
class
SiglipPreTrainedModel
extends
PreTrainedModel
{
}
class
SiglipModel
extends
SiglipPreTrainedModel
{
}
class
SiglipTextModel
extends
SiglipPreTrainedModel
{
static
async
from_pretrained
(
pretrained_model_name_or_path
options
=
{
}
)
{
options
.
model_file_name
?
?
=
'
text_model
'
;
return
super
.
from_pretrained
(
pretrained_model_name_or_path
options
)
;
}
}
class
SiglipVisionModel
extends
CLIPPreTrainedModel
{
static
async
from_pretrained
(
pretrained_model_name_or_path
options
=
{
}
)
{
options
.
model_file_name
?
?
=
'
vision_model
'
;
return
super
.
from_pretrained
(
pretrained_model_name_or_path
options
)
;
}
}
class
ChineseCLIPPreTrainedModel
extends
PreTrainedModel
{
}
class
ChineseCLIPModel
extends
ChineseCLIPPreTrainedModel
{
}
class
JinaCLIPPreTrainedModel
extends
PreTrainedModel
{
}
class
JinaCLIPModel
extends
JinaCLIPPreTrainedModel
{
async
forward
(
model_inputs
)
{
const
missing_text_inputs
=
!
model_inputs
.
input_ids
;
const
missing_image_inputs
=
!
model_inputs
.
pixel_values
;
if
(
missing_text_inputs
&
&
missing_image_inputs
)
{
throw
new
Error
(
'
Either
input_ids
or
pixel_values
should
be
provided
.
'
)
;
}
if
(
missing_text_inputs
)
{
model_inputs
.
input_ids
=
(
0
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_9__
.
ones
)
(
[
model_inputs
.
pixel_values
.
dims
[
0
]
1
]
)
;
}
if
(
missing_image_inputs
)
{
const
{
image_size
}
=
this
.
config
.
vision_config
;
model_inputs
.
pixel_values
=
(
0
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_9__
.
full
)
(
[
0
3
image_size
image_size
]
0
.
0
)
;
}
const
{
text_embeddings
image_embeddings
l2norm_text_embeddings
l2norm_image_embeddings
}
=
await
super
.
forward
(
model_inputs
)
;
const
result
=
{
}
;
if
(
!
missing_text_inputs
)
{
result
.
text_embeddings
=
text_embeddings
;
result
.
l2norm_text_embeddings
=
l2norm_text_embeddings
;
}
if
(
!
missing_image_inputs
)
{
result
.
image_embeddings
=
image_embeddings
;
result
.
l2norm_image_embeddings
=
l2norm_image_embeddings
;
}
return
result
}
}
class
JinaCLIPTextModel
extends
JinaCLIPPreTrainedModel
{
static
async
from_pretrained
(
pretrained_model_name_or_path
options
=
{
}
)
{
options
.
model_file_name
?
?
=
'
text_model
'
;
return
super
.
from_pretrained
(
pretrained_model_name_or_path
options
)
;
}
}
class
JinaCLIPVisionModel
extends
JinaCLIPPreTrainedModel
{
static
async
from_pretrained
(
pretrained_model_name_or_path
options
=
{
}
)
{
options
.
model_file_name
?
?
=
'
vision_model
'
;
return
super
.
from_pretrained
(
pretrained_model_name_or_path
options
)
;
}
}
class
CLIPSegPreTrainedModel
extends
PreTrainedModel
{
}
class
CLIPSegModel
extends
CLIPSegPreTrainedModel
{
}
class
CLIPSegForImageSegmentation
extends
CLIPSegPreTrainedModel
{
}
class
GPT2PreTrainedModel
extends
PreTrainedModel
{
}
class
GPT2Model
extends
GPT2PreTrainedModel
{
}
class
GPT2LMHeadModel
extends
GPT2PreTrainedModel
{
}
class
JAISPreTrainedModel
extends
PreTrainedModel
{
}
class
JAISModel
extends
JAISPreTrainedModel
{
}
class
JAISLMHeadModel
extends
JAISPreTrainedModel
{
}
class
GPTNeoPreTrainedModel
extends
PreTrainedModel
{
}
class
GPTNeoModel
extends
GPTNeoPreTrainedModel
{
}
class
GPTNeoForCausalLM
extends
GPTNeoPreTrainedModel
{
}
class
GPTNeoXPreTrainedModel
extends
PreTrainedModel
{
}
class
GPTNeoXModel
extends
GPTNeoXPreTrainedModel
{
}
class
GPTNeoXForCausalLM
extends
GPTNeoXPreTrainedModel
{
}
class
GPTJPreTrainedModel
extends
PreTrainedModel
{
}
class
GPTJModel
extends
GPTJPreTrainedModel
{
}
class
GPTJForCausalLM
extends
GPTJPreTrainedModel
{
}
class
GPTBigCodePreTrainedModel
extends
PreTrainedModel
{
}
class
GPTBigCodeModel
extends
GPTBigCodePreTrainedModel
{
}
class
GPTBigCodeForCausalLM
extends
GPTBigCodePreTrainedModel
{
}
class
CodeGenPreTrainedModel
extends
PreTrainedModel
{
}
class
CodeGenModel
extends
CodeGenPreTrainedModel
{
}
class
CodeGenForCausalLM
extends
CodeGenPreTrainedModel
{
}
class
LlamaPreTrainedModel
extends
PreTrainedModel
{
}
class
LlamaModel
extends
LlamaPreTrainedModel
{
}
class
LlamaForCausalLM
extends
LlamaPreTrainedModel
{
}
class
MobileLLMPreTrainedModel
extends
PreTrainedModel
{
}
class
MobileLLMModel
extends
MobileLLMPreTrainedModel
{
}
class
MobileLLMForCausalLM
extends
MobileLLMPreTrainedModel
{
}
class
OlmoPreTrainedModel
extends
PreTrainedModel
{
}
class
OlmoModel
extends
OlmoPreTrainedModel
{
}
class
OlmoForCausalLM
extends
OlmoPreTrainedModel
{
}
class
GranitePreTrainedModel
extends
PreTrainedModel
{
}
class
GraniteModel
extends
GranitePreTrainedModel
{
}
class
GraniteForCausalLM
extends
GranitePreTrainedModel
{
}
class
CoherePreTrainedModel
extends
PreTrainedModel
{
}
class
CohereModel
extends
CoherePreTrainedModel
{
}
class
CohereForCausalLM
extends
CoherePreTrainedModel
{
}
class
GemmaPreTrainedModel
extends
PreTrainedModel
{
}
class
GemmaModel
extends
GemmaPreTrainedModel
{
}
class
GemmaForCausalLM
extends
GemmaPreTrainedModel
{
}
class
Gemma2PreTrainedModel
extends
PreTrainedModel
{
}
class
Gemma2Model
extends
Gemma2PreTrainedModel
{
}
class
Gemma2ForCausalLM
extends
Gemma2PreTrainedModel
{
}
class
OpenELMPreTrainedModel
extends
PreTrainedModel
{
}
class
OpenELMModel
extends
OpenELMPreTrainedModel
{
}
class
OpenELMForCausalLM
extends
OpenELMPreTrainedModel
{
}
class
Qwen2PreTrainedModel
extends
PreTrainedModel
{
}
class
Qwen2Model
extends
Qwen2PreTrainedModel
{
}
class
Qwen2ForCausalLM
extends
Qwen2PreTrainedModel
{
}
class
Qwen2VLPreTrainedModel
extends
PreTrainedModel
{
forward_params
=
[
'
input_ids
'
'
attention_mask
'
'
position_ids
'
'
past_key_values
'
'
pixel_values
'
'
image_grid_thw
'
]
;
}
class
Qwen2VLForConditionalGeneration
extends
Qwen2VLPreTrainedModel
{
get_rope_index
(
input_ids
image_grid_thw
video_grid_thw
attention_mask
)
{
const
{
vision_config
image_token_id
video_token_id
vision_start_token_id
}
=
this
.
config
;
const
spatial_merge_size
=
vision_config
.
spatial_merge_size
?
?
2
;
const
mrope_position_deltas
=
[
]
;
if
(
image_grid_thw
|
|
video_grid_thw
)
{
let
total_input_ids
=
input_ids
.
tolist
(
)
;
if
(
!
attention_mask
)
{
attention_mask
=
(
0
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_9__
.
ones_like
)
(
input_ids
)
;
}
const
attention_mask_list
=
attention_mask
.
tolist
(
)
;
const
position_ids_list
=
Array
.
from
(
{
length
:
3
}
_
=
>
Array
.
from
(
{
length
:
input_ids
.
dims
[
0
]
}
_
=
>
Array
.
from
(
{
length
:
input_ids
.
dims
[
1
]
}
_
=
>
1
)
)
)
;
const
image_grid_thw_list
=
image_grid_thw
?
image_grid_thw
.
tolist
(
)
:
[
]
;
const
video_grid_thw_list
=
video_grid_thw
?
video_grid_thw
.
tolist
(
)
:
[
]
;
let
image_index
=
0
;
let
video_index
=
0
;
for
(
let
i
=
0
;
i
<
total_input_ids
.
length
;
+
+
i
)
{
const
ids
=
total_input_ids
[
i
]
.
filter
(
(
_
j
)
=
>
attention_mask_list
[
i
]
[
j
]
=
=
1
)
;
const
vision_start_indices
=
ids
.
reduce
(
(
acc
x
idx
)
=
>
{
if
(
x
=
=
vision_start_token_id
)
acc
.
push
(
idx
)
;
return
acc
;
}
[
]
)
;
const
vision_tokens
=
vision_start_indices
.
map
(
x
=
>
ids
[
x
+
1
]
)
;
const
image_nums
=
vision_tokens
.
filter
(
x
=
>
x
=
=
image_token_id
)
.
length
;
const
video_nums
=
vision_tokens
.
filter
(
x
=
>
x
=
=
video_token_id
)
.
length
;
let
llm_pos_ids_list
=
[
]
;
let
st
=
0
;
let
remain_images
=
image_nums
;
let
remain_videos
=
video_nums
;
for
(
let
j
=
0
;
j
<
vision_tokens
.
length
;
+
+
j
)
{
const
next_image_token
=
ids
.
findIndex
(
(
x
i
)
=
>
i
>
st
&
&
x
=
=
image_token_id
)
;
const
next_video_token
=
ids
.
findIndex
(
(
x
i
)
=
>
i
>
st
&
&
x
=
=
video_token_id
)
;
const
ed_image
=
(
remain_images
>
0
&
&
next_image_token
!
=
=
-
1
)
?
next_image_token
:
ids
.
length
+
1
;
const
ed_video
=
(
remain_videos
>
0
&
&
next_video_token
!
=
=
-
1
)
?
next_video_token
:
ids
.
length
+
1
;
let
ed
;
let
t
h
w
;
if
(
ed_image
<
ed_video
)
{
(
[
t
h
w
]
=
image_grid_thw_list
[
image_index
]
)
;
+
+
image_index
;
-
-
remain_images
;
ed
=
ed_image
;
}
else
{
(
[
t
h
w
]
=
video_grid_thw_list
[
video_index
]
)
;
+
+
video_index
;
-
-
remain_videos
;
ed
=
ed_video
;
}
const
[
llm_grid_t
llm_grid_h
llm_grid_w
]
=
[
Number
(
t
)
Math
.
floor
(
Number
(
h
)
/
spatial_merge_size
)
Math
.
floor
(
Number
(
w
)
/
spatial_merge_size
)
]
const
text_len
=
ed
-
st
;
const
st_idx
=
llm_pos_ids_list
.
length
>
0
?
(
0
_utils_maths_js__WEBPACK_IMPORTED_MODULE_11__
.
max
)
(
llm_pos_ids_list
.
at
(
-
1
)
)
[
0
]
+
1
:
0
;
llm_pos_ids_list
.
push
(
Array
.
from
(
{
length
:
3
*
text_len
}
(
_
i
)
=
>
st_idx
+
(
i
%
text_len
)
)
)
const
offset
=
text_len
+
st_idx
;
const
grid_size
=
llm_grid_t
*
llm_grid_h
*
llm_grid_w
;
const
t_index
=
Array
.
from
(
{
length
:
grid_size
}
(
_
i
)
=
>
offset
+
Math
.
floor
(
i
/
(
llm_grid_h
*
llm_grid_w
)
)
)
const
h_index
=
Array
.
from
(
{
length
:
grid_size
}
(
_
i
)
=
>
offset
+
Math
.
floor
(
i
/
llm_grid_w
)
%
llm_grid_h
)
const
w_index
=
Array
.
from
(
{
length
:
grid_size
}
(
_
i
)
=
>
offset
+
i
%
llm_grid_w
)
llm_pos_ids_list
.
push
(
[
t_index
h_index
w_index
]
.
flat
(
)
)
st
=
ed
+
grid_size
;
}
if
(
st
<
ids
.
length
)
{
const
st_idx
=
llm_pos_ids_list
.
length
>
0
?
(
0
_utils_maths_js__WEBPACK_IMPORTED_MODULE_11__
.
max
)
(
llm_pos_ids_list
.
at
(
-
1
)
)
[
0
]
+
1
:
0
;
const
text_len
=
ids
.
length
-
st
;
llm_pos_ids_list
.
push
(
Array
.
from
(
{
length
:
3
*
text_len
}
(
_
i
)
=
>
(
st_idx
+
(
i
%
text_len
)
)
)
)
}
const
num_items
=
llm_pos_ids_list
.
reduce
(
(
acc
x
)
=
>
acc
+
x
.
length
0
)
;
const
llm_positions
=
new
Array
(
num_items
)
;
let
index
=
0
;
for
(
let
x
=
0
;
x
<
3
;
+
+
x
)
{
for
(
let
y
=
0
;
y
<
llm_pos_ids_list
.
length
;
+
+
y
)
{
const
val
=
llm_pos_ids_list
[
y
]
;
const
text_len
=
val
.
length
/
3
;
for
(
let
z
=
x
*
text_len
;
z
<
(
x
+
1
)
*
text_len
;
+
+
z
)
{
llm_positions
[
index
+
+
]
=
val
[
z
]
;
}
}
}
let
count
=
0
;
const
attn_mask
=
attention_mask_list
[
i
]
;
for
(
let
y
=
0
;
y
<
attn_mask
.
length
;
+
+
y
)
{
if
(
attn_mask
[
y
]
=
=
1
)
{
for
(
let
x
=
0
;
x
<
3
;
+
+
x
)
{
position_ids_list
[
x
]
[
i
]
[
y
]
=
llm_positions
[
x
*
num_items
/
3
+
count
]
;
}
+
+
count
;
}
}
const
max_llm_positions
=
(
0
_utils_maths_js__WEBPACK_IMPORTED_MODULE_11__
.
max
)
(
llm_positions
)
[
0
]
;
mrope_position_deltas
.
push
(
max_llm_positions
+
1
-
total_input_ids
[
i
]
.
length
)
;
}
return
[
new
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_9__
.
Tensor
(
'
int64
'
position_ids_list
.
flat
(
Infinity
)
[
3
input_ids
.
dims
[
0
]
input_ids
.
dims
[
1
]
]
)
new
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_9__
.
Tensor
(
'
int64
'
mrope_position_deltas
[
mrope_position_deltas
.
length
1
]
)
]
;
}
else
{
if
(
attention_mask
)
{
const
{
data
dims
}
=
cumsum_masked_fill
(
attention_mask
)
;
const
position_ids
=
BigInt64Array
.
from
(
{
length
:
3
*
data
.
length
}
(
_
i
)
=
>
data
[
i
%
data
.
length
]
)
;
const
mrope_position_deltas
=
Array
.
from
(
{
length
:
dims
[
0
]
}
(
_
i
)
=
>
(
0
_utils_maths_js__WEBPACK_IMPORTED_MODULE_11__
.
max
)
(
data
.
subarray
(
dims
[
1
]
*
i
dims
[
1
]
*
(
i
+
1
)
)
)
[
0
]
+
1
+
dims
[
1
]
)
;
return
[
new
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_9__
.
Tensor
(
'
int64
'
position_ids
[
3
.
.
.
dims
]
)
new
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_9__
.
Tensor
(
'
int64
'
mrope_position_deltas
[
mrope_position_deltas
.
length
1
]
)
]
}
else
{
const
[
batch_size
seq_length
]
=
input_ids
.
dims
;
const
position_ids
=
BigInt64Array
.
from
(
{
length
:
3
*
batch_size
*
seq_length
}
(
_
i
)
=
>
BigInt
(
Math
.
floor
(
i
%
seq_length
/
batch_size
)
)
)
;
return
[
new
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_9__
.
Tensor
(
'
int64
'
position_ids
[
3
.
.
.
input_ids
.
dims
]
)
(
0
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_9__
.
zeros
)
(
[
batch_size
1
]
)
]
}
}
}
async
encode_image
(
{
pixel_values
image_grid_thw
}
)
{
const
features
=
(
await
sessionRun
(
this
.
sessions
[
'
vision_encoder
'
]
{
pixel_values
grid_thw
:
image_grid_thw
}
)
)
.
image_features
;
return
features
;
}
_merge_input_ids_with_image_features
(
{
inputs_embeds
image_features
input_ids
attention_mask
}
)
{
const
{
image_token_id
}
=
this
.
config
;
const
image_tokens
=
input_ids
.
tolist
(
)
.
map
(
ids
=
>
ids
.
reduce
(
(
acc
x
idx
)
=
>
{
if
(
x
=
=
image_token_id
)
acc
.
push
(
idx
)
;
return
acc
;
}
[
]
)
)
;
const
n_image_tokens
=
image_tokens
.
reduce
(
(
acc
x
)
=
>
acc
+
x
.
length
0
)
;
const
n_image_features
=
image_features
.
dims
[
0
]
;
if
(
n_image_tokens
!
=
=
n_image_features
)
{
throw
new
Error
(
Image
features
and
image
tokens
do
not
match
:
tokens
:
{
n_image_tokens
}
features
{
n_image_features
}
)
;
}
let
img
=
0
;
for
(
let
i
=
0
;
i
<
image_tokens
.
length
;
+
+
i
)
{
const
tokens
=
image_tokens
[
i
]
;
const
embeds
=
inputs_embeds
[
i
]
;
for
(
let
j
=
0
;
j
<
tokens
.
length
;
+
+
j
)
{
embeds
[
tokens
[
j
]
]
.
data
.
set
(
image_features
[
img
+
+
]
.
data
)
}
}
return
{
inputs_embeds
attention_mask
}
}
prepare_inputs_for_generation
(
input_ids
model_inputs
generation_config
)
{
if
(
model_inputs
.
attention_mask
&
&
!
model_inputs
.
position_ids
)
{
if
(
!
model_inputs
.
past_key_values
)
{
(
[
model_inputs
.
position_ids
model_inputs
.
rope_deltas
]
=
this
.
get_rope_index
(
model_inputs
.
input_ids
model_inputs
.
image_grid_thw
model_inputs
.
video_grid_thw
model_inputs
.
attention_mask
)
)
;
}
else
{
model_inputs
.
pixel_values
=
null
;
const
delta
=
BigInt
(
Object
.
values
(
model_inputs
.
past_key_values
)
[
0
]
.
dims
.
at
(
-
2
)
)
;
const
rope_deltas_list
=
model_inputs
.
rope_deltas
.
map
(
x
=
>
delta
+
x
)
;
model_inputs
.
position_ids
=
(
0
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_9__
.
stack
)
(
[
rope_deltas_list
rope_deltas_list
rope_deltas_list
]
0
)
}
}
return
model_inputs
;
}
}
class
PhiPreTrainedModel
extends
PreTrainedModel
{
}
class
PhiModel
extends
PhiPreTrainedModel
{
}
class
PhiForCausalLM
extends
PhiPreTrainedModel
{
}
class
Phi3PreTrainedModel
extends
PreTrainedModel
{
}
class
Phi3Model
extends
Phi3PreTrainedModel
{
}
class
Phi3ForCausalLM
extends
Phi3PreTrainedModel
{
}
class
BloomPreTrainedModel
extends
PreTrainedModel
{
}
class
BloomModel
extends
BloomPreTrainedModel
{
}
class
BloomForCausalLM
extends
BloomPreTrainedModel
{
}
class
MptPreTrainedModel
extends
PreTrainedModel
{
}
class
MptModel
extends
MptPreTrainedModel
{
}
class
MptForCausalLM
extends
MptPreTrainedModel
{
}
class
OPTPreTrainedModel
extends
PreTrainedModel
{
}
class
OPTModel
extends
OPTPreTrainedModel
{
}
class
OPTForCausalLM
extends
OPTPreTrainedModel
{
}
class
ViTPreTrainedModel
extends
PreTrainedModel
{
}
class
ViTModel
extends
ViTPreTrainedModel
{
}
class
ViTForImageClassification
extends
ViTPreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
SequenceClassifierOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
VitPosePreTrainedModel
extends
PreTrainedModel
{
}
class
VitPoseForPoseEstimation
extends
VitPosePreTrainedModel
{
}
class
PvtPreTrainedModel
extends
PreTrainedModel
{
}
class
PvtModel
extends
PvtPreTrainedModel
{
}
class
PvtForImageClassification
extends
PvtPreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
SequenceClassifierOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
ViTMAEPreTrainedModel
extends
PreTrainedModel
{
}
class
ViTMAEModel
extends
ViTMAEPreTrainedModel
{
}
class
ViTMSNPreTrainedModel
extends
PreTrainedModel
{
}
class
ViTMSNModel
extends
ViTMSNPreTrainedModel
{
}
class
ViTMSNForImageClassification
extends
ViTMSNPreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
SequenceClassifierOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
GroupViTPreTrainedModel
extends
PreTrainedModel
{
}
class
GroupViTModel
extends
GroupViTPreTrainedModel
{
}
class
FastViTPreTrainedModel
extends
PreTrainedModel
{
}
class
FastViTModel
extends
FastViTPreTrainedModel
{
}
class
FastViTForImageClassification
extends
FastViTPreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
SequenceClassifierOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
VitMattePreTrainedModel
extends
PreTrainedModel
{
}
class
VitMatteForImageMatting
extends
VitMattePreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
ImageMattingOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
MobileViTPreTrainedModel
extends
PreTrainedModel
{
}
class
MobileViTModel
extends
MobileViTPreTrainedModel
{
}
class
MobileViTForImageClassification
extends
MobileViTPreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
SequenceClassifierOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
MobileViTV2PreTrainedModel
extends
PreTrainedModel
{
}
class
MobileViTV2Model
extends
MobileViTV2PreTrainedModel
{
}
class
MobileViTV2ForImageClassification
extends
MobileViTV2PreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
SequenceClassifierOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
OwlViTPreTrainedModel
extends
PreTrainedModel
{
}
class
OwlViTModel
extends
OwlViTPreTrainedModel
{
}
class
OwlViTForObjectDetection
extends
OwlViTPreTrainedModel
{
}
class
Owlv2PreTrainedModel
extends
PreTrainedModel
{
}
class
Owlv2Model
extends
Owlv2PreTrainedModel
{
}
class
Owlv2ForObjectDetection
extends
Owlv2PreTrainedModel
{
}
class
BeitPreTrainedModel
extends
PreTrainedModel
{
}
class
BeitModel
extends
BeitPreTrainedModel
{
}
class
BeitForImageClassification
extends
BeitPreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
SequenceClassifierOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
DetrPreTrainedModel
extends
PreTrainedModel
{
}
class
DetrModel
extends
DetrPreTrainedModel
{
}
class
DetrForObjectDetection
extends
DetrPreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
DetrObjectDetectionOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
DetrForSegmentation
extends
DetrPreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
DetrSegmentationOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
DetrObjectDetectionOutput
extends
ModelOutput
{
constructor
(
{
logits
pred_boxes
}
)
{
super
(
)
;
this
.
logits
=
logits
;
this
.
pred_boxes
=
pred_boxes
;
}
}
class
DetrSegmentationOutput
extends
ModelOutput
{
constructor
(
{
logits
pred_boxes
pred_masks
}
)
{
super
(
)
;
this
.
logits
=
logits
;
this
.
pred_boxes
=
pred_boxes
;
this
.
pred_masks
=
pred_masks
;
}
}
class
RTDetrPreTrainedModel
extends
PreTrainedModel
{
}
class
RTDetrModel
extends
RTDetrPreTrainedModel
{
}
class
RTDetrForObjectDetection
extends
RTDetrPreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
RTDetrObjectDetectionOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
RTDetrObjectDetectionOutput
extends
ModelOutput
{
constructor
(
{
logits
pred_boxes
}
)
{
super
(
)
;
this
.
logits
=
logits
;
this
.
pred_boxes
=
pred_boxes
;
}
}
class
TableTransformerPreTrainedModel
extends
PreTrainedModel
{
}
class
TableTransformerModel
extends
TableTransformerPreTrainedModel
{
}
class
TableTransformerForObjectDetection
extends
TableTransformerPreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
TableTransformerObjectDetectionOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
TableTransformerObjectDetectionOutput
extends
DetrObjectDetectionOutput
{
}
class
DeiTPreTrainedModel
extends
PreTrainedModel
{
}
class
DeiTModel
extends
DeiTPreTrainedModel
{
}
class
DeiTForImageClassification
extends
DeiTPreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
SequenceClassifierOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
HieraPreTrainedModel
extends
PreTrainedModel
{
}
class
HieraModel
extends
HieraPreTrainedModel
{
}
class
HieraForImageClassification
extends
HieraPreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
SequenceClassifierOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
ResNetPreTrainedModel
extends
PreTrainedModel
{
}
class
ResNetModel
extends
ResNetPreTrainedModel
{
}
class
ResNetForImageClassification
extends
ResNetPreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
SequenceClassifierOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
SwinPreTrainedModel
extends
PreTrainedModel
{
}
class
SwinModel
extends
SwinPreTrainedModel
{
}
class
SwinForImageClassification
extends
SwinPreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
SequenceClassifierOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
Swin2SRPreTrainedModel
extends
PreTrainedModel
{
}
class
Swin2SRModel
extends
Swin2SRPreTrainedModel
{
}
class
Swin2SRForImageSuperResolution
extends
Swin2SRPreTrainedModel
{
}
class
DPTPreTrainedModel
extends
PreTrainedModel
{
}
class
DPTModel
extends
DPTPreTrainedModel
{
}
class
DPTForDepthEstimation
extends
DPTPreTrainedModel
{
}
class
DepthAnythingPreTrainedModel
extends
PreTrainedModel
{
}
class
DepthAnythingForDepthEstimation
extends
DepthAnythingPreTrainedModel
{
}
class
SapiensPreTrainedModel
extends
PreTrainedModel
{
}
class
SapiensForSemanticSegmentation
extends
SapiensPreTrainedModel
{
}
class
SapiensForDepthEstimation
extends
SapiensPreTrainedModel
{
}
class
SapiensForNormalEstimation
extends
SapiensPreTrainedModel
{
}
class
DepthProPreTrainedModel
extends
PreTrainedModel
{
}
class
DepthProForDepthEstimation
extends
DepthProPreTrainedModel
{
}
class
MaskFormerPreTrainedModel
extends
PreTrainedModel
{
}
class
MaskFormerModel
extends
MaskFormerPreTrainedModel
{
}
class
MaskFormerForInstanceSegmentation
extends
MaskFormerPreTrainedModel
{
}
class
GLPNPreTrainedModel
extends
PreTrainedModel
{
}
class
GLPNModel
extends
GLPNPreTrainedModel
{
}
class
GLPNForDepthEstimation
extends
GLPNPreTrainedModel
{
}
class
DonutSwinPreTrainedModel
extends
PreTrainedModel
{
}
class
DonutSwinModel
extends
DonutSwinPreTrainedModel
{
}
class
ConvNextPreTrainedModel
extends
PreTrainedModel
{
}
class
ConvNextModel
extends
ConvNextPreTrainedModel
{
}
class
ConvNextForImageClassification
extends
ConvNextPreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
SequenceClassifierOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
ConvNextV2PreTrainedModel
extends
PreTrainedModel
{
}
class
ConvNextV2Model
extends
ConvNextV2PreTrainedModel
{
}
class
ConvNextV2ForImageClassification
extends
ConvNextV2PreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
SequenceClassifierOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
Dinov2PreTrainedModel
extends
PreTrainedModel
{
}
class
Dinov2Model
extends
Dinov2PreTrainedModel
{
}
class
Dinov2ForImageClassification
extends
Dinov2PreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
SequenceClassifierOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
YolosPreTrainedModel
extends
PreTrainedModel
{
}
class
YolosModel
extends
YolosPreTrainedModel
{
}
class
YolosForObjectDetection
extends
YolosPreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
YolosObjectDetectionOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
YolosObjectDetectionOutput
extends
ModelOutput
{
constructor
(
{
logits
pred_boxes
}
)
{
super
(
)
;
this
.
logits
=
logits
;
this
.
pred_boxes
=
pred_boxes
;
}
}
class
SamPreTrainedModel
extends
PreTrainedModel
{
}
class
SamModel
extends
SamPreTrainedModel
{
async
get_image_embeddings
(
{
pixel_values
}
)
{
return
await
encoderForward
(
this
{
pixel_values
}
)
}
async
forward
(
model_inputs
)
{
if
(
!
model_inputs
.
image_embeddings
|
|
!
model_inputs
.
image_positional_embeddings
)
{
model_inputs
=
{
.
.
.
model_inputs
.
.
.
(
await
this
.
get_image_embeddings
(
model_inputs
)
)
}
}
if
(
!
model_inputs
.
input_labels
&
&
model_inputs
.
input_points
)
{
const
shape
=
model_inputs
.
input_points
.
dims
.
slice
(
0
-
1
)
;
const
numElements
=
shape
.
reduce
(
(
a
b
)
=
>
a
*
b
1
)
;
model_inputs
.
input_labels
=
new
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_9__
.
Tensor
(
'
int64
'
new
BigInt64Array
(
numElements
)
.
fill
(
1n
)
shape
)
;
}
const
decoder_inputs
=
{
image_embeddings
:
model_inputs
.
image_embeddings
image_positional_embeddings
:
model_inputs
.
image_positional_embeddings
}
;
if
(
model_inputs
.
input_points
)
{
decoder_inputs
.
input_points
=
model_inputs
.
input_points
;
}
if
(
model_inputs
.
input_labels
)
{
decoder_inputs
.
input_labels
=
model_inputs
.
input_labels
;
}
if
(
model_inputs
.
input_boxes
)
{
decoder_inputs
.
input_boxes
=
model_inputs
.
input_boxes
;
}
return
await
sessionRun
(
this
.
sessions
[
'
prompt_encoder_mask_decoder
'
]
decoder_inputs
)
;
}
async
_call
(
model_inputs
)
{
return
new
SamImageSegmentationOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
SamImageSegmentationOutput
extends
ModelOutput
{
constructor
(
{
iou_scores
pred_masks
}
)
{
super
(
)
;
this
.
iou_scores
=
iou_scores
;
this
.
pred_masks
=
pred_masks
;
}
}
class
MarianPreTrainedModel
extends
PreTrainedModel
{
}
;
class
MarianModel
extends
MarianPreTrainedModel
{
}
class
MarianMTModel
extends
MarianPreTrainedModel
{
}
class
M2M100PreTrainedModel
extends
PreTrainedModel
{
}
;
class
M2M100Model
extends
M2M100PreTrainedModel
{
}
class
M2M100ForConditionalGeneration
extends
M2M100PreTrainedModel
{
}
class
Wav2Vec2PreTrainedModel
extends
PreTrainedModel
{
}
;
class
Wav2Vec2Model
extends
Wav2Vec2PreTrainedModel
{
}
class
Wav2Vec2ForCTC
extends
Wav2Vec2PreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
CausalLMOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
Wav2Vec2ForSequenceClassification
extends
Wav2Vec2PreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
SequenceClassifierOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
Wav2Vec2ForAudioFrameClassification
extends
Wav2Vec2PreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
TokenClassifierOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
PyAnnotePreTrainedModel
extends
PreTrainedModel
{
}
;
class
PyAnnoteModel
extends
PyAnnotePreTrainedModel
{
}
class
PyAnnoteForAudioFrameClassification
extends
PyAnnotePreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
TokenClassifierOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
WeSpeakerResNetPreTrainedModel
extends
PreTrainedModel
{
}
;
class
WeSpeakerResNetModel
extends
WeSpeakerResNetPreTrainedModel
{
}
class
UniSpeechPreTrainedModel
extends
PreTrainedModel
{
}
;
class
UniSpeechModel
extends
UniSpeechPreTrainedModel
{
}
class
UniSpeechForCTC
extends
UniSpeechPreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
CausalLMOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
UniSpeechForSequenceClassification
extends
UniSpeechPreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
SequenceClassifierOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
UniSpeechSatPreTrainedModel
extends
PreTrainedModel
{
}
;
class
UniSpeechSatModel
extends
UniSpeechSatPreTrainedModel
{
}
class
UniSpeechSatForCTC
extends
UniSpeechSatPreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
CausalLMOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
UniSpeechSatForSequenceClassification
extends
UniSpeechSatPreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
SequenceClassifierOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
UniSpeechSatForAudioFrameClassification
extends
UniSpeechSatPreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
TokenClassifierOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
Wav2Vec2BertPreTrainedModel
extends
PreTrainedModel
{
}
;
class
Wav2Vec2BertModel
extends
Wav2Vec2BertPreTrainedModel
{
}
class
Wav2Vec2BertForCTC
extends
Wav2Vec2BertPreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
CausalLMOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
Wav2Vec2BertForSequenceClassification
extends
Wav2Vec2BertPreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
SequenceClassifierOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
HubertPreTrainedModel
extends
PreTrainedModel
{
}
class
HubertModel
extends
Wav2Vec2PreTrainedModel
{
}
class
HubertForCTC
extends
Wav2Vec2PreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
CausalLMOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
HubertForSequenceClassification
extends
Wav2Vec2PreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
SequenceClassifierOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
WavLMPreTrainedModel
extends
PreTrainedModel
{
}
;
class
WavLMModel
extends
WavLMPreTrainedModel
{
}
class
WavLMForCTC
extends
WavLMPreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
CausalLMOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
WavLMForSequenceClassification
extends
WavLMPreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
SequenceClassifierOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
WavLMForXVector
extends
WavLMPreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
XVectorOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
WavLMForAudioFrameClassification
extends
WavLMPreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
TokenClassifierOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
SpeechT5PreTrainedModel
extends
PreTrainedModel
{
}
;
class
SpeechT5Model
extends
SpeechT5PreTrainedModel
{
}
;
class
SpeechT5ForSpeechToText
extends
SpeechT5PreTrainedModel
{
}
class
SpeechT5ForTextToSpeech
extends
SpeechT5PreTrainedModel
{
async
generate_speech
(
input_values
speaker_embeddings
{
threshold
=
0
.
5
minlenratio
=
0
.
0
maxlenratio
=
20
.
0
vocoder
=
null
}
=
{
}
)
{
const
model_inputs
=
{
input_ids
:
input_values
}
const
{
encoder_outputs
encoder_attention_mask
}
=
await
encoderForward
(
this
model_inputs
)
;
const
r
=
encoder_outputs
.
dims
[
1
]
/
this
.
config
.
reduction_factor
;
const
maxlen
=
Math
.
floor
(
r
*
maxlenratio
)
;
const
minlen
=
Math
.
floor
(
r
*
minlenratio
)
;
const
num_mel_bins
=
this
.
config
.
num_mel_bins
;
let
spectrogramParts
=
[
]
;
let
past_key_values
=
null
;
let
decoder_outputs
=
null
;
let
idx
=
0
;
while
(
true
)
{
+
+
idx
;
const
use_cache_branch
=
boolTensor
(
!
!
decoder_outputs
)
;
let
output_sequence
;
if
(
decoder_outputs
)
{
output_sequence
=
decoder_outputs
.
output_sequence_out
;
}
else
{
output_sequence
=
new
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_9__
.
Tensor
(
'
float32
'
new
Float32Array
(
num_mel_bins
)
[
1
1
num_mel_bins
]
)
}
let
decoderFeeds
=
{
use_cache_branch
output_sequence
encoder_attention_mask
:
encoder_attention_mask
speaker_embeddings
:
speaker_embeddings
encoder_hidden_states
:
encoder_outputs
}
;
this
.
addPastKeyValues
(
decoderFeeds
past_key_values
)
;
decoder_outputs
=
await
sessionRun
(
this
.
sessions
[
'
decoder_model_merged
'
]
decoderFeeds
)
;
past_key_values
=
this
.
getPastKeyValues
(
decoder_outputs
past_key_values
)
;
const
{
prob
spectrum
}
=
decoder_outputs
;
spectrogramParts
.
push
(
spectrum
)
;
if
(
idx
>
=
minlen
&
&
(
Array
.
from
(
prob
.
data
)
.
filter
(
p
=
>
p
>
=
threshold
)
.
length
>
0
|
|
idx
>
=
maxlen
)
)
{
break
;
}
}
const
spectrogram
=
(
0
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_9__
.
cat
)
(
spectrogramParts
)
;
const
{
waveform
}
=
await
sessionRun
(
vocoder
.
sessions
[
'
model
'
]
{
spectrogram
}
)
;
return
{
spectrogram
waveform
}
}
}
class
SpeechT5HifiGan
extends
PreTrainedModel
{
main_input_name
=
'
spectrogram
'
;
}
class
TrOCRPreTrainedModel
extends
PreTrainedModel
{
}
class
TrOCRForCausalLM
extends
TrOCRPreTrainedModel
{
}
class
MistralPreTrainedModel
extends
PreTrainedModel
{
}
class
MistralModel
extends
MistralPreTrainedModel
{
}
class
MistralForCausalLM
extends
MistralPreTrainedModel
{
}
class
Starcoder2PreTrainedModel
extends
PreTrainedModel
{
}
class
Starcoder2Model
extends
Starcoder2PreTrainedModel
{
}
class
Starcoder2ForCausalLM
extends
Starcoder2PreTrainedModel
{
}
class
FalconPreTrainedModel
extends
PreTrainedModel
{
}
class
FalconModel
extends
FalconPreTrainedModel
{
}
class
FalconForCausalLM
extends
FalconPreTrainedModel
{
}
class
ClapPreTrainedModel
extends
PreTrainedModel
{
}
class
ClapModel
extends
ClapPreTrainedModel
{
}
class
ClapTextModelWithProjection
extends
ClapPreTrainedModel
{
static
async
from_pretrained
(
pretrained_model_name_or_path
options
=
{
}
)
{
options
.
model_file_name
?
?
=
'
text_model
'
;
return
super
.
from_pretrained
(
pretrained_model_name_or_path
options
)
;
}
}
class
ClapAudioModelWithProjection
extends
ClapPreTrainedModel
{
static
async
from_pretrained
(
pretrained_model_name_or_path
options
=
{
}
)
{
options
.
model_file_name
?
?
=
'
audio_model
'
;
return
super
.
from_pretrained
(
pretrained_model_name_or_path
options
)
;
}
}
class
VitsPreTrainedModel
extends
PreTrainedModel
{
}
class
VitsModel
extends
VitsPreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
VitsModelOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
SegformerPreTrainedModel
extends
PreTrainedModel
{
}
class
SegformerModel
extends
SegformerPreTrainedModel
{
}
class
SegformerForImageClassification
extends
SegformerPreTrainedModel
{
}
class
SegformerForSemanticSegmentation
extends
SegformerPreTrainedModel
{
}
class
StableLmPreTrainedModel
extends
PreTrainedModel
{
}
class
StableLmModel
extends
StableLmPreTrainedModel
{
}
class
StableLmForCausalLM
extends
StableLmPreTrainedModel
{
}
class
EfficientNetPreTrainedModel
extends
PreTrainedModel
{
}
class
EfficientNetModel
extends
EfficientNetPreTrainedModel
{
}
class
EfficientNetForImageClassification
extends
EfficientNetPreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
SequenceClassifierOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
MusicgenPreTrainedModel
extends
PreTrainedModel
{
}
class
MusicgenModel
extends
MusicgenPreTrainedModel
{
}
class
MusicgenForCausalLM
extends
MusicgenPreTrainedModel
{
}
class
MusicgenForConditionalGeneration
extends
PreTrainedModel
{
forward_params
=
[
'
input_ids
'
'
attention_mask
'
'
encoder_outputs
'
'
decoder_input_ids
'
'
decoder_attention_mask
'
'
past_key_values
'
]
;
_apply_and_filter_by_delay_pattern_mask
(
outputs
)
{
const
[
bs_x_codebooks
seqLength
]
=
outputs
.
dims
;
const
num_codebooks
=
this
.
config
.
decoder
.
num_codebooks
;
const
upperBound
=
(
seqLength
-
num_codebooks
)
;
let
newDataSize
=
0
;
for
(
let
i
=
0
;
i
<
outputs
.
size
;
+
+
i
)
{
if
(
outputs
.
data
[
i
]
=
=
=
this
.
config
.
decoder
.
pad_token_id
)
{
continue
;
}
const
row
=
(
i
%
seqLength
)
;
const
col
=
Math
.
floor
(
i
/
seqLength
)
%
num_codebooks
;
const
diff
=
row
-
col
;
if
(
diff
>
0
&
&
diff
<
=
upperBound
)
{
outputs
.
data
[
newDataSize
+
+
]
=
outputs
.
data
[
i
]
;
}
}
const
batch_size
=
Math
.
floor
(
bs_x_codebooks
/
num_codebooks
)
;
const
inferred
=
newDataSize
/
(
batch_size
*
num_codebooks
)
;
return
new
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_9__
.
Tensor
(
outputs
.
type
outputs
.
data
.
slice
(
0
newDataSize
)
[
batch_size
num_codebooks
inferred
]
)
;
}
prepare_inputs_for_generation
(
input_ids
model_inputs
generation_config
)
{
let
clonedInputIds
=
structuredClone
(
input_ids
)
;
for
(
let
i
=
0
;
i
<
clonedInputIds
.
length
;
+
+
i
)
{
for
(
let
j
=
0
;
j
<
clonedInputIds
[
i
]
.
length
;
+
+
j
)
{
if
(
(
i
%
this
.
config
.
decoder
.
num_codebooks
)
>
=
j
)
{
clonedInputIds
[
i
]
[
j
]
=
BigInt
(
this
.
config
.
decoder
.
pad_token_id
)
;
}
}
}
if
(
generation_config
.
guidance_scale
!
=
=
null
&
&
generation_config
.
guidance_scale
>
1
)
{
clonedInputIds
=
clonedInputIds
.
concat
(
clonedInputIds
)
;
}
const
prepped
=
super
.
prepare_inputs_for_generation
(
clonedInputIds
model_inputs
generation_config
)
;
return
prepped
;
}
async
generate
(
options
)
{
const
output_ids
=
await
super
.
generate
(
options
)
;
const
audio_codes
=
this
.
_apply_and_filter_by_delay_pattern_mask
(
(
output_ids
)
)
.
unsqueeze_
(
0
)
;
const
{
audio_values
}
=
await
sessionRun
(
this
.
sessions
[
'
encodec_decode
'
]
{
audio_codes
}
)
return
audio_values
;
}
}
class
MobileNetV1PreTrainedModel
extends
PreTrainedModel
{
}
class
MobileNetV1Model
extends
MobileNetV1PreTrainedModel
{
}
class
MobileNetV1ForImageClassification
extends
MobileNetV1PreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
SequenceClassifierOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
MobileNetV2PreTrainedModel
extends
PreTrainedModel
{
}
class
MobileNetV2Model
extends
MobileNetV2PreTrainedModel
{
}
class
MobileNetV2ForImageClassification
extends
MobileNetV2PreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
SequenceClassifierOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
MobileNetV3PreTrainedModel
extends
PreTrainedModel
{
}
class
MobileNetV3Model
extends
MobileNetV3PreTrainedModel
{
}
class
MobileNetV3ForImageClassification
extends
MobileNetV3PreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
SequenceClassifierOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
MobileNetV4PreTrainedModel
extends
PreTrainedModel
{
}
class
MobileNetV4Model
extends
MobileNetV4PreTrainedModel
{
}
class
MobileNetV4ForImageClassification
extends
MobileNetV4PreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
SequenceClassifierOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
DecisionTransformerPreTrainedModel
extends
PreTrainedModel
{
}
class
DecisionTransformerModel
extends
DecisionTransformerPreTrainedModel
{
}
class
MultiModalityPreTrainedModel
extends
PreTrainedModel
{
}
class
MultiModalityCausalLM
extends
MultiModalityPreTrainedModel
{
forward_params
=
[
'
input_ids
'
'
pixel_values
'
'
images_seq_mask
'
'
images_emb_mask
'
'
attention_mask
'
'
position_ids
'
'
past_key_values
'
]
;
constructor
(
.
.
.
args
)
{
super
(
.
.
.
args
)
;
this
.
_generation_mode
=
'
text
'
;
}
async
forward
(
model_inputs
)
{
const
mode
=
this
.
_generation_mode
?
?
'
text
'
;
let
output_1
;
if
(
mode
=
=
=
'
text
'
|
|
!
model_inputs
.
past_key_values
)
{
const
session
=
this
.
sessions
[
'
prepare_inputs_embeds
'
]
;
const
prep_inputs
=
(
0
_utils_core_js__WEBPACK_IMPORTED_MODULE_4__
.
pick
)
(
model_inputs
session
.
inputNames
)
;
output_1
=
await
sessionRun
(
session
prep_inputs
)
;
}
else
{
const
session
=
this
.
sessions
[
'
gen_img_embeds
'
]
;
const
prep_inputs
=
(
0
_utils_core_js__WEBPACK_IMPORTED_MODULE_4__
.
pick
)
(
{
image_ids
:
model_inputs
.
input_ids
}
session
.
inputNames
)
;
output_1
=
await
sessionRun
(
session
prep_inputs
)
;
}
const
input_2
=
{
.
.
.
model_inputs
.
.
.
output_1
}
const
output_2
=
await
decoderForward
(
this
input_2
)
;
const
head
=
this
.
sessions
[
mode
=
=
=
'
text
'
?
'
lm_head
'
:
'
gen_head
'
]
;
if
(
!
head
)
{
throw
new
Error
(
Unable
to
find
"
{
head
}
"
generation
head
)
;
}
const
output_3
=
await
sessionRun
(
head
(
0
_utils_core_js__WEBPACK_IMPORTED_MODULE_4__
.
pick
)
(
output_2
head
.
inputNames
)
)
return
{
.
.
.
output_1
.
.
.
output_2
.
.
.
output_3
}
;
}
async
generate
(
options
)
{
this
.
_generation_mode
=
'
text
'
;
return
super
.
generate
(
options
)
;
}
async
generate_images
(
options
)
{
this
.
_generation_mode
=
'
image
'
;
const
start_num_tokens
=
(
options
.
inputs
?
?
options
[
this
.
main_input_name
]
)
.
dims
[
1
]
;
const
all_tokens
=
await
super
.
generate
(
options
)
;
const
generated_tokens
=
(
(
all_tokens
)
)
.
slice
(
null
[
start_num_tokens
null
]
)
const
image_decode
=
this
.
sessions
[
'
image_decode
'
]
;
const
{
decoded_image
}
=
await
sessionRun
(
image_decode
{
generated_tokens
}
)
;
const
clamped
=
decoded_image
.
add_
(
1
)
.
mul_
(
255
/
2
)
.
clamp_
(
0
255
)
.
to
(
'
uint8
'
)
;
const
images
=
[
]
;
for
(
const
tensor
of
clamped
)
{
const
img
=
_utils_image_js__WEBPACK_IMPORTED_MODULE_10__
.
RawImage
.
fromTensor
(
tensor
)
;
images
.
push
(
img
)
;
}
return
images
;
}
}
class
MgpstrModelOutput
extends
ModelOutput
{
constructor
(
{
char_logits
bpe_logits
wp_logits
}
)
{
super
(
)
;
this
.
char_logits
=
char_logits
;
this
.
bpe_logits
=
bpe_logits
;
this
.
wp_logits
=
wp_logits
;
}
get
logits
(
)
{
return
[
this
.
char_logits
this
.
bpe_logits
this
.
wp_logits
]
;
}
}
class
MgpstrPreTrainedModel
extends
PreTrainedModel
{
}
class
MgpstrForSceneTextRecognition
extends
MgpstrPreTrainedModel
{
async
_call
(
model_inputs
)
{
return
new
MgpstrModelOutput
(
await
super
.
_call
(
model_inputs
)
)
;
}
}
class
PatchTSTPreTrainedModel
extends
PreTrainedModel
{
}
class
PatchTSTModel
extends
PatchTSTPreTrainedModel
{
}
class
PatchTSTForPrediction
extends
PatchTSTPreTrainedModel
{
}
class
PatchTSMixerPreTrainedModel
extends
PreTrainedModel
{
}
class
PatchTSMixerModel
extends
PatchTSMixerPreTrainedModel
{
}
class
PatchTSMixerForPrediction
extends
PatchTSMixerPreTrainedModel
{
}
class
PretrainedMixin
{
static
MODEL_CLASS_MAPPINGS
=
null
;
static
BASE_IF_FAIL
=
false
;
static
async
from_pretrained
(
pretrained_model_name_or_path
{
progress_callback
=
null
config
=
null
cache_dir
=
null
local_files_only
=
false
revision
=
'
main
'
model_file_name
=
null
subfolder
=
'
onnx
'
device
=
null
dtype
=
null
use_external_data_format
=
null
session_options
=
{
}
}
=
{
}
)
{
const
options
=
{
progress_callback
config
cache_dir
local_files_only
revision
model_file_name
subfolder
device
dtype
use_external_data_format
session_options
}
options
.
config
=
await
_configs_js__WEBPACK_IMPORTED_MODULE_0__
.
AutoConfig
.
from_pretrained
(
pretrained_model_name_or_path
options
)
;
if
(
!
this
.
MODEL_CLASS_MAPPINGS
)
{
throw
new
Error
(
"
MODEL_CLASS_MAPPINGS
not
implemented
for
this
type
of
AutoClass
:
"
+
this
.
name
)
;
}
for
(
const
MODEL_CLASS_MAPPING
of
this
.
MODEL_CLASS_MAPPINGS
)
{
const
modelInfo
=
MODEL_CLASS_MAPPING
.
get
(
options
.
config
.
model_type
)
;
if
(
!
modelInfo
)
{
continue
;
}
return
await
modelInfo
[
1
]
.
from_pretrained
(
pretrained_model_name_or_path
options
)
;
}
if
(
this
.
BASE_IF_FAIL
)
{
console
.
warn
(
Unknown
model
class
"
{
options
.
config
.
model_type
}
"
attempting
to
construct
from
base
class
.
)
;
return
await
PreTrainedModel
.
from_pretrained
(
pretrained_model_name_or_path
options
)
;
}
else
{
throw
Error
(
Unsupported
model
type
:
{
options
.
config
.
model_type
}
)
}
}
}
const
MODEL_MAPPING_NAMES_ENCODER_ONLY
=
new
Map
(
[
[
'
bert
'
[
'
BertModel
'
BertModel
]
]
[
'
nomic_bert
'
[
'
NomicBertModel
'
NomicBertModel
]
]
[
'
roformer
'
[
'
RoFormerModel
'
RoFormerModel
]
]
[
'
electra
'
[
'
ElectraModel
'
ElectraModel
]
]
[
'
esm
'
[
'
EsmModel
'
EsmModel
]
]
[
'
convbert
'
[
'
ConvBertModel
'
ConvBertModel
]
]
[
'
camembert
'
[
'
CamembertModel
'
CamembertModel
]
]
[
'
deberta
'
[
'
DebertaModel
'
DebertaModel
]
]
[
'
deberta
-
v2
'
[
'
DebertaV2Model
'
DebertaV2Model
]
]
[
'
mpnet
'
[
'
MPNetModel
'
MPNetModel
]
]
[
'
albert
'
[
'
AlbertModel
'
AlbertModel
]
]
[
'
distilbert
'
[
'
DistilBertModel
'
DistilBertModel
]
]
[
'
roberta
'
[
'
RobertaModel
'
RobertaModel
]
]
[
'
xlm
'
[
'
XLMModel
'
XLMModel
]
]
[
'
xlm
-
roberta
'
[
'
XLMRobertaModel
'
XLMRobertaModel
]
]
[
'
clap
'
[
'
ClapModel
'
ClapModel
]
]
[
'
clip
'
[
'
CLIPModel
'
CLIPModel
]
]
[
'
clipseg
'
[
'
CLIPSegModel
'
CLIPSegModel
]
]
[
'
chinese_clip
'
[
'
ChineseCLIPModel
'
ChineseCLIPModel
]
]
[
'
siglip
'
[
'
SiglipModel
'
SiglipModel
]
]
[
'
jina_clip
'
[
'
JinaCLIPModel
'
JinaCLIPModel
]
]
[
'
mobilebert
'
[
'
MobileBertModel
'
MobileBertModel
]
]
[
'
squeezebert
'
[
'
SqueezeBertModel
'
SqueezeBertModel
]
]
[
'
wav2vec2
'
[
'
Wav2Vec2Model
'
Wav2Vec2Model
]
]
[
'
wav2vec2
-
bert
'
[
'
Wav2Vec2BertModel
'
Wav2Vec2BertModel
]
]
[
'
unispeech
'
[
'
UniSpeechModel
'
UniSpeechModel
]
]
[
'
unispeech
-
sat
'
[
'
UniSpeechSatModel
'
UniSpeechSatModel
]
]
[
'
hubert
'
[
'
HubertModel
'
HubertModel
]
]
[
'
wavlm
'
[
'
WavLMModel
'
WavLMModel
]
]
[
'
audio
-
spectrogram
-
transformer
'
[
'
ASTModel
'
ASTModel
]
]
[
'
vits
'
[
'
VitsModel
'
VitsModel
]
]
[
'
pyannote
'
[
'
PyAnnoteModel
'
PyAnnoteModel
]
]
[
'
wespeaker
-
resnet
'
[
'
WeSpeakerResNetModel
'
WeSpeakerResNetModel
]
]
[
'
detr
'
[
'
DetrModel
'
DetrModel
]
]
[
'
rt_detr
'
[
'
RTDetrModel
'
RTDetrModel
]
]
[
'
table
-
transformer
'
[
'
TableTransformerModel
'
TableTransformerModel
]
]
[
'
vit
'
[
'
ViTModel
'
ViTModel
]
]
[
'
pvt
'
[
'
PvtModel
'
PvtModel
]
]
[
'
vit_msn
'
[
'
ViTMSNModel
'
ViTMSNModel
]
]
[
'
vit_mae
'
[
'
ViTMAEModel
'
ViTMAEModel
]
]
[
'
groupvit
'
[
'
GroupViTModel
'
GroupViTModel
]
]
[
'
fastvit
'
[
'
FastViTModel
'
FastViTModel
]
]
[
'
mobilevit
'
[
'
MobileViTModel
'
MobileViTModel
]
]
[
'
mobilevitv2
'
[
'
MobileViTV2Model
'
MobileViTV2Model
]
]
[
'
owlvit
'
[
'
OwlViTModel
'
OwlViTModel
]
]
[
'
owlv2
'
[
'
Owlv2Model
'
Owlv2Model
]
]
[
'
beit
'
[
'
BeitModel
'
BeitModel
]
]
[
'
deit
'
[
'
DeiTModel
'
DeiTModel
]
]
[
'
hiera
'
[
'
HieraModel
'
HieraModel
]
]
[
'
convnext
'
[
'
ConvNextModel
'
ConvNextModel
]
]
[
'
convnextv2
'
[
'
ConvNextV2Model
'
ConvNextV2Model
]
]
[
'
dinov2
'
[
'
Dinov2Model
'
Dinov2Model
]
]
[
'
resnet
'
[
'
ResNetModel
'
ResNetModel
]
]
[
'
swin
'
[
'
SwinModel
'
SwinModel
]
]
[
'
swin2sr
'
[
'
Swin2SRModel
'
Swin2SRModel
]
]
[
'
donut
-
swin
'
[
'
DonutSwinModel
'
DonutSwinModel
]
]
[
'
yolos
'
[
'
YolosModel
'
YolosModel
]
]
[
'
dpt
'
[
'
DPTModel
'
DPTModel
]
]
[
'
glpn
'
[
'
GLPNModel
'
GLPNModel
]
]
[
'
hifigan
'
[
'
SpeechT5HifiGan
'
SpeechT5HifiGan
]
]
[
'
efficientnet
'
[
'
EfficientNetModel
'
EfficientNetModel
]
]
[
'
decision_transformer
'
[
'
DecisionTransformerModel
'
DecisionTransformerModel
]
]
[
'
patchtst
'
[
'
PatchTSTForPrediction
'
PatchTSTModel
]
]
[
'
patchtsmixer
'
[
'
PatchTSMixerForPrediction
'
PatchTSMixerModel
]
]
[
'
mobilenet_v1
'
[
'
MobileNetV1Model
'
MobileNetV1Model
]
]
[
'
mobilenet_v2
'
[
'
MobileNetV2Model
'
MobileNetV2Model
]
]
[
'
mobilenet_v3
'
[
'
MobileNetV3Model
'
MobileNetV3Model
]
]
[
'
mobilenet_v4
'
[
'
MobileNetV4Model
'
MobileNetV4Model
]
]
[
'
maskformer
'
[
'
MaskFormerModel
'
MaskFormerModel
]
]
[
'
mgp
-
str
'
[
'
MgpstrForSceneTextRecognition
'
MgpstrForSceneTextRecognition
]
]
]
)
;
const
MODEL_MAPPING_NAMES_ENCODER_DECODER
=
new
Map
(
[
[
'
t5
'
[
'
T5Model
'
T5Model
]
]
[
'
longt5
'
[
'
LongT5Model
'
LongT5Model
]
]
[
'
mt5
'
[
'
MT5Model
'
MT5Model
]
]
[
'
bart
'
[
'
BartModel
'
BartModel
]
]
[
'
mbart
'
[
'
MBartModel
'
MBartModel
]
]
[
'
marian
'
[
'
MarianModel
'
MarianModel
]
]
[
'
whisper
'
[
'
WhisperModel
'
WhisperModel
]
]
[
'
m2m_100
'
[
'
M2M100Model
'
M2M100Model
]
]
[
'
blenderbot
'
[
'
BlenderbotModel
'
BlenderbotModel
]
]
[
'
blenderbot
-
small
'
[
'
BlenderbotSmallModel
'
BlenderbotSmallModel
]
]
]
)
;
const
MODEL_MAPPING_NAMES_DECODER_ONLY
=
new
Map
(
[
[
'
bloom
'
[
'
BloomModel
'
BloomModel
]
]
[
'
jais
'
[
'
JAISModel
'
JAISModel
]
]
[
'
gpt2
'
[
'
GPT2Model
'
GPT2Model
]
]
[
'
gptj
'
[
'
GPTJModel
'
GPTJModel
]
]
[
'
gpt_bigcode
'
[
'
GPTBigCodeModel
'
GPTBigCodeModel
]
]
[
'
gpt_neo
'
[
'
GPTNeoModel
'
GPTNeoModel
]
]
[
'
gpt_neox
'
[
'
GPTNeoXModel
'
GPTNeoXModel
]
]
[
'
codegen
'
[
'
CodeGenModel
'
CodeGenModel
]
]
[
'
llama
'
[
'
LlamaModel
'
LlamaModel
]
]
[
'
olmo
'
[
'
OlmoModel
'
OlmoModel
]
]
[
'
mobilellm
'
[
'
MobileLLMModel
'
MobileLLMModel
]
]
[
'
granite
'
[
'
GraniteModel
'
GraniteModel
]
]
[
'
cohere
'
[
'
CohereModel
'
CohereModel
]
]
[
'
gemma
'
[
'
GemmaModel
'
GemmaModel
]
]
[
'
gemma2
'
[
'
Gemma2Model
'
Gemma2Model
]
]
[
'
openelm
'
[
'
OpenELMModel
'
OpenELMModel
]
]
[
'
qwen2
'
[
'
Qwen2Model
'
Qwen2Model
]
]
[
'
phi
'
[
'
PhiModel
'
PhiModel
]
]
[
'
phi3
'
[
'
Phi3Model
'
Phi3Model
]
]
[
'
mpt
'
[
'
MptModel
'
MptModel
]
]
[
'
opt
'
[
'
OPTModel
'
OPTModel
]
]
[
'
mistral
'
[
'
MistralModel
'
MistralModel
]
]
[
'
starcoder2
'
[
'
Starcoder2Model
'
Starcoder2Model
]
]
[
'
falcon
'
[
'
FalconModel
'
FalconModel
]
]
[
'
stablelm
'
[
'
StableLmModel
'
StableLmModel
]
]
]
)
;
const
MODEL_FOR_SPEECH_SEQ_2_SEQ_MAPPING_NAMES
=
new
Map
(
[
[
'
speecht5
'
[
'
SpeechT5ForSpeechToText
'
SpeechT5ForSpeechToText
]
]
[
'
whisper
'
[
'
WhisperForConditionalGeneration
'
WhisperForConditionalGeneration
]
]
]
)
;
const
MODEL_FOR_TEXT_TO_SPECTROGRAM_MAPPING_NAMES
=
new
Map
(
[
[
'
speecht5
'
[
'
SpeechT5ForTextToSpeech
'
SpeechT5ForTextToSpeech
]
]
]
)
;
const
MODEL_FOR_TEXT_TO_WAVEFORM_MAPPING_NAMES
=
new
Map
(
[
[
'
vits
'
[
'
VitsModel
'
VitsModel
]
]
[
'
musicgen
'
[
'
MusicgenForConditionalGeneration
'
MusicgenForConditionalGeneration
]
]
]
)
;
const
MODEL_FOR_SEQUENCE_CLASSIFICATION_MAPPING_NAMES
=
new
Map
(
[
[
'
bert
'
[
'
BertForSequenceClassification
'
BertForSequenceClassification
]
]
[
'
roformer
'
[
'
RoFormerForSequenceClassification
'
RoFormerForSequenceClassification
]
]
[
'
electra
'
[
'
ElectraForSequenceClassification
'
ElectraForSequenceClassification
]
]
[
'
esm
'
[
'
EsmForSequenceClassification
'
EsmForSequenceClassification
]
]
[
'
convbert
'
[
'
ConvBertForSequenceClassification
'
ConvBertForSequenceClassification
]
]
[
'
camembert
'
[
'
CamembertForSequenceClassification
'
CamembertForSequenceClassification
]
]
[
'
deberta
'
[
'
DebertaForSequenceClassification
'
DebertaForSequenceClassification
]
]
[
'
deberta
-
v2
'
[
'
DebertaV2ForSequenceClassification
'
DebertaV2ForSequenceClassification
]
]
[
'
mpnet
'
[
'
MPNetForSequenceClassification
'
MPNetForSequenceClassification
]
]
[
'
albert
'
[
'
AlbertForSequenceClassification
'
AlbertForSequenceClassification
]
]
[
'
distilbert
'
[
'
DistilBertForSequenceClassification
'
DistilBertForSequenceClassification
]
]
[
'
roberta
'
[
'
RobertaForSequenceClassification
'
RobertaForSequenceClassification
]
]
[
'
xlm
'
[
'
XLMForSequenceClassification
'
XLMForSequenceClassification
]
]
[
'
xlm
-
roberta
'
[
'
XLMRobertaForSequenceClassification
'
XLMRobertaForSequenceClassification
]
]
[
'
bart
'
[
'
BartForSequenceClassification
'
BartForSequenceClassification
]
]
[
'
mbart
'
[
'
MBartForSequenceClassification
'
MBartForSequenceClassification
]
]
[
'
mobilebert
'
[
'
MobileBertForSequenceClassification
'
MobileBertForSequenceClassification
]
]
[
'
squeezebert
'
[
'
SqueezeBertForSequenceClassification
'
SqueezeBertForSequenceClassification
]
]
]
)
;
const
MODEL_FOR_TOKEN_CLASSIFICATION_MAPPING_NAMES
=
new
Map
(
[
[
'
bert
'
[
'
BertForTokenClassification
'
BertForTokenClassification
]
]
[
'
roformer
'
[
'
RoFormerForTokenClassification
'
RoFormerForTokenClassification
]
]
[
'
electra
'
[
'
ElectraForTokenClassification
'
ElectraForTokenClassification
]
]
[
'
esm
'
[
'
EsmForTokenClassification
'
EsmForTokenClassification
]
]
[
'
convbert
'
[
'
ConvBertForTokenClassification
'
ConvBertForTokenClassification
]
]
[
'
camembert
'
[
'
CamembertForTokenClassification
'
CamembertForTokenClassification
]
]
[
'
deberta
'
[
'
DebertaForTokenClassification
'
DebertaForTokenClassification
]
]
[
'
deberta
-
v2
'
[
'
DebertaV2ForTokenClassification
'
DebertaV2ForTokenClassification
]
]
[
'
mpnet
'
[
'
MPNetForTokenClassification
'
MPNetForTokenClassification
]
]
[
'
distilbert
'
[
'
DistilBertForTokenClassification
'
DistilBertForTokenClassification
]
]
[
'
roberta
'
[
'
RobertaForTokenClassification
'
RobertaForTokenClassification
]
]
[
'
xlm
'
[
'
XLMForTokenClassification
'
XLMForTokenClassification
]
]
[
'
xlm
-
roberta
'
[
'
XLMRobertaForTokenClassification
'
XLMRobertaForTokenClassification
]
]
]
)
;
const
MODEL_FOR_SEQ_TO_SEQ_CAUSAL_LM_MAPPING_NAMES
=
new
Map
(
[
[
'
t5
'
[
'
T5ForConditionalGeneration
'
T5ForConditionalGeneration
]
]
[
'
longt5
'
[
'
LongT5ForConditionalGeneration
'
LongT5ForConditionalGeneration
]
]
[
'
mt5
'
[
'
MT5ForConditionalGeneration
'
MT5ForConditionalGeneration
]
]
[
'
bart
'
[
'
BartForConditionalGeneration
'
BartForConditionalGeneration
]
]
[
'
mbart
'
[
'
MBartForConditionalGeneration
'
MBartForConditionalGeneration
]
]
[
'
marian
'
[
'
MarianMTModel
'
MarianMTModel
]
]
[
'
m2m_100
'
[
'
M2M100ForConditionalGeneration
'
M2M100ForConditionalGeneration
]
]
[
'
blenderbot
'
[
'
BlenderbotForConditionalGeneration
'
BlenderbotForConditionalGeneration
]
]
[
'
blenderbot
-
small
'
[
'
BlenderbotSmallForConditionalGeneration
'
BlenderbotSmallForConditionalGeneration
]
]
]
)
;
const
MODEL_FOR_CAUSAL_LM_MAPPING_NAMES
=
new
Map
(
[
[
'
bloom
'
[
'
BloomForCausalLM
'
BloomForCausalLM
]
]
[
'
gpt2
'
[
'
GPT2LMHeadModel
'
GPT2LMHeadModel
]
]
[
'
jais
'
[
'
JAISLMHeadModel
'
JAISLMHeadModel
]
]
[
'
gptj
'
[
'
GPTJForCausalLM
'
GPTJForCausalLM
]
]
[
'
gpt_bigcode
'
[
'
GPTBigCodeForCausalLM
'
GPTBigCodeForCausalLM
]
]
[
'
gpt_neo
'
[
'
GPTNeoForCausalLM
'
GPTNeoForCausalLM
]
]
[
'
gpt_neox
'
[
'
GPTNeoXForCausalLM
'
GPTNeoXForCausalLM
]
]
[
'
codegen
'
[
'
CodeGenForCausalLM
'
CodeGenForCausalLM
]
]
[
'
llama
'
[
'
LlamaForCausalLM
'
LlamaForCausalLM
]
]
[
'
olmo
'
[
'
OlmoForCausalLM
'
OlmoForCausalLM
]
]
[
'
mobilellm
'
[
'
MobileLLMForCausalLM
'
MobileLLMForCausalLM
]
]
[
'
granite
'
[
'
GraniteForCausalLM
'
GraniteForCausalLM
]
]
[
'
cohere
'
[
'
CohereForCausalLM
'
CohereForCausalLM
]
]
[
'
gemma
'
[
'
GemmaForCausalLM
'
GemmaForCausalLM
]
]
[
'
gemma2
'
[
'
Gemma2ForCausalLM
'
Gemma2ForCausalLM
]
]
[
'
openelm
'
[
'
OpenELMForCausalLM
'
OpenELMForCausalLM
]
]
[
'
qwen2
'
[
'
Qwen2ForCausalLM
'
Qwen2ForCausalLM
]
]
[
'
phi
'
[
'
PhiForCausalLM
'
PhiForCausalLM
]
]
[
'
phi3
'
[
'
Phi3ForCausalLM
'
Phi3ForCausalLM
]
]
[
'
mpt
'
[
'
MptForCausalLM
'
MptForCausalLM
]
]
[
'
opt
'
[
'
OPTForCausalLM
'
OPTForCausalLM
]
]
[
'
mbart
'
[
'
MBartForCausalLM
'
MBartForCausalLM
]
]
[
'
mistral
'
[
'
MistralForCausalLM
'
MistralForCausalLM
]
]
[
'
starcoder2
'
[
'
Starcoder2ForCausalLM
'
Starcoder2ForCausalLM
]
]
[
'
falcon
'
[
'
FalconForCausalLM
'
FalconForCausalLM
]
]
[
'
trocr
'
[
'
TrOCRForCausalLM
'
TrOCRForCausalLM
]
]
[
'
stablelm
'
[
'
StableLmForCausalLM
'
StableLmForCausalLM
]
]
]
)
;
const
MODEL_FOR_MULTIMODALITY_MAPPING_NAMES
=
new
Map
(
[
[
'
multi_modality
'
[
'
MultiModalityCausalLM
'
MultiModalityCausalLM
]
]
]
)
;
const
MODEL_FOR_MASKED_LM_MAPPING_NAMES
=
new
Map
(
[
[
'
bert
'
[
'
BertForMaskedLM
'
BertForMaskedLM
]
]
[
'
roformer
'
[
'
RoFormerForMaskedLM
'
RoFormerForMaskedLM
]
]
[
'
electra
'
[
'
ElectraForMaskedLM
'
ElectraForMaskedLM
]
]
[
'
esm
'
[
'
EsmForMaskedLM
'
EsmForMaskedLM
]
]
[
'
convbert
'
[
'
ConvBertForMaskedLM
'
ConvBertForMaskedLM
]
]
[
'
camembert
'
[
'
CamembertForMaskedLM
'
CamembertForMaskedLM
]
]
[
'
deberta
'
[
'
DebertaForMaskedLM
'
DebertaForMaskedLM
]
]
[
'
deberta
-
v2
'
[
'
DebertaV2ForMaskedLM
'
DebertaV2ForMaskedLM
]
]
[
'
mpnet
'
[
'
MPNetForMaskedLM
'
MPNetForMaskedLM
]
]
[
'
albert
'
[
'
AlbertForMaskedLM
'
AlbertForMaskedLM
]
]
[
'
distilbert
'
[
'
DistilBertForMaskedLM
'
DistilBertForMaskedLM
]
]
[
'
roberta
'
[
'
RobertaForMaskedLM
'
RobertaForMaskedLM
]
]
[
'
xlm
'
[
'
XLMWithLMHeadModel
'
XLMWithLMHeadModel
]
]
[
'
xlm
-
roberta
'
[
'
XLMRobertaForMaskedLM
'
XLMRobertaForMaskedLM
]
]
[
'
mobilebert
'
[
'
MobileBertForMaskedLM
'
MobileBertForMaskedLM
]
]
[
'
squeezebert
'
[
'
SqueezeBertForMaskedLM
'
SqueezeBertForMaskedLM
]
]
]
)
;
const
MODEL_FOR_QUESTION_ANSWERING_MAPPING_NAMES
=
new
Map
(
[
[
'
bert
'
[
'
BertForQuestionAnswering
'
BertForQuestionAnswering
]
]
[
'
roformer
'
[
'
RoFormerForQuestionAnswering
'
RoFormerForQuestionAnswering
]
]
[
'
electra
'
[
'
ElectraForQuestionAnswering
'
ElectraForQuestionAnswering
]
]
[
'
convbert
'
[
'
ConvBertForQuestionAnswering
'
ConvBertForQuestionAnswering
]
]
[
'
camembert
'
[
'
CamembertForQuestionAnswering
'
CamembertForQuestionAnswering
]
]
[
'
deberta
'
[
'
DebertaForQuestionAnswering
'
DebertaForQuestionAnswering
]
]
[
'
deberta
-
v2
'
[
'
DebertaV2ForQuestionAnswering
'
DebertaV2ForQuestionAnswering
]
]
[
'
mpnet
'
[
'
MPNetForQuestionAnswering
'
MPNetForQuestionAnswering
]
]
[
'
albert
'
[
'
AlbertForQuestionAnswering
'
AlbertForQuestionAnswering
]
]
[
'
distilbert
'
[
'
DistilBertForQuestionAnswering
'
DistilBertForQuestionAnswering
]
]
[
'
roberta
'
[
'
RobertaForQuestionAnswering
'
RobertaForQuestionAnswering
]
]
[
'
xlm
'
[
'
XLMForQuestionAnswering
'
XLMForQuestionAnswering
]
]
[
'
xlm
-
roberta
'
[
'
XLMRobertaForQuestionAnswering
'
XLMRobertaForQuestionAnswering
]
]
[
'
mobilebert
'
[
'
MobileBertForQuestionAnswering
'
MobileBertForQuestionAnswering
]
]
[
'
squeezebert
'
[
'
SqueezeBertForQuestionAnswering
'
SqueezeBertForQuestionAnswering
]
]
]
)
;
const
MODEL_FOR_VISION_2_SEQ_MAPPING_NAMES
=
new
Map
(
[
[
'
vision
-
encoder
-
decoder
'
[
'
VisionEncoderDecoderModel
'
VisionEncoderDecoderModel
]
]
]
)
;
const
MODEL_FOR_IMAGE_TEXT_TO_TEXT_MAPPING_NAMES
=
new
Map
(
[
[
'
llava
'
[
'
LlavaForConditionalGeneration
'
LlavaForConditionalGeneration
]
]
[
'
llava_onevision
'
[
'
LlavaOnevisionForConditionalGeneration
'
LlavaOnevisionForConditionalGeneration
]
]
[
'
moondream1
'
[
'
Moondream1ForConditionalGeneration
'
Moondream1ForConditionalGeneration
]
]
[
'
florence2
'
[
'
Florence2ForConditionalGeneration
'
Florence2ForConditionalGeneration
]
]
[
'
qwen2
-
vl
'
[
'
Qwen2VLForConditionalGeneration
'
Qwen2VLForConditionalGeneration
]
]
]
)
;
const
MODEL_FOR_DOCUMENT_QUESTION_ANSWERING_MAPPING_NAMES
=
new
Map
(
[
[
'
vision
-
encoder
-
decoder
'
[
'
VisionEncoderDecoderModel
'
VisionEncoderDecoderModel
]
]
]
)
;
const
MODEL_FOR_IMAGE_CLASSIFICATION_MAPPING_NAMES
=
new
Map
(
[
[
'
vit
'
[
'
ViTForImageClassification
'
ViTForImageClassification
]
]
[
'
pvt
'
[
'
PvtForImageClassification
'
PvtForImageClassification
]
]
[
'
vit_msn
'
[
'
ViTMSNForImageClassification
'
ViTMSNForImageClassification
]
]
[
'
fastvit
'
[
'
FastViTForImageClassification
'
FastViTForImageClassification
]
]
[
'
mobilevit
'
[
'
MobileViTForImageClassification
'
MobileViTForImageClassification
]
]
[
'
mobilevitv2
'
[
'
MobileViTV2ForImageClassification
'
MobileViTV2ForImageClassification
]
]
[
'
beit
'
[
'
BeitForImageClassification
'
BeitForImageClassification
]
]
[
'
deit
'
[
'
DeiTForImageClassification
'
DeiTForImageClassification
]
]
[
'
hiera
'
[
'
HieraForImageClassification
'
HieraForImageClassification
]
]
[
'
convnext
'
[
'
ConvNextForImageClassification
'
ConvNextForImageClassification
]
]
[
'
convnextv2
'
[
'
ConvNextV2ForImageClassification
'
ConvNextV2ForImageClassification
]
]
[
'
dinov2
'
[
'
Dinov2ForImageClassification
'
Dinov2ForImageClassification
]
]
[
'
resnet
'
[
'
ResNetForImageClassification
'
ResNetForImageClassification
]
]
[
'
swin
'
[
'
SwinForImageClassification
'
SwinForImageClassification
]
]
[
'
segformer
'
[
'
SegformerForImageClassification
'
SegformerForImageClassification
]
]
[
'
efficientnet
'
[
'
EfficientNetForImageClassification
'
EfficientNetForImageClassification
]
]
[
'
mobilenet_v1
'
[
'
MobileNetV1ForImageClassification
'
MobileNetV1ForImageClassification
]
]
[
'
mobilenet_v2
'
[
'
MobileNetV2ForImageClassification
'
MobileNetV2ForImageClassification
]
]
[
'
mobilenet_v3
'
[
'
MobileNetV3ForImageClassification
'
MobileNetV3ForImageClassification
]
]
[
'
mobilenet_v4
'
[
'
MobileNetV4ForImageClassification
'
MobileNetV4ForImageClassification
]
]
]
)
;
const
MODEL_FOR_OBJECT_DETECTION_MAPPING_NAMES
=
new
Map
(
[
[
'
detr
'
[
'
DetrForObjectDetection
'
DetrForObjectDetection
]
]
[
'
rt_detr
'
[
'
RTDetrForObjectDetection
'
RTDetrForObjectDetection
]
]
[
'
table
-
transformer
'
[
'
TableTransformerForObjectDetection
'
TableTransformerForObjectDetection
]
]
[
'
yolos
'
[
'
YolosForObjectDetection
'
YolosForObjectDetection
]
]
]
)
;
const
MODEL_FOR_ZERO_SHOT_OBJECT_DETECTION_MAPPING_NAMES
=
new
Map
(
[
[
'
owlvit
'
[
'
OwlViTForObjectDetection
'
OwlViTForObjectDetection
]
]
[
'
owlv2
'
[
'
Owlv2ForObjectDetection
'
Owlv2ForObjectDetection
]
]
]
)
;
const
MODEL_FOR_IMAGE_SEGMENTATION_MAPPING_NAMES
=
new
Map
(
[
[
'
detr
'
[
'
DetrForSegmentation
'
DetrForSegmentation
]
]
[
'
clipseg
'
[
'
CLIPSegForImageSegmentation
'
CLIPSegForImageSegmentation
]
]
]
)
;
const
MODEL_FOR_SEMANTIC_SEGMENTATION_MAPPING_NAMES
=
new
Map
(
[
[
'
segformer
'
[
'
SegformerForSemanticSegmentation
'
SegformerForSemanticSegmentation
]
]
[
'
sapiens
'
[
'
SapiensForSemanticSegmentation
'
SapiensForSemanticSegmentation
]
]
]
)
;
const
MODEL_FOR_UNIVERSAL_SEGMENTATION_MAPPING_NAMES
=
new
Map
(
[
[
'
detr
'
[
'
DetrForSegmentation
'
DetrForSegmentation
]
]
[
'
maskformer
'
[
'
MaskFormerForInstanceSegmentation
'
MaskFormerForInstanceSegmentation
]
]
]
)
;
const
MODEL_FOR_MASK_GENERATION_MAPPING_NAMES
=
new
Map
(
[
[
'
sam
'
[
'
SamModel
'
SamModel
]
]
]
)
;
const
MODEL_FOR_CTC_MAPPING_NAMES
=
new
Map
(
[
[
'
wav2vec2
'
[
'
Wav2Vec2ForCTC
'
Wav2Vec2ForCTC
]
]
[
'
wav2vec2
-
bert
'
[
'
Wav2Vec2BertForCTC
'
Wav2Vec2BertForCTC
]
]
[
'
unispeech
'
[
'
UniSpeechForCTC
'
UniSpeechForCTC
]
]
[
'
unispeech
-
sat
'
[
'
UniSpeechSatForCTC
'
UniSpeechSatForCTC
]
]
[
'
wavlm
'
[
'
WavLMForCTC
'
WavLMForCTC
]
]
[
'
hubert
'
[
'
HubertForCTC
'
HubertForCTC
]
]
]
)
;
const
MODEL_FOR_AUDIO_CLASSIFICATION_MAPPING_NAMES
=
new
Map
(
[
[
'
wav2vec2
'
[
'
Wav2Vec2ForSequenceClassification
'
Wav2Vec2ForSequenceClassification
]
]
[
'
wav2vec2
-
bert
'
[
'
Wav2Vec2BertForSequenceClassification
'
Wav2Vec2BertForSequenceClassification
]
]
[
'
unispeech
'
[
'
UniSpeechForSequenceClassification
'
UniSpeechForSequenceClassification
]
]
[
'
unispeech
-
sat
'
[
'
UniSpeechSatForSequenceClassification
'
UniSpeechSatForSequenceClassification
]
]
[
'
wavlm
'
[
'
WavLMForSequenceClassification
'
WavLMForSequenceClassification
]
]
[
'
hubert
'
[
'
HubertForSequenceClassification
'
HubertForSequenceClassification
]
]
[
'
audio
-
spectrogram
-
transformer
'
[
'
ASTForAudioClassification
'
ASTForAudioClassification
]
]
]
)
;
const
MODEL_FOR_AUDIO_XVECTOR_MAPPING_NAMES
=
new
Map
(
[
[
'
wavlm
'
[
'
WavLMForXVector
'
WavLMForXVector
]
]
]
)
;
const
MODEL_FOR_AUDIO_FRAME_CLASSIFICATION_MAPPING_NAMES
=
new
Map
(
[
[
'
unispeech
-
sat
'
[
'
UniSpeechSatForAudioFrameClassification
'
UniSpeechSatForAudioFrameClassification
]
]
[
'
wavlm
'
[
'
WavLMForAudioFrameClassification
'
WavLMForAudioFrameClassification
]
]
[
'
wav2vec2
'
[
'
Wav2Vec2ForAudioFrameClassification
'
Wav2Vec2ForAudioFrameClassification
]
]
[
'
pyannote
'
[
'
PyAnnoteForAudioFrameClassification
'
PyAnnoteForAudioFrameClassification
]
]
]
)
;
const
MODEL_FOR_IMAGE_MATTING_MAPPING_NAMES
=
new
Map
(
[
[
'
vitmatte
'
[
'
VitMatteForImageMatting
'
VitMatteForImageMatting
]
]
]
)
;
const
MODEL_FOR_TIME_SERIES_PREDICTION_MAPPING_NAMES
=
new
Map
(
[
[
'
patchtst
'
[
'
PatchTSTForPrediction
'
PatchTSTForPrediction
]
]
[
'
patchtsmixer
'
[
'
PatchTSMixerForPrediction
'
PatchTSMixerForPrediction
]
]
]
)
const
MODEL_FOR_IMAGE_TO_IMAGE_MAPPING_NAMES
=
new
Map
(
[
[
'
swin2sr
'
[
'
Swin2SRForImageSuperResolution
'
Swin2SRForImageSuperResolution
]
]
]
)
const
MODEL_FOR_DEPTH_ESTIMATION_MAPPING_NAMES
=
new
Map
(
[
[
'
dpt
'
[
'
DPTForDepthEstimation
'
DPTForDepthEstimation
]
]
[
'
depth_anything
'
[
'
DepthAnythingForDepthEstimation
'
DepthAnythingForDepthEstimation
]
]
[
'
glpn
'
[
'
GLPNForDepthEstimation
'
GLPNForDepthEstimation
]
]
[
'
sapiens
'
[
'
SapiensForDepthEstimation
'
SapiensForDepthEstimation
]
]
[
'
depth_pro
'
[
'
DepthProForDepthEstimation
'
DepthProForDepthEstimation
]
]
]
)
const
MODEL_FOR_NORMAL_ESTIMATION_MAPPING_NAMES
=
new
Map
(
[
[
'
sapiens
'
[
'
SapiensForNormalEstimation
'
SapiensForNormalEstimation
]
]
]
)
const
MODEL_FOR_POSE_ESTIMATION_MAPPING_NAMES
=
new
Map
(
[
[
'
vitpose
'
[
'
VitPoseForPoseEstimation
'
VitPoseForPoseEstimation
]
]
]
)
const
MODEL_FOR_IMAGE_FEATURE_EXTRACTION_MAPPING_NAMES
=
new
Map
(
[
[
'
clip
'
[
'
CLIPVisionModelWithProjection
'
CLIPVisionModelWithProjection
]
]
[
'
siglip
'
[
'
SiglipVisionModel
'
SiglipVisionModel
]
]
[
'
jina_clip
'
[
'
JinaCLIPVisionModel
'
JinaCLIPVisionModel
]
]
]
)
const
MODEL_CLASS_TYPE_MAPPING
=
[
[
MODEL_MAPPING_NAMES_ENCODER_ONLY
MODEL_TYPES
.
EncoderOnly
]
[
MODEL_MAPPING_NAMES_ENCODER_DECODER
MODEL_TYPES
.
EncoderDecoder
]
[
MODEL_MAPPING_NAMES_DECODER_ONLY
MODEL_TYPES
.
DecoderOnly
]
[
MODEL_FOR_SEQUENCE_CLASSIFICATION_MAPPING_NAMES
MODEL_TYPES
.
EncoderOnly
]
[
MODEL_FOR_TOKEN_CLASSIFICATION_MAPPING_NAMES
MODEL_TYPES
.
EncoderOnly
]
[
MODEL_FOR_SEQ_TO_SEQ_CAUSAL_LM_MAPPING_NAMES
MODEL_TYPES
.
Seq2Seq
]
[
MODEL_FOR_SPEECH_SEQ_2_SEQ_MAPPING_NAMES
MODEL_TYPES
.
Seq2Seq
]
[
MODEL_FOR_CAUSAL_LM_MAPPING_NAMES
MODEL_TYPES
.
DecoderOnly
]
[
MODEL_FOR_MULTIMODALITY_MAPPING_NAMES
MODEL_TYPES
.
MultiModality
]
[
MODEL_FOR_MASKED_LM_MAPPING_NAMES
MODEL_TYPES
.
EncoderOnly
]
[
MODEL_FOR_QUESTION_ANSWERING_MAPPING_NAMES
MODEL_TYPES
.
EncoderOnly
]
[
MODEL_FOR_VISION_2_SEQ_MAPPING_NAMES
MODEL_TYPES
.
Vision2Seq
]
[
MODEL_FOR_IMAGE_TEXT_TO_TEXT_MAPPING_NAMES
MODEL_TYPES
.
ImageTextToText
]
[
MODEL_FOR_IMAGE_CLASSIFICATION_MAPPING_NAMES
MODEL_TYPES
.
EncoderOnly
]
[
MODEL_FOR_IMAGE_SEGMENTATION_MAPPING_NAMES
MODEL_TYPES
.
EncoderOnly
]
[
MODEL_FOR_UNIVERSAL_SEGMENTATION_MAPPING_NAMES
MODEL_TYPES
.
EncoderOnly
]
[
MODEL_FOR_SEMANTIC_SEGMENTATION_MAPPING_NAMES
MODEL_TYPES
.
EncoderOnly
]
[
MODEL_FOR_IMAGE_MATTING_MAPPING_NAMES
MODEL_TYPES
.
EncoderOnly
]
[
MODEL_FOR_TIME_SERIES_PREDICTION_MAPPING_NAMES
MODEL_TYPES
.
EncoderOnly
]
[
MODEL_FOR_IMAGE_TO_IMAGE_MAPPING_NAMES
MODEL_TYPES
.
EncoderOnly
]
[
MODEL_FOR_DEPTH_ESTIMATION_MAPPING_NAMES
MODEL_TYPES
.
EncoderOnly
]
[
MODEL_FOR_NORMAL_ESTIMATION_MAPPING_NAMES
MODEL_TYPES
.
EncoderOnly
]
[
MODEL_FOR_POSE_ESTIMATION_MAPPING_NAMES
MODEL_TYPES
.
EncoderOnly
]
[
MODEL_FOR_OBJECT_DETECTION_MAPPING_NAMES
MODEL_TYPES
.
EncoderOnly
]
[
MODEL_FOR_ZERO_SHOT_OBJECT_DETECTION_MAPPING_NAMES
MODEL_TYPES
.
EncoderOnly
]
[
MODEL_FOR_MASK_GENERATION_MAPPING_NAMES
MODEL_TYPES
.
MaskGeneration
]
[
MODEL_FOR_CTC_MAPPING_NAMES
MODEL_TYPES
.
EncoderOnly
]
[
MODEL_FOR_AUDIO_CLASSIFICATION_MAPPING_NAMES
MODEL_TYPES
.
EncoderOnly
]
[
MODEL_FOR_TEXT_TO_SPECTROGRAM_MAPPING_NAMES
MODEL_TYPES
.
Seq2Seq
]
[
MODEL_FOR_TEXT_TO_WAVEFORM_MAPPING_NAMES
MODEL_TYPES
.
EncoderOnly
]
[
MODEL_FOR_AUDIO_XVECTOR_MAPPING_NAMES
MODEL_TYPES
.
EncoderOnly
]
[
MODEL_FOR_AUDIO_FRAME_CLASSIFICATION_MAPPING_NAMES
MODEL_TYPES
.
EncoderOnly
]
[
MODEL_FOR_IMAGE_FEATURE_EXTRACTION_MAPPING_NAMES
MODEL_TYPES
.
EncoderOnly
]
]
;
for
(
const
[
mappings
type
]
of
MODEL_CLASS_TYPE_MAPPING
)
{
for
(
const
[
name
model
]
of
mappings
.
values
(
)
)
{
MODEL_TYPE_MAPPING
.
set
(
name
type
)
;
MODEL_CLASS_TO_NAME_MAPPING
.
set
(
model
name
)
;
MODEL_NAME_TO_CLASS_MAPPING
.
set
(
name
model
)
;
}
}
const
CUSTOM_MAPPING
=
[
[
'
MusicgenForConditionalGeneration
'
MusicgenForConditionalGeneration
MODEL_TYPES
.
Musicgen
]
[
'
CLIPTextModelWithProjection
'
CLIPTextModelWithProjection
MODEL_TYPES
.
EncoderOnly
]
[
'
SiglipTextModel
'
SiglipTextModel
MODEL_TYPES
.
EncoderOnly
]
[
'
JinaCLIPTextModel
'
JinaCLIPTextModel
MODEL_TYPES
.
EncoderOnly
]
[
'
ClapTextModelWithProjection
'
ClapTextModelWithProjection
MODEL_TYPES
.
EncoderOnly
]
[
'
ClapAudioModelWithProjection
'
ClapAudioModelWithProjection
MODEL_TYPES
.
EncoderOnly
]
]
for
(
const
[
name
model
type
]
of
CUSTOM_MAPPING
)
{
MODEL_TYPE_MAPPING
.
set
(
name
type
)
;
MODEL_CLASS_TO_NAME_MAPPING
.
set
(
model
name
)
;
MODEL_NAME_TO_CLASS_MAPPING
.
set
(
name
model
)
;
}
class
AutoModel
extends
PretrainedMixin
{
static
MODEL_CLASS_MAPPINGS
=
MODEL_CLASS_TYPE_MAPPING
.
map
(
x
=
>
x
[
0
]
)
;
static
BASE_IF_FAIL
=
true
;
}
class
AutoModelForSequenceClassification
extends
PretrainedMixin
{
static
MODEL_CLASS_MAPPINGS
=
[
MODEL_FOR_SEQUENCE_CLASSIFICATION_MAPPING_NAMES
]
;
}
class
AutoModelForTokenClassification
extends
PretrainedMixin
{
static
MODEL_CLASS_MAPPINGS
=
[
MODEL_FOR_TOKEN_CLASSIFICATION_MAPPING_NAMES
]
;
}
class
AutoModelForSeq2SeqLM
extends
PretrainedMixin
{
static
MODEL_CLASS_MAPPINGS
=
[
MODEL_FOR_SEQ_TO_SEQ_CAUSAL_LM_MAPPING_NAMES
]
;
}
class
AutoModelForSpeechSeq2Seq
extends
PretrainedMixin
{
static
MODEL_CLASS_MAPPINGS
=
[
MODEL_FOR_SPEECH_SEQ_2_SEQ_MAPPING_NAMES
]
;
}
class
AutoModelForTextToSpectrogram
extends
PretrainedMixin
{
static
MODEL_CLASS_MAPPINGS
=
[
MODEL_FOR_TEXT_TO_SPECTROGRAM_MAPPING_NAMES
]
;
}
class
AutoModelForTextToWaveform
extends
PretrainedMixin
{
static
MODEL_CLASS_MAPPINGS
=
[
MODEL_FOR_TEXT_TO_WAVEFORM_MAPPING_NAMES
]
;
}
class
AutoModelForCausalLM
extends
PretrainedMixin
{
static
MODEL_CLASS_MAPPINGS
=
[
MODEL_FOR_CAUSAL_LM_MAPPING_NAMES
]
;
}
class
AutoModelForMaskedLM
extends
PretrainedMixin
{
static
MODEL_CLASS_MAPPINGS
=
[
MODEL_FOR_MASKED_LM_MAPPING_NAMES
]
;
}
class
AutoModelForQuestionAnswering
extends
PretrainedMixin
{
static
MODEL_CLASS_MAPPINGS
=
[
MODEL_FOR_QUESTION_ANSWERING_MAPPING_NAMES
]
;
}
class
AutoModelForVision2Seq
extends
PretrainedMixin
{
static
MODEL_CLASS_MAPPINGS
=
[
MODEL_FOR_VISION_2_SEQ_MAPPING_NAMES
]
;
}
class
AutoModelForImageClassification
extends
PretrainedMixin
{
static
MODEL_CLASS_MAPPINGS
=
[
MODEL_FOR_IMAGE_CLASSIFICATION_MAPPING_NAMES
]
;
}
class
AutoModelForImageSegmentation
extends
PretrainedMixin
{
static
MODEL_CLASS_MAPPINGS
=
[
MODEL_FOR_IMAGE_SEGMENTATION_MAPPING_NAMES
]
;
}
class
AutoModelForSemanticSegmentation
extends
PretrainedMixin
{
static
MODEL_CLASS_MAPPINGS
=
[
MODEL_FOR_SEMANTIC_SEGMENTATION_MAPPING_NAMES
]
;
}
class
AutoModelForUniversalSegmentation
extends
PretrainedMixin
{
static
MODEL_CLASS_MAPPINGS
=
[
MODEL_FOR_UNIVERSAL_SEGMENTATION_MAPPING_NAMES
]
;
}
class
AutoModelForObjectDetection
extends
PretrainedMixin
{
static
MODEL_CLASS_MAPPINGS
=
[
MODEL_FOR_OBJECT_DETECTION_MAPPING_NAMES
]
;
}
class
AutoModelForZeroShotObjectDetection
extends
PretrainedMixin
{
static
MODEL_CLASS_MAPPINGS
=
[
MODEL_FOR_ZERO_SHOT_OBJECT_DETECTION_MAPPING_NAMES
]
;
}
class
AutoModelForMaskGeneration
extends
PretrainedMixin
{
static
MODEL_CLASS_MAPPINGS
=
[
MODEL_FOR_MASK_GENERATION_MAPPING_NAMES
]
;
}
class
AutoModelForCTC
extends
PretrainedMixin
{
static
MODEL_CLASS_MAPPINGS
=
[
MODEL_FOR_CTC_MAPPING_NAMES
]
;
}
class
AutoModelForAudioClassification
extends
PretrainedMixin
{
static
MODEL_CLASS_MAPPINGS
=
[
MODEL_FOR_AUDIO_CLASSIFICATION_MAPPING_NAMES
]
;
}
class
AutoModelForXVector
extends
PretrainedMixin
{
static
MODEL_CLASS_MAPPINGS
=
[
MODEL_FOR_AUDIO_XVECTOR_MAPPING_NAMES
]
;
}
class
AutoModelForAudioFrameClassification
extends
PretrainedMixin
{
static
MODEL_CLASS_MAPPINGS
=
[
MODEL_FOR_AUDIO_FRAME_CLASSIFICATION_MAPPING_NAMES
]
;
}
class
AutoModelForDocumentQuestionAnswering
extends
PretrainedMixin
{
static
MODEL_CLASS_MAPPINGS
=
[
MODEL_FOR_DOCUMENT_QUESTION_ANSWERING_MAPPING_NAMES
]
;
}
class
AutoModelForImageMatting
extends
PretrainedMixin
{
static
MODEL_CLASS_MAPPINGS
=
[
MODEL_FOR_IMAGE_MATTING_MAPPING_NAMES
]
;
}
class
AutoModelForImageToImage
extends
PretrainedMixin
{
static
MODEL_CLASS_MAPPINGS
=
[
MODEL_FOR_IMAGE_TO_IMAGE_MAPPING_NAMES
]
;
}
class
AutoModelForDepthEstimation
extends
PretrainedMixin
{
static
MODEL_CLASS_MAPPINGS
=
[
MODEL_FOR_DEPTH_ESTIMATION_MAPPING_NAMES
]
;
}
class
AutoModelForNormalEstimation
extends
PretrainedMixin
{
static
MODEL_CLASS_MAPPINGS
=
[
MODEL_FOR_NORMAL_ESTIMATION_MAPPING_NAMES
]
;
}
class
AutoModelForPoseEstimation
extends
PretrainedMixin
{
static
MODEL_CLASS_MAPPINGS
=
[
MODEL_FOR_POSE_ESTIMATION_MAPPING_NAMES
]
;
}
class
AutoModelForImageFeatureExtraction
extends
PretrainedMixin
{
static
MODEL_CLASS_MAPPINGS
=
[
MODEL_FOR_IMAGE_FEATURE_EXTRACTION_MAPPING_NAMES
]
;
}
class
Seq2SeqLMOutput
extends
ModelOutput
{
constructor
(
{
logits
past_key_values
encoder_outputs
decoder_attentions
=
null
cross_attentions
=
null
}
)
{
super
(
)
;
this
.
logits
=
logits
;
this
.
past_key_values
=
past_key_values
;
this
.
encoder_outputs
=
encoder_outputs
;
this
.
decoder_attentions
=
decoder_attentions
;
this
.
cross_attentions
=
cross_attentions
;
}
}
class
SequenceClassifierOutput
extends
ModelOutput
{
constructor
(
{
logits
}
)
{
super
(
)
;
this
.
logits
=
logits
;
}
}
class
XVectorOutput
extends
ModelOutput
{
constructor
(
{
logits
embeddings
}
)
{
super
(
)
;
this
.
logits
=
logits
;
this
.
embeddings
=
embeddings
;
}
}
class
TokenClassifierOutput
extends
ModelOutput
{
constructor
(
{
logits
}
)
{
super
(
)
;
this
.
logits
=
logits
;
}
}
class
MaskedLMOutput
extends
ModelOutput
{
constructor
(
{
logits
}
)
{
super
(
)
;
this
.
logits
=
logits
;
}
}
class
QuestionAnsweringModelOutput
extends
ModelOutput
{
constructor
(
{
start_logits
end_logits
}
)
{
super
(
)
;
this
.
start_logits
=
start_logits
;
this
.
end_logits
=
end_logits
;
}
}
class
CausalLMOutput
extends
ModelOutput
{
constructor
(
{
logits
}
)
{
super
(
)
;
this
.
logits
=
logits
;
}
}
class
CausalLMOutputWithPast
extends
ModelOutput
{
constructor
(
{
logits
past_key_values
}
)
{
super
(
)
;
this
.
logits
=
logits
;
this
.
past_key_values
=
past_key_values
;
}
}
class
ImageMattingOutput
extends
ModelOutput
{
constructor
(
{
alphas
}
)
{
super
(
)
;
this
.
alphas
=
alphas
;
}
}
class
VitsModelOutput
extends
ModelOutput
{
constructor
(
{
waveform
spectrogram
}
)
{
super
(
)
;
this
.
waveform
=
waveform
;
this
.
spectrogram
=
spectrogram
;
}
}
}
)
"
.
/
src
/
models
/
audio_spectrogram_transformer
/
feature_extraction_audio_spectrogram_transformer
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
ASTFeatureExtractor
:
(
)
=
>
(
ASTFeatureExtractor
)
}
)
;
var
_base_feature_extraction_utils_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
src
/
base
/
feature_extraction_utils
.
js
"
)
;
var
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_1__
=
__webpack_require__
(
"
.
/
src
/
utils
/
tensor
.
js
"
)
;
var
_utils_audio_js__WEBPACK_IMPORTED_MODULE_2__
=
__webpack_require__
(
"
.
/
src
/
utils
/
audio
.
js
"
)
;
class
ASTFeatureExtractor
extends
_base_feature_extraction_utils_js__WEBPACK_IMPORTED_MODULE_0__
.
FeatureExtractor
{
constructor
(
config
)
{
super
(
config
)
;
const
sampling_rate
=
this
.
config
.
sampling_rate
;
const
mel_filters
=
(
0
_utils_audio_js__WEBPACK_IMPORTED_MODULE_2__
.
mel_filter_bank
)
(
256
this
.
config
.
num_mel_bins
20
Math
.
floor
(
sampling_rate
/
2
)
sampling_rate
null
"
kaldi
"
true
)
;
for
(
let
i
=
0
;
i
<
mel_filters
.
length
;
+
+
i
)
{
mel_filters
[
i
]
.
push
(
0
)
;
}
this
.
mel_filters
=
mel_filters
;
this
.
window
=
(
0
_utils_audio_js__WEBPACK_IMPORTED_MODULE_2__
.
window_function
)
(
400
'
hann
'
{
periodic
:
false
}
)
this
.
mean
=
this
.
config
.
mean
;
this
.
std
=
this
.
config
.
std
;
}
async
_extract_fbank_features
(
waveform
max_length
)
{
return
(
0
_utils_audio_js__WEBPACK_IMPORTED_MODULE_2__
.
spectrogram
)
(
waveform
this
.
window
400
160
{
fft_length
:
512
power
:
2
.
0
center
:
false
preemphasis
:
0
.
97
mel_filters
:
this
.
mel_filters
log_mel
:
'
log
'
mel_floor
:
1
.
192092955078125e
-
07
remove_dc_offset
:
true
max_num_frames
:
max_length
transpose
:
true
}
)
}
async
_call
(
audio
)
{
(
0
_base_feature_extraction_utils_js__WEBPACK_IMPORTED_MODULE_0__
.
validate_audio_inputs
)
(
audio
'
ASTFeatureExtractor
'
)
;
const
features
=
await
this
.
_extract_fbank_features
(
audio
this
.
config
.
max_length
)
;
if
(
this
.
config
.
do_normalize
)
{
const
denom
=
this
.
std
*
2
;
const
features_data
=
features
.
data
;
for
(
let
i
=
0
;
i
<
features_data
.
length
;
+
+
i
)
{
features_data
[
i
]
=
(
features_data
[
i
]
-
this
.
mean
)
/
denom
;
}
}
return
{
input_values
:
features
.
unsqueeze_
(
0
)
}
;
}
}
}
)
"
.
/
src
/
models
/
auto
/
feature_extraction_auto
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
AutoFeatureExtractor
:
(
)
=
>
(
AutoFeatureExtractor
)
}
)
;
var
_utils_constants_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
src
/
utils
/
constants
.
js
"
)
;
var
_utils_hub_js__WEBPACK_IMPORTED_MODULE_1__
=
__webpack_require__
(
"
.
/
src
/
utils
/
hub
.
js
"
)
;
var
_base_feature_extraction_utils_js__WEBPACK_IMPORTED_MODULE_2__
=
__webpack_require__
(
"
.
/
src
/
base
/
feature_extraction_utils
.
js
"
)
;
var
_feature_extractors_js__WEBPACK_IMPORTED_MODULE_3__
=
__webpack_require__
(
"
.
/
src
/
models
/
feature_extractors
.
js
"
)
;
class
AutoFeatureExtractor
{
static
async
from_pretrained
(
pretrained_model_name_or_path
options
=
{
}
)
{
const
preprocessorConfig
=
await
(
0
_utils_hub_js__WEBPACK_IMPORTED_MODULE_1__
.
getModelJSON
)
(
pretrained_model_name_or_path
_utils_constants_js__WEBPACK_IMPORTED_MODULE_0__
.
FEATURE_EXTRACTOR_NAME
true
options
)
;
const
key
=
preprocessorConfig
.
feature_extractor_type
;
const
feature_extractor_class
=
_feature_extractors_js__WEBPACK_IMPORTED_MODULE_3__
[
key
]
;
if
(
!
feature_extractor_class
)
{
throw
new
Error
(
Unknown
feature_extractor_type
:
'
{
key
}
'
.
Please
report
this
at
{
_utils_constants_js__WEBPACK_IMPORTED_MODULE_0__
.
GITHUB_ISSUE_URL
}
.
)
;
}
return
new
feature_extractor_class
(
preprocessorConfig
)
;
}
}
}
)
"
.
/
src
/
models
/
auto
/
image_processing_auto
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
AutoImageProcessor
:
(
)
=
>
(
AutoImageProcessor
)
}
)
;
var
_utils_constants_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
src
/
utils
/
constants
.
js
"
)
;
var
_utils_hub_js__WEBPACK_IMPORTED_MODULE_1__
=
__webpack_require__
(
"
.
/
src
/
utils
/
hub
.
js
"
)
;
var
_base_image_processors_utils_js__WEBPACK_IMPORTED_MODULE_2__
=
__webpack_require__
(
"
.
/
src
/
base
/
image_processors_utils
.
js
"
)
;
var
_image_processors_js__WEBPACK_IMPORTED_MODULE_3__
=
__webpack_require__
(
"
.
/
src
/
models
/
image_processors
.
js
"
)
;
class
AutoImageProcessor
{
static
async
from_pretrained
(
pretrained_model_name_or_path
options
=
{
}
)
{
const
preprocessorConfig
=
await
(
0
_utils_hub_js__WEBPACK_IMPORTED_MODULE_1__
.
getModelJSON
)
(
pretrained_model_name_or_path
_utils_constants_js__WEBPACK_IMPORTED_MODULE_0__
.
IMAGE_PROCESSOR_NAME
true
options
)
;
const
key
=
preprocessorConfig
.
image_processor_type
?
?
preprocessorConfig
.
feature_extractor_type
;
let
image_processor_class
=
_image_processors_js__WEBPACK_IMPORTED_MODULE_3__
[
key
]
;
if
(
!
image_processor_class
)
{
if
(
key
!
=
=
undefined
)
{
console
.
warn
(
Image
processor
type
'
{
key
}
'
not
found
assuming
base
ImageProcessor
.
Please
report
this
at
{
_utils_constants_js__WEBPACK_IMPORTED_MODULE_0__
.
GITHUB_ISSUE_URL
}
.
)
}
image_processor_class
=
_base_image_processors_utils_js__WEBPACK_IMPORTED_MODULE_2__
.
ImageProcessor
;
}
return
new
image_processor_class
(
preprocessorConfig
)
;
}
}
}
)
"
.
/
src
/
models
/
auto
/
processing_auto
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
AutoProcessor
:
(
)
=
>
(
AutoProcessor
)
}
)
;
var
_utils_constants_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
src
/
utils
/
constants
.
js
"
)
;
var
_utils_hub_js__WEBPACK_IMPORTED_MODULE_1__
=
__webpack_require__
(
"
.
/
src
/
utils
/
hub
.
js
"
)
;
var
_base_processing_utils_js__WEBPACK_IMPORTED_MODULE_2__
=
__webpack_require__
(
"
.
/
src
/
base
/
processing_utils
.
js
"
)
;
var
_processors_js__WEBPACK_IMPORTED_MODULE_3__
=
__webpack_require__
(
"
.
/
src
/
models
/
processors
.
js
"
)
;
var
_image_processors_js__WEBPACK_IMPORTED_MODULE_4__
=
__webpack_require__
(
"
.
/
src
/
models
/
image_processors
.
js
"
)
;
var
_feature_extractors_js__WEBPACK_IMPORTED_MODULE_5__
=
__webpack_require__
(
"
.
/
src
/
models
/
feature_extractors
.
js
"
)
;
class
AutoProcessor
{
static
async
from_pretrained
(
pretrained_model_name_or_path
options
=
{
}
)
{
const
preprocessorConfig
=
await
(
0
_utils_hub_js__WEBPACK_IMPORTED_MODULE_1__
.
getModelJSON
)
(
pretrained_model_name_or_path
_utils_constants_js__WEBPACK_IMPORTED_MODULE_0__
.
IMAGE_PROCESSOR_NAME
true
options
)
;
const
{
image_processor_type
feature_extractor_type
processor_class
}
=
preprocessorConfig
;
if
(
processor_class
&
&
_processors_js__WEBPACK_IMPORTED_MODULE_3__
[
processor_class
]
)
{
return
_processors_js__WEBPACK_IMPORTED_MODULE_3__
[
processor_class
]
.
from_pretrained
(
pretrained_model_name_or_path
options
)
;
}
if
(
!
image_processor_type
&
&
!
feature_extractor_type
)
{
throw
new
Error
(
'
No
image_processor_type
or
feature_extractor_type
found
in
the
config
.
'
)
;
}
const
components
=
{
}
;
if
(
image_processor_type
)
{
const
image_processor_class
=
_image_processors_js__WEBPACK_IMPORTED_MODULE_4__
[
image_processor_type
]
;
if
(
!
image_processor_class
)
{
throw
new
Error
(
Unknown
image_processor_type
:
'
{
image_processor_type
}
'
.
)
;
}
components
.
image_processor
=
new
image_processor_class
(
preprocessorConfig
)
;
}
if
(
feature_extractor_type
)
{
const
image_processor_class
=
_image_processors_js__WEBPACK_IMPORTED_MODULE_4__
[
feature_extractor_type
]
;
if
(
image_processor_class
)
{
components
.
image_processor
=
new
image_processor_class
(
preprocessorConfig
)
;
}
else
{
const
feature_extractor_class
=
_feature_extractors_js__WEBPACK_IMPORTED_MODULE_5__
[
feature_extractor_type
]
;
if
(
!
feature_extractor_class
)
{
throw
new
Error
(
Unknown
feature_extractor_type
:
'
{
feature_extractor_type
}
'
.
)
;
}
components
.
feature_extractor
=
new
feature_extractor_class
(
preprocessorConfig
)
;
}
}
const
config
=
{
}
;
return
new
_base_processing_utils_js__WEBPACK_IMPORTED_MODULE_2__
.
Processor
(
config
components
)
;
}
}
}
)
"
.
/
src
/
models
/
beit
/
image_processing_beit
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
BeitFeatureExtractor
:
(
)
=
>
(
BeitFeatureExtractor
)
}
)
;
var
_base_image_processors_utils_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
src
/
base
/
image_processors_utils
.
js
"
)
;
class
BeitFeatureExtractor
extends
_base_image_processors_utils_js__WEBPACK_IMPORTED_MODULE_0__
.
ImageProcessor
{
}
}
)
"
.
/
src
/
models
/
bit
/
image_processing_bit
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
BitImageProcessor
:
(
)
=
>
(
BitImageProcessor
)
}
)
;
var
_base_image_processors_utils_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
src
/
base
/
image_processors_utils
.
js
"
)
;
class
BitImageProcessor
extends
_base_image_processors_utils_js__WEBPACK_IMPORTED_MODULE_0__
.
ImageProcessor
{
}
}
)
"
.
/
src
/
models
/
chinese_clip
/
image_processing_chinese_clip
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
ChineseCLIPFeatureExtractor
:
(
)
=
>
(
ChineseCLIPFeatureExtractor
)
}
)
;
var
_base_image_processors_utils_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
src
/
base
/
image_processors_utils
.
js
"
)
;
class
ChineseCLIPFeatureExtractor
extends
_base_image_processors_utils_js__WEBPACK_IMPORTED_MODULE_0__
.
ImageProcessor
{
}
}
)
"
.
/
src
/
models
/
clap
/
feature_extraction_clap
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
ClapFeatureExtractor
:
(
)
=
>
(
ClapFeatureExtractor
)
}
)
;
var
_base_feature_extraction_utils_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
src
/
base
/
feature_extraction_utils
.
js
"
)
;
var
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_1__
=
__webpack_require__
(
"
.
/
src
/
utils
/
tensor
.
js
"
)
;
var
_utils_audio_js__WEBPACK_IMPORTED_MODULE_2__
=
__webpack_require__
(
"
.
/
src
/
utils
/
audio
.
js
"
)
;
class
ClapFeatureExtractor
extends
_base_feature_extraction_utils_js__WEBPACK_IMPORTED_MODULE_0__
.
FeatureExtractor
{
constructor
(
config
)
{
super
(
config
)
;
this
.
mel_filters
=
(
0
_utils_audio_js__WEBPACK_IMPORTED_MODULE_2__
.
mel_filter_bank
)
(
this
.
config
.
nb_frequency_bins
this
.
config
.
feature_size
this
.
config
.
frequency_min
this
.
config
.
frequency_max
this
.
config
.
sampling_rate
null
"
htk
"
)
;
this
.
mel_filters_slaney
=
(
0
_utils_audio_js__WEBPACK_IMPORTED_MODULE_2__
.
mel_filter_bank
)
(
this
.
config
.
nb_frequency_bins
this
.
config
.
feature_size
this
.
config
.
frequency_min
this
.
config
.
frequency_max
this
.
config
.
sampling_rate
"
slaney
"
"
slaney
"
)
;
this
.
window
=
(
0
_utils_audio_js__WEBPACK_IMPORTED_MODULE_2__
.
window_function
)
(
this
.
config
.
fft_window_size
'
hann
'
)
}
async
_get_input_mel
(
waveform
max_length
truncation
padding
)
{
let
input_mel
;
let
longer
=
false
;
const
diff
=
waveform
.
length
-
max_length
;
if
(
diff
>
0
)
{
if
(
truncation
=
=
=
'
rand_trunc
'
)
{
longer
=
true
;
const
idx
=
Math
.
floor
(
Math
.
random
(
)
*
(
diff
+
1
)
)
;
waveform
=
waveform
.
subarray
(
idx
idx
+
max_length
)
;
input_mel
=
await
this
.
_extract_fbank_features
(
waveform
this
.
mel_filters_slaney
this
.
config
.
nb_max_samples
)
;
}
else
{
throw
new
Error
(
Truncation
strategy
"
{
truncation
}
"
not
implemented
)
}
}
else
{
if
(
diff
<
0
)
{
let
padded
=
new
Float64Array
(
max_length
)
;
padded
.
set
(
waveform
)
;
if
(
padding
=
=
=
'
repeat
'
)
{
for
(
let
i
=
waveform
.
length
;
i
<
max_length
;
i
+
=
waveform
.
length
)
{
padded
.
set
(
waveform
.
subarray
(
0
Math
.
min
(
waveform
.
length
max_length
-
i
)
)
i
)
;
}
}
else
if
(
padding
=
=
=
'
repeatpad
'
)
{
for
(
let
i
=
waveform
.
length
;
i
<
-
diff
;
i
+
=
waveform
.
length
)
{
padded
.
set
(
waveform
i
)
;
}
}
waveform
=
padded
;
}
if
(
truncation
=
=
=
'
fusion
'
)
{
throw
new
Error
(
Truncation
strategy
"
{
truncation
}
"
not
implemented
)
}
input_mel
=
await
this
.
_extract_fbank_features
(
waveform
this
.
mel_filters_slaney
this
.
config
.
nb_max_samples
)
;
}
return
input_mel
.
unsqueeze_
(
0
)
;
}
async
_extract_fbank_features
(
waveform
mel_filters
max_length
=
null
)
{
return
(
0
_utils_audio_js__WEBPACK_IMPORTED_MODULE_2__
.
spectrogram
)
(
waveform
this
.
window
this
.
config
.
fft_window_size
this
.
config
.
hop_length
{
power
:
2
.
0
mel_filters
log_mel
:
'
dB
'
max_num_frames
:
max_length
do_pad
:
false
transpose
:
true
}
)
}
async
_call
(
audio
{
max_length
=
null
}
=
{
}
)
{
(
0
_base_feature_extraction_utils_js__WEBPACK_IMPORTED_MODULE_0__
.
validate_audio_inputs
)
(
audio
'
ClapFeatureExtractor
'
)
;
const
padded_inputs
=
await
this
.
_get_input_mel
(
audio
max_length
?
?
this
.
config
.
nb_max_samples
this
.
config
.
truncation
this
.
config
.
padding
)
;
return
{
input_features
:
padded_inputs
.
unsqueeze_
(
0
)
}
}
}
}
)
"
.
/
src
/
models
/
clip
/
image_processing_clip
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
CLIPFeatureExtractor
:
(
)
=
>
(
CLIPFeatureExtractor
)
CLIPImageProcessor
:
(
)
=
>
(
CLIPImageProcessor
)
}
)
;
var
_base_image_processors_utils_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
src
/
base
/
image_processors_utils
.
js
"
)
;
class
CLIPImageProcessor
extends
_base_image_processors_utils_js__WEBPACK_IMPORTED_MODULE_0__
.
ImageProcessor
{
}
class
CLIPFeatureExtractor
extends
CLIPImageProcessor
{
}
}
)
"
.
/
src
/
models
/
convnext
/
image_processing_convnext
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
ConvNextFeatureExtractor
:
(
)
=
>
(
ConvNextFeatureExtractor
)
ConvNextImageProcessor
:
(
)
=
>
(
ConvNextImageProcessor
)
}
)
;
var
_base_image_processors_utils_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
src
/
base
/
image_processors_utils
.
js
"
)
;
class
ConvNextImageProcessor
extends
_base_image_processors_utils_js__WEBPACK_IMPORTED_MODULE_0__
.
ImageProcessor
{
constructor
(
config
)
{
super
(
config
)
;
this
.
crop_pct
=
this
.
config
.
crop_pct
?
?
(
224
/
256
)
;
}
async
resize
(
image
)
{
const
shortest_edge
=
this
.
size
?
.
shortest_edge
;
if
(
shortest_edge
=
=
=
undefined
)
{
throw
new
Error
(
Size
dictionary
must
contain
'
shortest_edge
'
key
.
)
;
}
if
(
shortest_edge
<
384
)
{
const
resize_shortest_edge
=
Math
.
floor
(
shortest_edge
/
this
.
crop_pct
)
;
const
[
newWidth
newHeight
]
=
this
.
get_resize_output_image_size
(
image
{
shortest_edge
:
resize_shortest_edge
}
)
;
image
=
await
image
.
resize
(
newWidth
newHeight
{
resample
:
this
.
resample
}
)
;
image
=
await
image
.
center_crop
(
shortest_edge
shortest_edge
)
;
}
else
{
image
=
await
image
.
resize
(
shortest_edge
shortest_edge
{
resample
:
this
.
resample
}
)
;
}
return
image
;
}
}
class
ConvNextFeatureExtractor
extends
ConvNextImageProcessor
{
}
}
)
"
.
/
src
/
models
/
deit
/
image_processing_deit
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
DeiTFeatureExtractor
:
(
)
=
>
(
DeiTFeatureExtractor
)
DeiTImageProcessor
:
(
)
=
>
(
DeiTImageProcessor
)
}
)
;
var
_base_image_processors_utils_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
src
/
base
/
image_processors_utils
.
js
"
)
;
class
DeiTImageProcessor
extends
_base_image_processors_utils_js__WEBPACK_IMPORTED_MODULE_0__
.
ImageProcessor
{
}
class
DeiTFeatureExtractor
extends
DeiTImageProcessor
{
}
}
)
"
.
/
src
/
models
/
detr
/
image_processing_detr
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
DetrFeatureExtractor
:
(
)
=
>
(
DetrFeatureExtractor
)
DetrImageProcessor
:
(
)
=
>
(
DetrImageProcessor
)
}
)
;
var
_base_image_processors_utils_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
src
/
base
/
image_processors_utils
.
js
"
)
;
var
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_1__
=
__webpack_require__
(
"
.
/
src
/
utils
/
tensor
.
js
"
)
;
class
DetrImageProcessor
extends
_base_image_processors_utils_js__WEBPACK_IMPORTED_MODULE_0__
.
ImageProcessor
{
async
_call
(
images
)
{
const
result
=
await
super
.
_call
(
images
)
;
const
maskSize
=
[
result
.
pixel_values
.
dims
[
0
]
64
64
]
;
const
pixel_mask
=
(
0
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_1__
.
full
)
(
maskSize
1n
)
;
return
{
.
.
.
result
pixel_mask
}
;
}
post_process_object_detection
(
.
.
.
args
)
{
return
(
0
_base_image_processors_utils_js__WEBPACK_IMPORTED_MODULE_0__
.
post_process_object_detection
)
(
.
.
.
args
)
;
}
post_process_panoptic_segmentation
(
.
.
.
args
)
{
return
(
0
_base_image_processors_utils_js__WEBPACK_IMPORTED_MODULE_0__
.
post_process_panoptic_segmentation
)
(
.
.
.
args
)
;
}
post_process_instance_segmentation
(
.
.
.
args
)
{
return
(
0
_base_image_processors_utils_js__WEBPACK_IMPORTED_MODULE_0__
.
post_process_instance_segmentation
)
(
.
.
.
args
)
;
}
}
class
DetrFeatureExtractor
extends
DetrImageProcessor
{
}
}
)
"
.
/
src
/
models
/
donut
/
image_processing_donut
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
DonutFeatureExtractor
:
(
)
=
>
(
DonutFeatureExtractor
)
DonutImageProcessor
:
(
)
=
>
(
DonutImageProcessor
)
}
)
;
var
_base_image_processors_utils_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
src
/
base
/
image_processors_utils
.
js
"
)
;
class
DonutImageProcessor
extends
_base_image_processors_utils_js__WEBPACK_IMPORTED_MODULE_0__
.
ImageProcessor
{
pad_image
(
pixelData
imgDims
padSize
options
=
{
}
)
{
const
[
imageHeight
imageWidth
imageChannels
]
=
imgDims
;
let
image_mean
=
this
.
image_mean
;
if
(
!
Array
.
isArray
(
this
.
image_mean
)
)
{
image_mean
=
new
Array
(
imageChannels
)
.
fill
(
image_mean
)
;
}
let
image_std
=
this
.
image_std
;
if
(
!
Array
.
isArray
(
image_std
)
)
{
image_std
=
new
Array
(
imageChannels
)
.
fill
(
image_mean
)
;
}
const
constant_values
=
image_mean
.
map
(
(
x
i
)
=
>
-
x
/
image_std
[
i
]
)
;
return
super
.
pad_image
(
pixelData
imgDims
padSize
{
center
:
true
constant_values
.
.
.
options
}
)
;
}
}
class
DonutFeatureExtractor
extends
DonutImageProcessor
{
}
}
)
"
.
/
src
/
models
/
dpt
/
image_processing_dpt
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
DPTFeatureExtractor
:
(
)
=
>
(
DPTFeatureExtractor
)
DPTImageProcessor
:
(
)
=
>
(
DPTImageProcessor
)
}
)
;
var
_base_image_processors_utils_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
src
/
base
/
image_processors_utils
.
js
"
)
;
class
DPTImageProcessor
extends
_base_image_processors_utils_js__WEBPACK_IMPORTED_MODULE_0__
.
ImageProcessor
{
}
class
DPTFeatureExtractor
extends
DPTImageProcessor
{
}
}
)
"
.
/
src
/
models
/
efficientnet
/
image_processing_efficientnet
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
EfficientNetImageProcessor
:
(
)
=
>
(
EfficientNetImageProcessor
)
}
)
;
var
_base_image_processors_utils_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
src
/
base
/
image_processors_utils
.
js
"
)
;
class
EfficientNetImageProcessor
extends
_base_image_processors_utils_js__WEBPACK_IMPORTED_MODULE_0__
.
ImageProcessor
{
constructor
(
config
)
{
super
(
config
)
;
this
.
include_top
=
this
.
config
.
include_top
?
?
true
;
if
(
this
.
include_top
)
{
this
.
image_std
=
this
.
image_std
.
map
(
x
=
>
x
*
x
)
;
}
}
}
}
)
"
.
/
src
/
models
/
feature_extractors
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
ASTFeatureExtractor
:
(
)
=
>
(
_audio_spectrogram_transformer_feature_extraction_audio_spectrogram_transformer_js__WEBPACK_IMPORTED_MODULE_0__
.
ASTFeatureExtractor
)
ClapFeatureExtractor
:
(
)
=
>
(
_clap_feature_extraction_clap_js__WEBPACK_IMPORTED_MODULE_1__
.
ClapFeatureExtractor
)
ImageFeatureExtractor
:
(
)
=
>
(
_base_image_processors_utils_js__WEBPACK_IMPORTED_MODULE_8__
.
ImageProcessor
)
PyAnnoteFeatureExtractor
:
(
)
=
>
(
_pyannote_feature_extraction_pyannote_js__WEBPACK_IMPORTED_MODULE_2__
.
PyAnnoteFeatureExtractor
)
SeamlessM4TFeatureExtractor
:
(
)
=
>
(
_seamless_m4t_feature_extraction_seamless_m4t_js__WEBPACK_IMPORTED_MODULE_3__
.
SeamlessM4TFeatureExtractor
)
SpeechT5FeatureExtractor
:
(
)
=
>
(
_speecht5_feature_extraction_speecht5_js__WEBPACK_IMPORTED_MODULE_4__
.
SpeechT5FeatureExtractor
)
Wav2Vec2FeatureExtractor
:
(
)
=
>
(
_wav2vec2_feature_extraction_wav2vec2_js__WEBPACK_IMPORTED_MODULE_5__
.
Wav2Vec2FeatureExtractor
)
WeSpeakerFeatureExtractor
:
(
)
=
>
(
_wespeaker_feature_extraction_wespeaker_js__WEBPACK_IMPORTED_MODULE_6__
.
WeSpeakerFeatureExtractor
)
WhisperFeatureExtractor
:
(
)
=
>
(
_whisper_feature_extraction_whisper_js__WEBPACK_IMPORTED_MODULE_7__
.
WhisperFeatureExtractor
)
}
)
;
var
_audio_spectrogram_transformer_feature_extraction_audio_spectrogram_transformer_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
src
/
models
/
audio_spectrogram_transformer
/
feature_extraction_audio_spectrogram_transformer
.
js
"
)
;
var
_clap_feature_extraction_clap_js__WEBPACK_IMPORTED_MODULE_1__
=
__webpack_require__
(
"
.
/
src
/
models
/
clap
/
feature_extraction_clap
.
js
"
)
;
var
_pyannote_feature_extraction_pyannote_js__WEBPACK_IMPORTED_MODULE_2__
=
__webpack_require__
(
"
.
/
src
/
models
/
pyannote
/
feature_extraction_pyannote
.
js
"
)
;
var
_seamless_m4t_feature_extraction_seamless_m4t_js__WEBPACK_IMPORTED_MODULE_3__
=
__webpack_require__
(
"
.
/
src
/
models
/
seamless_m4t
/
feature_extraction_seamless_m4t
.
js
"
)
;
var
_speecht5_feature_extraction_speecht5_js__WEBPACK_IMPORTED_MODULE_4__
=
__webpack_require__
(
"
.
/
src
/
models
/
speecht5
/
feature_extraction_speecht5
.
js
"
)
;
var
_wav2vec2_feature_extraction_wav2vec2_js__WEBPACK_IMPORTED_MODULE_5__
=
__webpack_require__
(
"
.
/
src
/
models
/
wav2vec2
/
feature_extraction_wav2vec2
.
js
"
)
;
var
_wespeaker_feature_extraction_wespeaker_js__WEBPACK_IMPORTED_MODULE_6__
=
__webpack_require__
(
"
.
/
src
/
models
/
wespeaker
/
feature_extraction_wespeaker
.
js
"
)
;
var
_whisper_feature_extraction_whisper_js__WEBPACK_IMPORTED_MODULE_7__
=
__webpack_require__
(
"
.
/
src
/
models
/
whisper
/
feature_extraction_whisper
.
js
"
)
;
var
_base_image_processors_utils_js__WEBPACK_IMPORTED_MODULE_8__
=
__webpack_require__
(
"
.
/
src
/
base
/
image_processors_utils
.
js
"
)
;
}
)
"
.
/
src
/
models
/
florence2
/
processing_florence2
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
Florence2Processor
:
(
)
=
>
(
Florence2Processor
)
}
)
;
var
_base_processing_utils_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
src
/
base
/
processing_utils
.
js
"
)
;
var
_auto_image_processing_auto_js__WEBPACK_IMPORTED_MODULE_1__
=
__webpack_require__
(
"
.
/
src
/
models
/
auto
/
image_processing_auto
.
js
"
)
;
var
_tokenizers_js__WEBPACK_IMPORTED_MODULE_2__
=
__webpack_require__
(
"
.
/
src
/
tokenizers
.
js
"
)
;
class
Florence2Processor
extends
_base_processing_utils_js__WEBPACK_IMPORTED_MODULE_0__
.
Processor
{
static
tokenizer_class
=
_tokenizers_js__WEBPACK_IMPORTED_MODULE_2__
.
AutoTokenizer
static
image_processor_class
=
_auto_image_processing_auto_js__WEBPACK_IMPORTED_MODULE_1__
.
AutoImageProcessor
constructor
(
config
components
)
{
super
(
config
components
)
;
const
{
tasks_answer_post_processing_type
task_prompts_without_inputs
task_prompts_with_input
}
=
this
.
image_processor
.
config
;
this
.
tasks_answer_post_processing_type
=
new
Map
(
Object
.
entries
(
tasks_answer_post_processing_type
?
?
{
}
)
)
;
this
.
task_prompts_without_inputs
=
new
Map
(
Object
.
entries
(
task_prompts_without_inputs
?
?
{
}
)
)
;
this
.
task_prompts_with_input
=
new
Map
(
Object
.
entries
(
task_prompts_with_input
?
?
{
}
)
)
;
this
.
regexes
=
{
quad_boxes
:
/
(
.
+
?
)
<
loc_
(
\
d
+
)
>
<
loc_
(
\
d
+
)
>
<
loc_
(
\
d
+
)
>
<
loc_
(
\
d
+
)
>
<
loc_
(
\
d
+
)
>
<
loc_
(
\
d
+
)
>
<
loc_
(
\
d
+
)
>
<
loc_
(
\
d
+
)
>
/
gm
bboxes
:
/
(
[
^
<
]
+
)
?
<
loc_
(
\
d
+
)
>
<
loc_
(
\
d
+
)
>
<
loc_
(
\
d
+
)
>
<
loc_
(
\
d
+
)
>
/
gm
}
this
.
size_per_bin
=
1000
;
}
construct_prompts
(
text
)
{
if
(
typeof
text
=
=
=
'
string
'
)
{
text
=
[
text
]
;
}
const
prompts
=
[
]
;
for
(
const
t
of
text
)
{
if
(
this
.
task_prompts_without_inputs
.
has
(
t
)
)
{
prompts
.
push
(
this
.
task_prompts_without_inputs
.
get
(
t
)
)
;
}
else
{
for
(
const
[
task
prompt
]
of
this
.
task_prompts_with_input
)
{
if
(
t
.
includes
(
task
)
)
{
prompts
.
push
(
prompt
.
replaceAll
(
'
{
input
}
'
t
)
.
replaceAll
(
task
'
'
)
)
;
break
;
}
}
if
(
prompts
.
length
!
=
=
text
.
length
)
{
prompts
.
push
(
t
)
;
}
}
}
return
prompts
;
}
post_process_generation
(
text
task
image_size
)
{
const
task_answer_post_processing_type
=
this
.
tasks_answer_post_processing_type
.
get
(
task
)
?
?
'
pure_text
'
;
text
=
text
.
replaceAll
(
'
<
s
>
'
'
'
)
.
replaceAll
(
'
<
/
s
>
'
'
'
)
;
let
final_answer
;
switch
(
task_answer_post_processing_type
)
{
case
'
pure_text
'
:
final_answer
=
text
;
break
;
case
'
description_with_bboxes
'
:
case
'
bboxes
'
:
case
'
phrase_grounding
'
:
case
'
ocr
'
:
const
key
=
task_answer_post_processing_type
=
=
=
'
ocr
'
?
'
quad_boxes
'
:
'
bboxes
'
;
const
matches
=
text
.
matchAll
(
this
.
regexes
[
key
]
)
;
const
labels
=
[
]
;
const
items
=
[
]
;
for
(
const
[
_
label
.
.
.
locations
]
of
matches
)
{
labels
.
push
(
label
?
label
.
trim
(
)
:
labels
.
at
(
-
1
)
?
?
'
'
)
;
items
.
push
(
locations
.
map
(
(
x
i
)
=
>
(
Number
(
x
)
+
0
.
5
)
/
this
.
size_per_bin
*
image_size
[
i
%
2
]
)
)
;
}
final_answer
=
{
labels
[
key
]
:
items
}
;
break
;
default
:
throw
new
Error
(
Task
"
{
task
}
"
(
of
type
"
{
task_answer_post_processing_type
}
"
)
not
yet
implemented
.
)
;
}
return
{
[
task
]
:
final_answer
}
}
async
_call
(
images
text
=
null
kwargs
=
{
}
)
{
if
(
!
images
&
&
!
text
)
{
throw
new
Error
(
'
Either
text
or
images
must
be
provided
'
)
;
}
const
image_inputs
=
await
this
.
image_processor
(
images
kwargs
)
;
const
text_inputs
=
text
?
this
.
tokenizer
(
text
kwargs
)
:
{
}
;
return
{
.
.
.
image_inputs
.
.
.
text_inputs
}
}
}
}
)
"
.
/
src
/
models
/
glpn
/
image_processing_glpn
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
GLPNFeatureExtractor
:
(
)
=
>
(
GLPNFeatureExtractor
)
}
)
;
var
_base_image_processors_utils_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
src
/
base
/
image_processors_utils
.
js
"
)
;
class
GLPNFeatureExtractor
extends
_base_image_processors_utils_js__WEBPACK_IMPORTED_MODULE_0__
.
ImageProcessor
{
}
}
)
"
.
/
src
/
models
/
image_processors
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
BeitFeatureExtractor
:
(
)
=
>
(
_beit_image_processing_beit_js__WEBPACK_IMPORTED_MODULE_0__
.
BeitFeatureExtractor
)
BitImageProcessor
:
(
)
=
>
(
_bit_image_processing_bit_js__WEBPACK_IMPORTED_MODULE_1__
.
BitImageProcessor
)
CLIPFeatureExtractor
:
(
)
=
>
(
_clip_image_processing_clip_js__WEBPACK_IMPORTED_MODULE_3__
.
CLIPFeatureExtractor
)
CLIPImageProcessor
:
(
)
=
>
(
_clip_image_processing_clip_js__WEBPACK_IMPORTED_MODULE_3__
.
CLIPImageProcessor
)
ChineseCLIPFeatureExtractor
:
(
)
=
>
(
_chinese_clip_image_processing_chinese_clip_js__WEBPACK_IMPORTED_MODULE_2__
.
ChineseCLIPFeatureExtractor
)
ConvNextFeatureExtractor
:
(
)
=
>
(
_convnext_image_processing_convnext_js__WEBPACK_IMPORTED_MODULE_4__
.
ConvNextFeatureExtractor
)
ConvNextImageProcessor
:
(
)
=
>
(
_convnext_image_processing_convnext_js__WEBPACK_IMPORTED_MODULE_4__
.
ConvNextImageProcessor
)
DPTFeatureExtractor
:
(
)
=
>
(
_dpt_image_processing_dpt_js__WEBPACK_IMPORTED_MODULE_8__
.
DPTFeatureExtractor
)
DPTImageProcessor
:
(
)
=
>
(
_dpt_image_processing_dpt_js__WEBPACK_IMPORTED_MODULE_8__
.
DPTImageProcessor
)
DeiTFeatureExtractor
:
(
)
=
>
(
_deit_image_processing_deit_js__WEBPACK_IMPORTED_MODULE_5__
.
DeiTFeatureExtractor
)
DeiTImageProcessor
:
(
)
=
>
(
_deit_image_processing_deit_js__WEBPACK_IMPORTED_MODULE_5__
.
DeiTImageProcessor
)
DetrFeatureExtractor
:
(
)
=
>
(
_detr_image_processing_detr_js__WEBPACK_IMPORTED_MODULE_6__
.
DetrFeatureExtractor
)
DetrImageProcessor
:
(
)
=
>
(
_detr_image_processing_detr_js__WEBPACK_IMPORTED_MODULE_6__
.
DetrImageProcessor
)
DonutFeatureExtractor
:
(
)
=
>
(
_donut_image_processing_donut_js__WEBPACK_IMPORTED_MODULE_7__
.
DonutFeatureExtractor
)
DonutImageProcessor
:
(
)
=
>
(
_donut_image_processing_donut_js__WEBPACK_IMPORTED_MODULE_7__
.
DonutImageProcessor
)
EfficientNetImageProcessor
:
(
)
=
>
(
_efficientnet_image_processing_efficientnet_js__WEBPACK_IMPORTED_MODULE_9__
.
EfficientNetImageProcessor
)
GLPNFeatureExtractor
:
(
)
=
>
(
_glpn_image_processing_glpn_js__WEBPACK_IMPORTED_MODULE_10__
.
GLPNFeatureExtractor
)
JinaCLIPImageProcessor
:
(
)
=
>
(
_jina_clip_image_processing_jina_clip_js__WEBPACK_IMPORTED_MODULE_12__
.
JinaCLIPImageProcessor
)
LlavaOnevisionImageProcessor
:
(
)
=
>
(
_llava_onevision_image_processing_llava_onevision_js__WEBPACK_IMPORTED_MODULE_13__
.
LlavaOnevisionImageProcessor
)
Mask2FormerImageProcessor
:
(
)
=
>
(
_mask2former_image_processing_mask2former_js__WEBPACK_IMPORTED_MODULE_14__
.
Mask2FormerImageProcessor
)
MaskFormerFeatureExtractor
:
(
)
=
>
(
_maskformer_image_processing_maskformer_js__WEBPACK_IMPORTED_MODULE_15__
.
MaskFormerFeatureExtractor
)
MaskFormerImageProcessor
:
(
)
=
>
(
_maskformer_image_processing_maskformer_js__WEBPACK_IMPORTED_MODULE_15__
.
MaskFormerImageProcessor
)
MobileNetV1FeatureExtractor
:
(
)
=
>
(
_mobilenet_v1_image_processing_mobilenet_v1_js__WEBPACK_IMPORTED_MODULE_16__
.
MobileNetV1FeatureExtractor
)
MobileNetV1ImageProcessor
:
(
)
=
>
(
_mobilenet_v1_image_processing_mobilenet_v1_js__WEBPACK_IMPORTED_MODULE_16__
.
MobileNetV1ImageProcessor
)
MobileNetV2FeatureExtractor
:
(
)
=
>
(
_mobilenet_v2_image_processing_mobilenet_v2_js__WEBPACK_IMPORTED_MODULE_17__
.
MobileNetV2FeatureExtractor
)
MobileNetV2ImageProcessor
:
(
)
=
>
(
_mobilenet_v2_image_processing_mobilenet_v2_js__WEBPACK_IMPORTED_MODULE_17__
.
MobileNetV2ImageProcessor
)
MobileNetV3FeatureExtractor
:
(
)
=
>
(
_mobilenet_v3_image_processing_mobilenet_v3_js__WEBPACK_IMPORTED_MODULE_18__
.
MobileNetV3FeatureExtractor
)
MobileNetV3ImageProcessor
:
(
)
=
>
(
_mobilenet_v3_image_processing_mobilenet_v3_js__WEBPACK_IMPORTED_MODULE_18__
.
MobileNetV3ImageProcessor
)
MobileNetV4FeatureExtractor
:
(
)
=
>
(
_mobilenet_v4_image_processing_mobilenet_v4_js__WEBPACK_IMPORTED_MODULE_19__
.
MobileNetV4FeatureExtractor
)
MobileNetV4ImageProcessor
:
(
)
=
>
(
_mobilenet_v4_image_processing_mobilenet_v4_js__WEBPACK_IMPORTED_MODULE_19__
.
MobileNetV4ImageProcessor
)
MobileViTFeatureExtractor
:
(
)
=
>
(
_mobilevit_image_processing_mobilevit_js__WEBPACK_IMPORTED_MODULE_20__
.
MobileViTFeatureExtractor
)
MobileViTImageProcessor
:
(
)
=
>
(
_mobilevit_image_processing_mobilevit_js__WEBPACK_IMPORTED_MODULE_20__
.
MobileViTImageProcessor
)
NougatImageProcessor
:
(
)
=
>
(
_nougat_image_processing_nougat_js__WEBPACK_IMPORTED_MODULE_21__
.
NougatImageProcessor
)
OwlViTFeatureExtractor
:
(
)
=
>
(
_owlvit_image_processing_owlvit_js__WEBPACK_IMPORTED_MODULE_23__
.
OwlViTFeatureExtractor
)
OwlViTImageProcessor
:
(
)
=
>
(
_owlvit_image_processing_owlvit_js__WEBPACK_IMPORTED_MODULE_23__
.
OwlViTImageProcessor
)
Owlv2ImageProcessor
:
(
)
=
>
(
_owlv2_image_processing_owlv2_js__WEBPACK_IMPORTED_MODULE_22__
.
Owlv2ImageProcessor
)
PvtImageProcessor
:
(
)
=
>
(
_pvt_image_processing_pvt_js__WEBPACK_IMPORTED_MODULE_24__
.
PvtImageProcessor
)
Qwen2VLImageProcessor
:
(
)
=
>
(
_qwen2_vl_image_processing_qwen2_vl_js__WEBPACK_IMPORTED_MODULE_25__
.
Qwen2VLImageProcessor
)
RTDetrImageProcessor
:
(
)
=
>
(
_rt_detr_image_processing_rt_detr_js__WEBPACK_IMPORTED_MODULE_26__
.
RTDetrImageProcessor
)
SamImageProcessor
:
(
)
=
>
(
_sam_image_processing_sam_js__WEBPACK_IMPORTED_MODULE_27__
.
SamImageProcessor
)
SegformerFeatureExtractor
:
(
)
=
>
(
_segformer_image_processing_segformer_js__WEBPACK_IMPORTED_MODULE_28__
.
SegformerFeatureExtractor
)
SegformerImageProcessor
:
(
)
=
>
(
_segformer_image_processing_segformer_js__WEBPACK_IMPORTED_MODULE_28__
.
SegformerImageProcessor
)
SiglipImageProcessor
:
(
)
=
>
(
_siglip_image_processing_siglip_js__WEBPACK_IMPORTED_MODULE_29__
.
SiglipImageProcessor
)
Swin2SRImageProcessor
:
(
)
=
>
(
_swin2sr_image_processing_swin2sr_js__WEBPACK_IMPORTED_MODULE_30__
.
Swin2SRImageProcessor
)
VLMImageProcessor
:
(
)
=
>
(
_janus_image_processing_janus_js__WEBPACK_IMPORTED_MODULE_11__
.
VLMImageProcessor
)
ViTFeatureExtractor
:
(
)
=
>
(
_vit_image_processing_vit_js__WEBPACK_IMPORTED_MODULE_31__
.
ViTFeatureExtractor
)
ViTImageProcessor
:
(
)
=
>
(
_vit_image_processing_vit_js__WEBPACK_IMPORTED_MODULE_31__
.
ViTImageProcessor
)
VitMatteImageProcessor
:
(
)
=
>
(
_vitmatte_image_processing_vitmatte_js__WEBPACK_IMPORTED_MODULE_32__
.
VitMatteImageProcessor
)
VitPoseImageProcessor
:
(
)
=
>
(
_vitpose_image_processing_vitpose_js__WEBPACK_IMPORTED_MODULE_33__
.
VitPoseImageProcessor
)
YolosFeatureExtractor
:
(
)
=
>
(
_yolos_image_processing_yolos_js__WEBPACK_IMPORTED_MODULE_34__
.
YolosFeatureExtractor
)
YolosImageProcessor
:
(
)
=
>
(
_yolos_image_processing_yolos_js__WEBPACK_IMPORTED_MODULE_34__
.
YolosImageProcessor
)
}
)
;
var
_beit_image_processing_beit_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
src
/
models
/
beit
/
image_processing_beit
.
js
"
)
;
var
_bit_image_processing_bit_js__WEBPACK_IMPORTED_MODULE_1__
=
__webpack_require__
(
"
.
/
src
/
models
/
bit
/
image_processing_bit
.
js
"
)
;
var
_chinese_clip_image_processing_chinese_clip_js__WEBPACK_IMPORTED_MODULE_2__
=
__webpack_require__
(
"
.
/
src
/
models
/
chinese_clip
/
image_processing_chinese_clip
.
js
"
)
;
var
_clip_image_processing_clip_js__WEBPACK_IMPORTED_MODULE_3__
=
__webpack_require__
(
"
.
/
src
/
models
/
clip
/
image_processing_clip
.
js
"
)
;
var
_convnext_image_processing_convnext_js__WEBPACK_IMPORTED_MODULE_4__
=
__webpack_require__
(
"
.
/
src
/
models
/
convnext
/
image_processing_convnext
.
js
"
)
;
var
_deit_image_processing_deit_js__WEBPACK_IMPORTED_MODULE_5__
=
__webpack_require__
(
"
.
/
src
/
models
/
deit
/
image_processing_deit
.
js
"
)
;
var
_detr_image_processing_detr_js__WEBPACK_IMPORTED_MODULE_6__
=
__webpack_require__
(
"
.
/
src
/
models
/
detr
/
image_processing_detr
.
js
"
)
;
var
_donut_image_processing_donut_js__WEBPACK_IMPORTED_MODULE_7__
=
__webpack_require__
(
"
.
/
src
/
models
/
donut
/
image_processing_donut
.
js
"
)
;
var
_dpt_image_processing_dpt_js__WEBPACK_IMPORTED_MODULE_8__
=
__webpack_require__
(
"
.
/
src
/
models
/
dpt
/
image_processing_dpt
.
js
"
)
;
var
_efficientnet_image_processing_efficientnet_js__WEBPACK_IMPORTED_MODULE_9__
=
__webpack_require__
(
"
.
/
src
/
models
/
efficientnet
/
image_processing_efficientnet
.
js
"
)
;
var
_glpn_image_processing_glpn_js__WEBPACK_IMPORTED_MODULE_10__
=
__webpack_require__
(
"
.
/
src
/
models
/
glpn
/
image_processing_glpn
.
js
"
)
;
var
_janus_image_processing_janus_js__WEBPACK_IMPORTED_MODULE_11__
=
__webpack_require__
(
"
.
/
src
/
models
/
janus
/
image_processing_janus
.
js
"
)
;
var
_jina_clip_image_processing_jina_clip_js__WEBPACK_IMPORTED_MODULE_12__
=
__webpack_require__
(
"
.
/
src
/
models
/
jina_clip
/
image_processing_jina_clip
.
js
"
)
;
var
_llava_onevision_image_processing_llava_onevision_js__WEBPACK_IMPORTED_MODULE_13__
=
__webpack_require__
(
"
.
/
src
/
models
/
llava_onevision
/
image_processing_llava_onevision
.
js
"
)
;
var
_mask2former_image_processing_mask2former_js__WEBPACK_IMPORTED_MODULE_14__
=
__webpack_require__
(
"
.
/
src
/
models
/
mask2former
/
image_processing_mask2former
.
js
"
)
;
var
_maskformer_image_processing_maskformer_js__WEBPACK_IMPORTED_MODULE_15__
=
__webpack_require__
(
"
.
/
src
/
models
/
maskformer
/
image_processing_maskformer
.
js
"
)
;
var
_mobilenet_v1_image_processing_mobilenet_v1_js__WEBPACK_IMPORTED_MODULE_16__
=
__webpack_require__
(
"
.
/
src
/
models
/
mobilenet_v1
/
image_processing_mobilenet_v1
.
js
"
)
;
var
_mobilenet_v2_image_processing_mobilenet_v2_js__WEBPACK_IMPORTED_MODULE_17__
=
__webpack_require__
(
"
.
/
src
/
models
/
mobilenet_v2
/
image_processing_mobilenet_v2
.
js
"
)
;
var
_mobilenet_v3_image_processing_mobilenet_v3_js__WEBPACK_IMPORTED_MODULE_18__
=
__webpack_require__
(
"
.
/
src
/
models
/
mobilenet_v3
/
image_processing_mobilenet_v3
.
js
"
)
;
var
_mobilenet_v4_image_processing_mobilenet_v4_js__WEBPACK_IMPORTED_MODULE_19__
=
__webpack_require__
(
"
.
/
src
/
models
/
mobilenet_v4
/
image_processing_mobilenet_v4
.
js
"
)
;
var
_mobilevit_image_processing_mobilevit_js__WEBPACK_IMPORTED_MODULE_20__
=
__webpack_require__
(
"
.
/
src
/
models
/
mobilevit
/
image_processing_mobilevit
.
js
"
)
;
var
_nougat_image_processing_nougat_js__WEBPACK_IMPORTED_MODULE_21__
=
__webpack_require__
(
"
.
/
src
/
models
/
nougat
/
image_processing_nougat
.
js
"
)
;
var
_owlv2_image_processing_owlv2_js__WEBPACK_IMPORTED_MODULE_22__
=
__webpack_require__
(
"
.
/
src
/
models
/
owlv2
/
image_processing_owlv2
.
js
"
)
;
var
_owlvit_image_processing_owlvit_js__WEBPACK_IMPORTED_MODULE_23__
=
__webpack_require__
(
"
.
/
src
/
models
/
owlvit
/
image_processing_owlvit
.
js
"
)
;
var
_pvt_image_processing_pvt_js__WEBPACK_IMPORTED_MODULE_24__
=
__webpack_require__
(
"
.
/
src
/
models
/
pvt
/
image_processing_pvt
.
js
"
)
;
var
_qwen2_vl_image_processing_qwen2_vl_js__WEBPACK_IMPORTED_MODULE_25__
=
__webpack_require__
(
"
.
/
src
/
models
/
qwen2_vl
/
image_processing_qwen2_vl
.
js
"
)
;
var
_rt_detr_image_processing_rt_detr_js__WEBPACK_IMPORTED_MODULE_26__
=
__webpack_require__
(
"
.
/
src
/
models
/
rt_detr
/
image_processing_rt_detr
.
js
"
)
;
var
_sam_image_processing_sam_js__WEBPACK_IMPORTED_MODULE_27__
=
__webpack_require__
(
"
.
/
src
/
models
/
sam
/
image_processing_sam
.
js
"
)
;
var
_segformer_image_processing_segformer_js__WEBPACK_IMPORTED_MODULE_28__
=
__webpack_require__
(
"
.
/
src
/
models
/
segformer
/
image_processing_segformer
.
js
"
)
;
var
_siglip_image_processing_siglip_js__WEBPACK_IMPORTED_MODULE_29__
=
__webpack_require__
(
"
.
/
src
/
models
/
siglip
/
image_processing_siglip
.
js
"
)
;
var
_swin2sr_image_processing_swin2sr_js__WEBPACK_IMPORTED_MODULE_30__
=
__webpack_require__
(
"
.
/
src
/
models
/
swin2sr
/
image_processing_swin2sr
.
js
"
)
;
var
_vit_image_processing_vit_js__WEBPACK_IMPORTED_MODULE_31__
=
__webpack_require__
(
"
.
/
src
/
models
/
vit
/
image_processing_vit
.
js
"
)
;
var
_vitmatte_image_processing_vitmatte_js__WEBPACK_IMPORTED_MODULE_32__
=
__webpack_require__
(
"
.
/
src
/
models
/
vitmatte
/
image_processing_vitmatte
.
js
"
)
;
var
_vitpose_image_processing_vitpose_js__WEBPACK_IMPORTED_MODULE_33__
=
__webpack_require__
(
"
.
/
src
/
models
/
vitpose
/
image_processing_vitpose
.
js
"
)
;
var
_yolos_image_processing_yolos_js__WEBPACK_IMPORTED_MODULE_34__
=
__webpack_require__
(
"
.
/
src
/
models
/
yolos
/
image_processing_yolos
.
js
"
)
;
}
)
"
.
/
src
/
models
/
janus
/
image_processing_janus
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
VLMImageProcessor
:
(
)
=
>
(
VLMImageProcessor
)
}
)
;
var
_base_image_processors_utils_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
src
/
base
/
image_processors_utils
.
js
"
)
;
class
VLMImageProcessor
extends
_base_image_processors_utils_js__WEBPACK_IMPORTED_MODULE_0__
.
ImageProcessor
{
constructor
(
config
)
{
super
(
{
do_pad
:
true
pad_size
:
{
width
:
config
.
image_size
height
:
config
.
image_size
}
.
.
.
config
}
)
;
this
.
constant_values
=
this
.
config
.
background_color
.
map
(
x
=
>
x
*
this
.
rescale_factor
)
}
pad_image
(
pixelData
imgDims
padSize
options
)
{
return
super
.
pad_image
(
pixelData
imgDims
padSize
{
constant_values
:
this
.
constant_values
center
:
true
.
.
.
options
}
)
;
}
}
}
)
"
.
/
src
/
models
/
janus
/
processing_janus
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
VLChatProcessor
:
(
)
=
>
(
VLChatProcessor
)
}
)
;
var
_base_processing_utils_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
src
/
base
/
processing_utils
.
js
"
)
;
var
_auto_image_processing_auto_js__WEBPACK_IMPORTED_MODULE_1__
=
__webpack_require__
(
"
.
/
src
/
models
/
auto
/
image_processing_auto
.
js
"
)
;
var
_tokenizers_js__WEBPACK_IMPORTED_MODULE_2__
=
__webpack_require__
(
"
.
/
src
/
tokenizers
.
js
"
)
;
var
_utils_core_js__WEBPACK_IMPORTED_MODULE_3__
=
__webpack_require__
(
"
.
/
src
/
utils
/
core
.
js
"
)
;
var
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_4__
=
__webpack_require__
(
"
.
/
src
/
utils
/
tensor
.
js
"
)
;
var
_utils_image_js__WEBPACK_IMPORTED_MODULE_5__
=
__webpack_require__
(
"
.
/
src
/
utils
/
image
.
js
"
)
;
class
VLChatProcessor
extends
_base_processing_utils_js__WEBPACK_IMPORTED_MODULE_0__
.
Processor
{
static
image_processor_class
=
_auto_image_processing_auto_js__WEBPACK_IMPORTED_MODULE_1__
.
AutoImageProcessor
static
tokenizer_class
=
_tokenizers_js__WEBPACK_IMPORTED_MODULE_2__
.
AutoTokenizer
static
uses_processor_config
=
true
;
constructor
(
config
components
)
{
super
(
config
components
)
;
this
.
image_tag
=
this
.
config
.
image_tag
;
this
.
image_start_tag
=
this
.
config
.
image_start_tag
;
this
.
image_end_tag
=
this
.
config
.
image_end_tag
;
this
.
num_image_tokens
=
this
.
config
.
num_image_tokens
;
}
async
_call
(
conversation
{
images
=
null
chat_template
=
"
default
"
}
=
{
}
)
{
if
(
!
images
)
{
images
=
await
Promise
.
all
(
conversation
.
filter
(
(
msg
)
=
>
msg
.
images
)
.
flatMap
(
(
msg
)
=
>
msg
.
images
)
.
map
(
(
img
)
=
>
_utils_image_js__WEBPACK_IMPORTED_MODULE_5__
.
RawImage
.
read
(
img
)
)
)
;
}
else
if
(
!
Array
.
isArray
(
images
)
)
{
images
=
[
images
]
;
}
const
tokenizer
=
this
.
tokenizer
;
const
result
=
tokenizer
.
apply_chat_template
(
conversation
{
tokenize
:
false
add_generation_prompt
:
true
chat_template
}
)
;
const
encode
=
(
text
)
=
>
tokenizer
.
encode
(
text
{
add_special_tokens
:
false
}
)
;
const
parts
=
(
(
result
)
)
.
split
(
this
.
image_tag
)
;
const
num_images
=
parts
.
length
-
1
;
if
(
images
.
length
!
=
=
num_images
)
{
throw
new
Error
(
Number
of
images
provided
(
{
images
.
length
}
)
does
not
match
number
of
"
{
this
.
image_tag
}
"
image
tags
(
{
num_images
}
)
)
;
}
const
[
image_placeholder_tag_id
image_start_tag_id
image_end_tag_id
]
=
tokenizer
.
model
.
convert_tokens_to_ids
(
[
this
.
image_tag
this
.
image_start_tag
this
.
image_end_tag
]
)
;
let
input_ids
=
encode
(
parts
[
0
]
)
;
let
images_seq_mask
=
new
Array
(
input_ids
.
length
)
.
fill
(
false
)
;
for
(
let
i
=
1
;
i
<
parts
.
length
;
+
+
i
)
{
const
placeholder_image_tokens
=
new
Array
(
this
.
num_image_tokens
)
.
fill
(
image_placeholder_tag_id
)
;
const
tokens
=
encode
(
parts
[
i
]
)
;
input_ids
=
(
0
_utils_core_js__WEBPACK_IMPORTED_MODULE_3__
.
mergeArrays
)
(
input_ids
[
image_start_tag_id
]
placeholder_image_tokens
[
image_end_tag_id
]
tokens
)
;
const
image_mask
=
new
Array
(
this
.
num_image_tokens
)
.
fill
(
true
)
;
images_seq_mask
=
(
0
_utils_core_js__WEBPACK_IMPORTED_MODULE_3__
.
mergeArrays
)
(
images_seq_mask
[
false
]
image_mask
[
false
]
new
Array
(
tokens
.
length
)
.
fill
(
false
)
)
;
}
const
dims
=
[
1
input_ids
.
length
]
;
const
final
=
{
input_ids
:
new
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_4__
.
Tensor
(
'
int64
'
input_ids
dims
)
attention_mask
:
new
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_4__
.
Tensor
(
'
int64
'
new
Array
(
input_ids
.
length
)
.
fill
(
1
)
dims
)
images_seq_mask
:
new
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_4__
.
Tensor
(
'
bool
'
images_seq_mask
dims
)
images_emb_mask
:
new
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_4__
.
Tensor
(
'
bool
'
new
Array
(
num_images
*
this
.
num_image_tokens
)
.
fill
(
true
)
[
1
num_images
this
.
num_image_tokens
]
)
}
if
(
images
&
&
images
.
length
>
0
)
{
const
image_inputs
=
await
this
.
image_processor
(
images
)
;
image_inputs
.
pixel_values
.
unsqueeze_
(
0
)
;
return
{
.
.
.
final
.
.
.
image_inputs
}
;
}
return
final
;
}
}
}
)
"
.
/
src
/
models
/
jina_clip
/
image_processing_jina_clip
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
JinaCLIPImageProcessor
:
(
)
=
>
(
JinaCLIPImageProcessor
)
}
)
;
var
_base_image_processors_utils_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
src
/
base
/
image_processors_utils
.
js
"
)
;
class
JinaCLIPImageProcessor
extends
_base_image_processors_utils_js__WEBPACK_IMPORTED_MODULE_0__
.
ImageProcessor
{
constructor
(
config
)
{
const
{
resize_mode
fill_color
interpolation
size
.
.
.
other
}
=
config
;
const
new_size
=
resize_mode
=
=
=
'
squash
'
?
{
width
:
size
height
:
size
}
:
resize_mode
=
=
=
'
shortest
'
?
{
shortest_edge
:
size
}
:
{
longest_edge
:
size
}
;
const
resample
=
interpolation
=
=
=
'
bicubic
'
?
3
:
2
;
super
(
{
.
.
.
other
size
:
new_size
resample
do_center_crop
:
true
crop_size
:
size
do_normalize
:
true
}
)
;
}
}
}
)
"
.
/
src
/
models
/
jina_clip
/
processing_jina_clip
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
JinaCLIPProcessor
:
(
)
=
>
(
JinaCLIPProcessor
)
}
)
;
var
_base_processing_utils_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
src
/
base
/
processing_utils
.
js
"
)
;
var
_auto_image_processing_auto_js__WEBPACK_IMPORTED_MODULE_1__
=
__webpack_require__
(
"
.
/
src
/
models
/
auto
/
image_processing_auto
.
js
"
)
;
var
_tokenizers_js__WEBPACK_IMPORTED_MODULE_2__
=
__webpack_require__
(
"
.
/
src
/
tokenizers
.
js
"
)
;
class
JinaCLIPProcessor
extends
_base_processing_utils_js__WEBPACK_IMPORTED_MODULE_0__
.
Processor
{
static
tokenizer_class
=
_tokenizers_js__WEBPACK_IMPORTED_MODULE_2__
.
AutoTokenizer
static
image_processor_class
=
_auto_image_processing_auto_js__WEBPACK_IMPORTED_MODULE_1__
.
AutoImageProcessor
async
_call
(
text
=
null
images
=
null
kwargs
=
{
}
)
{
if
(
!
text
&
&
!
images
)
{
throw
new
Error
(
'
Either
text
or
images
must
be
provided
'
)
;
}
const
text_inputs
=
text
?
this
.
tokenizer
(
text
kwargs
)
:
{
}
;
const
image_inputs
=
images
?
await
this
.
image_processor
(
images
kwargs
)
:
{
}
;
return
{
.
.
.
text_inputs
.
.
.
image_inputs
}
}
}
}
)
"
.
/
src
/
models
/
llava_onevision
/
image_processing_llava_onevision
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
LlavaOnevisionImageProcessor
:
(
)
=
>
(
LlavaOnevisionImageProcessor
)
}
)
;
var
_base_image_processors_utils_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
src
/
base
/
image_processors_utils
.
js
"
)
;
class
LlavaOnevisionImageProcessor
extends
_base_image_processors_utils_js__WEBPACK_IMPORTED_MODULE_0__
.
ImageProcessor
{
}
}
)
"
.
/
src
/
models
/
mask2former
/
image_processing_mask2former
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
Mask2FormerImageProcessor
:
(
)
=
>
(
Mask2FormerImageProcessor
)
}
)
;
var
_maskformer_image_processing_maskformer_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
src
/
models
/
maskformer
/
image_processing_maskformer
.
js
"
)
;
class
Mask2FormerImageProcessor
extends
_maskformer_image_processing_maskformer_js__WEBPACK_IMPORTED_MODULE_0__
.
MaskFormerImageProcessor
{
}
}
)
"
.
/
src
/
models
/
maskformer
/
image_processing_maskformer
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
MaskFormerFeatureExtractor
:
(
)
=
>
(
MaskFormerFeatureExtractor
)
MaskFormerImageProcessor
:
(
)
=
>
(
MaskFormerImageProcessor
)
}
)
;
var
_base_image_processors_utils_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
src
/
base
/
image_processors_utils
.
js
"
)
;
class
MaskFormerImageProcessor
extends
_base_image_processors_utils_js__WEBPACK_IMPORTED_MODULE_0__
.
ImageProcessor
{
post_process_panoptic_segmentation
(
.
.
.
args
)
{
return
(
0
_base_image_processors_utils_js__WEBPACK_IMPORTED_MODULE_0__
.
post_process_panoptic_segmentation
)
(
.
.
.
args
)
;
}
post_process_instance_segmentation
(
.
.
.
args
)
{
return
(
0
_base_image_processors_utils_js__WEBPACK_IMPORTED_MODULE_0__
.
post_process_instance_segmentation
)
(
.
.
.
args
)
;
}
}
class
MaskFormerFeatureExtractor
extends
MaskFormerImageProcessor
{
}
}
)
"
.
/
src
/
models
/
mgp_str
/
processing_mgp_str
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
MgpstrProcessor
:
(
)
=
>
(
MgpstrProcessor
)
}
)
;
var
_base_processing_utils_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
src
/
base
/
processing_utils
.
js
"
)
;
var
_auto_image_processing_auto_js__WEBPACK_IMPORTED_MODULE_1__
=
__webpack_require__
(
"
.
/
src
/
models
/
auto
/
image_processing_auto
.
js
"
)
;
var
_tokenizers_js__WEBPACK_IMPORTED_MODULE_2__
=
__webpack_require__
(
"
.
/
src
/
tokenizers
.
js
"
)
;
var
_utils_maths_js__WEBPACK_IMPORTED_MODULE_3__
=
__webpack_require__
(
"
.
/
src
/
utils
/
maths
.
js
"
)
;
const
DECODE_TYPE_MAPPING
=
{
'
char
'
:
[
'
char_decode
'
1
]
'
bpe
'
:
[
'
bpe_decode
'
2
]
'
wp
'
:
[
'
wp_decode
'
102
]
}
class
MgpstrProcessor
extends
_base_processing_utils_js__WEBPACK_IMPORTED_MODULE_0__
.
Processor
{
static
tokenizer_class
=
_tokenizers_js__WEBPACK_IMPORTED_MODULE_2__
.
AutoTokenizer
static
image_processor_class
=
_auto_image_processing_auto_js__WEBPACK_IMPORTED_MODULE_1__
.
AutoImageProcessor
get
char_tokenizer
(
)
{
return
this
.
components
.
char_tokenizer
;
}
get
bpe_tokenizer
(
)
{
return
this
.
components
.
bpe_tokenizer
;
}
get
wp_tokenizer
(
)
{
return
this
.
components
.
wp_tokenizer
;
}
_decode_helper
(
pred_logits
format
)
{
if
(
!
DECODE_TYPE_MAPPING
.
hasOwnProperty
(
format
)
)
{
throw
new
Error
(
Format
{
format
}
is
not
supported
.
)
;
}
const
[
decoder_name
eos_token
]
=
DECODE_TYPE_MAPPING
[
format
]
;
const
decoder
=
this
[
decoder_name
]
.
bind
(
this
)
;
const
[
batch_size
batch_max_length
]
=
pred_logits
.
dims
;
const
conf_scores
=
[
]
;
const
all_ids
=
[
]
;
const
pred_logits_list
=
pred_logits
.
tolist
(
)
;
for
(
let
i
=
0
;
i
<
batch_size
;
+
+
i
)
{
const
logits
=
pred_logits_list
[
i
]
;
const
ids
=
[
]
;
const
scores
=
[
]
;
for
(
let
j
=
1
;
j
<
batch_max_length
;
+
+
j
)
{
const
[
max_prob
max_prob_index
]
=
(
0
_utils_maths_js__WEBPACK_IMPORTED_MODULE_3__
.
max
)
(
(
0
_utils_maths_js__WEBPACK_IMPORTED_MODULE_3__
.
softmax
)
(
logits
[
j
]
)
)
;
scores
.
push
(
max_prob
)
;
if
(
max_prob_index
=
=
eos_token
)
{
break
;
}
ids
.
push
(
max_prob_index
)
;
}
const
confidence_score
=
scores
.
length
>
0
?
scores
.
reduce
(
(
a
b
)
=
>
a
*
b
1
)
:
0
;
all_ids
.
push
(
ids
)
;
conf_scores
.
push
(
confidence_score
)
;
}
const
decoded
=
decoder
(
all_ids
)
;
return
[
decoded
conf_scores
]
;
}
char_decode
(
sequences
)
{
return
this
.
char_tokenizer
.
batch_decode
(
sequences
)
.
map
(
str
=
>
str
.
replaceAll
(
'
'
'
'
)
)
;
}
bpe_decode
(
sequences
)
{
return
this
.
bpe_tokenizer
.
batch_decode
(
sequences
)
}
wp_decode
(
sequences
)
{
return
this
.
wp_tokenizer
.
batch_decode
(
sequences
)
.
map
(
str
=
>
str
.
replaceAll
(
'
'
'
'
)
)
;
}
batch_decode
(
[
char_logits
bpe_logits
wp_logits
]
)
{
const
[
char_preds
char_scores
]
=
this
.
_decode_helper
(
char_logits
'
char
'
)
;
const
[
bpe_preds
bpe_scores
]
=
this
.
_decode_helper
(
bpe_logits
'
bpe
'
)
;
const
[
wp_preds
wp_scores
]
=
this
.
_decode_helper
(
wp_logits
'
wp
'
)
;
const
generated_text
=
[
]
;
const
scores
=
[
]
;
for
(
let
i
=
0
;
i
<
char_preds
.
length
;
+
+
i
)
{
const
[
max_score
max_score_index
]
=
(
0
_utils_maths_js__WEBPACK_IMPORTED_MODULE_3__
.
max
)
(
[
char_scores
[
i
]
bpe_scores
[
i
]
wp_scores
[
i
]
]
)
;
generated_text
.
push
(
[
char_preds
[
i
]
bpe_preds
[
i
]
wp_preds
[
i
]
]
[
max_score_index
]
)
;
scores
.
push
(
max_score
)
;
}
return
{
generated_text
scores
char_preds
bpe_preds
wp_preds
}
}
static
async
from_pretrained
(
.
.
.
args
)
{
const
base
=
await
super
.
from_pretrained
(
.
.
.
args
)
;
const
bpe_tokenizer
=
await
_tokenizers_js__WEBPACK_IMPORTED_MODULE_2__
.
AutoTokenizer
.
from_pretrained
(
"
Xenova
/
gpt2
"
)
const
wp_tokenizer
=
await
_tokenizers_js__WEBPACK_IMPORTED_MODULE_2__
.
AutoTokenizer
.
from_pretrained
(
"
Xenova
/
bert
-
base
-
uncased
"
)
base
.
components
=
{
image_processor
:
base
.
image_processor
char_tokenizer
:
base
.
tokenizer
bpe_tokenizer
:
bpe_tokenizer
wp_tokenizer
:
wp_tokenizer
}
return
base
;
}
async
_call
(
images
text
=
null
)
{
const
result
=
await
this
.
image_processor
(
images
)
;
if
(
text
)
{
result
.
labels
=
this
.
tokenizer
(
text
)
.
input_ids
}
return
result
;
}
}
}
)
"
.
/
src
/
models
/
mobilenet_v1
/
image_processing_mobilenet_v1
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
MobileNetV1FeatureExtractor
:
(
)
=
>
(
MobileNetV1FeatureExtractor
)
MobileNetV1ImageProcessor
:
(
)
=
>
(
MobileNetV1ImageProcessor
)
}
)
;
var
_base_image_processors_utils_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
src
/
base
/
image_processors_utils
.
js
"
)
;
class
MobileNetV1ImageProcessor
extends
_base_image_processors_utils_js__WEBPACK_IMPORTED_MODULE_0__
.
ImageProcessor
{
}
class
MobileNetV1FeatureExtractor
extends
MobileNetV1ImageProcessor
{
}
}
)
"
.
/
src
/
models
/
mobilenet_v2
/
image_processing_mobilenet_v2
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
MobileNetV2FeatureExtractor
:
(
)
=
>
(
MobileNetV2FeatureExtractor
)
MobileNetV2ImageProcessor
:
(
)
=
>
(
MobileNetV2ImageProcessor
)
}
)
;
var
_base_image_processors_utils_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
src
/
base
/
image_processors_utils
.
js
"
)
;
class
MobileNetV2ImageProcessor
extends
_base_image_processors_utils_js__WEBPACK_IMPORTED_MODULE_0__
.
ImageProcessor
{
}
class
MobileNetV2FeatureExtractor
extends
MobileNetV2ImageProcessor
{
}
}
)
"
.
/
src
/
models
/
mobilenet_v3
/
image_processing_mobilenet_v3
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
MobileNetV3FeatureExtractor
:
(
)
=
>
(
MobileNetV3FeatureExtractor
)
MobileNetV3ImageProcessor
:
(
)
=
>
(
MobileNetV3ImageProcessor
)
}
)
;
var
_base_image_processors_utils_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
src
/
base
/
image_processors_utils
.
js
"
)
;
class
MobileNetV3ImageProcessor
extends
_base_image_processors_utils_js__WEBPACK_IMPORTED_MODULE_0__
.
ImageProcessor
{
}
class
MobileNetV3FeatureExtractor
extends
MobileNetV3ImageProcessor
{
}
}
)
"
.
/
src
/
models
/
mobilenet_v4
/
image_processing_mobilenet_v4
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
MobileNetV4FeatureExtractor
:
(
)
=
>
(
MobileNetV4FeatureExtractor
)
MobileNetV4ImageProcessor
:
(
)
=
>
(
MobileNetV4ImageProcessor
)
}
)
;
var
_base_image_processors_utils_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
src
/
base
/
image_processors_utils
.
js
"
)
;
class
MobileNetV4ImageProcessor
extends
_base_image_processors_utils_js__WEBPACK_IMPORTED_MODULE_0__
.
ImageProcessor
{
}
class
MobileNetV4FeatureExtractor
extends
MobileNetV4ImageProcessor
{
}
}
)
"
.
/
src
/
models
/
mobilevit
/
image_processing_mobilevit
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
MobileViTFeatureExtractor
:
(
)
=
>
(
MobileViTFeatureExtractor
)
MobileViTImageProcessor
:
(
)
=
>
(
MobileViTImageProcessor
)
}
)
;
var
_base_image_processors_utils_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
src
/
base
/
image_processors_utils
.
js
"
)
;
class
MobileViTImageProcessor
extends
_base_image_processors_utils_js__WEBPACK_IMPORTED_MODULE_0__
.
ImageProcessor
{
}
class
MobileViTFeatureExtractor
extends
MobileViTImageProcessor
{
}
}
)
"
.
/
src
/
models
/
nougat
/
image_processing_nougat
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
NougatImageProcessor
:
(
)
=
>
(
NougatImageProcessor
)
}
)
;
var
_donut_image_processing_donut_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
src
/
models
/
donut
/
image_processing_donut
.
js
"
)
;
class
NougatImageProcessor
extends
_donut_image_processing_donut_js__WEBPACK_IMPORTED_MODULE_0__
.
DonutImageProcessor
{
}
}
)
"
.
/
src
/
models
/
owlv2
/
image_processing_owlv2
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
Owlv2ImageProcessor
:
(
)
=
>
(
Owlv2ImageProcessor
)
}
)
;
var
_owlvit_image_processing_owlvit_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
src
/
models
/
owlvit
/
image_processing_owlvit
.
js
"
)
;
class
Owlv2ImageProcessor
extends
_owlvit_image_processing_owlvit_js__WEBPACK_IMPORTED_MODULE_0__
.
OwlViTImageProcessor
{
}
}
)
"
.
/
src
/
models
/
owlvit
/
image_processing_owlvit
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
OwlViTFeatureExtractor
:
(
)
=
>
(
OwlViTFeatureExtractor
)
OwlViTImageProcessor
:
(
)
=
>
(
OwlViTImageProcessor
)
}
)
;
var
_base_image_processors_utils_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
src
/
base
/
image_processors_utils
.
js
"
)
;
class
OwlViTImageProcessor
extends
_base_image_processors_utils_js__WEBPACK_IMPORTED_MODULE_0__
.
ImageProcessor
{
post_process_object_detection
(
.
.
.
args
)
{
return
(
0
_base_image_processors_utils_js__WEBPACK_IMPORTED_MODULE_0__
.
post_process_object_detection
)
(
.
.
.
args
)
;
}
}
class
OwlViTFeatureExtractor
extends
OwlViTImageProcessor
{
}
}
)
"
.
/
src
/
models
/
owlvit
/
processing_owlvit
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
OwlViTProcessor
:
(
)
=
>
(
OwlViTProcessor
)
}
)
;
var
_base_processing_utils_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
src
/
base
/
processing_utils
.
js
"
)
;
var
_auto_image_processing_auto_js__WEBPACK_IMPORTED_MODULE_1__
=
__webpack_require__
(
"
.
/
src
/
models
/
auto
/
image_processing_auto
.
js
"
)
;
var
_tokenizers_js__WEBPACK_IMPORTED_MODULE_2__
=
__webpack_require__
(
"
.
/
src
/
tokenizers
.
js
"
)
;
class
OwlViTProcessor
extends
_base_processing_utils_js__WEBPACK_IMPORTED_MODULE_0__
.
Processor
{
static
tokenizer_class
=
_tokenizers_js__WEBPACK_IMPORTED_MODULE_2__
.
AutoTokenizer
static
image_processor_class
=
_auto_image_processing_auto_js__WEBPACK_IMPORTED_MODULE_1__
.
AutoImageProcessor
}
}
)
"
.
/
src
/
models
/
processors
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
Florence2Processor
:
(
)
=
>
(
_florence2_processing_florence2_js__WEBPACK_IMPORTED_MODULE_0__
.
Florence2Processor
)
JinaCLIPProcessor
:
(
)
=
>
(
_jina_clip_processing_jina_clip_js__WEBPACK_IMPORTED_MODULE_3__
.
JinaCLIPProcessor
)
MgpstrProcessor
:
(
)
=
>
(
_mgp_str_processing_mgp_str_js__WEBPACK_IMPORTED_MODULE_1__
.
MgpstrProcessor
)
OwlViTProcessor
:
(
)
=
>
(
_owlvit_processing_owlvit_js__WEBPACK_IMPORTED_MODULE_4__
.
OwlViTProcessor
)
PyAnnoteProcessor
:
(
)
=
>
(
_pyannote_processing_pyannote_js__WEBPACK_IMPORTED_MODULE_5__
.
PyAnnoteProcessor
)
Qwen2VLProcessor
:
(
)
=
>
(
_qwen2_vl_processing_qwen2_vl_js__WEBPACK_IMPORTED_MODULE_6__
.
Qwen2VLProcessor
)
SamProcessor
:
(
)
=
>
(
_sam_processing_sam_js__WEBPACK_IMPORTED_MODULE_7__
.
SamProcessor
)
SpeechT5Processor
:
(
)
=
>
(
_speecht5_processing_speecht5_js__WEBPACK_IMPORTED_MODULE_8__
.
SpeechT5Processor
)
VLChatProcessor
:
(
)
=
>
(
_janus_processing_janus_js__WEBPACK_IMPORTED_MODULE_2__
.
VLChatProcessor
)
Wav2Vec2ProcessorWithLM
:
(
)
=
>
(
_wav2vec2_processing_wav2vec2_js__WEBPACK_IMPORTED_MODULE_9__
.
Wav2Vec2ProcessorWithLM
)
WhisperProcessor
:
(
)
=
>
(
_whisper_processing_whisper_js__WEBPACK_IMPORTED_MODULE_10__
.
WhisperProcessor
)
}
)
;
var
_florence2_processing_florence2_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
src
/
models
/
florence2
/
processing_florence2
.
js
"
)
;
var
_mgp_str_processing_mgp_str_js__WEBPACK_IMPORTED_MODULE_1__
=
__webpack_require__
(
"
.
/
src
/
models
/
mgp_str
/
processing_mgp_str
.
js
"
)
;
var
_janus_processing_janus_js__WEBPACK_IMPORTED_MODULE_2__
=
__webpack_require__
(
"
.
/
src
/
models
/
janus
/
processing_janus
.
js
"
)
;
var
_jina_clip_processing_jina_clip_js__WEBPACK_IMPORTED_MODULE_3__
=
__webpack_require__
(
"
.
/
src
/
models
/
jina_clip
/
processing_jina_clip
.
js
"
)
;
var
_owlvit_processing_owlvit_js__WEBPACK_IMPORTED_MODULE_4__
=
__webpack_require__
(
"
.
/
src
/
models
/
owlvit
/
processing_owlvit
.
js
"
)
;
var
_pyannote_processing_pyannote_js__WEBPACK_IMPORTED_MODULE_5__
=
__webpack_require__
(
"
.
/
src
/
models
/
pyannote
/
processing_pyannote
.
js
"
)
;
var
_qwen2_vl_processing_qwen2_vl_js__WEBPACK_IMPORTED_MODULE_6__
=
__webpack_require__
(
"
.
/
src
/
models
/
qwen2_vl
/
processing_qwen2_vl
.
js
"
)
;
var
_sam_processing_sam_js__WEBPACK_IMPORTED_MODULE_7__
=
__webpack_require__
(
"
.
/
src
/
models
/
sam
/
processing_sam
.
js
"
)
;
var
_speecht5_processing_speecht5_js__WEBPACK_IMPORTED_MODULE_8__
=
__webpack_require__
(
"
.
/
src
/
models
/
speecht5
/
processing_speecht5
.
js
"
)
;
var
_wav2vec2_processing_wav2vec2_js__WEBPACK_IMPORTED_MODULE_9__
=
__webpack_require__
(
"
.
/
src
/
models
/
wav2vec2
/
processing_wav2vec2
.
js
"
)
;
var
_whisper_processing_whisper_js__WEBPACK_IMPORTED_MODULE_10__
=
__webpack_require__
(
"
.
/
src
/
models
/
whisper
/
processing_whisper
.
js
"
)
;
}
)
"
.
/
src
/
models
/
pvt
/
image_processing_pvt
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
PvtImageProcessor
:
(
)
=
>
(
PvtImageProcessor
)
}
)
;
var
_base_image_processors_utils_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
src
/
base
/
image_processors_utils
.
js
"
)
;
class
PvtImageProcessor
extends
_base_image_processors_utils_js__WEBPACK_IMPORTED_MODULE_0__
.
ImageProcessor
{
}
}
)
"
.
/
src
/
models
/
pyannote
/
feature_extraction_pyannote
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
PyAnnoteFeatureExtractor
:
(
)
=
>
(
PyAnnoteFeatureExtractor
)
}
)
;
var
_base_feature_extraction_utils_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
src
/
base
/
feature_extraction_utils
.
js
"
)
;
var
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_1__
=
__webpack_require__
(
"
.
/
src
/
utils
/
tensor
.
js
"
)
;
class
PyAnnoteFeatureExtractor
extends
_base_feature_extraction_utils_js__WEBPACK_IMPORTED_MODULE_0__
.
FeatureExtractor
{
async
_call
(
audio
)
{
(
0
_base_feature_extraction_utils_js__WEBPACK_IMPORTED_MODULE_0__
.
validate_audio_inputs
)
(
audio
'
PyAnnoteFeatureExtractor
'
)
;
if
(
audio
instanceof
Float64Array
)
{
audio
=
new
Float32Array
(
audio
)
;
}
const
shape
=
[
1
1
audio
.
length
]
;
return
{
input_values
:
new
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_1__
.
Tensor
(
'
float32
'
audio
shape
)
}
;
}
}
}
)
"
.
/
src
/
models
/
pyannote
/
processing_pyannote
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
PyAnnoteProcessor
:
(
)
=
>
(
PyAnnoteProcessor
)
}
)
;
var
_base_processing_utils_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
src
/
base
/
processing_utils
.
js
"
)
;
var
_auto_feature_extraction_auto_js__WEBPACK_IMPORTED_MODULE_1__
=
__webpack_require__
(
"
.
/
src
/
models
/
auto
/
feature_extraction_auto
.
js
"
)
;
var
_utils_maths_js__WEBPACK_IMPORTED_MODULE_2__
=
__webpack_require__
(
"
.
/
src
/
utils
/
maths
.
js
"
)
;
class
PyAnnoteProcessor
extends
_base_processing_utils_js__WEBPACK_IMPORTED_MODULE_0__
.
Processor
{
static
feature_extractor_class
=
_auto_feature_extraction_auto_js__WEBPACK_IMPORTED_MODULE_1__
.
AutoFeatureExtractor
async
_call
(
audio
)
{
return
await
this
.
feature_extractor
(
audio
)
}
samples_to_frames
(
samples
)
{
return
(
(
samples
-
this
.
config
.
offset
)
/
this
.
config
.
step
)
;
}
post_process_speaker_diarization
(
logits
num_samples
)
{
const
ratio
=
(
num_samples
/
this
.
samples_to_frames
(
num_samples
)
)
/
this
.
config
.
sampling_rate
;
const
results
=
[
]
;
for
(
const
scores
of
logits
.
tolist
(
)
)
{
const
accumulated_segments
=
[
]
;
let
current_speaker
=
-
1
;
for
(
let
i
=
0
;
i
<
scores
.
length
;
+
+
i
)
{
const
probabilities
=
(
0
_utils_maths_js__WEBPACK_IMPORTED_MODULE_2__
.
softmax
)
(
scores
[
i
]
)
;
const
[
score
id
]
=
(
0
_utils_maths_js__WEBPACK_IMPORTED_MODULE_2__
.
max
)
(
probabilities
)
;
const
[
start
end
]
=
[
i
i
+
1
]
;
if
(
id
!
=
=
current_speaker
)
{
current_speaker
=
id
;
accumulated_segments
.
push
(
{
id
start
end
score
}
)
;
}
else
{
accumulated_segments
.
at
(
-
1
)
.
end
=
end
;
accumulated_segments
.
at
(
-
1
)
.
score
+
=
score
;
}
}
results
.
push
(
accumulated_segments
.
map
(
(
{
id
start
end
score
}
)
=
>
(
{
id
start
:
start
*
ratio
end
:
end
*
ratio
confidence
:
score
/
(
end
-
start
)
}
)
)
)
;
}
return
results
;
}
}
}
)
"
.
/
src
/
models
/
qwen2_vl
/
image_processing_qwen2_vl
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
Qwen2VLImageProcessor
:
(
)
=
>
(
Qwen2VLImageProcessor
)
}
)
;
var
_base_image_processors_utils_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
src
/
base
/
image_processors_utils
.
js
"
)
;
var
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_1__
=
__webpack_require__
(
"
.
/
src
/
utils
/
tensor
.
js
"
)
;
class
Qwen2VLImageProcessor
extends
_base_image_processors_utils_js__WEBPACK_IMPORTED_MODULE_0__
.
ImageProcessor
{
async
_call
(
images
.
.
.
args
)
{
const
{
pixel_values
original_sizes
reshaped_input_sizes
}
=
await
super
.
_call
(
images
.
.
.
args
)
;
let
patches
=
pixel_values
;
const
{
temporal_patch_size
merge_size
patch_size
}
=
this
.
config
;
if
(
patches
.
dims
[
0
]
=
=
=
1
)
{
patches
=
(
0
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_1__
.
cat
)
(
Array
.
from
(
{
length
:
temporal_patch_size
}
(
)
=
>
patches
)
0
)
;
}
const
grid_t
=
patches
.
dims
[
0
]
/
temporal_patch_size
;
const
channel
=
patches
.
dims
[
1
]
;
const
grid_h
=
Math
.
floor
(
patches
.
dims
[
2
]
/
patch_size
)
;
const
grid_w
=
Math
.
floor
(
patches
.
dims
[
3
]
/
patch_size
)
;
const
flatten_patches
=
patches
.
view
(
grid_t
temporal_patch_size
channel
Math
.
floor
(
grid_h
/
merge_size
)
merge_size
patch_size
Math
.
floor
(
grid_w
/
merge_size
)
merge_size
patch_size
)
.
permute
(
0
3
6
4
7
2
1
5
8
)
.
view
(
grid_t
*
grid_h
*
grid_w
channel
*
temporal_patch_size
*
patch_size
*
patch_size
)
const
image_grid_thw
=
new
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_1__
.
Tensor
(
'
int64
'
[
grid_t
grid_h
grid_w
]
[
1
3
]
)
;
return
{
pixel_values
:
flatten_patches
image_grid_thw
original_sizes
reshaped_input_sizes
}
}
}
}
)
"
.
/
src
/
models
/
qwen2_vl
/
processing_qwen2_vl
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
Qwen2VLProcessor
:
(
)
=
>
(
Qwen2VLProcessor
)
}
)
;
var
_base_processing_utils_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
src
/
base
/
processing_utils
.
js
"
)
;
var
_auto_image_processing_auto_js__WEBPACK_IMPORTED_MODULE_1__
=
__webpack_require__
(
"
.
/
src
/
models
/
auto
/
image_processing_auto
.
js
"
)
;
var
_tokenizers_js__WEBPACK_IMPORTED_MODULE_2__
=
__webpack_require__
(
"
.
/
src
/
tokenizers
.
js
"
)
;
var
_utils_image_js__WEBPACK_IMPORTED_MODULE_3__
=
__webpack_require__
(
"
.
/
src
/
utils
/
image
.
js
"
)
;
class
Qwen2VLProcessor
extends
_base_processing_utils_js__WEBPACK_IMPORTED_MODULE_0__
.
Processor
{
static
image_processor_class
=
_auto_image_processing_auto_js__WEBPACK_IMPORTED_MODULE_1__
.
AutoImageProcessor
static
tokenizer_class
=
_tokenizers_js__WEBPACK_IMPORTED_MODULE_2__
.
AutoTokenizer
async
_call
(
text
images
=
null
.
.
.
args
)
{
if
(
!
Array
.
isArray
(
text
)
)
{
text
=
[
text
]
;
}
let
image_inputs
image_grid_thw
;
if
(
images
)
{
image_inputs
=
await
this
.
image_processor
(
images
)
;
image_grid_thw
=
image_inputs
.
image_grid_thw
;
}
if
(
image_grid_thw
)
{
let
merge_length
=
this
.
image_processor
.
config
.
merge_size
*
*
2
;
let
index
=
0
;
const
image_grid_thw_list
=
image_grid_thw
.
tolist
(
)
;
text
=
text
.
map
(
t
=
>
{
while
(
t
.
includes
(
"
<
|
image_pad
|
>
"
)
)
{
const
prod
=
Number
(
image_grid_thw_list
[
index
+
+
]
.
reduce
(
(
a
b
)
=
>
a
*
b
1n
)
)
;
t
=
t
.
replace
(
"
<
|
image_pad
|
>
"
"
<
|
placeholder
|
>
"
.
repeat
(
Math
.
floor
(
prod
/
merge_length
)
)
)
;
}
return
t
.
replaceAll
(
"
<
|
placeholder
|
>
"
"
<
|
image_pad
|
>
"
)
;
}
)
;
}
const
text_inputs
=
this
.
tokenizer
(
text
)
;
return
{
.
.
.
text_inputs
.
.
.
image_inputs
}
}
}
}
)
"
.
/
src
/
models
/
rt_detr
/
image_processing_rt_detr
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
RTDetrImageProcessor
:
(
)
=
>
(
RTDetrImageProcessor
)
}
)
;
var
_base_image_processors_utils_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
src
/
base
/
image_processors_utils
.
js
"
)
;
class
RTDetrImageProcessor
extends
_base_image_processors_utils_js__WEBPACK_IMPORTED_MODULE_0__
.
ImageProcessor
{
post_process_object_detection
(
.
.
.
args
)
{
return
(
0
_base_image_processors_utils_js__WEBPACK_IMPORTED_MODULE_0__
.
post_process_object_detection
)
(
.
.
.
args
)
;
}
}
}
)
"
.
/
src
/
models
/
sam
/
image_processing_sam
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
SamImageProcessor
:
(
)
=
>
(
SamImageProcessor
)
}
)
;
var
_base_image_processors_utils_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
src
/
base
/
image_processors_utils
.
js
"
)
;
var
_utils_core_js__WEBPACK_IMPORTED_MODULE_1__
=
__webpack_require__
(
"
.
/
src
/
utils
/
core
.
js
"
)
;
var
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_2__
=
__webpack_require__
(
"
.
/
src
/
utils
/
tensor
.
js
"
)
;
class
SamImageProcessor
extends
_base_image_processors_utils_js__WEBPACK_IMPORTED_MODULE_0__
.
ImageProcessor
{
reshape_input_points
(
input_points
original_sizes
reshaped_input_sizes
is_bounding_box
=
false
)
{
input_points
=
structuredClone
(
input_points
)
;
let
shape
=
(
0
_utils_core_js__WEBPACK_IMPORTED_MODULE_1__
.
calculateDimensions
)
(
input_points
)
;
if
(
shape
.
length
=
=
=
3
)
{
if
(
!
is_bounding_box
)
{
shape
=
[
1
.
.
.
shape
]
;
}
input_points
=
[
input_points
]
;
}
else
if
(
shape
.
length
!
=
=
4
)
{
throw
Error
(
"
The
input_points
must
be
a
4D
tensor
of
shape
batch_size
point_batch_size
nb_points_per_image
2
.
"
)
}
for
(
let
i
=
0
;
i
<
input_points
.
length
;
+
+
i
)
{
let
originalImageSize
=
original_sizes
[
i
]
;
let
reshapedImageSize
=
reshaped_input_sizes
[
i
]
;
let
resizeFactors
=
[
reshapedImageSize
[
0
]
/
originalImageSize
[
0
]
reshapedImageSize
[
1
]
/
originalImageSize
[
1
]
]
for
(
let
j
=
0
;
j
<
input_points
[
i
]
.
length
;
+
+
j
)
{
for
(
let
k
=
0
;
k
<
input_points
[
i
]
[
j
]
.
length
;
+
+
k
)
{
for
(
let
w
=
0
;
w
<
input_points
[
i
]
[
j
]
[
k
]
.
length
;
+
+
w
)
{
input_points
[
i
]
[
j
]
[
k
]
[
w
]
*
=
resizeFactors
[
w
%
2
]
;
}
}
}
}
return
new
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_2__
.
Tensor
(
'
float32
'
Float32Array
.
from
(
input_points
.
flat
(
Infinity
)
)
shape
)
}
add_input_labels
(
input_labels
input_points
)
{
let
shape
=
(
0
_utils_core_js__WEBPACK_IMPORTED_MODULE_1__
.
calculateDimensions
)
(
input_labels
)
;
if
(
shape
.
length
=
=
=
2
)
{
shape
=
[
1
.
.
.
shape
]
;
input_labels
=
[
input_labels
]
;
}
else
if
(
shape
.
length
!
=
=
3
)
{
throw
Error
(
"
The
input_points
must
be
a
4D
tensor
of
shape
batch_size
point_batch_size
nb_points_per_image
2
.
"
)
}
if
(
shape
.
some
(
(
x
i
)
=
>
x
!
=
=
input_points
.
dims
[
i
]
)
)
{
throw
Error
(
The
first
{
shape
.
length
}
dimensions
of
'
input_points
'
and
'
input_labels
'
must
be
the
same
.
)
}
return
new
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_2__
.
Tensor
(
'
int64
'
input_labels
.
flat
(
Infinity
)
.
map
(
BigInt
)
shape
)
}
async
_call
(
images
{
input_points
=
null
input_labels
=
null
input_boxes
=
null
}
=
{
}
)
{
const
processed
=
await
super
.
_call
(
images
)
;
if
(
input_points
)
{
processed
.
input_points
=
this
.
reshape_input_points
(
input_points
processed
.
original_sizes
processed
.
reshaped_input_sizes
)
;
}
if
(
input_labels
)
{
if
(
!
processed
.
input_points
)
{
throw
Error
(
"
input_points
must
be
provided
if
input_labels
are
provided
.
"
)
}
processed
.
input_labels
=
this
.
add_input_labels
(
input_labels
processed
.
input_points
)
;
}
if
(
input_boxes
)
{
processed
.
input_boxes
=
this
.
reshape_input_points
(
input_boxes
processed
.
original_sizes
processed
.
reshaped_input_sizes
true
)
;
}
return
processed
;
}
async
post_process_masks
(
masks
original_sizes
reshaped_input_sizes
{
mask_threshold
=
0
.
0
binarize
=
true
pad_size
=
null
}
=
{
}
)
{
const
output_masks
=
[
]
;
pad_size
=
pad_size
?
?
this
.
pad_size
;
const
target_image_size
=
[
pad_size
.
height
pad_size
.
width
]
;
for
(
let
i
=
0
;
i
<
original_sizes
.
length
;
+
+
i
)
{
const
original_size
=
original_sizes
[
i
]
;
const
reshaped_input_size
=
reshaped_input_sizes
[
i
]
;
let
interpolated_mask
=
(
await
(
0
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_2__
.
interpolate_4d
)
(
masks
[
i
]
{
mode
:
'
bilinear
'
size
:
target_image_size
}
)
)
;
interpolated_mask
=
interpolated_mask
.
slice
(
null
null
[
0
reshaped_input_size
[
0
]
]
[
0
reshaped_input_size
[
1
]
]
)
;
interpolated_mask
=
(
await
(
0
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_2__
.
interpolate_4d
)
(
interpolated_mask
{
mode
:
'
bilinear
'
size
:
original_size
}
)
)
;
if
(
binarize
)
{
const
data
=
interpolated_mask
.
data
;
const
binarizedMaskData
=
new
Uint8Array
(
data
.
length
)
;
for
(
let
i
=
0
;
i
<
data
.
length
;
+
+
i
)
{
if
(
data
[
i
]
>
mask_threshold
)
{
binarizedMaskData
[
i
]
=
1
;
}
}
interpolated_mask
=
new
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_2__
.
Tensor
(
'
bool
'
binarizedMaskData
interpolated_mask
.
dims
)
}
output_masks
.
push
(
interpolated_mask
)
;
}
return
output_masks
;
}
generate_crop_boxes
(
image
target_size
{
crop_n_layers
=
0
overlap_ratio
=
512
/
1500
points_per_crop
=
32
crop_n_points_downscale_factor
=
1
}
=
{
}
)
{
}
}
}
)
"
.
/
src
/
models
/
sam
/
processing_sam
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
SamProcessor
:
(
)
=
>
(
SamProcessor
)
}
)
;
var
_base_processing_utils_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
src
/
base
/
processing_utils
.
js
"
)
;
var
_auto_image_processing_auto_js__WEBPACK_IMPORTED_MODULE_1__
=
__webpack_require__
(
"
.
/
src
/
models
/
auto
/
image_processing_auto
.
js
"
)
;
class
SamProcessor
extends
_base_processing_utils_js__WEBPACK_IMPORTED_MODULE_0__
.
Processor
{
static
image_processor_class
=
_auto_image_processing_auto_js__WEBPACK_IMPORTED_MODULE_1__
.
AutoImageProcessor
async
_call
(
.
.
.
args
)
{
return
await
this
.
image_processor
(
.
.
.
args
)
;
}
post_process_masks
(
.
.
.
args
)
{
return
this
.
image_processor
.
post_process_masks
(
.
.
.
args
)
;
}
reshape_input_points
(
.
.
.
args
)
{
return
this
.
image_processor
.
reshape_input_points
(
.
.
.
args
)
;
}
}
}
)
"
.
/
src
/
models
/
seamless_m4t
/
feature_extraction_seamless_m4t
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
SeamlessM4TFeatureExtractor
:
(
)
=
>
(
SeamlessM4TFeatureExtractor
)
}
)
;
var
_base_feature_extraction_utils_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
src
/
base
/
feature_extraction_utils
.
js
"
)
;
var
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_1__
=
__webpack_require__
(
"
.
/
src
/
utils
/
tensor
.
js
"
)
;
var
_utils_audio_js__WEBPACK_IMPORTED_MODULE_2__
=
__webpack_require__
(
"
.
/
src
/
utils
/
audio
.
js
"
)
;
class
SeamlessM4TFeatureExtractor
extends
_base_feature_extraction_utils_js__WEBPACK_IMPORTED_MODULE_0__
.
FeatureExtractor
{
constructor
(
config
)
{
super
(
config
)
;
const
sampling_rate
=
this
.
config
.
sampling_rate
;
const
mel_filters
=
(
0
_utils_audio_js__WEBPACK_IMPORTED_MODULE_2__
.
mel_filter_bank
)
(
256
this
.
config
.
num_mel_bins
20
Math
.
floor
(
sampling_rate
/
2
)
sampling_rate
null
"
kaldi
"
true
)
;
for
(
let
i
=
0
;
i
<
mel_filters
.
length
;
+
+
i
)
{
mel_filters
[
i
]
.
push
(
0
)
;
}
this
.
mel_filters
=
mel_filters
;
this
.
window
=
(
0
_utils_audio_js__WEBPACK_IMPORTED_MODULE_2__
.
window_function
)
(
400
'
povey
'
{
periodic
:
false
}
)
}
async
_extract_fbank_features
(
waveform
max_length
)
{
waveform
=
waveform
.
map
(
(
x
)
=
>
x
*
32768
)
return
(
0
_utils_audio_js__WEBPACK_IMPORTED_MODULE_2__
.
spectrogram
)
(
waveform
this
.
window
400
160
{
fft_length
:
512
power
:
2
.
0
center
:
false
preemphasis
:
0
.
97
mel_filters
:
this
.
mel_filters
log_mel
:
'
log
'
mel_floor
:
1
.
192092955078125e
-
07
remove_dc_offset
:
true
max_num_frames
:
max_length
transpose
:
true
}
)
}
async
_call
(
audio
{
padding
=
true
pad_to_multiple_of
=
2
do_normalize_per_mel_bins
=
true
return_attention_mask
=
true
}
=
{
}
)
{
(
0
_base_feature_extraction_utils_js__WEBPACK_IMPORTED_MODULE_0__
.
validate_audio_inputs
)
(
audio
'
SeamlessM4TFeatureExtractor
'
)
;
let
features
=
await
this
.
_extract_fbank_features
(
audio
this
.
config
.
max_length
)
;
if
(
do_normalize_per_mel_bins
)
{
const
[
num_features
feature_size
]
=
features
.
dims
;
const
data
=
features
.
data
;
for
(
let
i
=
0
;
i
<
feature_size
;
+
+
i
)
{
let
sum
=
0
;
for
(
let
j
=
0
;
j
<
num_features
;
+
+
j
)
{
sum
+
=
data
[
j
*
feature_size
+
i
]
;
}
const
mean
=
sum
/
num_features
;
let
variance
=
0
;
for
(
let
j
=
0
;
j
<
num_features
;
+
+
j
)
{
variance
+
=
(
data
[
j
*
feature_size
+
i
]
-
mean
)
*
*
2
;
}
variance
/
=
num_features
-
1
;
const
std
=
Math
.
sqrt
(
variance
+
1e
-
7
)
;
for
(
let
j
=
0
;
j
<
num_features
;
+
+
j
)
{
const
index
=
j
*
feature_size
+
i
;
data
[
index
]
=
(
data
[
index
]
-
mean
)
/
std
;
}
}
}
let
padded_attention_mask
;
if
(
padding
)
{
const
[
num_frames
num_channels
]
=
features
.
dims
;
const
data
=
(
features
.
data
)
;
const
pad_size
=
num_frames
%
pad_to_multiple_of
;
if
(
pad_size
>
0
)
{
const
padded_data
=
new
Float32Array
(
num_channels
*
(
num_frames
+
pad_size
)
)
;
padded_data
.
set
(
data
)
padded_data
.
fill
(
this
.
config
.
padding_value
data
.
length
)
const
numPaddedFrames
=
num_frames
+
pad_size
;
features
=
new
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_1__
.
Tensor
(
features
.
type
padded_data
[
numPaddedFrames
num_channels
]
)
if
(
return_attention_mask
)
{
padded_attention_mask
=
new
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_1__
.
Tensor
(
'
int64
'
new
BigInt64Array
(
numPaddedFrames
)
[
1
numPaddedFrames
]
)
padded_attention_mask
.
data
.
fill
(
1n
0
num_frames
)
;
}
}
}
const
[
num_frames
num_channels
]
=
features
.
dims
;
const
stride
=
this
.
config
.
stride
;
const
remainder
=
num_frames
%
stride
;
if
(
remainder
!
=
=
0
)
{
throw
new
Error
(
The
number
of
frames
(
{
num_frames
}
)
must
be
a
multiple
of
the
stride
(
{
stride
}
)
.
)
}
const
input_features
=
features
.
view
(
1
Math
.
floor
(
num_frames
/
stride
)
num_channels
*
stride
)
;
const
result
=
{
input_features
}
if
(
return_attention_mask
)
{
const
reshapedNumFrames
=
input_features
.
dims
[
1
]
;
const
attention_mask_data
=
new
BigInt64Array
(
reshapedNumFrames
)
;
if
(
padded_attention_mask
)
{
const
padded_attention_mask_data
=
padded_attention_mask
.
data
;
for
(
let
i
=
1
j
=
0
;
i
<
num_frames
;
i
+
=
stride
+
+
j
)
{
attention_mask_data
[
j
]
=
padded_attention_mask_data
[
i
]
;
}
}
else
{
attention_mask_data
.
fill
(
1n
)
;
}
result
.
attention_mask
=
new
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_1__
.
Tensor
(
'
int64
'
attention_mask_data
[
1
reshapedNumFrames
]
)
;
}
return
result
;
}
}
}
)
"
.
/
src
/
models
/
segformer
/
image_processing_segformer
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
SegformerFeatureExtractor
:
(
)
=
>
(
SegformerFeatureExtractor
)
SegformerImageProcessor
:
(
)
=
>
(
SegformerImageProcessor
)
}
)
;
var
_base_image_processors_utils_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
src
/
base
/
image_processors_utils
.
js
"
)
;
class
SegformerImageProcessor
extends
_base_image_processors_utils_js__WEBPACK_IMPORTED_MODULE_0__
.
ImageProcessor
{
post_process_semantic_segmentation
(
.
.
.
args
)
{
return
(
0
_base_image_processors_utils_js__WEBPACK_IMPORTED_MODULE_0__
.
post_process_semantic_segmentation
)
(
.
.
.
args
)
;
}
}
class
SegformerFeatureExtractor
extends
SegformerImageProcessor
{
}
}
)
"
.
/
src
/
models
/
siglip
/
image_processing_siglip
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
SiglipImageProcessor
:
(
)
=
>
(
SiglipImageProcessor
)
}
)
;
var
_base_image_processors_utils_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
src
/
base
/
image_processors_utils
.
js
"
)
;
class
SiglipImageProcessor
extends
_base_image_processors_utils_js__WEBPACK_IMPORTED_MODULE_0__
.
ImageProcessor
{
}
}
)
"
.
/
src
/
models
/
speecht5
/
feature_extraction_speecht5
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
SpeechT5FeatureExtractor
:
(
)
=
>
(
SpeechT5FeatureExtractor
)
}
)
;
var
_base_feature_extraction_utils_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
src
/
base
/
feature_extraction_utils
.
js
"
)
;
class
SpeechT5FeatureExtractor
extends
_base_feature_extraction_utils_js__WEBPACK_IMPORTED_MODULE_0__
.
FeatureExtractor
{
}
}
)
"
.
/
src
/
models
/
speecht5
/
processing_speecht5
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
SpeechT5Processor
:
(
)
=
>
(
SpeechT5Processor
)
}
)
;
var
_base_processing_utils_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
src
/
base
/
processing_utils
.
js
"
)
;
var
_tokenizers_js__WEBPACK_IMPORTED_MODULE_1__
=
__webpack_require__
(
"
.
/
src
/
tokenizers
.
js
"
)
;
var
_auto_feature_extraction_auto_js__WEBPACK_IMPORTED_MODULE_2__
=
__webpack_require__
(
"
.
/
src
/
models
/
auto
/
feature_extraction_auto
.
js
"
)
;
class
SpeechT5Processor
extends
_base_processing_utils_js__WEBPACK_IMPORTED_MODULE_0__
.
Processor
{
static
tokenizer_class
=
_tokenizers_js__WEBPACK_IMPORTED_MODULE_1__
.
AutoTokenizer
static
feature_extractor_class
=
_auto_feature_extraction_auto_js__WEBPACK_IMPORTED_MODULE_2__
.
AutoFeatureExtractor
async
_call
(
input
)
{
return
await
this
.
feature_extractor
(
input
)
}
}
}
)
"
.
/
src
/
models
/
swin2sr
/
image_processing_swin2sr
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
Swin2SRImageProcessor
:
(
)
=
>
(
Swin2SRImageProcessor
)
}
)
;
var
_base_image_processors_utils_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
src
/
base
/
image_processors_utils
.
js
"
)
;
class
Swin2SRImageProcessor
extends
_base_image_processors_utils_js__WEBPACK_IMPORTED_MODULE_0__
.
ImageProcessor
{
pad_image
(
pixelData
imgDims
padSize
options
=
{
}
)
{
const
[
imageHeight
imageWidth
imageChannels
]
=
imgDims
;
return
super
.
pad_image
(
pixelData
imgDims
{
width
:
imageWidth
+
(
padSize
-
imageWidth
%
padSize
)
%
padSize
height
:
imageHeight
+
(
padSize
-
imageHeight
%
padSize
)
%
padSize
}
{
mode
:
'
symmetric
'
center
:
false
constant_values
:
-
1
.
.
.
options
}
)
}
}
}
)
"
.
/
src
/
models
/
vit
/
image_processing_vit
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
ViTFeatureExtractor
:
(
)
=
>
(
ViTFeatureExtractor
)
ViTImageProcessor
:
(
)
=
>
(
ViTImageProcessor
)
}
)
;
var
_base_image_processors_utils_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
src
/
base
/
image_processors_utils
.
js
"
)
;
class
ViTImageProcessor
extends
_base_image_processors_utils_js__WEBPACK_IMPORTED_MODULE_0__
.
ImageProcessor
{
}
class
ViTFeatureExtractor
extends
ViTImageProcessor
{
}
}
)
"
.
/
src
/
models
/
vitmatte
/
image_processing_vitmatte
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
VitMatteImageProcessor
:
(
)
=
>
(
VitMatteImageProcessor
)
}
)
;
var
_base_image_processors_utils_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
src
/
base
/
image_processors_utils
.
js
"
)
;
var
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_1__
=
__webpack_require__
(
"
.
/
src
/
utils
/
tensor
.
js
"
)
;
class
VitMatteImageProcessor
extends
_base_image_processors_utils_js__WEBPACK_IMPORTED_MODULE_0__
.
ImageProcessor
{
async
_call
(
images
trimaps
)
{
if
(
!
Array
.
isArray
(
images
)
)
{
images
=
[
images
]
;
}
if
(
!
Array
.
isArray
(
trimaps
)
)
{
trimaps
=
[
trimaps
]
;
}
const
imageData
=
await
Promise
.
all
(
images
.
map
(
x
=
>
this
.
preprocess
(
x
)
)
)
;
const
trimapData
=
await
Promise
.
all
(
trimaps
.
map
(
x
=
>
this
.
preprocess
(
x
{
do_normalize
:
false
do_convert_rgb
:
false
do_convert_grayscale
:
true
}
)
)
)
;
const
pixel_values
=
(
0
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_1__
.
stack
)
(
imageData
.
map
(
(
x
i
)
=
>
(
0
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_1__
.
cat
)
(
[
x
.
pixel_values
trimapData
[
i
]
.
pixel_values
]
0
)
)
0
)
;
return
{
pixel_values
original_sizes
:
imageData
.
map
(
x
=
>
x
.
original_size
)
reshaped_input_sizes
:
imageData
.
map
(
x
=
>
x
.
reshaped_input_size
)
}
}
}
}
)
"
.
/
src
/
models
/
vitpose
/
image_processing_vitpose
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
VitPoseImageProcessor
:
(
)
=
>
(
VitPoseImageProcessor
)
}
)
;
var
_base_image_processors_utils_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
src
/
base
/
image_processors_utils
.
js
"
)
;
class
VitPoseImageProcessor
extends
_base_image_processors_utils_js__WEBPACK_IMPORTED_MODULE_0__
.
ImageProcessor
{
post_process_pose_estimation
(
outputs
boxes
{
threshold
=
null
}
=
{
}
)
{
const
heatmaps
=
outputs
.
tolist
(
)
;
const
[
batch_size
num_classes
height
width
]
=
outputs
.
dims
;
const
results
=
[
]
;
for
(
let
b
=
0
;
b
<
batch_size
;
+
+
b
)
{
const
heatmap
=
heatmaps
[
b
]
;
const
bboxes
=
boxes
[
b
]
;
const
batch_results
=
[
]
;
for
(
let
n
=
0
;
n
<
bboxes
.
length
;
+
+
n
)
{
const
bbox
=
bboxes
[
n
]
;
const
keypoints
=
[
]
;
const
scores
=
[
]
;
const
labels
=
[
]
;
const
xScale
=
bbox
.
at
(
-
2
)
/
width
;
const
yScale
=
bbox
.
at
(
-
1
)
/
height
;
for
(
let
c
=
0
;
c
<
heatmap
.
length
;
+
+
c
)
{
let
[
xWeightedSum
yWeightedSum
]
=
[
0
0
]
;
let
sum
=
0
;
let
score
=
-
Infinity
;
const
row
=
heatmap
[
c
]
;
for
(
let
y
=
0
;
y
<
row
.
length
;
+
+
y
)
{
const
col
=
row
[
y
]
;
for
(
let
x
=
0
;
x
<
col
.
length
;
+
+
x
)
{
const
value
=
col
[
x
]
;
sum
+
=
value
;
score
=
Math
.
max
(
score
value
)
;
xWeightedSum
+
=
(
x
+
0
.
5
)
*
value
;
yWeightedSum
+
=
(
y
)
*
value
;
}
}
if
(
threshold
!
=
null
&
&
score
<
threshold
)
continue
;
const
keypoint
=
[
xScale
*
xWeightedSum
/
sum
yScale
*
yWeightedSum
/
sum
]
keypoints
.
push
(
keypoint
)
;
labels
.
push
(
c
)
;
scores
.
push
(
score
)
;
}
batch_results
.
push
(
{
bbox
scores
labels
keypoints
}
)
;
}
results
.
push
(
batch_results
)
;
}
return
results
;
}
}
}
)
"
.
/
src
/
models
/
wav2vec2
/
feature_extraction_wav2vec2
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
Wav2Vec2FeatureExtractor
:
(
)
=
>
(
Wav2Vec2FeatureExtractor
)
}
)
;
var
_base_feature_extraction_utils_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
src
/
base
/
feature_extraction_utils
.
js
"
)
;
var
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_1__
=
__webpack_require__
(
"
.
/
src
/
utils
/
tensor
.
js
"
)
;
class
Wav2Vec2FeatureExtractor
extends
_base_feature_extraction_utils_js__WEBPACK_IMPORTED_MODULE_0__
.
FeatureExtractor
{
_zero_mean_unit_var_norm
(
input_values
)
{
const
sum
=
input_values
.
reduce
(
(
a
b
)
=
>
a
+
b
0
)
;
const
mean
=
sum
/
input_values
.
length
;
const
variance
=
input_values
.
reduce
(
(
a
b
)
=
>
a
+
(
b
-
mean
)
*
*
2
0
)
/
input_values
.
length
;
return
input_values
.
map
(
x
=
>
(
x
-
mean
)
/
Math
.
sqrt
(
variance
+
1e
-
7
)
)
;
}
async
_call
(
audio
)
{
(
0
_base_feature_extraction_utils_js__WEBPACK_IMPORTED_MODULE_0__
.
validate_audio_inputs
)
(
audio
'
Wav2Vec2FeatureExtractor
'
)
;
if
(
audio
instanceof
Float64Array
)
{
audio
=
new
Float32Array
(
audio
)
;
}
let
input_values
=
audio
;
if
(
this
.
config
.
do_normalize
)
{
input_values
=
this
.
_zero_mean_unit_var_norm
(
input_values
)
;
}
const
shape
=
[
1
input_values
.
length
]
;
return
{
input_values
:
new
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_1__
.
Tensor
(
'
float32
'
input_values
shape
)
attention_mask
:
new
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_1__
.
Tensor
(
'
int64
'
new
BigInt64Array
(
input_values
.
length
)
.
fill
(
1n
)
shape
)
}
;
}
}
}
)
"
.
/
src
/
models
/
wav2vec2
/
processing_wav2vec2
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
Wav2Vec2ProcessorWithLM
:
(
)
=
>
(
Wav2Vec2ProcessorWithLM
)
}
)
;
var
_base_processing_utils_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
src
/
base
/
processing_utils
.
js
"
)
;
var
_auto_feature_extraction_auto_js__WEBPACK_IMPORTED_MODULE_1__
=
__webpack_require__
(
"
.
/
src
/
models
/
auto
/
feature_extraction_auto
.
js
"
)
;
class
Wav2Vec2ProcessorWithLM
extends
_base_processing_utils_js__WEBPACK_IMPORTED_MODULE_0__
.
Processor
{
static
feature_extractor_class
=
_auto_feature_extraction_auto_js__WEBPACK_IMPORTED_MODULE_1__
.
AutoFeatureExtractor
async
_call
(
audio
)
{
return
await
this
.
feature_extractor
(
audio
)
}
}
}
)
"
.
/
src
/
models
/
wespeaker
/
feature_extraction_wespeaker
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
WeSpeakerFeatureExtractor
:
(
)
=
>
(
WeSpeakerFeatureExtractor
)
}
)
;
var
_base_feature_extraction_utils_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
src
/
base
/
feature_extraction_utils
.
js
"
)
;
var
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_1__
=
__webpack_require__
(
"
.
/
src
/
utils
/
tensor
.
js
"
)
;
var
_utils_audio_js__WEBPACK_IMPORTED_MODULE_2__
=
__webpack_require__
(
"
.
/
src
/
utils
/
audio
.
js
"
)
;
class
WeSpeakerFeatureExtractor
extends
_base_feature_extraction_utils_js__WEBPACK_IMPORTED_MODULE_0__
.
FeatureExtractor
{
constructor
(
config
)
{
super
(
config
)
;
const
sampling_rate
=
this
.
config
.
sampling_rate
;
const
mel_filters
=
(
0
_utils_audio_js__WEBPACK_IMPORTED_MODULE_2__
.
mel_filter_bank
)
(
256
this
.
config
.
num_mel_bins
20
Math
.
floor
(
sampling_rate
/
2
)
sampling_rate
null
"
kaldi
"
true
)
;
for
(
let
i
=
0
;
i
<
mel_filters
.
length
;
+
+
i
)
{
mel_filters
[
i
]
.
push
(
0
)
;
}
this
.
mel_filters
=
mel_filters
;
this
.
window
=
(
0
_utils_audio_js__WEBPACK_IMPORTED_MODULE_2__
.
window_function
)
(
400
'
hamming
'
{
periodic
:
false
}
)
this
.
min_num_frames
=
this
.
config
.
min_num_frames
;
}
async
_extract_fbank_features
(
waveform
)
{
waveform
=
waveform
.
map
(
(
x
)
=
>
x
*
32768
)
return
(
0
_utils_audio_js__WEBPACK_IMPORTED_MODULE_2__
.
spectrogram
)
(
waveform
this
.
window
400
160
{
fft_length
:
512
power
:
2
.
0
center
:
false
preemphasis
:
0
.
97
mel_filters
:
this
.
mel_filters
log_mel
:
'
log
'
mel_floor
:
1
.
192092955078125e
-
07
remove_dc_offset
:
true
transpose
:
true
min_num_frames
:
this
.
min_num_frames
}
)
}
async
_call
(
audio
)
{
(
0
_base_feature_extraction_utils_js__WEBPACK_IMPORTED_MODULE_0__
.
validate_audio_inputs
)
(
audio
'
WeSpeakerFeatureExtractor
'
)
;
const
features
=
(
await
this
.
_extract_fbank_features
(
audio
)
)
.
unsqueeze_
(
0
)
;
if
(
this
.
config
.
fbank_centering_span
=
=
=
null
)
{
const
meanData
=
(
features
.
mean
(
1
)
.
data
)
;
const
featuresData
=
(
features
.
data
)
;
const
[
batch_size
num_frames
feature_size
]
=
features
.
dims
;
for
(
let
i
=
0
;
i
<
batch_size
;
+
+
i
)
{
const
offset1
=
i
*
num_frames
*
feature_size
;
const
offset2
=
i
*
feature_size
;
for
(
let
j
=
0
;
j
<
num_frames
;
+
+
j
)
{
const
offset3
=
offset1
+
j
*
feature_size
;
for
(
let
k
=
0
;
k
<
feature_size
;
+
+
k
)
{
featuresData
[
offset3
+
k
]
-
=
meanData
[
offset2
+
k
]
;
}
}
}
}
return
{
input_features
:
features
}
;
}
}
}
)
"
.
/
src
/
models
/
whisper
/
common_whisper
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
WHISPER_LANGUAGE_MAPPING
:
(
)
=
>
(
WHISPER_LANGUAGE_MAPPING
)
WHISPER_TO_LANGUAGE_CODE_MAPPING
:
(
)
=
>
(
WHISPER_TO_LANGUAGE_CODE_MAPPING
)
whisper_language_to_code
:
(
)
=
>
(
whisper_language_to_code
)
}
)
;
const
WHISPER_LANGUAGES
=
[
[
"
en
"
"
english
"
]
[
"
zh
"
"
chinese
"
]
[
"
de
"
"
german
"
]
[
"
es
"
"
spanish
"
]
[
"
ru
"
"
russian
"
]
[
"
ko
"
"
korean
"
]
[
"
fr
"
"
french
"
]
[
"
ja
"
"
japanese
"
]
[
"
pt
"
"
portuguese
"
]
[
"
tr
"
"
turkish
"
]
[
"
pl
"
"
polish
"
]
[
"
ca
"
"
catalan
"
]
[
"
nl
"
"
dutch
"
]
[
"
ar
"
"
arabic
"
]
[
"
sv
"
"
swedish
"
]
[
"
it
"
"
italian
"
]
[
"
id
"
"
indonesian
"
]
[
"
hi
"
"
hindi
"
]
[
"
fi
"
"
finnish
"
]
[
"
vi
"
"
vietnamese
"
]
[
"
he
"
"
hebrew
"
]
[
"
uk
"
"
ukrainian
"
]
[
"
el
"
"
greek
"
]
[
"
ms
"
"
malay
"
]
[
"
cs
"
"
czech
"
]
[
"
ro
"
"
romanian
"
]
[
"
da
"
"
danish
"
]
[
"
hu
"
"
hungarian
"
]
[
"
ta
"
"
tamil
"
]
[
"
no
"
"
norwegian
"
]
[
"
th
"
"
thai
"
]
[
"
ur
"
"
urdu
"
]
[
"
hr
"
"
croatian
"
]
[
"
bg
"
"
bulgarian
"
]
[
"
lt
"
"
lithuanian
"
]
[
"
la
"
"
latin
"
]
[
"
mi
"
"
maori
"
]
[
"
ml
"
"
malayalam
"
]
[
"
cy
"
"
welsh
"
]
[
"
sk
"
"
slovak
"
]
[
"
te
"
"
telugu
"
]
[
"
fa
"
"
persian
"
]
[
"
lv
"
"
latvian
"
]
[
"
bn
"
"
bengali
"
]
[
"
sr
"
"
serbian
"
]
[
"
az
"
"
azerbaijani
"
]
[
"
sl
"
"
slovenian
"
]
[
"
kn
"
"
kannada
"
]
[
"
et
"
"
estonian
"
]
[
"
mk
"
"
macedonian
"
]
[
"
br
"
"
breton
"
]
[
"
eu
"
"
basque
"
]
[
"
is
"
"
icelandic
"
]
[
"
hy
"
"
armenian
"
]
[
"
ne
"
"
nepali
"
]
[
"
mn
"
"
mongolian
"
]
[
"
bs
"
"
bosnian
"
]
[
"
kk
"
"
kazakh
"
]
[
"
sq
"
"
albanian
"
]
[
"
sw
"
"
swahili
"
]
[
"
gl
"
"
galician
"
]
[
"
mr
"
"
marathi
"
]
[
"
pa
"
"
punjabi
"
]
[
"
si
"
"
sinhala
"
]
[
"
km
"
"
khmer
"
]
[
"
sn
"
"
shona
"
]
[
"
yo
"
"
yoruba
"
]
[
"
so
"
"
somali
"
]
[
"
af
"
"
afrikaans
"
]
[
"
oc
"
"
occitan
"
]
[
"
ka
"
"
georgian
"
]
[
"
be
"
"
belarusian
"
]
[
"
tg
"
"
tajik
"
]
[
"
sd
"
"
sindhi
"
]
[
"
gu
"
"
gujarati
"
]
[
"
am
"
"
amharic
"
]
[
"
yi
"
"
yiddish
"
]
[
"
lo
"
"
lao
"
]
[
"
uz
"
"
uzbek
"
]
[
"
fo
"
"
faroese
"
]
[
"
ht
"
"
haitian
creole
"
]
[
"
ps
"
"
pashto
"
]
[
"
tk
"
"
turkmen
"
]
[
"
nn
"
"
nynorsk
"
]
[
"
mt
"
"
maltese
"
]
[
"
sa
"
"
sanskrit
"
]
[
"
lb
"
"
luxembourgish
"
]
[
"
my
"
"
myanmar
"
]
[
"
bo
"
"
tibetan
"
]
[
"
tl
"
"
tagalog
"
]
[
"
mg
"
"
malagasy
"
]
[
"
as
"
"
assamese
"
]
[
"
tt
"
"
tatar
"
]
[
"
haw
"
"
hawaiian
"
]
[
"
ln
"
"
lingala
"
]
[
"
ha
"
"
hausa
"
]
[
"
ba
"
"
bashkir
"
]
[
"
jw
"
"
javanese
"
]
[
"
su
"
"
sundanese
"
]
]
const
WHISPER_LANGUAGE_MAPPING
=
new
Map
(
WHISPER_LANGUAGES
)
;
const
WHISPER_TO_LANGUAGE_CODE_MAPPING
=
new
Map
(
[
.
.
.
WHISPER_LANGUAGES
.
map
(
(
[
k
v
]
)
=
>
[
v
k
]
)
.
.
.
[
[
"
burmese
"
"
my
"
]
[
"
valencian
"
"
ca
"
]
[
"
flemish
"
"
nl
"
]
[
"
haitian
"
"
ht
"
]
[
"
letzeburgesch
"
"
lb
"
]
[
"
pushto
"
"
ps
"
]
[
"
panjabi
"
"
pa
"
]
[
"
moldavian
"
"
ro
"
]
[
"
moldovan
"
"
ro
"
]
[
"
sinhalese
"
"
si
"
]
[
"
castilian
"
"
es
"
]
]
]
)
;
function
whisper_language_to_code
(
language
)
{
language
=
language
.
toLowerCase
(
)
;
let
language_code
=
WHISPER_TO_LANGUAGE_CODE_MAPPING
.
get
(
language
)
;
if
(
language_code
=
=
=
undefined
)
{
if
(
WHISPER_LANGUAGE_MAPPING
.
has
(
language
)
)
{
language_code
=
language
;
}
else
{
const
is_language_code
=
language
.
length
=
=
=
2
;
const
langs
=
is_language_code
?
WHISPER_LANGUAGE_MAPPING
.
keys
(
)
:
WHISPER_LANGUAGE_MAPPING
.
values
(
)
;
throw
new
Error
(
Language
"
{
language
}
"
is
not
supported
.
Must
be
one
of
:
{
JSON
.
stringify
(
langs
)
}
)
;
}
}
return
language_code
;
}
}
)
"
.
/
src
/
models
/
whisper
/
feature_extraction_whisper
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
WhisperFeatureExtractor
:
(
)
=
>
(
WhisperFeatureExtractor
)
}
)
;
var
_base_feature_extraction_utils_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
src
/
base
/
feature_extraction_utils
.
js
"
)
;
var
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_1__
=
__webpack_require__
(
"
.
/
src
/
utils
/
tensor
.
js
"
)
;
var
_utils_audio_js__WEBPACK_IMPORTED_MODULE_2__
=
__webpack_require__
(
"
.
/
src
/
utils
/
audio
.
js
"
)
;
var
_utils_maths_js__WEBPACK_IMPORTED_MODULE_3__
=
__webpack_require__
(
"
.
/
src
/
utils
/
maths
.
js
"
)
;
class
WhisperFeatureExtractor
extends
_base_feature_extraction_utils_js__WEBPACK_IMPORTED_MODULE_0__
.
FeatureExtractor
{
constructor
(
config
)
{
super
(
config
)
;
this
.
config
.
mel_filters
?
?
=
(
0
_utils_audio_js__WEBPACK_IMPORTED_MODULE_2__
.
mel_filter_bank
)
(
Math
.
floor
(
1
+
this
.
config
.
n_fft
/
2
)
this
.
config
.
feature_size
0
.
0
8000
.
0
this
.
config
.
sampling_rate
"
slaney
"
"
slaney
"
)
;
this
.
window
=
(
0
_utils_audio_js__WEBPACK_IMPORTED_MODULE_2__
.
window_function
)
(
this
.
config
.
n_fft
'
hann
'
)
;
}
async
_extract_fbank_features
(
waveform
)
{
const
features
=
await
(
0
_utils_audio_js__WEBPACK_IMPORTED_MODULE_2__
.
spectrogram
)
(
waveform
this
.
window
this
.
config
.
n_fft
this
.
config
.
hop_length
{
power
:
2
.
0
mel_filters
:
this
.
config
.
mel_filters
log_mel
:
'
log10
'
max_num_frames
:
this
.
config
.
nb_max_frames
}
)
const
data
=
features
.
data
;
const
maxValue
=
(
0
_utils_maths_js__WEBPACK_IMPORTED_MODULE_3__
.
max
)
(
data
)
[
0
]
;
for
(
let
i
=
0
;
i
<
data
.
length
;
+
+
i
)
{
data
[
i
]
=
(
Math
.
max
(
data
[
i
]
maxValue
-
8
.
0
)
+
4
.
0
)
/
4
.
0
;
}
return
features
;
}
async
_call
(
audio
)
{
(
0
_base_feature_extraction_utils_js__WEBPACK_IMPORTED_MODULE_0__
.
validate_audio_inputs
)
(
audio
'
WhisperFeatureExtractor
'
)
;
let
waveform
;
if
(
audio
.
length
>
this
.
config
.
n_samples
)
{
console
.
warn
(
"
Attempting
to
extract
features
for
audio
longer
than
30
seconds
.
"
+
"
If
using
a
pipeline
to
extract
transcript
from
a
long
audio
clip
"
+
"
remember
to
specify
chunk_length_s
and
/
or
stride_length_s
.
"
)
;
waveform
=
audio
.
slice
(
0
this
.
config
.
n_samples
)
;
}
else
{
waveform
=
new
Float32Array
(
this
.
config
.
n_samples
)
;
waveform
.
set
(
audio
)
;
}
const
features
=
await
this
.
_extract_fbank_features
(
waveform
)
;
return
{
input_features
:
features
.
unsqueeze_
(
0
)
}
;
}
}
}
)
"
.
/
src
/
models
/
whisper
/
generation_whisper
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
WhisperGenerationConfig
:
(
)
=
>
(
WhisperGenerationConfig
)
}
)
;
var
_generation_configuration_utils_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
src
/
generation
/
configuration_utils
.
js
"
)
;
class
WhisperGenerationConfig
extends
_generation_configuration_utils_js__WEBPACK_IMPORTED_MODULE_0__
.
GenerationConfig
{
return_timestamps
=
null
;
return_token_timestamps
=
null
;
num_frames
=
null
;
alignment_heads
=
null
;
task
=
null
;
language
=
null
;
no_timestamps_token_id
=
null
;
prompt_ids
=
null
;
is_multilingual
=
null
;
lang_to_id
=
null
;
task_to_id
=
null
;
max_initial_timestamp_index
=
1
;
}
}
)
"
.
/
src
/
models
/
whisper
/
processing_whisper
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
WhisperProcessor
:
(
)
=
>
(
WhisperProcessor
)
}
)
;
var
_auto_feature_extraction_auto_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
src
/
models
/
auto
/
feature_extraction_auto
.
js
"
)
;
var
_tokenizers_js__WEBPACK_IMPORTED_MODULE_1__
=
__webpack_require__
(
"
.
/
src
/
tokenizers
.
js
"
)
;
var
_base_processing_utils_js__WEBPACK_IMPORTED_MODULE_2__
=
__webpack_require__
(
"
.
/
src
/
base
/
processing_utils
.
js
"
)
;
class
WhisperProcessor
extends
_base_processing_utils_js__WEBPACK_IMPORTED_MODULE_2__
.
Processor
{
static
tokenizer_class
=
_tokenizers_js__WEBPACK_IMPORTED_MODULE_1__
.
AutoTokenizer
static
feature_extractor_class
=
_auto_feature_extraction_auto_js__WEBPACK_IMPORTED_MODULE_0__
.
AutoFeatureExtractor
async
_call
(
audio
)
{
return
await
this
.
feature_extractor
(
audio
)
;
}
}
}
)
"
.
/
src
/
models
/
yolos
/
image_processing_yolos
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
YolosFeatureExtractor
:
(
)
=
>
(
YolosFeatureExtractor
)
YolosImageProcessor
:
(
)
=
>
(
YolosImageProcessor
)
}
)
;
var
_base_image_processors_utils_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
src
/
base
/
image_processors_utils
.
js
"
)
;
class
YolosImageProcessor
extends
_base_image_processors_utils_js__WEBPACK_IMPORTED_MODULE_0__
.
ImageProcessor
{
post_process_object_detection
(
.
.
.
args
)
{
return
(
0
_base_image_processors_utils_js__WEBPACK_IMPORTED_MODULE_0__
.
post_process_object_detection
)
(
.
.
.
args
)
;
}
}
class
YolosFeatureExtractor
extends
YolosImageProcessor
{
}
}
)
"
.
/
src
/
ops
/
registry
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
TensorOpRegistry
:
(
)
=
>
(
TensorOpRegistry
)
}
)
;
var
_backends_onnx_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
src
/
backends
/
onnx
.
js
"
)
;
var
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_1__
=
__webpack_require__
(
"
.
/
src
/
utils
/
tensor
.
js
"
)
;
const
wrap
=
async
(
session_bytes
session_options
names
)
=
>
{
const
session
=
await
(
0
_backends_onnx_js__WEBPACK_IMPORTED_MODULE_0__
.
createInferenceSession
)
(
new
Uint8Array
(
session_bytes
)
session_options
)
;
return
(
async
(
inputs
)
=
>
{
const
ortFeed
=
Object
.
fromEntries
(
Object
.
entries
(
inputs
)
.
map
(
(
[
k
v
]
)
=
>
[
k
v
.
ort_tensor
]
)
)
;
const
outputs
=
await
session
.
run
(
ortFeed
)
;
if
(
Array
.
isArray
(
names
)
)
{
return
names
.
map
(
(
n
)
=
>
new
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_1__
.
Tensor
(
outputs
[
n
]
)
)
;
}
else
{
return
new
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_1__
.
Tensor
(
outputs
[
(
names
)
]
)
;
}
}
)
}
class
TensorOpRegistry
{
static
session_options
=
{
}
;
static
get
bilinear_interpolate_4d
(
)
{
if
(
!
this
.
_bilinear_interpolate_4d
)
{
this
.
_bilinear_interpolate_4d
=
wrap
(
[
8
9
18
0
58
128
1
10
40
10
1
120
10
0
10
0
10
1
115
18
1
121
34
6
82
101
115
105
122
101
42
17
10
4
109
111
100
101
34
6
108
105
110
101
97
114
160
1
3
18
1
114
90
31
10
1
120
18
26
10
24
8
1
18
20
10
3
18
1
98
10
3
18
1
99
10
3
18
1
104
10
3
18
1
119
90
15
10
1
115
18
10
10
8
8
7
18
4
10
2
8
4
98
31
10
1
121
18
26
10
24
8
1
18
20
10
3
18
1
98
10
3
18
1
99
10
3
18
1
104
10
3
18
1
119
66
2
16
20
]
this
.
session_options
'
y
'
)
;
}
return
this
.
_bilinear_interpolate_4d
;
}
static
get
bicubic_interpolate_4d
(
)
{
if
(
!
this
.
_bicubic_interpolate_4d
)
{
this
.
_bicubic_interpolate_4d
=
wrap
(
[
8
9
18
0
58
127
10
39
10
1
120
10
0
10
0
10
1
115
18
1
121
34
6
82
101
115
105
122
101
42
16
10
4
109
111
100
101
34
5
99
117
98
105
99
160
1
3
18
1
114
90
31
10
1
120
18
26
10
24
8
1
18
20
10
3
18
1
98
10
3
18
1
99
10
3
18
1
104
10
3
18
1
119
90
15
10
1
115
18
10
10
8
8
7
18
4
10
2
8
4
98
31
10
1
121
18
26
10
24
8
1
18
20
10
3
18
1
98
10
3
18
1
99
10
3
18
1
104
10
3
18
1
119
66
2
16
20
]
this
.
session_options
'
y
'
)
;
}
return
this
.
_bicubic_interpolate_4d
;
}
static
get
matmul
(
)
{
if
(
!
this
.
_matmul
)
{
this
.
_matmul
=
wrap
(
[
8
9
18
0
58
55
10
17
10
1
97
10
1
98
18
1
99
34
6
77
97
116
77
117
108
18
1
114
90
9
10
1
97
18
4
10
2
8
1
90
9
10
1
98
18
4
10
2
8
1
98
9
10
1
99
18
4
10
2
8
1
66
2
16
20
]
this
.
session_options
'
c
'
)
;
}
return
this
.
_matmul
;
}
static
get
stft
(
)
{
if
(
!
this
.
_stft
)
{
this
.
_stft
=
wrap
(
[
8
7
18
0
58
148
1
10
38
10
1
115
10
1
106
10
1
119
10
1
108
18
1
111
34
4
83
84
70
84
42
15
10
8
111
110
101
115
105
100
101
100
24
1
160
1
2
18
1
115
90
26
10
1
115
18
21
10
19
8
1
18
15
10
3
18
1
98
10
3
18
1
115
10
3
18
1
99
90
11
10
1
106
18
6
10
4
8
7
18
0
90
16
10
1
119
18
11
10
9
8
1
18
5
10
3
18
1
119
90
11
10
1
108
18
6
10
4
8
7
18
0
98
31
10
1
111
18
26
10
24
8
1
18
20
10
3
18
1
98
10
3
18
1
102
10
3
18
1
100
10
3
18
1
99
66
2
16
17
]
this
.
session_options
'
o
'
)
}
return
this
.
_stft
;
}
static
get
rfft
(
)
{
if
(
!
this
.
_rfft
)
{
this
.
_rfft
=
wrap
(
[
8
9
18
0
58
97
10
33
10
1
120
10
0
10
1
97
18
1
121
34
3
68
70
84
42
15
10
8
111
110
101
115
105
100
101
100
24
1
160
1
2
18
1
100
90
21
10
1
120
18
16
10
14
8
1
18
10
10
3
18
1
115
10
3
18
1
99
90
11
10
1
97
18
6
10
4
8
7
18
0
98
21
10
1
121
18
16
10
14
8
1
18
10
10
3
18
1
115
10
3
18
1
99
66
2
16
20
]
this
.
session_options
'
y
'
)
}
return
this
.
_rfft
;
}
static
get
top_k
(
)
{
if
(
!
this
.
_top_k
)
{
this
.
_top_k
=
wrap
(
[
8
10
18
0
58
73
10
18
10
1
120
10
1
107
18
1
118
18
1
105
34
4
84
111
112
75
18
1
116
90
9
10
1
120
18
4
10
2
8
1
90
15
10
1
107
18
10
10
8
8
7
18
4
10
2
8
1
98
9
10
1
118
18
4
10
2
8
1
98
9
10
1
105
18
4
10
2
8
7
66
2
16
21
]
this
.
session_options
[
'
v
'
'
i
'
]
)
}
return
this
.
_top_k
;
}
}
}
)
"
.
/
src
/
pipelines
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
AudioClassificationPipeline
:
(
)
=
>
(
AudioClassificationPipeline
)
AutomaticSpeechRecognitionPipeline
:
(
)
=
>
(
AutomaticSpeechRecognitionPipeline
)
DepthEstimationPipeline
:
(
)
=
>
(
DepthEstimationPipeline
)
DocumentQuestionAnsweringPipeline
:
(
)
=
>
(
DocumentQuestionAnsweringPipeline
)
FeatureExtractionPipeline
:
(
)
=
>
(
FeatureExtractionPipeline
)
FillMaskPipeline
:
(
)
=
>
(
FillMaskPipeline
)
ImageClassificationPipeline
:
(
)
=
>
(
ImageClassificationPipeline
)
ImageFeatureExtractionPipeline
:
(
)
=
>
(
ImageFeatureExtractionPipeline
)
ImageSegmentationPipeline
:
(
)
=
>
(
ImageSegmentationPipeline
)
ImageToImagePipeline
:
(
)
=
>
(
ImageToImagePipeline
)
ImageToTextPipeline
:
(
)
=
>
(
ImageToTextPipeline
)
ObjectDetectionPipeline
:
(
)
=
>
(
ObjectDetectionPipeline
)
Pipeline
:
(
)
=
>
(
Pipeline
)
QuestionAnsweringPipeline
:
(
)
=
>
(
QuestionAnsweringPipeline
)
SummarizationPipeline
:
(
)
=
>
(
SummarizationPipeline
)
Text2TextGenerationPipeline
:
(
)
=
>
(
Text2TextGenerationPipeline
)
TextClassificationPipeline
:
(
)
=
>
(
TextClassificationPipeline
)
TextGenerationPipeline
:
(
)
=
>
(
TextGenerationPipeline
)
TextToAudioPipeline
:
(
)
=
>
(
TextToAudioPipeline
)
TokenClassificationPipeline
:
(
)
=
>
(
TokenClassificationPipeline
)
TranslationPipeline
:
(
)
=
>
(
TranslationPipeline
)
ZeroShotAudioClassificationPipeline
:
(
)
=
>
(
ZeroShotAudioClassificationPipeline
)
ZeroShotClassificationPipeline
:
(
)
=
>
(
ZeroShotClassificationPipeline
)
ZeroShotImageClassificationPipeline
:
(
)
=
>
(
ZeroShotImageClassificationPipeline
)
ZeroShotObjectDetectionPipeline
:
(
)
=
>
(
ZeroShotObjectDetectionPipeline
)
pipeline
:
(
)
=
>
(
pipeline
)
}
)
;
var
_tokenizers_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
src
/
tokenizers
.
js
"
)
;
var
_models_js__WEBPACK_IMPORTED_MODULE_1__
=
__webpack_require__
(
"
.
/
src
/
models
.
js
"
)
;
var
_models_auto_processing_auto_js__WEBPACK_IMPORTED_MODULE_2__
=
__webpack_require__
(
"
.
/
src
/
models
/
auto
/
processing_auto
.
js
"
)
;
var
_base_processing_utils_js__WEBPACK_IMPORTED_MODULE_3__
=
__webpack_require__
(
"
.
/
src
/
base
/
processing_utils
.
js
"
)
;
var
_utils_generic_js__WEBPACK_IMPORTED_MODULE_4__
=
__webpack_require__
(
"
.
/
src
/
utils
/
generic
.
js
"
)
;
var
_utils_core_js__WEBPACK_IMPORTED_MODULE_5__
=
__webpack_require__
(
"
.
/
src
/
utils
/
core
.
js
"
)
;
var
_utils_maths_js__WEBPACK_IMPORTED_MODULE_6__
=
__webpack_require__
(
"
.
/
src
/
utils
/
maths
.
js
"
)
;
var
_utils_audio_js__WEBPACK_IMPORTED_MODULE_7__
=
__webpack_require__
(
"
.
/
src
/
utils
/
audio
.
js
"
)
;
var
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_8__
=
__webpack_require__
(
"
.
/
src
/
utils
/
tensor
.
js
"
)
;
var
_utils_image_js__WEBPACK_IMPORTED_MODULE_9__
=
__webpack_require__
(
"
.
/
src
/
utils
/
image
.
js
"
)
;
async
function
prepareImages
(
images
)
{
if
(
!
Array
.
isArray
(
images
)
)
{
images
=
[
images
]
;
}
return
await
Promise
.
all
(
images
.
map
(
x
=
>
_utils_image_js__WEBPACK_IMPORTED_MODULE_9__
.
RawImage
.
read
(
x
)
)
)
;
}
async
function
prepareAudios
(
audios
sampling_rate
)
{
if
(
!
Array
.
isArray
(
audios
)
)
{
audios
=
[
audios
]
;
}
return
await
Promise
.
all
(
audios
.
map
(
x
=
>
{
if
(
typeof
x
=
=
=
'
string
'
|
|
x
instanceof
URL
)
{
return
(
0
_utils_audio_js__WEBPACK_IMPORTED_MODULE_7__
.
read_audio
)
(
x
sampling_rate
)
;
}
else
if
(
x
instanceof
Float64Array
)
{
return
new
Float32Array
(
x
)
;
}
return
x
;
}
)
)
;
}
function
get_bounding_box
(
box
asInteger
)
{
if
(
asInteger
)
{
box
=
box
.
map
(
x
=
>
x
|
0
)
;
}
const
[
xmin
ymin
xmax
ymax
]
=
box
;
return
{
xmin
ymin
xmax
ymax
}
;
}
class
Pipeline
extends
_utils_generic_js__WEBPACK_IMPORTED_MODULE_4__
.
Callable
{
constructor
(
{
task
model
tokenizer
=
null
processor
=
null
}
)
{
super
(
)
;
this
.
task
=
task
;
this
.
model
=
model
;
this
.
tokenizer
=
tokenizer
;
this
.
processor
=
processor
;
}
async
dispose
(
)
{
await
this
.
model
.
dispose
(
)
;
}
}
class
TextClassificationPipeline
extends
(
(
Pipeline
)
)
{
constructor
(
options
)
{
super
(
options
)
;
}
async
_call
(
texts
{
top_k
=
1
}
=
{
}
)
{
const
model_inputs
=
this
.
tokenizer
(
texts
{
padding
:
true
truncation
:
true
}
)
;
const
outputs
=
await
this
.
model
(
model_inputs
)
const
function_to_apply
=
this
.
model
.
config
.
problem_type
=
=
=
'
multi_label_classification
'
?
batch
=
>
batch
.
sigmoid
(
)
:
batch
=
>
new
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_8__
.
Tensor
(
'
float32
'
(
0
_utils_maths_js__WEBPACK_IMPORTED_MODULE_6__
.
softmax
)
(
batch
.
data
)
batch
.
dims
)
;
const
id2label
=
this
.
model
.
config
.
id2label
;
const
toReturn
=
[
]
;
for
(
const
batch
of
outputs
.
logits
)
{
const
output
=
function_to_apply
(
batch
)
;
const
scores
=
await
(
0
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_8__
.
topk
)
(
output
top_k
)
;
const
values
=
scores
[
0
]
.
tolist
(
)
;
const
indices
=
scores
[
1
]
.
tolist
(
)
;
const
vals
=
indices
.
map
(
(
x
i
)
=
>
(
{
label
:
id2label
?
id2label
[
x
]
:
LABEL_
{
x
}
score
:
values
[
i
]
}
)
)
;
if
(
top_k
=
=
=
1
)
{
toReturn
.
push
(
.
.
.
vals
)
;
}
else
{
toReturn
.
push
(
vals
)
;
}
}
return
Array
.
isArray
(
texts
)
|
|
top_k
=
=
=
1
?
(
toReturn
)
:
(
toReturn
)
[
0
]
;
}
}
class
TokenClassificationPipeline
extends
(
(
Pipeline
)
)
{
constructor
(
options
)
{
super
(
options
)
;
}
async
_call
(
texts
{
ignore_labels
=
[
'
O
'
]
}
=
{
}
)
{
const
isBatched
=
Array
.
isArray
(
texts
)
;
const
model_inputs
=
this
.
tokenizer
(
isBatched
?
texts
:
[
texts
]
{
padding
:
true
truncation
:
true
}
)
;
const
outputs
=
await
this
.
model
(
model_inputs
)
const
logits
=
outputs
.
logits
;
const
id2label
=
this
.
model
.
config
.
id2label
;
const
toReturn
=
[
]
;
for
(
let
i
=
0
;
i
<
logits
.
dims
[
0
]
;
+
+
i
)
{
const
ids
=
model_inputs
.
input_ids
[
i
]
;
const
batch
=
logits
[
i
]
;
const
tokens
=
[
]
;
for
(
let
j
=
0
;
j
<
batch
.
dims
[
0
]
;
+
+
j
)
{
const
tokenData
=
batch
[
j
]
;
const
topScoreIndex
=
(
0
_utils_maths_js__WEBPACK_IMPORTED_MODULE_6__
.
max
)
(
tokenData
.
data
)
[
1
]
;
const
entity
=
id2label
?
id2label
[
topScoreIndex
]
:
LABEL_
{
topScoreIndex
}
;
if
(
ignore_labels
.
includes
(
entity
)
)
{
continue
;
}
const
word
=
this
.
tokenizer
.
decode
(
[
ids
[
j
]
.
item
(
)
]
{
skip_special_tokens
:
true
}
)
;
if
(
word
=
=
=
'
'
)
{
continue
;
}
const
scores
=
(
0
_utils_maths_js__WEBPACK_IMPORTED_MODULE_6__
.
softmax
)
(
tokenData
.
data
)
;
tokens
.
push
(
{
entity
:
entity
score
:
scores
[
topScoreIndex
]
index
:
j
word
:
word
}
)
;
}
toReturn
.
push
(
tokens
)
;
}
return
isBatched
?
toReturn
:
toReturn
[
0
]
;
}
}
class
QuestionAnsweringPipeline
extends
(
(
Pipeline
)
)
{
constructor
(
options
)
{
super
(
options
)
;
}
async
_call
(
question
context
{
top_k
=
1
}
=
{
}
)
{
const
inputs
=
this
.
tokenizer
(
question
{
text_pair
:
context
padding
:
true
truncation
:
true
}
)
;
const
{
start_logits
end_logits
}
=
await
this
.
model
(
inputs
)
;
const
input_ids
=
inputs
.
input_ids
.
tolist
(
)
;
const
attention_mask
=
inputs
.
attention_mask
.
tolist
(
)
;
const
special_tokens
=
this
.
tokenizer
.
all_special_ids
;
const
toReturn
=
[
]
;
for
(
let
j
=
0
;
j
<
start_logits
.
dims
[
0
]
;
+
+
j
)
{
const
ids
=
input_ids
[
j
]
;
const
sepIndex
=
ids
.
findIndex
(
x
=
>
x
=
=
this
.
tokenizer
.
sep_token_id
)
;
const
valid_mask
=
attention_mask
[
j
]
.
map
(
(
y
ix
)
=
>
(
y
=
=
1
&
&
(
ix
=
=
=
0
|
|
(
ix
>
sepIndex
&
&
special_tokens
.
findIndex
(
x
=
>
x
=
=
ids
[
ix
]
)
=
=
=
-
1
)
)
)
)
;
const
start
=
start_logits
[
j
]
.
tolist
(
)
;
const
end
=
end_logits
[
j
]
.
tolist
(
)
;
for
(
let
i
=
1
;
i
<
start
.
length
;
+
+
i
)
{
if
(
attention_mask
[
j
]
=
=
0
|
|
i
<
=
sepIndex
|
|
special_tokens
.
findIndex
(
x
=
>
x
=
=
ids
[
i
]
)
!
=
=
-
1
)
{
start
[
i
]
=
-
Infinity
;
end
[
i
]
=
-
Infinity
;
}
}
const
start_scores
=
(
0
_utils_maths_js__WEBPACK_IMPORTED_MODULE_6__
.
softmax
)
(
start
)
.
map
(
(
x
i
)
=
>
[
x
i
]
)
;
const
end_scores
=
(
0
_utils_maths_js__WEBPACK_IMPORTED_MODULE_6__
.
softmax
)
(
end
)
.
map
(
(
x
i
)
=
>
[
x
i
]
)
;
start_scores
[
0
]
[
0
]
=
0
;
end_scores
[
0
]
[
0
]
=
0
;
const
options
=
(
0
_utils_core_js__WEBPACK_IMPORTED_MODULE_5__
.
product
)
(
start_scores
end_scores
)
.
filter
(
x
=
>
x
[
0
]
[
1
]
<
=
x
[
1
]
[
1
]
)
.
map
(
x
=
>
[
x
[
0
]
[
1
]
x
[
1
]
[
1
]
x
[
0
]
[
0
]
*
x
[
1
]
[
0
]
]
)
.
sort
(
(
a
b
)
=
>
b
[
2
]
-
a
[
2
]
)
;
for
(
let
k
=
0
;
k
<
Math
.
min
(
options
.
length
top_k
)
;
+
+
k
)
{
const
[
start
end
score
]
=
options
[
k
]
;
const
answer_tokens
=
ids
.
slice
(
start
end
+
1
)
const
answer
=
this
.
tokenizer
.
decode
(
answer_tokens
{
skip_special_tokens
:
true
}
)
;
toReturn
.
push
(
{
answer
score
}
)
;
}
}
return
(
top_k
=
=
=
1
)
?
toReturn
[
0
]
:
toReturn
;
}
}
class
FillMaskPipeline
extends
(
(
Pipeline
)
)
{
constructor
(
options
)
{
super
(
options
)
;
}
async
_call
(
texts
{
top_k
=
5
}
=
{
}
)
{
const
model_inputs
=
this
.
tokenizer
(
texts
{
padding
:
true
truncation
:
true
}
)
;
const
{
logits
}
=
await
this
.
model
(
model_inputs
)
const
toReturn
=
[
]
;
const
input_ids
=
model_inputs
.
input_ids
.
tolist
(
)
;
for
(
let
i
=
0
;
i
<
input_ids
.
length
;
+
+
i
)
{
const
ids
=
input_ids
[
i
]
;
const
mask_token_index
=
ids
.
findIndex
(
x
=
>
x
=
=
this
.
tokenizer
.
mask_token_id
)
;
if
(
mask_token_index
=
=
=
-
1
)
{
throw
Error
(
Mask
token
(
{
this
.
tokenizer
.
mask_token
}
)
not
found
in
text
.
)
}
const
itemLogits
=
logits
[
i
]
[
mask_token_index
]
;
const
scores
=
await
(
0
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_8__
.
topk
)
(
new
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_8__
.
Tensor
(
'
float32
'
(
0
_utils_maths_js__WEBPACK_IMPORTED_MODULE_6__
.
softmax
)
(
itemLogits
.
data
)
itemLogits
.
dims
)
top_k
)
;
const
values
=
scores
[
0
]
.
tolist
(
)
;
const
indices
=
scores
[
1
]
.
tolist
(
)
;
toReturn
.
push
(
indices
.
map
(
(
x
i
)
=
>
{
const
sequence
=
ids
.
slice
(
)
;
sequence
[
mask_token_index
]
=
x
;
return
{
score
:
values
[
i
]
token
:
Number
(
x
)
token_str
:
this
.
tokenizer
.
model
.
vocab
[
x
]
sequence
:
this
.
tokenizer
.
decode
(
sequence
{
skip_special_tokens
:
true
}
)
}
}
)
)
;
}
return
Array
.
isArray
(
texts
)
?
toReturn
:
toReturn
[
0
]
;
}
}
class
Text2TextGenerationPipeline
extends
(
(
Pipeline
)
)
{
_key
=
'
generated_text
'
;
constructor
(
options
)
{
super
(
options
)
;
}
async
_call
(
texts
generate_kwargs
=
{
}
)
{
if
(
!
Array
.
isArray
(
texts
)
)
{
texts
=
[
texts
]
;
}
if
(
this
.
model
.
config
.
prefix
)
{
texts
=
texts
.
map
(
x
=
>
this
.
model
.
config
.
prefix
+
x
)
}
const
task_specific_params
=
this
.
model
.
config
.
task_specific_params
if
(
task_specific_params
&
&
task_specific_params
[
this
.
task
]
)
{
if
(
task_specific_params
[
this
.
task
]
.
prefix
)
{
texts
=
texts
.
map
(
x
=
>
task_specific_params
[
this
.
task
]
.
prefix
+
x
)
}
}
const
tokenizer
=
this
.
tokenizer
;
const
tokenizer_options
=
{
padding
:
true
truncation
:
true
}
let
inputs
;
if
(
this
instanceof
TranslationPipeline
&
&
'
_build_translation_inputs
'
in
tokenizer
)
{
inputs
=
tokenizer
.
_build_translation_inputs
(
texts
tokenizer_options
generate_kwargs
)
;
}
else
{
inputs
=
tokenizer
(
texts
tokenizer_options
)
;
}
const
outputTokenIds
=
await
this
.
model
.
generate
(
{
.
.
.
inputs
.
.
.
generate_kwargs
}
)
;
return
tokenizer
.
batch_decode
(
(
outputTokenIds
)
{
skip_special_tokens
:
true
}
)
.
map
(
text
=
>
(
{
[
this
.
_key
]
:
text
}
)
)
;
}
}
class
SummarizationPipeline
extends
(
(
(
Text2TextGenerationPipeline
)
)
)
{
_key
=
'
summary_text
'
;
constructor
(
options
)
{
super
(
options
)
;
}
}
class
TranslationPipeline
extends
(
(
(
Text2TextGenerationPipeline
)
)
)
{
_key
=
'
translation_text
'
;
constructor
(
options
)
{
super
(
options
)
;
}
}
function
isChat
(
x
)
{
return
Array
.
isArray
(
x
)
&
&
x
.
every
(
x
=
>
'
role
'
in
x
&
&
'
content
'
in
x
)
;
}
class
TextGenerationPipeline
extends
(
(
Pipeline
)
)
{
constructor
(
options
)
{
super
(
options
)
;
}
async
_call
(
texts
generate_kwargs
=
{
}
)
{
let
isBatched
=
false
;
let
isChatInput
=
false
;
let
inputs
;
if
(
typeof
texts
=
=
=
'
string
'
)
{
inputs
=
texts
=
[
texts
]
;
}
else
if
(
Array
.
isArray
(
texts
)
&
&
texts
.
every
(
x
=
>
typeof
x
=
=
=
'
string
'
)
)
{
isBatched
=
true
;
inputs
=
(
texts
)
;
}
else
{
if
(
isChat
(
texts
)
)
{
texts
=
[
(
texts
)
]
;
}
else
if
(
Array
.
isArray
(
texts
)
&
&
texts
.
every
(
isChat
)
)
{
isBatched
=
true
;
}
else
{
throw
new
Error
(
'
Input
must
be
a
string
an
array
of
strings
a
Chat
or
an
array
of
Chats
'
)
;
}
isChatInput
=
true
;
inputs
=
(
(
texts
)
.
map
(
x
=
>
this
.
tokenizer
.
apply_chat_template
(
x
{
tokenize
:
false
add_generation_prompt
:
true
}
)
)
)
;
}
const
add_special_tokens
=
generate_kwargs
.
add_special_tokens
?
?
false
;
const
return_full_text
=
isChatInput
?
false
:
generate_kwargs
.
return_full_text
?
?
true
;
this
.
tokenizer
.
padding_side
=
'
left
'
;
const
text_inputs
=
this
.
tokenizer
(
inputs
{
add_special_tokens
padding
:
true
truncation
:
true
}
)
;
const
outputTokenIds
=
(
await
this
.
model
.
generate
(
{
.
.
.
text_inputs
.
.
.
generate_kwargs
}
)
)
;
const
decoded
=
this
.
tokenizer
.
batch_decode
(
outputTokenIds
{
skip_special_tokens
:
true
}
)
;
let
promptLengths
;
if
(
!
return_full_text
&
&
text_inputs
.
input_ids
.
dims
.
at
(
-
1
)
>
0
)
{
promptLengths
=
this
.
tokenizer
.
batch_decode
(
text_inputs
.
input_ids
{
skip_special_tokens
:
true
}
)
.
map
(
x
=
>
x
.
length
)
;
}
const
toReturn
=
Array
.
from
(
{
length
:
texts
.
length
}
_
=
>
[
]
)
;
for
(
let
i
=
0
;
i
<
decoded
.
length
;
+
+
i
)
{
const
textIndex
=
Math
.
floor
(
i
/
outputTokenIds
.
dims
[
0
]
*
texts
.
length
)
;
if
(
promptLengths
)
{
decoded
[
i
]
=
decoded
[
i
]
.
slice
(
promptLengths
[
textIndex
]
)
;
}
toReturn
[
textIndex
]
.
push
(
{
generated_text
:
isChatInput
?
[
.
.
.
(
(
(
texts
)
[
textIndex
]
)
)
{
role
:
'
assistant
'
content
:
decoded
[
i
]
}
]
:
decoded
[
i
]
}
)
;
}
return
(
!
isBatched
&
&
toReturn
.
length
=
=
=
1
)
?
toReturn
[
0
]
:
toReturn
;
}
}
class
ZeroShotClassificationPipeline
extends
(
(
Pipeline
)
)
{
constructor
(
options
)
{
super
(
options
)
;
this
.
label2id
=
Object
.
fromEntries
(
Object
.
entries
(
(
(
this
)
.
model
)
.
config
.
label2id
)
.
map
(
(
[
k
v
]
)
=
>
[
k
.
toLowerCase
(
)
v
]
)
)
;
this
.
entailment_id
=
this
.
label2id
[
'
entailment
'
]
;
if
(
this
.
entailment_id
=
=
=
undefined
)
{
console
.
warn
(
"
Could
not
find
'
entailment
'
in
label2id
mapping
.
Using
2
as
entailment_id
.
"
)
;
this
.
entailment_id
=
2
;
}
this
.
contradiction_id
=
this
.
label2id
[
'
contradiction
'
]
?
?
this
.
label2id
[
'
not_entailment
'
]
;
if
(
this
.
contradiction_id
=
=
=
undefined
)
{
console
.
warn
(
"
Could
not
find
'
contradiction
'
in
label2id
mapping
.
Using
0
as
contradiction_id
.
"
)
;
this
.
contradiction_id
=
0
;
}
}
async
_call
(
texts
candidate_labels
{
hypothesis_template
=
"
This
example
is
{
}
.
"
multi_label
=
false
}
=
{
}
)
{
const
isBatched
=
Array
.
isArray
(
texts
)
;
if
(
!
isBatched
)
{
texts
=
[
(
texts
)
]
;
}
if
(
!
Array
.
isArray
(
candidate_labels
)
)
{
candidate_labels
=
[
candidate_labels
]
;
}
const
hypotheses
=
candidate_labels
.
map
(
x
=
>
hypothesis_template
.
replace
(
'
{
}
'
x
)
)
;
const
softmaxEach
=
multi_label
|
|
candidate_labels
.
length
=
=
=
1
;
const
toReturn
=
[
]
;
for
(
const
premise
of
texts
)
{
const
entails_logits
=
[
]
;
for
(
const
hypothesis
of
hypotheses
)
{
const
inputs
=
this
.
tokenizer
(
premise
{
text_pair
:
hypothesis
padding
:
true
truncation
:
true
}
)
const
outputs
=
await
this
.
model
(
inputs
)
if
(
softmaxEach
)
{
entails_logits
.
push
(
[
outputs
.
logits
.
data
[
this
.
contradiction_id
]
outputs
.
logits
.
data
[
this
.
entailment_id
]
]
)
}
else
{
entails_logits
.
push
(
outputs
.
logits
.
data
[
this
.
entailment_id
]
)
}
}
const
scores
=
softmaxEach
?
entails_logits
.
map
(
x
=
>
(
0
_utils_maths_js__WEBPACK_IMPORTED_MODULE_6__
.
softmax
)
(
x
)
[
1
]
)
:
(
0
_utils_maths_js__WEBPACK_IMPORTED_MODULE_6__
.
softmax
)
(
entails_logits
)
;
const
scores_sorted
=
scores
.
map
(
(
x
i
)
=
>
[
x
i
]
)
.
sort
(
(
a
b
)
=
>
(
b
[
0
]
-
a
[
0
]
)
)
;
toReturn
.
push
(
{
sequence
:
premise
labels
:
scores_sorted
.
map
(
x
=
>
candidate_labels
[
x
[
1
]
]
)
scores
:
scores_sorted
.
map
(
x
=
>
x
[
0
]
)
}
)
;
}
return
isBatched
?
toReturn
:
toReturn
[
0
]
;
}
}
class
FeatureExtractionPipeline
extends
(
(
Pipeline
)
)
{
constructor
(
options
)
{
super
(
options
)
;
}
async
_call
(
texts
{
pooling
=
(
'
none
'
)
normalize
=
false
quantize
=
false
precision
=
(
'
binary
'
)
}
=
{
}
)
{
const
model_inputs
=
this
.
tokenizer
(
texts
{
padding
:
true
truncation
:
true
}
)
;
const
outputs
=
await
this
.
model
(
model_inputs
)
let
result
=
outputs
.
last_hidden_state
?
?
outputs
.
logits
?
?
outputs
.
token_embeddings
;
if
(
pooling
=
=
=
'
none
'
)
{
}
else
if
(
pooling
=
=
=
'
mean
'
)
{
result
=
(
0
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_8__
.
mean_pooling
)
(
result
model_inputs
.
attention_mask
)
;
}
else
if
(
pooling
=
=
=
'
cls
'
)
{
result
=
result
.
slice
(
null
0
)
;
}
else
{
throw
Error
(
Pooling
method
'
{
pooling
}
'
not
supported
.
)
;
}
if
(
normalize
)
{
result
=
result
.
normalize
(
2
-
1
)
;
}
if
(
quantize
)
{
result
=
(
0
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_8__
.
quantize_embeddings
)
(
result
precision
)
;
}
return
result
;
}
}
class
ImageFeatureExtractionPipeline
extends
(
(
Pipeline
)
)
{
constructor
(
options
)
{
super
(
options
)
;
}
async
_call
(
images
{
pool
=
null
}
=
{
}
)
{
const
preparedImages
=
await
prepareImages
(
images
)
;
const
{
pixel_values
}
=
await
this
.
processor
(
preparedImages
)
;
const
outputs
=
await
this
.
model
(
{
pixel_values
}
)
;
let
result
;
if
(
pool
)
{
if
(
!
(
'
pooler_output
'
in
outputs
)
)
{
throw
Error
(
No
pooled
output
was
returned
.
Make
sure
the
model
has
a
'
pooler
'
layer
when
using
the
'
pool
'
option
.
)
;
}
result
=
outputs
.
pooler_output
;
}
else
{
result
=
outputs
.
last_hidden_state
?
?
outputs
.
logits
?
?
outputs
.
image_embeds
;
}
return
result
;
}
}
class
AudioClassificationPipeline
extends
(
(
Pipeline
)
)
{
constructor
(
options
)
{
super
(
options
)
;
}
async
_call
(
audio
{
top_k
=
5
}
=
{
}
)
{
const
sampling_rate
=
this
.
processor
.
feature_extractor
.
config
.
sampling_rate
;
const
preparedAudios
=
await
prepareAudios
(
audio
sampling_rate
)
;
const
id2label
=
this
.
model
.
config
.
id2label
;
const
toReturn
=
[
]
;
for
(
const
aud
of
preparedAudios
)
{
const
inputs
=
await
this
.
processor
(
aud
)
;
const
output
=
await
this
.
model
(
inputs
)
;
const
logits
=
output
.
logits
[
0
]
;
const
scores
=
await
(
0
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_8__
.
topk
)
(
new
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_8__
.
Tensor
(
'
float32
'
(
0
_utils_maths_js__WEBPACK_IMPORTED_MODULE_6__
.
softmax
)
(
logits
.
data
)
logits
.
dims
)
top_k
)
;
const
values
=
scores
[
0
]
.
tolist
(
)
;
const
indices
=
scores
[
1
]
.
tolist
(
)
;
const
vals
=
indices
.
map
(
(
x
i
)
=
>
(
{
label
:
(
id2label
?
id2label
[
x
]
:
LABEL_
{
x
}
)
score
:
(
values
[
i
]
)
}
)
)
;
toReturn
.
push
(
vals
)
;
}
;
return
Array
.
isArray
(
audio
)
?
toReturn
:
toReturn
[
0
]
;
}
}
class
ZeroShotAudioClassificationPipeline
extends
(
(
Pipeline
)
)
{
constructor
(
options
)
{
super
(
options
)
;
}
async
_call
(
audio
candidate_labels
{
hypothesis_template
=
"
This
is
a
sound
of
{
}
.
"
}
=
{
}
)
{
const
single
=
!
Array
.
isArray
(
audio
)
;
if
(
single
)
{
audio
=
[
(
audio
)
]
;
}
const
texts
=
candidate_labels
.
map
(
x
=
>
hypothesis_template
.
replace
(
'
{
}
'
x
)
)
;
const
text_inputs
=
this
.
tokenizer
(
texts
{
padding
:
true
truncation
:
true
}
)
;
const
sampling_rate
=
this
.
processor
.
feature_extractor
.
config
.
sampling_rate
;
const
preparedAudios
=
await
prepareAudios
(
audio
sampling_rate
)
;
const
toReturn
=
[
]
;
for
(
const
aud
of
preparedAudios
)
{
const
audio_inputs
=
await
this
.
processor
(
aud
)
;
const
output
=
await
this
.
model
(
{
.
.
.
text_inputs
.
.
.
audio_inputs
}
)
;
const
probs
=
(
0
_utils_maths_js__WEBPACK_IMPORTED_MODULE_6__
.
softmax
)
(
output
.
logits_per_audio
.
data
)
;
toReturn
.
push
(
[
.
.
.
probs
]
.
map
(
(
x
i
)
=
>
(
{
score
:
x
label
:
candidate_labels
[
i
]
}
)
)
)
;
}
return
single
?
toReturn
[
0
]
:
toReturn
;
}
}
class
AutomaticSpeechRecognitionPipeline
extends
(
(
Pipeline
)
)
{
constructor
(
options
)
{
super
(
options
)
;
}
async
_call
(
audio
kwargs
=
{
}
)
{
switch
(
this
.
model
.
config
.
model_type
)
{
case
'
whisper
'
:
return
this
.
_call_whisper
(
audio
kwargs
)
case
'
wav2vec2
'
:
case
'
wav2vec2
-
bert
'
:
case
'
unispeech
'
:
case
'
unispeech
-
sat
'
:
case
'
hubert
'
:
return
this
.
_call_wav2vec2
(
audio
kwargs
)
default
:
throw
new
Error
(
AutomaticSpeechRecognitionPipeline
does
not
support
model
type
'
{
this
.
model
.
config
.
model_type
}
'
.
)
}
}
async
_call_wav2vec2
(
audio
kwargs
)
{
if
(
kwargs
.
language
)
{
console
.
warn
(
'
language
parameter
is
not
yet
supported
for
wav2vec2
models
defaulting
to
"
English
"
.
'
)
;
}
if
(
kwargs
.
task
)
{
console
.
warn
(
'
task
parameter
is
not
yet
supported
for
wav2vec2
models
defaulting
to
"
transcribe
"
.
'
)
;
}
const
single
=
!
Array
.
isArray
(
audio
)
;
if
(
single
)
{
audio
=
[
(
audio
)
]
;
}
const
sampling_rate
=
this
.
processor
.
feature_extractor
.
config
.
sampling_rate
;
const
preparedAudios
=
await
prepareAudios
(
audio
sampling_rate
)
;
const
toReturn
=
[
]
;
for
(
const
aud
of
preparedAudios
)
{
const
inputs
=
await
this
.
processor
(
aud
)
;
const
output
=
await
this
.
model
(
inputs
)
;
const
logits
=
output
.
logits
[
0
]
;
const
predicted_ids
=
[
]
;
for
(
const
item
of
logits
)
{
predicted_ids
.
push
(
(
0
_utils_maths_js__WEBPACK_IMPORTED_MODULE_6__
.
max
)
(
item
.
data
)
[
1
]
)
}
const
predicted_sentences
=
this
.
tokenizer
.
decode
(
predicted_ids
)
toReturn
.
push
(
{
text
:
predicted_sentences
}
)
}
return
single
?
toReturn
[
0
]
:
toReturn
;
}
async
_call_whisper
(
audio
kwargs
)
{
const
return_timestamps
=
kwargs
.
return_timestamps
?
?
false
;
const
chunk_length_s
=
kwargs
.
chunk_length_s
?
?
0
;
const
force_full_sequences
=
kwargs
.
force_full_sequences
?
?
false
;
let
stride_length_s
=
kwargs
.
stride_length_s
?
?
null
;
const
generation_config
=
{
.
.
.
kwargs
}
if
(
return_timestamps
=
=
=
'
word
'
)
{
generation_config
[
'
return_token_timestamps
'
]
=
true
;
generation_config
[
'
return_timestamps
'
]
=
false
;
}
const
single
=
!
Array
.
isArray
(
audio
)
;
if
(
single
)
{
audio
=
[
(
audio
)
]
;
}
const
time_precision
=
this
.
processor
.
feature_extractor
.
config
.
chunk_length
/
this
.
model
.
config
.
max_source_positions
;
const
hop_length
=
this
.
processor
.
feature_extractor
.
config
.
hop_length
;
const
sampling_rate
=
this
.
processor
.
feature_extractor
.
config
.
sampling_rate
;
const
preparedAudios
=
await
prepareAudios
(
audio
sampling_rate
)
;
const
toReturn
=
[
]
;
for
(
const
aud
of
preparedAudios
)
{
let
chunks
=
[
]
;
if
(
chunk_length_s
>
0
)
{
if
(
stride_length_s
=
=
=
null
)
{
stride_length_s
=
chunk_length_s
/
6
;
}
else
if
(
chunk_length_s
<
=
stride_length_s
)
{
throw
Error
(
"
chunk_length_s
must
be
larger
than
stride_length_s
.
"
)
}
const
window
=
sampling_rate
*
chunk_length_s
;
const
stride
=
sampling_rate
*
stride_length_s
;
const
jump
=
window
-
2
*
stride
;
let
offset
=
0
;
while
(
true
)
{
const
offset_end
=
offset
+
window
;
const
subarr
=
aud
.
subarray
(
offset
offset_end
)
;
const
feature
=
await
this
.
processor
(
subarr
)
;
const
is_first
=
offset
=
=
=
0
;
const
is_last
=
offset_end
>
=
aud
.
length
;
chunks
.
push
(
{
stride
:
[
subarr
.
length
is_first
?
0
:
stride
is_last
?
0
:
stride
]
input_features
:
feature
.
input_features
is_last
}
)
if
(
is_last
)
break
;
offset
+
=
jump
;
}
}
else
{
chunks
=
[
{
stride
:
[
aud
.
length
0
0
]
input_features
:
(
await
this
.
processor
(
aud
)
)
.
input_features
is_last
:
true
}
]
}
for
(
const
chunk
of
chunks
)
{
generation_config
.
num_frames
=
Math
.
floor
(
chunk
.
stride
[
0
]
/
hop_length
)
;
const
data
=
await
this
.
model
.
generate
(
{
inputs
:
chunk
.
input_features
.
.
.
generation_config
}
)
;
if
(
return_timestamps
=
=
=
'
word
'
)
{
chunk
.
tokens
=
data
.
sequences
.
tolist
(
)
[
0
]
;
chunk
.
token_timestamps
=
data
.
token_timestamps
.
tolist
(
)
[
0
]
.
map
(
(
x
)
=
>
(
0
_utils_maths_js__WEBPACK_IMPORTED_MODULE_6__
.
round
)
(
x
2
)
)
;
}
else
{
chunk
.
tokens
=
(
(
data
)
)
[
0
]
.
tolist
(
)
;
}
chunk
.
stride
=
chunk
.
stride
.
map
(
x
=
>
x
/
sampling_rate
)
;
}
const
[
full_text
optional
]
=
this
.
tokenizer
.
_decode_asr
(
chunks
{
time_precision
return_timestamps
force_full_sequences
}
)
;
toReturn
.
push
(
{
text
:
full_text
.
.
.
optional
}
)
}
return
single
?
toReturn
[
0
]
:
toReturn
;
}
}
class
ImageToTextPipeline
extends
(
(
Pipeline
)
)
{
constructor
(
options
)
{
super
(
options
)
;
}
async
_call
(
images
generate_kwargs
=
{
}
)
{
const
isBatched
=
Array
.
isArray
(
images
)
;
const
preparedImages
=
await
prepareImages
(
images
)
;
const
{
pixel_values
}
=
await
this
.
processor
(
preparedImages
)
;
const
toReturn
=
[
]
;
for
(
const
batch
of
pixel_values
)
{
batch
.
dims
=
[
1
.
.
.
batch
.
dims
]
const
output
=
await
this
.
model
.
generate
(
{
inputs
:
batch
.
.
.
generate_kwargs
}
)
;
const
decoded
=
this
.
tokenizer
.
batch_decode
(
(
output
)
{
skip_special_tokens
:
true
}
)
.
map
(
x
=
>
(
{
generated_text
:
x
.
trim
(
)
}
)
)
toReturn
.
push
(
decoded
)
;
}
return
isBatched
?
toReturn
:
toReturn
[
0
]
;
}
}
class
ImageClassificationPipeline
extends
(
(
Pipeline
)
)
{
constructor
(
options
)
{
super
(
options
)
;
}
async
_call
(
images
{
top_k
=
5
}
=
{
}
)
{
const
preparedImages
=
await
prepareImages
(
images
)
;
const
{
pixel_values
}
=
await
this
.
processor
(
preparedImages
)
;
const
output
=
await
this
.
model
(
{
pixel_values
}
)
;
const
id2label
=
this
.
model
.
config
.
id2label
;
const
toReturn
=
[
]
;
for
(
const
batch
of
output
.
logits
)
{
const
scores
=
await
(
0
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_8__
.
topk
)
(
new
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_8__
.
Tensor
(
'
float32
'
(
0
_utils_maths_js__WEBPACK_IMPORTED_MODULE_6__
.
softmax
)
(
batch
.
data
)
batch
.
dims
)
top_k
)
;
const
values
=
scores
[
0
]
.
tolist
(
)
;
const
indices
=
scores
[
1
]
.
tolist
(
)
;
const
vals
=
indices
.
map
(
(
x
i
)
=
>
(
{
label
:
(
id2label
?
id2label
[
x
]
:
LABEL_
{
x
}
)
score
:
(
values
[
i
]
)
}
)
)
;
toReturn
.
push
(
vals
)
;
}
return
Array
.
isArray
(
images
)
?
toReturn
:
toReturn
[
0
]
;
}
}
class
ImageSegmentationPipeline
extends
(
(
Pipeline
)
)
{
constructor
(
options
)
{
super
(
options
)
;
this
.
subtasks_mapping
=
{
panoptic
:
'
post_process_panoptic_segmentation
'
instance
:
'
post_process_instance_segmentation
'
semantic
:
'
post_process_semantic_segmentation
'
}
}
async
_call
(
images
{
threshold
=
0
.
5
mask_threshold
=
0
.
5
overlap_mask_area_threshold
=
0
.
8
label_ids_to_fuse
=
null
target_sizes
=
null
subtask
=
null
}
=
{
}
)
{
const
isBatched
=
Array
.
isArray
(
images
)
;
if
(
isBatched
&
&
images
.
length
!
=
=
1
)
{
throw
Error
(
"
Image
segmentation
pipeline
currently
only
supports
a
batch
size
of
1
.
"
)
;
}
const
preparedImages
=
await
prepareImages
(
images
)
;
const
imageSizes
=
preparedImages
.
map
(
x
=
>
[
x
.
height
x
.
width
]
)
;
const
{
pixel_values
pixel_mask
}
=
await
this
.
processor
(
preparedImages
)
;
const
output
=
await
this
.
model
(
{
pixel_values
pixel_mask
}
)
;
let
fn
=
null
;
if
(
subtask
!
=
=
null
)
{
fn
=
this
.
subtasks_mapping
[
subtask
]
;
}
else
{
for
(
let
[
task
func
]
of
Object
.
entries
(
this
.
subtasks_mapping
)
)
{
if
(
func
in
this
.
processor
.
image_processor
)
{
fn
=
this
.
processor
.
image_processor
[
func
]
.
bind
(
this
.
processor
.
image_processor
)
;
subtask
=
task
;
break
;
}
}
}
const
id2label
=
this
.
model
.
config
.
id2label
;
const
annotation
=
[
]
;
if
(
subtask
=
=
=
'
panoptic
'
|
|
subtask
=
=
=
'
instance
'
)
{
const
processed
=
fn
(
output
threshold
mask_threshold
overlap_mask_area_threshold
label_ids_to_fuse
target_sizes
?
?
imageSizes
)
[
0
]
;
const
segmentation
=
processed
.
segmentation
;
for
(
const
segment
of
processed
.
segments_info
)
{
const
maskData
=
new
Uint8ClampedArray
(
segmentation
.
data
.
length
)
;
for
(
let
i
=
0
;
i
<
segmentation
.
data
.
length
;
+
+
i
)
{
if
(
segmentation
.
data
[
i
]
=
=
=
segment
.
id
)
{
maskData
[
i
]
=
255
;
}
}
const
mask
=
new
_utils_image_js__WEBPACK_IMPORTED_MODULE_9__
.
RawImage
(
maskData
segmentation
.
dims
[
1
]
segmentation
.
dims
[
0
]
1
)
annotation
.
push
(
{
score
:
segment
.
score
label
:
id2label
[
segment
.
label_id
]
mask
:
mask
}
)
}
}
else
if
(
subtask
=
=
=
'
semantic
'
)
{
const
{
segmentation
labels
}
=
fn
(
output
target_sizes
?
?
imageSizes
)
[
0
]
;
for
(
const
label
of
labels
)
{
const
maskData
=
new
Uint8ClampedArray
(
segmentation
.
data
.
length
)
;
for
(
let
i
=
0
;
i
<
segmentation
.
data
.
length
;
+
+
i
)
{
if
(
segmentation
.
data
[
i
]
=
=
=
label
)
{
maskData
[
i
]
=
255
;
}
}
const
mask
=
new
_utils_image_js__WEBPACK_IMPORTED_MODULE_9__
.
RawImage
(
maskData
segmentation
.
dims
[
1
]
segmentation
.
dims
[
0
]
1
)
;
annotation
.
push
(
{
score
:
null
label
:
id2label
[
label
]
mask
:
mask
}
)
;
}
}
else
{
throw
Error
(
Subtask
{
subtask
}
not
supported
.
)
;
}
return
annotation
;
}
}
class
ZeroShotImageClassificationPipeline
extends
(
(
Pipeline
)
)
{
constructor
(
options
)
{
super
(
options
)
;
}
async
_call
(
images
candidate_labels
{
hypothesis_template
=
"
This
is
a
photo
of
{
}
"
}
=
{
}
)
{
const
isBatched
=
Array
.
isArray
(
images
)
;
const
preparedImages
=
await
prepareImages
(
images
)
;
const
texts
=
candidate_labels
.
map
(
x
=
>
hypothesis_template
.
replace
(
'
{
}
'
x
)
)
;
const
text_inputs
=
this
.
tokenizer
(
texts
{
padding
:
this
.
model
.
config
.
model_type
=
=
=
'
siglip
'
?
'
max_length
'
:
true
truncation
:
true
}
)
;
const
{
pixel_values
}
=
await
this
.
processor
(
preparedImages
)
;
const
output
=
await
this
.
model
(
{
.
.
.
text_inputs
pixel_values
}
)
;
const
function_to_apply
=
this
.
model
.
config
.
model_type
=
=
=
'
siglip
'
?
batch
=
>
batch
.
sigmoid
(
)
.
data
:
batch
=
>
(
0
_utils_maths_js__WEBPACK_IMPORTED_MODULE_6__
.
softmax
)
(
batch
.
data
)
;
const
toReturn
=
[
]
;
for
(
const
batch
of
output
.
logits_per_image
)
{
const
probs
=
function_to_apply
(
batch
)
;
const
result
=
[
.
.
.
probs
]
.
map
(
(
x
i
)
=
>
(
{
score
:
x
label
:
candidate_labels
[
i
]
}
)
)
;
result
.
sort
(
(
a
b
)
=
>
b
.
score
-
a
.
score
)
;
toReturn
.
push
(
result
)
;
}
return
isBatched
?
toReturn
:
toReturn
[
0
]
;
}
}
class
ObjectDetectionPipeline
extends
(
(
Pipeline
)
)
{
constructor
(
options
)
{
super
(
options
)
;
}
async
_call
(
images
{
threshold
=
0
.
9
percentage
=
false
}
=
{
}
)
{
const
isBatched
=
Array
.
isArray
(
images
)
;
if
(
isBatched
&
&
images
.
length
!
=
=
1
)
{
throw
Error
(
"
Object
detection
pipeline
currently
only
supports
a
batch
size
of
1
.
"
)
;
}
const
preparedImages
=
await
prepareImages
(
images
)
;
const
imageSizes
=
percentage
?
null
:
preparedImages
.
map
(
x
=
>
[
x
.
height
x
.
width
]
)
;
const
{
pixel_values
pixel_mask
}
=
await
this
.
processor
(
preparedImages
)
;
const
output
=
await
this
.
model
(
{
pixel_values
pixel_mask
}
)
;
const
processed
=
this
.
processor
.
image_processor
.
post_process_object_detection
(
output
threshold
imageSizes
)
;
const
id2label
=
this
.
model
.
config
.
id2label
;
const
result
=
processed
.
map
(
batch
=
>
(
batch
.
boxes
.
map
(
(
box
i
)
=
>
(
{
score
:
batch
.
scores
[
i
]
label
:
id2label
[
batch
.
classes
[
i
]
]
box
:
get_bounding_box
(
box
!
percentage
)
}
)
)
)
)
return
isBatched
?
result
:
result
[
0
]
;
}
}
class
ZeroShotObjectDetectionPipeline
extends
(
(
Pipeline
)
)
{
constructor
(
options
)
{
super
(
options
)
;
}
async
_call
(
images
candidate_labels
{
threshold
=
0
.
1
top_k
=
null
percentage
=
false
}
=
{
}
)
{
const
isBatched
=
Array
.
isArray
(
images
)
;
const
preparedImages
=
await
prepareImages
(
images
)
;
const
text_inputs
=
this
.
tokenizer
(
candidate_labels
{
padding
:
true
truncation
:
true
}
)
;
const
model_inputs
=
await
this
.
processor
(
preparedImages
)
;
const
toReturn
=
[
]
;
for
(
let
i
=
0
;
i
<
preparedImages
.
length
;
+
+
i
)
{
const
image
=
preparedImages
[
i
]
;
const
imageSize
=
percentage
?
null
:
[
[
image
.
height
image
.
width
]
]
;
const
pixel_values
=
model_inputs
.
pixel_values
[
i
]
.
unsqueeze_
(
0
)
;
const
output
=
await
this
.
model
(
{
.
.
.
text_inputs
pixel_values
}
)
;
const
processed
=
this
.
processor
.
image_processor
.
post_process_object_detection
(
output
threshold
imageSize
true
)
[
0
]
;
let
result
=
processed
.
boxes
.
map
(
(
box
i
)
=
>
(
{
score
:
processed
.
scores
[
i
]
label
:
candidate_labels
[
processed
.
classes
[
i
]
]
box
:
get_bounding_box
(
box
!
percentage
)
}
)
)
.
sort
(
(
a
b
)
=
>
b
.
score
-
a
.
score
)
;
if
(
top_k
!
=
=
null
)
{
result
=
result
.
slice
(
0
top_k
)
;
}
toReturn
.
push
(
result
)
}
return
isBatched
?
toReturn
:
toReturn
[
0
]
;
}
}
class
DocumentQuestionAnsweringPipeline
extends
(
(
Pipeline
)
)
{
constructor
(
options
)
{
super
(
options
)
;
}
async
_call
(
image
question
generate_kwargs
=
{
}
)
{
const
preparedImage
=
(
await
prepareImages
(
image
)
)
[
0
]
;
const
{
pixel_values
}
=
await
this
.
processor
(
preparedImage
)
;
const
task_prompt
=
<
s_docvqa
>
<
s_question
>
{
question
}
<
/
s_question
>
<
s_answer
>
;
const
decoder_input_ids
=
this
.
tokenizer
(
task_prompt
{
add_special_tokens
:
false
padding
:
true
truncation
:
true
}
)
.
input_ids
;
const
output
=
await
this
.
model
.
generate
(
{
inputs
:
pixel_values
max_length
:
this
.
model
.
config
.
decoder
.
max_position_embeddings
decoder_input_ids
.
.
.
generate_kwargs
}
)
;
const
decoded
=
this
.
tokenizer
.
batch_decode
(
(
output
)
)
[
0
]
;
const
match
=
decoded
.
match
(
/
<
s_answer
>
(
.
*
?
)
<
\
/
s_answer
>
/
)
;
let
answer
=
null
;
if
(
match
&
&
match
.
length
>
=
2
)
{
answer
=
match
[
1
]
.
trim
(
)
;
}
return
[
{
answer
}
]
;
}
}
class
TextToAudioPipeline
extends
(
(
Pipeline
)
)
{
DEFAULT_VOCODER_ID
=
"
Xenova
/
speecht5_hifigan
"
constructor
(
options
)
{
super
(
options
)
;
this
.
vocoder
=
options
.
vocoder
?
?
null
;
}
async
_call
(
text_inputs
{
speaker_embeddings
=
null
}
=
{
}
)
{
if
(
this
.
processor
)
{
return
this
.
_call_text_to_spectrogram
(
text_inputs
{
speaker_embeddings
}
)
;
}
else
{
return
this
.
_call_text_to_waveform
(
text_inputs
)
;
}
}
async
_call_text_to_waveform
(
text_inputs
)
{
const
inputs
=
this
.
tokenizer
(
text_inputs
{
padding
:
true
truncation
:
true
}
)
;
const
{
waveform
}
=
await
this
.
model
(
inputs
)
;
const
sampling_rate
=
this
.
model
.
config
.
sampling_rate
;
return
{
audio
:
waveform
.
data
sampling_rate
}
}
async
_call_text_to_spectrogram
(
text_inputs
{
speaker_embeddings
}
)
{
if
(
!
this
.
vocoder
)
{
console
.
log
(
'
No
vocoder
specified
using
default
HifiGan
vocoder
.
'
)
;
this
.
vocoder
=
await
_models_js__WEBPACK_IMPORTED_MODULE_1__
.
AutoModel
.
from_pretrained
(
this
.
DEFAULT_VOCODER_ID
{
dtype
:
'
fp32
'
}
)
;
}
if
(
typeof
speaker_embeddings
=
=
=
'
string
'
|
|
speaker_embeddings
instanceof
URL
)
{
speaker_embeddings
=
new
Float32Array
(
await
(
await
fetch
(
speaker_embeddings
)
)
.
arrayBuffer
(
)
)
;
}
if
(
speaker_embeddings
instanceof
Float32Array
)
{
speaker_embeddings
=
new
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_8__
.
Tensor
(
'
float32
'
speaker_embeddings
[
1
speaker_embeddings
.
length
]
)
}
else
if
(
!
(
speaker_embeddings
instanceof
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_8__
.
Tensor
)
)
{
throw
new
Error
(
"
Speaker
embeddings
must
be
a
Tensor
Float32Array
string
or
URL
.
"
)
}
const
{
input_ids
}
=
this
.
tokenizer
(
text_inputs
{
padding
:
true
truncation
:
true
}
)
;
const
{
waveform
}
=
await
this
.
model
.
generate_speech
(
input_ids
speaker_embeddings
{
vocoder
:
this
.
vocoder
}
)
;
const
sampling_rate
=
this
.
processor
.
feature_extractor
.
config
.
sampling_rate
;
return
{
audio
:
waveform
.
data
sampling_rate
}
}
}
class
ImageToImagePipeline
extends
(
(
Pipeline
)
)
{
constructor
(
options
)
{
super
(
options
)
;
}
async
_call
(
images
)
{
const
preparedImages
=
await
prepareImages
(
images
)
;
const
inputs
=
await
this
.
processor
(
preparedImages
)
;
const
outputs
=
await
this
.
model
(
inputs
)
;
const
toReturn
=
[
]
;
for
(
const
batch
of
outputs
.
reconstruction
)
{
const
output
=
batch
.
squeeze
(
)
.
clamp_
(
0
1
)
.
mul_
(
255
)
.
round_
(
)
.
to
(
'
uint8
'
)
;
toReturn
.
push
(
_utils_image_js__WEBPACK_IMPORTED_MODULE_9__
.
RawImage
.
fromTensor
(
output
)
)
;
}
return
toReturn
.
length
>
1
?
toReturn
:
toReturn
[
0
]
;
}
}
class
DepthEstimationPipeline
extends
(
(
Pipeline
)
)
{
constructor
(
options
)
{
super
(
options
)
;
}
async
_call
(
images
)
{
const
preparedImages
=
await
prepareImages
(
images
)
;
const
inputs
=
await
this
.
processor
(
preparedImages
)
;
const
{
predicted_depth
}
=
await
this
.
model
(
inputs
)
;
const
toReturn
=
[
]
;
for
(
let
i
=
0
;
i
<
preparedImages
.
length
;
+
+
i
)
{
const
prediction
=
(
0
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_8__
.
interpolate
)
(
predicted_depth
[
i
]
preparedImages
[
i
]
.
size
.
reverse
(
)
'
bilinear
'
false
)
;
const
formatted
=
prediction
.
mul_
(
255
/
(
0
_utils_maths_js__WEBPACK_IMPORTED_MODULE_6__
.
max
)
(
prediction
.
data
)
[
0
]
)
.
to
(
'
uint8
'
)
;
toReturn
.
push
(
{
predicted_depth
:
predicted_depth
[
i
]
depth
:
_utils_image_js__WEBPACK_IMPORTED_MODULE_9__
.
RawImage
.
fromTensor
(
formatted
)
}
)
;
}
return
toReturn
.
length
>
1
?
toReturn
:
toReturn
[
0
]
;
}
}
const
SUPPORTED_TASKS
=
Object
.
freeze
(
{
"
text
-
classification
"
:
{
"
tokenizer
"
:
_tokenizers_js__WEBPACK_IMPORTED_MODULE_0__
.
AutoTokenizer
"
pipeline
"
:
TextClassificationPipeline
"
model
"
:
_models_js__WEBPACK_IMPORTED_MODULE_1__
.
AutoModelForSequenceClassification
"
default
"
:
{
"
model
"
:
"
Xenova
/
distilbert
-
base
-
uncased
-
finetuned
-
sst
-
2
-
english
"
}
"
type
"
:
"
text
"
}
"
token
-
classification
"
:
{
"
tokenizer
"
:
_tokenizers_js__WEBPACK_IMPORTED_MODULE_0__
.
AutoTokenizer
"
pipeline
"
:
TokenClassificationPipeline
"
model
"
:
_models_js__WEBPACK_IMPORTED_MODULE_1__
.
AutoModelForTokenClassification
"
default
"
:
{
"
model
"
:
"
Xenova
/
bert
-
base
-
multilingual
-
cased
-
ner
-
hrl
"
}
"
type
"
:
"
text
"
}
"
question
-
answering
"
:
{
"
tokenizer
"
:
_tokenizers_js__WEBPACK_IMPORTED_MODULE_0__
.
AutoTokenizer
"
pipeline
"
:
QuestionAnsweringPipeline
"
model
"
:
_models_js__WEBPACK_IMPORTED_MODULE_1__
.
AutoModelForQuestionAnswering
"
default
"
:
{
"
model
"
:
"
Xenova
/
distilbert
-
base
-
cased
-
distilled
-
squad
"
}
"
type
"
:
"
text
"
}
"
fill
-
mask
"
:
{
"
tokenizer
"
:
_tokenizers_js__WEBPACK_IMPORTED_MODULE_0__
.
AutoTokenizer
"
pipeline
"
:
FillMaskPipeline
"
model
"
:
_models_js__WEBPACK_IMPORTED_MODULE_1__
.
AutoModelForMaskedLM
"
default
"
:
{
"
model
"
:
"
Xenova
/
bert
-
base
-
uncased
"
}
"
type
"
:
"
text
"
}
"
summarization
"
:
{
"
tokenizer
"
:
_tokenizers_js__WEBPACK_IMPORTED_MODULE_0__
.
AutoTokenizer
"
pipeline
"
:
SummarizationPipeline
"
model
"
:
_models_js__WEBPACK_IMPORTED_MODULE_1__
.
AutoModelForSeq2SeqLM
"
default
"
:
{
"
model
"
:
"
Xenova
/
distilbart
-
cnn
-
6
-
6
"
}
"
type
"
:
"
text
"
}
"
translation
"
:
{
"
tokenizer
"
:
_tokenizers_js__WEBPACK_IMPORTED_MODULE_0__
.
AutoTokenizer
"
pipeline
"
:
TranslationPipeline
"
model
"
:
_models_js__WEBPACK_IMPORTED_MODULE_1__
.
AutoModelForSeq2SeqLM
"
default
"
:
{
"
model
"
:
"
Xenova
/
t5
-
small
"
}
"
type
"
:
"
text
"
}
"
text2text
-
generation
"
:
{
"
tokenizer
"
:
_tokenizers_js__WEBPACK_IMPORTED_MODULE_0__
.
AutoTokenizer
"
pipeline
"
:
Text2TextGenerationPipeline
"
model
"
:
_models_js__WEBPACK_IMPORTED_MODULE_1__
.
AutoModelForSeq2SeqLM
"
default
"
:
{
"
model
"
:
"
Xenova
/
flan
-
t5
-
small
"
}
"
type
"
:
"
text
"
}
"
text
-
generation
"
:
{
"
tokenizer
"
:
_tokenizers_js__WEBPACK_IMPORTED_MODULE_0__
.
AutoTokenizer
"
pipeline
"
:
TextGenerationPipeline
"
model
"
:
_models_js__WEBPACK_IMPORTED_MODULE_1__
.
AutoModelForCausalLM
"
default
"
:
{
"
model
"
:
"
Xenova
/
gpt2
"
}
"
type
"
:
"
text
"
}
"
zero
-
shot
-
classification
"
:
{
"
tokenizer
"
:
_tokenizers_js__WEBPACK_IMPORTED_MODULE_0__
.
AutoTokenizer
"
pipeline
"
:
ZeroShotClassificationPipeline
"
model
"
:
_models_js__WEBPACK_IMPORTED_MODULE_1__
.
AutoModelForSequenceClassification
"
default
"
:
{
"
model
"
:
"
Xenova
/
distilbert
-
base
-
uncased
-
mnli
"
}
"
type
"
:
"
text
"
}
"
audio
-
classification
"
:
{
"
pipeline
"
:
AudioClassificationPipeline
"
model
"
:
_models_js__WEBPACK_IMPORTED_MODULE_1__
.
AutoModelForAudioClassification
"
processor
"
:
_models_auto_processing_auto_js__WEBPACK_IMPORTED_MODULE_2__
.
AutoProcessor
"
default
"
:
{
"
model
"
:
"
Xenova
/
wav2vec2
-
base
-
superb
-
ks
"
}
"
type
"
:
"
audio
"
}
"
zero
-
shot
-
audio
-
classification
"
:
{
"
tokenizer
"
:
_tokenizers_js__WEBPACK_IMPORTED_MODULE_0__
.
AutoTokenizer
"
pipeline
"
:
ZeroShotAudioClassificationPipeline
"
model
"
:
_models_js__WEBPACK_IMPORTED_MODULE_1__
.
AutoModel
"
processor
"
:
_models_auto_processing_auto_js__WEBPACK_IMPORTED_MODULE_2__
.
AutoProcessor
"
default
"
:
{
"
model
"
:
"
Xenova
/
clap
-
htsat
-
unfused
"
}
"
type
"
:
"
multimodal
"
}
"
automatic
-
speech
-
recognition
"
:
{
"
tokenizer
"
:
_tokenizers_js__WEBPACK_IMPORTED_MODULE_0__
.
AutoTokenizer
"
pipeline
"
:
AutomaticSpeechRecognitionPipeline
"
model
"
:
[
_models_js__WEBPACK_IMPORTED_MODULE_1__
.
AutoModelForSpeechSeq2Seq
_models_js__WEBPACK_IMPORTED_MODULE_1__
.
AutoModelForCTC
]
"
processor
"
:
_models_auto_processing_auto_js__WEBPACK_IMPORTED_MODULE_2__
.
AutoProcessor
"
default
"
:
{
"
model
"
:
"
Xenova
/
whisper
-
tiny
.
en
"
}
"
type
"
:
"
multimodal
"
}
"
text
-
to
-
audio
"
:
{
"
tokenizer
"
:
_tokenizers_js__WEBPACK_IMPORTED_MODULE_0__
.
AutoTokenizer
"
pipeline
"
:
TextToAudioPipeline
"
model
"
:
[
_models_js__WEBPACK_IMPORTED_MODULE_1__
.
AutoModelForTextToWaveform
_models_js__WEBPACK_IMPORTED_MODULE_1__
.
AutoModelForTextToSpectrogram
]
"
processor
"
:
[
_models_auto_processing_auto_js__WEBPACK_IMPORTED_MODULE_2__
.
AutoProcessor
null
]
"
default
"
:
{
"
model
"
:
"
Xenova
/
speecht5_tts
"
}
"
type
"
:
"
text
"
}
"
image
-
to
-
text
"
:
{
"
tokenizer
"
:
_tokenizers_js__WEBPACK_IMPORTED_MODULE_0__
.
AutoTokenizer
"
pipeline
"
:
ImageToTextPipeline
"
model
"
:
_models_js__WEBPACK_IMPORTED_MODULE_1__
.
AutoModelForVision2Seq
"
processor
"
:
_models_auto_processing_auto_js__WEBPACK_IMPORTED_MODULE_2__
.
AutoProcessor
"
default
"
:
{
"
model
"
:
"
Xenova
/
vit
-
gpt2
-
image
-
captioning
"
}
"
type
"
:
"
multimodal
"
}
"
image
-
classification
"
:
{
"
pipeline
"
:
ImageClassificationPipeline
"
model
"
:
_models_js__WEBPACK_IMPORTED_MODULE_1__
.
AutoModelForImageClassification
"
processor
"
:
_models_auto_processing_auto_js__WEBPACK_IMPORTED_MODULE_2__
.
AutoProcessor
"
default
"
:
{
"
model
"
:
"
Xenova
/
vit
-
base
-
patch16
-
224
"
}
"
type
"
:
"
multimodal
"
}
"
image
-
segmentation
"
:
{
"
pipeline
"
:
ImageSegmentationPipeline
"
model
"
:
[
_models_js__WEBPACK_IMPORTED_MODULE_1__
.
AutoModelForImageSegmentation
_models_js__WEBPACK_IMPORTED_MODULE_1__
.
AutoModelForSemanticSegmentation
_models_js__WEBPACK_IMPORTED_MODULE_1__
.
AutoModelForUniversalSegmentation
]
"
processor
"
:
_models_auto_processing_auto_js__WEBPACK_IMPORTED_MODULE_2__
.
AutoProcessor
"
default
"
:
{
"
model
"
:
"
Xenova
/
detr
-
resnet
-
50
-
panoptic
"
}
"
type
"
:
"
multimodal
"
}
"
zero
-
shot
-
image
-
classification
"
:
{
"
tokenizer
"
:
_tokenizers_js__WEBPACK_IMPORTED_MODULE_0__
.
AutoTokenizer
"
pipeline
"
:
ZeroShotImageClassificationPipeline
"
model
"
:
_models_js__WEBPACK_IMPORTED_MODULE_1__
.
AutoModel
"
processor
"
:
_models_auto_processing_auto_js__WEBPACK_IMPORTED_MODULE_2__
.
AutoProcessor
"
default
"
:
{
"
model
"
:
"
Xenova
/
clip
-
vit
-
base
-
patch32
"
}
"
type
"
:
"
multimodal
"
}
"
object
-
detection
"
:
{
"
pipeline
"
:
ObjectDetectionPipeline
"
model
"
:
_models_js__WEBPACK_IMPORTED_MODULE_1__
.
AutoModelForObjectDetection
"
processor
"
:
_models_auto_processing_auto_js__WEBPACK_IMPORTED_MODULE_2__
.
AutoProcessor
"
default
"
:
{
"
model
"
:
"
Xenova
/
detr
-
resnet
-
50
"
}
"
type
"
:
"
multimodal
"
}
"
zero
-
shot
-
object
-
detection
"
:
{
"
tokenizer
"
:
_tokenizers_js__WEBPACK_IMPORTED_MODULE_0__
.
AutoTokenizer
"
pipeline
"
:
ZeroShotObjectDetectionPipeline
"
model
"
:
_models_js__WEBPACK_IMPORTED_MODULE_1__
.
AutoModelForZeroShotObjectDetection
"
processor
"
:
_models_auto_processing_auto_js__WEBPACK_IMPORTED_MODULE_2__
.
AutoProcessor
"
default
"
:
{
"
model
"
:
"
Xenova
/
owlvit
-
base
-
patch32
"
}
"
type
"
:
"
multimodal
"
}
"
document
-
question
-
answering
"
:
{
"
tokenizer
"
:
_tokenizers_js__WEBPACK_IMPORTED_MODULE_0__
.
AutoTokenizer
"
pipeline
"
:
DocumentQuestionAnsweringPipeline
"
model
"
:
_models_js__WEBPACK_IMPORTED_MODULE_1__
.
AutoModelForDocumentQuestionAnswering
"
processor
"
:
_models_auto_processing_auto_js__WEBPACK_IMPORTED_MODULE_2__
.
AutoProcessor
"
default
"
:
{
"
model
"
:
"
Xenova
/
donut
-
base
-
finetuned
-
docvqa
"
}
"
type
"
:
"
multimodal
"
}
"
image
-
to
-
image
"
:
{
"
pipeline
"
:
ImageToImagePipeline
"
model
"
:
_models_js__WEBPACK_IMPORTED_MODULE_1__
.
AutoModelForImageToImage
"
processor
"
:
_models_auto_processing_auto_js__WEBPACK_IMPORTED_MODULE_2__
.
AutoProcessor
"
default
"
:
{
"
model
"
:
"
Xenova
/
swin2SR
-
classical
-
sr
-
x2
-
64
"
}
"
type
"
:
"
image
"
}
"
depth
-
estimation
"
:
{
"
pipeline
"
:
DepthEstimationPipeline
"
model
"
:
_models_js__WEBPACK_IMPORTED_MODULE_1__
.
AutoModelForDepthEstimation
"
processor
"
:
_models_auto_processing_auto_js__WEBPACK_IMPORTED_MODULE_2__
.
AutoProcessor
"
default
"
:
{
"
model
"
:
"
Xenova
/
dpt
-
large
"
}
"
type
"
:
"
image
"
}
"
feature
-
extraction
"
:
{
"
tokenizer
"
:
_tokenizers_js__WEBPACK_IMPORTED_MODULE_0__
.
AutoTokenizer
"
pipeline
"
:
FeatureExtractionPipeline
"
model
"
:
_models_js__WEBPACK_IMPORTED_MODULE_1__
.
AutoModel
"
default
"
:
{
"
model
"
:
"
Xenova
/
all
-
MiniLM
-
L6
-
v2
"
}
"
type
"
:
"
text
"
}
"
image
-
feature
-
extraction
"
:
{
"
processor
"
:
_models_auto_processing_auto_js__WEBPACK_IMPORTED_MODULE_2__
.
AutoProcessor
"
pipeline
"
:
ImageFeatureExtractionPipeline
"
model
"
:
[
_models_js__WEBPACK_IMPORTED_MODULE_1__
.
AutoModelForImageFeatureExtraction
_models_js__WEBPACK_IMPORTED_MODULE_1__
.
AutoModel
]
"
default
"
:
{
"
model
"
:
"
Xenova
/
vit
-
base
-
patch16
-
224
-
in21k
"
}
"
type
"
:
"
image
"
}
}
)
const
TASK_ALIASES
=
Object
.
freeze
(
{
"
sentiment
-
analysis
"
:
"
text
-
classification
"
"
ner
"
:
"
token
-
classification
"
"
asr
"
:
"
automatic
-
speech
-
recognition
"
"
text
-
to
-
speech
"
:
"
text
-
to
-
audio
"
"
embeddings
"
:
"
feature
-
extraction
"
}
)
;
async
function
pipeline
(
task
model
=
null
{
progress_callback
=
null
config
=
null
cache_dir
=
null
local_files_only
=
false
revision
=
'
main
'
device
=
null
dtype
=
null
model_file_name
=
null
session_options
=
{
}
}
=
{
}
)
{
task
=
TASK_ALIASES
[
task
]
?
?
task
;
const
pipelineInfo
=
SUPPORTED_TASKS
[
task
.
split
(
'
_
'
1
)
[
0
]
]
;
if
(
!
pipelineInfo
)
{
throw
Error
(
Unsupported
pipeline
:
{
task
}
.
Must
be
one
of
[
{
Object
.
keys
(
SUPPORTED_TASKS
)
}
]
)
}
if
(
!
model
)
{
model
=
pipelineInfo
.
default
.
model
console
.
log
(
No
model
specified
.
Using
default
model
:
"
{
model
}
"
.
)
;
}
const
pretrainedOptions
=
{
progress_callback
config
cache_dir
local_files_only
revision
device
dtype
model_file_name
session_options
}
const
classes
=
new
Map
(
[
[
'
tokenizer
'
pipelineInfo
.
tokenizer
]
[
'
model
'
pipelineInfo
.
model
]
[
'
processor
'
pipelineInfo
.
processor
]
]
)
;
const
results
=
await
loadItems
(
classes
model
pretrainedOptions
)
;
results
.
task
=
task
;
(
0
_utils_core_js__WEBPACK_IMPORTED_MODULE_5__
.
dispatchCallback
)
(
progress_callback
{
'
status
'
:
'
ready
'
'
task
'
:
task
'
model
'
:
model
}
)
;
const
pipelineClass
=
pipelineInfo
.
pipeline
;
return
new
pipelineClass
(
results
)
;
}
async
function
loadItems
(
mapping
model
pretrainedOptions
)
{
const
result
=
Object
.
create
(
null
)
;
const
promises
=
[
]
;
for
(
const
[
name
cls
]
of
mapping
.
entries
(
)
)
{
if
(
!
cls
)
continue
;
let
promise
;
if
(
Array
.
isArray
(
cls
)
)
{
promise
=
new
Promise
(
async
(
resolve
reject
)
=
>
{
let
e
;
for
(
const
c
of
cls
)
{
if
(
c
=
=
=
null
)
{
resolve
(
null
)
;
return
;
}
try
{
resolve
(
await
c
.
from_pretrained
(
model
pretrainedOptions
)
)
;
return
;
}
catch
(
err
)
{
if
(
err
.
message
?
.
includes
(
'
Unsupported
model
type
'
)
)
{
e
=
err
;
}
else
if
(
err
.
message
?
.
includes
(
'
Could
not
locate
file
'
)
)
{
e
=
err
;
}
else
{
reject
(
err
)
;
return
;
}
}
}
reject
(
e
)
;
}
)
}
else
{
promise
=
cls
.
from_pretrained
(
model
pretrainedOptions
)
;
}
result
[
name
]
=
promise
;
promises
.
push
(
promise
)
;
}
await
Promise
.
all
(
promises
)
;
for
(
const
[
name
promise
]
of
Object
.
entries
(
result
)
)
{
result
[
name
]
=
await
promise
;
}
return
result
;
}
}
)
"
.
/
src
/
tokenizers
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
AlbertTokenizer
:
(
)
=
>
(
AlbertTokenizer
)
AutoTokenizer
:
(
)
=
>
(
AutoTokenizer
)
BartTokenizer
:
(
)
=
>
(
BartTokenizer
)
BertTokenizer
:
(
)
=
>
(
BertTokenizer
)
BlenderbotSmallTokenizer
:
(
)
=
>
(
BlenderbotSmallTokenizer
)
BlenderbotTokenizer
:
(
)
=
>
(
BlenderbotTokenizer
)
BloomTokenizer
:
(
)
=
>
(
BloomTokenizer
)
CLIPTokenizer
:
(
)
=
>
(
CLIPTokenizer
)
CamembertTokenizer
:
(
)
=
>
(
CamembertTokenizer
)
CodeGenTokenizer
:
(
)
=
>
(
CodeGenTokenizer
)
CodeLlamaTokenizer
:
(
)
=
>
(
CodeLlamaTokenizer
)
CohereTokenizer
:
(
)
=
>
(
CohereTokenizer
)
ConvBertTokenizer
:
(
)
=
>
(
ConvBertTokenizer
)
DebertaTokenizer
:
(
)
=
>
(
DebertaTokenizer
)
DebertaV2Tokenizer
:
(
)
=
>
(
DebertaV2Tokenizer
)
DistilBertTokenizer
:
(
)
=
>
(
DistilBertTokenizer
)
ElectraTokenizer
:
(
)
=
>
(
ElectraTokenizer
)
EsmTokenizer
:
(
)
=
>
(
EsmTokenizer
)
FalconTokenizer
:
(
)
=
>
(
FalconTokenizer
)
GPT2Tokenizer
:
(
)
=
>
(
GPT2Tokenizer
)
GPTNeoXTokenizer
:
(
)
=
>
(
GPTNeoXTokenizer
)
GemmaTokenizer
:
(
)
=
>
(
GemmaTokenizer
)
Grok1Tokenizer
:
(
)
=
>
(
Grok1Tokenizer
)
HerbertTokenizer
:
(
)
=
>
(
HerbertTokenizer
)
LlamaTokenizer
:
(
)
=
>
(
LlamaTokenizer
)
M2M100Tokenizer
:
(
)
=
>
(
M2M100Tokenizer
)
MBart50Tokenizer
:
(
)
=
>
(
MBart50Tokenizer
)
MBartTokenizer
:
(
)
=
>
(
MBartTokenizer
)
MPNetTokenizer
:
(
)
=
>
(
MPNetTokenizer
)
MarianTokenizer
:
(
)
=
>
(
MarianTokenizer
)
MgpstrTokenizer
:
(
)
=
>
(
MgpstrTokenizer
)
MobileBertTokenizer
:
(
)
=
>
(
MobileBertTokenizer
)
NllbTokenizer
:
(
)
=
>
(
NllbTokenizer
)
NougatTokenizer
:
(
)
=
>
(
NougatTokenizer
)
PreTrainedTokenizer
:
(
)
=
>
(
PreTrainedTokenizer
)
Qwen2Tokenizer
:
(
)
=
>
(
Qwen2Tokenizer
)
RoFormerTokenizer
:
(
)
=
>
(
RoFormerTokenizer
)
RobertaTokenizer
:
(
)
=
>
(
RobertaTokenizer
)
SiglipTokenizer
:
(
)
=
>
(
SiglipTokenizer
)
SpeechT5Tokenizer
:
(
)
=
>
(
SpeechT5Tokenizer
)
SqueezeBertTokenizer
:
(
)
=
>
(
SqueezeBertTokenizer
)
T5Tokenizer
:
(
)
=
>
(
T5Tokenizer
)
TokenizerModel
:
(
)
=
>
(
TokenizerModel
)
VitsTokenizer
:
(
)
=
>
(
VitsTokenizer
)
Wav2Vec2CTCTokenizer
:
(
)
=
>
(
Wav2Vec2CTCTokenizer
)
WhisperTokenizer
:
(
)
=
>
(
WhisperTokenizer
)
XLMRobertaTokenizer
:
(
)
=
>
(
XLMRobertaTokenizer
)
XLMTokenizer
:
(
)
=
>
(
XLMTokenizer
)
is_chinese_char
:
(
)
=
>
(
is_chinese_char
)
}
)
;
var
_utils_generic_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
src
/
utils
/
generic
.
js
"
)
;
var
_utils_core_js__WEBPACK_IMPORTED_MODULE_1__
=
__webpack_require__
(
"
.
/
src
/
utils
/
core
.
js
"
)
;
var
_utils_hub_js__WEBPACK_IMPORTED_MODULE_2__
=
__webpack_require__
(
"
.
/
src
/
utils
/
hub
.
js
"
)
;
var
_utils_maths_js__WEBPACK_IMPORTED_MODULE_3__
=
__webpack_require__
(
"
.
/
src
/
utils
/
maths
.
js
"
)
;
var
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_4__
=
__webpack_require__
(
"
.
/
src
/
utils
/
tensor
.
js
"
)
;
var
_utils_data_structures_js__WEBPACK_IMPORTED_MODULE_5__
=
__webpack_require__
(
"
.
/
src
/
utils
/
data
-
structures
.
js
"
)
;
var
_huggingface_jinja__WEBPACK_IMPORTED_MODULE_6__
=
__webpack_require__
(
"
.
/
node_modules
/
huggingface
/
jinja
/
dist
/
index
.
js
"
)
;
var
_models_whisper_common_whisper_js__WEBPACK_IMPORTED_MODULE_7__
=
__webpack_require__
(
"
.
/
src
/
models
/
whisper
/
common_whisper
.
js
"
)
;
var
_utils_constants_js__WEBPACK_IMPORTED_MODULE_8__
=
__webpack_require__
(
"
.
/
src
/
utils
/
constants
.
js
"
)
;
async
function
loadTokenizer
(
pretrained_model_name_or_path
options
)
{
const
info
=
await
Promise
.
all
(
[
(
0
_utils_hub_js__WEBPACK_IMPORTED_MODULE_2__
.
getModelJSON
)
(
pretrained_model_name_or_path
'
tokenizer
.
json
'
true
options
)
(
0
_utils_hub_js__WEBPACK_IMPORTED_MODULE_2__
.
getModelJSON
)
(
pretrained_model_name_or_path
'
tokenizer_config
.
json
'
true
options
)
]
)
if
(
options
.
legacy
!
=
=
null
)
{
info
[
1
]
.
legacy
=
options
.
legacy
;
}
return
info
;
}
function
regexSplit
(
text
regex
)
{
const
result
=
[
]
;
let
prev
=
0
;
for
(
const
match
of
text
.
matchAll
(
regex
)
)
{
const
fullMatch
=
match
[
0
]
;
if
(
prev
<
match
.
index
)
{
result
.
push
(
text
.
slice
(
prev
match
.
index
)
)
;
}
if
(
fullMatch
.
length
>
0
)
{
result
.
push
(
fullMatch
)
;
}
prev
=
match
.
index
+
fullMatch
.
length
;
}
if
(
prev
<
text
.
length
)
{
result
.
push
(
text
.
slice
(
prev
)
)
;
}
return
result
;
}
function
createPattern
(
pattern
invert
=
true
)
{
if
(
pattern
.
Regex
!
=
=
undefined
)
{
let
regex
=
pattern
.
Regex
.
replace
(
/
\
\
(
[
#
&
~
]
)
/
g
'
1
'
)
;
for
(
const
[
key
value
]
of
PROBLEMATIC_REGEX_MAP
)
{
regex
=
regex
.
replaceAll
(
key
value
)
;
}
return
new
RegExp
(
regex
'
gu
'
)
;
}
else
if
(
pattern
.
String
!
=
=
undefined
)
{
const
escaped
=
(
0
_utils_core_js__WEBPACK_IMPORTED_MODULE_1__
.
escapeRegExp
)
(
pattern
.
String
)
;
return
new
RegExp
(
invert
?
escaped
:
(
{
escaped
}
)
'
gu
'
)
;
}
else
{
console
.
warn
(
'
Unknown
pattern
type
:
'
pattern
)
return
null
;
}
}
function
objectToMap
(
obj
)
{
return
new
Map
(
Object
.
entries
(
obj
)
)
;
}
function
prepareTensorForDecode
(
tensor
)
{
const
dims
=
tensor
.
dims
;
switch
(
dims
.
length
)
{
case
1
:
return
tensor
.
tolist
(
)
;
case
2
:
if
(
dims
[
0
]
!
=
=
1
)
{
throw
new
Error
(
'
Unable
to
decode
tensor
with
batch
size
!
=
=
1
.
Use
tokenizer
.
batch_decode
(
.
.
.
)
for
batched
inputs
.
'
)
;
}
return
tensor
.
tolist
(
)
[
0
]
;
default
:
throw
new
Error
(
Expected
tensor
to
have
1
-
2
dimensions
got
{
dims
.
length
}
.
)
}
}
function
clean_up_tokenization
(
text
)
{
return
text
.
replace
(
/
\
.
/
g
'
.
'
)
.
replace
(
/
\
?
/
g
'
?
'
)
.
replace
(
/
\
!
/
g
'
!
'
)
.
replace
(
/
/
g
'
'
)
.
replace
(
/
\
'
/
g
"
'
"
)
.
replace
(
/
n
\
'
t
/
g
"
n
'
t
"
)
.
replace
(
/
\
'
m
/
g
"
'
m
"
)
.
replace
(
/
\
'
s
/
g
"
'
s
"
)
.
replace
(
/
\
'
ve
/
g
"
'
ve
"
)
.
replace
(
/
\
'
re
/
g
"
'
re
"
)
;
}
function
remove_accents
(
text
)
{
return
text
.
replace
(
/
\
p
{
M
}
/
gu
'
'
)
;
}
function
lowercase_and_remove_accent
(
text
)
{
return
remove_accents
(
text
.
toLowerCase
(
)
)
;
}
function
is_chinese_char
(
cp
)
{
return
(
(
cp
>
=
0x4E00
&
&
cp
<
=
0x9FFF
)
|
|
(
cp
>
=
0x3400
&
&
cp
<
=
0x4DBF
)
|
|
(
cp
>
=
0x20000
&
&
cp
<
=
0x2A6DF
)
|
|
(
cp
>
=
0x2A700
&
&
cp
<
=
0x2B73F
)
|
|
(
cp
>
=
0x2B740
&
&
cp
<
=
0x2B81F
)
|
|
(
cp
>
=
0x2B820
&
&
cp
<
=
0x2CEAF
)
|
|
(
cp
>
=
0xF900
&
&
cp
<
=
0xFAFF
)
|
|
(
cp
>
=
0x2F800
&
&
cp
<
=
0x2FA1F
)
)
}
function
fuse_unk
(
arr
tokens_to_ids
unk_token_id
)
{
const
fused
=
[
]
;
let
i
=
0
;
while
(
i
<
arr
.
length
)
{
fused
.
push
(
arr
[
i
]
)
if
(
(
tokens_to_ids
.
get
(
arr
[
i
]
)
?
?
unk_token_id
)
!
=
=
unk_token_id
)
{
+
+
i
;
continue
;
}
while
(
+
+
i
<
arr
.
length
&
&
(
tokens_to_ids
.
get
(
arr
[
i
]
)
?
?
unk_token_id
)
=
=
=
unk_token_id
)
{
if
(
tokens_to_ids
.
get
(
fused
.
at
(
-
1
)
)
!
=
=
unk_token_id
)
{
fused
[
fused
.
length
-
1
]
+
=
arr
[
i
]
;
}
}
}
return
fused
;
}
function
whitespace_split
(
text
)
{
return
text
.
match
(
/
\
S
+
/
g
)
|
|
[
]
;
}
const
PUNCTUATION_REGEX
=
'
\
\
p
{
P
}
\
\
u0021
-
\
\
u002F
\
\
u003A
-
\
\
u0040
\
\
u005B
-
\
\
u0060
\
\
u007B
-
\
\
u007E
'
;
const
PUNCTUATION_ONLY_REGEX
=
new
RegExp
(
^
[
{
PUNCTUATION_REGEX
}
]
+
'
gu
'
)
;
const
BLOOM_SPLIT_CHARS
=
'
.
!
?
\
u2026
\
u3002
\
uff0c
\
u3001
\
u0964
\
u06d4
\
u060c
'
;
const
PROBLEMATIC_REGEX_MAP
=
new
Map
(
[
[
"
(
?
i
:
'
s
|
'
t
|
'
re
|
'
ve
|
'
m
|
'
ll
|
'
d
)
"
"
(
?
:
'
(
[
sS
]
|
[
tT
]
|
[
rR
]
[
eE
]
|
[
vV
]
[
eE
]
|
[
mM
]
|
[
lL
]
[
lL
]
|
[
dD
]
)
)
"
]
[
?
[
^
(
\
\
s
|
[
{
BLOOM_SPLIT_CHARS
}
]
)
]
+
?
[
^
\
\
s
{
BLOOM_SPLIT_CHARS
}
]
+
]
]
)
class
AddedToken
{
constructor
(
config
)
{
this
.
content
=
config
.
content
;
this
.
id
=
config
.
id
;
this
.
single_word
=
config
.
single_word
?
?
false
;
this
.
lstrip
=
config
.
lstrip
?
?
false
;
this
.
rstrip
=
config
.
rstrip
?
?
false
;
this
.
special
=
config
.
special
?
?
false
;
this
.
normalized
=
config
.
normalized
?
?
null
;
}
}
class
TokenizerModel
extends
_utils_generic_js__WEBPACK_IMPORTED_MODULE_0__
.
Callable
{
constructor
(
config
)
{
super
(
)
;
this
.
config
=
config
;
this
.
vocab
=
[
]
;
this
.
tokens_to_ids
=
new
Map
(
)
;
this
.
unk_token_id
=
undefined
;
this
.
unk_token
=
undefined
;
this
.
end_of_word_suffix
=
undefined
;
this
.
fuse_unk
=
this
.
config
.
fuse_unk
?
?
false
;
}
static
fromConfig
(
config
.
.
.
args
)
{
switch
(
config
.
type
)
{
case
'
WordPiece
'
:
return
new
WordPieceTokenizer
(
config
)
;
case
'
Unigram
'
:
return
new
Unigram
(
config
.
.
.
args
)
;
case
'
BPE
'
:
return
new
BPE
(
config
)
;
default
:
if
(
config
.
vocab
)
{
if
(
Array
.
isArray
(
config
.
vocab
)
)
{
return
new
Unigram
(
config
.
.
.
args
)
;
}
else
{
return
new
LegacyTokenizerModel
(
config
.
.
.
args
)
;
}
}
throw
new
Error
(
Unknown
TokenizerModel
type
:
{
config
.
type
}
)
;
}
}
_call
(
tokens
)
{
tokens
=
this
.
encode
(
tokens
)
;
if
(
this
.
fuse_unk
)
{
tokens
=
fuse_unk
(
tokens
this
.
tokens_to_ids
this
.
unk_token_id
)
;
}
return
tokens
;
}
encode
(
tokens
)
{
throw
Error
(
"
encode
should
be
implemented
in
subclass
.
"
)
}
convert_tokens_to_ids
(
tokens
)
{
return
tokens
.
map
(
t
=
>
this
.
tokens_to_ids
.
get
(
t
)
?
?
this
.
unk_token_id
)
;
}
convert_ids_to_tokens
(
ids
)
{
return
ids
.
map
(
i
=
>
this
.
vocab
[
i
]
?
?
this
.
unk_token
)
;
}
}
class
WordPieceTokenizer
extends
TokenizerModel
{
constructor
(
config
)
{
super
(
config
)
;
this
.
tokens_to_ids
=
objectToMap
(
config
.
vocab
)
;
this
.
unk_token_id
=
this
.
tokens_to_ids
.
get
(
config
.
unk_token
)
;
this
.
unk_token
=
config
.
unk_token
;
this
.
max_input_chars_per_word
=
config
.
max_input_chars_per_word
?
?
100
;
this
.
vocab
=
new
Array
(
this
.
tokens_to_ids
.
size
)
;
for
(
const
[
key
value
]
of
this
.
tokens_to_ids
)
{
this
.
vocab
[
value
]
=
key
;
}
}
encode
(
tokens
)
{
const
outputTokens
=
[
]
;
for
(
const
token
of
tokens
)
{
const
chars
=
[
.
.
.
token
]
;
if
(
chars
.
length
>
this
.
max_input_chars_per_word
)
{
outputTokens
.
push
(
this
.
unk_token
)
;
continue
;
}
let
isUnknown
=
false
;
let
start
=
0
;
const
subTokens
=
[
]
;
while
(
start
<
chars
.
length
)
{
let
end
=
chars
.
length
;
let
currentSubstring
=
null
;
while
(
start
<
end
)
{
let
substr
=
chars
.
slice
(
start
end
)
.
join
(
'
'
)
;
if
(
start
>
0
)
{
substr
=
this
.
config
.
continuing_subword_prefix
+
substr
;
}
if
(
this
.
tokens_to_ids
.
has
(
substr
)
)
{
currentSubstring
=
substr
;
break
;
}
-
-
end
;
}
if
(
currentSubstring
=
=
=
null
)
{
isUnknown
=
true
;
break
;
}
subTokens
.
push
(
currentSubstring
)
;
start
=
end
;
}
if
(
isUnknown
)
{
outputTokens
.
push
(
this
.
unk_token
)
;
}
else
{
outputTokens
.
push
(
.
.
.
subTokens
)
;
}
}
return
outputTokens
;
}
}
class
Unigram
extends
TokenizerModel
{
constructor
(
config
moreConfig
)
{
super
(
config
)
;
const
vocabSize
=
config
.
vocab
.
length
;
this
.
vocab
=
new
Array
(
vocabSize
)
;
this
.
scores
=
new
Array
(
vocabSize
)
;
for
(
let
i
=
0
;
i
<
vocabSize
;
+
+
i
)
{
const
piece
=
config
.
vocab
[
i
]
;
this
.
vocab
[
i
]
=
piece
[
0
]
;
this
.
scores
[
i
]
=
piece
[
1
]
;
}
this
.
unk_token_id
=
config
.
unk_id
;
this
.
unk_token
=
this
.
vocab
[
config
.
unk_id
]
;
this
.
tokens_to_ids
=
new
Map
(
this
.
vocab
.
map
(
(
x
i
)
=
>
[
x
i
]
)
)
;
this
.
bos_token
=
'
'
;
this
.
bos_token_id
=
this
.
tokens_to_ids
.
get
(
this
.
bos_token
)
;
this
.
eos_token
=
moreConfig
.
eos_token
;
this
.
eos_token_id
=
this
.
tokens_to_ids
.
get
(
this
.
eos_token
)
;
this
.
unk_token
=
this
.
vocab
[
this
.
unk_token_id
]
;
this
.
minScore
=
(
0
_utils_maths_js__WEBPACK_IMPORTED_MODULE_3__
.
min
)
(
this
.
scores
)
[
0
]
;
this
.
unk_score
=
this
.
minScore
-
10
.
0
;
this
.
scores
[
this
.
unk_token_id
]
=
this
.
unk_score
;
this
.
trie
=
new
_utils_data_structures_js__WEBPACK_IMPORTED_MODULE_5__
.
CharTrie
(
)
;
this
.
trie
.
extend
(
this
.
vocab
)
;
this
.
fuse_unk
=
true
;
}
populateNodes
(
lattice
)
{
const
chars
=
lattice
.
chars
;
const
mblen
=
1
;
let
beginPos
=
0
;
while
(
beginPos
<
chars
.
length
)
{
let
hasSingleNode
=
false
;
const
tokens
=
[
]
;
const
sliced
=
chars
.
slice
(
beginPos
)
.
join
(
'
'
)
;
const
prefixedTokens
=
this
.
trie
.
commonPrefixSearch
(
sliced
)
;
for
(
const
token
of
prefixedTokens
)
{
tokens
.
push
(
token
)
;
const
tokenId
=
this
.
tokens_to_ids
.
get
(
token
)
;
const
tokenScore
=
this
.
scores
[
tokenId
]
;
const
n
=
(
0
_utils_core_js__WEBPACK_IMPORTED_MODULE_1__
.
len
)
(
token
)
;
lattice
.
insert
(
beginPos
n
tokenScore
tokenId
)
;
if
(
!
hasSingleNode
&
&
n
=
=
=
mblen
)
{
hasSingleNode
=
true
;
}
}
if
(
!
hasSingleNode
)
{
lattice
.
insert
(
beginPos
mblen
this
.
unk_score
this
.
unk_token_id
)
;
}
beginPos
+
=
mblen
;
}
}
tokenize
(
normalized
)
{
const
lattice
=
new
_utils_data_structures_js__WEBPACK_IMPORTED_MODULE_5__
.
TokenLattice
(
normalized
this
.
bos_token_id
this
.
eos_token_id
)
;
this
.
populateNodes
(
lattice
)
;
return
lattice
.
tokens
(
)
;
}
encode
(
tokens
)
{
const
toReturn
=
[
]
;
for
(
const
token
of
tokens
)
{
const
tokenized
=
this
.
tokenize
(
token
)
;
toReturn
.
push
(
.
.
.
tokenized
)
;
}
return
toReturn
;
}
}
const
BYTES_TO_UNICODE
=
(
(
)
=
>
{
const
bs
=
[
.
.
.
Array
.
from
(
{
length
:
"
~
"
.
charCodeAt
(
0
)
-
"
!
"
.
charCodeAt
(
0
)
+
1
}
(
_
i
)
=
>
i
+
"
!
"
.
charCodeAt
(
0
)
)
.
.
.
Array
.
from
(
{
length
:
"
"
.
charCodeAt
(
0
)
-
"
"
.
charCodeAt
(
0
)
+
1
}
(
_
i
)
=
>
i
+
"
"
.
charCodeAt
(
0
)
)
.
.
.
Array
.
from
(
{
length
:
"
"
.
charCodeAt
(
0
)
-
"
"
.
charCodeAt
(
0
)
+
1
}
(
_
i
)
=
>
i
+
"
"
.
charCodeAt
(
0
)
)
]
;
const
cs
=
bs
.
slice
(
)
;
let
n
=
0
;
for
(
let
b
=
0
;
b
<
256
;
+
+
b
)
{
if
(
!
bs
.
includes
(
b
)
)
{
bs
.
push
(
b
)
;
cs
.
push
(
256
+
n
)
;
n
+
=
1
;
}
}
const
ccs
=
cs
.
map
(
n
=
>
String
.
fromCharCode
(
n
)
)
;
return
Object
.
fromEntries
(
bs
.
map
(
(
b
i
)
=
>
[
b
ccs
[
i
]
]
)
)
;
}
)
(
)
;
const
UNICODE_TO_BYTES
=
(
0
_utils_core_js__WEBPACK_IMPORTED_MODULE_1__
.
reverseDictionary
)
(
BYTES_TO_UNICODE
)
;
class
BPE
extends
TokenizerModel
{
constructor
(
config
)
{
super
(
config
)
;
this
.
tokens_to_ids
=
objectToMap
(
config
.
vocab
)
;
this
.
unk_token_id
=
this
.
tokens_to_ids
.
get
(
config
.
unk_token
)
;
this
.
unk_token
=
config
.
unk_token
;
this
.
vocab
=
new
Array
(
this
.
tokens_to_ids
.
size
)
;
for
(
const
[
key
value
]
of
this
.
tokens_to_ids
)
{
this
.
vocab
[
value
]
=
key
;
}
const
use_new_merge_format
=
Array
.
isArray
(
config
.
merges
[
0
]
)
;
this
.
merges
=
use_new_merge_format
?
(
config
.
merges
)
:
(
(
config
.
merges
)
)
.
map
(
x
=
>
(
x
.
split
(
'
'
2
)
)
)
;
this
.
bpe_ranks
=
new
Map
(
this
.
merges
.
map
(
(
x
i
)
=
>
[
JSON
.
stringify
(
x
)
i
]
)
)
;
this
.
end_of_word_suffix
=
config
.
end_of_word_suffix
;
this
.
continuing_subword_suffix
=
config
.
continuing_subword_suffix
?
?
null
;
this
.
byte_fallback
=
this
.
config
.
byte_fallback
?
?
false
;
if
(
this
.
byte_fallback
)
{
this
.
text_encoder
=
new
TextEncoder
(
)
;
}
this
.
ignore_merges
=
this
.
config
.
ignore_merges
?
?
false
;
this
.
cache
=
new
Map
(
)
;
}
bpe
(
token
)
{
if
(
token
.
length
=
=
=
0
)
{
return
[
]
;
}
const
cached
=
this
.
cache
.
get
(
token
)
;
if
(
cached
!
=
=
undefined
)
{
return
cached
;
}
const
word
=
Array
.
from
(
token
)
;
if
(
this
.
end_of_word_suffix
)
{
word
[
word
.
length
-
1
]
+
=
this
.
end_of_word_suffix
;
}
let
result
=
[
]
;
if
(
word
.
length
>
1
)
{
const
queue
=
new
_utils_data_structures_js__WEBPACK_IMPORTED_MODULE_5__
.
PriorityQueue
(
(
a
b
)
=
>
a
.
score
<
b
.
score
)
;
let
startingNode
=
{
token
:
word
[
0
]
bias
:
0
prev
:
null
next
:
null
}
let
previousNode
=
startingNode
for
(
let
i
=
1
;
i
<
word
.
length
;
+
+
i
)
{
const
currentNode
=
{
bias
:
i
/
word
.
length
token
:
word
[
i
]
prev
:
previousNode
next
:
null
}
previousNode
.
next
=
currentNode
this
.
_add_node
(
queue
previousNode
)
previousNode
=
currentNode
}
while
(
!
queue
.
isEmpty
(
)
)
{
const
node
=
queue
.
pop
(
)
;
if
(
node
.
deleted
|
|
!
node
.
next
|
|
node
.
next
.
deleted
)
continue
;
node
.
deleted
=
true
;
node
.
next
.
deleted
=
true
;
if
(
node
.
prev
)
{
const
newPreviousNode
=
{
.
.
.
node
.
prev
}
;
node
.
prev
.
deleted
=
true
;
node
.
prev
=
newPreviousNode
;
if
(
newPreviousNode
.
prev
)
{
newPreviousNode
.
prev
.
next
=
newPreviousNode
;
}
else
{
startingNode
=
newPreviousNode
;
}
}
const
merged
=
{
token
:
node
.
token
+
node
.
next
.
token
bias
:
node
.
bias
prev
:
node
.
prev
next
:
node
.
next
.
next
}
if
(
merged
.
prev
)
{
merged
.
prev
.
next
=
merged
;
this
.
_add_node
(
queue
merged
.
prev
)
;
}
else
{
startingNode
=
merged
;
}
if
(
merged
.
next
)
{
merged
.
next
.
prev
=
merged
;
this
.
_add_node
(
queue
merged
)
;
}
}
for
(
let
currentNode
=
startingNode
;
currentNode
!
=
=
null
;
currentNode
=
currentNode
.
next
)
{
result
.
push
(
currentNode
.
token
)
;
}
}
else
{
result
=
word
;
}
if
(
this
.
continuing_subword_suffix
)
{
for
(
let
i
=
0
;
i
<
result
.
length
-
1
;
+
+
i
)
{
result
[
i
]
+
=
this
.
continuing_subword_suffix
;
}
}
this
.
cache
.
set
(
token
result
)
;
return
result
;
}
_add_node
(
queue
node
)
{
const
rank
=
this
.
bpe_ranks
.
get
(
JSON
.
stringify
(
[
node
.
token
node
.
next
.
token
]
)
)
;
if
(
rank
!
=
=
undefined
)
{
node
.
score
=
rank
+
node
.
bias
;
queue
.
push
(
node
)
;
}
}
encode
(
tokens
)
{
const
outputTokens
=
[
]
;
for
(
const
token
of
tokens
)
{
if
(
this
.
ignore_merges
&
&
this
.
tokens_to_ids
.
has
(
token
)
)
{
outputTokens
.
push
(
token
)
;
continue
;
}
const
bpe_token_list
=
this
.
bpe
(
token
)
;
for
(
const
t
of
bpe_token_list
)
{
if
(
this
.
tokens_to_ids
.
has
(
t
)
)
{
outputTokens
.
push
(
t
)
;
}
else
if
(
this
.
byte_fallback
)
{
const
byteTokens
=
Array
.
from
(
this
.
text_encoder
.
encode
(
t
)
)
.
map
(
x
=
>
<
0x
{
x
.
toString
(
16
)
.
toUpperCase
(
)
.
padStart
(
2
'
0
'
)
}
>
)
;
if
(
byteTokens
.
every
(
x
=
>
this
.
tokens_to_ids
.
has
(
x
)
)
)
{
outputTokens
.
push
(
.
.
.
byteTokens
)
;
}
else
{
outputTokens
.
push
(
this
.
unk_token
)
;
}
}
else
{
outputTokens
.
push
(
this
.
unk_token
)
;
}
}
}
return
outputTokens
;
}
}
class
LegacyTokenizerModel
extends
TokenizerModel
{
constructor
(
config
moreConfig
)
{
super
(
config
)
;
this
.
tokens_to_ids
=
objectToMap
(
moreConfig
.
target_lang
?
config
.
vocab
[
moreConfig
.
target_lang
]
:
config
.
vocab
)
;
this
.
bos_token
=
moreConfig
.
bos_token
;
this
.
bos_token_id
=
this
.
tokens_to_ids
.
get
(
this
.
bos_token
)
;
this
.
eos_token
=
moreConfig
.
eos_token
;
this
.
eos_token_id
=
this
.
tokens_to_ids
.
get
(
this
.
eos_token
)
;
this
.
pad_token
=
moreConfig
.
pad_token
;
this
.
pad_token_id
=
this
.
tokens_to_ids
.
get
(
this
.
pad_token
)
;
this
.
unk_token
=
moreConfig
.
unk_token
;
this
.
unk_token_id
=
this
.
tokens_to_ids
.
get
(
this
.
unk_token
)
;
this
.
vocab
=
new
Array
(
this
.
tokens_to_ids
.
size
)
;
for
(
const
[
key
value
]
of
this
.
tokens_to_ids
)
{
this
.
vocab
[
value
]
=
key
;
}
}
encode
(
tokens
)
{
return
tokens
;
}
}
class
Normalizer
extends
_utils_generic_js__WEBPACK_IMPORTED_MODULE_0__
.
Callable
{
constructor
(
config
)
{
super
(
)
;
this
.
config
=
config
;
}
static
fromConfig
(
config
)
{
if
(
config
=
=
=
null
)
return
null
;
switch
(
config
.
type
)
{
case
'
BertNormalizer
'
:
return
new
BertNormalizer
(
config
)
;
case
'
Precompiled
'
:
return
new
Precompiled
(
config
)
;
case
'
Sequence
'
:
return
new
NormalizerSequence
(
config
)
;
case
'
Replace
'
:
return
new
Replace
(
config
)
;
case
'
NFC
'
:
return
new
NFC
(
config
)
;
case
'
NFKC
'
:
return
new
NFKC
(
config
)
;
case
'
NFKD
'
:
return
new
NFKD
(
config
)
;
case
'
Strip
'
:
return
new
StripNormalizer
(
config
)
;
case
'
StripAccents
'
:
return
new
StripAccents
(
config
)
;
case
'
Lowercase
'
:
return
new
Lowercase
(
config
)
;
case
'
Prepend
'
:
return
new
Prepend
(
config
)
;
default
:
throw
new
Error
(
Unknown
Normalizer
type
:
{
config
.
type
}
)
;
}
}
normalize
(
text
)
{
throw
Error
(
"
normalize
should
be
implemented
in
subclass
.
"
)
}
_call
(
text
)
{
return
this
.
normalize
(
text
)
;
}
}
class
Replace
extends
Normalizer
{
normalize
(
text
)
{
const
pattern
=
createPattern
(
this
.
config
.
pattern
)
;
return
pattern
=
=
=
null
?
text
:
text
.
replaceAll
(
pattern
this
.
config
.
content
)
;
}
}
class
NFC
extends
Normalizer
{
normalize
(
text
)
{
text
=
text
.
normalize
(
'
NFC
'
)
return
text
;
}
}
class
NFKC
extends
Normalizer
{
normalize
(
text
)
{
text
=
text
.
normalize
(
'
NFKC
'
)
return
text
;
}
}
class
NFKD
extends
Normalizer
{
normalize
(
text
)
{
text
=
text
.
normalize
(
'
NFKD
'
)
return
text
;
}
}
class
StripNormalizer
extends
Normalizer
{
normalize
(
text
)
{
if
(
this
.
config
.
strip_left
&
&
this
.
config
.
strip_right
)
{
text
=
text
.
trim
(
)
;
}
else
{
if
(
this
.
config
.
strip_left
)
{
text
=
text
.
trimStart
(
)
;
}
if
(
this
.
config
.
strip_right
)
{
text
=
text
.
trimEnd
(
)
;
}
}
return
text
;
}
}
class
StripAccents
extends
Normalizer
{
normalize
(
text
)
{
text
=
remove_accents
(
text
)
;
return
text
;
}
}
class
Lowercase
extends
Normalizer
{
normalize
(
text
)
{
text
=
text
.
toLowerCase
(
)
;
return
text
;
}
}
class
Prepend
extends
Normalizer
{
normalize
(
text
)
{
text
=
this
.
config
.
prepend
+
text
;
return
text
;
}
}
class
NormalizerSequence
extends
Normalizer
{
constructor
(
config
)
{
super
(
config
)
;
this
.
normalizers
=
config
.
normalizers
.
map
(
x
=
>
Normalizer
.
fromConfig
(
x
)
)
;
}
normalize
(
text
)
{
return
this
.
normalizers
.
reduce
(
(
t
normalizer
)
=
>
{
return
normalizer
.
normalize
(
t
)
;
}
text
)
;
}
}
class
BertNormalizer
extends
Normalizer
{
_tokenize_chinese_chars
(
text
)
{
const
output
=
[
]
;
for
(
let
i
=
0
;
i
<
text
.
length
;
+
+
i
)
{
const
char
=
text
[
i
]
;
const
cp
=
char
.
charCodeAt
(
0
)
;
if
(
is_chinese_char
(
cp
)
)
{
output
.
push
(
"
"
)
;
output
.
push
(
char
)
;
output
.
push
(
"
"
)
;
}
else
{
output
.
push
(
char
)
;
}
}
return
output
.
join
(
"
"
)
;
}
stripAccents
(
text
)
{
return
text
.
normalize
(
'
NFD
'
)
.
replace
(
/
\
p
{
Mn
}
/
gu
'
'
)
;
}
_is_control
(
char
)
{
switch
(
char
)
{
case
'
\
t
'
:
case
'
\
n
'
:
case
'
\
r
'
:
return
false
;
default
:
return
/
^
\
p
{
Cc
}
|
\
p
{
Cf
}
|
\
p
{
Co
}
|
\
p
{
Cs
}
/
u
.
test
(
char
)
;
}
}
_clean_text
(
text
)
{
const
output
=
[
]
;
for
(
const
char
of
text
)
{
const
cp
=
char
.
charCodeAt
(
0
)
;
if
(
cp
=
=
=
0
|
|
cp
=
=
=
0xFFFD
|
|
this
.
_is_control
(
char
)
)
{
continue
;
}
if
(
/
^
\
s
/
.
test
(
char
)
)
{
output
.
push
(
"
"
)
;
}
else
{
output
.
push
(
char
)
;
}
}
return
output
.
join
(
"
"
)
;
}
normalize
(
text
)
{
if
(
this
.
config
.
clean_text
)
{
text
=
this
.
_clean_text
(
text
)
;
}
if
(
this
.
config
.
handle_chinese_chars
)
{
text
=
this
.
_tokenize_chinese_chars
(
text
)
;
}
if
(
this
.
config
.
lowercase
)
{
text
=
text
.
toLowerCase
(
)
;
if
(
this
.
config
.
strip_accents
!
=
=
false
)
{
text
=
this
.
stripAccents
(
text
)
;
}
}
else
if
(
this
.
config
.
strip_accents
)
{
text
=
this
.
stripAccents
(
text
)
;
}
return
text
;
}
}
class
PreTokenizer
extends
_utils_generic_js__WEBPACK_IMPORTED_MODULE_0__
.
Callable
{
static
fromConfig
(
config
)
{
if
(
config
=
=
=
null
)
return
null
;
switch
(
config
.
type
)
{
case
'
BertPreTokenizer
'
:
return
new
BertPreTokenizer
(
config
)
;
case
'
Sequence
'
:
return
new
PreTokenizerSequence
(
config
)
;
case
'
Whitespace
'
:
return
new
WhitespacePreTokenizer
(
config
)
;
case
'
WhitespaceSplit
'
:
return
new
WhitespaceSplit
(
config
)
;
case
'
Metaspace
'
:
return
new
MetaspacePreTokenizer
(
config
)
;
case
'
ByteLevel
'
:
return
new
ByteLevelPreTokenizer
(
config
)
;
case
'
Split
'
:
return
new
SplitPreTokenizer
(
config
)
;
case
'
Punctuation
'
:
return
new
PunctuationPreTokenizer
(
config
)
;
case
'
Digits
'
:
return
new
DigitsPreTokenizer
(
config
)
;
case
'
Replace
'
:
return
new
ReplacePreTokenizer
(
config
)
;
default
:
throw
new
Error
(
Unknown
PreTokenizer
type
:
{
config
.
type
}
)
;
}
}
pre_tokenize_text
(
text
options
)
{
throw
Error
(
"
pre_tokenize_text
should
be
implemented
in
subclass
.
"
)
}
pre_tokenize
(
text
options
)
{
return
(
Array
.
isArray
(
text
)
?
text
.
map
(
x
=
>
this
.
pre_tokenize_text
(
x
options
)
)
:
this
.
pre_tokenize_text
(
text
options
)
)
.
flat
(
)
;
}
_call
(
text
options
)
{
return
this
.
pre_tokenize
(
text
options
)
;
}
}
class
BertPreTokenizer
extends
PreTokenizer
{
constructor
(
config
)
{
super
(
)
;
this
.
pattern
=
new
RegExp
(
[
^
\
\
s
{
PUNCTUATION_REGEX
}
]
+
|
[
{
PUNCTUATION_REGEX
}
]
'
gu
'
)
;
}
pre_tokenize_text
(
text
options
)
{
return
text
.
trim
(
)
.
match
(
this
.
pattern
)
|
|
[
]
;
}
}
class
ByteLevelPreTokenizer
extends
PreTokenizer
{
constructor
(
config
)
{
super
(
)
;
this
.
config
=
config
;
this
.
add_prefix_space
=
this
.
config
.
add_prefix_space
;
this
.
trim_offsets
=
this
.
config
.
trim_offsets
;
this
.
use_regex
=
this
.
config
.
use_regex
?
?
true
;
this
.
pattern
=
/
'
s
|
'
t
|
'
re
|
'
ve
|
'
m
|
'
ll
|
'
d
|
?
\
p
{
L
}
+
|
?
\
p
{
N
}
+
|
?
[
^
\
s
\
p
{
L
}
\
p
{
N
}
]
+
|
\
s
+
(
?
!
\
S
)
|
\
s
+
/
gu
;
this
.
byte_encoder
=
BYTES_TO_UNICODE
;
this
.
text_encoder
=
new
TextEncoder
(
)
;
}
pre_tokenize_text
(
text
options
)
{
if
(
this
.
add_prefix_space
&
&
!
text
.
startsWith
(
'
'
)
)
{
text
=
'
'
+
text
;
}
const
tokens
=
this
.
use_regex
?
(
text
.
match
(
this
.
pattern
)
|
|
[
]
)
:
[
text
]
;
return
tokens
.
map
(
token
=
>
Array
.
from
(
this
.
text_encoder
.
encode
(
token
)
byte
=
>
this
.
byte_encoder
[
byte
]
)
.
join
(
'
'
)
)
;
}
}
class
SplitPreTokenizer
extends
PreTokenizer
{
constructor
(
config
)
{
super
(
)
;
this
.
config
=
config
;
this
.
pattern
=
createPattern
(
this
.
config
.
pattern
this
.
config
.
invert
)
;
}
pre_tokenize_text
(
text
options
)
{
if
(
this
.
pattern
=
=
=
null
)
{
return
[
]
;
}
if
(
this
.
config
.
invert
)
{
return
text
.
match
(
this
.
pattern
)
|
|
[
]
;
}
else
if
(
this
.
config
.
behavior
?
.
toLowerCase
(
)
=
=
=
'
removed
'
)
{
return
text
.
split
(
this
.
pattern
)
.
filter
(
x
=
>
x
)
;
}
else
{
return
regexSplit
(
text
this
.
pattern
)
;
}
}
}
class
PunctuationPreTokenizer
extends
PreTokenizer
{
constructor
(
config
)
{
super
(
)
;
this
.
config
=
config
;
this
.
pattern
=
new
RegExp
(
[
^
{
PUNCTUATION_REGEX
}
]
+
|
[
{
PUNCTUATION_REGEX
}
]
+
'
gu
'
)
;
}
pre_tokenize_text
(
text
options
)
{
return
text
.
match
(
this
.
pattern
)
|
|
[
]
;
}
}
class
DigitsPreTokenizer
extends
PreTokenizer
{
constructor
(
config
)
{
super
(
)
;
this
.
config
=
config
;
const
digit_pattern
=
[
^
\
\
d
]
+
|
\
\
d
{
this
.
config
.
individual_digits
?
'
'
:
'
+
'
}
;
this
.
pattern
=
new
RegExp
(
digit_pattern
'
gu
'
)
;
}
pre_tokenize_text
(
text
options
)
{
return
text
.
match
(
this
.
pattern
)
|
|
[
]
;
}
}
class
PostProcessor
extends
_utils_generic_js__WEBPACK_IMPORTED_MODULE_0__
.
Callable
{
constructor
(
config
)
{
super
(
)
;
this
.
config
=
config
;
}
static
fromConfig
(
config
)
{
if
(
config
=
=
=
null
)
return
null
;
switch
(
config
.
type
)
{
case
'
TemplateProcessing
'
:
return
new
TemplateProcessing
(
config
)
;
case
'
ByteLevel
'
:
return
new
ByteLevelPostProcessor
(
config
)
;
case
'
RobertaProcessing
'
:
return
new
RobertaProcessing
(
config
)
;
case
'
BertProcessing
'
:
return
new
BertProcessing
(
config
)
;
case
'
Sequence
'
:
return
new
PostProcessorSequence
(
config
)
;
default
:
throw
new
Error
(
Unknown
PostProcessor
type
:
{
config
.
type
}
)
;
}
}
post_process
(
tokens
.
.
.
args
)
{
throw
Error
(
"
post_process
should
be
implemented
in
subclass
.
"
)
}
_call
(
tokens
.
.
.
args
)
{
return
this
.
post_process
(
tokens
.
.
.
args
)
;
}
}
class
BertProcessing
extends
PostProcessor
{
constructor
(
config
)
{
super
(
config
)
;
this
.
cls
=
config
.
cls
[
0
]
;
this
.
sep
=
config
.
sep
[
0
]
;
}
post_process
(
tokens
tokens_pair
=
null
{
add_special_tokens
=
true
}
=
{
}
)
{
if
(
add_special_tokens
)
{
tokens
=
(
0
_utils_core_js__WEBPACK_IMPORTED_MODULE_1__
.
mergeArrays
)
(
[
this
.
cls
]
tokens
[
this
.
sep
]
)
;
}
let
token_type_ids
=
new
Array
(
tokens
.
length
)
.
fill
(
0
)
;
if
(
tokens_pair
!
=
=
null
)
{
const
middle
=
(
add_special_tokens
&
&
this
instanceof
RobertaProcessing
)
?
[
this
.
sep
]
:
[
]
;
const
after
=
add_special_tokens
?
[
this
.
sep
]
:
[
]
;
tokens
=
(
0
_utils_core_js__WEBPACK_IMPORTED_MODULE_1__
.
mergeArrays
)
(
tokens
middle
tokens_pair
after
)
;
token_type_ids
=
(
0
_utils_core_js__WEBPACK_IMPORTED_MODULE_1__
.
mergeArrays
)
(
token_type_ids
new
Array
(
tokens_pair
.
length
+
middle
.
length
+
after
.
length
)
.
fill
(
1
)
)
;
}
return
{
tokens
token_type_ids
}
;
}
}
class
RobertaProcessing
extends
BertProcessing
{
}
class
TemplateProcessing
extends
PostProcessor
{
constructor
(
config
)
{
super
(
config
)
;
this
.
single
=
config
.
single
;
this
.
pair
=
config
.
pair
;
}
post_process
(
tokens
tokens_pair
=
null
{
add_special_tokens
=
true
}
=
{
}
)
{
const
type
=
tokens_pair
=
=
=
null
?
this
.
single
:
this
.
pair
let
processedTokens
=
[
]
;
let
types
=
[
]
;
for
(
const
item
of
type
)
{
if
(
'
SpecialToken
'
in
item
)
{
if
(
add_special_tokens
)
{
processedTokens
.
push
(
item
.
SpecialToken
.
id
)
;
types
.
push
(
item
.
SpecialToken
.
type_id
)
;
}
}
else
if
(
'
Sequence
'
in
item
)
{
if
(
item
.
Sequence
.
id
=
=
=
'
A
'
)
{
processedTokens
=
(
0
_utils_core_js__WEBPACK_IMPORTED_MODULE_1__
.
mergeArrays
)
(
processedTokens
tokens
)
;
types
=
(
0
_utils_core_js__WEBPACK_IMPORTED_MODULE_1__
.
mergeArrays
)
(
types
new
Array
(
tokens
.
length
)
.
fill
(
item
.
Sequence
.
type_id
)
)
;
}
else
if
(
item
.
Sequence
.
id
=
=
=
'
B
'
)
{
processedTokens
=
(
0
_utils_core_js__WEBPACK_IMPORTED_MODULE_1__
.
mergeArrays
)
(
processedTokens
tokens_pair
)
;
types
=
(
0
_utils_core_js__WEBPACK_IMPORTED_MODULE_1__
.
mergeArrays
)
(
types
new
Array
(
tokens_pair
.
length
)
.
fill
(
item
.
Sequence
.
type_id
)
)
;
}
}
}
return
{
tokens
:
processedTokens
token_type_ids
:
types
}
;
}
}
class
ByteLevelPostProcessor
extends
PostProcessor
{
post_process
(
tokens
tokens_pair
=
null
)
{
if
(
tokens_pair
)
{
tokens
=
(
0
_utils_core_js__WEBPACK_IMPORTED_MODULE_1__
.
mergeArrays
)
(
tokens
tokens_pair
)
;
}
return
{
tokens
}
;
}
}
class
PostProcessorSequence
extends
PostProcessor
{
constructor
(
config
)
{
super
(
config
)
;
this
.
processors
=
config
.
processors
.
map
(
x
=
>
PostProcessor
.
fromConfig
(
x
)
)
;
}
post_process
(
tokens
tokens_pair
=
null
options
=
{
}
)
{
let
token_type_ids
;
for
(
const
processor
of
this
.
processors
)
{
if
(
processor
instanceof
ByteLevelPostProcessor
)
{
const
output
=
processor
.
post_process
(
tokens
)
;
tokens
=
output
.
tokens
;
if
(
tokens_pair
)
{
const
pair_output
=
processor
.
post_process
(
tokens_pair
)
;
tokens_pair
=
pair_output
.
tokens
;
}
}
else
{
const
output
=
processor
.
post_process
(
tokens
tokens_pair
options
)
;
tokens
=
output
.
tokens
;
token_type_ids
=
output
.
token_type_ids
;
}
}
return
{
tokens
token_type_ids
}
;
}
}
class
Decoder
extends
_utils_generic_js__WEBPACK_IMPORTED_MODULE_0__
.
Callable
{
constructor
(
config
)
{
super
(
)
;
this
.
config
=
config
;
this
.
added_tokens
=
[
]
;
this
.
end_of_word_suffix
=
null
;
this
.
trim_offsets
=
config
.
trim_offsets
;
}
static
fromConfig
(
config
)
{
if
(
config
=
=
=
null
)
return
null
;
switch
(
config
.
type
)
{
case
'
WordPiece
'
:
return
new
WordPieceDecoder
(
config
)
;
case
'
Metaspace
'
:
return
new
MetaspaceDecoder
(
config
)
;
case
'
ByteLevel
'
:
return
new
ByteLevelDecoder
(
config
)
;
case
'
Replace
'
:
return
new
ReplaceDecoder
(
config
)
;
case
'
ByteFallback
'
:
return
new
ByteFallback
(
config
)
;
case
'
Fuse
'
:
return
new
FuseDecoder
(
config
)
;
case
'
Strip
'
:
return
new
StripDecoder
(
config
)
;
case
'
Sequence
'
:
return
new
DecoderSequence
(
config
)
;
case
'
CTC
'
:
return
new
CTCDecoder
(
config
)
;
case
'
BPEDecoder
'
:
return
new
BPEDecoder
(
config
)
;
default
:
throw
new
Error
(
Unknown
Decoder
type
:
{
config
.
type
}
)
;
}
}
_call
(
tokens
)
{
return
this
.
decode
(
tokens
)
;
}
decode
(
tokens
)
{
return
this
.
decode_chain
(
tokens
)
.
join
(
'
'
)
;
}
decode_chain
(
tokens
)
{
throw
Error
(
"
decode_chain
should
be
implemented
in
subclass
.
"
)
}
}
class
ReplaceDecoder
extends
Decoder
{
decode_chain
(
tokens
)
{
const
pattern
=
createPattern
(
this
.
config
.
pattern
)
;
return
pattern
=
=
=
null
?
tokens
:
tokens
.
map
(
token
=
>
token
.
replaceAll
(
pattern
this
.
config
.
content
)
)
}
}
class
ByteFallback
extends
Decoder
{
constructor
(
config
)
{
super
(
config
)
;
this
.
text_decoder
=
new
TextDecoder
(
)
;
}
decode_chain
(
tokens
)
{
const
new_tokens
=
[
]
;
let
previous_byte_tokens
=
[
]
;
for
(
const
token
of
tokens
)
{
let
bytes
=
null
;
if
(
token
.
length
=
=
=
6
&
&
token
.
startsWith
(
'
<
0x
'
)
&
&
token
.
endsWith
(
'
>
'
)
)
{
const
byte
=
parseInt
(
token
.
slice
(
3
5
)
16
)
;
if
(
!
isNaN
(
byte
)
)
{
bytes
=
byte
;
}
}
if
(
bytes
!
=
=
null
)
{
previous_byte_tokens
.
push
(
bytes
)
;
}
else
{
if
(
previous_byte_tokens
.
length
>
0
)
{
const
string
=
this
.
text_decoder
.
decode
(
Uint8Array
.
from
(
previous_byte_tokens
)
)
;
new_tokens
.
push
(
string
)
;
previous_byte_tokens
=
[
]
;
}
new_tokens
.
push
(
token
)
;
}
}
if
(
previous_byte_tokens
.
length
>
0
)
{
const
string
=
this
.
text_decoder
.
decode
(
Uint8Array
.
from
(
previous_byte_tokens
)
)
;
new_tokens
.
push
(
string
)
;
previous_byte_tokens
=
[
]
;
}
return
new_tokens
;
}
}
class
FuseDecoder
extends
Decoder
{
decode_chain
(
tokens
)
{
return
[
tokens
.
join
(
'
'
)
]
;
}
}
class
StripDecoder
extends
Decoder
{
constructor
(
config
)
{
super
(
config
)
;
this
.
content
=
this
.
config
.
content
;
this
.
start
=
this
.
config
.
start
;
this
.
stop
=
this
.
config
.
stop
;
}
decode_chain
(
tokens
)
{
return
tokens
.
map
(
token
=
>
{
let
start_cut
=
0
;
for
(
let
i
=
0
;
i
<
this
.
start
;
+
+
i
)
{
if
(
token
[
i
]
=
=
=
this
.
content
)
{
start_cut
=
i
+
1
;
continue
;
}
else
{
break
;
}
}
let
stop_cut
=
token
.
length
;
for
(
let
i
=
0
;
i
<
this
.
stop
;
+
+
i
)
{
const
index
=
token
.
length
-
i
-
1
;
if
(
token
[
index
]
=
=
=
this
.
content
)
{
stop_cut
=
index
;
continue
;
}
else
{
break
;
}
}
return
token
.
slice
(
start_cut
stop_cut
)
}
)
;
}
}
class
WordPieceDecoder
extends
Decoder
{
constructor
(
config
)
{
super
(
config
)
;
this
.
cleanup
=
config
.
cleanup
;
}
decode_chain
(
tokens
)
{
return
tokens
.
map
(
(
token
i
)
=
>
{
if
(
i
!
=
=
0
)
{
if
(
token
.
startsWith
(
this
.
config
.
prefix
)
)
{
token
=
token
.
replace
(
this
.
config
.
prefix
'
'
)
;
}
else
{
token
=
'
'
+
token
;
}
}
if
(
this
.
cleanup
)
{
token
=
clean_up_tokenization
(
token
)
}
return
token
;
}
)
;
}
}
class
ByteLevelDecoder
extends
Decoder
{
constructor
(
config
)
{
super
(
config
)
;
this
.
byte_decoder
=
UNICODE_TO_BYTES
;
this
.
text_decoder
=
new
TextDecoder
(
"
utf
-
8
"
{
fatal
:
false
ignoreBOM
:
true
}
)
;
this
.
end_of_word_suffix
=
null
;
}
convert_tokens_to_string
(
tokens
)
{
const
text
=
tokens
.
join
(
'
'
)
;
const
byteArray
=
new
Uint8Array
(
[
.
.
.
text
]
.
map
(
c
=
>
this
.
byte_decoder
[
c
]
)
)
;
const
decoded_text
=
this
.
text_decoder
.
decode
(
byteArray
)
;
return
decoded_text
;
}
decode_chain
(
tokens
)
{
const
sub_texts
=
[
]
;
let
current_sub_text
=
[
]
;
for
(
const
token
of
tokens
)
{
if
(
this
.
added_tokens
.
find
(
x
=
>
x
.
content
=
=
=
token
)
!
=
=
undefined
)
{
if
(
current_sub_text
.
length
>
0
)
{
sub_texts
.
push
(
this
.
convert_tokens_to_string
(
current_sub_text
)
)
;
current_sub_text
=
[
]
;
}
sub_texts
.
push
(
token
)
;
}
else
{
current_sub_text
.
push
(
token
)
;
}
}
if
(
current_sub_text
.
length
>
0
)
{
sub_texts
.
push
(
this
.
convert_tokens_to_string
(
current_sub_text
)
)
;
}
return
sub_texts
;
}
}
class
CTCDecoder
extends
Decoder
{
constructor
(
config
)
{
super
(
config
)
;
this
.
pad_token
=
this
.
config
.
pad_token
;
this
.
word_delimiter_token
=
this
.
config
.
word_delimiter_token
;
this
.
cleanup
=
this
.
config
.
cleanup
;
}
convert_tokens_to_string
(
tokens
)
{
if
(
tokens
.
length
=
=
=
0
)
return
'
'
;
const
grouped_tokens
=
[
tokens
[
0
]
]
;
for
(
let
i
=
1
;
i
<
tokens
.
length
;
+
+
i
)
{
if
(
tokens
[
i
]
!
=
=
grouped_tokens
.
at
(
-
1
)
)
{
grouped_tokens
.
push
(
tokens
[
i
]
)
;
}
}
const
filtered_tokens
=
grouped_tokens
.
filter
(
token
=
>
token
!
=
=
this
.
pad_token
)
;
let
text
=
filtered_tokens
.
join
(
'
'
)
;
if
(
this
.
cleanup
)
{
text
=
clean_up_tokenization
(
text
)
.
replaceAll
(
this
.
word_delimiter_token
'
'
)
.
trim
(
)
;
}
return
text
;
}
decode_chain
(
tokens
)
{
return
[
this
.
convert_tokens_to_string
(
tokens
)
]
;
}
}
class
DecoderSequence
extends
Decoder
{
constructor
(
config
)
{
super
(
config
)
;
this
.
decoders
=
config
.
decoders
.
map
(
x
=
>
Decoder
.
fromConfig
(
x
)
)
;
}
decode_chain
(
tokens
)
{
return
this
.
decoders
.
reduce
(
(
toks
decoder
)
=
>
{
return
decoder
.
decode_chain
(
toks
)
;
}
tokens
)
;
}
}
class
BPEDecoder
extends
Decoder
{
constructor
(
config
)
{
super
(
config
)
;
this
.
suffix
=
this
.
config
.
suffix
;
}
decode_chain
(
tokens
)
{
return
tokens
.
map
(
(
token
i
)
=
>
{
return
token
.
replaceAll
(
this
.
suffix
(
i
=
=
=
tokens
.
length
-
1
)
?
'
'
:
'
'
)
}
)
;
}
}
class
VitsDecoder
extends
Decoder
{
decode_chain
(
tokens
)
{
let
decoded
=
'
'
;
for
(
let
i
=
1
;
i
<
tokens
.
length
;
i
+
=
2
)
{
decoded
+
=
tokens
[
i
]
;
}
return
[
decoded
]
;
}
}
class
MetaspacePreTokenizer
extends
PreTokenizer
{
constructor
(
config
)
{
super
(
)
;
this
.
addPrefixSpace
=
config
.
add_prefix_space
;
this
.
replacement
=
config
.
replacement
;
this
.
strRep
=
config
.
str_rep
|
|
this
.
replacement
;
this
.
prepend_scheme
=
config
.
prepend_scheme
?
?
'
always
'
;
}
pre_tokenize_text
(
text
{
section_index
=
undefined
}
=
{
}
)
{
let
normalized
=
text
.
replaceAll
(
'
'
this
.
strRep
)
;
if
(
(
this
.
addPrefixSpace
&
&
!
normalized
.
startsWith
(
this
.
replacement
)
)
&
&
(
this
.
prepend_scheme
=
=
=
'
always
'
|
|
(
this
.
prepend_scheme
=
=
=
'
first
'
&
&
section_index
=
=
=
0
)
)
)
{
normalized
=
this
.
strRep
+
normalized
;
}
return
[
normalized
]
;
}
}
class
MetaspaceDecoder
extends
Decoder
{
constructor
(
config
)
{
super
(
config
)
;
this
.
addPrefixSpace
=
config
.
add_prefix_space
;
this
.
replacement
=
config
.
replacement
;
}
decode_chain
(
tokens
)
{
const
result
=
[
]
;
for
(
let
i
=
0
;
i
<
tokens
.
length
;
+
+
i
)
{
let
normalized
=
tokens
[
i
]
.
replaceAll
(
this
.
replacement
'
'
)
;
if
(
this
.
addPrefixSpace
&
&
i
=
=
0
&
&
normalized
.
startsWith
(
'
'
)
)
{
normalized
=
normalized
.
substring
(
1
)
;
}
result
.
push
(
normalized
)
;
}
return
result
;
}
}
class
Precompiled
extends
Normalizer
{
constructor
(
config
)
{
super
(
config
)
;
this
.
charsmap
=
config
.
precompiled_charsmap
;
}
normalize
(
text
)
{
text
=
text
.
replace
(
/
[
\
u0001
-
\
u0008
\
u000B
\
u000E
-
\
u001F
\
u007F
\
u008F
\
u009F
]
/
gm
'
'
)
;
text
=
text
.
replace
(
/
[
\
u0009
\
u000A
\
u000C
\
u000D
\
u00A0
\
u1680
\
u2000
-
\
u200F
\
u2028
\
u2029
\
u202F
\
u205F
\
u2581
\
u3000
\
uFEFF
\
uFFFD
]
/
gm
'
\
u0020
'
)
;
if
(
text
.
includes
(
'
\
uFF5E
'
)
)
{
const
parts
=
text
.
split
(
'
\
uFF5E
'
)
;
text
=
parts
.
map
(
part
=
>
part
.
normalize
(
'
NFKC
'
)
)
.
join
(
'
\
uFF5E
'
)
;
}
else
{
text
=
text
.
normalize
(
'
NFKC
'
)
;
}
return
text
;
}
}
class
PreTokenizerSequence
extends
PreTokenizer
{
constructor
(
config
)
{
super
(
)
;
this
.
tokenizers
=
config
.
pretokenizers
.
map
(
x
=
>
PreTokenizer
.
fromConfig
(
x
)
)
;
}
pre_tokenize_text
(
text
options
)
{
return
this
.
tokenizers
.
reduce
(
(
preTokenizedText
tokenizer
)
=
>
{
return
tokenizer
.
pre_tokenize
(
preTokenizedText
options
)
;
}
[
text
]
)
;
}
}
class
WhitespacePreTokenizer
extends
PreTokenizer
{
constructor
(
config
)
{
super
(
)
;
}
pre_tokenize_text
(
text
options
)
{
return
text
.
match
(
/
\
w
+
|
[
^
\
w
\
s
]
+
/
g
)
|
|
[
]
;
}
}
class
WhitespaceSplit
extends
PreTokenizer
{
constructor
(
config
)
{
super
(
)
;
}
pre_tokenize_text
(
text
options
)
{
return
whitespace_split
(
text
)
;
}
}
class
ReplacePreTokenizer
extends
PreTokenizer
{
constructor
(
config
)
{
super
(
)
;
this
.
config
=
config
;
this
.
pattern
=
createPattern
(
this
.
config
.
pattern
)
;
this
.
content
=
this
.
config
.
content
;
}
pre_tokenize_text
(
text
options
)
{
if
(
this
.
pattern
=
=
=
null
)
{
return
[
text
]
;
}
return
[
text
.
replaceAll
(
this
.
pattern
this
.
config
.
content
)
]
;
}
}
const
SPECIAL_TOKEN_ATTRIBUTES
=
[
'
bos_token
'
'
eos_token
'
'
unk_token
'
'
sep_token
'
'
pad_token
'
'
cls_token
'
'
mask_token
'
]
function
padHelper
(
item
length
value_fn
side
)
{
for
(
const
key
of
Object
.
keys
(
item
)
)
{
const
diff
=
length
-
item
[
key
]
.
length
;
const
value
=
value_fn
(
key
)
;
const
padData
=
new
Array
(
diff
)
.
fill
(
value
)
;
item
[
key
]
=
side
=
=
=
'
right
'
?
(
0
_utils_core_js__WEBPACK_IMPORTED_MODULE_1__
.
mergeArrays
)
(
item
[
key
]
padData
)
:
(
0
_utils_core_js__WEBPACK_IMPORTED_MODULE_1__
.
mergeArrays
)
(
padData
item
[
key
]
)
;
}
}
function
truncateHelper
(
item
length
)
{
for
(
const
key
of
Object
.
keys
(
item
)
)
{
item
[
key
]
.
length
=
length
;
}
}
class
PreTrainedTokenizer
extends
_utils_generic_js__WEBPACK_IMPORTED_MODULE_0__
.
Callable
{
return_token_type_ids
=
false
;
padding_side
=
'
right
'
;
constructor
(
tokenizerJSON
tokenizerConfig
)
{
super
(
)
;
this
.
_tokenizer_config
=
tokenizerConfig
;
this
.
normalizer
=
Normalizer
.
fromConfig
(
tokenizerJSON
.
normalizer
)
;
this
.
pre_tokenizer
=
PreTokenizer
.
fromConfig
(
tokenizerJSON
.
pre_tokenizer
)
;
this
.
model
=
TokenizerModel
.
fromConfig
(
tokenizerJSON
.
model
tokenizerConfig
)
;
this
.
post_processor
=
PostProcessor
.
fromConfig
(
tokenizerJSON
.
post_processor
)
;
this
.
decoder
=
Decoder
.
fromConfig
(
tokenizerJSON
.
decoder
)
;
this
.
special_tokens
=
[
]
;
this
.
all_special_ids
=
[
]
;
this
.
added_tokens
=
[
]
;
for
(
const
addedToken
of
tokenizerJSON
.
added_tokens
)
{
const
token
=
new
AddedToken
(
addedToken
)
;
this
.
added_tokens
.
push
(
token
)
;
this
.
model
.
tokens_to_ids
.
set
(
token
.
content
token
.
id
)
;
this
.
model
.
vocab
[
token
.
id
]
=
token
.
content
;
if
(
token
.
special
)
{
this
.
special_tokens
.
push
(
token
.
content
)
;
this
.
all_special_ids
.
push
(
token
.
id
)
;
}
}
this
.
additional_special_tokens
=
tokenizerConfig
.
additional_special_tokens
?
?
[
]
;
this
.
special_tokens
.
push
(
.
.
.
this
.
additional_special_tokens
)
;
this
.
special_tokens
=
[
.
.
.
new
Set
(
this
.
special_tokens
)
]
;
if
(
this
.
decoder
)
{
this
.
decoder
.
added_tokens
=
this
.
added_tokens
;
this
.
decoder
.
end_of_word_suffix
=
this
.
model
.
end_of_word_suffix
;
}
this
.
added_tokens_regex
=
this
.
added_tokens
.
length
>
0
?
new
RegExp
(
this
.
added_tokens
.
slice
(
)
.
sort
(
(
a
b
)
=
>
b
.
content
.
length
-
a
.
content
.
length
)
.
map
(
x
=
>
{
x
.
lstrip
?
'
\
\
s
*
'
:
'
'
}
(
{
(
0
_utils_core_js__WEBPACK_IMPORTED_MODULE_1__
.
escapeRegExp
)
(
x
.
content
)
}
)
{
x
.
rstrip
?
'
\
\
s
*
'
:
'
'
}
)
.
join
(
'
|
'
)
)
:
null
;
this
.
mask_token
=
this
.
getToken
(
'
mask_token
'
)
;
this
.
mask_token_id
=
this
.
model
.
tokens_to_ids
.
get
(
this
.
mask_token
)
;
this
.
pad_token
=
this
.
getToken
(
'
pad_token
'
'
eos_token
'
)
;
this
.
pad_token_id
=
this
.
model
.
tokens_to_ids
.
get
(
this
.
pad_token
)
;
this
.
sep_token
=
this
.
getToken
(
'
sep_token
'
)
;
this
.
sep_token_id
=
this
.
model
.
tokens_to_ids
.
get
(
this
.
sep_token
)
;
this
.
unk_token
=
this
.
getToken
(
'
unk_token
'
)
;
this
.
unk_token_id
=
this
.
model
.
tokens_to_ids
.
get
(
this
.
unk_token
)
;
this
.
model_max_length
=
tokenizerConfig
.
model_max_length
;
this
.
remove_space
=
tokenizerConfig
.
remove_space
;
this
.
clean_up_tokenization_spaces
=
tokenizerConfig
.
clean_up_tokenization_spaces
?
?
true
;
this
.
do_lowercase_and_remove_accent
=
tokenizerConfig
.
do_lowercase_and_remove_accent
?
?
false
;
if
(
tokenizerConfig
.
padding_side
)
{
this
.
padding_side
=
tokenizerConfig
.
padding_side
;
}
this
.
legacy
=
false
;
this
.
chat_template
=
tokenizerConfig
.
chat_template
?
?
null
;
if
(
Array
.
isArray
(
this
.
chat_template
)
)
{
const
chat_template
=
Object
.
create
(
null
)
;
for
(
const
{
name
template
}
of
this
.
chat_template
)
{
if
(
typeof
name
!
=
=
'
string
'
|
|
typeof
template
!
=
=
'
string
'
)
{
throw
new
Error
(
'
Chat
template
must
be
a
list
of
objects
with
"
name
"
and
"
template
"
properties
'
)
;
}
chat_template
[
name
]
=
template
;
}
this
.
chat_template
=
chat_template
;
}
this
.
_compiled_template_cache
=
new
Map
(
)
;
}
getToken
(
.
.
.
keys
)
{
for
(
const
key
of
keys
)
{
const
item
=
this
.
_tokenizer_config
[
key
]
;
if
(
!
item
)
continue
;
if
(
typeof
item
=
=
=
'
object
'
)
{
if
(
item
.
__type
=
=
=
'
AddedToken
'
)
{
return
item
.
content
;
}
else
{
throw
Error
(
Unknown
token
:
{
item
}
)
;
}
}
else
{
return
item
;
}
}
return
null
;
}
static
async
from_pretrained
(
pretrained_model_name_or_path
{
progress_callback
=
null
config
=
null
cache_dir
=
null
local_files_only
=
false
revision
=
'
main
'
legacy
=
null
}
=
{
}
)
{
const
info
=
await
loadTokenizer
(
pretrained_model_name_or_path
{
progress_callback
config
cache_dir
local_files_only
revision
legacy
}
)
return
new
this
(
.
.
.
info
)
;
}
_call
(
text
{
text_pair
=
null
add_special_tokens
=
true
padding
=
false
truncation
=
null
max_length
=
null
return_tensor
=
true
return_token_type_ids
=
null
}
=
{
}
)
{
const
isBatched
=
Array
.
isArray
(
text
)
;
let
encodedTokens
;
if
(
isBatched
)
{
if
(
text
.
length
=
=
=
0
)
{
throw
Error
(
'
text
array
must
be
non
-
empty
'
)
}
if
(
text_pair
!
=
=
null
)
{
if
(
!
Array
.
isArray
(
text_pair
)
)
{
throw
Error
(
'
text_pair
must
also
be
an
array
'
)
}
else
if
(
text
.
length
!
=
=
text_pair
.
length
)
{
throw
Error
(
'
text
and
text_pair
must
have
the
same
length
'
)
}
encodedTokens
=
text
.
map
(
(
t
i
)
=
>
this
.
_encode_plus
(
t
{
text_pair
:
text_pair
[
i
]
add_special_tokens
return_token_type_ids
}
)
)
}
else
{
encodedTokens
=
text
.
map
(
x
=
>
this
.
_encode_plus
(
x
{
add_special_tokens
return_token_type_ids
}
)
)
;
}
}
else
{
if
(
text
=
=
=
null
|
|
text
=
=
=
undefined
)
{
throw
Error
(
'
text
may
not
be
null
or
undefined
'
)
}
if
(
Array
.
isArray
(
text_pair
)
)
{
throw
Error
(
'
When
specifying
text_pair
since
text
is
a
string
text_pair
must
also
be
a
string
(
i
.
e
.
not
an
array
)
.
'
)
}
encodedTokens
=
[
this
.
_encode_plus
(
text
{
text_pair
add_special_tokens
return_token_type_ids
}
)
]
;
}
if
(
max_length
=
=
=
null
)
{
if
(
padding
=
=
=
'
max_length
'
)
{
max_length
=
this
.
model_max_length
;
}
else
{
max_length
=
(
0
_utils_maths_js__WEBPACK_IMPORTED_MODULE_3__
.
max
)
(
encodedTokens
.
map
(
x
=
>
x
.
input_ids
.
length
)
)
[
0
]
;
}
}
else
{
if
(
!
truncation
)
{
console
.
warn
(
Truncation
was
not
explicitly
activated
but
\
max_length
\
is
provided
a
specific
value
please
use
\
truncation
=
true
\
to
explicitly
truncate
examples
to
max
length
.
)
}
}
max_length
=
Math
.
min
(
max_length
this
.
model_max_length
?
?
Infinity
)
;
if
(
padding
|
|
truncation
)
{
for
(
let
i
=
0
;
i
<
encodedTokens
.
length
;
+
+
i
)
{
if
(
encodedTokens
[
i
]
.
input_ids
.
length
=
=
=
max_length
)
{
continue
;
}
else
if
(
encodedTokens
[
i
]
.
input_ids
.
length
>
max_length
)
{
if
(
truncation
)
{
truncateHelper
(
encodedTokens
[
i
]
max_length
)
;
}
}
else
{
if
(
padding
)
{
padHelper
(
encodedTokens
[
i
]
max_length
key
=
>
key
=
=
=
'
input_ids
'
?
this
.
pad_token_id
:
0
this
.
padding_side
)
;
}
}
}
}
const
result
=
{
}
;
if
(
return_tensor
)
{
if
(
!
(
padding
&
&
truncation
)
)
{
if
(
encodedTokens
.
some
(
x
=
>
{
for
(
const
key
of
Object
.
keys
(
x
)
)
{
if
(
x
[
key
]
.
length
!
=
=
encodedTokens
[
0
]
[
key
]
?
.
length
)
{
return
true
;
}
}
return
false
;
}
)
)
{
throw
Error
(
"
Unable
to
create
tensor
you
should
probably
activate
truncation
and
/
or
padding
"
+
"
with
'
padding
=
true
'
and
'
truncation
=
true
'
to
have
batched
tensors
with
the
same
length
.
"
)
}
}
const
dims
=
[
encodedTokens
.
length
encodedTokens
[
0
]
.
input_ids
.
length
]
;
for
(
const
key
of
Object
.
keys
(
encodedTokens
[
0
]
)
)
{
result
[
key
]
=
new
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_4__
.
Tensor
(
'
int64
'
BigInt64Array
.
from
(
encodedTokens
.
flatMap
(
x
=
>
x
[
key
]
)
.
map
(
BigInt
)
)
dims
)
;
}
}
else
{
for
(
const
key
of
Object
.
keys
(
encodedTokens
[
0
]
)
)
{
result
[
key
]
=
encodedTokens
.
map
(
x
=
>
x
[
key
]
)
;
}
if
(
!
isBatched
)
{
for
(
const
key
of
Object
.
keys
(
result
)
)
{
result
[
key
]
=
result
[
key
]
[
0
]
;
}
}
}
return
(
result
)
;
}
_encode_text
(
text
)
{
if
(
text
=
=
=
null
)
return
null
;
const
sections
=
this
.
added_tokens_regex
?
text
.
split
(
this
.
added_tokens_regex
)
.
filter
(
x
=
>
x
)
:
[
text
]
;
const
tokens
=
sections
.
map
(
(
x
section_index
)
=
>
{
const
addedToken
=
this
.
added_tokens
.
find
(
t
=
>
t
.
content
=
=
=
x
)
;
if
(
addedToken
!
=
=
undefined
)
{
return
x
}
else
{
if
(
this
.
remove_space
=
=
=
true
)
{
x
=
x
.
trim
(
)
.
split
(
/
\
s
+
/
)
.
join
(
'
'
)
;
}
if
(
this
.
do_lowercase_and_remove_accent
)
{
x
=
lowercase_and_remove_accent
(
x
)
;
}
if
(
this
.
normalizer
!
=
=
null
)
{
x
=
this
.
normalizer
(
x
)
;
}
if
(
x
.
length
=
=
=
0
)
{
return
[
]
;
}
const
sectionTokens
=
(
this
.
pre_tokenizer
!
=
=
null
)
?
this
.
pre_tokenizer
(
x
{
section_index
}
)
:
[
x
]
;
const
tokens
=
this
.
model
(
sectionTokens
)
;
return
tokens
;
}
}
)
.
flat
(
)
;
return
tokens
;
}
_encode_plus
(
text
{
text_pair
=
null
add_special_tokens
=
true
return_token_type_ids
=
null
}
=
{
}
)
{
const
{
tokens
token_type_ids
}
=
this
.
_tokenize_helper
(
text
{
pair
:
text_pair
add_special_tokens
}
)
;
const
input_ids
=
this
.
model
.
convert_tokens_to_ids
(
tokens
)
;
const
result
=
{
input_ids
attention_mask
:
new
Array
(
input_ids
.
length
)
.
fill
(
1
)
}
if
(
(
return_token_type_ids
?
?
this
.
return_token_type_ids
)
&
&
token_type_ids
)
{
result
.
token_type_ids
=
token_type_ids
;
}
return
result
;
}
_tokenize_helper
(
text
{
pair
=
null
add_special_tokens
=
false
}
=
{
}
)
{
const
tokens
=
this
.
_encode_text
(
text
)
;
const
tokens2
=
this
.
_encode_text
(
pair
)
;
return
this
.
post_processor
?
this
.
post_processor
(
tokens
tokens2
{
add_special_tokens
}
)
:
{
tokens
:
(
0
_utils_core_js__WEBPACK_IMPORTED_MODULE_1__
.
mergeArrays
)
(
tokens
?
?
[
]
tokens2
?
?
[
]
)
}
;
}
tokenize
(
text
{
pair
=
null
add_special_tokens
=
false
}
=
{
}
)
{
return
this
.
_tokenize_helper
(
text
{
pair
add_special_tokens
}
)
.
tokens
;
}
encode
(
text
{
text_pair
=
null
add_special_tokens
=
true
return_token_type_ids
=
null
}
=
{
}
)
{
return
this
.
_encode_plus
(
text
{
text_pair
add_special_tokens
return_token_type_ids
}
)
.
input_ids
;
}
batch_decode
(
batch
decode_args
=
{
}
)
{
if
(
batch
instanceof
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_4__
.
Tensor
)
{
batch
=
batch
.
tolist
(
)
;
}
return
batch
.
map
(
x
=
>
this
.
decode
(
x
decode_args
)
)
;
}
decode
(
token_ids
decode_args
=
{
}
)
{
if
(
token_ids
instanceof
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_4__
.
Tensor
)
{
token_ids
=
prepareTensorForDecode
(
token_ids
)
;
}
if
(
!
Array
.
isArray
(
token_ids
)
|
|
token_ids
.
length
=
=
=
0
|
|
!
(
0
_utils_core_js__WEBPACK_IMPORTED_MODULE_1__
.
isIntegralNumber
)
(
token_ids
[
0
]
)
)
{
throw
Error
(
"
token_ids
must
be
a
non
-
empty
array
of
integers
.
"
)
;
}
return
this
.
decode_single
(
token_ids
decode_args
)
}
decode_single
(
token_ids
{
skip_special_tokens
=
false
clean_up_tokenization_spaces
=
null
}
)
{
let
tokens
=
this
.
model
.
convert_ids_to_tokens
(
token_ids
)
;
if
(
skip_special_tokens
)
{
tokens
=
tokens
.
filter
(
x
=
>
!
this
.
special_tokens
.
includes
(
x
)
)
;
}
let
decoded
=
this
.
decoder
?
this
.
decoder
(
tokens
)
:
tokens
.
join
(
'
'
)
;
if
(
this
.
decoder
&
&
this
.
decoder
.
end_of_word_suffix
)
{
decoded
=
decoded
.
replaceAll
(
this
.
decoder
.
end_of_word_suffix
'
'
)
;
if
(
skip_special_tokens
)
{
decoded
=
decoded
.
trim
(
)
;
}
}
if
(
clean_up_tokenization_spaces
?
?
this
.
clean_up_tokenization_spaces
)
{
decoded
=
clean_up_tokenization
(
decoded
)
;
}
return
decoded
;
}
get_chat_template
(
{
chat_template
=
null
tools
=
null
}
=
{
}
)
{
if
(
this
.
chat_template
&
&
typeof
this
.
chat_template
=
=
=
'
object
'
)
{
const
template_dict
=
this
.
chat_template
;
if
(
chat_template
!
=
=
null
&
&
Object
.
hasOwn
(
template_dict
chat_template
)
)
{
chat_template
=
template_dict
[
chat_template
]
;
}
else
if
(
chat_template
=
=
=
null
)
{
if
(
tools
!
=
=
null
&
&
'
tool_use
'
in
template_dict
)
{
chat_template
=
template_dict
[
'
tool_use
'
]
;
}
else
if
(
'
default
'
in
template_dict
)
{
chat_template
=
template_dict
[
'
default
'
]
;
}
else
{
throw
Error
(
This
model
has
multiple
chat
templates
with
no
default
specified
!
Please
either
pass
a
chat
+
template
or
the
name
of
the
template
you
wish
to
use
to
the
'
chat_template
'
argument
.
Available
+
template
names
are
{
Object
.
keys
(
template_dict
)
.
sort
(
)
}
.
)
}
}
}
else
if
(
chat_template
=
=
=
null
)
{
if
(
this
.
chat_template
)
{
chat_template
=
this
.
chat_template
;
}
else
{
throw
Error
(
"
Cannot
use
apply_chat_template
(
)
because
tokenizer
.
chat_template
is
not
set
and
no
template
"
+
"
argument
was
passed
!
For
information
about
writing
templates
and
setting
the
"
+
"
tokenizer
.
chat_template
attribute
please
see
the
documentation
at
"
+
"
https
:
/
/
huggingface
.
co
/
docs
/
transformers
/
main
/
en
/
chat_templating
"
)
}
}
return
chat_template
;
}
apply_chat_template
(
conversation
{
tools
=
null
documents
=
null
chat_template
=
null
add_generation_prompt
=
false
tokenize
=
true
padding
=
false
truncation
=
false
max_length
=
null
return_tensor
=
true
return_dict
=
false
tokenizer_kwargs
=
{
}
.
.
.
kwargs
}
=
{
}
)
{
chat_template
=
this
.
get_chat_template
(
{
chat_template
tools
}
)
;
if
(
typeof
chat_template
!
=
=
'
string
'
)
{
throw
Error
(
chat_template
must
be
a
string
but
got
{
typeof
chat_template
}
)
;
}
let
compiledTemplate
=
this
.
_compiled_template_cache
.
get
(
chat_template
)
;
if
(
compiledTemplate
=
=
=
undefined
)
{
compiledTemplate
=
new
_huggingface_jinja__WEBPACK_IMPORTED_MODULE_6__
.
Template
(
chat_template
)
;
this
.
_compiled_template_cache
.
set
(
chat_template
compiledTemplate
)
;
}
const
special_tokens_map
=
Object
.
create
(
null
)
;
for
(
const
key
of
SPECIAL_TOKEN_ATTRIBUTES
)
{
const
value
=
this
.
getToken
(
key
)
;
if
(
value
)
{
special_tokens_map
[
key
]
=
value
;
}
}
const
rendered
=
compiledTemplate
.
render
(
{
messages
:
conversation
add_generation_prompt
tools
documents
.
.
.
special_tokens_map
.
.
.
kwargs
}
)
;
if
(
tokenize
)
{
const
out
=
this
.
_call
(
rendered
{
add_special_tokens
:
false
padding
truncation
max_length
return_tensor
.
.
.
tokenizer_kwargs
}
)
;
return
return_dict
?
out
:
out
.
input_ids
;
}
return
rendered
;
}
}
class
BertTokenizer
extends
PreTrainedTokenizer
{
return_token_type_ids
=
true
;
}
class
AlbertTokenizer
extends
PreTrainedTokenizer
{
return_token_type_ids
=
true
;
}
class
MobileBertTokenizer
extends
PreTrainedTokenizer
{
return_token_type_ids
=
true
;
}
class
SqueezeBertTokenizer
extends
PreTrainedTokenizer
{
return_token_type_ids
=
true
;
}
class
DebertaTokenizer
extends
PreTrainedTokenizer
{
return_token_type_ids
=
true
;
}
class
DebertaV2Tokenizer
extends
PreTrainedTokenizer
{
return_token_type_ids
=
true
;
}
class
HerbertTokenizer
extends
PreTrainedTokenizer
{
return_token_type_ids
=
true
;
}
class
ConvBertTokenizer
extends
PreTrainedTokenizer
{
return_token_type_ids
=
true
;
}
class
RoFormerTokenizer
extends
PreTrainedTokenizer
{
return_token_type_ids
=
true
;
}
class
DistilBertTokenizer
extends
PreTrainedTokenizer
{
}
class
CamembertTokenizer
extends
PreTrainedTokenizer
{
}
class
XLMTokenizer
extends
PreTrainedTokenizer
{
return_token_type_ids
=
true
;
constructor
(
tokenizerJSON
tokenizerConfig
)
{
super
(
tokenizerJSON
tokenizerConfig
)
;
console
.
warn
(
'
WARNING
:
XLMTokenizer
is
not
yet
supported
by
Hugging
Face
\
'
s
"
fast
"
tokenizers
library
.
Therefore
you
may
experience
slightly
inaccurate
results
.
'
)
}
}
class
ElectraTokenizer
extends
PreTrainedTokenizer
{
return_token_type_ids
=
true
;
}
class
T5Tokenizer
extends
PreTrainedTokenizer
{
}
class
GPT2Tokenizer
extends
PreTrainedTokenizer
{
}
class
BartTokenizer
extends
PreTrainedTokenizer
{
}
class
MBartTokenizer
extends
PreTrainedTokenizer
{
constructor
(
tokenizerJSON
tokenizerConfig
)
{
super
(
tokenizerJSON
tokenizerConfig
)
;
this
.
languageRegex
=
/
^
[
a
-
z
]
{
2
}
_
[
A
-
Z
]
{
2
}
/
;
this
.
language_codes
=
this
.
special_tokens
.
filter
(
x
=
>
this
.
languageRegex
.
test
(
x
)
)
;
this
.
lang_to_token
=
x
=
>
x
;
}
_build_translation_inputs
(
raw_inputs
tokenizer_options
generate_kwargs
)
{
return
_build_translation_inputs
(
this
raw_inputs
tokenizer_options
generate_kwargs
)
;
}
}
class
MBart50Tokenizer
extends
MBartTokenizer
{
}
class
RobertaTokenizer
extends
PreTrainedTokenizer
{
}
class
BloomTokenizer
extends
PreTrainedTokenizer
{
}
const
SPIECE_UNDERLINE
=
"
"
;
class
LlamaTokenizer
extends
PreTrainedTokenizer
{
padding_side
=
'
left
'
;
constructor
(
tokenizerJSON
tokenizerConfig
)
{
super
(
tokenizerJSON
tokenizerConfig
)
;
this
.
legacy
=
tokenizerConfig
.
legacy
?
?
true
;
if
(
!
this
.
legacy
)
{
this
.
normalizer
=
null
;
this
.
pre_tokenizer
=
new
MetaspacePreTokenizer
(
{
replacement
:
SPIECE_UNDERLINE
add_prefix_space
:
true
prepend_scheme
:
"
first
"
}
)
;
}
}
_encode_text
(
text
)
{
if
(
text
=
=
=
null
)
return
null
;
if
(
this
.
legacy
|
|
text
.
length
=
=
=
0
)
{
return
super
.
_encode_text
(
text
)
;
}
let
tokens
=
super
.
_encode_text
(
SPIECE_UNDERLINE
+
text
.
replaceAll
(
SPIECE_UNDERLINE
"
"
)
)
;
if
(
tokens
.
length
>
1
&
&
tokens
[
0
]
=
=
=
SPIECE_UNDERLINE
&
&
this
.
special_tokens
.
includes
(
tokens
[
1
]
)
)
{
tokens
=
tokens
.
slice
(
1
)
;
}
return
tokens
;
}
}
class
CodeLlamaTokenizer
extends
PreTrainedTokenizer
{
}
class
XLMRobertaTokenizer
extends
PreTrainedTokenizer
{
}
class
MPNetTokenizer
extends
PreTrainedTokenizer
{
}
class
FalconTokenizer
extends
PreTrainedTokenizer
{
}
class
GPTNeoXTokenizer
extends
PreTrainedTokenizer
{
}
class
EsmTokenizer
extends
PreTrainedTokenizer
{
}
class
Qwen2Tokenizer
extends
PreTrainedTokenizer
{
}
class
GemmaTokenizer
extends
PreTrainedTokenizer
{
}
class
Grok1Tokenizer
extends
PreTrainedTokenizer
{
}
function
_build_translation_inputs
(
self
raw_inputs
tokenizer_options
generate_kwargs
)
{
if
(
!
(
'
language_codes
'
in
self
)
|
|
!
Array
.
isArray
(
self
.
language_codes
)
)
{
throw
new
Error
(
'
Tokenizer
must
have
language_codes
attribute
set
and
it
should
be
an
array
of
language
ids
.
'
)
}
if
(
!
(
'
languageRegex
'
in
self
)
|
|
!
(
self
.
languageRegex
instanceof
RegExp
)
)
{
throw
new
Error
(
'
Tokenizer
must
have
languageRegex
attribute
set
and
it
should
be
a
regular
expression
.
'
)
}
if
(
!
(
'
lang_to_token
'
in
self
)
|
|
typeof
self
.
lang_to_token
!
=
=
'
function
'
)
{
throw
new
Error
(
'
Tokenizer
must
have
lang_to_token
attribute
set
and
it
should
be
a
function
.
'
)
}
const
src_lang_token
=
generate_kwargs
.
src_lang
;
const
tgt_lang_token
=
generate_kwargs
.
tgt_lang
;
if
(
!
self
.
language_codes
.
includes
(
tgt_lang_token
)
)
{
throw
new
Error
(
Target
language
code
"
{
tgt_lang_token
}
"
is
not
valid
.
Must
be
one
of
:
{
{
self
.
language_codes
.
join
(
'
'
)
}
}
)
;
}
if
(
src_lang_token
!
=
=
undefined
)
{
if
(
!
self
.
language_codes
.
includes
(
src_lang_token
)
)
{
throw
new
Error
(
Source
language
code
"
{
src_lang_token
}
"
is
not
valid
.
Must
be
one
of
:
{
{
self
.
language_codes
.
join
(
'
'
)
}
}
)
;
}
for
(
const
item
of
self
.
post_processor
.
config
.
single
)
{
if
(
'
SpecialToken
'
in
item
&
&
self
.
languageRegex
.
test
(
item
.
SpecialToken
.
id
)
)
{
item
.
SpecialToken
.
id
=
self
.
lang_to_token
(
src_lang_token
)
;
break
;
}
}
}
generate_kwargs
.
forced_bos_token_id
=
self
.
model
.
convert_tokens_to_ids
(
[
self
.
lang_to_token
(
tgt_lang_token
)
]
)
[
0
]
;
return
self
.
_call
(
raw_inputs
tokenizer_options
)
;
}
class
NllbTokenizer
extends
PreTrainedTokenizer
{
constructor
(
tokenizerJSON
tokenizerConfig
)
{
super
(
tokenizerJSON
tokenizerConfig
)
;
this
.
languageRegex
=
/
^
[
a
-
z
]
{
3
}
_
[
A
-
Z
]
[
a
-
z
]
{
3
}
/
;
this
.
language_codes
=
this
.
special_tokens
.
filter
(
x
=
>
this
.
languageRegex
.
test
(
x
)
)
;
this
.
lang_to_token
=
x
=
>
x
;
}
_build_translation_inputs
(
raw_inputs
tokenizer_options
generate_kwargs
)
{
return
_build_translation_inputs
(
this
raw_inputs
tokenizer_options
generate_kwargs
)
;
}
}
class
M2M100Tokenizer
extends
PreTrainedTokenizer
{
constructor
(
tokenizerJSON
tokenizerConfig
)
{
super
(
tokenizerJSON
tokenizerConfig
)
;
this
.
languageRegex
=
/
^
__
[
a
-
z
]
{
2
3
}
__
/
;
this
.
language_codes
=
this
.
special_tokens
.
filter
(
x
=
>
this
.
languageRegex
.
test
(
x
)
)
.
map
(
x
=
>
x
.
slice
(
2
-
2
)
)
;
this
.
lang_to_token
=
x
=
>
__
{
x
}
__
;
}
_build_translation_inputs
(
raw_inputs
tokenizer_options
generate_kwargs
)
{
return
_build_translation_inputs
(
this
raw_inputs
tokenizer_options
generate_kwargs
)
;
}
}
class
WhisperTokenizer
extends
PreTrainedTokenizer
{
get
timestamp_begin
(
)
{
return
this
.
model
.
convert_tokens_to_ids
(
[
"
<
|
notimestamps
|
>
"
]
)
[
0
]
+
1
;
}
_decode_asr
(
sequences
{
return_timestamps
=
false
return_language
=
false
time_precision
=
null
force_full_sequences
=
true
}
=
{
}
)
{
if
(
time_precision
=
=
=
null
)
{
throw
Error
(
"
Must
specify
time_precision
"
)
}
let
last_language
=
null
;
const
returnWordTimestamps
=
return_timestamps
=
=
=
"
word
"
;
function
new_chunk
(
)
{
return
{
"
language
"
:
last_language
"
timestamp
"
:
[
null
null
]
"
text
"
:
"
"
}
;
}
const
chunks
=
[
]
;
let
chunk
=
new_chunk
(
)
;
let
time_offset
=
0
.
0
;
const
timestamp_begin
=
this
.
timestamp_begin
;
let
previous_tokens
=
[
]
;
let
previous_token_timestamps
=
[
]
;
let
skip
=
false
;
let
right_stride_start
=
null
;
const
all_special_ids
=
new
Set
(
this
.
all_special_ids
)
;
for
(
const
output
of
sequences
)
{
const
token_ids
=
output
.
tokens
;
const
token_timestamps
=
returnWordTimestamps
?
output
.
token_timestamps
:
null
;
let
last_timestamp
=
null
;
let
first_timestamp
=
timestamp_begin
;
if
(
"
stride
"
in
output
)
{
const
[
chunk_len
stride_left
stride_right
]
=
output
.
stride
;
time_offset
-
=
stride_left
;
right_stride_start
=
chunk_len
-
stride_right
;
if
(
stride_left
)
{
first_timestamp
=
stride_left
/
time_precision
+
timestamp_begin
;
}
if
(
stride_right
)
{
for
(
let
i
=
token_ids
.
length
-
1
;
i
>
=
0
;
-
-
i
)
{
const
token
=
Number
(
token_ids
[
i
]
)
;
if
(
token
>
=
timestamp_begin
)
{
if
(
last_timestamp
!
=
=
null
&
&
(
token
-
timestamp_begin
)
*
time_precision
<
right_stride_start
)
{
break
;
}
last_timestamp
=
token
;
}
}
}
}
let
current_tokens
=
[
]
;
let
current_token_timestamps
=
[
]
;
for
(
let
i
=
0
;
i
<
token_ids
.
length
;
+
+
i
)
{
const
token
=
Number
(
token_ids
[
i
]
)
;
if
(
all_special_ids
.
has
(
token
)
)
{
const
text
=
this
.
decode
(
[
token
]
)
;
const
language
=
_models_whisper_common_whisper_js__WEBPACK_IMPORTED_MODULE_7__
.
WHISPER_LANGUAGE_MAPPING
.
get
(
text
.
slice
(
2
-
2
)
)
;
if
(
language
!
=
=
undefined
)
{
if
(
last_language
!
=
=
null
&
&
language
!
=
=
last_language
&
&
!
return_timestamps
)
{
previous_tokens
.
push
(
current_tokens
)
;
const
resolved_tokens
=
this
.
findLongestCommonSequence
(
previous_tokens
)
[
0
]
;
const
resolved_text
=
this
.
decode
(
resolved_tokens
)
;
chunk
.
text
=
resolved_text
;
chunks
.
push
(
chunk
)
;
previous_tokens
=
[
]
;
current_tokens
=
[
]
;
chunk
=
new_chunk
(
)
;
}
last_language
=
chunk
.
language
=
language
;
}
else
{
}
}
else
if
(
token
>
=
timestamp_begin
)
{
const
time
=
(
token
-
timestamp_begin
)
*
time_precision
+
time_offset
;
const
rounded_time
=
(
0
_utils_maths_js__WEBPACK_IMPORTED_MODULE_3__
.
round
)
(
time
2
)
;
if
(
last_timestamp
!
=
=
null
&
&
token
>
=
last_timestamp
)
{
skip
=
true
;
}
else
if
(
skip
|
|
(
previous_tokens
.
length
>
0
&
&
token
<
first_timestamp
)
)
{
skip
=
false
;
}
else
if
(
chunk
.
timestamp
[
0
]
=
=
=
null
)
{
chunk
.
timestamp
[
0
]
=
rounded_time
;
}
else
{
if
(
rounded_time
=
=
=
chunk
.
timestamp
[
0
]
)
{
}
else
{
chunk
.
timestamp
[
1
]
=
rounded_time
;
previous_tokens
.
push
(
current_tokens
)
if
(
returnWordTimestamps
)
{
previous_token_timestamps
.
push
(
current_token_timestamps
)
;
}
const
[
resolved_tokens
resolved_token_timestamps
]
=
this
.
findLongestCommonSequence
(
previous_tokens
previous_token_timestamps
)
const
resolved_text
=
this
.
decode
(
resolved_tokens
)
chunk
.
text
=
resolved_text
if
(
returnWordTimestamps
)
{
chunk
.
words
=
this
.
collateWordTimestamps
(
resolved_tokens
resolved_token_timestamps
last_language
)
}
chunks
.
push
(
chunk
)
previous_tokens
=
[
]
current_tokens
=
[
]
previous_token_timestamps
=
[
]
current_token_timestamps
=
[
]
chunk
=
new_chunk
(
)
}
}
}
else
{
current_tokens
.
push
(
token
)
if
(
returnWordTimestamps
)
{
let
start_time
=
(
0
_utils_maths_js__WEBPACK_IMPORTED_MODULE_3__
.
round
)
(
token_timestamps
[
i
]
+
time_offset
2
)
;
let
end_time
;
if
(
i
+
1
<
token_timestamps
.
length
)
{
end_time
=
(
0
_utils_maths_js__WEBPACK_IMPORTED_MODULE_3__
.
round
)
(
token_timestamps
[
i
+
1
]
+
time_offset
2
)
;
const
decoded_text
=
this
.
decode
(
[
token
]
)
;
if
(
PUNCTUATION_ONLY_REGEX
.
test
(
decoded_text
)
)
{
end_time
=
(
0
_utils_maths_js__WEBPACK_IMPORTED_MODULE_3__
.
round
)
(
Math
.
min
(
start_time
+
time_precision
end_time
)
2
)
;
}
}
else
{
end_time
=
null
;
}
current_token_timestamps
.
push
(
[
start_time
end_time
]
)
;
}
}
}
if
(
'
stride
'
in
output
)
{
const
[
chunk_len
stride_left
stride_right
]
=
output
.
stride
;
time_offset
+
=
chunk_len
-
stride_right
}
if
(
current_tokens
.
length
>
0
)
{
previous_tokens
.
push
(
current_tokens
)
if
(
returnWordTimestamps
)
{
previous_token_timestamps
.
push
(
current_token_timestamps
)
;
}
}
else
if
(
previous_tokens
.
every
(
p
=
>
p
.
length
=
=
=
0
)
)
{
chunk
=
new_chunk
(
)
previous_tokens
=
[
]
current_tokens
=
[
]
previous_token_timestamps
=
[
]
;
current_token_timestamps
=
[
]
;
}
}
if
(
previous_tokens
.
length
>
0
)
{
if
(
force_full_sequences
&
&
return_timestamps
)
{
throw
new
Error
(
"
Whisper
did
not
predict
an
ending
timestamp
which
can
happen
if
audio
is
cut
off
in
the
middle
of
a
word
.
"
+
"
Also
make
sure
WhisperTimeStampLogitsProcessor
was
used
during
generation
.
"
)
;
}
const
[
resolved_tokens
resolved_token_timestamps
]
=
this
.
findLongestCommonSequence
(
previous_tokens
previous_token_timestamps
)
;
const
resolved_text
=
this
.
decode
(
resolved_tokens
)
;
chunk
.
text
=
resolved_text
;
if
(
returnWordTimestamps
)
{
chunk
.
words
=
this
.
collateWordTimestamps
(
resolved_tokens
resolved_token_timestamps
last_language
)
}
chunks
.
push
(
chunk
)
;
}
let
optional
=
Object
.
create
(
null
)
;
const
full_text
=
chunks
.
map
(
chunk
=
>
chunk
.
text
)
.
join
(
'
'
)
;
if
(
return_timestamps
|
|
return_language
)
{
for
(
let
i
=
0
;
i
<
chunks
.
length
;
+
+
i
)
{
const
chunk
=
chunks
[
i
]
;
if
(
!
return_timestamps
)
{
delete
chunk
[
"
timestamp
"
]
;
}
if
(
!
return_language
)
{
delete
chunk
[
"
language
"
]
;
}
}
if
(
returnWordTimestamps
)
{
const
new_chunks
=
[
]
;
for
(
const
chunk
of
chunks
)
{
for
(
const
word
of
chunk
.
words
)
{
new_chunks
.
push
(
word
)
;
}
}
optional
=
{
"
chunks
"
:
new_chunks
}
;
}
else
{
optional
=
{
"
chunks
"
:
chunks
}
;
}
}
return
[
full_text
optional
]
;
}
findLongestCommonSequence
(
sequences
token_timestamp_sequences
=
null
)
{
let
leftSequence
=
sequences
[
0
]
;
let
leftLength
=
leftSequence
.
length
;
let
totalSequence
=
[
]
;
const
use_token_timestamp_sequences
=
Array
.
isArray
(
token_timestamp_sequences
)
&
&
token_timestamp_sequences
.
length
>
0
;
let
total_token_timestamp_sequence
=
use_token_timestamp_sequences
?
[
]
:
null
;
let
left_token_timestamp_sequence
=
use_token_timestamp_sequences
?
token_timestamp_sequences
[
0
]
:
null
;
for
(
let
i
=
1
;
i
<
sequences
.
length
;
+
+
i
)
{
const
rightSequence
=
sequences
[
i
]
;
let
max
=
0
.
0
;
let
maxIndices
=
[
leftLength
leftLength
0
0
]
;
const
rightLength
=
rightSequence
.
length
;
for
(
let
j
=
1
;
j
<
leftLength
+
rightLength
;
+
+
j
)
{
const
leftStart
=
Math
.
max
(
0
leftLength
-
j
)
;
const
leftStop
=
Math
.
min
(
leftLength
leftLength
+
rightLength
-
j
)
;
const
left
=
leftSequence
.
slice
(
leftStart
leftStop
)
;
const
rightStart
=
Math
.
max
(
0
j
-
leftLength
)
;
const
rightStop
=
Math
.
min
(
rightLength
j
)
;
const
right
=
rightSequence
.
slice
(
rightStart
rightStop
)
;
if
(
left
.
length
!
=
=
right
.
length
)
{
throw
new
Error
(
"
There
is
a
bug
within
whisper
decode_asr
function
please
report
it
.
Dropping
to
prevent
bad
inference
.
"
)
;
}
let
matches
;
if
(
use_token_timestamp_sequences
)
{
matches
=
left
.
filter
(
(
elem
idx
)
=
>
(
elem
=
=
=
right
[
idx
]
&
&
left_token_timestamp_sequence
[
leftStart
+
idx
]
<
=
token_timestamp_sequences
[
i
]
[
rightStart
+
idx
]
)
)
.
length
;
}
else
{
matches
=
left
.
filter
(
(
elem
idx
)
=
>
elem
=
=
=
right
[
idx
]
)
.
length
;
}
const
eps
=
j
/
10000
.
0
;
const
matching
=
matches
/
j
+
eps
;
if
(
matches
>
1
&
&
matching
>
max
)
{
max
=
matching
;
maxIndices
=
[
leftStart
leftStop
rightStart
rightStop
]
;
}
}
const
[
leftStart
leftStop
rightStart
rightStop
]
=
maxIndices
;
const
leftMid
=
Math
.
floor
(
(
leftStop
+
leftStart
)
/
2
)
;
const
rightMid
=
Math
.
floor
(
(
rightStop
+
rightStart
)
/
2
)
;
totalSequence
.
push
(
.
.
.
leftSequence
.
slice
(
0
leftMid
)
)
;
leftSequence
=
rightSequence
.
slice
(
rightMid
)
;
leftLength
=
leftSequence
.
length
;
if
(
use_token_timestamp_sequences
)
{
total_token_timestamp_sequence
.
push
(
.
.
.
left_token_timestamp_sequence
.
slice
(
0
leftMid
)
)
;
left_token_timestamp_sequence
=
token_timestamp_sequences
[
i
]
.
slice
(
rightMid
)
;
}
}
totalSequence
.
push
(
.
.
.
leftSequence
)
;
if
(
use_token_timestamp_sequences
)
{
total_token_timestamp_sequence
.
push
(
.
.
.
left_token_timestamp_sequence
)
;
return
[
totalSequence
total_token_timestamp_sequence
]
;
}
else
{
return
[
totalSequence
[
]
]
;
}
}
collateWordTimestamps
(
tokens
token_timestamps
language
)
{
const
[
words
_
token_indices
]
=
this
.
combineTokensIntoWords
(
tokens
language
)
;
const
timings
=
[
]
;
for
(
let
i
=
0
;
i
<
words
.
length
;
+
+
i
)
{
const
indices
=
token_indices
[
i
]
;
timings
.
push
(
{
text
:
words
[
i
]
timestamp
:
[
token_timestamps
[
indices
.
at
(
0
)
]
[
0
]
token_timestamps
[
indices
.
at
(
-
1
)
]
[
1
]
]
}
)
;
}
return
timings
;
}
combineTokensIntoWords
(
tokens
language
prepend_punctionations
=
"
\
"
'
(
[
{
-
"
append_punctuations
=
"
\
"
'
.
!
?
:
)
]
}
"
)
{
language
=
language
?
?
'
english
'
;
let
words
word_tokens
token_indices
;
if
(
[
"
chinese
"
"
japanese
"
"
thai
"
"
lao
"
"
myanmar
"
]
.
includes
(
language
)
)
{
[
words
word_tokens
token_indices
]
=
this
.
splitTokensOnUnicode
(
tokens
)
}
else
{
[
words
word_tokens
token_indices
]
=
this
.
splitTokensOnSpaces
(
tokens
)
}
return
this
.
mergePunctuations
(
words
word_tokens
token_indices
prepend_punctionations
append_punctuations
)
;
}
decode
(
token_ids
decode_args
)
{
let
text
;
if
(
decode_args
?
.
decode_with_timestamps
)
{
if
(
token_ids
instanceof
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_4__
.
Tensor
)
{
token_ids
=
prepareTensorForDecode
(
token_ids
)
;
}
text
=
this
.
decodeWithTimestamps
(
token_ids
decode_args
)
;
}
else
{
text
=
super
.
decode
(
token_ids
decode_args
)
;
}
return
text
;
}
decodeWithTimestamps
(
token_ids
decode_args
)
{
const
time_precision
=
decode_args
?
.
time_precision
?
?
0
.
02
;
const
timestamp_begin
=
Array
.
from
(
this
.
all_special_ids
)
.
at
(
-
1
)
+
1
;
let
outputs
=
[
[
]
]
;
for
(
let
token
of
token_ids
)
{
token
=
Number
(
token
)
;
if
(
token
>
=
timestamp_begin
)
{
const
timestamp
=
(
(
token
-
timestamp_begin
)
*
time_precision
)
.
toFixed
(
2
)
;
outputs
.
push
(
<
|
{
timestamp
}
|
>
)
;
outputs
.
push
(
[
]
)
;
}
else
{
outputs
[
outputs
.
length
-
1
]
.
push
(
token
)
;
}
}
outputs
=
outputs
.
map
(
s
=
>
typeof
s
=
=
=
'
string
'
?
s
:
super
.
decode
(
s
decode_args
)
)
return
outputs
.
join
(
'
'
)
;
}
splitTokensOnUnicode
(
tokens
)
{
const
decoded_full
=
this
.
decode
(
tokens
{
decode_with_timestamps
:
true
}
)
;
const
replacement_char
=
'
\
uFFFD
'
;
const
words
=
[
]
const
word_tokens
=
[
]
const
token_indices
=
[
]
let
current_tokens
=
[
]
let
current_indices
=
[
]
let
unicode_offset
=
0
for
(
let
token_idx
=
0
;
token_idx
<
tokens
.
length
;
+
+
token_idx
)
{
const
token
=
tokens
[
token_idx
]
;
current_tokens
.
push
(
token
)
;
current_indices
.
push
(
token_idx
)
;
const
decoded
=
this
.
decode
(
current_tokens
{
decode_with_timestamps
:
true
}
)
;
if
(
!
decoded
.
includes
(
replacement_char
)
|
|
decoded_full
[
unicode_offset
+
decoded
.
indexOf
(
replacement_char
)
]
=
=
=
replacement_char
)
{
words
.
push
(
decoded
)
word_tokens
.
push
(
current_tokens
)
token_indices
.
push
(
current_indices
)
current_tokens
=
[
]
current_indices
=
[
]
unicode_offset
+
=
decoded
.
length
;
}
}
return
[
words
word_tokens
token_indices
]
}
splitTokensOnSpaces
(
tokens
)
{
const
[
subwords
subword_tokens_list
subword_indices_list
]
=
this
.
splitTokensOnUnicode
(
tokens
)
;
const
words
=
[
]
const
word_tokens
=
[
]
const
token_indices
=
[
]
const
punctuationRegex
=
new
RegExp
(
^
[
{
PUNCTUATION_REGEX
}
]
'
gu
'
)
;
for
(
let
i
=
0
;
i
<
subwords
.
length
;
+
+
i
)
{
const
subword
=
subwords
[
i
]
;
const
subword_tokens
=
subword_tokens_list
[
i
]
;
const
subword_indices
=
subword_indices_list
[
i
]
;
const
special
=
subword_tokens
[
0
]
>
=
this
.
model
.
tokens_to_ids
.
get
(
'
<
|
endoftext
|
>
'
)
;
const
with_space
=
subword
.
startsWith
(
'
'
)
;
const
trimmed
=
subword
.
trim
(
)
;
const
punctuation
=
punctuationRegex
.
test
(
trimmed
)
;
if
(
special
|
|
with_space
|
|
punctuation
|
|
words
.
length
=
=
=
0
)
{
words
.
push
(
subword
)
;
word_tokens
.
push
(
subword_tokens
)
;
token_indices
.
push
(
subword_indices
)
;
}
else
{
const
ix
=
words
.
length
-
1
;
words
[
ix
]
+
=
subword
;
word_tokens
[
ix
]
.
push
(
.
.
.
subword_tokens
)
;
token_indices
[
ix
]
.
push
(
.
.
.
subword_indices
)
;
}
}
return
[
words
word_tokens
token_indices
]
;
}
mergePunctuations
(
words
tokens
indices
prepended
appended
)
{
const
newWords
=
structuredClone
(
words
)
;
const
newTokens
=
structuredClone
(
tokens
)
;
const
newIndices
=
structuredClone
(
indices
)
;
let
i
=
newWords
.
length
-
2
;
let
j
=
newWords
.
length
-
1
;
while
(
i
>
=
0
)
{
if
(
newWords
[
i
]
.
startsWith
(
'
'
)
&
&
prepended
.
includes
(
newWords
[
i
]
.
trim
(
)
)
)
{
newWords
[
j
]
=
newWords
[
i
]
+
newWords
[
j
]
;
newTokens
[
j
]
=
(
0
_utils_core_js__WEBPACK_IMPORTED_MODULE_1__
.
mergeArrays
)
(
newTokens
[
i
]
newTokens
[
j
]
)
;
newIndices
[
j
]
=
(
0
_utils_core_js__WEBPACK_IMPORTED_MODULE_1__
.
mergeArrays
)
(
newIndices
[
i
]
newIndices
[
j
]
)
;
newWords
[
i
]
=
'
'
;
newTokens
[
i
]
=
[
]
;
newIndices
[
i
]
=
[
]
;
}
else
{
j
=
i
;
}
-
-
i
;
}
i
=
0
;
j
=
1
;
while
(
j
<
newWords
.
length
)
{
if
(
!
newWords
[
i
]
.
endsWith
(
'
'
)
&
&
appended
.
includes
(
newWords
[
j
]
)
)
{
newWords
[
i
]
+
=
newWords
[
j
]
;
newTokens
[
i
]
=
(
0
_utils_core_js__WEBPACK_IMPORTED_MODULE_1__
.
mergeArrays
)
(
newTokens
[
i
]
newTokens
[
j
]
)
;
newIndices
[
i
]
=
(
0
_utils_core_js__WEBPACK_IMPORTED_MODULE_1__
.
mergeArrays
)
(
newIndices
[
i
]
newIndices
[
j
]
)
;
newWords
[
j
]
=
'
'
;
newTokens
[
j
]
=
[
]
;
newIndices
[
j
]
=
[
]
;
}
else
{
i
=
j
;
}
+
+
j
;
}
return
[
newWords
.
filter
(
x
=
>
x
)
newTokens
.
filter
(
x
=
>
x
.
length
>
0
)
newIndices
.
filter
(
x
=
>
x
.
length
>
0
)
]
}
}
class
CodeGenTokenizer
extends
PreTrainedTokenizer
{
}
class
CLIPTokenizer
extends
PreTrainedTokenizer
{
}
class
SiglipTokenizer
extends
PreTrainedTokenizer
{
}
class
MarianTokenizer
extends
PreTrainedTokenizer
{
constructor
(
tokenizerJSON
tokenizerConfig
)
{
super
(
tokenizerJSON
tokenizerConfig
)
;
this
.
languageRegex
=
/
^
(
>
>
\
w
+
<
<
)
\
s
*
/
g
;
this
.
supported_language_codes
=
this
.
model
.
vocab
.
filter
(
x
=
>
this
.
languageRegex
.
test
(
x
)
)
;
console
.
warn
(
'
WARNING
:
MarianTokenizer
is
not
yet
supported
by
Hugging
Face
\
'
s
"
fast
"
tokenizers
library
.
Therefore
you
may
experience
slightly
inaccurate
results
.
'
)
}
_encode_text
(
text
)
{
if
(
text
=
=
=
null
)
return
null
;
const
[
matchInfo
.
.
.
remainder
]
=
text
.
trim
(
)
.
split
(
this
.
languageRegex
)
;
if
(
remainder
.
length
=
=
=
0
)
{
return
super
.
_encode_text
(
matchInfo
)
;
}
else
if
(
remainder
.
length
=
=
=
2
)
{
const
[
language
text
]
=
remainder
;
if
(
!
this
.
supported_language_codes
.
includes
(
language
)
)
{
console
.
warn
(
Unsupported
language
code
"
{
language
}
"
detected
which
may
lead
to
unexpected
behavior
.
Should
be
one
of
:
{
JSON
.
stringify
(
this
.
supported_language_codes
)
}
)
}
return
(
0
_utils_core_js__WEBPACK_IMPORTED_MODULE_1__
.
mergeArrays
)
(
[
language
]
super
.
_encode_text
(
text
)
)
;
}
}
}
class
Wav2Vec2CTCTokenizer
extends
PreTrainedTokenizer
{
}
class
BlenderbotTokenizer
extends
PreTrainedTokenizer
{
}
class
BlenderbotSmallTokenizer
extends
PreTrainedTokenizer
{
}
class
SpeechT5Tokenizer
extends
PreTrainedTokenizer
{
}
class
NougatTokenizer
extends
PreTrainedTokenizer
{
}
class
VitsTokenizer
extends
PreTrainedTokenizer
{
constructor
(
tokenizerJSON
tokenizerConfig
)
{
super
(
tokenizerJSON
tokenizerConfig
)
;
this
.
decoder
=
new
VitsDecoder
(
{
}
)
;
}
}
class
CohereTokenizer
extends
PreTrainedTokenizer
{
}
class
MgpstrTokenizer
extends
PreTrainedTokenizer
{
}
class
AutoTokenizer
{
static
TOKENIZER_CLASS_MAPPING
=
{
T5Tokenizer
DistilBertTokenizer
CamembertTokenizer
DebertaTokenizer
DebertaV2Tokenizer
BertTokenizer
HerbertTokenizer
ConvBertTokenizer
RoFormerTokenizer
XLMTokenizer
ElectraTokenizer
MobileBertTokenizer
SqueezeBertTokenizer
AlbertTokenizer
GPT2Tokenizer
BartTokenizer
MBartTokenizer
MBart50Tokenizer
RobertaTokenizer
WhisperTokenizer
CodeGenTokenizer
CLIPTokenizer
SiglipTokenizer
MarianTokenizer
BloomTokenizer
NllbTokenizer
M2M100Tokenizer
LlamaTokenizer
CodeLlamaTokenizer
XLMRobertaTokenizer
MPNetTokenizer
FalconTokenizer
GPTNeoXTokenizer
EsmTokenizer
Wav2Vec2CTCTokenizer
BlenderbotTokenizer
BlenderbotSmallTokenizer
SpeechT5Tokenizer
NougatTokenizer
VitsTokenizer
Qwen2Tokenizer
GemmaTokenizer
Grok1Tokenizer
CohereTokenizer
MgpstrTokenizer
PreTrainedTokenizer
}
static
async
from_pretrained
(
pretrained_model_name_or_path
{
progress_callback
=
null
config
=
null
cache_dir
=
null
local_files_only
=
false
revision
=
'
main
'
legacy
=
null
}
=
{
}
)
{
const
[
tokenizerJSON
tokenizerConfig
]
=
await
loadTokenizer
(
pretrained_model_name_or_path
{
progress_callback
config
cache_dir
local_files_only
revision
legacy
}
)
const
tokenizerName
=
tokenizerConfig
.
tokenizer_class
?
.
replace
(
/
Fast
/
'
'
)
?
?
'
PreTrainedTokenizer
'
;
let
cls
=
this
.
TOKENIZER_CLASS_MAPPING
[
tokenizerName
]
;
if
(
!
cls
)
{
console
.
warn
(
Unknown
tokenizer
class
"
{
tokenizerName
}
"
attempting
to
construct
from
base
class
.
)
;
cls
=
PreTrainedTokenizer
;
}
return
new
cls
(
tokenizerJSON
tokenizerConfig
)
;
}
}
}
)
"
.
/
src
/
utils
/
audio
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
hamming
:
(
)
=
>
(
hamming
)
hanning
:
(
)
=
>
(
hanning
)
mel_filter_bank
:
(
)
=
>
(
mel_filter_bank
)
read_audio
:
(
)
=
>
(
read_audio
)
spectrogram
:
(
)
=
>
(
spectrogram
)
window_function
:
(
)
=
>
(
window_function
)
}
)
;
var
_hub_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
src
/
utils
/
hub
.
js
"
)
;
var
_maths_js__WEBPACK_IMPORTED_MODULE_1__
=
__webpack_require__
(
"
.
/
src
/
utils
/
maths
.
js
"
)
;
var
_core_js__WEBPACK_IMPORTED_MODULE_2__
=
__webpack_require__
(
"
.
/
src
/
utils
/
core
.
js
"
)
;
var
_tensor_js__WEBPACK_IMPORTED_MODULE_3__
=
__webpack_require__
(
"
.
/
src
/
utils
/
tensor
.
js
"
)
;
async
function
read_audio
(
url
sampling_rate
)
{
if
(
typeof
AudioContext
=
=
=
'
undefined
'
)
{
throw
Error
(
"
Unable
to
load
audio
from
path
/
URL
since
AudioContext
is
not
available
in
your
environment
.
"
+
"
Instead
audio
data
should
be
passed
directly
to
the
pipeline
/
processor
.
"
+
"
For
more
information
and
some
example
code
see
https
:
/
/
huggingface
.
co
/
docs
/
transformers
.
js
/
guides
/
node
-
audio
-
processing
.
"
)
}
const
response
=
await
(
await
(
0
_hub_js__WEBPACK_IMPORTED_MODULE_0__
.
getFile
)
(
url
)
)
.
arrayBuffer
(
)
;
const
audioCTX
=
new
AudioContext
(
{
sampleRate
:
sampling_rate
}
)
;
if
(
typeof
sampling_rate
=
=
=
'
undefined
'
)
{
console
.
warn
(
No
sampling
rate
provided
using
default
of
{
audioCTX
.
sampleRate
}
Hz
.
)
}
const
decoded
=
await
audioCTX
.
decodeAudioData
(
response
)
;
let
audio
;
if
(
decoded
.
numberOfChannels
=
=
=
2
)
{
const
SCALING_FACTOR
=
Math
.
sqrt
(
2
)
;
const
left
=
decoded
.
getChannelData
(
0
)
;
const
right
=
decoded
.
getChannelData
(
1
)
;
audio
=
new
Float32Array
(
left
.
length
)
;
for
(
let
i
=
0
;
i
<
decoded
.
length
;
+
+
i
)
{
audio
[
i
]
=
SCALING_FACTOR
*
(
left
[
i
]
+
right
[
i
]
)
/
2
;
}
}
else
{
audio
=
decoded
.
getChannelData
(
0
)
;
}
return
audio
;
}
function
generalized_cosine_window
(
M
a_0
)
{
if
(
M
<
1
)
{
return
new
Float64Array
(
)
;
}
if
(
M
=
=
=
1
)
{
return
new
Float64Array
(
[
1
]
)
;
}
const
a_1
=
1
-
a_0
;
const
factor
=
2
*
Math
.
PI
/
(
M
-
1
)
;
const
cos_vals
=
new
Float64Array
(
M
)
;
for
(
let
i
=
0
;
i
<
M
;
+
+
i
)
{
cos_vals
[
i
]
=
a_0
-
a_1
*
Math
.
cos
(
i
*
factor
)
;
}
return
cos_vals
;
}
function
hanning
(
M
)
{
return
generalized_cosine_window
(
M
0
.
5
)
;
}
function
hamming
(
M
)
{
return
generalized_cosine_window
(
M
0
.
54
)
;
}
const
HERTZ_TO_MEL_MAPPING
=
{
"
htk
"
:
(
freq
)
=
>
2595
.
0
*
Math
.
log10
(
1
.
0
+
(
freq
/
700
.
0
)
)
"
kaldi
"
:
(
freq
)
=
>
1127
.
0
*
Math
.
log
(
1
.
0
+
(
freq
/
700
.
0
)
)
"
slaney
"
:
(
freq
min_log_hertz
=
1000
.
0
min_log_mel
=
15
.
0
logstep
=
27
.
0
/
Math
.
log
(
6
.
4
)
)
=
>
freq
>
=
min_log_hertz
?
min_log_mel
+
Math
.
log
(
freq
/
min_log_hertz
)
*
logstep
:
3
.
0
*
freq
/
200
.
0
}
function
hertz_to_mel
(
freq
mel_scale
=
"
htk
"
)
{
const
fn
=
HERTZ_TO_MEL_MAPPING
[
mel_scale
]
;
if
(
!
fn
)
{
throw
new
Error
(
'
mel_scale
should
be
one
of
"
htk
"
"
slaney
"
or
"
kaldi
"
.
'
)
;
}
return
typeof
freq
=
=
=
'
number
'
?
fn
(
freq
)
:
freq
.
map
(
x
=
>
fn
(
x
)
)
;
}
const
MEL_TO_HERTZ_MAPPING
=
{
"
htk
"
:
(
mels
)
=
>
700
.
0
*
(
10
.
0
*
*
(
mels
/
2595
.
0
)
-
1
.
0
)
"
kaldi
"
:
(
mels
)
=
>
700
.
0
*
(
Math
.
exp
(
mels
/
1127
.
0
)
-
1
.
0
)
"
slaney
"
:
(
mels
min_log_hertz
=
1000
.
0
min_log_mel
=
15
.
0
logstep
=
Math
.
log
(
6
.
4
)
/
27
.
0
)
=
>
mels
>
=
min_log_mel
?
min_log_hertz
*
Math
.
exp
(
logstep
*
(
mels
-
min_log_mel
)
)
:
200
.
0
*
mels
/
3
.
0
}
function
mel_to_hertz
(
mels
mel_scale
=
"
htk
"
)
{
const
fn
=
MEL_TO_HERTZ_MAPPING
[
mel_scale
]
;
if
(
!
fn
)
{
throw
new
Error
(
'
mel_scale
should
be
one
of
"
htk
"
"
slaney
"
or
"
kaldi
"
.
'
)
;
}
return
typeof
mels
=
=
=
'
number
'
?
fn
(
mels
)
:
mels
.
map
(
x
=
>
fn
(
x
)
)
;
}
function
_create_triangular_filter_bank
(
fft_freqs
filter_freqs
)
{
const
filter_diff
=
Float64Array
.
from
(
{
length
:
filter_freqs
.
length
-
1
}
(
_
i
)
=
>
filter_freqs
[
i
+
1
]
-
filter_freqs
[
i
]
)
;
const
slopes
=
Array
.
from
(
{
length
:
fft_freqs
.
length
}
(
)
=
>
new
Array
(
filter_freqs
.
length
)
)
;
for
(
let
j
=
0
;
j
<
fft_freqs
.
length
;
+
+
j
)
{
const
slope
=
slopes
[
j
]
;
for
(
let
i
=
0
;
i
<
filter_freqs
.
length
;
+
+
i
)
{
slope
[
i
]
=
filter_freqs
[
i
]
-
fft_freqs
[
j
]
;
}
}
const
numFreqs
=
filter_freqs
.
length
-
2
;
const
ret
=
Array
.
from
(
{
length
:
numFreqs
}
(
)
=
>
new
Array
(
fft_freqs
.
length
)
)
;
for
(
let
j
=
0
;
j
<
fft_freqs
.
length
;
+
+
j
)
{
const
slope
=
slopes
[
j
]
;
for
(
let
i
=
0
;
i
<
numFreqs
;
+
+
i
)
{
const
down
=
-
slope
[
i
]
/
filter_diff
[
i
]
;
const
up
=
slope
[
i
+
2
]
/
filter_diff
[
i
+
1
]
;
ret
[
i
]
[
j
]
=
Math
.
max
(
0
Math
.
min
(
down
up
)
)
;
}
}
return
ret
;
}
function
linspace
(
start
end
num
)
{
const
step
=
(
end
-
start
)
/
(
num
-
1
)
;
return
Float64Array
.
from
(
{
length
:
num
}
(
_
i
)
=
>
start
+
step
*
i
)
;
}
function
mel_filter_bank
(
num_frequency_bins
num_mel_filters
min_frequency
max_frequency
sampling_rate
norm
=
null
mel_scale
=
"
htk
"
triangularize_in_mel_space
=
false
)
{
if
(
norm
!
=
=
null
&
&
norm
!
=
=
"
slaney
"
)
{
throw
new
Error
(
'
norm
must
be
one
of
null
or
"
slaney
"
'
)
;
}
const
mel_min
=
hertz_to_mel
(
min_frequency
mel_scale
)
;
const
mel_max
=
hertz_to_mel
(
max_frequency
mel_scale
)
;
const
mel_freqs
=
linspace
(
mel_min
mel_max
num_mel_filters
+
2
)
;
let
filter_freqs
=
mel_to_hertz
(
mel_freqs
mel_scale
)
;
let
fft_freqs
;
if
(
triangularize_in_mel_space
)
{
const
fft_bin_width
=
sampling_rate
/
(
num_frequency_bins
*
2
)
;
fft_freqs
=
hertz_to_mel
(
Float64Array
.
from
(
{
length
:
num_frequency_bins
}
(
_
i
)
=
>
i
*
fft_bin_width
)
mel_scale
)
;
filter_freqs
=
mel_freqs
;
}
else
{
fft_freqs
=
linspace
(
0
Math
.
floor
(
sampling_rate
/
2
)
num_frequency_bins
)
;
}
const
mel_filters
=
_create_triangular_filter_bank
(
fft_freqs
filter_freqs
)
;
if
(
norm
!
=
=
null
&
&
norm
=
=
=
"
slaney
"
)
{
for
(
let
i
=
0
;
i
<
num_mel_filters
;
+
+
i
)
{
const
filter
=
mel_filters
[
i
]
;
const
enorm
=
2
.
0
/
(
filter_freqs
[
i
+
2
]
-
filter_freqs
[
i
]
)
;
for
(
let
j
=
0
;
j
<
num_frequency_bins
;
+
+
j
)
{
filter
[
j
]
*
=
enorm
;
}
}
}
return
mel_filters
;
}
function
padReflect
(
array
left
right
)
{
const
padded
=
new
array
.
constructor
(
array
.
length
+
left
+
right
)
;
const
w
=
array
.
length
-
1
;
for
(
let
i
=
0
;
i
<
array
.
length
;
+
+
i
)
{
padded
[
left
+
i
]
=
array
[
i
]
;
}
for
(
let
i
=
1
;
i
<
=
left
;
+
+
i
)
{
padded
[
left
-
i
]
=
array
[
(
0
_core_js__WEBPACK_IMPORTED_MODULE_2__
.
calculateReflectOffset
)
(
i
w
)
]
;
}
for
(
let
i
=
1
;
i
<
=
right
;
+
+
i
)
{
padded
[
w
+
left
+
i
]
=
array
[
(
0
_core_js__WEBPACK_IMPORTED_MODULE_2__
.
calculateReflectOffset
)
(
w
-
i
w
)
]
;
}
return
padded
;
}
function
_db_conversion_helper
(
spectrogram
factor
reference
min_value
db_range
)
{
if
(
reference
<
=
0
)
{
throw
new
Error
(
'
reference
must
be
greater
than
zero
'
)
;
}
if
(
min_value
<
=
0
)
{
throw
new
Error
(
'
min_value
must
be
greater
than
zero
'
)
;
}
reference
=
Math
.
max
(
min_value
reference
)
;
const
logReference
=
Math
.
log10
(
reference
)
;
for
(
let
i
=
0
;
i
<
spectrogram
.
length
;
+
+
i
)
{
spectrogram
[
i
]
=
factor
*
Math
.
log10
(
Math
.
max
(
min_value
spectrogram
[
i
]
)
-
logReference
)
}
if
(
db_range
!
=
=
null
)
{
if
(
db_range
<
=
0
)
{
throw
new
Error
(
'
db_range
must
be
greater
than
zero
'
)
;
}
const
maxValue
=
(
0
_maths_js__WEBPACK_IMPORTED_MODULE_1__
.
max
)
(
spectrogram
)
[
0
]
-
db_range
;
for
(
let
i
=
0
;
i
<
spectrogram
.
length
;
+
+
i
)
{
spectrogram
[
i
]
=
Math
.
max
(
spectrogram
[
i
]
maxValue
)
;
}
}
return
spectrogram
;
}
function
amplitude_to_db
(
spectrogram
reference
=
1
.
0
min_value
=
1e
-
5
db_range
=
null
)
{
return
_db_conversion_helper
(
spectrogram
20
.
0
reference
min_value
db_range
)
;
}
function
power_to_db
(
spectrogram
reference
=
1
.
0
min_value
=
1e
-
10
db_range
=
null
)
{
return
_db_conversion_helper
(
spectrogram
10
.
0
reference
min_value
db_range
)
;
}
async
function
spectrogram
(
waveform
window
frame_length
hop_length
{
fft_length
=
null
power
=
1
.
0
center
=
true
pad_mode
=
"
reflect
"
onesided
=
true
preemphasis
=
null
mel_filters
=
null
mel_floor
=
1e
-
10
log_mel
=
null
reference
=
1
.
0
min_value
=
1e
-
10
db_range
=
null
remove_dc_offset
=
null
min_num_frames
=
null
max_num_frames
=
null
do_pad
=
true
transpose
=
false
}
=
{
}
)
{
const
window_length
=
window
.
length
;
if
(
fft_length
=
=
=
null
)
{
fft_length
=
frame_length
;
}
if
(
frame_length
>
fft_length
)
{
throw
Error
(
frame_length
(
{
frame_length
}
)
may
not
be
larger
than
fft_length
(
{
fft_length
}
)
)
}
if
(
window_length
!
=
=
frame_length
)
{
throw
new
Error
(
Length
of
the
window
(
{
window_length
}
)
must
equal
frame_length
(
{
frame_length
}
)
)
;
}
if
(
hop_length
<
=
0
)
{
throw
new
Error
(
"
hop_length
must
be
greater
than
zero
"
)
;
}
if
(
power
=
=
=
null
&
&
mel_filters
!
=
=
null
)
{
throw
new
Error
(
"
You
have
provided
mel_filters
but
power
is
None
.
Mel
spectrogram
computation
is
not
yet
supported
for
complex
-
valued
spectrogram
.
"
+
"
Specify
power
to
fix
this
issue
.
"
)
;
}
if
(
center
)
{
if
(
pad_mode
!
=
=
'
reflect
'
)
{
throw
new
Error
(
pad_mode
=
"
{
pad_mode
}
"
not
implemented
yet
.
)
}
const
half_window
=
Math
.
floor
(
(
fft_length
-
1
)
/
2
)
+
1
;
waveform
=
padReflect
(
waveform
half_window
half_window
)
;
}
let
num_frames
=
Math
.
floor
(
1
+
Math
.
floor
(
(
waveform
.
length
-
frame_length
)
/
hop_length
)
)
if
(
min_num_frames
!
=
=
null
&
&
num_frames
<
min_num_frames
)
{
num_frames
=
min_num_frames
}
const
num_frequency_bins
=
onesided
?
Math
.
floor
(
fft_length
/
2
)
+
1
:
fft_length
let
d1
=
num_frames
;
let
d1Max
=
num_frames
;
if
(
max_num_frames
!
=
=
null
)
{
if
(
max_num_frames
>
num_frames
)
{
if
(
do_pad
)
{
d1Max
=
max_num_frames
;
}
}
else
{
d1Max
=
d1
=
max_num_frames
;
}
}
const
fft
=
new
_maths_js__WEBPACK_IMPORTED_MODULE_1__
.
FFT
(
fft_length
)
;
const
inputBuffer
=
new
Float64Array
(
fft_length
)
;
const
outputBuffer
=
new
Float64Array
(
fft
.
outputBufferSize
)
;
const
transposedMagnitudeData
=
new
Float32Array
(
num_frequency_bins
*
d1Max
)
;
for
(
let
i
=
0
;
i
<
d1
;
+
+
i
)
{
const
offset
=
i
*
hop_length
;
const
buffer_size
=
Math
.
min
(
waveform
.
length
-
offset
frame_length
)
;
if
(
buffer_size
!
=
=
frame_length
)
{
inputBuffer
.
fill
(
0
0
frame_length
)
;
}
for
(
let
j
=
0
;
j
<
buffer_size
;
+
+
j
)
{
inputBuffer
[
j
]
=
waveform
[
offset
+
j
]
;
}
if
(
remove_dc_offset
)
{
let
sum
=
0
;
for
(
let
j
=
0
;
j
<
buffer_size
;
+
+
j
)
{
sum
+
=
inputBuffer
[
j
]
;
}
const
mean
=
sum
/
buffer_size
;
for
(
let
j
=
0
;
j
<
buffer_size
;
+
+
j
)
{
inputBuffer
[
j
]
-
=
mean
;
}
}
if
(
preemphasis
!
=
=
null
)
{
for
(
let
j
=
buffer_size
-
1
;
j
>
=
1
;
-
-
j
)
{
inputBuffer
[
j
]
-
=
preemphasis
*
inputBuffer
[
j
-
1
]
;
}
inputBuffer
[
0
]
*
=
1
-
preemphasis
;
}
for
(
let
j
=
0
;
j
<
window
.
length
;
+
+
j
)
{
inputBuffer
[
j
]
*
=
window
[
j
]
;
}
fft
.
realTransform
(
outputBuffer
inputBuffer
)
;
for
(
let
j
=
0
;
j
<
num_frequency_bins
;
+
+
j
)
{
const
j2
=
j
<
<
1
;
transposedMagnitudeData
[
j
*
d1Max
+
i
]
=
outputBuffer
[
j2
]
*
*
2
+
outputBuffer
[
j2
+
1
]
*
*
2
;
}
}
if
(
power
!
=
=
null
&
&
power
!
=
=
2
)
{
const
pow
=
2
/
power
;
for
(
let
i
=
0
;
i
<
transposedMagnitudeData
.
length
;
+
+
i
)
{
transposedMagnitudeData
[
i
]
*
*
=
pow
;
}
}
const
num_mel_filters
=
mel_filters
.
length
;
let
mel_spec
=
await
(
0
_tensor_js__WEBPACK_IMPORTED_MODULE_3__
.
matmul
)
(
new
_tensor_js__WEBPACK_IMPORTED_MODULE_3__
.
Tensor
(
'
float32
'
mel_filters
.
flat
(
)
[
num_mel_filters
num_frequency_bins
]
)
new
_tensor_js__WEBPACK_IMPORTED_MODULE_3__
.
Tensor
(
'
float32
'
transposedMagnitudeData
[
num_frequency_bins
d1Max
]
)
)
;
if
(
transpose
)
{
mel_spec
=
mel_spec
.
transpose
(
1
0
)
;
}
const
mel_spec_data
=
(
mel_spec
.
data
)
;
for
(
let
i
=
0
;
i
<
mel_spec_data
.
length
;
+
+
i
)
{
mel_spec_data
[
i
]
=
Math
.
max
(
mel_floor
mel_spec_data
[
i
]
)
;
}
if
(
power
!
=
=
null
&
&
log_mel
!
=
=
null
)
{
const
o
=
Math
.
min
(
mel_spec_data
.
length
d1
*
num_mel_filters
)
;
switch
(
log_mel
)
{
case
'
log
'
:
for
(
let
i
=
0
;
i
<
o
;
+
+
i
)
{
mel_spec_data
[
i
]
=
Math
.
log
(
mel_spec_data
[
i
]
)
;
}
break
;
case
'
log10
'
:
for
(
let
i
=
0
;
i
<
o
;
+
+
i
)
{
mel_spec_data
[
i
]
=
Math
.
log10
(
mel_spec_data
[
i
]
)
;
}
break
;
case
'
dB
'
:
if
(
power
=
=
=
1
.
0
)
{
amplitude_to_db
(
mel_spec_data
reference
min_value
db_range
)
;
}
else
if
(
power
=
=
=
2
.
0
)
{
power_to_db
(
mel_spec_data
reference
min_value
db_range
)
;
}
else
{
throw
new
Error
(
Cannot
use
log_mel
option
'
{
log_mel
}
'
with
power
{
power
}
)
}
break
;
default
:
throw
new
Error
(
log_mel
must
be
one
of
null
'
log
'
'
log10
'
or
'
dB
'
.
Got
'
{
log_mel
}
'
)
;
}
}
return
mel_spec
;
}
function
window_function
(
window_length
name
{
periodic
=
true
frame_length
=
null
center
=
true
}
=
{
}
)
{
const
length
=
periodic
?
window_length
+
1
:
window_length
;
let
window
;
switch
(
name
)
{
case
'
boxcar
'
:
window
=
new
Float64Array
(
length
)
.
fill
(
1
.
0
)
;
break
;
case
'
hann
'
:
case
'
hann_window
'
:
window
=
hanning
(
length
)
;
break
;
case
'
hamming
'
:
window
=
hamming
(
length
)
;
break
;
case
'
povey
'
:
window
=
hanning
(
length
)
.
map
(
x
=
>
Math
.
pow
(
x
0
.
85
)
)
;
break
;
default
:
throw
new
Error
(
Unknown
window
type
{
name
}
.
)
;
}
if
(
periodic
)
{
window
=
window
.
subarray
(
0
window_length
)
;
}
if
(
frame_length
=
=
=
null
)
{
return
window
;
}
if
(
window_length
>
frame_length
)
{
throw
new
Error
(
Length
of
the
window
(
{
window_length
}
)
may
not
be
larger
than
frame_length
(
{
frame_length
}
)
)
;
}
return
window
;
}
}
)
"
.
/
src
/
utils
/
constants
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
CHAT_TEMPLATE_NAME
:
(
)
=
>
(
CHAT_TEMPLATE_NAME
)
CONFIG_NAME
:
(
)
=
>
(
CONFIG_NAME
)
FEATURE_EXTRACTOR_NAME
:
(
)
=
>
(
FEATURE_EXTRACTOR_NAME
)
GENERATION_CONFIG_NAME
:
(
)
=
>
(
GENERATION_CONFIG_NAME
)
GITHUB_ISSUE_URL
:
(
)
=
>
(
GITHUB_ISSUE_URL
)
IMAGE_PROCESSOR_NAME
:
(
)
=
>
(
IMAGE_PROCESSOR_NAME
)
PROCESSOR_NAME
:
(
)
=
>
(
PROCESSOR_NAME
)
}
)
;
const
GITHUB_ISSUE_URL
=
'
https
:
/
/
github
.
com
/
huggingface
/
transformers
.
js
/
issues
/
new
/
choose
'
;
const
CONFIG_NAME
=
"
config
.
json
"
const
FEATURE_EXTRACTOR_NAME
=
"
preprocessor_config
.
json
"
const
IMAGE_PROCESSOR_NAME
=
FEATURE_EXTRACTOR_NAME
const
PROCESSOR_NAME
=
"
processor_config
.
json
"
const
CHAT_TEMPLATE_NAME
=
"
chat_template
.
json
"
const
GENERATION_CONFIG_NAME
=
"
generation_config
.
json
"
}
)
"
.
/
src
/
utils
/
core
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
calculateDimensions
:
(
)
=
>
(
calculateDimensions
)
calculateReflectOffset
:
(
)
=
>
(
calculateReflectOffset
)
dispatchCallback
:
(
)
=
>
(
dispatchCallback
)
escapeRegExp
:
(
)
=
>
(
escapeRegExp
)
isIntegralNumber
:
(
)
=
>
(
isIntegralNumber
)
isNullishDimension
:
(
)
=
>
(
isNullishDimension
)
isTypedArray
:
(
)
=
>
(
isTypedArray
)
len
:
(
)
=
>
(
len
)
mergeArrays
:
(
)
=
>
(
mergeArrays
)
pick
:
(
)
=
>
(
pick
)
pop
:
(
)
=
>
(
pop
)
product
:
(
)
=
>
(
product
)
reverseDictionary
:
(
)
=
>
(
reverseDictionary
)
}
)
;
function
dispatchCallback
(
progress_callback
data
)
{
if
(
progress_callback
)
progress_callback
(
data
)
;
}
function
reverseDictionary
(
data
)
{
return
Object
.
fromEntries
(
Object
.
entries
(
data
)
.
map
(
(
[
key
value
]
)
=
>
[
value
key
]
)
)
;
}
function
escapeRegExp
(
string
)
{
return
string
.
replace
(
/
[
.
*
+
?
^
{
}
(
)
|
[
\
]
\
\
]
/
g
'
\
\
&
'
)
;
}
function
isTypedArray
(
val
)
{
return
val
?
.
prototype
?
.
__proto__
?
.
constructor
?
.
name
=
=
=
'
TypedArray
'
;
}
function
isIntegralNumber
(
x
)
{
return
Number
.
isInteger
(
x
)
|
|
typeof
x
=
=
=
'
bigint
'
}
function
isNullishDimension
(
x
)
{
return
x
=
=
=
null
|
|
x
=
=
=
undefined
|
|
x
=
=
=
-
1
;
}
function
calculateDimensions
(
arr
)
{
const
dimensions
=
[
]
;
let
current
=
arr
;
while
(
Array
.
isArray
(
current
)
)
{
dimensions
.
push
(
current
.
length
)
;
current
=
current
[
0
]
;
}
return
dimensions
;
}
function
pop
(
obj
key
defaultValue
=
undefined
)
{
const
value
=
obj
[
key
]
;
if
(
value
!
=
=
undefined
)
{
delete
obj
[
key
]
;
return
value
;
}
if
(
defaultValue
=
=
=
undefined
)
{
throw
Error
(
Key
{
key
}
does
not
exist
in
object
.
)
}
return
defaultValue
;
}
function
mergeArrays
(
.
.
.
arrs
)
{
return
Array
.
prototype
.
concat
.
apply
(
[
]
arrs
)
;
}
function
product
(
.
.
.
a
)
{
return
a
.
reduce
(
(
a
b
)
=
>
a
.
flatMap
(
d
=
>
b
.
map
(
e
=
>
[
d
e
]
)
)
)
;
}
function
calculateReflectOffset
(
i
w
)
{
return
Math
.
abs
(
(
i
+
w
)
%
(
2
*
w
)
-
w
)
;
}
function
pick
(
o
props
)
{
return
Object
.
assign
(
{
}
.
.
.
props
.
map
(
(
prop
)
=
>
{
if
(
o
[
prop
]
!
=
=
undefined
)
{
return
{
[
prop
]
:
o
[
prop
]
}
;
}
}
)
)
;
}
function
len
(
s
)
{
let
length
=
0
;
for
(
const
c
of
s
)
+
+
length
;
return
length
;
}
}
)
"
.
/
src
/
utils
/
data
-
structures
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
CharTrie
:
(
)
=
>
(
CharTrie
)
PriorityQueue
:
(
)
=
>
(
PriorityQueue
)
TokenLattice
:
(
)
=
>
(
TokenLattice
)
}
)
;
class
PriorityQueue
{
constructor
(
comparator
=
(
a
b
)
=
>
a
>
b
maxSize
=
Infinity
)
{
this
.
_heap
=
[
]
;
this
.
_comparator
=
comparator
;
this
.
_maxSize
=
maxSize
;
}
get
size
(
)
{
return
this
.
_heap
.
length
;
}
isEmpty
(
)
{
return
this
.
size
=
=
=
0
;
}
peek
(
)
{
return
this
.
_heap
[
0
]
;
}
push
(
.
.
.
values
)
{
return
this
.
extend
(
values
)
;
}
extend
(
values
)
{
for
(
const
value
of
values
)
{
if
(
this
.
size
<
this
.
_maxSize
)
{
this
.
_heap
.
push
(
value
)
;
this
.
_siftUp
(
)
;
}
else
{
const
smallest
=
this
.
_smallest
(
)
;
if
(
this
.
_comparator
(
value
this
.
_heap
[
smallest
]
)
)
{
this
.
_heap
[
smallest
]
=
value
;
this
.
_siftUpFrom
(
smallest
)
;
}
}
}
return
this
.
size
;
}
pop
(
)
{
const
poppedValue
=
this
.
peek
(
)
;
const
bottom
=
this
.
size
-
1
;
if
(
bottom
>
0
)
{
this
.
_swap
(
0
bottom
)
;
}
this
.
_heap
.
pop
(
)
;
this
.
_siftDown
(
)
;
return
poppedValue
;
}
replace
(
value
)
{
const
replacedValue
=
this
.
peek
(
)
;
this
.
_heap
[
0
]
=
value
;
this
.
_siftDown
(
)
;
return
replacedValue
;
}
_parent
(
i
)
{
return
(
(
i
+
1
)
>
>
>
1
)
-
1
;
}
_left
(
i
)
{
return
(
i
<
<
1
)
+
1
;
}
_right
(
i
)
{
return
(
i
+
1
)
<
<
1
;
}
_greater
(
i
j
)
{
return
this
.
_comparator
(
this
.
_heap
[
i
]
this
.
_heap
[
j
]
)
;
}
_swap
(
i
j
)
{
const
temp
=
this
.
_heap
[
i
]
;
this
.
_heap
[
i
]
=
this
.
_heap
[
j
]
;
this
.
_heap
[
j
]
=
temp
;
}
_siftUp
(
)
{
this
.
_siftUpFrom
(
this
.
size
-
1
)
;
}
_siftUpFrom
(
node
)
{
while
(
node
>
0
&
&
this
.
_greater
(
node
this
.
_parent
(
node
)
)
)
{
this
.
_swap
(
node
this
.
_parent
(
node
)
)
;
node
=
this
.
_parent
(
node
)
;
}
}
_siftDown
(
)
{
let
node
=
0
;
while
(
(
this
.
_left
(
node
)
<
this
.
size
&
&
this
.
_greater
(
this
.
_left
(
node
)
node
)
)
|
|
(
this
.
_right
(
node
)
<
this
.
size
&
&
this
.
_greater
(
this
.
_right
(
node
)
node
)
)
)
{
const
maxChild
=
(
this
.
_right
(
node
)
<
this
.
size
&
&
this
.
_greater
(
this
.
_right
(
node
)
this
.
_left
(
node
)
)
)
?
this
.
_right
(
node
)
:
this
.
_left
(
node
)
;
this
.
_swap
(
node
maxChild
)
;
node
=
maxChild
;
}
}
_smallest
(
)
{
return
(
2
*
*
(
Math
.
floor
(
Math
.
log2
(
this
.
size
)
)
)
-
1
)
;
}
}
class
CharTrie
{
constructor
(
)
{
this
.
root
=
CharTrieNode
.
default
(
)
;
}
extend
(
texts
)
{
for
(
const
text
of
texts
)
{
this
.
push
(
text
)
;
}
}
push
(
text
)
{
let
node
=
this
.
root
;
for
(
const
ch
of
text
)
{
let
child
=
node
.
children
.
get
(
ch
)
;
if
(
child
=
=
=
undefined
)
{
child
=
CharTrieNode
.
default
(
)
;
node
.
children
.
set
(
ch
child
)
;
}
node
=
child
;
}
node
.
isLeaf
=
true
;
}
*
commonPrefixSearch
(
text
)
{
let
node
=
this
.
root
;
if
(
node
=
=
=
undefined
)
return
;
let
prefix
=
"
"
;
for
(
const
ch
of
text
)
{
prefix
+
=
ch
;
node
=
node
.
children
.
get
(
ch
)
;
if
(
node
=
=
=
undefined
)
return
;
if
(
node
.
isLeaf
)
{
yield
prefix
;
}
}
}
}
class
CharTrieNode
{
constructor
(
isLeaf
children
)
{
this
.
isLeaf
=
isLeaf
;
this
.
children
=
children
;
}
static
default
(
)
{
return
new
CharTrieNode
(
false
new
Map
(
)
)
;
}
}
class
TokenLattice
{
constructor
(
sentence
bosTokenId
eosTokenId
)
{
this
.
chars
=
Array
.
from
(
sentence
)
;
this
.
len
=
this
.
chars
.
length
;
this
.
bosTokenId
=
bosTokenId
;
this
.
eosTokenId
=
eosTokenId
;
this
.
nodes
=
[
]
;
this
.
beginNodes
=
Array
.
from
(
{
length
:
this
.
len
+
1
}
(
)
=
>
[
]
)
;
this
.
endNodes
=
Array
.
from
(
{
length
:
this
.
len
+
1
}
(
)
=
>
[
]
)
;
const
bos
=
new
TokenLatticeNode
(
this
.
bosTokenId
0
0
0
0
.
0
)
;
const
eos
=
new
TokenLatticeNode
(
this
.
eosTokenId
1
this
.
len
0
0
.
0
)
;
this
.
nodes
.
push
(
bos
.
clone
(
)
)
;
this
.
nodes
.
push
(
eos
.
clone
(
)
)
;
this
.
beginNodes
[
this
.
len
]
.
push
(
eos
)
;
this
.
endNodes
[
0
]
.
push
(
bos
)
;
}
insert
(
pos
length
score
tokenId
)
{
const
nodeId
=
this
.
nodes
.
length
;
const
node
=
new
TokenLatticeNode
(
tokenId
nodeId
pos
length
score
)
;
this
.
beginNodes
[
pos
]
.
push
(
node
)
;
this
.
endNodes
[
pos
+
length
]
.
push
(
node
)
;
this
.
nodes
.
push
(
node
)
;
}
viterbi
(
)
{
const
len
=
this
.
len
;
let
pos
=
0
;
while
(
pos
<
=
len
)
{
if
(
this
.
beginNodes
[
pos
]
.
length
=
=
0
)
{
return
[
]
;
}
for
(
let
rnode
of
this
.
beginNodes
[
pos
]
)
{
rnode
.
prev
=
null
;
let
bestScore
=
0
.
0
;
let
bestNode
=
null
;
for
(
let
lnode
of
this
.
endNodes
[
pos
]
)
{
const
score
=
lnode
.
backtraceScore
+
rnode
.
score
;
if
(
bestNode
=
=
=
null
|
|
score
>
bestScore
)
{
bestNode
=
lnode
.
clone
(
)
;
bestScore
=
score
;
}
}
if
(
bestNode
!
=
=
null
)
{
rnode
.
prev
=
bestNode
;
rnode
.
backtraceScore
=
bestScore
;
}
else
{
return
[
]
;
}
}
+
+
pos
;
}
const
results
=
[
]
;
const
root
=
this
.
beginNodes
[
len
]
[
0
]
;
const
prev
=
root
.
prev
;
if
(
prev
=
=
=
null
)
{
return
[
]
;
}
let
node
=
prev
.
clone
(
)
;
while
(
node
.
prev
!
=
=
null
)
{
results
.
push
(
node
.
clone
(
)
)
;
const
n
=
node
.
clone
(
)
;
node
=
n
.
prev
.
clone
(
)
;
}
results
.
reverse
(
)
;
return
results
;
}
piece
(
node
)
{
return
this
.
chars
.
slice
(
node
.
pos
node
.
pos
+
node
.
length
)
.
join
(
'
'
)
;
}
tokens
(
)
{
const
nodes
=
this
.
viterbi
(
)
;
return
nodes
.
map
(
x
=
>
this
.
piece
(
x
)
)
;
}
tokenIds
(
)
{
const
nodes
=
this
.
viterbi
(
)
;
return
nodes
.
map
(
x
=
>
x
.
tokenId
)
;
}
}
class
TokenLatticeNode
{
constructor
(
tokenId
nodeId
pos
length
score
)
{
this
.
tokenId
=
tokenId
;
this
.
nodeId
=
nodeId
;
this
.
pos
=
pos
;
this
.
length
=
length
;
this
.
score
=
score
;
this
.
prev
=
null
;
this
.
backtraceScore
=
0
.
0
;
}
clone
(
)
{
const
n
=
new
TokenLatticeNode
(
this
.
tokenId
this
.
nodeId
this
.
pos
this
.
length
this
.
score
)
;
n
.
prev
=
this
.
prev
;
n
.
backtraceScore
=
this
.
backtraceScore
;
return
n
;
}
}
}
)
"
.
/
src
/
utils
/
devices
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
DEVICE_TYPES
:
(
)
=
>
(
DEVICE_TYPES
)
}
)
;
const
DEVICE_TYPES
=
Object
.
freeze
(
{
auto
:
'
auto
'
gpu
:
'
gpu
'
cpu
:
'
cpu
'
wasm
:
'
wasm
'
webgpu
:
'
webgpu
'
cuda
:
'
cuda
'
dml
:
'
dml
'
webnn
:
'
webnn
'
'
webnn
-
npu
'
:
'
webnn
-
npu
'
'
webnn
-
gpu
'
:
'
webnn
-
gpu
'
'
webnn
-
cpu
'
:
'
webnn
-
cpu
'
}
)
;
}
)
"
.
/
src
/
utils
/
dtypes
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
DATA_TYPES
:
(
)
=
>
(
DATA_TYPES
)
DEFAULT_DEVICE_DTYPE_MAPPING
:
(
)
=
>
(
DEFAULT_DEVICE_DTYPE_MAPPING
)
DEFAULT_DTYPE_SUFFIX_MAPPING
:
(
)
=
>
(
DEFAULT_DTYPE_SUFFIX_MAPPING
)
isWebGpuFp16Supported
:
(
)
=
>
(
isWebGpuFp16Supported
)
}
)
;
var
_env_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
src
/
env
.
js
"
)
;
var
_devices_js__WEBPACK_IMPORTED_MODULE_1__
=
__webpack_require__
(
"
.
/
src
/
utils
/
devices
.
js
"
)
;
const
isWebGpuFp16Supported
=
(
function
(
)
{
let
cachedResult
;
return
async
function
(
)
{
if
(
cachedResult
=
=
=
undefined
)
{
if
(
!
_env_js__WEBPACK_IMPORTED_MODULE_0__
.
apis
.
IS_WEBGPU_AVAILABLE
)
{
cachedResult
=
false
;
}
else
{
try
{
const
adapter
=
await
navigator
.
gpu
.
requestAdapter
(
)
;
cachedResult
=
adapter
.
features
.
has
(
'
shader
-
f16
'
)
;
}
catch
(
e
)
{
cachedResult
=
false
;
}
}
}
return
cachedResult
;
}
;
}
)
(
)
;
const
DATA_TYPES
=
Object
.
freeze
(
{
fp32
:
'
fp32
'
fp16
:
'
fp16
'
q8
:
'
q8
'
int8
:
'
int8
'
uint8
:
'
uint8
'
q4
:
'
q4
'
bnb4
:
'
bnb4
'
q4f16
:
'
q4f16
'
}
)
;
const
DEFAULT_DEVICE_DTYPE_MAPPING
=
Object
.
freeze
(
{
[
_devices_js__WEBPACK_IMPORTED_MODULE_1__
.
DEVICE_TYPES
.
wasm
]
:
DATA_TYPES
.
q8
}
)
;
const
DEFAULT_DTYPE_SUFFIX_MAPPING
=
Object
.
freeze
(
{
[
DATA_TYPES
.
fp32
]
:
'
'
[
DATA_TYPES
.
fp16
]
:
'
_fp16
'
[
DATA_TYPES
.
int8
]
:
'
_int8
'
[
DATA_TYPES
.
uint8
]
:
'
_uint8
'
[
DATA_TYPES
.
q8
]
:
'
_quantized
'
[
DATA_TYPES
.
q4
]
:
'
_q4
'
[
DATA_TYPES
.
q4f16
]
:
'
_q4f16
'
[
DATA_TYPES
.
bnb4
]
:
'
_bnb4
'
}
)
;
}
)
"
.
/
src
/
utils
/
generic
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
Callable
:
(
)
=
>
(
Callable
)
}
)
;
const
Callable
=
(
class
{
constructor
(
)
{
let
closure
=
function
(
.
.
.
args
)
{
return
closure
.
_call
(
.
.
.
args
)
}
return
Object
.
setPrototypeOf
(
closure
new
.
target
.
prototype
)
}
_call
(
.
.
.
args
)
{
throw
Error
(
'
Must
implement
_call
method
in
subclass
'
)
}
}
)
;
}
)
"
.
/
src
/
utils
/
hub
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
getFile
:
(
)
=
>
(
getFile
)
getModelFile
:
(
)
=
>
(
getModelFile
)
getModelJSON
:
(
)
=
>
(
getModelJSON
)
}
)
;
var
fs__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
?
7a2c
"
)
;
var
path__WEBPACK_IMPORTED_MODULE_1__
=
__webpack_require__
(
"
?
a42a
"
)
;
var
_env_js__WEBPACK_IMPORTED_MODULE_2__
=
__webpack_require__
(
"
.
/
src
/
env
.
js
"
)
;
var
_core_js__WEBPACK_IMPORTED_MODULE_3__
=
__webpack_require__
(
"
.
/
src
/
utils
/
core
.
js
"
)
;
const
CONTENT_TYPE_MAP
=
{
'
txt
'
:
'
text
/
plain
'
'
html
'
:
'
text
/
html
'
'
css
'
:
'
text
/
css
'
'
js
'
:
'
text
/
javascript
'
'
json
'
:
'
application
/
json
'
'
png
'
:
'
image
/
png
'
'
jpg
'
:
'
image
/
jpeg
'
'
jpeg
'
:
'
image
/
jpeg
'
'
gif
'
:
'
image
/
gif
'
}
class
FileResponse
{
constructor
(
filePath
)
{
this
.
filePath
=
filePath
;
this
.
headers
=
new
Headers
(
)
;
this
.
exists
=
fs__WEBPACK_IMPORTED_MODULE_0__
.
existsSync
(
filePath
)
;
if
(
this
.
exists
)
{
this
.
status
=
200
;
this
.
statusText
=
'
OK
'
;
let
stats
=
fs__WEBPACK_IMPORTED_MODULE_0__
.
statSync
(
filePath
)
;
this
.
headers
.
set
(
'
content
-
length
'
stats
.
size
.
toString
(
)
)
;
this
.
updateContentType
(
)
;
let
self
=
this
;
this
.
body
=
new
ReadableStream
(
{
start
(
controller
)
{
self
.
arrayBuffer
(
)
.
then
(
buffer
=
>
{
controller
.
enqueue
(
new
Uint8Array
(
buffer
)
)
;
controller
.
close
(
)
;
}
)
}
}
)
;
}
else
{
this
.
status
=
404
;
this
.
statusText
=
'
Not
Found
'
;
this
.
body
=
null
;
}
}
updateContentType
(
)
{
const
extension
=
this
.
filePath
.
toString
(
)
.
split
(
'
.
'
)
.
pop
(
)
.
toLowerCase
(
)
;
this
.
headers
.
set
(
'
content
-
type
'
CONTENT_TYPE_MAP
[
extension
]
?
?
'
application
/
octet
-
stream
'
)
;
}
clone
(
)
{
let
response
=
new
FileResponse
(
this
.
filePath
)
;
response
.
exists
=
this
.
exists
;
response
.
status
=
this
.
status
;
response
.
statusText
=
this
.
statusText
;
response
.
headers
=
new
Headers
(
this
.
headers
)
;
return
response
;
}
async
arrayBuffer
(
)
{
const
data
=
await
fs__WEBPACK_IMPORTED_MODULE_0__
.
promises
.
readFile
(
this
.
filePath
)
;
return
data
.
buffer
;
}
async
blob
(
)
{
const
data
=
await
fs__WEBPACK_IMPORTED_MODULE_0__
.
promises
.
readFile
(
this
.
filePath
)
;
return
new
Blob
(
[
data
]
{
type
:
this
.
headers
.
get
(
'
content
-
type
'
)
}
)
;
}
async
text
(
)
{
const
data
=
await
fs__WEBPACK_IMPORTED_MODULE_0__
.
promises
.
readFile
(
this
.
filePath
'
utf8
'
)
;
return
data
;
}
async
json
(
)
{
return
JSON
.
parse
(
await
this
.
text
(
)
)
;
}
}
function
isValidUrl
(
string
protocols
=
null
validHosts
=
null
)
{
let
url
;
try
{
url
=
new
URL
(
string
)
;
}
catch
(
_
)
{
return
false
;
}
if
(
protocols
&
&
!
protocols
.
includes
(
url
.
protocol
)
)
{
return
false
;
}
if
(
validHosts
&
&
!
validHosts
.
includes
(
url
.
hostname
)
)
{
return
false
;
}
return
true
;
}
async
function
getFile
(
urlOrPath
)
{
if
(
_env_js__WEBPACK_IMPORTED_MODULE_2__
.
env
.
useFS
&
&
!
isValidUrl
(
urlOrPath
[
'
http
:
'
'
https
:
'
'
blob
:
'
]
)
)
{
return
new
FileResponse
(
urlOrPath
)
;
}
else
if
(
typeof
process
!
=
=
'
undefined
'
&
&
process
?
.
release
?
.
name
=
=
=
'
node
'
)
{
const
IS_CI
=
!
!
process
.
env
?
.
TESTING_REMOTELY
;
const
version
=
_env_js__WEBPACK_IMPORTED_MODULE_2__
.
env
.
version
;
const
headers
=
new
Headers
(
)
;
headers
.
set
(
'
User
-
Agent
'
transformers
.
js
/
{
version
}
;
is_ci
/
{
IS_CI
}
;
)
;
const
isHFURL
=
isValidUrl
(
urlOrPath
[
'
http
:
'
'
https
:
'
]
[
'
huggingface
.
co
'
'
hf
.
co
'
]
)
;
if
(
isHFURL
)
{
const
token
=
process
.
env
?
.
HF_TOKEN
?
?
process
.
env
?
.
HF_ACCESS_TOKEN
;
if
(
token
)
{
headers
.
set
(
'
Authorization
'
Bearer
{
token
}
)
;
}
}
return
fetch
(
urlOrPath
{
headers
}
)
;
}
else
{
return
fetch
(
urlOrPath
)
;
}
}
const
ERROR_MAPPING
=
{
400
:
'
Bad
request
error
occurred
while
trying
to
load
file
'
401
:
'
Unauthorized
access
to
file
'
403
:
'
Forbidden
access
to
file
'
404
:
'
Could
not
locate
file
'
408
:
'
Request
timeout
error
occurred
while
trying
to
load
file
'
500
:
'
Internal
server
error
error
occurred
while
trying
to
load
file
'
502
:
'
Bad
gateway
error
occurred
while
trying
to
load
file
'
503
:
'
Service
unavailable
error
occurred
while
trying
to
load
file
'
504
:
'
Gateway
timeout
error
occurred
while
trying
to
load
file
'
}
function
handleError
(
status
remoteURL
fatal
)
{
if
(
!
fatal
)
{
return
null
;
}
const
message
=
ERROR_MAPPING
[
status
]
?
?
Error
(
{
status
}
)
occurred
while
trying
to
load
file
;
throw
Error
(
{
message
}
:
"
{
remoteURL
}
"
.
)
;
}
class
FileCache
{
constructor
(
path
)
{
this
.
path
=
path
;
}
async
match
(
request
)
{
let
filePath
=
path__WEBPACK_IMPORTED_MODULE_1__
.
join
(
this
.
path
request
)
;
let
file
=
new
FileResponse
(
filePath
)
;
if
(
file
.
exists
)
{
return
file
;
}
else
{
return
undefined
;
}
}
async
put
(
request
response
)
{
const
buffer
=
Buffer
.
from
(
await
response
.
arrayBuffer
(
)
)
;
let
outputPath
=
path__WEBPACK_IMPORTED_MODULE_1__
.
join
(
this
.
path
request
)
;
try
{
await
fs__WEBPACK_IMPORTED_MODULE_0__
.
promises
.
mkdir
(
path__WEBPACK_IMPORTED_MODULE_1__
.
dirname
(
outputPath
)
{
recursive
:
true
}
)
;
await
fs__WEBPACK_IMPORTED_MODULE_0__
.
promises
.
writeFile
(
outputPath
buffer
)
;
}
catch
(
err
)
{
console
.
warn
(
'
An
error
occurred
while
writing
the
file
to
cache
:
'
err
)
}
}
}
async
function
tryCache
(
cache
.
.
.
names
)
{
for
(
let
name
of
names
)
{
try
{
let
result
=
await
cache
.
match
(
name
)
;
if
(
result
)
return
result
;
}
catch
(
e
)
{
continue
;
}
}
return
undefined
;
}
async
function
getModelFile
(
path_or_repo_id
filename
fatal
=
true
options
=
{
}
)
{
if
(
!
_env_js__WEBPACK_IMPORTED_MODULE_2__
.
env
.
allowLocalModels
)
{
if
(
options
.
local_files_only
)
{
throw
Error
(
"
Invalid
configuration
detected
:
local
models
are
disabled
(
env
.
allowLocalModels
=
false
)
but
you
have
requested
to
only
use
local
models
(
local_files_only
=
true
)
.
"
)
}
else
if
(
!
_env_js__WEBPACK_IMPORTED_MODULE_2__
.
env
.
allowRemoteModels
)
{
throw
Error
(
"
Invalid
configuration
detected
:
both
local
and
remote
models
are
disabled
.
Fix
by
setting
env
.
allowLocalModels
or
env
.
allowRemoteModels
to
true
.
"
)
}
}
(
0
_core_js__WEBPACK_IMPORTED_MODULE_3__
.
dispatchCallback
)
(
options
.
progress_callback
{
status
:
'
initiate
'
name
:
path_or_repo_id
file
:
filename
}
)
let
cache
;
if
(
!
cache
&
&
_env_js__WEBPACK_IMPORTED_MODULE_2__
.
env
.
useBrowserCache
)
{
if
(
typeof
caches
=
=
=
'
undefined
'
)
{
throw
Error
(
'
Browser
cache
is
not
available
in
this
environment
.
'
)
}
try
{
cache
=
await
caches
.
open
(
'
transformers
-
cache
'
)
;
}
catch
(
e
)
{
console
.
warn
(
'
An
error
occurred
while
opening
the
browser
cache
:
'
e
)
;
}
}
if
(
!
cache
&
&
_env_js__WEBPACK_IMPORTED_MODULE_2__
.
env
.
useFSCache
)
{
cache
=
new
FileCache
(
options
.
cache_dir
?
?
_env_js__WEBPACK_IMPORTED_MODULE_2__
.
env
.
cacheDir
)
;
}
if
(
!
cache
&
&
_env_js__WEBPACK_IMPORTED_MODULE_2__
.
env
.
useCustomCache
)
{
if
(
!
_env_js__WEBPACK_IMPORTED_MODULE_2__
.
env
.
customCache
)
{
throw
Error
(
'
env
.
useCustomCache
=
true
but
env
.
customCache
is
not
defined
.
'
)
}
if
(
!
_env_js__WEBPACK_IMPORTED_MODULE_2__
.
env
.
customCache
.
match
|
|
!
_env_js__WEBPACK_IMPORTED_MODULE_2__
.
env
.
customCache
.
put
)
{
throw
new
Error
(
"
env
.
customCache
must
be
an
object
which
implements
the
match
and
put
functions
of
the
Web
Cache
API
.
"
+
"
For
more
information
see
https
:
/
/
developer
.
mozilla
.
org
/
en
-
US
/
docs
/
Web
/
API
/
Cache
"
)
}
cache
=
_env_js__WEBPACK_IMPORTED_MODULE_2__
.
env
.
customCache
;
}
const
revision
=
options
.
revision
?
?
'
main
'
;
let
requestURL
=
pathJoin
(
path_or_repo_id
filename
)
;
let
localPath
=
pathJoin
(
_env_js__WEBPACK_IMPORTED_MODULE_2__
.
env
.
localModelPath
requestURL
)
;
let
remoteURL
=
pathJoin
(
_env_js__WEBPACK_IMPORTED_MODULE_2__
.
env
.
remoteHost
_env_js__WEBPACK_IMPORTED_MODULE_2__
.
env
.
remotePathTemplate
.
replaceAll
(
'
{
model
}
'
path_or_repo_id
)
.
replaceAll
(
'
{
revision
}
'
encodeURIComponent
(
revision
)
)
filename
)
;
let
fsCacheKey
=
revision
=
=
=
'
main
'
?
requestURL
:
pathJoin
(
path_or_repo_id
revision
filename
)
;
let
cacheKey
;
let
proposedCacheKey
=
cache
instanceof
FileCache
?
fsCacheKey
:
remoteURL
;
let
toCacheResponse
=
false
;
let
response
;
if
(
cache
)
{
response
=
await
tryCache
(
cache
localPath
proposedCacheKey
)
;
}
const
cacheHit
=
response
!
=
=
undefined
;
if
(
response
=
=
=
undefined
)
{
if
(
_env_js__WEBPACK_IMPORTED_MODULE_2__
.
env
.
allowLocalModels
)
{
const
isURL
=
isValidUrl
(
requestURL
[
'
http
:
'
'
https
:
'
]
)
;
if
(
!
isURL
)
{
try
{
response
=
await
getFile
(
localPath
)
;
cacheKey
=
localPath
;
}
catch
(
e
)
{
console
.
warn
(
Unable
to
load
from
local
path
"
{
localPath
}
"
:
"
{
e
}
"
)
;
}
}
else
if
(
options
.
local_files_only
)
{
throw
new
Error
(
\
local_files_only
=
true
\
but
attempted
to
load
a
remote
file
from
:
{
requestURL
}
.
)
;
}
else
if
(
!
_env_js__WEBPACK_IMPORTED_MODULE_2__
.
env
.
allowRemoteModels
)
{
throw
new
Error
(
\
env
.
allowRemoteModels
=
false
\
but
attempted
to
load
a
remote
file
from
:
{
requestURL
}
.
)
;
}
}
if
(
response
=
=
=
undefined
|
|
response
.
status
=
=
=
404
)
{
if
(
options
.
local_files_only
|
|
!
_env_js__WEBPACK_IMPORTED_MODULE_2__
.
env
.
allowRemoteModels
)
{
if
(
fatal
)
{
throw
Error
(
\
local_files_only
=
true
\
or
\
env
.
allowRemoteModels
=
false
\
and
file
was
not
found
locally
at
"
{
localPath
}
"
.
)
;
}
else
{
return
null
;
}
}
response
=
await
getFile
(
remoteURL
)
;
if
(
response
.
status
!
=
=
200
)
{
return
handleError
(
response
.
status
remoteURL
fatal
)
;
}
cacheKey
=
proposedCacheKey
;
}
toCacheResponse
=
cache
&
&
typeof
Response
!
=
=
'
undefined
'
&
&
response
instanceof
Response
&
&
response
.
status
=
=
=
200
}
(
0
_core_js__WEBPACK_IMPORTED_MODULE_3__
.
dispatchCallback
)
(
options
.
progress_callback
{
status
:
'
download
'
name
:
path_or_repo_id
file
:
filename
}
)
const
progressInfo
=
{
status
:
'
progress
'
name
:
path_or_repo_id
file
:
filename
}
let
buffer
;
if
(
!
options
.
progress_callback
)
{
buffer
=
new
Uint8Array
(
await
response
.
arrayBuffer
(
)
)
;
}
else
if
(
cacheHit
&
&
typeof
navigator
!
=
=
'
undefined
'
&
&
/
firefox
/
i
.
test
(
navigator
.
userAgent
)
)
{
buffer
=
new
Uint8Array
(
await
response
.
arrayBuffer
(
)
)
;
(
0
_core_js__WEBPACK_IMPORTED_MODULE_3__
.
dispatchCallback
)
(
options
.
progress_callback
{
.
.
.
progressInfo
progress
:
100
loaded
:
buffer
.
length
total
:
buffer
.
length
}
)
}
else
{
buffer
=
await
readResponse
(
response
data
=
>
{
(
0
_core_js__WEBPACK_IMPORTED_MODULE_3__
.
dispatchCallback
)
(
options
.
progress_callback
{
.
.
.
progressInfo
.
.
.
data
}
)
}
)
}
if
(
toCacheResponse
&
&
cacheKey
&
&
(
await
cache
.
match
(
cacheKey
)
=
=
=
undefined
)
)
{
await
cache
.
put
(
cacheKey
new
Response
(
buffer
{
headers
:
response
.
headers
}
)
)
.
catch
(
err
=
>
{
console
.
warn
(
Unable
to
add
response
to
browser
cache
:
{
err
}
.
)
;
}
)
;
}
(
0
_core_js__WEBPACK_IMPORTED_MODULE_3__
.
dispatchCallback
)
(
options
.
progress_callback
{
status
:
'
done
'
name
:
path_or_repo_id
file
:
filename
}
)
;
return
buffer
;
}
async
function
getModelJSON
(
modelPath
fileName
fatal
=
true
options
=
{
}
)
{
let
buffer
=
await
getModelFile
(
modelPath
fileName
fatal
options
)
;
if
(
buffer
=
=
=
null
)
{
return
{
}
}
let
decoder
=
new
TextDecoder
(
'
utf
-
8
'
)
;
let
jsonData
=
decoder
.
decode
(
buffer
)
;
return
JSON
.
parse
(
jsonData
)
;
}
async
function
readResponse
(
response
progress_callback
)
{
const
contentLength
=
response
.
headers
.
get
(
'
Content
-
Length
'
)
;
if
(
contentLength
=
=
=
null
)
{
console
.
warn
(
'
Unable
to
determine
content
-
length
from
response
headers
.
Will
expand
buffer
when
needed
.
'
)
}
let
total
=
parseInt
(
contentLength
?
?
'
0
'
)
;
let
buffer
=
new
Uint8Array
(
total
)
;
let
loaded
=
0
;
const
reader
=
response
.
body
.
getReader
(
)
;
async
function
read
(
)
{
const
{
done
value
}
=
await
reader
.
read
(
)
;
if
(
done
)
return
;
let
newLoaded
=
loaded
+
value
.
length
;
if
(
newLoaded
>
total
)
{
total
=
newLoaded
;
let
newBuffer
=
new
Uint8Array
(
total
)
;
newBuffer
.
set
(
buffer
)
;
buffer
=
newBuffer
;
}
buffer
.
set
(
value
loaded
)
loaded
=
newLoaded
;
const
progress
=
(
loaded
/
total
)
*
100
;
progress_callback
(
{
progress
:
progress
loaded
:
loaded
total
:
total
}
)
return
read
(
)
;
}
await
read
(
)
;
return
buffer
;
}
function
pathJoin
(
.
.
.
parts
)
{
parts
=
parts
.
map
(
(
part
index
)
=
>
{
if
(
index
)
{
part
=
part
.
replace
(
new
RegExp
(
'
^
/
'
)
'
'
)
;
}
if
(
index
!
=
=
parts
.
length
-
1
)
{
part
=
part
.
replace
(
new
RegExp
(
'
/
'
)
'
'
)
;
}
return
part
;
}
)
return
parts
.
join
(
'
/
'
)
;
}
}
)
"
.
/
src
/
utils
/
image
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
RawImage
:
(
)
=
>
(
RawImage
)
}
)
;
var
_core_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
src
/
utils
/
core
.
js
"
)
;
var
_hub_js__WEBPACK_IMPORTED_MODULE_1__
=
__webpack_require__
(
"
.
/
src
/
utils
/
hub
.
js
"
)
;
var
_env_js__WEBPACK_IMPORTED_MODULE_2__
=
__webpack_require__
(
"
.
/
src
/
env
.
js
"
)
;
var
_tensor_js__WEBPACK_IMPORTED_MODULE_3__
=
__webpack_require__
(
"
.
/
src
/
utils
/
tensor
.
js
"
)
;
var
sharp__WEBPACK_IMPORTED_MODULE_4__
=
__webpack_require__
(
"
?
2b25
"
)
;
const
BROWSER_ENV
=
typeof
self
!
=
=
'
undefined
'
;
const
WEBWORKER_ENV
=
BROWSER_ENV
&
&
self
.
constructor
.
name
=
=
=
'
DedicatedWorkerGlobalScope
'
;
let
createCanvasFunction
;
let
ImageDataClass
;
let
loadImageFunction
;
if
(
BROWSER_ENV
)
{
createCanvasFunction
=
(
width
height
)
=
>
{
if
(
!
self
.
OffscreenCanvas
)
{
throw
new
Error
(
'
OffscreenCanvas
not
supported
by
this
browser
.
'
)
;
}
return
new
self
.
OffscreenCanvas
(
width
height
)
}
;
loadImageFunction
=
self
.
createImageBitmap
;
ImageDataClass
=
self
.
ImageData
;
}
else
if
(
sharp__WEBPACK_IMPORTED_MODULE_4__
)
{
loadImageFunction
=
async
(
img
)
=
>
{
const
metadata
=
await
img
.
metadata
(
)
;
const
rawChannels
=
metadata
.
channels
;
const
{
data
info
}
=
await
img
.
rotate
(
)
.
raw
(
)
.
toBuffer
(
{
resolveWithObject
:
true
}
)
;
const
newImage
=
new
RawImage
(
new
Uint8ClampedArray
(
data
)
info
.
width
info
.
height
info
.
channels
)
;
if
(
rawChannels
!
=
=
undefined
&
&
rawChannels
!
=
=
info
.
channels
)
{
newImage
.
convert
(
rawChannels
)
;
}
return
newImage
;
}
}
else
{
throw
new
Error
(
'
Unable
to
load
image
processing
library
.
'
)
;
}
const
RESAMPLING_MAPPING
=
{
0
:
'
nearest
'
1
:
'
lanczos
'
2
:
'
bilinear
'
3
:
'
bicubic
'
4
:
'
box
'
5
:
'
hamming
'
}
const
CONTENT_TYPE_MAP
=
new
Map
(
[
[
'
png
'
'
image
/
png
'
]
[
'
jpg
'
'
image
/
jpeg
'
]
[
'
jpeg
'
'
image
/
jpeg
'
]
[
'
gif
'
'
image
/
gif
'
]
]
)
;
class
RawImage
{
constructor
(
data
width
height
channels
)
{
this
.
data
=
data
;
this
.
width
=
width
;
this
.
height
=
height
;
this
.
channels
=
channels
;
}
get
size
(
)
{
return
[
this
.
width
this
.
height
]
;
}
static
async
read
(
input
)
{
if
(
input
instanceof
RawImage
)
{
return
input
;
}
else
if
(
typeof
input
=
=
=
'
string
'
|
|
input
instanceof
URL
)
{
return
await
this
.
fromURL
(
input
)
;
}
else
{
throw
new
Error
(
Unsupported
input
type
:
{
typeof
input
}
)
;
}
}
static
fromCanvas
(
canvas
)
{
if
(
!
BROWSER_ENV
)
{
throw
new
Error
(
'
fromCanvas
(
)
is
only
supported
in
browser
environments
.
'
)
}
const
ctx
=
canvas
.
getContext
(
'
2d
'
)
;
const
data
=
ctx
.
getImageData
(
0
0
canvas
.
width
canvas
.
height
)
.
data
;
return
new
RawImage
(
data
canvas
.
width
canvas
.
height
4
)
;
}
static
async
fromURL
(
url
)
{
const
response
=
await
(
0
_hub_js__WEBPACK_IMPORTED_MODULE_1__
.
getFile
)
(
url
)
;
if
(
response
.
status
!
=
=
200
)
{
throw
new
Error
(
Unable
to
read
image
from
"
{
url
}
"
(
{
response
.
status
}
{
response
.
statusText
}
)
)
;
}
const
blob
=
await
response
.
blob
(
)
;
return
this
.
fromBlob
(
blob
)
;
}
static
async
fromBlob
(
blob
)
{
if
(
BROWSER_ENV
)
{
const
img
=
await
loadImageFunction
(
blob
)
;
const
ctx
=
createCanvasFunction
(
img
.
width
img
.
height
)
.
getContext
(
'
2d
'
)
;
ctx
.
drawImage
(
img
0
0
)
;
return
new
this
(
ctx
.
getImageData
(
0
0
img
.
width
img
.
height
)
.
data
img
.
width
img
.
height
4
)
;
}
else
{
const
img
=
sharp__WEBPACK_IMPORTED_MODULE_4__
(
await
blob
.
arrayBuffer
(
)
)
;
return
await
loadImageFunction
(
img
)
;
}
}
static
fromTensor
(
tensor
channel_format
=
'
CHW
'
)
{
if
(
tensor
.
dims
.
length
!
=
=
3
)
{
throw
new
Error
(
Tensor
should
have
3
dimensions
but
has
{
tensor
.
dims
.
length
}
dimensions
.
)
;
}
if
(
channel_format
=
=
=
'
CHW
'
)
{
tensor
=
tensor
.
transpose
(
1
2
0
)
;
}
else
if
(
channel_format
=
=
=
'
HWC
'
)
{
}
else
{
throw
new
Error
(
Unsupported
channel
format
:
{
channel_format
}
)
;
}
if
(
!
(
tensor
.
data
instanceof
Uint8ClampedArray
|
|
tensor
.
data
instanceof
Uint8Array
)
)
{
throw
new
Error
(
Unsupported
tensor
type
:
{
tensor
.
type
}
)
;
}
switch
(
tensor
.
dims
[
2
]
)
{
case
1
:
case
2
:
case
3
:
case
4
:
return
new
RawImage
(
tensor
.
data
tensor
.
dims
[
1
]
tensor
.
dims
[
0
]
tensor
.
dims
[
2
]
)
;
default
:
throw
new
Error
(
Unsupported
number
of
channels
:
{
tensor
.
dims
[
2
]
}
)
;
}
}
grayscale
(
)
{
if
(
this
.
channels
=
=
=
1
)
{
return
this
;
}
const
newData
=
new
Uint8ClampedArray
(
this
.
width
*
this
.
height
*
1
)
;
switch
(
this
.
channels
)
{
case
3
:
case
4
:
for
(
let
i
=
0
offset
=
0
;
i
<
this
.
data
.
length
;
i
+
=
this
.
channels
)
{
const
red
=
this
.
data
[
i
]
;
const
green
=
this
.
data
[
i
+
1
]
;
const
blue
=
this
.
data
[
i
+
2
]
;
newData
[
offset
+
+
]
=
Math
.
round
(
0
.
2989
*
red
+
0
.
5870
*
green
+
0
.
1140
*
blue
)
;
}
break
;
default
:
throw
new
Error
(
Conversion
failed
due
to
unsupported
number
of
channels
:
{
this
.
channels
}
)
;
}
return
this
.
_update
(
newData
this
.
width
this
.
height
1
)
;
}
rgb
(
)
{
if
(
this
.
channels
=
=
=
3
)
{
return
this
;
}
const
newData
=
new
Uint8ClampedArray
(
this
.
width
*
this
.
height
*
3
)
;
switch
(
this
.
channels
)
{
case
1
:
for
(
let
i
=
0
offset
=
0
;
i
<
this
.
data
.
length
;
+
+
i
)
{
newData
[
offset
+
+
]
=
this
.
data
[
i
]
;
newData
[
offset
+
+
]
=
this
.
data
[
i
]
;
newData
[
offset
+
+
]
=
this
.
data
[
i
]
;
}
break
;
case
4
:
for
(
let
i
=
0
offset
=
0
;
i
<
this
.
data
.
length
;
i
+
=
4
)
{
newData
[
offset
+
+
]
=
this
.
data
[
i
]
;
newData
[
offset
+
+
]
=
this
.
data
[
i
+
1
]
;
newData
[
offset
+
+
]
=
this
.
data
[
i
+
2
]
;
}
break
;
default
:
throw
new
Error
(
Conversion
failed
due
to
unsupported
number
of
channels
:
{
this
.
channels
}
)
;
}
return
this
.
_update
(
newData
this
.
width
this
.
height
3
)
;
}
rgba
(
)
{
if
(
this
.
channels
=
=
=
4
)
{
return
this
;
}
const
newData
=
new
Uint8ClampedArray
(
this
.
width
*
this
.
height
*
4
)
;
switch
(
this
.
channels
)
{
case
1
:
for
(
let
i
=
0
offset
=
0
;
i
<
this
.
data
.
length
;
+
+
i
)
{
newData
[
offset
+
+
]
=
this
.
data
[
i
]
;
newData
[
offset
+
+
]
=
this
.
data
[
i
]
;
newData
[
offset
+
+
]
=
this
.
data
[
i
]
;
newData
[
offset
+
+
]
=
255
;
}
break
;
case
3
:
for
(
let
i
=
0
offset
=
0
;
i
<
this
.
data
.
length
;
i
+
=
3
)
{
newData
[
offset
+
+
]
=
this
.
data
[
i
]
;
newData
[
offset
+
+
]
=
this
.
data
[
i
+
1
]
;
newData
[
offset
+
+
]
=
this
.
data
[
i
+
2
]
;
newData
[
offset
+
+
]
=
255
;
}
break
;
default
:
throw
new
Error
(
Conversion
failed
due
to
unsupported
number
of
channels
:
{
this
.
channels
}
)
;
}
return
this
.
_update
(
newData
this
.
width
this
.
height
4
)
;
}
async
resize
(
width
height
{
resample
=
2
}
=
{
}
)
{
if
(
this
.
width
=
=
=
width
&
&
this
.
height
=
=
=
height
)
{
return
this
;
}
let
resampleMethod
=
RESAMPLING_MAPPING
[
resample
]
?
?
resample
;
const
nullish_width
=
(
0
_core_js__WEBPACK_IMPORTED_MODULE_0__
.
isNullishDimension
)
(
width
)
;
const
nullish_height
=
(
0
_core_js__WEBPACK_IMPORTED_MODULE_0__
.
isNullishDimension
)
(
height
)
;
if
(
nullish_width
&
&
nullish_height
)
{
return
this
;
}
else
if
(
nullish_width
)
{
width
=
(
height
/
this
.
height
)
*
this
.
width
;
}
else
if
(
nullish_height
)
{
height
=
(
width
/
this
.
width
)
*
this
.
height
;
}
if
(
BROWSER_ENV
)
{
const
numChannels
=
this
.
channels
;
const
canvas
=
this
.
toCanvas
(
)
;
const
ctx
=
createCanvasFunction
(
width
height
)
.
getContext
(
'
2d
'
)
;
ctx
.
drawImage
(
canvas
0
0
width
height
)
;
const
resizedImage
=
new
RawImage
(
ctx
.
getImageData
(
0
0
width
height
)
.
data
width
height
4
)
;
return
resizedImage
.
convert
(
numChannels
)
;
}
else
{
let
img
=
this
.
toSharp
(
)
;
switch
(
resampleMethod
)
{
case
'
box
'
:
case
'
hamming
'
:
if
(
resampleMethod
=
=
=
'
box
'
|
|
resampleMethod
=
=
=
'
hamming
'
)
{
console
.
warn
(
Resampling
method
{
resampleMethod
}
is
not
yet
supported
.
Using
bilinear
instead
.
)
;
resampleMethod
=
'
bilinear
'
;
}
case
'
nearest
'
:
case
'
bilinear
'
:
case
'
bicubic
'
:
img
=
img
.
affine
(
[
width
/
this
.
width
0
0
height
/
this
.
height
]
{
interpolator
:
resampleMethod
}
)
;
break
;
case
'
lanczos
'
:
img
=
img
.
resize
(
{
width
height
fit
:
'
fill
'
kernel
:
'
lanczos3
'
}
)
;
break
;
default
:
throw
new
Error
(
Resampling
method
{
resampleMethod
}
is
not
supported
.
)
;
}
return
await
loadImageFunction
(
img
)
;
}
}
async
pad
(
[
left
right
top
bottom
]
)
{
left
=
Math
.
max
(
left
0
)
;
right
=
Math
.
max
(
right
0
)
;
top
=
Math
.
max
(
top
0
)
;
bottom
=
Math
.
max
(
bottom
0
)
;
if
(
left
=
=
=
0
&
&
right
=
=
=
0
&
&
top
=
=
=
0
&
&
bottom
=
=
=
0
)
{
return
this
;
}
if
(
BROWSER_ENV
)
{
const
numChannels
=
this
.
channels
;
const
canvas
=
this
.
toCanvas
(
)
;
const
newWidth
=
this
.
width
+
left
+
right
;
const
newHeight
=
this
.
height
+
top
+
bottom
;
const
ctx
=
createCanvasFunction
(
newWidth
newHeight
)
.
getContext
(
'
2d
'
)
;
ctx
.
drawImage
(
canvas
0
0
this
.
width
this
.
height
left
top
this
.
width
this
.
height
)
;
const
paddedImage
=
new
RawImage
(
ctx
.
getImageData
(
0
0
newWidth
newHeight
)
.
data
newWidth
newHeight
4
)
;
return
paddedImage
.
convert
(
numChannels
)
;
}
else
{
const
img
=
this
.
toSharp
(
)
.
extend
(
{
left
right
top
bottom
}
)
;
return
await
loadImageFunction
(
img
)
;
}
}
async
crop
(
[
x_min
y_min
x_max
y_max
]
)
{
x_min
=
Math
.
max
(
x_min
0
)
;
y_min
=
Math
.
max
(
y_min
0
)
;
x_max
=
Math
.
min
(
x_max
this
.
width
-
1
)
;
y_max
=
Math
.
min
(
y_max
this
.
height
-
1
)
;
if
(
x_min
=
=
=
0
&
&
y_min
=
=
=
0
&
&
x_max
=
=
=
this
.
width
-
1
&
&
y_max
=
=
=
this
.
height
-
1
)
{
return
this
;
}
const
crop_width
=
x_max
-
x_min
+
1
;
const
crop_height
=
y_max
-
y_min
+
1
;
if
(
BROWSER_ENV
)
{
const
numChannels
=
this
.
channels
;
const
canvas
=
this
.
toCanvas
(
)
;
const
ctx
=
createCanvasFunction
(
crop_width
crop_height
)
.
getContext
(
'
2d
'
)
;
ctx
.
drawImage
(
canvas
x_min
y_min
crop_width
crop_height
0
0
crop_width
crop_height
)
;
const
resizedImage
=
new
RawImage
(
ctx
.
getImageData
(
0
0
crop_width
crop_height
)
.
data
crop_width
crop_height
4
)
;
return
resizedImage
.
convert
(
numChannels
)
;
}
else
{
const
img
=
this
.
toSharp
(
)
.
extract
(
{
left
:
x_min
top
:
y_min
width
:
crop_width
height
:
crop_height
}
)
;
return
await
loadImageFunction
(
img
)
;
}
}
async
center_crop
(
crop_width
crop_height
)
{
if
(
this
.
width
=
=
=
crop_width
&
&
this
.
height
=
=
=
crop_height
)
{
return
this
;
}
const
width_offset
=
(
this
.
width
-
crop_width
)
/
2
;
const
height_offset
=
(
this
.
height
-
crop_height
)
/
2
;
if
(
BROWSER_ENV
)
{
const
numChannels
=
this
.
channels
;
const
canvas
=
this
.
toCanvas
(
)
;
const
ctx
=
createCanvasFunction
(
crop_width
crop_height
)
.
getContext
(
'
2d
'
)
;
let
sourceX
=
0
;
let
sourceY
=
0
;
let
destX
=
0
;
let
destY
=
0
;
if
(
width_offset
>
=
0
)
{
sourceX
=
width_offset
;
}
else
{
destX
=
-
width_offset
;
}
if
(
height_offset
>
=
0
)
{
sourceY
=
height_offset
;
}
else
{
destY
=
-
height_offset
;
}
ctx
.
drawImage
(
canvas
sourceX
sourceY
crop_width
crop_height
destX
destY
crop_width
crop_height
)
;
const
resizedImage
=
new
RawImage
(
ctx
.
getImageData
(
0
0
crop_width
crop_height
)
.
data
crop_width
crop_height
4
)
;
return
resizedImage
.
convert
(
numChannels
)
;
}
else
{
let
img
=
this
.
toSharp
(
)
;
if
(
width_offset
>
=
0
&
&
height_offset
>
=
0
)
{
img
=
img
.
extract
(
{
left
:
Math
.
floor
(
width_offset
)
top
:
Math
.
floor
(
height_offset
)
width
:
crop_width
height
:
crop_height
}
)
}
else
if
(
width_offset
<
=
0
&
&
height_offset
<
=
0
)
{
const
top
=
Math
.
floor
(
-
height_offset
)
;
const
left
=
Math
.
floor
(
-
width_offset
)
;
img
=
img
.
extend
(
{
top
:
top
left
:
left
right
:
crop_width
-
this
.
width
-
left
bottom
:
crop_height
-
this
.
height
-
top
}
)
;
}
else
{
let
y_padding
=
[
0
0
]
;
let
y_extract
=
0
;
if
(
height_offset
<
0
)
{
y_padding
[
0
]
=
Math
.
floor
(
-
height_offset
)
;
y_padding
[
1
]
=
crop_height
-
this
.
height
-
y_padding
[
0
]
;
}
else
{
y_extract
=
Math
.
floor
(
height_offset
)
;
}
let
x_padding
=
[
0
0
]
;
let
x_extract
=
0
;
if
(
width_offset
<
0
)
{
x_padding
[
0
]
=
Math
.
floor
(
-
width_offset
)
;
x_padding
[
1
]
=
crop_width
-
this
.
width
-
x_padding
[
0
]
;
}
else
{
x_extract
=
Math
.
floor
(
width_offset
)
;
}
img
=
img
.
extend
(
{
top
:
y_padding
[
0
]
bottom
:
y_padding
[
1
]
left
:
x_padding
[
0
]
right
:
x_padding
[
1
]
}
)
.
extract
(
{
left
:
x_extract
top
:
y_extract
width
:
crop_width
height
:
crop_height
}
)
}
return
await
loadImageFunction
(
img
)
;
}
}
async
toBlob
(
type
=
'
image
/
png
'
quality
=
1
)
{
if
(
!
BROWSER_ENV
)
{
throw
new
Error
(
'
toBlob
(
)
is
only
supported
in
browser
environments
.
'
)
}
const
canvas
=
this
.
toCanvas
(
)
;
return
await
canvas
.
convertToBlob
(
{
type
quality
}
)
;
}
toTensor
(
channel_format
=
'
CHW
'
)
{
let
tensor
=
new
_tensor_js__WEBPACK_IMPORTED_MODULE_3__
.
Tensor
(
'
uint8
'
new
Uint8Array
(
this
.
data
)
[
this
.
height
this
.
width
this
.
channels
]
)
;
if
(
channel_format
=
=
=
'
HWC
'
)
{
}
else
if
(
channel_format
=
=
=
'
CHW
'
)
{
tensor
=
tensor
.
permute
(
2
0
1
)
;
}
else
{
throw
new
Error
(
Unsupported
channel
format
:
{
channel_format
}
)
;
}
return
tensor
;
}
toCanvas
(
)
{
if
(
!
BROWSER_ENV
)
{
throw
new
Error
(
'
toCanvas
(
)
is
only
supported
in
browser
environments
.
'
)
}
const
cloned
=
this
.
clone
(
)
.
rgba
(
)
;
const
clonedCanvas
=
createCanvasFunction
(
cloned
.
width
cloned
.
height
)
;
const
data
=
new
ImageDataClass
(
cloned
.
data
cloned
.
width
cloned
.
height
)
;
clonedCanvas
.
getContext
(
'
2d
'
)
.
putImageData
(
data
0
0
)
;
return
clonedCanvas
;
}
split
(
)
{
const
{
data
width
height
channels
}
=
this
;
const
data_type
=
(
data
.
constructor
)
;
const
per_channel_length
=
data
.
length
/
channels
;
const
split_data
=
Array
.
from
(
{
length
:
channels
}
(
)
=
>
new
data_type
(
per_channel_length
)
)
;
for
(
let
i
=
0
;
i
<
per_channel_length
;
+
+
i
)
{
const
data_offset
=
channels
*
i
;
for
(
let
j
=
0
;
j
<
channels
;
+
+
j
)
{
split_data
[
j
]
[
i
]
=
data
[
data_offset
+
j
]
;
}
}
return
split_data
.
map
(
(
data
)
=
>
new
RawImage
(
data
width
height
1
)
)
;
}
_update
(
data
width
height
channels
=
null
)
{
this
.
data
=
data
;
this
.
width
=
width
;
this
.
height
=
height
;
if
(
channels
!
=
=
null
)
{
this
.
channels
=
channels
;
}
return
this
;
}
clone
(
)
{
return
new
RawImage
(
this
.
data
.
slice
(
)
this
.
width
this
.
height
this
.
channels
)
;
}
convert
(
numChannels
)
{
if
(
this
.
channels
=
=
=
numChannels
)
return
this
;
switch
(
numChannels
)
{
case
1
:
this
.
grayscale
(
)
;
break
;
case
3
:
this
.
rgb
(
)
;
break
;
case
4
:
this
.
rgba
(
)
;
break
;
default
:
throw
new
Error
(
Conversion
failed
due
to
unsupported
number
of
channels
:
{
this
.
channels
}
)
;
}
return
this
;
}
async
save
(
path
)
{
if
(
BROWSER_ENV
)
{
if
(
WEBWORKER_ENV
)
{
throw
new
Error
(
'
Unable
to
save
an
image
from
a
Web
Worker
.
'
)
}
const
extension
=
path
.
split
(
'
.
'
)
.
pop
(
)
.
toLowerCase
(
)
;
const
mime
=
CONTENT_TYPE_MAP
.
get
(
extension
)
?
?
'
image
/
png
'
;
const
blob
=
await
this
.
toBlob
(
mime
)
;
const
dataURL
=
URL
.
createObjectURL
(
blob
)
;
const
downloadLink
=
document
.
createElement
(
'
a
'
)
;
downloadLink
.
href
=
dataURL
;
downloadLink
.
download
=
path
;
downloadLink
.
click
(
)
;
downloadLink
.
remove
(
)
;
}
else
if
(
!
_env_js__WEBPACK_IMPORTED_MODULE_2__
.
env
.
useFS
)
{
throw
new
Error
(
'
Unable
to
save
the
image
because
filesystem
is
disabled
in
this
environment
.
'
)
}
else
{
const
img
=
this
.
toSharp
(
)
;
return
await
img
.
toFile
(
path
)
;
}
}
toSharp
(
)
{
if
(
BROWSER_ENV
)
{
throw
new
Error
(
'
toSharp
(
)
is
only
supported
in
server
-
side
environments
.
'
)
}
return
sharp__WEBPACK_IMPORTED_MODULE_4__
(
this
.
data
{
raw
:
{
width
:
this
.
width
height
:
this
.
height
channels
:
this
.
channels
}
}
)
;
}
}
}
)
"
.
/
src
/
utils
/
maths
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
FFT
:
(
)
=
>
(
FFT
)
bankers_round
:
(
)
=
>
(
bankers_round
)
cos_sim
:
(
)
=
>
(
cos_sim
)
dot
:
(
)
=
>
(
dot
)
dynamic_time_warping
:
(
)
=
>
(
dynamic_time_warping
)
interpolate_data
:
(
)
=
>
(
interpolate_data
)
log_softmax
:
(
)
=
>
(
log_softmax
)
magnitude
:
(
)
=
>
(
magnitude
)
max
:
(
)
=
>
(
max
)
medianFilter
:
(
)
=
>
(
medianFilter
)
min
:
(
)
=
>
(
min
)
permute_data
:
(
)
=
>
(
permute_data
)
round
:
(
)
=
>
(
round
)
softmax
:
(
)
=
>
(
softmax
)
}
)
;
function
interpolate_data
(
input
[
in_channels
in_height
in_width
]
[
out_height
out_width
]
mode
=
'
bilinear
'
align_corners
=
false
)
{
const
x_scale
=
out_width
/
in_width
;
const
y_scale
=
out_height
/
in_height
;
const
out_img
=
new
input
.
constructor
(
out_height
*
out_width
*
in_channels
)
;
const
inStride
=
in_height
*
in_width
;
const
outStride
=
out_height
*
out_width
;
for
(
let
i
=
0
;
i
<
out_height
;
+
+
i
)
{
for
(
let
j
=
0
;
j
<
out_width
;
+
+
j
)
{
const
outOffset
=
i
*
out_width
+
j
;
const
x
=
(
j
+
0
.
5
)
/
x_scale
-
0
.
5
;
const
y
=
(
i
+
0
.
5
)
/
y_scale
-
0
.
5
;
let
x1
=
Math
.
floor
(
x
)
;
let
y1
=
Math
.
floor
(
y
)
;
const
x2
=
Math
.
min
(
x1
+
1
in_width
-
1
)
;
const
y2
=
Math
.
min
(
y1
+
1
in_height
-
1
)
;
x1
=
Math
.
max
(
x1
0
)
;
y1
=
Math
.
max
(
y1
0
)
;
const
s
=
x
-
x1
;
const
t
=
y
-
y1
;
const
w1
=
(
1
-
s
)
*
(
1
-
t
)
;
const
w2
=
s
*
(
1
-
t
)
;
const
w3
=
(
1
-
s
)
*
t
;
const
w4
=
s
*
t
;
const
yStride
=
y1
*
in_width
;
const
xStride
=
y2
*
in_width
;
const
idx1
=
yStride
+
x1
;
const
idx2
=
yStride
+
x2
;
const
idx3
=
xStride
+
x1
;
const
idx4
=
xStride
+
x2
;
for
(
let
k
=
0
;
k
<
in_channels
;
+
+
k
)
{
const
cOffset
=
k
*
inStride
;
out_img
[
k
*
outStride
+
outOffset
]
=
w1
*
input
[
cOffset
+
idx1
]
+
w2
*
input
[
cOffset
+
idx2
]
+
w3
*
input
[
cOffset
+
idx3
]
+
w4
*
input
[
cOffset
+
idx4
]
;
}
}
}
return
out_img
;
}
function
permute_data
(
array
dims
axes
)
{
const
shape
=
new
Array
(
axes
.
length
)
;
const
stride
=
new
Array
(
axes
.
length
)
;
for
(
let
i
=
axes
.
length
-
1
s
=
1
;
i
>
=
0
;
-
-
i
)
{
stride
[
i
]
=
s
;
shape
[
i
]
=
dims
[
axes
[
i
]
]
;
s
*
=
shape
[
i
]
;
}
const
invStride
=
axes
.
map
(
(
_
i
)
=
>
stride
[
axes
.
indexOf
(
i
)
]
)
;
const
permutedData
=
new
array
.
constructor
(
array
.
length
)
;
for
(
let
i
=
0
;
i
<
array
.
length
;
+
+
i
)
{
let
newIndex
=
0
;
for
(
let
j
=
dims
.
length
-
1
k
=
i
;
j
>
=
0
;
-
-
j
)
{
newIndex
+
=
(
k
%
dims
[
j
]
)
*
invStride
[
j
]
;
k
=
Math
.
floor
(
k
/
dims
[
j
]
)
;
}
permutedData
[
newIndex
]
=
array
[
i
]
;
}
return
[
permutedData
shape
]
;
}
function
softmax
(
arr
)
{
const
maxVal
=
max
(
arr
)
[
0
]
;
const
exps
=
arr
.
map
(
x
=
>
Math
.
exp
(
x
-
maxVal
)
)
;
const
sumExps
=
exps
.
reduce
(
(
acc
val
)
=
>
acc
+
val
0
)
;
const
softmaxArr
=
exps
.
map
(
x
=
>
x
/
sumExps
)
;
return
(
softmaxArr
)
;
}
function
log_softmax
(
arr
)
{
const
maxVal
=
max
(
arr
)
[
0
]
;
let
sumExps
=
0
;
for
(
let
i
=
0
;
i
<
arr
.
length
;
+
+
i
)
{
sumExps
+
=
Math
.
exp
(
arr
[
i
]
-
maxVal
)
;
}
const
logSum
=
Math
.
log
(
sumExps
)
;
const
logSoftmaxArr
=
arr
.
map
(
x
=
>
x
-
maxVal
-
logSum
)
;
return
(
logSoftmaxArr
)
;
}
function
dot
(
arr1
arr2
)
{
let
result
=
0
;
for
(
let
i
=
0
;
i
<
arr1
.
length
;
+
+
i
)
{
result
+
=
arr1
[
i
]
*
arr2
[
i
]
;
}
return
result
;
}
function
cos_sim
(
arr1
arr2
)
{
const
dotProduct
=
dot
(
arr1
arr2
)
;
const
magnitudeA
=
magnitude
(
arr1
)
;
const
magnitudeB
=
magnitude
(
arr2
)
;
const
cosineSimilarity
=
dotProduct
/
(
magnitudeA
*
magnitudeB
)
;
return
cosineSimilarity
;
}
function
magnitude
(
arr
)
{
return
Math
.
sqrt
(
arr
.
reduce
(
(
acc
val
)
=
>
acc
+
val
*
val
0
)
)
;
}
function
min
(
arr
)
{
if
(
arr
.
length
=
=
=
0
)
throw
Error
(
'
Array
must
not
be
empty
'
)
;
let
min
=
arr
[
0
]
;
let
indexOfMin
=
0
;
for
(
let
i
=
1
;
i
<
arr
.
length
;
+
+
i
)
{
if
(
arr
[
i
]
<
min
)
{
min
=
arr
[
i
]
;
indexOfMin
=
i
;
}
}
return
[
min
indexOfMin
]
;
}
function
max
(
arr
)
{
if
(
arr
.
length
=
=
=
0
)
throw
Error
(
'
Array
must
not
be
empty
'
)
;
let
max
=
arr
[
0
]
;
let
indexOfMax
=
0
;
for
(
let
i
=
1
;
i
<
arr
.
length
;
+
+
i
)
{
if
(
arr
[
i
]
>
max
)
{
max
=
arr
[
i
]
;
indexOfMax
=
i
;
}
}
return
[
Number
(
max
)
indexOfMax
]
;
}
function
isPowerOfTwo
(
number
)
{
return
(
number
>
0
)
&
&
(
(
number
&
(
number
-
1
)
)
=
=
=
0
)
;
}
class
P2FFT
{
constructor
(
size
)
{
this
.
size
=
size
|
0
;
if
(
this
.
size
<
=
1
|
|
!
isPowerOfTwo
(
this
.
size
)
)
throw
new
Error
(
'
FFT
size
must
be
a
power
of
two
larger
than
1
'
)
;
this
.
_csize
=
size
<
<
1
;
this
.
table
=
new
Float64Array
(
this
.
size
*
2
)
;
for
(
let
i
=
0
;
i
<
this
.
table
.
length
;
i
+
=
2
)
{
const
angle
=
Math
.
PI
*
i
/
this
.
size
;
this
.
table
[
i
]
=
Math
.
cos
(
angle
)
;
this
.
table
[
i
+
1
]
=
-
Math
.
sin
(
angle
)
;
}
let
power
=
0
;
for
(
let
t
=
1
;
this
.
size
>
t
;
t
<
<
=
1
)
+
+
power
;
this
.
_width
=
power
%
2
=
=
=
0
?
power
-
1
:
power
;
this
.
_bitrev
=
new
Int32Array
(
1
<
<
this
.
_width
)
;
for
(
let
j
=
0
;
j
<
this
.
_bitrev
.
length
;
+
+
j
)
{
this
.
_bitrev
[
j
]
=
0
;
for
(
let
shift
=
0
;
shift
<
this
.
_width
;
shift
+
=
2
)
{
const
revShift
=
this
.
_width
-
shift
-
2
;
this
.
_bitrev
[
j
]
|
=
(
(
j
>
>
>
shift
)
&
3
)
<
<
revShift
;
}
}
}
createComplexArray
(
)
{
return
new
Float64Array
(
this
.
_csize
)
;
}
fromComplexArray
(
complex
storage
)
{
const
res
=
storage
|
|
new
Array
(
complex
.
length
>
>
>
1
)
;
for
(
let
i
=
0
;
i
<
complex
.
length
;
i
+
=
2
)
res
[
i
>
>
>
1
]
=
complex
[
i
]
;
return
res
;
}
toComplexArray
(
input
storage
)
{
const
res
=
storage
|
|
this
.
createComplexArray
(
)
;
for
(
let
i
=
0
;
i
<
res
.
length
;
i
+
=
2
)
{
res
[
i
]
=
input
[
i
>
>
>
1
]
;
res
[
i
+
1
]
=
0
;
}
return
res
;
}
transform
(
out
data
)
{
if
(
out
=
=
=
data
)
throw
new
Error
(
'
Input
and
output
buffers
must
be
different
'
)
;
this
.
_transform4
(
out
data
1
)
;
}
realTransform
(
out
data
)
{
if
(
out
=
=
=
data
)
throw
new
Error
(
'
Input
and
output
buffers
must
be
different
'
)
;
this
.
_realTransform4
(
out
data
1
)
;
}
inverseTransform
(
out
data
)
{
if
(
out
=
=
=
data
)
throw
new
Error
(
'
Input
and
output
buffers
must
be
different
'
)
;
this
.
_transform4
(
out
data
-
1
)
;
for
(
let
i
=
0
;
i
<
out
.
length
;
+
+
i
)
out
[
i
]
/
=
this
.
size
;
}
_transform4
(
out
data
inv
)
{
const
size
=
this
.
_csize
;
const
width
=
this
.
_width
;
let
step
=
1
<
<
width
;
let
len
=
(
size
/
step
)
<
<
1
;
let
outOff
;
let
t
;
const
bitrev
=
this
.
_bitrev
;
if
(
len
=
=
=
4
)
{
for
(
outOff
=
0
t
=
0
;
outOff
<
size
;
outOff
+
=
len
+
+
t
)
{
const
off
=
bitrev
[
t
]
;
this
.
_singleTransform2
(
data
out
outOff
off
step
)
;
}
}
else
{
for
(
outOff
=
0
t
=
0
;
outOff
<
size
;
outOff
+
=
len
+
+
t
)
{
const
off
=
bitrev
[
t
]
;
this
.
_singleTransform4
(
data
out
outOff
off
step
inv
)
;
}
}
const
table
=
this
.
table
;
for
(
step
>
>
=
2
;
step
>
=
2
;
step
>
>
=
2
)
{
len
=
(
size
/
step
)
<
<
1
;
const
quarterLen
=
len
>
>
>
2
;
for
(
outOff
=
0
;
outOff
<
size
;
outOff
+
=
len
)
{
const
limit
=
outOff
+
quarterLen
-
1
;
for
(
let
i
=
outOff
k
=
0
;
i
<
limit
;
i
+
=
2
k
+
=
step
)
{
const
A
=
i
;
const
B
=
A
+
quarterLen
;
const
C
=
B
+
quarterLen
;
const
D
=
C
+
quarterLen
;
const
Ar
=
out
[
A
]
;
const
Ai
=
out
[
A
+
1
]
;
const
Br
=
out
[
B
]
;
const
Bi
=
out
[
B
+
1
]
;
const
Cr
=
out
[
C
]
;
const
Ci
=
out
[
C
+
1
]
;
const
Dr
=
out
[
D
]
;
const
Di
=
out
[
D
+
1
]
;
const
tableBr
=
table
[
k
]
;
const
tableBi
=
inv
*
table
[
k
+
1
]
;
const
MBr
=
Br
*
tableBr
-
Bi
*
tableBi
;
const
MBi
=
Br
*
tableBi
+
Bi
*
tableBr
;
const
tableCr
=
table
[
2
*
k
]
;
const
tableCi
=
inv
*
table
[
2
*
k
+
1
]
;
const
MCr
=
Cr
*
tableCr
-
Ci
*
tableCi
;
const
MCi
=
Cr
*
tableCi
+
Ci
*
tableCr
;
const
tableDr
=
table
[
3
*
k
]
;
const
tableDi
=
inv
*
table
[
3
*
k
+
1
]
;
const
MDr
=
Dr
*
tableDr
-
Di
*
tableDi
;
const
MDi
=
Dr
*
tableDi
+
Di
*
tableDr
;
const
T0r
=
Ar
+
MCr
;
const
T0i
=
Ai
+
MCi
;
const
T1r
=
Ar
-
MCr
;
const
T1i
=
Ai
-
MCi
;
const
T2r
=
MBr
+
MDr
;
const
T2i
=
MBi
+
MDi
;
const
T3r
=
inv
*
(
MBr
-
MDr
)
;
const
T3i
=
inv
*
(
MBi
-
MDi
)
;
out
[
A
]
=
T0r
+
T2r
;
out
[
A
+
1
]
=
T0i
+
T2i
;
out
[
B
]
=
T1r
+
T3i
;
out
[
B
+
1
]
=
T1i
-
T3r
;
out
[
C
]
=
T0r
-
T2r
;
out
[
C
+
1
]
=
T0i
-
T2i
;
out
[
D
]
=
T1r
-
T3i
;
out
[
D
+
1
]
=
T1i
+
T3r
;
}
}
}
}
_singleTransform2
(
data
out
outOff
off
step
)
{
const
evenR
=
data
[
off
]
;
const
evenI
=
data
[
off
+
1
]
;
const
oddR
=
data
[
off
+
step
]
;
const
oddI
=
data
[
off
+
step
+
1
]
;
out
[
outOff
]
=
evenR
+
oddR
;
out
[
outOff
+
1
]
=
evenI
+
oddI
;
out
[
outOff
+
2
]
=
evenR
-
oddR
;
out
[
outOff
+
3
]
=
evenI
-
oddI
;
}
_singleTransform4
(
data
out
outOff
off
step
inv
)
{
const
step2
=
step
*
2
;
const
step3
=
step
*
3
;
const
Ar
=
data
[
off
]
;
const
Ai
=
data
[
off
+
1
]
;
const
Br
=
data
[
off
+
step
]
;
const
Bi
=
data
[
off
+
step
+
1
]
;
const
Cr
=
data
[
off
+
step2
]
;
const
Ci
=
data
[
off
+
step2
+
1
]
;
const
Dr
=
data
[
off
+
step3
]
;
const
Di
=
data
[
off
+
step3
+
1
]
;
const
T0r
=
Ar
+
Cr
;
const
T0i
=
Ai
+
Ci
;
const
T1r
=
Ar
-
Cr
;
const
T1i
=
Ai
-
Ci
;
const
T2r
=
Br
+
Dr
;
const
T2i
=
Bi
+
Di
;
const
T3r
=
inv
*
(
Br
-
Dr
)
;
const
T3i
=
inv
*
(
Bi
-
Di
)
;
out
[
outOff
]
=
T0r
+
T2r
;
out
[
outOff
+
1
]
=
T0i
+
T2i
;
out
[
outOff
+
2
]
=
T1r
+
T3i
;
out
[
outOff
+
3
]
=
T1i
-
T3r
;
out
[
outOff
+
4
]
=
T0r
-
T2r
;
out
[
outOff
+
5
]
=
T0i
-
T2i
;
out
[
outOff
+
6
]
=
T1r
-
T3i
;
out
[
outOff
+
7
]
=
T1i
+
T3r
;
}
_realTransform4
(
out
data
inv
)
{
const
size
=
this
.
_csize
;
const
width
=
this
.
_width
;
let
step
=
1
<
<
width
;
let
len
=
(
size
/
step
)
<
<
1
;
let
outOff
;
let
t
;
const
bitrev
=
this
.
_bitrev
;
if
(
len
=
=
=
4
)
{
for
(
outOff
=
0
t
=
0
;
outOff
<
size
;
outOff
+
=
len
+
+
t
)
{
const
off
=
bitrev
[
t
]
;
this
.
_singleRealTransform2
(
data
out
outOff
off
>
>
>
1
step
>
>
>
1
)
;
}
}
else
{
for
(
outOff
=
0
t
=
0
;
outOff
<
size
;
outOff
+
=
len
+
+
t
)
{
const
off
=
bitrev
[
t
]
;
this
.
_singleRealTransform4
(
data
out
outOff
off
>
>
>
1
step
>
>
>
1
inv
)
;
}
}
const
table
=
this
.
table
;
for
(
step
>
>
=
2
;
step
>
=
2
;
step
>
>
=
2
)
{
len
=
(
size
/
step
)
<
<
1
;
const
halfLen
=
len
>
>
>
1
;
const
quarterLen
=
halfLen
>
>
>
1
;
const
hquarterLen
=
quarterLen
>
>
>
1
;
for
(
outOff
=
0
;
outOff
<
size
;
outOff
+
=
len
)
{
for
(
let
i
=
0
k
=
0
;
i
<
=
hquarterLen
;
i
+
=
2
k
+
=
step
)
{
const
A
=
outOff
+
i
;
const
B
=
A
+
quarterLen
;
const
C
=
B
+
quarterLen
;
const
D
=
C
+
quarterLen
;
const
Ar
=
out
[
A
]
;
const
Ai
=
out
[
A
+
1
]
;
const
Br
=
out
[
B
]
;
const
Bi
=
out
[
B
+
1
]
;
const
Cr
=
out
[
C
]
;
const
Ci
=
out
[
C
+
1
]
;
const
Dr
=
out
[
D
]
;
const
Di
=
out
[
D
+
1
]
;
const
MAr
=
Ar
;
const
MAi
=
Ai
;
const
tableBr
=
table
[
k
]
;
const
tableBi
=
inv
*
table
[
k
+
1
]
;
const
MBr
=
Br
*
tableBr
-
Bi
*
tableBi
;
const
MBi
=
Br
*
tableBi
+
Bi
*
tableBr
;
const
tableCr
=
table
[
2
*
k
]
;
const
tableCi
=
inv
*
table
[
2
*
k
+
1
]
;
const
MCr
=
Cr
*
tableCr
-
Ci
*
tableCi
;
const
MCi
=
Cr
*
tableCi
+
Ci
*
tableCr
;
const
tableDr
=
table
[
3
*
k
]
;
const
tableDi
=
inv
*
table
[
3
*
k
+
1
]
;
const
MDr
=
Dr
*
tableDr
-
Di
*
tableDi
;
const
MDi
=
Dr
*
tableDi
+
Di
*
tableDr
;
const
T0r
=
MAr
+
MCr
;
const
T0i
=
MAi
+
MCi
;
const
T1r
=
MAr
-
MCr
;
const
T1i
=
MAi
-
MCi
;
const
T2r
=
MBr
+
MDr
;
const
T2i
=
MBi
+
MDi
;
const
T3r
=
inv
*
(
MBr
-
MDr
)
;
const
T3i
=
inv
*
(
MBi
-
MDi
)
;
out
[
A
]
=
T0r
+
T2r
;
out
[
A
+
1
]
=
T0i
+
T2i
;
out
[
B
]
=
T1r
+
T3i
;
out
[
B
+
1
]
=
T1i
-
T3r
;
if
(
i
=
=
=
0
)
{
out
[
C
]
=
T0r
-
T2r
;
out
[
C
+
1
]
=
T0i
-
T2i
;
continue
;
}
if
(
i
=
=
=
hquarterLen
)
continue
;
const
SA
=
outOff
+
quarterLen
-
i
;
const
SB
=
outOff
+
halfLen
-
i
;
out
[
SA
]
=
T1r
-
inv
*
T3i
;
out
[
SA
+
1
]
=
-
T1i
-
inv
*
T3r
;
out
[
SB
]
=
T0r
-
inv
*
T2r
;
out
[
SB
+
1
]
=
-
T0i
+
inv
*
T2i
;
}
}
}
const
half
=
size
>
>
>
1
;
for
(
let
i
=
2
;
i
<
half
;
i
+
=
2
)
{
out
[
size
-
i
]
=
out
[
i
]
;
out
[
size
-
i
+
1
]
=
-
out
[
i
+
1
]
;
}
}
_singleRealTransform2
(
data
out
outOff
off
step
)
{
const
evenR
=
data
[
off
]
;
const
oddR
=
data
[
off
+
step
]
;
out
[
outOff
]
=
evenR
+
oddR
;
out
[
outOff
+
1
]
=
0
;
out
[
outOff
+
2
]
=
evenR
-
oddR
;
out
[
outOff
+
3
]
=
0
;
}
_singleRealTransform4
(
data
out
outOff
off
step
inv
)
{
const
step2
=
step
*
2
;
const
step3
=
step
*
3
;
const
Ar
=
data
[
off
]
;
const
Br
=
data
[
off
+
step
]
;
const
Cr
=
data
[
off
+
step2
]
;
const
Dr
=
data
[
off
+
step3
]
;
const
T0r
=
Ar
+
Cr
;
const
T1r
=
Ar
-
Cr
;
const
T2r
=
Br
+
Dr
;
const
T3r
=
inv
*
(
Br
-
Dr
)
;
out
[
outOff
]
=
T0r
+
T2r
;
out
[
outOff
+
1
]
=
0
;
out
[
outOff
+
2
]
=
T1r
;
out
[
outOff
+
3
]
=
-
T3r
;
out
[
outOff
+
4
]
=
T0r
-
T2r
;
out
[
outOff
+
5
]
=
0
;
out
[
outOff
+
6
]
=
T1r
;
out
[
outOff
+
7
]
=
T3r
;
}
}
class
NP2FFT
{
constructor
(
fft_length
)
{
const
a
=
2
*
(
fft_length
-
1
)
;
const
b
=
2
*
(
2
*
fft_length
-
1
)
;
const
nextP2
=
2
*
*
(
Math
.
ceil
(
Math
.
log2
(
b
)
)
)
this
.
bufferSize
=
nextP2
;
this
.
_a
=
a
;
const
chirp
=
new
Float64Array
(
b
)
;
const
ichirp
=
new
Float64Array
(
nextP2
)
;
this
.
_chirpBuffer
=
new
Float64Array
(
nextP2
)
;
this
.
_buffer1
=
new
Float64Array
(
nextP2
)
;
this
.
_buffer2
=
new
Float64Array
(
nextP2
)
;
this
.
_outBuffer1
=
new
Float64Array
(
nextP2
)
;
this
.
_outBuffer2
=
new
Float64Array
(
nextP2
)
;
const
theta
=
-
2
*
Math
.
PI
/
fft_length
;
const
baseR
=
Math
.
cos
(
theta
)
;
const
baseI
=
Math
.
sin
(
theta
)
;
for
(
let
i
=
0
;
i
<
b
>
>
1
;
+
+
i
)
{
const
e
=
(
i
+
1
-
fft_length
)
*
*
2
/
2
.
0
;
const
result_mod
=
Math
.
sqrt
(
baseR
*
*
2
+
baseI
*
*
2
)
*
*
e
;
const
result_arg
=
e
*
Math
.
atan2
(
baseI
baseR
)
;
const
i2
=
2
*
i
;
chirp
[
i2
]
=
result_mod
*
Math
.
cos
(
result_arg
)
;
chirp
[
i2
+
1
]
=
result_mod
*
Math
.
sin
(
result_arg
)
;
ichirp
[
i2
]
=
chirp
[
i2
]
;
ichirp
[
i2
+
1
]
=
-
chirp
[
i2
+
1
]
;
}
this
.
_slicedChirpBuffer
=
chirp
.
subarray
(
a
b
)
;
this
.
_f
=
new
P2FFT
(
nextP2
>
>
1
)
;
this
.
_f
.
transform
(
this
.
_chirpBuffer
ichirp
)
;
}
_transform
(
output
input
real
)
{
const
ib1
=
this
.
_buffer1
;
const
ib2
=
this
.
_buffer2
;
const
ob2
=
this
.
_outBuffer1
;
const
ob3
=
this
.
_outBuffer2
;
const
cb
=
this
.
_chirpBuffer
;
const
sb
=
this
.
_slicedChirpBuffer
;
const
a
=
this
.
_a
;
if
(
real
)
{
for
(
let
j
=
0
;
j
<
sb
.
length
;
j
+
=
2
)
{
const
j2
=
j
+
1
const
j3
=
j
>
>
1
;
const
a_real
=
input
[
j3
]
;
ib1
[
j
]
=
a_real
*
sb
[
j
]
;
ib1
[
j2
]
=
a_real
*
sb
[
j2
]
;
}
}
else
{
for
(
let
j
=
0
;
j
<
sb
.
length
;
j
+
=
2
)
{
const
j2
=
j
+
1
ib1
[
j
]
=
input
[
j
]
*
sb
[
j
]
-
input
[
j2
]
*
sb
[
j2
]
;
ib1
[
j2
]
=
input
[
j
]
*
sb
[
j2
]
+
input
[
j2
]
*
sb
[
j
]
;
}
}
this
.
_f
.
transform
(
ob2
ib1
)
;
for
(
let
j
=
0
;
j
<
cb
.
length
;
j
+
=
2
)
{
const
j2
=
j
+
1
;
ib2
[
j
]
=
ob2
[
j
]
*
cb
[
j
]
-
ob2
[
j2
]
*
cb
[
j2
]
;
ib2
[
j2
]
=
ob2
[
j
]
*
cb
[
j2
]
+
ob2
[
j2
]
*
cb
[
j
]
;
}
this
.
_f
.
inverseTransform
(
ob3
ib2
)
;
for
(
let
j
=
0
;
j
<
ob3
.
length
;
j
+
=
2
)
{
const
a_real
=
ob3
[
j
+
a
]
;
const
a_imag
=
ob3
[
j
+
a
+
1
]
;
const
b_real
=
sb
[
j
]
;
const
b_imag
=
sb
[
j
+
1
]
;
output
[
j
]
=
a_real
*
b_real
-
a_imag
*
b_imag
;
output
[
j
+
1
]
=
a_real
*
b_imag
+
a_imag
*
b_real
;
}
}
transform
(
output
input
)
{
this
.
_transform
(
output
input
false
)
;
}
realTransform
(
output
input
)
{
this
.
_transform
(
output
input
true
)
;
}
}
class
FFT
{
constructor
(
fft_length
)
{
this
.
fft_length
=
fft_length
;
this
.
isPowerOfTwo
=
isPowerOfTwo
(
fft_length
)
;
if
(
this
.
isPowerOfTwo
)
{
this
.
fft
=
new
P2FFT
(
fft_length
)
;
this
.
outputBufferSize
=
2
*
fft_length
;
}
else
{
this
.
fft
=
new
NP2FFT
(
fft_length
)
;
this
.
outputBufferSize
=
this
.
fft
.
bufferSize
;
}
}
realTransform
(
out
input
)
{
this
.
fft
.
realTransform
(
out
input
)
;
}
transform
(
out
input
)
{
this
.
fft
.
transform
(
out
input
)
;
}
}
function
medianFilter
(
data
windowSize
)
{
if
(
windowSize
%
2
=
=
=
0
|
|
windowSize
<
=
0
)
{
throw
new
Error
(
'
Window
size
must
be
a
positive
odd
number
'
)
;
}
const
outputArray
=
new
data
.
constructor
(
data
.
length
)
;
const
buffer
=
new
data
.
constructor
(
windowSize
)
;
const
halfWindowSize
=
Math
.
floor
(
windowSize
/
2
)
;
for
(
let
i
=
0
;
i
<
data
.
length
;
+
+
i
)
{
let
valuesIndex
=
0
;
for
(
let
j
=
-
halfWindowSize
;
j
<
=
halfWindowSize
;
+
+
j
)
{
let
index
=
i
+
j
;
if
(
index
<
0
)
{
index
=
Math
.
abs
(
index
)
;
}
else
if
(
index
>
=
data
.
length
)
{
index
=
2
*
(
data
.
length
-
1
)
-
index
;
}
buffer
[
valuesIndex
+
+
]
=
data
[
index
]
;
}
buffer
.
sort
(
)
;
outputArray
[
i
]
=
buffer
[
halfWindowSize
]
;
}
return
outputArray
;
}
function
round
(
num
decimals
)
{
const
pow
=
Math
.
pow
(
10
decimals
)
;
return
Math
.
round
(
num
*
pow
)
/
pow
;
}
function
bankers_round
(
x
)
{
const
r
=
Math
.
round
(
x
)
;
const
br
=
Math
.
abs
(
x
)
%
1
=
=
=
0
.
5
?
(
r
%
2
=
=
=
0
?
r
:
r
-
1
)
:
r
;
return
br
;
}
function
dynamic_time_warping
(
matrix
)
{
const
output_length
=
matrix
.
length
;
const
input_length
=
matrix
[
0
]
.
length
;
const
outputShape
=
[
output_length
+
1
input_length
+
1
]
;
const
cost
=
Array
.
from
(
{
length
:
outputShape
[
0
]
}
(
)
=
>
Array
(
outputShape
[
1
]
)
.
fill
(
Infinity
)
)
;
cost
[
0
]
[
0
]
=
0
;
const
trace
=
Array
.
from
(
{
length
:
outputShape
[
0
]
}
(
)
=
>
Array
(
outputShape
[
1
]
)
.
fill
(
-
1
)
)
;
for
(
let
j
=
1
;
j
<
outputShape
[
1
]
;
+
+
j
)
{
for
(
let
i
=
1
;
i
<
outputShape
[
0
]
;
+
+
i
)
{
const
c0
=
cost
[
i
-
1
]
[
j
-
1
]
;
const
c1
=
cost
[
i
-
1
]
[
j
]
;
const
c2
=
cost
[
i
]
[
j
-
1
]
;
let
c
t
;
if
(
c0
<
c1
&
&
c0
<
c2
)
{
c
=
c0
;
t
=
0
;
}
else
if
(
c1
<
c0
&
&
c1
<
c2
)
{
c
=
c1
;
t
=
1
;
}
else
{
c
=
c2
;
t
=
2
;
}
cost
[
i
]
[
j
]
=
matrix
[
i
-
1
]
[
j
-
1
]
+
c
;
trace
[
i
]
[
j
]
=
t
;
}
}
for
(
let
i
=
0
;
i
<
outputShape
[
1
]
;
+
+
i
)
{
trace
[
0
]
[
i
]
=
2
;
}
for
(
let
i
=
0
;
i
<
outputShape
[
0
]
;
+
+
i
)
{
trace
[
i
]
[
0
]
=
1
;
}
let
i
=
output_length
;
let
j
=
input_length
;
let
text_indices
=
[
]
;
let
time_indices
=
[
]
;
while
(
i
>
0
|
|
j
>
0
)
{
text_indices
.
push
(
i
-
1
)
;
time_indices
.
push
(
j
-
1
)
;
switch
(
trace
[
i
]
[
j
]
)
{
case
0
:
-
-
i
;
-
-
j
;
break
;
case
1
:
-
-
i
;
break
;
case
2
:
-
-
j
;
break
;
default
:
throw
new
Error
(
Internal
error
in
dynamic
time
warping
.
Unexpected
trace
[
{
i
}
{
j
}
]
.
Please
file
a
bug
report
.
)
}
}
text_indices
.
reverse
(
)
;
time_indices
.
reverse
(
)
;
return
[
text_indices
time_indices
]
;
}
}
)
"
.
/
src
/
utils
/
tensor
.
js
"
:
(
(
__unused_webpack___webpack_module__
__webpack_exports__
__webpack_require__
)
=
>
{
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
Tensor
:
(
)
=
>
(
Tensor
)
cat
:
(
)
=
>
(
cat
)
full
:
(
)
=
>
(
full
)
full_like
:
(
)
=
>
(
full_like
)
interpolate
:
(
)
=
>
(
interpolate
)
interpolate_4d
:
(
)
=
>
(
interpolate_4d
)
layer_norm
:
(
)
=
>
(
layer_norm
)
matmul
:
(
)
=
>
(
matmul
)
mean
:
(
)
=
>
(
mean
)
mean_pooling
:
(
)
=
>
(
mean_pooling
)
ones
:
(
)
=
>
(
ones
)
ones_like
:
(
)
=
>
(
ones_like
)
permute
:
(
)
=
>
(
permute
)
quantize_embeddings
:
(
)
=
>
(
quantize_embeddings
)
rfft
:
(
)
=
>
(
rfft
)
stack
:
(
)
=
>
(
stack
)
std_mean
:
(
)
=
>
(
std_mean
)
topk
:
(
)
=
>
(
topk
)
zeros
:
(
)
=
>
(
zeros
)
zeros_like
:
(
)
=
>
(
zeros_like
)
}
)
;
var
_maths_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
src
/
utils
/
maths
.
js
"
)
;
var
_backends_onnx_js__WEBPACK_IMPORTED_MODULE_1__
=
__webpack_require__
(
"
.
/
src
/
backends
/
onnx
.
js
"
)
;
var
_ops_registry_js__WEBPACK_IMPORTED_MODULE_2__
=
__webpack_require__
(
"
.
/
src
/
ops
/
registry
.
js
"
)
;
const
DataTypeMap
=
Object
.
freeze
(
{
float32
:
Float32Array
float16
:
Uint16Array
float64
:
Float64Array
string
:
Array
int8
:
Int8Array
uint8
:
Uint8Array
int16
:
Int16Array
uint16
:
Uint16Array
int32
:
Int32Array
uint32
:
Uint32Array
int64
:
BigInt64Array
uint64
:
BigUint64Array
bool
:
Uint8Array
}
)
;
class
Tensor
{
get
dims
(
)
{
return
this
.
ort_tensor
.
dims
;
}
set
dims
(
value
)
{
this
.
ort_tensor
.
dims
=
value
;
}
get
type
(
)
{
return
this
.
ort_tensor
.
type
;
}
;
get
data
(
)
{
return
this
.
ort_tensor
.
data
;
}
get
size
(
)
{
return
this
.
ort_tensor
.
size
;
}
;
get
location
(
)
{
return
this
.
ort_tensor
.
location
;
}
;
ort_tensor
;
constructor
(
.
.
.
args
)
{
if
(
(
0
_backends_onnx_js__WEBPACK_IMPORTED_MODULE_1__
.
isONNXTensor
)
(
args
[
0
]
)
)
{
this
.
ort_tensor
=
(
args
[
0
]
)
;
}
else
{
this
.
ort_tensor
=
new
_backends_onnx_js__WEBPACK_IMPORTED_MODULE_1__
.
Tensor
(
(
args
[
0
]
)
(
args
[
1
]
)
args
[
2
]
)
;
}
return
new
Proxy
(
this
{
get
:
(
obj
key
)
=
>
{
if
(
typeof
key
=
=
=
'
string
'
)
{
let
index
=
Number
(
key
)
;
if
(
Number
.
isInteger
(
index
)
)
{
return
obj
.
_getitem
(
index
)
;
}
}
return
obj
[
key
]
;
}
set
:
(
obj
key
value
)
=
>
{
return
obj
[
key
]
=
value
;
}
}
)
;
}
dispose
(
)
{
this
.
ort_tensor
.
dispose
(
)
;
}
*
[
Symbol
.
iterator
]
(
)
{
const
[
iterLength
.
.
.
iterDims
]
=
this
.
dims
;
if
(
iterDims
.
length
>
0
)
{
const
iterSize
=
iterDims
.
reduce
(
(
a
b
)
=
>
a
*
b
)
;
for
(
let
i
=
0
;
i
<
iterLength
;
+
+
i
)
{
yield
this
.
_subarray
(
i
iterSize
iterDims
)
;
}
}
else
{
yield
*
this
.
data
}
}
_getitem
(
index
)
{
const
[
iterLength
.
.
.
iterDims
]
=
this
.
dims
;
index
=
safeIndex
(
index
iterLength
)
;
if
(
iterDims
.
length
>
0
)
{
const
iterSize
=
iterDims
.
reduce
(
(
a
b
)
=
>
a
*
b
)
;
return
this
.
_subarray
(
index
iterSize
iterDims
)
;
}
else
{
return
new
Tensor
(
this
.
type
[
this
.
data
[
index
]
]
iterDims
)
;
}
}
indexOf
(
item
)
{
const
this_data
=
this
.
data
;
for
(
let
index
=
0
;
index
<
this_data
.
length
;
+
+
index
)
{
if
(
this_data
[
index
]
=
=
item
)
{
return
index
;
}
}
return
-
1
;
}
_subarray
(
index
iterSize
iterDims
)
{
const
o1
=
index
*
iterSize
;
const
o2
=
(
index
+
1
)
*
iterSize
;
const
data
=
(
'
subarray
'
in
this
.
data
)
?
this
.
data
.
subarray
(
o1
o2
)
:
this
.
data
.
slice
(
o1
o2
)
;
return
new
Tensor
(
this
.
type
data
iterDims
)
;
}
item
(
)
{
const
this_data
=
this
.
data
;
if
(
this_data
.
length
!
=
=
1
)
{
throw
new
Error
(
a
Tensor
with
{
this_data
.
length
}
elements
cannot
be
converted
to
Scalar
)
;
}
return
this_data
[
0
]
;
}
tolist
(
)
{
return
reshape
(
this
.
data
this
.
dims
)
}
sigmoid
(
)
{
return
this
.
clone
(
)
.
sigmoid_
(
)
;
}
sigmoid_
(
)
{
const
this_data
=
this
.
data
;
for
(
let
i
=
0
;
i
<
this_data
.
length
;
+
+
i
)
{
this_data
[
i
]
=
1
/
(
1
+
Math
.
exp
(
-
this_data
[
i
]
)
)
;
}
return
this
;
}
map
(
callback
)
{
return
this
.
clone
(
)
.
map_
(
callback
)
;
}
map_
(
callback
)
{
const
this_data
=
this
.
data
;
for
(
let
i
=
0
;
i
<
this_data
.
length
;
+
+
i
)
{
this_data
[
i
]
=
callback
(
this_data
[
i
]
i
this_data
)
;
}
return
this
;
}
mul
(
val
)
{
return
this
.
clone
(
)
.
mul_
(
val
)
;
}
mul_
(
val
)
{
const
this_data
=
this
.
data
;
for
(
let
i
=
0
;
i
<
this_data
.
length
;
+
+
i
)
{
this_data
[
i
]
*
=
val
;
}
return
this
;
}
div
(
val
)
{
return
this
.
clone
(
)
.
div_
(
val
)
;
}
div_
(
val
)
{
const
this_data
=
this
.
data
;
for
(
let
i
=
0
;
i
<
this_data
.
length
;
+
+
i
)
{
this_data
[
i
]
/
=
val
;
}
return
this
;
}
add
(
val
)
{
return
this
.
clone
(
)
.
add_
(
val
)
;
}
add_
(
val
)
{
const
this_data
=
this
.
data
;
for
(
let
i
=
0
;
i
<
this_data
.
length
;
+
+
i
)
{
this_data
[
i
]
+
=
val
;
}
return
this
;
}
sub
(
val
)
{
return
this
.
clone
(
)
.
sub_
(
val
)
;
}
sub_
(
val
)
{
const
this_data
=
this
.
data
;
for
(
let
i
=
0
;
i
<
this_data
.
length
;
+
+
i
)
{
this_data
[
i
]
-
=
val
;
}
return
this
;
}
clone
(
)
{
return
new
Tensor
(
this
.
type
this
.
data
.
slice
(
)
this
.
dims
.
slice
(
)
)
;
}
slice
(
.
.
.
slices
)
{
const
newTensorDims
=
[
]
;
const
newOffsets
=
[
]
;
for
(
let
sliceIndex
=
0
;
sliceIndex
<
this
.
dims
.
length
;
+
+
sliceIndex
)
{
let
slice
=
slices
[
sliceIndex
]
;
if
(
slice
=
=
=
null
|
|
slice
=
=
=
undefined
)
{
newOffsets
.
push
(
[
0
this
.
dims
[
sliceIndex
]
]
)
;
newTensorDims
.
push
(
this
.
dims
[
sliceIndex
]
)
;
}
else
if
(
typeof
slice
=
=
=
'
number
'
)
{
slice
=
safeIndex
(
slice
this
.
dims
[
sliceIndex
]
sliceIndex
)
;
newOffsets
.
push
(
[
slice
slice
+
1
]
)
;
}
else
if
(
Array
.
isArray
(
slice
)
&
&
slice
.
length
=
=
=
2
)
{
let
[
start
end
]
=
slice
;
start
=
start
=
=
=
null
?
0
:
safeIndex
(
start
this
.
dims
[
sliceIndex
]
sliceIndex
false
)
;
end
=
end
=
=
=
null
?
this
.
dims
[
sliceIndex
]
:
safeIndex
(
end
this
.
dims
[
sliceIndex
]
sliceIndex
false
)
;
if
(
start
>
end
)
{
throw
new
Error
(
Invalid
slice
:
{
slice
}
)
;
}
const
offsets
=
[
Math
.
max
(
start
0
)
Math
.
min
(
end
this
.
dims
[
sliceIndex
]
)
]
;
newOffsets
.
push
(
offsets
)
;
newTensorDims
.
push
(
offsets
[
1
]
-
offsets
[
0
]
)
;
}
else
{
throw
new
Error
(
Invalid
slice
:
{
slice
}
)
;
}
}
const
newDims
=
newOffsets
.
map
(
(
[
start
end
]
)
=
>
end
-
start
)
;
const
newBufferSize
=
newDims
.
reduce
(
(
a
b
)
=
>
a
*
b
)
;
const
this_data
=
this
.
data
;
const
data
=
new
this_data
.
constructor
(
newBufferSize
)
;
const
stride
=
this
.
stride
(
)
;
for
(
let
i
=
0
;
i
<
newBufferSize
;
+
+
i
)
{
let
originalIndex
=
0
;
for
(
let
j
=
newDims
.
length
-
1
num
=
i
;
j
>
=
0
;
-
-
j
)
{
const
size
=
newDims
[
j
]
;
originalIndex
+
=
(
(
num
%
size
)
+
newOffsets
[
j
]
[
0
]
)
*
stride
[
j
]
;
num
=
Math
.
floor
(
num
/
size
)
;
}
data
[
i
]
=
this_data
[
originalIndex
]
;
}
return
new
Tensor
(
this
.
type
data
newTensorDims
)
;
}
permute
(
.
.
.
dims
)
{
return
permute
(
this
dims
)
;
}
transpose
(
.
.
.
dims
)
{
return
this
.
permute
(
.
.
.
dims
)
;
}
sum
(
dim
=
null
keepdim
=
false
)
{
return
this
.
norm
(
1
dim
keepdim
)
;
}
norm
(
p
=
'
fro
'
dim
=
null
keepdim
=
false
)
{
if
(
p
=
=
=
'
fro
'
)
{
p
=
2
;
}
else
if
(
typeof
p
=
=
=
'
string
'
)
{
throw
Error
(
Unsupported
norm
:
{
p
}
)
;
}
const
this_data
=
this
.
data
;
if
(
dim
=
=
=
null
)
{
let
val
=
this_data
.
reduce
(
(
a
b
)
=
>
a
+
(
b
*
*
p
)
0
)
*
*
(
1
/
p
)
;
return
new
Tensor
(
this
.
type
[
val
]
[
]
)
;
}
dim
=
safeIndex
(
dim
this
.
dims
.
length
)
;
const
resultDims
=
this
.
dims
.
slice
(
)
;
resultDims
[
dim
]
=
1
;
const
result
=
new
this_data
.
constructor
(
this_data
.
length
/
this
.
dims
[
dim
]
)
;
for
(
let
i
=
0
;
i
<
this_data
.
length
;
+
+
i
)
{
let
resultIndex
=
0
;
for
(
let
j
=
this
.
dims
.
length
-
1
num
=
i
resultMultiplier
=
1
;
j
>
=
0
;
-
-
j
)
{
const
size
=
this
.
dims
[
j
]
;
if
(
j
!
=
=
dim
)
{
const
index
=
num
%
size
;
resultIndex
+
=
index
*
resultMultiplier
;
resultMultiplier
*
=
resultDims
[
j
]
;
}
num
=
Math
.
floor
(
num
/
size
)
;
}
result
[
resultIndex
]
+
=
(
this_data
[
i
]
)
*
*
p
;
}
if
(
p
!
=
=
1
)
{
for
(
let
i
=
0
;
i
<
result
.
length
;
+
+
i
)
{
result
[
i
]
=
result
[
i
]
*
*
(
1
/
p
)
;
}
}
if
(
!
keepdim
)
{
resultDims
.
splice
(
dim
1
)
;
}
return
new
Tensor
(
this
.
type
result
resultDims
)
;
}
normalize_
(
p
=
2
.
0
dim
=
1
)
{
dim
=
safeIndex
(
dim
this
.
dims
.
length
)
;
const
norm
=
this
.
norm
(
p
dim
true
)
;
const
this_data
=
this
.
data
;
const
norm_data
=
norm
.
data
;
for
(
let
i
=
0
;
i
<
this_data
.
length
;
+
+
i
)
{
let
resultIndex
=
0
;
for
(
let
j
=
this
.
dims
.
length
-
1
num
=
i
resultMultiplier
=
1
;
j
>
=
0
;
-
-
j
)
{
const
size
=
this
.
dims
[
j
]
;
if
(
j
!
=
=
dim
)
{
const
index
=
num
%
size
;
resultIndex
+
=
index
*
resultMultiplier
;
resultMultiplier
*
=
this
.
dims
[
j
]
;
}
num
=
Math
.
floor
(
num
/
size
)
;
}
this_data
[
i
]
/
=
norm_data
[
resultIndex
]
;
}
return
this
;
}
normalize
(
p
=
2
.
0
dim
=
1
)
{
return
this
.
clone
(
)
.
normalize_
(
p
dim
)
;
}
stride
(
)
{
return
dimsToStride
(
this
.
dims
)
;
}
squeeze
(
dim
=
null
)
{
return
new
Tensor
(
this
.
type
this
.
data
calc_squeeze_dims
(
this
.
dims
dim
)
)
}
squeeze_
(
dim
=
null
)
{
this
.
dims
=
calc_squeeze_dims
(
this
.
dims
dim
)
;
return
this
;
}
unsqueeze
(
dim
=
null
)
{
return
new
Tensor
(
this
.
type
this
.
data
calc_unsqueeze_dims
(
this
.
dims
dim
)
)
;
}
unsqueeze_
(
dim
=
null
)
{
this
.
dims
=
calc_unsqueeze_dims
(
this
.
dims
dim
)
;
return
this
;
}
flatten_
(
start_dim
=
0
end_dim
=
-
1
)
{
end_dim
=
(
end_dim
+
this
.
dims
.
length
)
%
this
.
dims
.
length
;
let
dimsToKeepBefore
=
this
.
dims
.
slice
(
0
start_dim
)
;
let
dimsToFlatten
=
this
.
dims
.
slice
(
start_dim
end_dim
+
1
)
;
let
dimsToKeepAfter
=
this
.
dims
.
slice
(
end_dim
+
1
)
;
this
.
dims
=
[
.
.
.
dimsToKeepBefore
dimsToFlatten
.
reduce
(
(
a
b
)
=
>
a
*
b
1
)
.
.
.
dimsToKeepAfter
]
return
this
;
}
flatten
(
start_dim
=
0
end_dim
=
-
1
)
{
return
this
.
clone
(
)
.
flatten_
(
start_dim
end_dim
)
;
}
view
(
.
.
.
dims
)
{
let
inferredIndex
=
-
1
;
for
(
let
i
=
0
;
i
<
dims
.
length
;
+
+
i
)
{
if
(
dims
[
i
]
=
=
=
-
1
)
{
if
(
inferredIndex
!
=
=
-
1
)
{
throw
new
Error
(
"
Only
one
dimension
can
be
inferred
"
)
;
}
inferredIndex
=
i
;
}
}
const
this_data
=
this
.
data
;
if
(
inferredIndex
!
=
=
-
1
)
{
const
productOther
=
dims
.
reduce
(
(
product
curr
index
)
=
>
{
return
index
!
=
=
inferredIndex
?
product
*
curr
:
product
}
1
)
;
dims
[
inferredIndex
]
=
this_data
.
length
/
productOther
;
}
return
new
Tensor
(
this
.
type
this_data
dims
)
;
}
neg_
(
)
{
const
this_data
=
this
.
data
;
for
(
let
i
=
0
;
i
<
this_data
.
length
;
+
+
i
)
{
this_data
[
i
]
=
-
this_data
[
i
]
;
}
return
this
;
}
neg
(
)
{
return
this
.
clone
(
)
.
neg_
(
)
;
}
clamp_
(
min
max
)
{
const
this_data
=
this
.
data
;
for
(
let
i
=
0
;
i
<
this_data
.
length
;
+
+
i
)
{
this_data
[
i
]
=
Math
.
min
(
Math
.
max
(
this_data
[
i
]
min
)
max
)
;
}
return
this
;
}
clamp
(
min
max
)
{
return
this
.
clone
(
)
.
clamp_
(
min
max
)
;
}
round_
(
)
{
const
this_data
=
this
.
data
;
for
(
let
i
=
0
;
i
<
this_data
.
length
;
+
+
i
)
{
this_data
[
i
]
=
Math
.
round
(
this_data
[
i
]
)
;
}
return
this
;
}
round
(
)
{
return
this
.
clone
(
)
.
round_
(
)
;
}
mean
(
dim
=
null
keepdim
=
false
)
{
return
mean
(
this
dim
keepdim
)
;
}
to
(
type
)
{
if
(
this
.
type
=
=
=
type
)
return
this
;
if
(
!
DataTypeMap
.
hasOwnProperty
(
type
)
)
{
throw
new
Error
(
Unsupported
type
:
{
type
}
)
;
}
return
new
Tensor
(
type
DataTypeMap
[
type
]
.
from
(
this
.
data
)
this
.
dims
)
;
}
}
function
reshape
(
data
dimensions
)
{
const
totalElements
=
data
.
length
;
const
dimensionSize
=
dimensions
.
reduce
(
(
a
b
)
=
>
a
*
b
)
;
if
(
totalElements
!
=
=
dimensionSize
)
{
throw
Error
(
cannot
reshape
array
of
size
{
totalElements
}
into
shape
(
{
dimensions
}
)
)
;
}
let
reshapedArray
=
data
;
for
(
let
i
=
dimensions
.
length
-
1
;
i
>
=
0
;
i
-
-
)
{
reshapedArray
=
reshapedArray
.
reduce
(
(
acc
val
)
=
>
{
let
lastArray
=
acc
[
acc
.
length
-
1
]
;
if
(
lastArray
.
length
<
dimensions
[
i
]
)
{
lastArray
.
push
(
val
)
;
}
else
{
acc
.
push
(
[
val
]
)
;
}
return
acc
;
}
[
[
]
]
)
;
}
return
reshapedArray
[
0
]
;
}
function
permute
(
tensor
axes
)
{
const
[
permutedData
shape
]
=
(
0
_maths_js__WEBPACK_IMPORTED_MODULE_0__
.
permute_data
)
(
tensor
.
data
tensor
.
dims
axes
)
;
return
new
Tensor
(
tensor
.
type
permutedData
shape
)
;
}
function
interpolate
(
input
[
out_height
out_width
]
mode
=
'
bilinear
'
align_corners
=
false
)
{
const
in_channels
=
input
.
dims
.
at
(
-
3
)
?
?
1
;
const
in_height
=
input
.
dims
.
at
(
-
2
)
;
const
in_width
=
input
.
dims
.
at
(
-
1
)
;
let
output
=
(
0
_maths_js__WEBPACK_IMPORTED_MODULE_0__
.
interpolate_data
)
(
(
input
.
data
)
[
in_channels
in_height
in_width
]
[
out_height
out_width
]
mode
align_corners
)
;
return
new
Tensor
(
input
.
type
output
[
in_channels
out_height
out_width
]
)
;
}
async
function
interpolate_4d
(
input
{
size
=
null
mode
=
'
bilinear
'
}
=
{
}
)
{
if
(
input
.
dims
.
length
!
=
=
4
)
{
throw
new
Error
(
'
interpolate_4d
currently
only
supports
4D
input
.
'
)
;
}
if
(
!
size
)
{
throw
new
Error
(
'
interpolate_4d
requires
a
size
argument
.
'
)
;
}
let
targetDims
;
if
(
size
.
length
=
=
=
2
)
{
targetDims
=
[
.
.
.
input
.
dims
.
slice
(
0
2
)
.
.
.
size
]
;
}
else
if
(
size
.
length
=
=
=
3
)
{
targetDims
=
[
input
.
dims
[
0
]
.
.
.
size
]
;
}
else
if
(
size
.
length
=
=
=
4
)
{
targetDims
=
size
;
}
else
{
throw
new
Error
(
'
size
must
be
of
length
2
3
or
4
.
'
)
;
}
let
op
;
if
(
mode
=
=
=
'
bilinear
'
)
{
op
=
await
_ops_registry_js__WEBPACK_IMPORTED_MODULE_2__
.
TensorOpRegistry
.
bilinear_interpolate_4d
;
}
else
if
(
mode
=
=
=
'
bicubic
'
)
{
op
=
await
_ops_registry_js__WEBPACK_IMPORTED_MODULE_2__
.
TensorOpRegistry
.
bicubic_interpolate_4d
;
}
else
{
throw
new
Error
(
Unsupported
mode
:
{
mode
}
)
;
}
const
sizeTensor
=
new
Tensor
(
'
int64
'
new
BigInt64Array
(
targetDims
.
map
(
BigInt
)
)
[
targetDims
.
length
]
)
;
return
await
op
(
{
x
:
input
s
:
sizeTensor
}
)
;
}
async
function
matmul
(
a
b
)
{
const
op
=
await
_ops_registry_js__WEBPACK_IMPORTED_MODULE_2__
.
TensorOpRegistry
.
matmul
;
return
await
op
(
{
a
b
}
)
;
}
async
function
rfft
(
x
a
)
{
const
op
=
await
_ops_registry_js__WEBPACK_IMPORTED_MODULE_2__
.
TensorOpRegistry
.
rfft
;
return
await
op
(
{
x
a
}
)
;
}
async
function
topk
(
x
k
)
{
const
op
=
await
_ops_registry_js__WEBPACK_IMPORTED_MODULE_2__
.
TensorOpRegistry
.
top_k
;
if
(
k
=
=
=
null
)
{
k
=
x
.
dims
.
at
(
-
1
)
;
}
else
{
k
=
Math
.
min
(
k
x
.
dims
.
at
(
-
1
)
)
;
}
return
await
op
(
{
x
k
:
new
Tensor
(
'
int64
'
[
BigInt
(
k
)
]
[
1
]
)
}
)
;
}
function
mean_pooling
(
last_hidden_state
attention_mask
)
{
const
lastHiddenStateData
=
last_hidden_state
.
data
;
const
attentionMaskData
=
attention_mask
.
data
;
const
shape
=
[
last_hidden_state
.
dims
[
0
]
last_hidden_state
.
dims
[
2
]
]
;
const
returnedData
=
new
lastHiddenStateData
.
constructor
(
shape
[
0
]
*
shape
[
1
]
)
;
const
[
batchSize
seqLength
embedDim
]
=
last_hidden_state
.
dims
;
let
outIndex
=
0
;
for
(
let
i
=
0
;
i
<
batchSize
;
+
+
i
)
{
const
offset
=
i
*
embedDim
*
seqLength
;
for
(
let
k
=
0
;
k
<
embedDim
;
+
+
k
)
{
let
sum
=
0
;
let
count
=
0
;
const
attnMaskOffset
=
i
*
seqLength
;
const
offset2
=
offset
+
k
;
for
(
let
j
=
0
;
j
<
seqLength
;
+
+
j
)
{
const
attn
=
Number
(
attentionMaskData
[
attnMaskOffset
+
j
]
)
;
count
+
=
attn
;
sum
+
=
lastHiddenStateData
[
offset2
+
j
*
embedDim
]
*
attn
;
}
const
avg
=
sum
/
count
;
returnedData
[
outIndex
+
+
]
=
avg
;
}
}
return
new
Tensor
(
last_hidden_state
.
type
returnedData
shape
)
}
function
layer_norm
(
input
normalized_shape
{
eps
=
1e
-
5
}
=
{
}
)
{
if
(
input
.
dims
.
length
!
=
=
2
)
{
throw
new
Error
(
'
layer_norm
currently
only
supports
2D
input
.
'
)
;
}
const
[
batchSize
featureDim
]
=
input
.
dims
;
if
(
normalized_shape
.
length
!
=
=
1
&
&
normalized_shape
[
0
]
!
=
=
featureDim
)
{
throw
new
Error
(
'
normalized_shape
must
be
a
1D
array
with
shape
[
input
.
dims
[
1
]
]
.
'
)
;
}
const
[
std
mean
]
=
std_mean
(
input
1
0
true
)
;
const
stdData
=
(
std
.
data
)
;
const
meanData
=
(
mean
.
data
)
;
const
inputData
=
(
input
.
data
)
;
const
returnedData
=
new
inputData
.
constructor
(
inputData
.
length
)
;
for
(
let
i
=
0
;
i
<
batchSize
;
+
+
i
)
{
const
offset
=
i
*
featureDim
;
for
(
let
j
=
0
;
j
<
featureDim
;
+
+
j
)
{
const
offset2
=
offset
+
j
;
returnedData
[
offset2
]
=
(
inputData
[
offset2
]
-
meanData
[
i
]
)
/
(
stdData
[
i
]
+
eps
)
;
}
}
return
new
Tensor
(
input
.
type
returnedData
input
.
dims
)
;
}
function
calc_squeeze_dims
(
dims
dim
)
{
dims
=
dims
.
slice
(
)
;
if
(
dim
=
=
=
null
)
{
dims
=
dims
.
filter
(
(
d
)
=
>
d
!
=
=
1
)
;
}
else
if
(
typeof
dim
=
=
=
'
number
'
)
{
if
(
dims
[
dim
]
=
=
=
1
)
{
dims
.
splice
(
dim
1
)
;
}
}
else
if
(
Array
.
isArray
(
dim
)
)
{
dims
=
dims
.
filter
(
(
x
i
)
=
>
{
return
x
!
=
=
1
|
|
!
dim
.
includes
(
i
)
;
}
)
;
}
return
dims
;
}
function
calc_unsqueeze_dims
(
dims
dim
)
{
dim
=
safeIndex
(
dim
dims
.
length
+
1
)
;
dims
=
dims
.
slice
(
)
;
dims
.
splice
(
dim
0
1
)
;
return
dims
;
}
function
safeIndex
(
index
size
dimension
=
null
boundsCheck
=
true
)
{
if
(
boundsCheck
&
&
(
index
<
-
size
|
|
index
>
=
size
)
)
{
throw
new
Error
(
IndexError
:
index
{
index
}
is
out
of
bounds
for
dimension
{
dimension
=
=
=
null
?
'
'
:
'
'
+
dimension
}
with
size
{
size
}
)
;
}
if
(
index
<
0
)
{
index
=
(
(
index
%
size
)
+
size
)
%
size
;
}
return
index
;
}
function
cat
(
tensors
dim
=
0
)
{
dim
=
safeIndex
(
dim
tensors
[
0
]
.
dims
.
length
)
;
const
resultDims
=
tensors
[
0
]
.
dims
.
slice
(
)
;
resultDims
[
dim
]
=
tensors
.
reduce
(
(
a
b
)
=
>
a
+
b
.
dims
[
dim
]
0
)
;
const
resultSize
=
resultDims
.
reduce
(
(
a
b
)
=
>
a
*
b
1
)
;
const
result
=
new
tensors
[
0
]
.
data
.
constructor
(
resultSize
)
;
const
resultType
=
tensors
[
0
]
.
type
;
if
(
dim
=
=
=
0
)
{
let
offset
=
0
;
for
(
const
tensor
of
tensors
)
{
const
tensorData
=
tensor
.
data
;
result
.
set
(
tensorData
offset
)
;
offset
+
=
tensorData
.
length
;
}
}
else
{
let
currentDim
=
0
;
for
(
let
t
=
0
;
t
<
tensors
.
length
;
+
+
t
)
{
const
{
data
dims
}
=
tensors
[
t
]
;
for
(
let
i
=
0
;
i
<
data
.
length
;
+
+
i
)
{
let
resultIndex
=
0
;
for
(
let
j
=
dims
.
length
-
1
num
=
i
resultMultiplier
=
1
;
j
>
=
0
;
-
-
j
)
{
const
size
=
dims
[
j
]
;
let
index
=
num
%
size
;
if
(
j
=
=
=
dim
)
{
index
+
=
currentDim
;
}
resultIndex
+
=
index
*
resultMultiplier
;
resultMultiplier
*
=
resultDims
[
j
]
;
num
=
Math
.
floor
(
num
/
size
)
;
}
result
[
resultIndex
]
=
data
[
i
]
;
}
currentDim
+
=
dims
[
dim
]
;
}
}
return
new
Tensor
(
resultType
result
resultDims
)
;
}
function
stack
(
tensors
dim
=
0
)
{
return
cat
(
tensors
.
map
(
t
=
>
t
.
unsqueeze
(
dim
)
)
dim
)
;
}
function
std_mean
(
input
dim
=
null
correction
=
1
keepdim
=
false
)
{
const
inputData
=
(
input
.
data
)
;
const
inputDims
=
input
.
dims
;
if
(
dim
=
=
=
null
)
{
const
sum
=
inputData
.
reduce
(
(
a
b
)
=
>
a
+
b
0
)
;
const
mean
=
sum
/
inputData
.
length
;
const
std
=
Math
.
sqrt
(
inputData
.
reduce
(
(
a
b
)
=
>
a
+
(
b
-
mean
)
*
*
2
0
)
/
(
inputData
.
length
-
correction
)
)
;
const
meanTensor
=
new
Tensor
(
input
.
type
[
mean
]
[
]
)
;
const
stdTensor
=
new
Tensor
(
input
.
type
[
std
]
[
]
)
;
return
[
stdTensor
meanTensor
]
;
}
dim
=
safeIndex
(
dim
inputDims
.
length
)
;
const
meanTensor
=
mean
(
input
dim
keepdim
)
;
const
meanTensorData
=
meanTensor
.
data
;
const
resultDims
=
inputDims
.
slice
(
)
;
resultDims
[
dim
]
=
1
;
const
result
=
new
inputData
.
constructor
(
inputData
.
length
/
inputDims
[
dim
]
)
;
for
(
let
i
=
0
;
i
<
inputData
.
length
;
+
+
i
)
{
let
resultIndex
=
0
;
for
(
let
j
=
inputDims
.
length
-
1
num
=
i
resultMultiplier
=
1
;
j
>
=
0
;
-
-
j
)
{
const
size
=
inputDims
[
j
]
;
if
(
j
!
=
=
dim
)
{
const
index
=
num
%
size
;
resultIndex
+
=
index
*
resultMultiplier
;
resultMultiplier
*
=
resultDims
[
j
]
;
}
num
=
Math
.
floor
(
num
/
size
)
;
}
result
[
resultIndex
]
+
=
(
inputData
[
i
]
-
meanTensorData
[
resultIndex
]
)
*
*
2
;
}
for
(
let
i
=
0
;
i
<
result
.
length
;
+
+
i
)
{
result
[
i
]
=
Math
.
sqrt
(
result
[
i
]
/
(
inputDims
[
dim
]
-
correction
)
)
;
}
if
(
!
keepdim
)
{
resultDims
.
splice
(
dim
1
)
;
}
const
stdTensor
=
new
Tensor
(
input
.
type
result
resultDims
)
;
return
[
stdTensor
meanTensor
]
;
}
function
mean
(
input
dim
=
null
keepdim
=
false
)
{
const
inputData
=
(
input
.
data
)
;
if
(
dim
=
=
=
null
)
{
const
val
=
inputData
.
reduce
(
(
a
b
)
=
>
a
+
b
0
)
;
return
new
Tensor
(
input
.
type
[
val
/
inputData
.
length
]
[
]
)
;
}
const
inputDims
=
input
.
dims
;
dim
=
safeIndex
(
dim
inputDims
.
length
)
;
const
resultDims
=
inputDims
.
slice
(
)
;
resultDims
[
dim
]
=
1
;
const
result
=
new
inputData
.
constructor
(
inputData
.
length
/
inputDims
[
dim
]
)
;
for
(
let
i
=
0
;
i
<
inputData
.
length
;
+
+
i
)
{
let
resultIndex
=
0
;
for
(
let
j
=
inputDims
.
length
-
1
num
=
i
resultMultiplier
=
1
;
j
>
=
0
;
-
-
j
)
{
const
size
=
inputDims
[
j
]
;
if
(
j
!
=
=
dim
)
{
const
index
=
num
%
size
;
resultIndex
+
=
index
*
resultMultiplier
;
resultMultiplier
*
=
resultDims
[
j
]
;
}
num
=
Math
.
floor
(
num
/
size
)
;
}
result
[
resultIndex
]
+
=
inputData
[
i
]
;
}
if
(
inputDims
[
dim
]
!
=
=
1
)
{
for
(
let
i
=
0
;
i
<
result
.
length
;
+
+
i
)
{
result
[
i
]
=
result
[
i
]
/
inputDims
[
dim
]
;
}
}
if
(
!
keepdim
)
{
resultDims
.
splice
(
dim
1
)
;
}
return
new
Tensor
(
input
.
type
result
resultDims
)
;
}
function
dimsToStride
(
dims
)
{
const
stride
=
new
Array
(
dims
.
length
)
;
for
(
let
i
=
dims
.
length
-
1
s2
=
1
;
i
>
=
0
;
-
-
i
)
{
stride
[
i
]
=
s2
;
s2
*
=
dims
[
i
]
;
}
return
stride
;
}
function
fullHelper
(
size
fill_value
dtype
cls
)
{
const
numElements
=
size
.
reduce
(
(
a
b
)
=
>
a
*
b
1
)
;
return
new
Tensor
(
dtype
new
cls
(
numElements
)
.
fill
(
fill_value
)
size
)
}
function
full
(
size
fill_value
)
{
let
dtype
;
let
typedArrayCls
;
if
(
typeof
fill_value
=
=
=
'
number
'
)
{
dtype
=
'
float32
'
;
typedArrayCls
=
Float32Array
;
}
else
if
(
typeof
fill_value
=
=
=
'
bigint
'
)
{
dtype
=
'
int64
'
;
typedArrayCls
=
BigInt64Array
;
}
else
{
throw
new
Error
(
Unsupported
data
type
:
{
typeof
fill_value
}
)
;
}
return
fullHelper
(
size
fill_value
dtype
typedArrayCls
)
;
}
function
full_like
(
tensor
fill_value
)
{
return
full
(
tensor
.
dims
fill_value
)
;
}
function
ones
(
size
)
{
return
fullHelper
(
size
1n
'
int64
'
BigInt64Array
)
;
}
function
ones_like
(
tensor
)
{
return
ones
(
tensor
.
dims
)
;
}
function
zeros
(
size
)
{
return
fullHelper
(
size
0n
'
int64
'
BigInt64Array
)
;
}
function
zeros_like
(
tensor
)
{
return
zeros
(
tensor
.
dims
)
;
}
function
quantize_embeddings
(
tensor
precision
)
{
if
(
tensor
.
dims
.
length
!
=
=
2
)
{
throw
new
Error
(
"
The
tensor
must
have
2
dimensions
"
)
;
}
if
(
tensor
.
dims
.
at
(
-
1
)
%
8
!
=
=
0
)
{
throw
new
Error
(
"
The
last
dimension
of
the
tensor
must
be
a
multiple
of
8
"
)
;
}
if
(
!
[
'
binary
'
'
ubinary
'
]
.
includes
(
precision
)
)
{
throw
new
Error
(
"
The
precision
must
be
either
'
binary
'
or
'
ubinary
'
"
)
;
}
const
signed
=
precision
=
=
=
'
binary
'
;
const
dtype
=
signed
?
'
int8
'
:
'
uint8
'
;
const
cls
=
signed
?
Int8Array
:
Uint8Array
;
const
inputData
=
tensor
.
data
;
const
outputData
=
new
cls
(
inputData
.
length
/
8
)
;
for
(
let
i
=
0
;
i
<
inputData
.
length
;
+
+
i
)
{
const
bit
=
inputData
[
i
]
>
0
?
1
:
0
;
const
arrayIndex
=
Math
.
floor
(
i
/
8
)
;
const
bitPosition
=
i
%
8
;
outputData
[
arrayIndex
]
|
=
bit
<
<
(
7
-
bitPosition
)
;
if
(
signed
&
&
bitPosition
=
=
=
0
)
{
outputData
[
arrayIndex
]
-
=
128
;
}
}
;
return
new
Tensor
(
dtype
outputData
[
tensor
.
dims
[
0
]
tensor
.
dims
[
1
]
/
8
]
)
;
}
}
)
}
)
;
var
__webpack_module_cache__
=
{
}
;
function
__webpack_require__
(
moduleId
)
{
var
cachedModule
=
__webpack_module_cache__
[
moduleId
]
;
if
(
cachedModule
!
=
=
undefined
)
{
return
cachedModule
.
exports
;
}
var
module
=
__webpack_module_cache__
[
moduleId
]
=
{
exports
:
{
}
}
;
__webpack_modules__
[
moduleId
]
(
module
module
.
exports
__webpack_require__
)
;
return
module
.
exports
;
}
(
(
)
=
>
{
__webpack_require__
.
d
=
(
exports
definition
)
=
>
{
for
(
var
key
in
definition
)
{
if
(
__webpack_require__
.
o
(
definition
key
)
&
&
!
__webpack_require__
.
o
(
exports
key
)
)
{
Object
.
defineProperty
(
exports
key
{
enumerable
:
true
get
:
definition
[
key
]
}
)
;
}
}
}
;
}
)
(
)
;
(
(
)
=
>
{
__webpack_require__
.
o
=
(
obj
prop
)
=
>
(
Object
.
prototype
.
hasOwnProperty
.
call
(
obj
prop
)
)
}
)
(
)
;
(
(
)
=
>
{
__webpack_require__
.
r
=
(
exports
)
=
>
{
if
(
typeof
Symbol
!
=
=
'
undefined
'
&
&
Symbol
.
toStringTag
)
{
Object
.
defineProperty
(
exports
Symbol
.
toStringTag
{
value
:
'
Module
'
}
)
;
}
Object
.
defineProperty
(
exports
'
__esModule
'
{
value
:
true
}
)
;
}
;
}
)
(
)
;
var
__webpack_exports__
=
{
}
;
__webpack_require__
.
r
(
__webpack_exports__
)
;
__webpack_require__
.
d
(
__webpack_exports__
{
ASTFeatureExtractor
:
(
)
=
>
(
_models_feature_extractors_js__WEBPACK_IMPORTED_MODULE_10__
.
ASTFeatureExtractor
)
ASTForAudioClassification
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
ASTForAudioClassification
)
ASTModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
ASTModel
)
ASTPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
ASTPreTrainedModel
)
AlbertForMaskedLM
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
AlbertForMaskedLM
)
AlbertForQuestionAnswering
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
AlbertForQuestionAnswering
)
AlbertForSequenceClassification
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
AlbertForSequenceClassification
)
AlbertModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
AlbertModel
)
AlbertPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
AlbertPreTrainedModel
)
AlbertTokenizer
:
(
)
=
>
(
_tokenizers_js__WEBPACK_IMPORTED_MODULE_3__
.
AlbertTokenizer
)
AudioClassificationPipeline
:
(
)
=
>
(
_pipelines_js__WEBPACK_IMPORTED_MODULE_1__
.
AudioClassificationPipeline
)
AutoConfig
:
(
)
=
>
(
_configs_js__WEBPACK_IMPORTED_MODULE_4__
.
AutoConfig
)
AutoFeatureExtractor
:
(
)
=
>
(
_models_auto_feature_extraction_auto_js__WEBPACK_IMPORTED_MODULE_11__
.
AutoFeatureExtractor
)
AutoImageProcessor
:
(
)
=
>
(
_models_auto_image_processing_auto_js__WEBPACK_IMPORTED_MODULE_14__
.
AutoImageProcessor
)
AutoModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
AutoModel
)
AutoModelForAudioClassification
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
AutoModelForAudioClassification
)
AutoModelForAudioFrameClassification
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
AutoModelForAudioFrameClassification
)
AutoModelForCTC
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
AutoModelForCTC
)
AutoModelForCausalLM
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
AutoModelForCausalLM
)
AutoModelForDepthEstimation
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
AutoModelForDepthEstimation
)
AutoModelForDocumentQuestionAnswering
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
AutoModelForDocumentQuestionAnswering
)
AutoModelForImageClassification
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
AutoModelForImageClassification
)
AutoModelForImageFeatureExtraction
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
AutoModelForImageFeatureExtraction
)
AutoModelForImageMatting
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
AutoModelForImageMatting
)
AutoModelForImageSegmentation
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
AutoModelForImageSegmentation
)
AutoModelForImageToImage
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
AutoModelForImageToImage
)
AutoModelForMaskGeneration
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
AutoModelForMaskGeneration
)
AutoModelForMaskedLM
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
AutoModelForMaskedLM
)
AutoModelForNormalEstimation
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
AutoModelForNormalEstimation
)
AutoModelForObjectDetection
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
AutoModelForObjectDetection
)
AutoModelForPoseEstimation
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
AutoModelForPoseEstimation
)
AutoModelForQuestionAnswering
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
AutoModelForQuestionAnswering
)
AutoModelForSemanticSegmentation
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
AutoModelForSemanticSegmentation
)
AutoModelForSeq2SeqLM
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
AutoModelForSeq2SeqLM
)
AutoModelForSequenceClassification
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
AutoModelForSequenceClassification
)
AutoModelForSpeechSeq2Seq
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
AutoModelForSpeechSeq2Seq
)
AutoModelForTextToSpectrogram
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
AutoModelForTextToSpectrogram
)
AutoModelForTextToWaveform
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
AutoModelForTextToWaveform
)
AutoModelForTokenClassification
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
AutoModelForTokenClassification
)
AutoModelForUniversalSegmentation
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
AutoModelForUniversalSegmentation
)
AutoModelForVision2Seq
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
AutoModelForVision2Seq
)
AutoModelForXVector
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
AutoModelForXVector
)
AutoModelForZeroShotObjectDetection
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
AutoModelForZeroShotObjectDetection
)
AutoProcessor
:
(
)
=
>
(
_models_auto_processing_auto_js__WEBPACK_IMPORTED_MODULE_17__
.
AutoProcessor
)
AutoTokenizer
:
(
)
=
>
(
_tokenizers_js__WEBPACK_IMPORTED_MODULE_3__
.
AutoTokenizer
)
AutomaticSpeechRecognitionPipeline
:
(
)
=
>
(
_pipelines_js__WEBPACK_IMPORTED_MODULE_1__
.
AutomaticSpeechRecognitionPipeline
)
BartForConditionalGeneration
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
BartForConditionalGeneration
)
BartForSequenceClassification
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
BartForSequenceClassification
)
BartModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
BartModel
)
BartPretrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
BartPretrainedModel
)
BartTokenizer
:
(
)
=
>
(
_tokenizers_js__WEBPACK_IMPORTED_MODULE_3__
.
BartTokenizer
)
BaseModelOutput
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
BaseModelOutput
)
BaseStreamer
:
(
)
=
>
(
_generation_streamers_js__WEBPACK_IMPORTED_MODULE_18__
.
BaseStreamer
)
BeitFeatureExtractor
:
(
)
=
>
(
_models_image_processors_js__WEBPACK_IMPORTED_MODULE_13__
.
BeitFeatureExtractor
)
BeitForImageClassification
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
BeitForImageClassification
)
BeitModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
BeitModel
)
BeitPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
BeitPreTrainedModel
)
BertForMaskedLM
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
BertForMaskedLM
)
BertForQuestionAnswering
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
BertForQuestionAnswering
)
BertForSequenceClassification
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
BertForSequenceClassification
)
BertForTokenClassification
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
BertForTokenClassification
)
BertModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
BertModel
)
BertPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
BertPreTrainedModel
)
BertTokenizer
:
(
)
=
>
(
_tokenizers_js__WEBPACK_IMPORTED_MODULE_3__
.
BertTokenizer
)
BitImageProcessor
:
(
)
=
>
(
_models_image_processors_js__WEBPACK_IMPORTED_MODULE_13__
.
BitImageProcessor
)
BlenderbotForConditionalGeneration
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
BlenderbotForConditionalGeneration
)
BlenderbotModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
BlenderbotModel
)
BlenderbotPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
BlenderbotPreTrainedModel
)
BlenderbotSmallForConditionalGeneration
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
BlenderbotSmallForConditionalGeneration
)
BlenderbotSmallModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
BlenderbotSmallModel
)
BlenderbotSmallPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
BlenderbotSmallPreTrainedModel
)
BlenderbotSmallTokenizer
:
(
)
=
>
(
_tokenizers_js__WEBPACK_IMPORTED_MODULE_3__
.
BlenderbotSmallTokenizer
)
BlenderbotTokenizer
:
(
)
=
>
(
_tokenizers_js__WEBPACK_IMPORTED_MODULE_3__
.
BlenderbotTokenizer
)
BloomForCausalLM
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
BloomForCausalLM
)
BloomModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
BloomModel
)
BloomPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
BloomPreTrainedModel
)
BloomTokenizer
:
(
)
=
>
(
_tokenizers_js__WEBPACK_IMPORTED_MODULE_3__
.
BloomTokenizer
)
CLIPFeatureExtractor
:
(
)
=
>
(
_models_image_processors_js__WEBPACK_IMPORTED_MODULE_13__
.
CLIPFeatureExtractor
)
CLIPImageProcessor
:
(
)
=
>
(
_models_image_processors_js__WEBPACK_IMPORTED_MODULE_13__
.
CLIPImageProcessor
)
CLIPModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
CLIPModel
)
CLIPPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
CLIPPreTrainedModel
)
CLIPSegForImageSegmentation
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
CLIPSegForImageSegmentation
)
CLIPSegModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
CLIPSegModel
)
CLIPSegPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
CLIPSegPreTrainedModel
)
CLIPTextModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
CLIPTextModel
)
CLIPTextModelWithProjection
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
CLIPTextModelWithProjection
)
CLIPTokenizer
:
(
)
=
>
(
_tokenizers_js__WEBPACK_IMPORTED_MODULE_3__
.
CLIPTokenizer
)
CLIPVisionModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
CLIPVisionModel
)
CLIPVisionModelWithProjection
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
CLIPVisionModelWithProjection
)
CamembertForMaskedLM
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
CamembertForMaskedLM
)
CamembertForQuestionAnswering
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
CamembertForQuestionAnswering
)
CamembertForSequenceClassification
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
CamembertForSequenceClassification
)
CamembertForTokenClassification
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
CamembertForTokenClassification
)
CamembertModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
CamembertModel
)
CamembertPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
CamembertPreTrainedModel
)
CamembertTokenizer
:
(
)
=
>
(
_tokenizers_js__WEBPACK_IMPORTED_MODULE_3__
.
CamembertTokenizer
)
CausalLMOutput
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
CausalLMOutput
)
CausalLMOutputWithPast
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
CausalLMOutputWithPast
)
ChineseCLIPFeatureExtractor
:
(
)
=
>
(
_models_image_processors_js__WEBPACK_IMPORTED_MODULE_13__
.
ChineseCLIPFeatureExtractor
)
ChineseCLIPModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
ChineseCLIPModel
)
ChineseCLIPPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
ChineseCLIPPreTrainedModel
)
ClapAudioModelWithProjection
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
ClapAudioModelWithProjection
)
ClapFeatureExtractor
:
(
)
=
>
(
_models_feature_extractors_js__WEBPACK_IMPORTED_MODULE_10__
.
ClapFeatureExtractor
)
ClapModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
ClapModel
)
ClapPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
ClapPreTrainedModel
)
ClapTextModelWithProjection
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
ClapTextModelWithProjection
)
ClassifierFreeGuidanceLogitsProcessor
:
(
)
=
>
(
_generation_logits_process_js__WEBPACK_IMPORTED_MODULE_20__
.
ClassifierFreeGuidanceLogitsProcessor
)
CodeGenForCausalLM
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
CodeGenForCausalLM
)
CodeGenModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
CodeGenModel
)
CodeGenPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
CodeGenPreTrainedModel
)
CodeGenTokenizer
:
(
)
=
>
(
_tokenizers_js__WEBPACK_IMPORTED_MODULE_3__
.
CodeGenTokenizer
)
CodeLlamaTokenizer
:
(
)
=
>
(
_tokenizers_js__WEBPACK_IMPORTED_MODULE_3__
.
CodeLlamaTokenizer
)
CohereForCausalLM
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
CohereForCausalLM
)
CohereModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
CohereModel
)
CoherePreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
CoherePreTrainedModel
)
CohereTokenizer
:
(
)
=
>
(
_tokenizers_js__WEBPACK_IMPORTED_MODULE_3__
.
CohereTokenizer
)
ConvBertForMaskedLM
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
ConvBertForMaskedLM
)
ConvBertForQuestionAnswering
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
ConvBertForQuestionAnswering
)
ConvBertForSequenceClassification
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
ConvBertForSequenceClassification
)
ConvBertForTokenClassification
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
ConvBertForTokenClassification
)
ConvBertModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
ConvBertModel
)
ConvBertPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
ConvBertPreTrainedModel
)
ConvBertTokenizer
:
(
)
=
>
(
_tokenizers_js__WEBPACK_IMPORTED_MODULE_3__
.
ConvBertTokenizer
)
ConvNextFeatureExtractor
:
(
)
=
>
(
_models_image_processors_js__WEBPACK_IMPORTED_MODULE_13__
.
ConvNextFeatureExtractor
)
ConvNextForImageClassification
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
ConvNextForImageClassification
)
ConvNextImageProcessor
:
(
)
=
>
(
_models_image_processors_js__WEBPACK_IMPORTED_MODULE_13__
.
ConvNextImageProcessor
)
ConvNextModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
ConvNextModel
)
ConvNextPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
ConvNextPreTrainedModel
)
ConvNextV2ForImageClassification
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
ConvNextV2ForImageClassification
)
ConvNextV2Model
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
ConvNextV2Model
)
ConvNextV2PreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
ConvNextV2PreTrainedModel
)
DPTFeatureExtractor
:
(
)
=
>
(
_models_image_processors_js__WEBPACK_IMPORTED_MODULE_13__
.
DPTFeatureExtractor
)
DPTForDepthEstimation
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
DPTForDepthEstimation
)
DPTImageProcessor
:
(
)
=
>
(
_models_image_processors_js__WEBPACK_IMPORTED_MODULE_13__
.
DPTImageProcessor
)
DPTModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
DPTModel
)
DPTPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
DPTPreTrainedModel
)
DebertaForMaskedLM
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
DebertaForMaskedLM
)
DebertaForQuestionAnswering
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
DebertaForQuestionAnswering
)
DebertaForSequenceClassification
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
DebertaForSequenceClassification
)
DebertaForTokenClassification
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
DebertaForTokenClassification
)
DebertaModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
DebertaModel
)
DebertaPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
DebertaPreTrainedModel
)
DebertaTokenizer
:
(
)
=
>
(
_tokenizers_js__WEBPACK_IMPORTED_MODULE_3__
.
DebertaTokenizer
)
DebertaV2ForMaskedLM
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
DebertaV2ForMaskedLM
)
DebertaV2ForQuestionAnswering
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
DebertaV2ForQuestionAnswering
)
DebertaV2ForSequenceClassification
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
DebertaV2ForSequenceClassification
)
DebertaV2ForTokenClassification
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
DebertaV2ForTokenClassification
)
DebertaV2Model
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
DebertaV2Model
)
DebertaV2PreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
DebertaV2PreTrainedModel
)
DebertaV2Tokenizer
:
(
)
=
>
(
_tokenizers_js__WEBPACK_IMPORTED_MODULE_3__
.
DebertaV2Tokenizer
)
DecisionTransformerModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
DecisionTransformerModel
)
DecisionTransformerPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
DecisionTransformerPreTrainedModel
)
DeiTFeatureExtractor
:
(
)
=
>
(
_models_image_processors_js__WEBPACK_IMPORTED_MODULE_13__
.
DeiTFeatureExtractor
)
DeiTForImageClassification
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
DeiTForImageClassification
)
DeiTImageProcessor
:
(
)
=
>
(
_models_image_processors_js__WEBPACK_IMPORTED_MODULE_13__
.
DeiTImageProcessor
)
DeiTModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
DeiTModel
)
DeiTPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
DeiTPreTrainedModel
)
DepthAnythingForDepthEstimation
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
DepthAnythingForDepthEstimation
)
DepthAnythingPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
DepthAnythingPreTrainedModel
)
DepthEstimationPipeline
:
(
)
=
>
(
_pipelines_js__WEBPACK_IMPORTED_MODULE_1__
.
DepthEstimationPipeline
)
DepthProForDepthEstimation
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
DepthProForDepthEstimation
)
DepthProPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
DepthProPreTrainedModel
)
DetrFeatureExtractor
:
(
)
=
>
(
_models_image_processors_js__WEBPACK_IMPORTED_MODULE_13__
.
DetrFeatureExtractor
)
DetrForObjectDetection
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
DetrForObjectDetection
)
DetrForSegmentation
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
DetrForSegmentation
)
DetrImageProcessor
:
(
)
=
>
(
_models_image_processors_js__WEBPACK_IMPORTED_MODULE_13__
.
DetrImageProcessor
)
DetrModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
DetrModel
)
DetrObjectDetectionOutput
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
DetrObjectDetectionOutput
)
DetrPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
DetrPreTrainedModel
)
DetrSegmentationOutput
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
DetrSegmentationOutput
)
Dinov2ForImageClassification
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
Dinov2ForImageClassification
)
Dinov2Model
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
Dinov2Model
)
Dinov2PreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
Dinov2PreTrainedModel
)
DistilBertForMaskedLM
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
DistilBertForMaskedLM
)
DistilBertForQuestionAnswering
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
DistilBertForQuestionAnswering
)
DistilBertForSequenceClassification
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
DistilBertForSequenceClassification
)
DistilBertForTokenClassification
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
DistilBertForTokenClassification
)
DistilBertModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
DistilBertModel
)
DistilBertPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
DistilBertPreTrainedModel
)
DistilBertTokenizer
:
(
)
=
>
(
_tokenizers_js__WEBPACK_IMPORTED_MODULE_3__
.
DistilBertTokenizer
)
DocumentQuestionAnsweringPipeline
:
(
)
=
>
(
_pipelines_js__WEBPACK_IMPORTED_MODULE_1__
.
DocumentQuestionAnsweringPipeline
)
DonutFeatureExtractor
:
(
)
=
>
(
_models_image_processors_js__WEBPACK_IMPORTED_MODULE_13__
.
DonutFeatureExtractor
)
DonutImageProcessor
:
(
)
=
>
(
_models_image_processors_js__WEBPACK_IMPORTED_MODULE_13__
.
DonutImageProcessor
)
DonutSwinModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
DonutSwinModel
)
DonutSwinPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
DonutSwinPreTrainedModel
)
EfficientNetForImageClassification
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
EfficientNetForImageClassification
)
EfficientNetImageProcessor
:
(
)
=
>
(
_models_image_processors_js__WEBPACK_IMPORTED_MODULE_13__
.
EfficientNetImageProcessor
)
EfficientNetModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
EfficientNetModel
)
EfficientNetPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
EfficientNetPreTrainedModel
)
ElectraForMaskedLM
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
ElectraForMaskedLM
)
ElectraForQuestionAnswering
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
ElectraForQuestionAnswering
)
ElectraForSequenceClassification
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
ElectraForSequenceClassification
)
ElectraForTokenClassification
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
ElectraForTokenClassification
)
ElectraModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
ElectraModel
)
ElectraPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
ElectraPreTrainedModel
)
ElectraTokenizer
:
(
)
=
>
(
_tokenizers_js__WEBPACK_IMPORTED_MODULE_3__
.
ElectraTokenizer
)
EosTokenCriteria
:
(
)
=
>
(
_generation_stopping_criteria_js__WEBPACK_IMPORTED_MODULE_19__
.
EosTokenCriteria
)
EsmForMaskedLM
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
EsmForMaskedLM
)
EsmForSequenceClassification
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
EsmForSequenceClassification
)
EsmForTokenClassification
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
EsmForTokenClassification
)
EsmModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
EsmModel
)
EsmPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
EsmPreTrainedModel
)
EsmTokenizer
:
(
)
=
>
(
_tokenizers_js__WEBPACK_IMPORTED_MODULE_3__
.
EsmTokenizer
)
FFT
:
(
)
=
>
(
_utils_maths_js__WEBPACK_IMPORTED_MODULE_8__
.
FFT
)
FalconForCausalLM
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
FalconForCausalLM
)
FalconModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
FalconModel
)
FalconPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
FalconPreTrainedModel
)
FalconTokenizer
:
(
)
=
>
(
_tokenizers_js__WEBPACK_IMPORTED_MODULE_3__
.
FalconTokenizer
)
FastViTForImageClassification
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
FastViTForImageClassification
)
FastViTModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
FastViTModel
)
FastViTPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
FastViTPreTrainedModel
)
FeatureExtractionPipeline
:
(
)
=
>
(
_pipelines_js__WEBPACK_IMPORTED_MODULE_1__
.
FeatureExtractionPipeline
)
FeatureExtractor
:
(
)
=
>
(
_base_feature_extraction_utils_js__WEBPACK_IMPORTED_MODULE_9__
.
FeatureExtractor
)
FillMaskPipeline
:
(
)
=
>
(
_pipelines_js__WEBPACK_IMPORTED_MODULE_1__
.
FillMaskPipeline
)
Florence2ForConditionalGeneration
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
Florence2ForConditionalGeneration
)
Florence2PreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
Florence2PreTrainedModel
)
Florence2Processor
:
(
)
=
>
(
_models_processors_js__WEBPACK_IMPORTED_MODULE_16__
.
Florence2Processor
)
ForcedBOSTokenLogitsProcessor
:
(
)
=
>
(
_generation_logits_process_js__WEBPACK_IMPORTED_MODULE_20__
.
ForcedBOSTokenLogitsProcessor
)
ForcedEOSTokenLogitsProcessor
:
(
)
=
>
(
_generation_logits_process_js__WEBPACK_IMPORTED_MODULE_20__
.
ForcedEOSTokenLogitsProcessor
)
GLPNFeatureExtractor
:
(
)
=
>
(
_models_image_processors_js__WEBPACK_IMPORTED_MODULE_13__
.
GLPNFeatureExtractor
)
GLPNForDepthEstimation
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
GLPNForDepthEstimation
)
GLPNModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
GLPNModel
)
GLPNPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
GLPNPreTrainedModel
)
GPT2LMHeadModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
GPT2LMHeadModel
)
GPT2Model
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
GPT2Model
)
GPT2PreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
GPT2PreTrainedModel
)
GPT2Tokenizer
:
(
)
=
>
(
_tokenizers_js__WEBPACK_IMPORTED_MODULE_3__
.
GPT2Tokenizer
)
GPTBigCodeForCausalLM
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
GPTBigCodeForCausalLM
)
GPTBigCodeModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
GPTBigCodeModel
)
GPTBigCodePreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
GPTBigCodePreTrainedModel
)
GPTJForCausalLM
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
GPTJForCausalLM
)
GPTJModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
GPTJModel
)
GPTJPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
GPTJPreTrainedModel
)
GPTNeoForCausalLM
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
GPTNeoForCausalLM
)
GPTNeoModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
GPTNeoModel
)
GPTNeoPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
GPTNeoPreTrainedModel
)
GPTNeoXForCausalLM
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
GPTNeoXForCausalLM
)
GPTNeoXModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
GPTNeoXModel
)
GPTNeoXPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
GPTNeoXPreTrainedModel
)
GPTNeoXTokenizer
:
(
)
=
>
(
_tokenizers_js__WEBPACK_IMPORTED_MODULE_3__
.
GPTNeoXTokenizer
)
Gemma2ForCausalLM
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
Gemma2ForCausalLM
)
Gemma2Model
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
Gemma2Model
)
Gemma2PreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
Gemma2PreTrainedModel
)
GemmaForCausalLM
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
GemmaForCausalLM
)
GemmaModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
GemmaModel
)
GemmaPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
GemmaPreTrainedModel
)
GemmaTokenizer
:
(
)
=
>
(
_tokenizers_js__WEBPACK_IMPORTED_MODULE_3__
.
GemmaTokenizer
)
GraniteForCausalLM
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
GraniteForCausalLM
)
GraniteModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
GraniteModel
)
GranitePreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
GranitePreTrainedModel
)
Grok1Tokenizer
:
(
)
=
>
(
_tokenizers_js__WEBPACK_IMPORTED_MODULE_3__
.
Grok1Tokenizer
)
GroupViTModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
GroupViTModel
)
GroupViTPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
GroupViTPreTrainedModel
)
HerbertTokenizer
:
(
)
=
>
(
_tokenizers_js__WEBPACK_IMPORTED_MODULE_3__
.
HerbertTokenizer
)
HieraForImageClassification
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
HieraForImageClassification
)
HieraModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
HieraModel
)
HieraPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
HieraPreTrainedModel
)
HubertForCTC
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
HubertForCTC
)
HubertForSequenceClassification
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
HubertForSequenceClassification
)
HubertModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
HubertModel
)
HubertPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
HubertPreTrainedModel
)
ImageClassificationPipeline
:
(
)
=
>
(
_pipelines_js__WEBPACK_IMPORTED_MODULE_1__
.
ImageClassificationPipeline
)
ImageFeatureExtractionPipeline
:
(
)
=
>
(
_pipelines_js__WEBPACK_IMPORTED_MODULE_1__
.
ImageFeatureExtractionPipeline
)
ImageFeatureExtractor
:
(
)
=
>
(
_models_feature_extractors_js__WEBPACK_IMPORTED_MODULE_10__
.
ImageFeatureExtractor
)
ImageMattingOutput
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
ImageMattingOutput
)
ImageProcessor
:
(
)
=
>
(
_base_image_processors_utils_js__WEBPACK_IMPORTED_MODULE_12__
.
ImageProcessor
)
ImageSegmentationPipeline
:
(
)
=
>
(
_pipelines_js__WEBPACK_IMPORTED_MODULE_1__
.
ImageSegmentationPipeline
)
ImageToImagePipeline
:
(
)
=
>
(
_pipelines_js__WEBPACK_IMPORTED_MODULE_1__
.
ImageToImagePipeline
)
ImageToTextPipeline
:
(
)
=
>
(
_pipelines_js__WEBPACK_IMPORTED_MODULE_1__
.
ImageToTextPipeline
)
InterruptableStoppingCriteria
:
(
)
=
>
(
_generation_stopping_criteria_js__WEBPACK_IMPORTED_MODULE_19__
.
InterruptableStoppingCriteria
)
JAISLMHeadModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
JAISLMHeadModel
)
JAISModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
JAISModel
)
JAISPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
JAISPreTrainedModel
)
JinaCLIPImageProcessor
:
(
)
=
>
(
_models_image_processors_js__WEBPACK_IMPORTED_MODULE_13__
.
JinaCLIPImageProcessor
)
JinaCLIPModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
JinaCLIPModel
)
JinaCLIPPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
JinaCLIPPreTrainedModel
)
JinaCLIPProcessor
:
(
)
=
>
(
_models_processors_js__WEBPACK_IMPORTED_MODULE_16__
.
JinaCLIPProcessor
)
JinaCLIPTextModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
JinaCLIPTextModel
)
JinaCLIPVisionModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
JinaCLIPVisionModel
)
LlamaForCausalLM
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
LlamaForCausalLM
)
LlamaModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
LlamaModel
)
LlamaPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
LlamaPreTrainedModel
)
LlamaTokenizer
:
(
)
=
>
(
_tokenizers_js__WEBPACK_IMPORTED_MODULE_3__
.
LlamaTokenizer
)
LlavaForConditionalGeneration
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
LlavaForConditionalGeneration
)
LlavaOnevisionForConditionalGeneration
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
LlavaOnevisionForConditionalGeneration
)
LlavaOnevisionImageProcessor
:
(
)
=
>
(
_models_image_processors_js__WEBPACK_IMPORTED_MODULE_13__
.
LlavaOnevisionImageProcessor
)
LlavaPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
LlavaPreTrainedModel
)
LogitsProcessor
:
(
)
=
>
(
_generation_logits_process_js__WEBPACK_IMPORTED_MODULE_20__
.
LogitsProcessor
)
LogitsProcessorList
:
(
)
=
>
(
_generation_logits_process_js__WEBPACK_IMPORTED_MODULE_20__
.
LogitsProcessorList
)
LogitsWarper
:
(
)
=
>
(
_generation_logits_process_js__WEBPACK_IMPORTED_MODULE_20__
.
LogitsWarper
)
LongT5ForConditionalGeneration
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
LongT5ForConditionalGeneration
)
LongT5Model
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
LongT5Model
)
LongT5PreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
LongT5PreTrainedModel
)
M2M100ForConditionalGeneration
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
M2M100ForConditionalGeneration
)
M2M100Model
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
M2M100Model
)
M2M100PreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
M2M100PreTrainedModel
)
M2M100Tokenizer
:
(
)
=
>
(
_tokenizers_js__WEBPACK_IMPORTED_MODULE_3__
.
M2M100Tokenizer
)
MBart50Tokenizer
:
(
)
=
>
(
_tokenizers_js__WEBPACK_IMPORTED_MODULE_3__
.
MBart50Tokenizer
)
MBartForCausalLM
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
MBartForCausalLM
)
MBartForConditionalGeneration
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
MBartForConditionalGeneration
)
MBartForSequenceClassification
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
MBartForSequenceClassification
)
MBartModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
MBartModel
)
MBartPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
MBartPreTrainedModel
)
MBartTokenizer
:
(
)
=
>
(
_tokenizers_js__WEBPACK_IMPORTED_MODULE_3__
.
MBartTokenizer
)
MPNetForMaskedLM
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
MPNetForMaskedLM
)
MPNetForQuestionAnswering
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
MPNetForQuestionAnswering
)
MPNetForSequenceClassification
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
MPNetForSequenceClassification
)
MPNetForTokenClassification
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
MPNetForTokenClassification
)
MPNetModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
MPNetModel
)
MPNetPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
MPNetPreTrainedModel
)
MPNetTokenizer
:
(
)
=
>
(
_tokenizers_js__WEBPACK_IMPORTED_MODULE_3__
.
MPNetTokenizer
)
MT5ForConditionalGeneration
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
MT5ForConditionalGeneration
)
MT5Model
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
MT5Model
)
MT5PreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
MT5PreTrainedModel
)
MarianMTModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
MarianMTModel
)
MarianModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
MarianModel
)
MarianPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
MarianPreTrainedModel
)
MarianTokenizer
:
(
)
=
>
(
_tokenizers_js__WEBPACK_IMPORTED_MODULE_3__
.
MarianTokenizer
)
Mask2FormerImageProcessor
:
(
)
=
>
(
_models_image_processors_js__WEBPACK_IMPORTED_MODULE_13__
.
Mask2FormerImageProcessor
)
MaskFormerFeatureExtractor
:
(
)
=
>
(
_models_image_processors_js__WEBPACK_IMPORTED_MODULE_13__
.
MaskFormerFeatureExtractor
)
MaskFormerForInstanceSegmentation
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
MaskFormerForInstanceSegmentation
)
MaskFormerImageProcessor
:
(
)
=
>
(
_models_image_processors_js__WEBPACK_IMPORTED_MODULE_13__
.
MaskFormerImageProcessor
)
MaskFormerModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
MaskFormerModel
)
MaskFormerPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
MaskFormerPreTrainedModel
)
MaskedLMOutput
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
MaskedLMOutput
)
MaxLengthCriteria
:
(
)
=
>
(
_generation_stopping_criteria_js__WEBPACK_IMPORTED_MODULE_19__
.
MaxLengthCriteria
)
MgpstrForSceneTextRecognition
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
MgpstrForSceneTextRecognition
)
MgpstrModelOutput
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
MgpstrModelOutput
)
MgpstrPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
MgpstrPreTrainedModel
)
MgpstrProcessor
:
(
)
=
>
(
_models_processors_js__WEBPACK_IMPORTED_MODULE_16__
.
MgpstrProcessor
)
MgpstrTokenizer
:
(
)
=
>
(
_tokenizers_js__WEBPACK_IMPORTED_MODULE_3__
.
MgpstrTokenizer
)
MinLengthLogitsProcessor
:
(
)
=
>
(
_generation_logits_process_js__WEBPACK_IMPORTED_MODULE_20__
.
MinLengthLogitsProcessor
)
MinNewTokensLengthLogitsProcessor
:
(
)
=
>
(
_generation_logits_process_js__WEBPACK_IMPORTED_MODULE_20__
.
MinNewTokensLengthLogitsProcessor
)
MistralForCausalLM
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
MistralForCausalLM
)
MistralModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
MistralModel
)
MistralPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
MistralPreTrainedModel
)
MobileBertForMaskedLM
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
MobileBertForMaskedLM
)
MobileBertForQuestionAnswering
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
MobileBertForQuestionAnswering
)
MobileBertForSequenceClassification
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
MobileBertForSequenceClassification
)
MobileBertModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
MobileBertModel
)
MobileBertPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
MobileBertPreTrainedModel
)
MobileBertTokenizer
:
(
)
=
>
(
_tokenizers_js__WEBPACK_IMPORTED_MODULE_3__
.
MobileBertTokenizer
)
MobileLLMForCausalLM
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
MobileLLMForCausalLM
)
MobileLLMModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
MobileLLMModel
)
MobileLLMPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
MobileLLMPreTrainedModel
)
MobileNetV1FeatureExtractor
:
(
)
=
>
(
_models_image_processors_js__WEBPACK_IMPORTED_MODULE_13__
.
MobileNetV1FeatureExtractor
)
MobileNetV1ForImageClassification
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
MobileNetV1ForImageClassification
)
MobileNetV1ImageProcessor
:
(
)
=
>
(
_models_image_processors_js__WEBPACK_IMPORTED_MODULE_13__
.
MobileNetV1ImageProcessor
)
MobileNetV1Model
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
MobileNetV1Model
)
MobileNetV1PreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
MobileNetV1PreTrainedModel
)
MobileNetV2FeatureExtractor
:
(
)
=
>
(
_models_image_processors_js__WEBPACK_IMPORTED_MODULE_13__
.
MobileNetV2FeatureExtractor
)
MobileNetV2ForImageClassification
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
MobileNetV2ForImageClassification
)
MobileNetV2ImageProcessor
:
(
)
=
>
(
_models_image_processors_js__WEBPACK_IMPORTED_MODULE_13__
.
MobileNetV2ImageProcessor
)
MobileNetV2Model
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
MobileNetV2Model
)
MobileNetV2PreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
MobileNetV2PreTrainedModel
)
MobileNetV3FeatureExtractor
:
(
)
=
>
(
_models_image_processors_js__WEBPACK_IMPORTED_MODULE_13__
.
MobileNetV3FeatureExtractor
)
MobileNetV3ForImageClassification
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
MobileNetV3ForImageClassification
)
MobileNetV3ImageProcessor
:
(
)
=
>
(
_models_image_processors_js__WEBPACK_IMPORTED_MODULE_13__
.
MobileNetV3ImageProcessor
)
MobileNetV3Model
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
MobileNetV3Model
)
MobileNetV3PreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
MobileNetV3PreTrainedModel
)
MobileNetV4FeatureExtractor
:
(
)
=
>
(
_models_image_processors_js__WEBPACK_IMPORTED_MODULE_13__
.
MobileNetV4FeatureExtractor
)
MobileNetV4ForImageClassification
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
MobileNetV4ForImageClassification
)
MobileNetV4ImageProcessor
:
(
)
=
>
(
_models_image_processors_js__WEBPACK_IMPORTED_MODULE_13__
.
MobileNetV4ImageProcessor
)
MobileNetV4Model
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
MobileNetV4Model
)
MobileNetV4PreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
MobileNetV4PreTrainedModel
)
MobileViTFeatureExtractor
:
(
)
=
>
(
_models_image_processors_js__WEBPACK_IMPORTED_MODULE_13__
.
MobileViTFeatureExtractor
)
MobileViTForImageClassification
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
MobileViTForImageClassification
)
MobileViTImageProcessor
:
(
)
=
>
(
_models_image_processors_js__WEBPACK_IMPORTED_MODULE_13__
.
MobileViTImageProcessor
)
MobileViTModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
MobileViTModel
)
MobileViTPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
MobileViTPreTrainedModel
)
MobileViTV2ForImageClassification
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
MobileViTV2ForImageClassification
)
MobileViTV2Model
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
MobileViTV2Model
)
MobileViTV2PreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
MobileViTV2PreTrainedModel
)
ModelOutput
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
ModelOutput
)
Moondream1ForConditionalGeneration
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
Moondream1ForConditionalGeneration
)
MptForCausalLM
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
MptForCausalLM
)
MptModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
MptModel
)
MptPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
MptPreTrainedModel
)
MultiModalityCausalLM
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
MultiModalityCausalLM
)
MultiModalityPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
MultiModalityPreTrainedModel
)
MusicgenForCausalLM
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
MusicgenForCausalLM
)
MusicgenForConditionalGeneration
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
MusicgenForConditionalGeneration
)
MusicgenModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
MusicgenModel
)
MusicgenPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
MusicgenPreTrainedModel
)
NllbTokenizer
:
(
)
=
>
(
_tokenizers_js__WEBPACK_IMPORTED_MODULE_3__
.
NllbTokenizer
)
NoBadWordsLogitsProcessor
:
(
)
=
>
(
_generation_logits_process_js__WEBPACK_IMPORTED_MODULE_20__
.
NoBadWordsLogitsProcessor
)
NoRepeatNGramLogitsProcessor
:
(
)
=
>
(
_generation_logits_process_js__WEBPACK_IMPORTED_MODULE_20__
.
NoRepeatNGramLogitsProcessor
)
NomicBertModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
NomicBertModel
)
NomicBertPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
NomicBertPreTrainedModel
)
NougatImageProcessor
:
(
)
=
>
(
_models_image_processors_js__WEBPACK_IMPORTED_MODULE_13__
.
NougatImageProcessor
)
NougatTokenizer
:
(
)
=
>
(
_tokenizers_js__WEBPACK_IMPORTED_MODULE_3__
.
NougatTokenizer
)
OPTForCausalLM
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
OPTForCausalLM
)
OPTModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
OPTModel
)
OPTPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
OPTPreTrainedModel
)
ObjectDetectionPipeline
:
(
)
=
>
(
_pipelines_js__WEBPACK_IMPORTED_MODULE_1__
.
ObjectDetectionPipeline
)
OlmoForCausalLM
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
OlmoForCausalLM
)
OlmoModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
OlmoModel
)
OlmoPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
OlmoPreTrainedModel
)
OpenELMForCausalLM
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
OpenELMForCausalLM
)
OpenELMModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
OpenELMModel
)
OpenELMPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
OpenELMPreTrainedModel
)
OwlViTFeatureExtractor
:
(
)
=
>
(
_models_image_processors_js__WEBPACK_IMPORTED_MODULE_13__
.
OwlViTFeatureExtractor
)
OwlViTForObjectDetection
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
OwlViTForObjectDetection
)
OwlViTImageProcessor
:
(
)
=
>
(
_models_image_processors_js__WEBPACK_IMPORTED_MODULE_13__
.
OwlViTImageProcessor
)
OwlViTModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
OwlViTModel
)
OwlViTPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
OwlViTPreTrainedModel
)
OwlViTProcessor
:
(
)
=
>
(
_models_processors_js__WEBPACK_IMPORTED_MODULE_16__
.
OwlViTProcessor
)
Owlv2ForObjectDetection
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
Owlv2ForObjectDetection
)
Owlv2ImageProcessor
:
(
)
=
>
(
_models_image_processors_js__WEBPACK_IMPORTED_MODULE_13__
.
Owlv2ImageProcessor
)
Owlv2Model
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
Owlv2Model
)
Owlv2PreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
Owlv2PreTrainedModel
)
PatchTSMixerForPrediction
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
PatchTSMixerForPrediction
)
PatchTSMixerModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
PatchTSMixerModel
)
PatchTSMixerPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
PatchTSMixerPreTrainedModel
)
PatchTSTForPrediction
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
PatchTSTForPrediction
)
PatchTSTModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
PatchTSTModel
)
PatchTSTPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
PatchTSTPreTrainedModel
)
Phi3ForCausalLM
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
Phi3ForCausalLM
)
Phi3Model
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
Phi3Model
)
Phi3PreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
Phi3PreTrainedModel
)
PhiForCausalLM
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
PhiForCausalLM
)
PhiModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
PhiModel
)
PhiPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
PhiPreTrainedModel
)
Pipeline
:
(
)
=
>
(
_pipelines_js__WEBPACK_IMPORTED_MODULE_1__
.
Pipeline
)
PreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
PreTrainedModel
)
PreTrainedTokenizer
:
(
)
=
>
(
_tokenizers_js__WEBPACK_IMPORTED_MODULE_3__
.
PreTrainedTokenizer
)
PretrainedConfig
:
(
)
=
>
(
_configs_js__WEBPACK_IMPORTED_MODULE_4__
.
PretrainedConfig
)
PretrainedMixin
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
PretrainedMixin
)
Processor
:
(
)
=
>
(
_base_processing_utils_js__WEBPACK_IMPORTED_MODULE_15__
.
Processor
)
PvtForImageClassification
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
PvtForImageClassification
)
PvtImageProcessor
:
(
)
=
>
(
_models_image_processors_js__WEBPACK_IMPORTED_MODULE_13__
.
PvtImageProcessor
)
PvtModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
PvtModel
)
PvtPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
PvtPreTrainedModel
)
PyAnnoteFeatureExtractor
:
(
)
=
>
(
_models_feature_extractors_js__WEBPACK_IMPORTED_MODULE_10__
.
PyAnnoteFeatureExtractor
)
PyAnnoteForAudioFrameClassification
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
PyAnnoteForAudioFrameClassification
)
PyAnnoteModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
PyAnnoteModel
)
PyAnnotePreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
PyAnnotePreTrainedModel
)
PyAnnoteProcessor
:
(
)
=
>
(
_models_processors_js__WEBPACK_IMPORTED_MODULE_16__
.
PyAnnoteProcessor
)
QuestionAnsweringModelOutput
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
QuestionAnsweringModelOutput
)
QuestionAnsweringPipeline
:
(
)
=
>
(
_pipelines_js__WEBPACK_IMPORTED_MODULE_1__
.
QuestionAnsweringPipeline
)
Qwen2ForCausalLM
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
Qwen2ForCausalLM
)
Qwen2Model
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
Qwen2Model
)
Qwen2PreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
Qwen2PreTrainedModel
)
Qwen2Tokenizer
:
(
)
=
>
(
_tokenizers_js__WEBPACK_IMPORTED_MODULE_3__
.
Qwen2Tokenizer
)
Qwen2VLForConditionalGeneration
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
Qwen2VLForConditionalGeneration
)
Qwen2VLImageProcessor
:
(
)
=
>
(
_models_image_processors_js__WEBPACK_IMPORTED_MODULE_13__
.
Qwen2VLImageProcessor
)
Qwen2VLPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
Qwen2VLPreTrainedModel
)
Qwen2VLProcessor
:
(
)
=
>
(
_models_processors_js__WEBPACK_IMPORTED_MODULE_16__
.
Qwen2VLProcessor
)
RTDetrForObjectDetection
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
RTDetrForObjectDetection
)
RTDetrImageProcessor
:
(
)
=
>
(
_models_image_processors_js__WEBPACK_IMPORTED_MODULE_13__
.
RTDetrImageProcessor
)
RTDetrModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
RTDetrModel
)
RTDetrObjectDetectionOutput
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
RTDetrObjectDetectionOutput
)
RTDetrPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
RTDetrPreTrainedModel
)
RawImage
:
(
)
=
>
(
_utils_image_js__WEBPACK_IMPORTED_MODULE_6__
.
RawImage
)
RepetitionPenaltyLogitsProcessor
:
(
)
=
>
(
_generation_logits_process_js__WEBPACK_IMPORTED_MODULE_20__
.
RepetitionPenaltyLogitsProcessor
)
ResNetForImageClassification
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
ResNetForImageClassification
)
ResNetModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
ResNetModel
)
ResNetPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
ResNetPreTrainedModel
)
RoFormerForMaskedLM
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
RoFormerForMaskedLM
)
RoFormerForQuestionAnswering
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
RoFormerForQuestionAnswering
)
RoFormerForSequenceClassification
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
RoFormerForSequenceClassification
)
RoFormerForTokenClassification
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
RoFormerForTokenClassification
)
RoFormerModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
RoFormerModel
)
RoFormerPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
RoFormerPreTrainedModel
)
RoFormerTokenizer
:
(
)
=
>
(
_tokenizers_js__WEBPACK_IMPORTED_MODULE_3__
.
RoFormerTokenizer
)
RobertaForMaskedLM
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
RobertaForMaskedLM
)
RobertaForQuestionAnswering
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
RobertaForQuestionAnswering
)
RobertaForSequenceClassification
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
RobertaForSequenceClassification
)
RobertaForTokenClassification
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
RobertaForTokenClassification
)
RobertaModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
RobertaModel
)
RobertaPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
RobertaPreTrainedModel
)
RobertaTokenizer
:
(
)
=
>
(
_tokenizers_js__WEBPACK_IMPORTED_MODULE_3__
.
RobertaTokenizer
)
SamImageProcessor
:
(
)
=
>
(
_models_image_processors_js__WEBPACK_IMPORTED_MODULE_13__
.
SamImageProcessor
)
SamImageSegmentationOutput
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
SamImageSegmentationOutput
)
SamModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
SamModel
)
SamPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
SamPreTrainedModel
)
SamProcessor
:
(
)
=
>
(
_models_processors_js__WEBPACK_IMPORTED_MODULE_16__
.
SamProcessor
)
SapiensForDepthEstimation
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
SapiensForDepthEstimation
)
SapiensForNormalEstimation
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
SapiensForNormalEstimation
)
SapiensForSemanticSegmentation
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
SapiensForSemanticSegmentation
)
SapiensPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
SapiensPreTrainedModel
)
SeamlessM4TFeatureExtractor
:
(
)
=
>
(
_models_feature_extractors_js__WEBPACK_IMPORTED_MODULE_10__
.
SeamlessM4TFeatureExtractor
)
SegformerFeatureExtractor
:
(
)
=
>
(
_models_image_processors_js__WEBPACK_IMPORTED_MODULE_13__
.
SegformerFeatureExtractor
)
SegformerForImageClassification
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
SegformerForImageClassification
)
SegformerForSemanticSegmentation
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
SegformerForSemanticSegmentation
)
SegformerImageProcessor
:
(
)
=
>
(
_models_image_processors_js__WEBPACK_IMPORTED_MODULE_13__
.
SegformerImageProcessor
)
SegformerModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
SegformerModel
)
SegformerPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
SegformerPreTrainedModel
)
Seq2SeqLMOutput
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
Seq2SeqLMOutput
)
SequenceClassifierOutput
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
SequenceClassifierOutput
)
SiglipImageProcessor
:
(
)
=
>
(
_models_image_processors_js__WEBPACK_IMPORTED_MODULE_13__
.
SiglipImageProcessor
)
SiglipModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
SiglipModel
)
SiglipPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
SiglipPreTrainedModel
)
SiglipTextModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
SiglipTextModel
)
SiglipTokenizer
:
(
)
=
>
(
_tokenizers_js__WEBPACK_IMPORTED_MODULE_3__
.
SiglipTokenizer
)
SiglipVisionModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
SiglipVisionModel
)
SpeechT5FeatureExtractor
:
(
)
=
>
(
_models_feature_extractors_js__WEBPACK_IMPORTED_MODULE_10__
.
SpeechT5FeatureExtractor
)
SpeechT5ForSpeechToText
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
SpeechT5ForSpeechToText
)
SpeechT5ForTextToSpeech
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
SpeechT5ForTextToSpeech
)
SpeechT5HifiGan
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
SpeechT5HifiGan
)
SpeechT5Model
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
SpeechT5Model
)
SpeechT5PreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
SpeechT5PreTrainedModel
)
SpeechT5Processor
:
(
)
=
>
(
_models_processors_js__WEBPACK_IMPORTED_MODULE_16__
.
SpeechT5Processor
)
SpeechT5Tokenizer
:
(
)
=
>
(
_tokenizers_js__WEBPACK_IMPORTED_MODULE_3__
.
SpeechT5Tokenizer
)
SqueezeBertForMaskedLM
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
SqueezeBertForMaskedLM
)
SqueezeBertForQuestionAnswering
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
SqueezeBertForQuestionAnswering
)
SqueezeBertForSequenceClassification
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
SqueezeBertForSequenceClassification
)
SqueezeBertModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
SqueezeBertModel
)
SqueezeBertPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
SqueezeBertPreTrainedModel
)
SqueezeBertTokenizer
:
(
)
=
>
(
_tokenizers_js__WEBPACK_IMPORTED_MODULE_3__
.
SqueezeBertTokenizer
)
StableLmForCausalLM
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
StableLmForCausalLM
)
StableLmModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
StableLmModel
)
StableLmPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
StableLmPreTrainedModel
)
Starcoder2ForCausalLM
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
Starcoder2ForCausalLM
)
Starcoder2Model
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
Starcoder2Model
)
Starcoder2PreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
Starcoder2PreTrainedModel
)
StoppingCriteria
:
(
)
=
>
(
_generation_stopping_criteria_js__WEBPACK_IMPORTED_MODULE_19__
.
StoppingCriteria
)
StoppingCriteriaList
:
(
)
=
>
(
_generation_stopping_criteria_js__WEBPACK_IMPORTED_MODULE_19__
.
StoppingCriteriaList
)
SummarizationPipeline
:
(
)
=
>
(
_pipelines_js__WEBPACK_IMPORTED_MODULE_1__
.
SummarizationPipeline
)
SuppressTokensAtBeginLogitsProcessor
:
(
)
=
>
(
_generation_logits_process_js__WEBPACK_IMPORTED_MODULE_20__
.
SuppressTokensAtBeginLogitsProcessor
)
Swin2SRForImageSuperResolution
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
Swin2SRForImageSuperResolution
)
Swin2SRImageProcessor
:
(
)
=
>
(
_models_image_processors_js__WEBPACK_IMPORTED_MODULE_13__
.
Swin2SRImageProcessor
)
Swin2SRModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
Swin2SRModel
)
Swin2SRPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
Swin2SRPreTrainedModel
)
SwinForImageClassification
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
SwinForImageClassification
)
SwinModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
SwinModel
)
SwinPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
SwinPreTrainedModel
)
T5ForConditionalGeneration
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
T5ForConditionalGeneration
)
T5Model
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
T5Model
)
T5PreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
T5PreTrainedModel
)
T5Tokenizer
:
(
)
=
>
(
_tokenizers_js__WEBPACK_IMPORTED_MODULE_3__
.
T5Tokenizer
)
TableTransformerForObjectDetection
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
TableTransformerForObjectDetection
)
TableTransformerModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
TableTransformerModel
)
TableTransformerObjectDetectionOutput
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
TableTransformerObjectDetectionOutput
)
TableTransformerPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
TableTransformerPreTrainedModel
)
TemperatureLogitsWarper
:
(
)
=
>
(
_generation_logits_process_js__WEBPACK_IMPORTED_MODULE_20__
.
TemperatureLogitsWarper
)
Tensor
:
(
)
=
>
(
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_7__
.
Tensor
)
Text2TextGenerationPipeline
:
(
)
=
>
(
_pipelines_js__WEBPACK_IMPORTED_MODULE_1__
.
Text2TextGenerationPipeline
)
TextClassificationPipeline
:
(
)
=
>
(
_pipelines_js__WEBPACK_IMPORTED_MODULE_1__
.
TextClassificationPipeline
)
TextGenerationPipeline
:
(
)
=
>
(
_pipelines_js__WEBPACK_IMPORTED_MODULE_1__
.
TextGenerationPipeline
)
TextStreamer
:
(
)
=
>
(
_generation_streamers_js__WEBPACK_IMPORTED_MODULE_18__
.
TextStreamer
)
TextToAudioPipeline
:
(
)
=
>
(
_pipelines_js__WEBPACK_IMPORTED_MODULE_1__
.
TextToAudioPipeline
)
TokenClassificationPipeline
:
(
)
=
>
(
_pipelines_js__WEBPACK_IMPORTED_MODULE_1__
.
TokenClassificationPipeline
)
TokenClassifierOutput
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
TokenClassifierOutput
)
TokenizerModel
:
(
)
=
>
(
_tokenizers_js__WEBPACK_IMPORTED_MODULE_3__
.
TokenizerModel
)
TopKLogitsWarper
:
(
)
=
>
(
_generation_logits_process_js__WEBPACK_IMPORTED_MODULE_20__
.
TopKLogitsWarper
)
TopPLogitsWarper
:
(
)
=
>
(
_generation_logits_process_js__WEBPACK_IMPORTED_MODULE_20__
.
TopPLogitsWarper
)
TrOCRForCausalLM
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
TrOCRForCausalLM
)
TrOCRPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
TrOCRPreTrainedModel
)
TranslationPipeline
:
(
)
=
>
(
_pipelines_js__WEBPACK_IMPORTED_MODULE_1__
.
TranslationPipeline
)
UniSpeechForCTC
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
UniSpeechForCTC
)
UniSpeechForSequenceClassification
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
UniSpeechForSequenceClassification
)
UniSpeechModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
UniSpeechModel
)
UniSpeechPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
UniSpeechPreTrainedModel
)
UniSpeechSatForAudioFrameClassification
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
UniSpeechSatForAudioFrameClassification
)
UniSpeechSatForCTC
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
UniSpeechSatForCTC
)
UniSpeechSatForSequenceClassification
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
UniSpeechSatForSequenceClassification
)
UniSpeechSatModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
UniSpeechSatModel
)
UniSpeechSatPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
UniSpeechSatPreTrainedModel
)
VLChatProcessor
:
(
)
=
>
(
_models_processors_js__WEBPACK_IMPORTED_MODULE_16__
.
VLChatProcessor
)
VLMImageProcessor
:
(
)
=
>
(
_models_image_processors_js__WEBPACK_IMPORTED_MODULE_13__
.
VLMImageProcessor
)
ViTFeatureExtractor
:
(
)
=
>
(
_models_image_processors_js__WEBPACK_IMPORTED_MODULE_13__
.
ViTFeatureExtractor
)
ViTForImageClassification
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
ViTForImageClassification
)
ViTImageProcessor
:
(
)
=
>
(
_models_image_processors_js__WEBPACK_IMPORTED_MODULE_13__
.
ViTImageProcessor
)
ViTMAEModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
ViTMAEModel
)
ViTMAEPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
ViTMAEPreTrainedModel
)
ViTMSNForImageClassification
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
ViTMSNForImageClassification
)
ViTMSNModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
ViTMSNModel
)
ViTMSNPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
ViTMSNPreTrainedModel
)
ViTModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
ViTModel
)
ViTPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
ViTPreTrainedModel
)
VisionEncoderDecoderModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
VisionEncoderDecoderModel
)
VitMatteForImageMatting
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
VitMatteForImageMatting
)
VitMatteImageProcessor
:
(
)
=
>
(
_models_image_processors_js__WEBPACK_IMPORTED_MODULE_13__
.
VitMatteImageProcessor
)
VitMattePreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
VitMattePreTrainedModel
)
VitPoseForPoseEstimation
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
VitPoseForPoseEstimation
)
VitPoseImageProcessor
:
(
)
=
>
(
_models_image_processors_js__WEBPACK_IMPORTED_MODULE_13__
.
VitPoseImageProcessor
)
VitPosePreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
VitPosePreTrainedModel
)
VitsModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
VitsModel
)
VitsModelOutput
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
VitsModelOutput
)
VitsPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
VitsPreTrainedModel
)
VitsTokenizer
:
(
)
=
>
(
_tokenizers_js__WEBPACK_IMPORTED_MODULE_3__
.
VitsTokenizer
)
Wav2Vec2BertForCTC
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
Wav2Vec2BertForCTC
)
Wav2Vec2BertForSequenceClassification
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
Wav2Vec2BertForSequenceClassification
)
Wav2Vec2BertModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
Wav2Vec2BertModel
)
Wav2Vec2BertPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
Wav2Vec2BertPreTrainedModel
)
Wav2Vec2CTCTokenizer
:
(
)
=
>
(
_tokenizers_js__WEBPACK_IMPORTED_MODULE_3__
.
Wav2Vec2CTCTokenizer
)
Wav2Vec2FeatureExtractor
:
(
)
=
>
(
_models_feature_extractors_js__WEBPACK_IMPORTED_MODULE_10__
.
Wav2Vec2FeatureExtractor
)
Wav2Vec2ForAudioFrameClassification
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
Wav2Vec2ForAudioFrameClassification
)
Wav2Vec2ForCTC
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
Wav2Vec2ForCTC
)
Wav2Vec2ForSequenceClassification
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
Wav2Vec2ForSequenceClassification
)
Wav2Vec2Model
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
Wav2Vec2Model
)
Wav2Vec2PreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
Wav2Vec2PreTrainedModel
)
Wav2Vec2ProcessorWithLM
:
(
)
=
>
(
_models_processors_js__WEBPACK_IMPORTED_MODULE_16__
.
Wav2Vec2ProcessorWithLM
)
WavLMForAudioFrameClassification
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
WavLMForAudioFrameClassification
)
WavLMForCTC
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
WavLMForCTC
)
WavLMForSequenceClassification
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
WavLMForSequenceClassification
)
WavLMForXVector
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
WavLMForXVector
)
WavLMModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
WavLMModel
)
WavLMPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
WavLMPreTrainedModel
)
WeSpeakerFeatureExtractor
:
(
)
=
>
(
_models_feature_extractors_js__WEBPACK_IMPORTED_MODULE_10__
.
WeSpeakerFeatureExtractor
)
WeSpeakerResNetModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
WeSpeakerResNetModel
)
WeSpeakerResNetPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
WeSpeakerResNetPreTrainedModel
)
WhisperFeatureExtractor
:
(
)
=
>
(
_models_feature_extractors_js__WEBPACK_IMPORTED_MODULE_10__
.
WhisperFeatureExtractor
)
WhisperForConditionalGeneration
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
WhisperForConditionalGeneration
)
WhisperModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
WhisperModel
)
WhisperPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
WhisperPreTrainedModel
)
WhisperProcessor
:
(
)
=
>
(
_models_processors_js__WEBPACK_IMPORTED_MODULE_16__
.
WhisperProcessor
)
WhisperTextStreamer
:
(
)
=
>
(
_generation_streamers_js__WEBPACK_IMPORTED_MODULE_18__
.
WhisperTextStreamer
)
WhisperTimeStampLogitsProcessor
:
(
)
=
>
(
_generation_logits_process_js__WEBPACK_IMPORTED_MODULE_20__
.
WhisperTimeStampLogitsProcessor
)
WhisperTokenizer
:
(
)
=
>
(
_tokenizers_js__WEBPACK_IMPORTED_MODULE_3__
.
WhisperTokenizer
)
XLMForQuestionAnswering
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
XLMForQuestionAnswering
)
XLMForSequenceClassification
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
XLMForSequenceClassification
)
XLMForTokenClassification
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
XLMForTokenClassification
)
XLMModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
XLMModel
)
XLMPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
XLMPreTrainedModel
)
XLMRobertaForMaskedLM
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
XLMRobertaForMaskedLM
)
XLMRobertaForQuestionAnswering
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
XLMRobertaForQuestionAnswering
)
XLMRobertaForSequenceClassification
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
XLMRobertaForSequenceClassification
)
XLMRobertaForTokenClassification
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
XLMRobertaForTokenClassification
)
XLMRobertaModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
XLMRobertaModel
)
XLMRobertaPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
XLMRobertaPreTrainedModel
)
XLMRobertaTokenizer
:
(
)
=
>
(
_tokenizers_js__WEBPACK_IMPORTED_MODULE_3__
.
XLMRobertaTokenizer
)
XLMTokenizer
:
(
)
=
>
(
_tokenizers_js__WEBPACK_IMPORTED_MODULE_3__
.
XLMTokenizer
)
XLMWithLMHeadModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
XLMWithLMHeadModel
)
XVectorOutput
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
XVectorOutput
)
YolosFeatureExtractor
:
(
)
=
>
(
_models_image_processors_js__WEBPACK_IMPORTED_MODULE_13__
.
YolosFeatureExtractor
)
YolosForObjectDetection
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
YolosForObjectDetection
)
YolosImageProcessor
:
(
)
=
>
(
_models_image_processors_js__WEBPACK_IMPORTED_MODULE_13__
.
YolosImageProcessor
)
YolosModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
YolosModel
)
YolosObjectDetectionOutput
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
YolosObjectDetectionOutput
)
YolosPreTrainedModel
:
(
)
=
>
(
_models_js__WEBPACK_IMPORTED_MODULE_2__
.
YolosPreTrainedModel
)
ZeroShotAudioClassificationPipeline
:
(
)
=
>
(
_pipelines_js__WEBPACK_IMPORTED_MODULE_1__
.
ZeroShotAudioClassificationPipeline
)
ZeroShotClassificationPipeline
:
(
)
=
>
(
_pipelines_js__WEBPACK_IMPORTED_MODULE_1__
.
ZeroShotClassificationPipeline
)
ZeroShotImageClassificationPipeline
:
(
)
=
>
(
_pipelines_js__WEBPACK_IMPORTED_MODULE_1__
.
ZeroShotImageClassificationPipeline
)
ZeroShotObjectDetectionPipeline
:
(
)
=
>
(
_pipelines_js__WEBPACK_IMPORTED_MODULE_1__
.
ZeroShotObjectDetectionPipeline
)
bankers_round
:
(
)
=
>
(
_utils_maths_js__WEBPACK_IMPORTED_MODULE_8__
.
bankers_round
)
cat
:
(
)
=
>
(
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_7__
.
cat
)
cos_sim
:
(
)
=
>
(
_utils_maths_js__WEBPACK_IMPORTED_MODULE_8__
.
cos_sim
)
dot
:
(
)
=
>
(
_utils_maths_js__WEBPACK_IMPORTED_MODULE_8__
.
dot
)
dynamic_time_warping
:
(
)
=
>
(
_utils_maths_js__WEBPACK_IMPORTED_MODULE_8__
.
dynamic_time_warping
)
env
:
(
)
=
>
(
_env_js__WEBPACK_IMPORTED_MODULE_0__
.
env
)
full
:
(
)
=
>
(
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_7__
.
full
)
full_like
:
(
)
=
>
(
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_7__
.
full_like
)
getKeyValueShapes
:
(
)
=
>
(
_configs_js__WEBPACK_IMPORTED_MODULE_4__
.
getKeyValueShapes
)
hamming
:
(
)
=
>
(
_utils_audio_js__WEBPACK_IMPORTED_MODULE_5__
.
hamming
)
hanning
:
(
)
=
>
(
_utils_audio_js__WEBPACK_IMPORTED_MODULE_5__
.
hanning
)
interpolate
:
(
)
=
>
(
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_7__
.
interpolate
)
interpolate_4d
:
(
)
=
>
(
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_7__
.
interpolate_4d
)
interpolate_data
:
(
)
=
>
(
_utils_maths_js__WEBPACK_IMPORTED_MODULE_8__
.
interpolate_data
)
is_chinese_char
:
(
)
=
>
(
_tokenizers_js__WEBPACK_IMPORTED_MODULE_3__
.
is_chinese_char
)
layer_norm
:
(
)
=
>
(
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_7__
.
layer_norm
)
log_softmax
:
(
)
=
>
(
_utils_maths_js__WEBPACK_IMPORTED_MODULE_8__
.
log_softmax
)
magnitude
:
(
)
=
>
(
_utils_maths_js__WEBPACK_IMPORTED_MODULE_8__
.
magnitude
)
matmul
:
(
)
=
>
(
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_7__
.
matmul
)
max
:
(
)
=
>
(
_utils_maths_js__WEBPACK_IMPORTED_MODULE_8__
.
max
)
mean
:
(
)
=
>
(
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_7__
.
mean
)
mean_pooling
:
(
)
=
>
(
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_7__
.
mean_pooling
)
medianFilter
:
(
)
=
>
(
_utils_maths_js__WEBPACK_IMPORTED_MODULE_8__
.
medianFilter
)
mel_filter_bank
:
(
)
=
>
(
_utils_audio_js__WEBPACK_IMPORTED_MODULE_5__
.
mel_filter_bank
)
min
:
(
)
=
>
(
_utils_maths_js__WEBPACK_IMPORTED_MODULE_8__
.
min
)
ones
:
(
)
=
>
(
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_7__
.
ones
)
ones_like
:
(
)
=
>
(
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_7__
.
ones_like
)
permute
:
(
)
=
>
(
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_7__
.
permute
)
permute_data
:
(
)
=
>
(
_utils_maths_js__WEBPACK_IMPORTED_MODULE_8__
.
permute_data
)
pipeline
:
(
)
=
>
(
_pipelines_js__WEBPACK_IMPORTED_MODULE_1__
.
pipeline
)
quantize_embeddings
:
(
)
=
>
(
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_7__
.
quantize_embeddings
)
read_audio
:
(
)
=
>
(
_utils_audio_js__WEBPACK_IMPORTED_MODULE_5__
.
read_audio
)
rfft
:
(
)
=
>
(
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_7__
.
rfft
)
round
:
(
)
=
>
(
_utils_maths_js__WEBPACK_IMPORTED_MODULE_8__
.
round
)
softmax
:
(
)
=
>
(
_utils_maths_js__WEBPACK_IMPORTED_MODULE_8__
.
softmax
)
spectrogram
:
(
)
=
>
(
_utils_audio_js__WEBPACK_IMPORTED_MODULE_5__
.
spectrogram
)
stack
:
(
)
=
>
(
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_7__
.
stack
)
std_mean
:
(
)
=
>
(
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_7__
.
std_mean
)
topk
:
(
)
=
>
(
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_7__
.
topk
)
window_function
:
(
)
=
>
(
_utils_audio_js__WEBPACK_IMPORTED_MODULE_5__
.
window_function
)
zeros
:
(
)
=
>
(
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_7__
.
zeros
)
zeros_like
:
(
)
=
>
(
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_7__
.
zeros_like
)
}
)
;
var
_env_js__WEBPACK_IMPORTED_MODULE_0__
=
__webpack_require__
(
"
.
/
src
/
env
.
js
"
)
;
var
_pipelines_js__WEBPACK_IMPORTED_MODULE_1__
=
__webpack_require__
(
"
.
/
src
/
pipelines
.
js
"
)
;
var
_models_js__WEBPACK_IMPORTED_MODULE_2__
=
__webpack_require__
(
"
.
/
src
/
models
.
js
"
)
;
var
_tokenizers_js__WEBPACK_IMPORTED_MODULE_3__
=
__webpack_require__
(
"
.
/
src
/
tokenizers
.
js
"
)
;
var
_configs_js__WEBPACK_IMPORTED_MODULE_4__
=
__webpack_require__
(
"
.
/
src
/
configs
.
js
"
)
;
var
_utils_audio_js__WEBPACK_IMPORTED_MODULE_5__
=
__webpack_require__
(
"
.
/
src
/
utils
/
audio
.
js
"
)
;
var
_utils_image_js__WEBPACK_IMPORTED_MODULE_6__
=
__webpack_require__
(
"
.
/
src
/
utils
/
image
.
js
"
)
;
var
_utils_tensor_js__WEBPACK_IMPORTED_MODULE_7__
=
__webpack_require__
(
"
.
/
src
/
utils
/
tensor
.
js
"
)
;
var
_utils_maths_js__WEBPACK_IMPORTED_MODULE_8__
=
__webpack_require__
(
"
.
/
src
/
utils
/
maths
.
js
"
)
;
var
_base_feature_extraction_utils_js__WEBPACK_IMPORTED_MODULE_9__
=
__webpack_require__
(
"
.
/
src
/
base
/
feature_extraction_utils
.
js
"
)
;
var
_models_feature_extractors_js__WEBPACK_IMPORTED_MODULE_10__
=
__webpack_require__
(
"
.
/
src
/
models
/
feature_extractors
.
js
"
)
;
var
_models_auto_feature_extraction_auto_js__WEBPACK_IMPORTED_MODULE_11__
=
__webpack_require__
(
"
.
/
src
/
models
/
auto
/
feature_extraction_auto
.
js
"
)
;
var
_base_image_processors_utils_js__WEBPACK_IMPORTED_MODULE_12__
=
__webpack_require__
(
"
.
/
src
/
base
/
image_processors_utils
.
js
"
)
;
var
_models_image_processors_js__WEBPACK_IMPORTED_MODULE_13__
=
__webpack_require__
(
"
.
/
src
/
models
/
image_processors
.
js
"
)
;
var
_models_auto_image_processing_auto_js__WEBPACK_IMPORTED_MODULE_14__
=
__webpack_require__
(
"
.
/
src
/
models
/
auto
/
image_processing_auto
.
js
"
)
;
var
_base_processing_utils_js__WEBPACK_IMPORTED_MODULE_15__
=
__webpack_require__
(
"
.
/
src
/
base
/
processing_utils
.
js
"
)
;
var
_models_processors_js__WEBPACK_IMPORTED_MODULE_16__
=
__webpack_require__
(
"
.
/
src
/
models
/
processors
.
js
"
)
;
var
_models_auto_processing_auto_js__WEBPACK_IMPORTED_MODULE_17__
=
__webpack_require__
(
"
.
/
src
/
models
/
auto
/
processing_auto
.
js
"
)
;
var
_generation_streamers_js__WEBPACK_IMPORTED_MODULE_18__
=
__webpack_require__
(
"
.
/
src
/
generation
/
streamers
.
js
"
)
;
var
_generation_stopping_criteria_js__WEBPACK_IMPORTED_MODULE_19__
=
__webpack_require__
(
"
.
/
src
/
generation
/
stopping_criteria
.
js
"
)
;
var
_generation_logits_process_js__WEBPACK_IMPORTED_MODULE_20__
=
__webpack_require__
(
"
.
/
src
/
generation
/
logits_process
.
js
"
)
;
var
__webpack_exports__ASTFeatureExtractor
=
__webpack_exports__
.
ASTFeatureExtractor
;
var
__webpack_exports__ASTForAudioClassification
=
__webpack_exports__
.
ASTForAudioClassification
;
var
__webpack_exports__ASTModel
=
__webpack_exports__
.
ASTModel
;
var
__webpack_exports__ASTPreTrainedModel
=
__webpack_exports__
.
ASTPreTrainedModel
;
var
__webpack_exports__AlbertForMaskedLM
=
__webpack_exports__
.
AlbertForMaskedLM
;
var
__webpack_exports__AlbertForQuestionAnswering
=
__webpack_exports__
.
AlbertForQuestionAnswering
;
var
__webpack_exports__AlbertForSequenceClassification
=
__webpack_exports__
.
AlbertForSequenceClassification
;
var
__webpack_exports__AlbertModel
=
__webpack_exports__
.
AlbertModel
;
var
__webpack_exports__AlbertPreTrainedModel
=
__webpack_exports__
.
AlbertPreTrainedModel
;
var
__webpack_exports__AlbertTokenizer
=
__webpack_exports__
.
AlbertTokenizer
;
var
__webpack_exports__AudioClassificationPipeline
=
__webpack_exports__
.
AudioClassificationPipeline
;
var
__webpack_exports__AutoConfig
=
__webpack_exports__
.
AutoConfig
;
var
__webpack_exports__AutoFeatureExtractor
=
__webpack_exports__
.
AutoFeatureExtractor
;
var
__webpack_exports__AutoImageProcessor
=
__webpack_exports__
.
AutoImageProcessor
;
var
__webpack_exports__AutoModel
=
__webpack_exports__
.
AutoModel
;
var
__webpack_exports__AutoModelForAudioClassification
=
__webpack_exports__
.
AutoModelForAudioClassification
;
var
__webpack_exports__AutoModelForAudioFrameClassification
=
__webpack_exports__
.
AutoModelForAudioFrameClassification
;
var
__webpack_exports__AutoModelForCTC
=
__webpack_exports__
.
AutoModelForCTC
;
var
__webpack_exports__AutoModelForCausalLM
=
__webpack_exports__
.
AutoModelForCausalLM
;
var
__webpack_exports__AutoModelForDepthEstimation
=
__webpack_exports__
.
AutoModelForDepthEstimation
;
var
__webpack_exports__AutoModelForDocumentQuestionAnswering
=
__webpack_exports__
.
AutoModelForDocumentQuestionAnswering
;
var
__webpack_exports__AutoModelForImageClassification
=
__webpack_exports__
.
AutoModelForImageClassification
;
var
__webpack_exports__AutoModelForImageFeatureExtraction
=
__webpack_exports__
.
AutoModelForImageFeatureExtraction
;
var
__webpack_exports__AutoModelForImageMatting
=
__webpack_exports__
.
AutoModelForImageMatting
;
var
__webpack_exports__AutoModelForImageSegmentation
=
__webpack_exports__
.
AutoModelForImageSegmentation
;
var
__webpack_exports__AutoModelForImageToImage
=
__webpack_exports__
.
AutoModelForImageToImage
;
var
__webpack_exports__AutoModelForMaskGeneration
=
__webpack_exports__
.
AutoModelForMaskGeneration
;
var
__webpack_exports__AutoModelForMaskedLM
=
__webpack_exports__
.
AutoModelForMaskedLM
;
var
__webpack_exports__AutoModelForNormalEstimation
=
__webpack_exports__
.
AutoModelForNormalEstimation
;
var
__webpack_exports__AutoModelForObjectDetection
=
__webpack_exports__
.
AutoModelForObjectDetection
;
var
__webpack_exports__AutoModelForPoseEstimation
=
__webpack_exports__
.
AutoModelForPoseEstimation
;
var
__webpack_exports__AutoModelForQuestionAnswering
=
__webpack_exports__
.
AutoModelForQuestionAnswering
;
var
__webpack_exports__AutoModelForSemanticSegmentation
=
__webpack_exports__
.
AutoModelForSemanticSegmentation
;
var
__webpack_exports__AutoModelForSeq2SeqLM
=
__webpack_exports__
.
AutoModelForSeq2SeqLM
;
var
__webpack_exports__AutoModelForSequenceClassification
=
__webpack_exports__
.
AutoModelForSequenceClassification
;
var
__webpack_exports__AutoModelForSpeechSeq2Seq
=
__webpack_exports__
.
AutoModelForSpeechSeq2Seq
;
var
__webpack_exports__AutoModelForTextToSpectrogram
=
__webpack_exports__
.
AutoModelForTextToSpectrogram
;
var
__webpack_exports__AutoModelForTextToWaveform
=
__webpack_exports__
.
AutoModelForTextToWaveform
;
var
__webpack_exports__AutoModelForTokenClassification
=
__webpack_exports__
.
AutoModelForTokenClassification
;
var
__webpack_exports__AutoModelForUniversalSegmentation
=
__webpack_exports__
.
AutoModelForUniversalSegmentation
;
var
__webpack_exports__AutoModelForVision2Seq
=
__webpack_exports__
.
AutoModelForVision2Seq
;
var
__webpack_exports__AutoModelForXVector
=
__webpack_exports__
.
AutoModelForXVector
;
var
__webpack_exports__AutoModelForZeroShotObjectDetection
=
__webpack_exports__
.
AutoModelForZeroShotObjectDetection
;
var
__webpack_exports__AutoProcessor
=
__webpack_exports__
.
AutoProcessor
;
var
__webpack_exports__AutoTokenizer
=
__webpack_exports__
.
AutoTokenizer
;
var
__webpack_exports__AutomaticSpeechRecognitionPipeline
=
__webpack_exports__
.
AutomaticSpeechRecognitionPipeline
;
var
__webpack_exports__BartForConditionalGeneration
=
__webpack_exports__
.
BartForConditionalGeneration
;
var
__webpack_exports__BartForSequenceClassification
=
__webpack_exports__
.
BartForSequenceClassification
;
var
__webpack_exports__BartModel
=
__webpack_exports__
.
BartModel
;
var
__webpack_exports__BartPretrainedModel
=
__webpack_exports__
.
BartPretrainedModel
;
var
__webpack_exports__BartTokenizer
=
__webpack_exports__
.
BartTokenizer
;
var
__webpack_exports__BaseModelOutput
=
__webpack_exports__
.
BaseModelOutput
;
var
__webpack_exports__BaseStreamer
=
__webpack_exports__
.
BaseStreamer
;
var
__webpack_exports__BeitFeatureExtractor
=
__webpack_exports__
.
BeitFeatureExtractor
;
var
__webpack_exports__BeitForImageClassification
=
__webpack_exports__
.
BeitForImageClassification
;
var
__webpack_exports__BeitModel
=
__webpack_exports__
.
BeitModel
;
var
__webpack_exports__BeitPreTrainedModel
=
__webpack_exports__
.
BeitPreTrainedModel
;
var
__webpack_exports__BertForMaskedLM
=
__webpack_exports__
.
BertForMaskedLM
;
var
__webpack_exports__BertForQuestionAnswering
=
__webpack_exports__
.
BertForQuestionAnswering
;
var
__webpack_exports__BertForSequenceClassification
=
__webpack_exports__
.
BertForSequenceClassification
;
var
__webpack_exports__BertForTokenClassification
=
__webpack_exports__
.
BertForTokenClassification
;
var
__webpack_exports__BertModel
=
__webpack_exports__
.
BertModel
;
var
__webpack_exports__BertPreTrainedModel
=
__webpack_exports__
.
BertPreTrainedModel
;
var
__webpack_exports__BertTokenizer
=
__webpack_exports__
.
BertTokenizer
;
var
__webpack_exports__BitImageProcessor
=
__webpack_exports__
.
BitImageProcessor
;
var
__webpack_exports__BlenderbotForConditionalGeneration
=
__webpack_exports__
.
BlenderbotForConditionalGeneration
;
var
__webpack_exports__BlenderbotModel
=
__webpack_exports__
.
BlenderbotModel
;
var
__webpack_exports__BlenderbotPreTrainedModel
=
__webpack_exports__
.
BlenderbotPreTrainedModel
;
var
__webpack_exports__BlenderbotSmallForConditionalGeneration
=
__webpack_exports__
.
BlenderbotSmallForConditionalGeneration
;
var
__webpack_exports__BlenderbotSmallModel
=
__webpack_exports__
.
BlenderbotSmallModel
;
var
__webpack_exports__BlenderbotSmallPreTrainedModel
=
__webpack_exports__
.
BlenderbotSmallPreTrainedModel
;
var
__webpack_exports__BlenderbotSmallTokenizer
=
__webpack_exports__
.
BlenderbotSmallTokenizer
;
var
__webpack_exports__BlenderbotTokenizer
=
__webpack_exports__
.
BlenderbotTokenizer
;
var
__webpack_exports__BloomForCausalLM
=
__webpack_exports__
.
BloomForCausalLM
;
var
__webpack_exports__BloomModel
=
__webpack_exports__
.
BloomModel
;
var
__webpack_exports__BloomPreTrainedModel
=
__webpack_exports__
.
BloomPreTrainedModel
;
var
__webpack_exports__BloomTokenizer
=
__webpack_exports__
.
BloomTokenizer
;
var
__webpack_exports__CLIPFeatureExtractor
=
__webpack_exports__
.
CLIPFeatureExtractor
;
var
__webpack_exports__CLIPImageProcessor
=
__webpack_exports__
.
CLIPImageProcessor
;
var
__webpack_exports__CLIPModel
=
__webpack_exports__
.
CLIPModel
;
var
__webpack_exports__CLIPPreTrainedModel
=
__webpack_exports__
.
CLIPPreTrainedModel
;
var
__webpack_exports__CLIPSegForImageSegmentation
=
__webpack_exports__
.
CLIPSegForImageSegmentation
;
var
__webpack_exports__CLIPSegModel
=
__webpack_exports__
.
CLIPSegModel
;
var
__webpack_exports__CLIPSegPreTrainedModel
=
__webpack_exports__
.
CLIPSegPreTrainedModel
;
var
__webpack_exports__CLIPTextModel
=
__webpack_exports__
.
CLIPTextModel
;
var
__webpack_exports__CLIPTextModelWithProjection
=
__webpack_exports__
.
CLIPTextModelWithProjection
;
var
__webpack_exports__CLIPTokenizer
=
__webpack_exports__
.
CLIPTokenizer
;
var
__webpack_exports__CLIPVisionModel
=
__webpack_exports__
.
CLIPVisionModel
;
var
__webpack_exports__CLIPVisionModelWithProjection
=
__webpack_exports__
.
CLIPVisionModelWithProjection
;
var
__webpack_exports__CamembertForMaskedLM
=
__webpack_exports__
.
CamembertForMaskedLM
;
var
__webpack_exports__CamembertForQuestionAnswering
=
__webpack_exports__
.
CamembertForQuestionAnswering
;
var
__webpack_exports__CamembertForSequenceClassification
=
__webpack_exports__
.
CamembertForSequenceClassification
;
var
__webpack_exports__CamembertForTokenClassification
=
__webpack_exports__
.
CamembertForTokenClassification
;
var
__webpack_exports__CamembertModel
=
__webpack_exports__
.
CamembertModel
;
var
__webpack_exports__CamembertPreTrainedModel
=
__webpack_exports__
.
CamembertPreTrainedModel
;
var
__webpack_exports__CamembertTokenizer
=
__webpack_exports__
.
CamembertTokenizer
;
var
__webpack_exports__CausalLMOutput
=
__webpack_exports__
.
CausalLMOutput
;
var
__webpack_exports__CausalLMOutputWithPast
=
__webpack_exports__
.
CausalLMOutputWithPast
;
var
__webpack_exports__ChineseCLIPFeatureExtractor
=
__webpack_exports__
.
ChineseCLIPFeatureExtractor
;
var
__webpack_exports__ChineseCLIPModel
=
__webpack_exports__
.
ChineseCLIPModel
;
var
__webpack_exports__ChineseCLIPPreTrainedModel
=
__webpack_exports__
.
ChineseCLIPPreTrainedModel
;
var
__webpack_exports__ClapAudioModelWithProjection
=
__webpack_exports__
.
ClapAudioModelWithProjection
;
var
__webpack_exports__ClapFeatureExtractor
=
__webpack_exports__
.
ClapFeatureExtractor
;
var
__webpack_exports__ClapModel
=
__webpack_exports__
.
ClapModel
;
var
__webpack_exports__ClapPreTrainedModel
=
__webpack_exports__
.
ClapPreTrainedModel
;
var
__webpack_exports__ClapTextModelWithProjection
=
__webpack_exports__
.
ClapTextModelWithProjection
;
var
__webpack_exports__ClassifierFreeGuidanceLogitsProcessor
=
__webpack_exports__
.
ClassifierFreeGuidanceLogitsProcessor
;
var
__webpack_exports__CodeGenForCausalLM
=
__webpack_exports__
.
CodeGenForCausalLM
;
var
__webpack_exports__CodeGenModel
=
__webpack_exports__
.
CodeGenModel
;
var
__webpack_exports__CodeGenPreTrainedModel
=
__webpack_exports__
.
CodeGenPreTrainedModel
;
var
__webpack_exports__CodeGenTokenizer
=
__webpack_exports__
.
CodeGenTokenizer
;
var
__webpack_exports__CodeLlamaTokenizer
=
__webpack_exports__
.
CodeLlamaTokenizer
;
var
__webpack_exports__CohereForCausalLM
=
__webpack_exports__
.
CohereForCausalLM
;
var
__webpack_exports__CohereModel
=
__webpack_exports__
.
CohereModel
;
var
__webpack_exports__CoherePreTrainedModel
=
__webpack_exports__
.
CoherePreTrainedModel
;
var
__webpack_exports__CohereTokenizer
=
__webpack_exports__
.
CohereTokenizer
;
var
__webpack_exports__ConvBertForMaskedLM
=
__webpack_exports__
.
ConvBertForMaskedLM
;
var
__webpack_exports__ConvBertForQuestionAnswering
=
__webpack_exports__
.
ConvBertForQuestionAnswering
;
var
__webpack_exports__ConvBertForSequenceClassification
=
__webpack_exports__
.
ConvBertForSequenceClassification
;
var
__webpack_exports__ConvBertForTokenClassification
=
__webpack_exports__
.
ConvBertForTokenClassification
;
var
__webpack_exports__ConvBertModel
=
__webpack_exports__
.
ConvBertModel
;
var
__webpack_exports__ConvBertPreTrainedModel
=
__webpack_exports__
.
ConvBertPreTrainedModel
;
var
__webpack_exports__ConvBertTokenizer
=
__webpack_exports__
.
ConvBertTokenizer
;
var
__webpack_exports__ConvNextFeatureExtractor
=
__webpack_exports__
.
ConvNextFeatureExtractor
;
var
__webpack_exports__ConvNextForImageClassification
=
__webpack_exports__
.
ConvNextForImageClassification
;
var
__webpack_exports__ConvNextImageProcessor
=
__webpack_exports__
.
ConvNextImageProcessor
;
var
__webpack_exports__ConvNextModel
=
__webpack_exports__
.
ConvNextModel
;
var
__webpack_exports__ConvNextPreTrainedModel
=
__webpack_exports__
.
ConvNextPreTrainedModel
;
var
__webpack_exports__ConvNextV2ForImageClassification
=
__webpack_exports__
.
ConvNextV2ForImageClassification
;
var
__webpack_exports__ConvNextV2Model
=
__webpack_exports__
.
ConvNextV2Model
;
var
__webpack_exports__ConvNextV2PreTrainedModel
=
__webpack_exports__
.
ConvNextV2PreTrainedModel
;
var
__webpack_exports__DPTFeatureExtractor
=
__webpack_exports__
.
DPTFeatureExtractor
;
var
__webpack_exports__DPTForDepthEstimation
=
__webpack_exports__
.
DPTForDepthEstimation
;
var
__webpack_exports__DPTImageProcessor
=
__webpack_exports__
.
DPTImageProcessor
;
var
__webpack_exports__DPTModel
=
__webpack_exports__
.
DPTModel
;
var
__webpack_exports__DPTPreTrainedModel
=
__webpack_exports__
.
DPTPreTrainedModel
;
var
__webpack_exports__DebertaForMaskedLM
=
__webpack_exports__
.
DebertaForMaskedLM
;
var
__webpack_exports__DebertaForQuestionAnswering
=
__webpack_exports__
.
DebertaForQuestionAnswering
;
var
__webpack_exports__DebertaForSequenceClassification
=
__webpack_exports__
.
DebertaForSequenceClassification
;
var
__webpack_exports__DebertaForTokenClassification
=
__webpack_exports__
.
DebertaForTokenClassification
;
var
__webpack_exports__DebertaModel
=
__webpack_exports__
.
DebertaModel
;
var
__webpack_exports__DebertaPreTrainedModel
=
__webpack_exports__
.
DebertaPreTrainedModel
;
var
__webpack_exports__DebertaTokenizer
=
__webpack_exports__
.
DebertaTokenizer
;
var
__webpack_exports__DebertaV2ForMaskedLM
=
__webpack_exports__
.
DebertaV2ForMaskedLM
;
var
__webpack_exports__DebertaV2ForQuestionAnswering
=
__webpack_exports__
.
DebertaV2ForQuestionAnswering
;
var
__webpack_exports__DebertaV2ForSequenceClassification
=
__webpack_exports__
.
DebertaV2ForSequenceClassification
;
var
__webpack_exports__DebertaV2ForTokenClassification
=
__webpack_exports__
.
DebertaV2ForTokenClassification
;
var
__webpack_exports__DebertaV2Model
=
__webpack_exports__
.
DebertaV2Model
;
var
__webpack_exports__DebertaV2PreTrainedModel
=
__webpack_exports__
.
DebertaV2PreTrainedModel
;
var
__webpack_exports__DebertaV2Tokenizer
=
__webpack_exports__
.
DebertaV2Tokenizer
;
var
__webpack_exports__DecisionTransformerModel
=
__webpack_exports__
.
DecisionTransformerModel
;
var
__webpack_exports__DecisionTransformerPreTrainedModel
=
__webpack_exports__
.
DecisionTransformerPreTrainedModel
;
var
__webpack_exports__DeiTFeatureExtractor
=
__webpack_exports__
.
DeiTFeatureExtractor
;
var
__webpack_exports__DeiTForImageClassification
=
__webpack_exports__
.
DeiTForImageClassification
;
var
__webpack_exports__DeiTImageProcessor
=
__webpack_exports__
.
DeiTImageProcessor
;
var
__webpack_exports__DeiTModel
=
__webpack_exports__
.
DeiTModel
;
var
__webpack_exports__DeiTPreTrainedModel
=
__webpack_exports__
.
DeiTPreTrainedModel
;
var
__webpack_exports__DepthAnythingForDepthEstimation
=
__webpack_exports__
.
DepthAnythingForDepthEstimation
;
var
__webpack_exports__DepthAnythingPreTrainedModel
=
__webpack_exports__
.
DepthAnythingPreTrainedModel
;
var
__webpack_exports__DepthEstimationPipeline
=
__webpack_exports__
.
DepthEstimationPipeline
;
var
__webpack_exports__DepthProForDepthEstimation
=
__webpack_exports__
.
DepthProForDepthEstimation
;
var
__webpack_exports__DepthProPreTrainedModel
=
__webpack_exports__
.
DepthProPreTrainedModel
;
var
__webpack_exports__DetrFeatureExtractor
=
__webpack_exports__
.
DetrFeatureExtractor
;
var
__webpack_exports__DetrForObjectDetection
=
__webpack_exports__
.
DetrForObjectDetection
;
var
__webpack_exports__DetrForSegmentation
=
__webpack_exports__
.
DetrForSegmentation
;
var
__webpack_exports__DetrImageProcessor
=
__webpack_exports__
.
DetrImageProcessor
;
var
__webpack_exports__DetrModel
=
__webpack_exports__
.
DetrModel
;
var
__webpack_exports__DetrObjectDetectionOutput
=
__webpack_exports__
.
DetrObjectDetectionOutput
;
var
__webpack_exports__DetrPreTrainedModel
=
__webpack_exports__
.
DetrPreTrainedModel
;
var
__webpack_exports__DetrSegmentationOutput
=
__webpack_exports__
.
DetrSegmentationOutput
;
var
__webpack_exports__Dinov2ForImageClassification
=
__webpack_exports__
.
Dinov2ForImageClassification
;
var
__webpack_exports__Dinov2Model
=
__webpack_exports__
.
Dinov2Model
;
var
__webpack_exports__Dinov2PreTrainedModel
=
__webpack_exports__
.
Dinov2PreTrainedModel
;
var
__webpack_exports__DistilBertForMaskedLM
=
__webpack_exports__
.
DistilBertForMaskedLM
;
var
__webpack_exports__DistilBertForQuestionAnswering
=
__webpack_exports__
.
DistilBertForQuestionAnswering
;
var
__webpack_exports__DistilBertForSequenceClassification
=
__webpack_exports__
.
DistilBertForSequenceClassification
;
var
__webpack_exports__DistilBertForTokenClassification
=
__webpack_exports__
.
DistilBertForTokenClassification
;
var
__webpack_exports__DistilBertModel
=
__webpack_exports__
.
DistilBertModel
;
var
__webpack_exports__DistilBertPreTrainedModel
=
__webpack_exports__
.
DistilBertPreTrainedModel
;
var
__webpack_exports__DistilBertTokenizer
=
__webpack_exports__
.
DistilBertTokenizer
;
var
__webpack_exports__DocumentQuestionAnsweringPipeline
=
__webpack_exports__
.
DocumentQuestionAnsweringPipeline
;
var
__webpack_exports__DonutFeatureExtractor
=
__webpack_exports__
.
DonutFeatureExtractor
;
var
__webpack_exports__DonutImageProcessor
=
__webpack_exports__
.
DonutImageProcessor
;
var
__webpack_exports__DonutSwinModel
=
__webpack_exports__
.
DonutSwinModel
;
var
__webpack_exports__DonutSwinPreTrainedModel
=
__webpack_exports__
.
DonutSwinPreTrainedModel
;
var
__webpack_exports__EfficientNetForImageClassification
=
__webpack_exports__
.
EfficientNetForImageClassification
;
var
__webpack_exports__EfficientNetImageProcessor
=
__webpack_exports__
.
EfficientNetImageProcessor
;
var
__webpack_exports__EfficientNetModel
=
__webpack_exports__
.
EfficientNetModel
;
var
__webpack_exports__EfficientNetPreTrainedModel
=
__webpack_exports__
.
EfficientNetPreTrainedModel
;
var
__webpack_exports__ElectraForMaskedLM
=
__webpack_exports__
.
ElectraForMaskedLM
;
var
__webpack_exports__ElectraForQuestionAnswering
=
__webpack_exports__
.
ElectraForQuestionAnswering
;
var
__webpack_exports__ElectraForSequenceClassification
=
__webpack_exports__
.
ElectraForSequenceClassification
;
var
__webpack_exports__ElectraForTokenClassification
=
__webpack_exports__
.
ElectraForTokenClassification
;
var
__webpack_exports__ElectraModel
=
__webpack_exports__
.
ElectraModel
;
var
__webpack_exports__ElectraPreTrainedModel
=
__webpack_exports__
.
ElectraPreTrainedModel
;
var
__webpack_exports__ElectraTokenizer
=
__webpack_exports__
.
ElectraTokenizer
;
var
__webpack_exports__EosTokenCriteria
=
__webpack_exports__
.
EosTokenCriteria
;
var
__webpack_exports__EsmForMaskedLM
=
__webpack_exports__
.
EsmForMaskedLM
;
var
__webpack_exports__EsmForSequenceClassification
=
__webpack_exports__
.
EsmForSequenceClassification
;
var
__webpack_exports__EsmForTokenClassification
=
__webpack_exports__
.
EsmForTokenClassification
;
var
__webpack_exports__EsmModel
=
__webpack_exports__
.
EsmModel
;
var
__webpack_exports__EsmPreTrainedModel
=
__webpack_exports__
.
EsmPreTrainedModel
;
var
__webpack_exports__EsmTokenizer
=
__webpack_exports__
.
EsmTokenizer
;
var
__webpack_exports__FFT
=
__webpack_exports__
.
FFT
;
var
__webpack_exports__FalconForCausalLM
=
__webpack_exports__
.
FalconForCausalLM
;
var
__webpack_exports__FalconModel
=
__webpack_exports__
.
FalconModel
;
var
__webpack_exports__FalconPreTrainedModel
=
__webpack_exports__
.
FalconPreTrainedModel
;
var
__webpack_exports__FalconTokenizer
=
__webpack_exports__
.
FalconTokenizer
;
var
__webpack_exports__FastViTForImageClassification
=
__webpack_exports__
.
FastViTForImageClassification
;
var
__webpack_exports__FastViTModel
=
__webpack_exports__
.
FastViTModel
;
var
__webpack_exports__FastViTPreTrainedModel
=
__webpack_exports__
.
FastViTPreTrainedModel
;
var
__webpack_exports__FeatureExtractionPipeline
=
__webpack_exports__
.
FeatureExtractionPipeline
;
var
__webpack_exports__FeatureExtractor
=
__webpack_exports__
.
FeatureExtractor
;
var
__webpack_exports__FillMaskPipeline
=
__webpack_exports__
.
FillMaskPipeline
;
var
__webpack_exports__Florence2ForConditionalGeneration
=
__webpack_exports__
.
Florence2ForConditionalGeneration
;
var
__webpack_exports__Florence2PreTrainedModel
=
__webpack_exports__
.
Florence2PreTrainedModel
;
var
__webpack_exports__Florence2Processor
=
__webpack_exports__
.
Florence2Processor
;
var
__webpack_exports__ForcedBOSTokenLogitsProcessor
=
__webpack_exports__
.
ForcedBOSTokenLogitsProcessor
;
var
__webpack_exports__ForcedEOSTokenLogitsProcessor
=
__webpack_exports__
.
ForcedEOSTokenLogitsProcessor
;
var
__webpack_exports__GLPNFeatureExtractor
=
__webpack_exports__
.
GLPNFeatureExtractor
;
var
__webpack_exports__GLPNForDepthEstimation
=
__webpack_exports__
.
GLPNForDepthEstimation
;
var
__webpack_exports__GLPNModel
=
__webpack_exports__
.
GLPNModel
;
var
__webpack_exports__GLPNPreTrainedModel
=
__webpack_exports__
.
GLPNPreTrainedModel
;
var
__webpack_exports__GPT2LMHeadModel
=
__webpack_exports__
.
GPT2LMHeadModel
;
var
__webpack_exports__GPT2Model
=
__webpack_exports__
.
GPT2Model
;
var
__webpack_exports__GPT2PreTrainedModel
=
__webpack_exports__
.
GPT2PreTrainedModel
;
var
__webpack_exports__GPT2Tokenizer
=
__webpack_exports__
.
GPT2Tokenizer
;
var
__webpack_exports__GPTBigCodeForCausalLM
=
__webpack_exports__
.
GPTBigCodeForCausalLM
;
var
__webpack_exports__GPTBigCodeModel
=
__webpack_exports__
.
GPTBigCodeModel
;
var
__webpack_exports__GPTBigCodePreTrainedModel
=
__webpack_exports__
.
GPTBigCodePreTrainedModel
;
var
__webpack_exports__GPTJForCausalLM
=
__webpack_exports__
.
GPTJForCausalLM
;
var
__webpack_exports__GPTJModel
=
__webpack_exports__
.
GPTJModel
;
var
__webpack_exports__GPTJPreTrainedModel
=
__webpack_exports__
.
GPTJPreTrainedModel
;
var
__webpack_exports__GPTNeoForCausalLM
=
__webpack_exports__
.
GPTNeoForCausalLM
;
var
__webpack_exports__GPTNeoModel
=
__webpack_exports__
.
GPTNeoModel
;
var
__webpack_exports__GPTNeoPreTrainedModel
=
__webpack_exports__
.
GPTNeoPreTrainedModel
;
var
__webpack_exports__GPTNeoXForCausalLM
=
__webpack_exports__
.
GPTNeoXForCausalLM
;
var
__webpack_exports__GPTNeoXModel
=
__webpack_exports__
.
GPTNeoXModel
;
var
__webpack_exports__GPTNeoXPreTrainedModel
=
__webpack_exports__
.
GPTNeoXPreTrainedModel
;
var
__webpack_exports__GPTNeoXTokenizer
=
__webpack_exports__
.
GPTNeoXTokenizer
;
var
__webpack_exports__Gemma2ForCausalLM
=
__webpack_exports__
.
Gemma2ForCausalLM
;
var
__webpack_exports__Gemma2Model
=
__webpack_exports__
.
Gemma2Model
;
var
__webpack_exports__Gemma2PreTrainedModel
=
__webpack_exports__
.
Gemma2PreTrainedModel
;
var
__webpack_exports__GemmaForCausalLM
=
__webpack_exports__
.
GemmaForCausalLM
;
var
__webpack_exports__GemmaModel
=
__webpack_exports__
.
GemmaModel
;
var
__webpack_exports__GemmaPreTrainedModel
=
__webpack_exports__
.
GemmaPreTrainedModel
;
var
__webpack_exports__GemmaTokenizer
=
__webpack_exports__
.
GemmaTokenizer
;
var
__webpack_exports__GraniteForCausalLM
=
__webpack_exports__
.
GraniteForCausalLM
;
var
__webpack_exports__GraniteModel
=
__webpack_exports__
.
GraniteModel
;
var
__webpack_exports__GranitePreTrainedModel
=
__webpack_exports__
.
GranitePreTrainedModel
;
var
__webpack_exports__Grok1Tokenizer
=
__webpack_exports__
.
Grok1Tokenizer
;
var
__webpack_exports__GroupViTModel
=
__webpack_exports__
.
GroupViTModel
;
var
__webpack_exports__GroupViTPreTrainedModel
=
__webpack_exports__
.
GroupViTPreTrainedModel
;
var
__webpack_exports__HerbertTokenizer
=
__webpack_exports__
.
HerbertTokenizer
;
var
__webpack_exports__HieraForImageClassification
=
__webpack_exports__
.
HieraForImageClassification
;
var
__webpack_exports__HieraModel
=
__webpack_exports__
.
HieraModel
;
var
__webpack_exports__HieraPreTrainedModel
=
__webpack_exports__
.
HieraPreTrainedModel
;
var
__webpack_exports__HubertForCTC
=
__webpack_exports__
.
HubertForCTC
;
var
__webpack_exports__HubertForSequenceClassification
=
__webpack_exports__
.
HubertForSequenceClassification
;
var
__webpack_exports__HubertModel
=
__webpack_exports__
.
HubertModel
;
var
__webpack_exports__HubertPreTrainedModel
=
__webpack_exports__
.
HubertPreTrainedModel
;
var
__webpack_exports__ImageClassificationPipeline
=
__webpack_exports__
.
ImageClassificationPipeline
;
var
__webpack_exports__ImageFeatureExtractionPipeline
=
__webpack_exports__
.
ImageFeatureExtractionPipeline
;
var
__webpack_exports__ImageFeatureExtractor
=
__webpack_exports__
.
ImageFeatureExtractor
;
var
__webpack_exports__ImageMattingOutput
=
__webpack_exports__
.
ImageMattingOutput
;
var
__webpack_exports__ImageProcessor
=
__webpack_exports__
.
ImageProcessor
;
var
__webpack_exports__ImageSegmentationPipeline
=
__webpack_exports__
.
ImageSegmentationPipeline
;
var
__webpack_exports__ImageToImagePipeline
=
__webpack_exports__
.
ImageToImagePipeline
;
var
__webpack_exports__ImageToTextPipeline
=
__webpack_exports__
.
ImageToTextPipeline
;
var
__webpack_exports__InterruptableStoppingCriteria
=
__webpack_exports__
.
InterruptableStoppingCriteria
;
var
__webpack_exports__JAISLMHeadModel
=
__webpack_exports__
.
JAISLMHeadModel
;
var
__webpack_exports__JAISModel
=
__webpack_exports__
.
JAISModel
;
var
__webpack_exports__JAISPreTrainedModel
=
__webpack_exports__
.
JAISPreTrainedModel
;
var
__webpack_exports__JinaCLIPImageProcessor
=
__webpack_exports__
.
JinaCLIPImageProcessor
;
var
__webpack_exports__JinaCLIPModel
=
__webpack_exports__
.
JinaCLIPModel
;
var
__webpack_exports__JinaCLIPPreTrainedModel
=
__webpack_exports__
.
JinaCLIPPreTrainedModel
;
var
__webpack_exports__JinaCLIPProcessor
=
__webpack_exports__
.
JinaCLIPProcessor
;
var
__webpack_exports__JinaCLIPTextModel
=
__webpack_exports__
.
JinaCLIPTextModel
;
var
__webpack_exports__JinaCLIPVisionModel
=
__webpack_exports__
.
JinaCLIPVisionModel
;
var
__webpack_exports__LlamaForCausalLM
=
__webpack_exports__
.
LlamaForCausalLM
;
var
__webpack_exports__LlamaModel
=
__webpack_exports__
.
LlamaModel
;
var
__webpack_exports__LlamaPreTrainedModel
=
__webpack_exports__
.
LlamaPreTrainedModel
;
var
__webpack_exports__LlamaTokenizer
=
__webpack_exports__
.
LlamaTokenizer
;
var
__webpack_exports__LlavaForConditionalGeneration
=
__webpack_exports__
.
LlavaForConditionalGeneration
;
var
__webpack_exports__LlavaOnevisionForConditionalGeneration
=
__webpack_exports__
.
LlavaOnevisionForConditionalGeneration
;
var
__webpack_exports__LlavaOnevisionImageProcessor
=
__webpack_exports__
.
LlavaOnevisionImageProcessor
;
var
__webpack_exports__LlavaPreTrainedModel
=
__webpack_exports__
.
LlavaPreTrainedModel
;
var
__webpack_exports__LogitsProcessor
=
__webpack_exports__
.
LogitsProcessor
;
var
__webpack_exports__LogitsProcessorList
=
__webpack_exports__
.
LogitsProcessorList
;
var
__webpack_exports__LogitsWarper
=
__webpack_exports__
.
LogitsWarper
;
var
__webpack_exports__LongT5ForConditionalGeneration
=
__webpack_exports__
.
LongT5ForConditionalGeneration
;
var
__webpack_exports__LongT5Model
=
__webpack_exports__
.
LongT5Model
;
var
__webpack_exports__LongT5PreTrainedModel
=
__webpack_exports__
.
LongT5PreTrainedModel
;
var
__webpack_exports__M2M100ForConditionalGeneration
=
__webpack_exports__
.
M2M100ForConditionalGeneration
;
var
__webpack_exports__M2M100Model
=
__webpack_exports__
.
M2M100Model
;
var
__webpack_exports__M2M100PreTrainedModel
=
__webpack_exports__
.
M2M100PreTrainedModel
;
var
__webpack_exports__M2M100Tokenizer
=
__webpack_exports__
.
M2M100Tokenizer
;
var
__webpack_exports__MBart50Tokenizer
=
__webpack_exports__
.
MBart50Tokenizer
;
var
__webpack_exports__MBartForCausalLM
=
__webpack_exports__
.
MBartForCausalLM
;
var
__webpack_exports__MBartForConditionalGeneration
=
__webpack_exports__
.
MBartForConditionalGeneration
;
var
__webpack_exports__MBartForSequenceClassification
=
__webpack_exports__
.
MBartForSequenceClassification
;
var
__webpack_exports__MBartModel
=
__webpack_exports__
.
MBartModel
;
var
__webpack_exports__MBartPreTrainedModel
=
__webpack_exports__
.
MBartPreTrainedModel
;
var
__webpack_exports__MBartTokenizer
=
__webpack_exports__
.
MBartTokenizer
;
var
__webpack_exports__MPNetForMaskedLM
=
__webpack_exports__
.
MPNetForMaskedLM
;
var
__webpack_exports__MPNetForQuestionAnswering
=
__webpack_exports__
.
MPNetForQuestionAnswering
;
var
__webpack_exports__MPNetForSequenceClassification
=
__webpack_exports__
.
MPNetForSequenceClassification
;
var
__webpack_exports__MPNetForTokenClassification
=
__webpack_exports__
.
MPNetForTokenClassification
;
var
__webpack_exports__MPNetModel
=
__webpack_exports__
.
MPNetModel
;
var
__webpack_exports__MPNetPreTrainedModel
=
__webpack_exports__
.
MPNetPreTrainedModel
;
var
__webpack_exports__MPNetTokenizer
=
__webpack_exports__
.
MPNetTokenizer
;
var
__webpack_exports__MT5ForConditionalGeneration
=
__webpack_exports__
.
MT5ForConditionalGeneration
;
var
__webpack_exports__MT5Model
=
__webpack_exports__
.
MT5Model
;
var
__webpack_exports__MT5PreTrainedModel
=
__webpack_exports__
.
MT5PreTrainedModel
;
var
__webpack_exports__MarianMTModel
=
__webpack_exports__
.
MarianMTModel
;
var
__webpack_exports__MarianModel
=
__webpack_exports__
.
MarianModel
;
var
__webpack_exports__MarianPreTrainedModel
=
__webpack_exports__
.
MarianPreTrainedModel
;
var
__webpack_exports__MarianTokenizer
=
__webpack_exports__
.
MarianTokenizer
;
var
__webpack_exports__Mask2FormerImageProcessor
=
__webpack_exports__
.
Mask2FormerImageProcessor
;
var
__webpack_exports__MaskFormerFeatureExtractor
=
__webpack_exports__
.
MaskFormerFeatureExtractor
;
var
__webpack_exports__MaskFormerForInstanceSegmentation
=
__webpack_exports__
.
MaskFormerForInstanceSegmentation
;
var
__webpack_exports__MaskFormerImageProcessor
=
__webpack_exports__
.
MaskFormerImageProcessor
;
var
__webpack_exports__MaskFormerModel
=
__webpack_exports__
.
MaskFormerModel
;
var
__webpack_exports__MaskFormerPreTrainedModel
=
__webpack_exports__
.
MaskFormerPreTrainedModel
;
var
__webpack_exports__MaskedLMOutput
=
__webpack_exports__
.
MaskedLMOutput
;
var
__webpack_exports__MaxLengthCriteria
=
__webpack_exports__
.
MaxLengthCriteria
;
var
__webpack_exports__MgpstrForSceneTextRecognition
=
__webpack_exports__
.
MgpstrForSceneTextRecognition
;
var
__webpack_exports__MgpstrModelOutput
=
__webpack_exports__
.
MgpstrModelOutput
;
var
__webpack_exports__MgpstrPreTrainedModel
=
__webpack_exports__
.
MgpstrPreTrainedModel
;
var
__webpack_exports__MgpstrProcessor
=
__webpack_exports__
.
MgpstrProcessor
;
var
__webpack_exports__MgpstrTokenizer
=
__webpack_exports__
.
MgpstrTokenizer
;
var
__webpack_exports__MinLengthLogitsProcessor
=
__webpack_exports__
.
MinLengthLogitsProcessor
;
var
__webpack_exports__MinNewTokensLengthLogitsProcessor
=
__webpack_exports__
.
MinNewTokensLengthLogitsProcessor
;
var
__webpack_exports__MistralForCausalLM
=
__webpack_exports__
.
MistralForCausalLM
;
var
__webpack_exports__MistralModel
=
__webpack_exports__
.
MistralModel
;
var
__webpack_exports__MistralPreTrainedModel
=
__webpack_exports__
.
MistralPreTrainedModel
;
var
__webpack_exports__MobileBertForMaskedLM
=
__webpack_exports__
.
MobileBertForMaskedLM
;
var
__webpack_exports__MobileBertForQuestionAnswering
=
__webpack_exports__
.
MobileBertForQuestionAnswering
;
var
__webpack_exports__MobileBertForSequenceClassification
=
__webpack_exports__
.
MobileBertForSequenceClassification
;
var
__webpack_exports__MobileBertModel
=
__webpack_exports__
.
MobileBertModel
;
var
__webpack_exports__MobileBertPreTrainedModel
=
__webpack_exports__
.
MobileBertPreTrainedModel
;
var
__webpack_exports__MobileBertTokenizer
=
__webpack_exports__
.
MobileBertTokenizer
;
var
__webpack_exports__MobileLLMForCausalLM
=
__webpack_exports__
.
MobileLLMForCausalLM
;
var
__webpack_exports__MobileLLMModel
=
__webpack_exports__
.
MobileLLMModel
;
var
__webpack_exports__MobileLLMPreTrainedModel
=
__webpack_exports__
.
MobileLLMPreTrainedModel
;
var
__webpack_exports__MobileNetV1FeatureExtractor
=
__webpack_exports__
.
MobileNetV1FeatureExtractor
;
var
__webpack_exports__MobileNetV1ForImageClassification
=
__webpack_exports__
.
MobileNetV1ForImageClassification
;
var
__webpack_exports__MobileNetV1ImageProcessor
=
__webpack_exports__
.
MobileNetV1ImageProcessor
;
var
__webpack_exports__MobileNetV1Model
=
__webpack_exports__
.
MobileNetV1Model
;
var
__webpack_exports__MobileNetV1PreTrainedModel
=
__webpack_exports__
.
MobileNetV1PreTrainedModel
;
var
__webpack_exports__MobileNetV2FeatureExtractor
=
__webpack_exports__
.
MobileNetV2FeatureExtractor
;
var
__webpack_exports__MobileNetV2ForImageClassification
=
__webpack_exports__
.
MobileNetV2ForImageClassification
;
var
__webpack_exports__MobileNetV2ImageProcessor
=
__webpack_exports__
.
MobileNetV2ImageProcessor
;
var
__webpack_exports__MobileNetV2Model
=
__webpack_exports__
.
MobileNetV2Model
;
var
__webpack_exports__MobileNetV2PreTrainedModel
=
__webpack_exports__
.
MobileNetV2PreTrainedModel
;
var
__webpack_exports__MobileNetV3FeatureExtractor
=
__webpack_exports__
.
MobileNetV3FeatureExtractor
;
var
__webpack_exports__MobileNetV3ForImageClassification
=
__webpack_exports__
.
MobileNetV3ForImageClassification
;
var
__webpack_exports__MobileNetV3ImageProcessor
=
__webpack_exports__
.
MobileNetV3ImageProcessor
;
var
__webpack_exports__MobileNetV3Model
=
__webpack_exports__
.
MobileNetV3Model
;
var
__webpack_exports__MobileNetV3PreTrainedModel
=
__webpack_exports__
.
MobileNetV3PreTrainedModel
;
var
__webpack_exports__MobileNetV4FeatureExtractor
=
__webpack_exports__
.
MobileNetV4FeatureExtractor
;
var
__webpack_exports__MobileNetV4ForImageClassification
=
__webpack_exports__
.
MobileNetV4ForImageClassification
;
var
__webpack_exports__MobileNetV4ImageProcessor
=
__webpack_exports__
.
MobileNetV4ImageProcessor
;
var
__webpack_exports__MobileNetV4Model
=
__webpack_exports__
.
MobileNetV4Model
;
var
__webpack_exports__MobileNetV4PreTrainedModel
=
__webpack_exports__
.
MobileNetV4PreTrainedModel
;
var
__webpack_exports__MobileViTFeatureExtractor
=
__webpack_exports__
.
MobileViTFeatureExtractor
;
var
__webpack_exports__MobileViTForImageClassification
=
__webpack_exports__
.
MobileViTForImageClassification
;
var
__webpack_exports__MobileViTImageProcessor
=
__webpack_exports__
.
MobileViTImageProcessor
;
var
__webpack_exports__MobileViTModel
=
__webpack_exports__
.
MobileViTModel
;
var
__webpack_exports__MobileViTPreTrainedModel
=
__webpack_exports__
.
MobileViTPreTrainedModel
;
var
__webpack_exports__MobileViTV2ForImageClassification
=
__webpack_exports__
.
MobileViTV2ForImageClassification
;
var
__webpack_exports__MobileViTV2Model
=
__webpack_exports__
.
MobileViTV2Model
;
var
__webpack_exports__MobileViTV2PreTrainedModel
=
__webpack_exports__
.
MobileViTV2PreTrainedModel
;
var
__webpack_exports__ModelOutput
=
__webpack_exports__
.
ModelOutput
;
var
__webpack_exports__Moondream1ForConditionalGeneration
=
__webpack_exports__
.
Moondream1ForConditionalGeneration
;
var
__webpack_exports__MptForCausalLM
=
__webpack_exports__
.
MptForCausalLM
;
var
__webpack_exports__MptModel
=
__webpack_exports__
.
MptModel
;
var
__webpack_exports__MptPreTrainedModel
=
__webpack_exports__
.
MptPreTrainedModel
;
var
__webpack_exports__MultiModalityCausalLM
=
__webpack_exports__
.
MultiModalityCausalLM
;
var
__webpack_exports__MultiModalityPreTrainedModel
=
__webpack_exports__
.
MultiModalityPreTrainedModel
;
var
__webpack_exports__MusicgenForCausalLM
=
__webpack_exports__
.
MusicgenForCausalLM
;
var
__webpack_exports__MusicgenForConditionalGeneration
=
__webpack_exports__
.
MusicgenForConditionalGeneration
;
var
__webpack_exports__MusicgenModel
=
__webpack_exports__
.
MusicgenModel
;
var
__webpack_exports__MusicgenPreTrainedModel
=
__webpack_exports__
.
MusicgenPreTrainedModel
;
var
__webpack_exports__NllbTokenizer
=
__webpack_exports__
.
NllbTokenizer
;
var
__webpack_exports__NoBadWordsLogitsProcessor
=
__webpack_exports__
.
NoBadWordsLogitsProcessor
;
var
__webpack_exports__NoRepeatNGramLogitsProcessor
=
__webpack_exports__
.
NoRepeatNGramLogitsProcessor
;
var
__webpack_exports__NomicBertModel
=
__webpack_exports__
.
NomicBertModel
;
var
__webpack_exports__NomicBertPreTrainedModel
=
__webpack_exports__
.
NomicBertPreTrainedModel
;
var
__webpack_exports__NougatImageProcessor
=
__webpack_exports__
.
NougatImageProcessor
;
var
__webpack_exports__NougatTokenizer
=
__webpack_exports__
.
NougatTokenizer
;
var
__webpack_exports__OPTForCausalLM
=
__webpack_exports__
.
OPTForCausalLM
;
var
__webpack_exports__OPTModel
=
__webpack_exports__
.
OPTModel
;
var
__webpack_exports__OPTPreTrainedModel
=
__webpack_exports__
.
OPTPreTrainedModel
;
var
__webpack_exports__ObjectDetectionPipeline
=
__webpack_exports__
.
ObjectDetectionPipeline
;
var
__webpack_exports__OlmoForCausalLM
=
__webpack_exports__
.
OlmoForCausalLM
;
var
__webpack_exports__OlmoModel
=
__webpack_exports__
.
OlmoModel
;
var
__webpack_exports__OlmoPreTrainedModel
=
__webpack_exports__
.
OlmoPreTrainedModel
;
var
__webpack_exports__OpenELMForCausalLM
=
__webpack_exports__
.
OpenELMForCausalLM
;
var
__webpack_exports__OpenELMModel
=
__webpack_exports__
.
OpenELMModel
;
var
__webpack_exports__OpenELMPreTrainedModel
=
__webpack_exports__
.
OpenELMPreTrainedModel
;
var
__webpack_exports__OwlViTFeatureExtractor
=
__webpack_exports__
.
OwlViTFeatureExtractor
;
var
__webpack_exports__OwlViTForObjectDetection
=
__webpack_exports__
.
OwlViTForObjectDetection
;
var
__webpack_exports__OwlViTImageProcessor
=
__webpack_exports__
.
OwlViTImageProcessor
;
var
__webpack_exports__OwlViTModel
=
__webpack_exports__
.
OwlViTModel
;
var
__webpack_exports__OwlViTPreTrainedModel
=
__webpack_exports__
.
OwlViTPreTrainedModel
;
var
__webpack_exports__OwlViTProcessor
=
__webpack_exports__
.
OwlViTProcessor
;
var
__webpack_exports__Owlv2ForObjectDetection
=
__webpack_exports__
.
Owlv2ForObjectDetection
;
var
__webpack_exports__Owlv2ImageProcessor
=
__webpack_exports__
.
Owlv2ImageProcessor
;
var
__webpack_exports__Owlv2Model
=
__webpack_exports__
.
Owlv2Model
;
var
__webpack_exports__Owlv2PreTrainedModel
=
__webpack_exports__
.
Owlv2PreTrainedModel
;
var
__webpack_exports__PatchTSMixerForPrediction
=
__webpack_exports__
.
PatchTSMixerForPrediction
;
var
__webpack_exports__PatchTSMixerModel
=
__webpack_exports__
.
PatchTSMixerModel
;
var
__webpack_exports__PatchTSMixerPreTrainedModel
=
__webpack_exports__
.
PatchTSMixerPreTrainedModel
;
var
__webpack_exports__PatchTSTForPrediction
=
__webpack_exports__
.
PatchTSTForPrediction
;
var
__webpack_exports__PatchTSTModel
=
__webpack_exports__
.
PatchTSTModel
;
var
__webpack_exports__PatchTSTPreTrainedModel
=
__webpack_exports__
.
PatchTSTPreTrainedModel
;
var
__webpack_exports__Phi3ForCausalLM
=
__webpack_exports__
.
Phi3ForCausalLM
;
var
__webpack_exports__Phi3Model
=
__webpack_exports__
.
Phi3Model
;
var
__webpack_exports__Phi3PreTrainedModel
=
__webpack_exports__
.
Phi3PreTrainedModel
;
var
__webpack_exports__PhiForCausalLM
=
__webpack_exports__
.
PhiForCausalLM
;
var
__webpack_exports__PhiModel
=
__webpack_exports__
.
PhiModel
;
var
__webpack_exports__PhiPreTrainedModel
=
__webpack_exports__
.
PhiPreTrainedModel
;
var
__webpack_exports__Pipeline
=
__webpack_exports__
.
Pipeline
;
var
__webpack_exports__PreTrainedModel
=
__webpack_exports__
.
PreTrainedModel
;
var
__webpack_exports__PreTrainedTokenizer
=
__webpack_exports__
.
PreTrainedTokenizer
;
var
__webpack_exports__PretrainedConfig
=
__webpack_exports__
.
PretrainedConfig
;
var
__webpack_exports__PretrainedMixin
=
__webpack_exports__
.
PretrainedMixin
;
var
__webpack_exports__Processor
=
__webpack_exports__
.
Processor
;
var
__webpack_exports__PvtForImageClassification
=
__webpack_exports__
.
PvtForImageClassification
;
var
__webpack_exports__PvtImageProcessor
=
__webpack_exports__
.
PvtImageProcessor
;
var
__webpack_exports__PvtModel
=
__webpack_exports__
.
PvtModel
;
var
__webpack_exports__PvtPreTrainedModel
=
__webpack_exports__
.
PvtPreTrainedModel
;
var
__webpack_exports__PyAnnoteFeatureExtractor
=
__webpack_exports__
.
PyAnnoteFeatureExtractor
;
var
__webpack_exports__PyAnnoteForAudioFrameClassification
=
__webpack_exports__
.
PyAnnoteForAudioFrameClassification
;
var
__webpack_exports__PyAnnoteModel
=
__webpack_exports__
.
PyAnnoteModel
;
var
__webpack_exports__PyAnnotePreTrainedModel
=
__webpack_exports__
.
PyAnnotePreTrainedModel
;
var
__webpack_exports__PyAnnoteProcessor
=
__webpack_exports__
.
PyAnnoteProcessor
;
var
__webpack_exports__QuestionAnsweringModelOutput
=
__webpack_exports__
.
QuestionAnsweringModelOutput
;
var
__webpack_exports__QuestionAnsweringPipeline
=
__webpack_exports__
.
QuestionAnsweringPipeline
;
var
__webpack_exports__Qwen2ForCausalLM
=
__webpack_exports__
.
Qwen2ForCausalLM
;
var
__webpack_exports__Qwen2Model
=
__webpack_exports__
.
Qwen2Model
;
var
__webpack_exports__Qwen2PreTrainedModel
=
__webpack_exports__
.
Qwen2PreTrainedModel
;
var
__webpack_exports__Qwen2Tokenizer
=
__webpack_exports__
.
Qwen2Tokenizer
;
var
__webpack_exports__Qwen2VLForConditionalGeneration
=
__webpack_exports__
.
Qwen2VLForConditionalGeneration
;
var
__webpack_exports__Qwen2VLImageProcessor
=
__webpack_exports__
.
Qwen2VLImageProcessor
;
var
__webpack_exports__Qwen2VLPreTrainedModel
=
__webpack_exports__
.
Qwen2VLPreTrainedModel
;
var
__webpack_exports__Qwen2VLProcessor
=
__webpack_exports__
.
Qwen2VLProcessor
;
var
__webpack_exports__RTDetrForObjectDetection
=
__webpack_exports__
.
RTDetrForObjectDetection
;
var
__webpack_exports__RTDetrImageProcessor
=
__webpack_exports__
.
RTDetrImageProcessor
;
var
__webpack_exports__RTDetrModel
=
__webpack_exports__
.
RTDetrModel
;
var
__webpack_exports__RTDetrObjectDetectionOutput
=
__webpack_exports__
.
RTDetrObjectDetectionOutput
;
var
__webpack_exports__RTDetrPreTrainedModel
=
__webpack_exports__
.
RTDetrPreTrainedModel
;
var
__webpack_exports__RawImage
=
__webpack_exports__
.
RawImage
;
var
__webpack_exports__RepetitionPenaltyLogitsProcessor
=
__webpack_exports__
.
RepetitionPenaltyLogitsProcessor
;
var
__webpack_exports__ResNetForImageClassification
=
__webpack_exports__
.
ResNetForImageClassification
;
var
__webpack_exports__ResNetModel
=
__webpack_exports__
.
ResNetModel
;
var
__webpack_exports__ResNetPreTrainedModel
=
__webpack_exports__
.
ResNetPreTrainedModel
;
var
__webpack_exports__RoFormerForMaskedLM
=
__webpack_exports__
.
RoFormerForMaskedLM
;
var
__webpack_exports__RoFormerForQuestionAnswering
=
__webpack_exports__
.
RoFormerForQuestionAnswering
;
var
__webpack_exports__RoFormerForSequenceClassification
=
__webpack_exports__
.
RoFormerForSequenceClassification
;
var
__webpack_exports__RoFormerForTokenClassification
=
__webpack_exports__
.
RoFormerForTokenClassification
;
var
__webpack_exports__RoFormerModel
=
__webpack_exports__
.
RoFormerModel
;
var
__webpack_exports__RoFormerPreTrainedModel
=
__webpack_exports__
.
RoFormerPreTrainedModel
;
var
__webpack_exports__RoFormerTokenizer
=
__webpack_exports__
.
RoFormerTokenizer
;
var
__webpack_exports__RobertaForMaskedLM
=
__webpack_exports__
.
RobertaForMaskedLM
;
var
__webpack_exports__RobertaForQuestionAnswering
=
__webpack_exports__
.
RobertaForQuestionAnswering
;
var
__webpack_exports__RobertaForSequenceClassification
=
__webpack_exports__
.
RobertaForSequenceClassification
;
var
__webpack_exports__RobertaForTokenClassification
=
__webpack_exports__
.
RobertaForTokenClassification
;
var
__webpack_exports__RobertaModel
=
__webpack_exports__
.
RobertaModel
;
var
__webpack_exports__RobertaPreTrainedModel
=
__webpack_exports__
.
RobertaPreTrainedModel
;
var
__webpack_exports__RobertaTokenizer
=
__webpack_exports__
.
RobertaTokenizer
;
var
__webpack_exports__SamImageProcessor
=
__webpack_exports__
.
SamImageProcessor
;
var
__webpack_exports__SamImageSegmentationOutput
=
__webpack_exports__
.
SamImageSegmentationOutput
;
var
__webpack_exports__SamModel
=
__webpack_exports__
.
SamModel
;
var
__webpack_exports__SamPreTrainedModel
=
__webpack_exports__
.
SamPreTrainedModel
;
var
__webpack_exports__SamProcessor
=
__webpack_exports__
.
SamProcessor
;
var
__webpack_exports__SapiensForDepthEstimation
=
__webpack_exports__
.
SapiensForDepthEstimation
;
var
__webpack_exports__SapiensForNormalEstimation
=
__webpack_exports__
.
SapiensForNormalEstimation
;
var
__webpack_exports__SapiensForSemanticSegmentation
=
__webpack_exports__
.
SapiensForSemanticSegmentation
;
var
__webpack_exports__SapiensPreTrainedModel
=
__webpack_exports__
.
SapiensPreTrainedModel
;
var
__webpack_exports__SeamlessM4TFeatureExtractor
=
__webpack_exports__
.
SeamlessM4TFeatureExtractor
;
var
__webpack_exports__SegformerFeatureExtractor
=
__webpack_exports__
.
SegformerFeatureExtractor
;
var
__webpack_exports__SegformerForImageClassification
=
__webpack_exports__
.
SegformerForImageClassification
;
var
__webpack_exports__SegformerForSemanticSegmentation
=
__webpack_exports__
.
SegformerForSemanticSegmentation
;
var
__webpack_exports__SegformerImageProcessor
=
__webpack_exports__
.
SegformerImageProcessor
;
var
__webpack_exports__SegformerModel
=
__webpack_exports__
.
SegformerModel
;
var
__webpack_exports__SegformerPreTrainedModel
=
__webpack_exports__
.
SegformerPreTrainedModel
;
var
__webpack_exports__Seq2SeqLMOutput
=
__webpack_exports__
.
Seq2SeqLMOutput
;
var
__webpack_exports__SequenceClassifierOutput
=
__webpack_exports__
.
SequenceClassifierOutput
;
var
__webpack_exports__SiglipImageProcessor
=
__webpack_exports__
.
SiglipImageProcessor
;
var
__webpack_exports__SiglipModel
=
__webpack_exports__
.
SiglipModel
;
var
__webpack_exports__SiglipPreTrainedModel
=
__webpack_exports__
.
SiglipPreTrainedModel
;
var
__webpack_exports__SiglipTextModel
=
__webpack_exports__
.
SiglipTextModel
;
var
__webpack_exports__SiglipTokenizer
=
__webpack_exports__
.
SiglipTokenizer
;
var
__webpack_exports__SiglipVisionModel
=
__webpack_exports__
.
SiglipVisionModel
;
var
__webpack_exports__SpeechT5FeatureExtractor
=
__webpack_exports__
.
SpeechT5FeatureExtractor
;
var
__webpack_exports__SpeechT5ForSpeechToText
=
__webpack_exports__
.
SpeechT5ForSpeechToText
;
var
__webpack_exports__SpeechT5ForTextToSpeech
=
__webpack_exports__
.
SpeechT5ForTextToSpeech
;
var
__webpack_exports__SpeechT5HifiGan
=
__webpack_exports__
.
SpeechT5HifiGan
;
var
__webpack_exports__SpeechT5Model
=
__webpack_exports__
.
SpeechT5Model
;
var
__webpack_exports__SpeechT5PreTrainedModel
=
__webpack_exports__
.
SpeechT5PreTrainedModel
;
var
__webpack_exports__SpeechT5Processor
=
__webpack_exports__
.
SpeechT5Processor
;
var
__webpack_exports__SpeechT5Tokenizer
=
__webpack_exports__
.
SpeechT5Tokenizer
;
var
__webpack_exports__SqueezeBertForMaskedLM
=
__webpack_exports__
.
SqueezeBertForMaskedLM
;
var
__webpack_exports__SqueezeBertForQuestionAnswering
=
__webpack_exports__
.
SqueezeBertForQuestionAnswering
;
var
__webpack_exports__SqueezeBertForSequenceClassification
=
__webpack_exports__
.
SqueezeBertForSequenceClassification
;
var
__webpack_exports__SqueezeBertModel
=
__webpack_exports__
.
SqueezeBertModel
;
var
__webpack_exports__SqueezeBertPreTrainedModel
=
__webpack_exports__
.
SqueezeBertPreTrainedModel
;
var
__webpack_exports__SqueezeBertTokenizer
=
__webpack_exports__
.
SqueezeBertTokenizer
;
var
__webpack_exports__StableLmForCausalLM
=
__webpack_exports__
.
StableLmForCausalLM
;
var
__webpack_exports__StableLmModel
=
__webpack_exports__
.
StableLmModel
;
var
__webpack_exports__StableLmPreTrainedModel
=
__webpack_exports__
.
StableLmPreTrainedModel
;
var
__webpack_exports__Starcoder2ForCausalLM
=
__webpack_exports__
.
Starcoder2ForCausalLM
;
var
__webpack_exports__Starcoder2Model
=
__webpack_exports__
.
Starcoder2Model
;
var
__webpack_exports__Starcoder2PreTrainedModel
=
__webpack_exports__
.
Starcoder2PreTrainedModel
;
var
__webpack_exports__StoppingCriteria
=
__webpack_exports__
.
StoppingCriteria
;
var
__webpack_exports__StoppingCriteriaList
=
__webpack_exports__
.
StoppingCriteriaList
;
var
__webpack_exports__SummarizationPipeline
=
__webpack_exports__
.
SummarizationPipeline
;
var
__webpack_exports__SuppressTokensAtBeginLogitsProcessor
=
__webpack_exports__
.
SuppressTokensAtBeginLogitsProcessor
;
var
__webpack_exports__Swin2SRForImageSuperResolution
=
__webpack_exports__
.
Swin2SRForImageSuperResolution
;
var
__webpack_exports__Swin2SRImageProcessor
=
__webpack_exports__
.
Swin2SRImageProcessor
;
var
__webpack_exports__Swin2SRModel
=
__webpack_exports__
.
Swin2SRModel
;
var
__webpack_exports__Swin2SRPreTrainedModel
=
__webpack_exports__
.
Swin2SRPreTrainedModel
;
var
__webpack_exports__SwinForImageClassification
=
__webpack_exports__
.
SwinForImageClassification
;
var
__webpack_exports__SwinModel
=
__webpack_exports__
.
SwinModel
;
var
__webpack_exports__SwinPreTrainedModel
=
__webpack_exports__
.
SwinPreTrainedModel
;
var
__webpack_exports__T5ForConditionalGeneration
=
__webpack_exports__
.
T5ForConditionalGeneration
;
var
__webpack_exports__T5Model
=
__webpack_exports__
.
T5Model
;
var
__webpack_exports__T5PreTrainedModel
=
__webpack_exports__
.
T5PreTrainedModel
;
var
__webpack_exports__T5Tokenizer
=
__webpack_exports__
.
T5Tokenizer
;
var
__webpack_exports__TableTransformerForObjectDetection
=
__webpack_exports__
.
TableTransformerForObjectDetection
;
var
__webpack_exports__TableTransformerModel
=
__webpack_exports__
.
TableTransformerModel
;
var
__webpack_exports__TableTransformerObjectDetectionOutput
=
__webpack_exports__
.
TableTransformerObjectDetectionOutput
;
var
__webpack_exports__TableTransformerPreTrainedModel
=
__webpack_exports__
.
TableTransformerPreTrainedModel
;
var
__webpack_exports__TemperatureLogitsWarper
=
__webpack_exports__
.
TemperatureLogitsWarper
;
var
__webpack_exports__Tensor
=
__webpack_exports__
.
Tensor
;
var
__webpack_exports__Text2TextGenerationPipeline
=
__webpack_exports__
.
Text2TextGenerationPipeline
;
var
__webpack_exports__TextClassificationPipeline
=
__webpack_exports__
.
TextClassificationPipeline
;
var
__webpack_exports__TextGenerationPipeline
=
__webpack_exports__
.
TextGenerationPipeline
;
var
__webpack_exports__TextStreamer
=
__webpack_exports__
.
TextStreamer
;
var
__webpack_exports__TextToAudioPipeline
=
__webpack_exports__
.
TextToAudioPipeline
;
var
__webpack_exports__TokenClassificationPipeline
=
__webpack_exports__
.
TokenClassificationPipeline
;
var
__webpack_exports__TokenClassifierOutput
=
__webpack_exports__
.
TokenClassifierOutput
;
var
__webpack_exports__TokenizerModel
=
__webpack_exports__
.
TokenizerModel
;
var
__webpack_exports__TopKLogitsWarper
=
__webpack_exports__
.
TopKLogitsWarper
;
var
__webpack_exports__TopPLogitsWarper
=
__webpack_exports__
.
TopPLogitsWarper
;
var
__webpack_exports__TrOCRForCausalLM
=
__webpack_exports__
.
TrOCRForCausalLM
;
var
__webpack_exports__TrOCRPreTrainedModel
=
__webpack_exports__
.
TrOCRPreTrainedModel
;
var
__webpack_exports__TranslationPipeline
=
__webpack_exports__
.
TranslationPipeline
;
var
__webpack_exports__UniSpeechForCTC
=
__webpack_exports__
.
UniSpeechForCTC
;
var
__webpack_exports__UniSpeechForSequenceClassification
=
__webpack_exports__
.
UniSpeechForSequenceClassification
;
var
__webpack_exports__UniSpeechModel
=
__webpack_exports__
.
UniSpeechModel
;
var
__webpack_exports__UniSpeechPreTrainedModel
=
__webpack_exports__
.
UniSpeechPreTrainedModel
;
var
__webpack_exports__UniSpeechSatForAudioFrameClassification
=
__webpack_exports__
.
UniSpeechSatForAudioFrameClassification
;
var
__webpack_exports__UniSpeechSatForCTC
=
__webpack_exports__
.
UniSpeechSatForCTC
;
var
__webpack_exports__UniSpeechSatForSequenceClassification
=
__webpack_exports__
.
UniSpeechSatForSequenceClassification
;
var
__webpack_exports__UniSpeechSatModel
=
__webpack_exports__
.
UniSpeechSatModel
;
var
__webpack_exports__UniSpeechSatPreTrainedModel
=
__webpack_exports__
.
UniSpeechSatPreTrainedModel
;
var
__webpack_exports__VLChatProcessor
=
__webpack_exports__
.
VLChatProcessor
;
var
__webpack_exports__VLMImageProcessor
=
__webpack_exports__
.
VLMImageProcessor
;
var
__webpack_exports__ViTFeatureExtractor
=
__webpack_exports__
.
ViTFeatureExtractor
;
var
__webpack_exports__ViTForImageClassification
=
__webpack_exports__
.
ViTForImageClassification
;
var
__webpack_exports__ViTImageProcessor
=
__webpack_exports__
.
ViTImageProcessor
;
var
__webpack_exports__ViTMAEModel
=
__webpack_exports__
.
ViTMAEModel
;
var
__webpack_exports__ViTMAEPreTrainedModel
=
__webpack_exports__
.
ViTMAEPreTrainedModel
;
var
__webpack_exports__ViTMSNForImageClassification
=
__webpack_exports__
.
ViTMSNForImageClassification
;
var
__webpack_exports__ViTMSNModel
=
__webpack_exports__
.
ViTMSNModel
;
var
__webpack_exports__ViTMSNPreTrainedModel
=
__webpack_exports__
.
ViTMSNPreTrainedModel
;
var
__webpack_exports__ViTModel
=
__webpack_exports__
.
ViTModel
;
var
__webpack_exports__ViTPreTrainedModel
=
__webpack_exports__
.
ViTPreTrainedModel
;
var
__webpack_exports__VisionEncoderDecoderModel
=
__webpack_exports__
.
VisionEncoderDecoderModel
;
var
__webpack_exports__VitMatteForImageMatting
=
__webpack_exports__
.
VitMatteForImageMatting
;
var
__webpack_exports__VitMatteImageProcessor
=
__webpack_exports__
.
VitMatteImageProcessor
;
var
__webpack_exports__VitMattePreTrainedModel
=
__webpack_exports__
.
VitMattePreTrainedModel
;
var
__webpack_exports__VitPoseForPoseEstimation
=
__webpack_exports__
.
VitPoseForPoseEstimation
;
var
__webpack_exports__VitPoseImageProcessor
=
__webpack_exports__
.
VitPoseImageProcessor
;
var
__webpack_exports__VitPosePreTrainedModel
=
__webpack_exports__
.
VitPosePreTrainedModel
;
var
__webpack_exports__VitsModel
=
__webpack_exports__
.
VitsModel
;
var
__webpack_exports__VitsModelOutput
=
__webpack_exports__
.
VitsModelOutput
;
var
__webpack_exports__VitsPreTrainedModel
=
__webpack_exports__
.
VitsPreTrainedModel
;
var
__webpack_exports__VitsTokenizer
=
__webpack_exports__
.
VitsTokenizer
;
var
__webpack_exports__Wav2Vec2BertForCTC
=
__webpack_exports__
.
Wav2Vec2BertForCTC
;
var
__webpack_exports__Wav2Vec2BertForSequenceClassification
=
__webpack_exports__
.
Wav2Vec2BertForSequenceClassification
;
var
__webpack_exports__Wav2Vec2BertModel
=
__webpack_exports__
.
Wav2Vec2BertModel
;
var
__webpack_exports__Wav2Vec2BertPreTrainedModel
=
__webpack_exports__
.
Wav2Vec2BertPreTrainedModel
;
var
__webpack_exports__Wav2Vec2CTCTokenizer
=
__webpack_exports__
.
Wav2Vec2CTCTokenizer
;
var
__webpack_exports__Wav2Vec2FeatureExtractor
=
__webpack_exports__
.
Wav2Vec2FeatureExtractor
;
var
__webpack_exports__Wav2Vec2ForAudioFrameClassification
=
__webpack_exports__
.
Wav2Vec2ForAudioFrameClassification
;
var
__webpack_exports__Wav2Vec2ForCTC
=
__webpack_exports__
.
Wav2Vec2ForCTC
;
var
__webpack_exports__Wav2Vec2ForSequenceClassification
=
__webpack_exports__
.
Wav2Vec2ForSequenceClassification
;
var
__webpack_exports__Wav2Vec2Model
=
__webpack_exports__
.
Wav2Vec2Model
;
var
__webpack_exports__Wav2Vec2PreTrainedModel
=
__webpack_exports__
.
Wav2Vec2PreTrainedModel
;
var
__webpack_exports__Wav2Vec2ProcessorWithLM
=
__webpack_exports__
.
Wav2Vec2ProcessorWithLM
;
var
__webpack_exports__WavLMForAudioFrameClassification
=
__webpack_exports__
.
WavLMForAudioFrameClassification
;
var
__webpack_exports__WavLMForCTC
=
__webpack_exports__
.
WavLMForCTC
;
var
__webpack_exports__WavLMForSequenceClassification
=
__webpack_exports__
.
WavLMForSequenceClassification
;
var
__webpack_exports__WavLMForXVector
=
__webpack_exports__
.
WavLMForXVector
;
var
__webpack_exports__WavLMModel
=
__webpack_exports__
.
WavLMModel
;
var
__webpack_exports__WavLMPreTrainedModel
=
__webpack_exports__
.
WavLMPreTrainedModel
;
var
__webpack_exports__WeSpeakerFeatureExtractor
=
__webpack_exports__
.
WeSpeakerFeatureExtractor
;
var
__webpack_exports__WeSpeakerResNetModel
=
__webpack_exports__
.
WeSpeakerResNetModel
;
var
__webpack_exports__WeSpeakerResNetPreTrainedModel
=
__webpack_exports__
.
WeSpeakerResNetPreTrainedModel
;
var
__webpack_exports__WhisperFeatureExtractor
=
__webpack_exports__
.
WhisperFeatureExtractor
;
var
__webpack_exports__WhisperForConditionalGeneration
=
__webpack_exports__
.
WhisperForConditionalGeneration
;
var
__webpack_exports__WhisperModel
=
__webpack_exports__
.
WhisperModel
;
var
__webpack_exports__WhisperPreTrainedModel
=
__webpack_exports__
.
WhisperPreTrainedModel
;
var
__webpack_exports__WhisperProcessor
=
__webpack_exports__
.
WhisperProcessor
;
var
__webpack_exports__WhisperTextStreamer
=
__webpack_exports__
.
WhisperTextStreamer
;
var
__webpack_exports__WhisperTimeStampLogitsProcessor
=
__webpack_exports__
.
WhisperTimeStampLogitsProcessor
;
var
__webpack_exports__WhisperTokenizer
=
__webpack_exports__
.
WhisperTokenizer
;
var
__webpack_exports__XLMForQuestionAnswering
=
__webpack_exports__
.
XLMForQuestionAnswering
;
var
__webpack_exports__XLMForSequenceClassification
=
__webpack_exports__
.
XLMForSequenceClassification
;
var
__webpack_exports__XLMForTokenClassification
=
__webpack_exports__
.
XLMForTokenClassification
;
var
__webpack_exports__XLMModel
=
__webpack_exports__
.
XLMModel
;
var
__webpack_exports__XLMPreTrainedModel
=
__webpack_exports__
.
XLMPreTrainedModel
;
var
__webpack_exports__XLMRobertaForMaskedLM
=
__webpack_exports__
.
XLMRobertaForMaskedLM
;
var
__webpack_exports__XLMRobertaForQuestionAnswering
=
__webpack_exports__
.
XLMRobertaForQuestionAnswering
;
var
__webpack_exports__XLMRobertaForSequenceClassification
=
__webpack_exports__
.
XLMRobertaForSequenceClassification
;
var
__webpack_exports__XLMRobertaForTokenClassification
=
__webpack_exports__
.
XLMRobertaForTokenClassification
;
var
__webpack_exports__XLMRobertaModel
=
__webpack_exports__
.
XLMRobertaModel
;
var
__webpack_exports__XLMRobertaPreTrainedModel
=
__webpack_exports__
.
XLMRobertaPreTrainedModel
;
var
__webpack_exports__XLMRobertaTokenizer
=
__webpack_exports__
.
XLMRobertaTokenizer
;
var
__webpack_exports__XLMTokenizer
=
__webpack_exports__
.
XLMTokenizer
;
var
__webpack_exports__XLMWithLMHeadModel
=
__webpack_exports__
.
XLMWithLMHeadModel
;
var
__webpack_exports__XVectorOutput
=
__webpack_exports__
.
XVectorOutput
;
var
__webpack_exports__YolosFeatureExtractor
=
__webpack_exports__
.
YolosFeatureExtractor
;
var
__webpack_exports__YolosForObjectDetection
=
__webpack_exports__
.
YolosForObjectDetection
;
var
__webpack_exports__YolosImageProcessor
=
__webpack_exports__
.
YolosImageProcessor
;
var
__webpack_exports__YolosModel
=
__webpack_exports__
.
YolosModel
;
var
__webpack_exports__YolosObjectDetectionOutput
=
__webpack_exports__
.
YolosObjectDetectionOutput
;
var
__webpack_exports__YolosPreTrainedModel
=
__webpack_exports__
.
YolosPreTrainedModel
;
var
__webpack_exports__ZeroShotAudioClassificationPipeline
=
__webpack_exports__
.
ZeroShotAudioClassificationPipeline
;
var
__webpack_exports__ZeroShotClassificationPipeline
=
__webpack_exports__
.
ZeroShotClassificationPipeline
;
var
__webpack_exports__ZeroShotImageClassificationPipeline
=
__webpack_exports__
.
ZeroShotImageClassificationPipeline
;
var
__webpack_exports__ZeroShotObjectDetectionPipeline
=
__webpack_exports__
.
ZeroShotObjectDetectionPipeline
;
var
__webpack_exports__bankers_round
=
__webpack_exports__
.
bankers_round
;
var
__webpack_exports__cat
=
__webpack_exports__
.
cat
;
var
__webpack_exports__cos_sim
=
__webpack_exports__
.
cos_sim
;
var
__webpack_exports__dot
=
__webpack_exports__
.
dot
;
var
__webpack_exports__dynamic_time_warping
=
__webpack_exports__
.
dynamic_time_warping
;
var
__webpack_exports__env
=
__webpack_exports__
.
env
;
var
__webpack_exports__full
=
__webpack_exports__
.
full
;
var
__webpack_exports__full_like
=
__webpack_exports__
.
full_like
;
var
__webpack_exports__getKeyValueShapes
=
__webpack_exports__
.
getKeyValueShapes
;
var
__webpack_exports__hamming
=
__webpack_exports__
.
hamming
;
var
__webpack_exports__hanning
=
__webpack_exports__
.
hanning
;
var
__webpack_exports__interpolate
=
__webpack_exports__
.
interpolate
;
var
__webpack_exports__interpolate_4d
=
__webpack_exports__
.
interpolate_4d
;
var
__webpack_exports__interpolate_data
=
__webpack_exports__
.
interpolate_data
;
var
__webpack_exports__is_chinese_char
=
__webpack_exports__
.
is_chinese_char
;
var
__webpack_exports__layer_norm
=
__webpack_exports__
.
layer_norm
;
var
__webpack_exports__log_softmax
=
__webpack_exports__
.
log_softmax
;
var
__webpack_exports__magnitude
=
__webpack_exports__
.
magnitude
;
var
__webpack_exports__matmul
=
__webpack_exports__
.
matmul
;
var
__webpack_exports__max
=
__webpack_exports__
.
max
;
var
__webpack_exports__mean
=
__webpack_exports__
.
mean
;
var
__webpack_exports__mean_pooling
=
__webpack_exports__
.
mean_pooling
;
var
__webpack_exports__medianFilter
=
__webpack_exports__
.
medianFilter
;
var
__webpack_exports__mel_filter_bank
=
__webpack_exports__
.
mel_filter_bank
;
var
__webpack_exports__min
=
__webpack_exports__
.
min
;
var
__webpack_exports__ones
=
__webpack_exports__
.
ones
;
var
__webpack_exports__ones_like
=
__webpack_exports__
.
ones_like
;
var
__webpack_exports__permute
=
__webpack_exports__
.
permute
;
var
__webpack_exports__permute_data
=
__webpack_exports__
.
permute_data
;
var
__webpack_exports__pipeline
=
__webpack_exports__
.
pipeline
;
var
__webpack_exports__quantize_embeddings
=
__webpack_exports__
.
quantize_embeddings
;
var
__webpack_exports__read_audio
=
__webpack_exports__
.
read_audio
;
var
__webpack_exports__rfft
=
__webpack_exports__
.
rfft
;
var
__webpack_exports__round
=
__webpack_exports__
.
round
;
var
__webpack_exports__softmax
=
__webpack_exports__
.
softmax
;
var
__webpack_exports__spectrogram
=
__webpack_exports__
.
spectrogram
;
var
__webpack_exports__stack
=
__webpack_exports__
.
stack
;
var
__webpack_exports__std_mean
=
__webpack_exports__
.
std_mean
;
var
__webpack_exports__topk
=
__webpack_exports__
.
topk
;
var
__webpack_exports__window_function
=
__webpack_exports__
.
window_function
;
var
__webpack_exports__zeros
=
__webpack_exports__
.
zeros
;
var
__webpack_exports__zeros_like
=
__webpack_exports__
.
zeros_like
;
export
{
__webpack_exports__ASTFeatureExtractor
as
ASTFeatureExtractor
__webpack_exports__ASTForAudioClassification
as
ASTForAudioClassification
__webpack_exports__ASTModel
as
ASTModel
__webpack_exports__ASTPreTrainedModel
as
ASTPreTrainedModel
__webpack_exports__AlbertForMaskedLM
as
AlbertForMaskedLM
__webpack_exports__AlbertForQuestionAnswering
as
AlbertForQuestionAnswering
__webpack_exports__AlbertForSequenceClassification
as
AlbertForSequenceClassification
__webpack_exports__AlbertModel
as
AlbertModel
__webpack_exports__AlbertPreTrainedModel
as
AlbertPreTrainedModel
__webpack_exports__AlbertTokenizer
as
AlbertTokenizer
__webpack_exports__AudioClassificationPipeline
as
AudioClassificationPipeline
__webpack_exports__AutoConfig
as
AutoConfig
__webpack_exports__AutoFeatureExtractor
as
AutoFeatureExtractor
__webpack_exports__AutoImageProcessor
as
AutoImageProcessor
__webpack_exports__AutoModel
as
AutoModel
__webpack_exports__AutoModelForAudioClassification
as
AutoModelForAudioClassification
__webpack_exports__AutoModelForAudioFrameClassification
as
AutoModelForAudioFrameClassification
__webpack_exports__AutoModelForCTC
as
AutoModelForCTC
__webpack_exports__AutoModelForCausalLM
as
AutoModelForCausalLM
__webpack_exports__AutoModelForDepthEstimation
as
AutoModelForDepthEstimation
__webpack_exports__AutoModelForDocumentQuestionAnswering
as
AutoModelForDocumentQuestionAnswering
__webpack_exports__AutoModelForImageClassification
as
AutoModelForImageClassification
__webpack_exports__AutoModelForImageFeatureExtraction
as
AutoModelForImageFeatureExtraction
__webpack_exports__AutoModelForImageMatting
as
AutoModelForImageMatting
__webpack_exports__AutoModelForImageSegmentation
as
AutoModelForImageSegmentation
__webpack_exports__AutoModelForImageToImage
as
AutoModelForImageToImage
__webpack_exports__AutoModelForMaskGeneration
as
AutoModelForMaskGeneration
__webpack_exports__AutoModelForMaskedLM
as
AutoModelForMaskedLM
__webpack_exports__AutoModelForNormalEstimation
as
AutoModelForNormalEstimation
__webpack_exports__AutoModelForObjectDetection
as
AutoModelForObjectDetection
__webpack_exports__AutoModelForPoseEstimation
as
AutoModelForPoseEstimation
__webpack_exports__AutoModelForQuestionAnswering
as
AutoModelForQuestionAnswering
__webpack_exports__AutoModelForSemanticSegmentation
as
AutoModelForSemanticSegmentation
__webpack_exports__AutoModelForSeq2SeqLM
as
AutoModelForSeq2SeqLM
__webpack_exports__AutoModelForSequenceClassification
as
AutoModelForSequenceClassification
__webpack_exports__AutoModelForSpeechSeq2Seq
as
AutoModelForSpeechSeq2Seq
__webpack_exports__AutoModelForTextToSpectrogram
as
AutoModelForTextToSpectrogram
__webpack_exports__AutoModelForTextToWaveform
as
AutoModelForTextToWaveform
__webpack_exports__AutoModelForTokenClassification
as
AutoModelForTokenClassification
__webpack_exports__AutoModelForUniversalSegmentation
as
AutoModelForUniversalSegmentation
__webpack_exports__AutoModelForVision2Seq
as
AutoModelForVision2Seq
__webpack_exports__AutoModelForXVector
as
AutoModelForXVector
__webpack_exports__AutoModelForZeroShotObjectDetection
as
AutoModelForZeroShotObjectDetection
__webpack_exports__AutoProcessor
as
AutoProcessor
__webpack_exports__AutoTokenizer
as
AutoTokenizer
__webpack_exports__AutomaticSpeechRecognitionPipeline
as
AutomaticSpeechRecognitionPipeline
__webpack_exports__BartForConditionalGeneration
as
BartForConditionalGeneration
__webpack_exports__BartForSequenceClassification
as
BartForSequenceClassification
__webpack_exports__BartModel
as
BartModel
__webpack_exports__BartPretrainedModel
as
BartPretrainedModel
__webpack_exports__BartTokenizer
as
BartTokenizer
__webpack_exports__BaseModelOutput
as
BaseModelOutput
__webpack_exports__BaseStreamer
as
BaseStreamer
__webpack_exports__BeitFeatureExtractor
as
BeitFeatureExtractor
__webpack_exports__BeitForImageClassification
as
BeitForImageClassification
__webpack_exports__BeitModel
as
BeitModel
__webpack_exports__BeitPreTrainedModel
as
BeitPreTrainedModel
__webpack_exports__BertForMaskedLM
as
BertForMaskedLM
__webpack_exports__BertForQuestionAnswering
as
BertForQuestionAnswering
__webpack_exports__BertForSequenceClassification
as
BertForSequenceClassification
__webpack_exports__BertForTokenClassification
as
BertForTokenClassification
__webpack_exports__BertModel
as
BertModel
__webpack_exports__BertPreTrainedModel
as
BertPreTrainedModel
__webpack_exports__BertTokenizer
as
BertTokenizer
__webpack_exports__BitImageProcessor
as
BitImageProcessor
__webpack_exports__BlenderbotForConditionalGeneration
as
BlenderbotForConditionalGeneration
__webpack_exports__BlenderbotModel
as
BlenderbotModel
__webpack_exports__BlenderbotPreTrainedModel
as
BlenderbotPreTrainedModel
__webpack_exports__BlenderbotSmallForConditionalGeneration
as
BlenderbotSmallForConditionalGeneration
__webpack_exports__BlenderbotSmallModel
as
BlenderbotSmallModel
__webpack_exports__BlenderbotSmallPreTrainedModel
as
BlenderbotSmallPreTrainedModel
__webpack_exports__BlenderbotSmallTokenizer
as
BlenderbotSmallTokenizer
__webpack_exports__BlenderbotTokenizer
as
BlenderbotTokenizer
__webpack_exports__BloomForCausalLM
as
BloomForCausalLM
__webpack_exports__BloomModel
as
BloomModel
__webpack_exports__BloomPreTrainedModel
as
BloomPreTrainedModel
__webpack_exports__BloomTokenizer
as
BloomTokenizer
__webpack_exports__CLIPFeatureExtractor
as
CLIPFeatureExtractor
__webpack_exports__CLIPImageProcessor
as
CLIPImageProcessor
__webpack_exports__CLIPModel
as
CLIPModel
__webpack_exports__CLIPPreTrainedModel
as
CLIPPreTrainedModel
__webpack_exports__CLIPSegForImageSegmentation
as
CLIPSegForImageSegmentation
__webpack_exports__CLIPSegModel
as
CLIPSegModel
__webpack_exports__CLIPSegPreTrainedModel
as
CLIPSegPreTrainedModel
__webpack_exports__CLIPTextModel
as
CLIPTextModel
__webpack_exports__CLIPTextModelWithProjection
as
CLIPTextModelWithProjection
__webpack_exports__CLIPTokenizer
as
CLIPTokenizer
__webpack_exports__CLIPVisionModel
as
CLIPVisionModel
__webpack_exports__CLIPVisionModelWithProjection
as
CLIPVisionModelWithProjection
__webpack_exports__CamembertForMaskedLM
as
CamembertForMaskedLM
__webpack_exports__CamembertForQuestionAnswering
as
CamembertForQuestionAnswering
__webpack_exports__CamembertForSequenceClassification
as
CamembertForSequenceClassification
__webpack_exports__CamembertForTokenClassification
as
CamembertForTokenClassification
__webpack_exports__CamembertModel
as
CamembertModel
__webpack_exports__CamembertPreTrainedModel
as
CamembertPreTrainedModel
__webpack_exports__CamembertTokenizer
as
CamembertTokenizer
__webpack_exports__CausalLMOutput
as
CausalLMOutput
__webpack_exports__CausalLMOutputWithPast
as
CausalLMOutputWithPast
__webpack_exports__ChineseCLIPFeatureExtractor
as
ChineseCLIPFeatureExtractor
__webpack_exports__ChineseCLIPModel
as
ChineseCLIPModel
__webpack_exports__ChineseCLIPPreTrainedModel
as
ChineseCLIPPreTrainedModel
__webpack_exports__ClapAudioModelWithProjection
as
ClapAudioModelWithProjection
__webpack_exports__ClapFeatureExtractor
as
ClapFeatureExtractor
__webpack_exports__ClapModel
as
ClapModel
__webpack_exports__ClapPreTrainedModel
as
ClapPreTrainedModel
__webpack_exports__ClapTextModelWithProjection
as
ClapTextModelWithProjection
__webpack_exports__ClassifierFreeGuidanceLogitsProcessor
as
ClassifierFreeGuidanceLogitsProcessor
__webpack_exports__CodeGenForCausalLM
as
CodeGenForCausalLM
__webpack_exports__CodeGenModel
as
CodeGenModel
__webpack_exports__CodeGenPreTrainedModel
as
CodeGenPreTrainedModel
__webpack_exports__CodeGenTokenizer
as
CodeGenTokenizer
__webpack_exports__CodeLlamaTokenizer
as
CodeLlamaTokenizer
__webpack_exports__CohereForCausalLM
as
CohereForCausalLM
__webpack_exports__CohereModel
as
CohereModel
__webpack_exports__CoherePreTrainedModel
as
CoherePreTrainedModel
__webpack_exports__CohereTokenizer
as
CohereTokenizer
__webpack_exports__ConvBertForMaskedLM
as
ConvBertForMaskedLM
__webpack_exports__ConvBertForQuestionAnswering
as
ConvBertForQuestionAnswering
__webpack_exports__ConvBertForSequenceClassification
as
ConvBertForSequenceClassification
__webpack_exports__ConvBertForTokenClassification
as
ConvBertForTokenClassification
__webpack_exports__ConvBertModel
as
ConvBertModel
__webpack_exports__ConvBertPreTrainedModel
as
ConvBertPreTrainedModel
__webpack_exports__ConvBertTokenizer
as
ConvBertTokenizer
__webpack_exports__ConvNextFeatureExtractor
as
ConvNextFeatureExtractor
__webpack_exports__ConvNextForImageClassification
as
ConvNextForImageClassification
__webpack_exports__ConvNextImageProcessor
as
ConvNextImageProcessor
__webpack_exports__ConvNextModel
as
ConvNextModel
__webpack_exports__ConvNextPreTrainedModel
as
ConvNextPreTrainedModel
__webpack_exports__ConvNextV2ForImageClassification
as
ConvNextV2ForImageClassification
__webpack_exports__ConvNextV2Model
as
ConvNextV2Model
__webpack_exports__ConvNextV2PreTrainedModel
as
ConvNextV2PreTrainedModel
__webpack_exports__DPTFeatureExtractor
as
DPTFeatureExtractor
__webpack_exports__DPTForDepthEstimation
as
DPTForDepthEstimation
__webpack_exports__DPTImageProcessor
as
DPTImageProcessor
__webpack_exports__DPTModel
as
DPTModel
__webpack_exports__DPTPreTrainedModel
as
DPTPreTrainedModel
__webpack_exports__DebertaForMaskedLM
as
DebertaForMaskedLM
__webpack_exports__DebertaForQuestionAnswering
as
DebertaForQuestionAnswering
__webpack_exports__DebertaForSequenceClassification
as
DebertaForSequenceClassification
__webpack_exports__DebertaForTokenClassification
as
DebertaForTokenClassification
__webpack_exports__DebertaModel
as
DebertaModel
__webpack_exports__DebertaPreTrainedModel
as
DebertaPreTrainedModel
__webpack_exports__DebertaTokenizer
as
DebertaTokenizer
__webpack_exports__DebertaV2ForMaskedLM
as
DebertaV2ForMaskedLM
__webpack_exports__DebertaV2ForQuestionAnswering
as
DebertaV2ForQuestionAnswering
__webpack_exports__DebertaV2ForSequenceClassification
as
DebertaV2ForSequenceClassification
__webpack_exports__DebertaV2ForTokenClassification
as
DebertaV2ForTokenClassification
__webpack_exports__DebertaV2Model
as
DebertaV2Model
__webpack_exports__DebertaV2PreTrainedModel
as
DebertaV2PreTrainedModel
__webpack_exports__DebertaV2Tokenizer
as
DebertaV2Tokenizer
__webpack_exports__DecisionTransformerModel
as
DecisionTransformerModel
__webpack_exports__DecisionTransformerPreTrainedModel
as
DecisionTransformerPreTrainedModel
__webpack_exports__DeiTFeatureExtractor
as
DeiTFeatureExtractor
__webpack_exports__DeiTForImageClassification
as
DeiTForImageClassification
__webpack_exports__DeiTImageProcessor
as
DeiTImageProcessor
__webpack_exports__DeiTModel
as
DeiTModel
__webpack_exports__DeiTPreTrainedModel
as
DeiTPreTrainedModel
__webpack_exports__DepthAnythingForDepthEstimation
as
DepthAnythingForDepthEstimation
__webpack_exports__DepthAnythingPreTrainedModel
as
DepthAnythingPreTrainedModel
__webpack_exports__DepthEstimationPipeline
as
DepthEstimationPipeline
__webpack_exports__DepthProForDepthEstimation
as
DepthProForDepthEstimation
__webpack_exports__DepthProPreTrainedModel
as
DepthProPreTrainedModel
__webpack_exports__DetrFeatureExtractor
as
DetrFeatureExtractor
__webpack_exports__DetrForObjectDetection
as
DetrForObjectDetection
__webpack_exports__DetrForSegmentation
as
DetrForSegmentation
__webpack_exports__DetrImageProcessor
as
DetrImageProcessor
__webpack_exports__DetrModel
as
DetrModel
__webpack_exports__DetrObjectDetectionOutput
as
DetrObjectDetectionOutput
__webpack_exports__DetrPreTrainedModel
as
DetrPreTrainedModel
__webpack_exports__DetrSegmentationOutput
as
DetrSegmentationOutput
__webpack_exports__Dinov2ForImageClassification
as
Dinov2ForImageClassification
__webpack_exports__Dinov2Model
as
Dinov2Model
__webpack_exports__Dinov2PreTrainedModel
as
Dinov2PreTrainedModel
__webpack_exports__DistilBertForMaskedLM
as
DistilBertForMaskedLM
__webpack_exports__DistilBertForQuestionAnswering
as
DistilBertForQuestionAnswering
__webpack_exports__DistilBertForSequenceClassification
as
DistilBertForSequenceClassification
__webpack_exports__DistilBertForTokenClassification
as
DistilBertForTokenClassification
__webpack_exports__DistilBertModel
as
DistilBertModel
__webpack_exports__DistilBertPreTrainedModel
as
DistilBertPreTrainedModel
__webpack_exports__DistilBertTokenizer
as
DistilBertTokenizer
__webpack_exports__DocumentQuestionAnsweringPipeline
as
DocumentQuestionAnsweringPipeline
__webpack_exports__DonutFeatureExtractor
as
DonutFeatureExtractor
__webpack_exports__DonutImageProcessor
as
DonutImageProcessor
__webpack_exports__DonutSwinModel
as
DonutSwinModel
__webpack_exports__DonutSwinPreTrainedModel
as
DonutSwinPreTrainedModel
__webpack_exports__EfficientNetForImageClassification
as
EfficientNetForImageClassification
__webpack_exports__EfficientNetImageProcessor
as
EfficientNetImageProcessor
__webpack_exports__EfficientNetModel
as
EfficientNetModel
__webpack_exports__EfficientNetPreTrainedModel
as
EfficientNetPreTrainedModel
__webpack_exports__ElectraForMaskedLM
as
ElectraForMaskedLM
__webpack_exports__ElectraForQuestionAnswering
as
ElectraForQuestionAnswering
__webpack_exports__ElectraForSequenceClassification
as
ElectraForSequenceClassification
__webpack_exports__ElectraForTokenClassification
as
ElectraForTokenClassification
__webpack_exports__ElectraModel
as
ElectraModel
__webpack_exports__ElectraPreTrainedModel
as
ElectraPreTrainedModel
__webpack_exports__ElectraTokenizer
as
ElectraTokenizer
__webpack_exports__EosTokenCriteria
as
EosTokenCriteria
__webpack_exports__EsmForMaskedLM
as
EsmForMaskedLM
__webpack_exports__EsmForSequenceClassification
as
EsmForSequenceClassification
__webpack_exports__EsmForTokenClassification
as
EsmForTokenClassification
__webpack_exports__EsmModel
as
EsmModel
__webpack_exports__EsmPreTrainedModel
as
EsmPreTrainedModel
__webpack_exports__EsmTokenizer
as
EsmTokenizer
__webpack_exports__FFT
as
FFT
__webpack_exports__FalconForCausalLM
as
FalconForCausalLM
__webpack_exports__FalconModel
as
FalconModel
__webpack_exports__FalconPreTrainedModel
as
FalconPreTrainedModel
__webpack_exports__FalconTokenizer
as
FalconTokenizer
__webpack_exports__FastViTForImageClassification
as
FastViTForImageClassification
__webpack_exports__FastViTModel
as
FastViTModel
__webpack_exports__FastViTPreTrainedModel
as
FastViTPreTrainedModel
__webpack_exports__FeatureExtractionPipeline
as
FeatureExtractionPipeline
__webpack_exports__FeatureExtractor
as
FeatureExtractor
__webpack_exports__FillMaskPipeline
as
FillMaskPipeline
__webpack_exports__Florence2ForConditionalGeneration
as
Florence2ForConditionalGeneration
__webpack_exports__Florence2PreTrainedModel
as
Florence2PreTrainedModel
__webpack_exports__Florence2Processor
as
Florence2Processor
__webpack_exports__ForcedBOSTokenLogitsProcessor
as
ForcedBOSTokenLogitsProcessor
__webpack_exports__ForcedEOSTokenLogitsProcessor
as
ForcedEOSTokenLogitsProcessor
__webpack_exports__GLPNFeatureExtractor
as
GLPNFeatureExtractor
__webpack_exports__GLPNForDepthEstimation
as
GLPNForDepthEstimation
__webpack_exports__GLPNModel
as
GLPNModel
__webpack_exports__GLPNPreTrainedModel
as
GLPNPreTrainedModel
__webpack_exports__GPT2LMHeadModel
as
GPT2LMHeadModel
__webpack_exports__GPT2Model
as
GPT2Model
__webpack_exports__GPT2PreTrainedModel
as
GPT2PreTrainedModel
__webpack_exports__GPT2Tokenizer
as
GPT2Tokenizer
__webpack_exports__GPTBigCodeForCausalLM
as
GPTBigCodeForCausalLM
__webpack_exports__GPTBigCodeModel
as
GPTBigCodeModel
__webpack_exports__GPTBigCodePreTrainedModel
as
GPTBigCodePreTrainedModel
__webpack_exports__GPTJForCausalLM
as
GPTJForCausalLM
__webpack_exports__GPTJModel
as
GPTJModel
__webpack_exports__GPTJPreTrainedModel
as
GPTJPreTrainedModel
__webpack_exports__GPTNeoForCausalLM
as
GPTNeoForCausalLM
__webpack_exports__GPTNeoModel
as
GPTNeoModel
__webpack_exports__GPTNeoPreTrainedModel
as
GPTNeoPreTrainedModel
__webpack_exports__GPTNeoXForCausalLM
as
GPTNeoXForCausalLM
__webpack_exports__GPTNeoXModel
as
GPTNeoXModel
__webpack_exports__GPTNeoXPreTrainedModel
as
GPTNeoXPreTrainedModel
__webpack_exports__GPTNeoXTokenizer
as
GPTNeoXTokenizer
__webpack_exports__Gemma2ForCausalLM
as
Gemma2ForCausalLM
__webpack_exports__Gemma2Model
as
Gemma2Model
__webpack_exports__Gemma2PreTrainedModel
as
Gemma2PreTrainedModel
__webpack_exports__GemmaForCausalLM
as
GemmaForCausalLM
__webpack_exports__GemmaModel
as
GemmaModel
__webpack_exports__GemmaPreTrainedModel
as
GemmaPreTrainedModel
__webpack_exports__GemmaTokenizer
as
GemmaTokenizer
__webpack_exports__GraniteForCausalLM
as
GraniteForCausalLM
__webpack_exports__GraniteModel
as
GraniteModel
__webpack_exports__GranitePreTrainedModel
as
GranitePreTrainedModel
__webpack_exports__Grok1Tokenizer
as
Grok1Tokenizer
__webpack_exports__GroupViTModel
as
GroupViTModel
__webpack_exports__GroupViTPreTrainedModel
as
GroupViTPreTrainedModel
__webpack_exports__HerbertTokenizer
as
HerbertTokenizer
__webpack_exports__HieraForImageClassification
as
HieraForImageClassification
__webpack_exports__HieraModel
as
HieraModel
__webpack_exports__HieraPreTrainedModel
as
HieraPreTrainedModel
__webpack_exports__HubertForCTC
as
HubertForCTC
__webpack_exports__HubertForSequenceClassification
as
HubertForSequenceClassification
__webpack_exports__HubertModel
as
HubertModel
__webpack_exports__HubertPreTrainedModel
as
HubertPreTrainedModel
__webpack_exports__ImageClassificationPipeline
as
ImageClassificationPipeline
__webpack_exports__ImageFeatureExtractionPipeline
as
ImageFeatureExtractionPipeline
__webpack_exports__ImageFeatureExtractor
as
ImageFeatureExtractor
__webpack_exports__ImageMattingOutput
as
ImageMattingOutput
__webpack_exports__ImageProcessor
as
ImageProcessor
__webpack_exports__ImageSegmentationPipeline
as
ImageSegmentationPipeline
__webpack_exports__ImageToImagePipeline
as
ImageToImagePipeline
__webpack_exports__ImageToTextPipeline
as
ImageToTextPipeline
__webpack_exports__InterruptableStoppingCriteria
as
InterruptableStoppingCriteria
__webpack_exports__JAISLMHeadModel
as
JAISLMHeadModel
__webpack_exports__JAISModel
as
JAISModel
__webpack_exports__JAISPreTrainedModel
as
JAISPreTrainedModel
__webpack_exports__JinaCLIPImageProcessor
as
JinaCLIPImageProcessor
__webpack_exports__JinaCLIPModel
as
JinaCLIPModel
__webpack_exports__JinaCLIPPreTrainedModel
as
JinaCLIPPreTrainedModel
__webpack_exports__JinaCLIPProcessor
as
JinaCLIPProcessor
__webpack_exports__JinaCLIPTextModel
as
JinaCLIPTextModel
__webpack_exports__JinaCLIPVisionModel
as
JinaCLIPVisionModel
__webpack_exports__LlamaForCausalLM
as
LlamaForCausalLM
__webpack_exports__LlamaModel
as
LlamaModel
__webpack_exports__LlamaPreTrainedModel
as
LlamaPreTrainedModel
__webpack_exports__LlamaTokenizer
as
LlamaTokenizer
__webpack_exports__LlavaForConditionalGeneration
as
LlavaForConditionalGeneration
__webpack_exports__LlavaOnevisionForConditionalGeneration
as
LlavaOnevisionForConditionalGeneration
__webpack_exports__LlavaOnevisionImageProcessor
as
LlavaOnevisionImageProcessor
__webpack_exports__LlavaPreTrainedModel
as
LlavaPreTrainedModel
__webpack_exports__LogitsProcessor
as
LogitsProcessor
__webpack_exports__LogitsProcessorList
as
LogitsProcessorList
__webpack_exports__LogitsWarper
as
LogitsWarper
__webpack_exports__LongT5ForConditionalGeneration
as
LongT5ForConditionalGeneration
__webpack_exports__LongT5Model
as
LongT5Model
__webpack_exports__LongT5PreTrainedModel
as
LongT5PreTrainedModel
__webpack_exports__M2M100ForConditionalGeneration
as
M2M100ForConditionalGeneration
__webpack_exports__M2M100Model
as
M2M100Model
__webpack_exports__M2M100PreTrainedModel
as
M2M100PreTrainedModel
__webpack_exports__M2M100Tokenizer
as
M2M100Tokenizer
__webpack_exports__MBart50Tokenizer
as
MBart50Tokenizer
__webpack_exports__MBartForCausalLM
as
MBartForCausalLM
__webpack_exports__MBartForConditionalGeneration
as
MBartForConditionalGeneration
__webpack_exports__MBartForSequenceClassification
as
MBartForSequenceClassification
__webpack_exports__MBartModel
as
MBartModel
__webpack_exports__MBartPreTrainedModel
as
MBartPreTrainedModel
__webpack_exports__MBartTokenizer
as
MBartTokenizer
__webpack_exports__MPNetForMaskedLM
as
MPNetForMaskedLM
__webpack_exports__MPNetForQuestionAnswering
as
MPNetForQuestionAnswering
__webpack_exports__MPNetForSequenceClassification
as
MPNetForSequenceClassification
__webpack_exports__MPNetForTokenClassification
as
MPNetForTokenClassification
__webpack_exports__MPNetModel
as
MPNetModel
__webpack_exports__MPNetPreTrainedModel
as
MPNetPreTrainedModel
__webpack_exports__MPNetTokenizer
as
MPNetTokenizer
__webpack_exports__MT5ForConditionalGeneration
as
MT5ForConditionalGeneration
__webpack_exports__MT5Model
as
MT5Model
__webpack_exports__MT5PreTrainedModel
as
MT5PreTrainedModel
__webpack_exports__MarianMTModel
as
MarianMTModel
__webpack_exports__MarianModel
as
MarianModel
__webpack_exports__MarianPreTrainedModel
as
MarianPreTrainedModel
__webpack_exports__MarianTokenizer
as
MarianTokenizer
__webpack_exports__Mask2FormerImageProcessor
as
Mask2FormerImageProcessor
__webpack_exports__MaskFormerFeatureExtractor
as
MaskFormerFeatureExtractor
__webpack_exports__MaskFormerForInstanceSegmentation
as
MaskFormerForInstanceSegmentation
__webpack_exports__MaskFormerImageProcessor
as
MaskFormerImageProcessor
__webpack_exports__MaskFormerModel
as
MaskFormerModel
__webpack_exports__MaskFormerPreTrainedModel
as
MaskFormerPreTrainedModel
__webpack_exports__MaskedLMOutput
as
MaskedLMOutput
__webpack_exports__MaxLengthCriteria
as
MaxLengthCriteria
__webpack_exports__MgpstrForSceneTextRecognition
as
MgpstrForSceneTextRecognition
__webpack_exports__MgpstrModelOutput
as
MgpstrModelOutput
__webpack_exports__MgpstrPreTrainedModel
as
MgpstrPreTrainedModel
__webpack_exports__MgpstrProcessor
as
MgpstrProcessor
__webpack_exports__MgpstrTokenizer
as
MgpstrTokenizer
__webpack_exports__MinLengthLogitsProcessor
as
MinLengthLogitsProcessor
__webpack_exports__MinNewTokensLengthLogitsProcessor
as
MinNewTokensLengthLogitsProcessor
__webpack_exports__MistralForCausalLM
as
MistralForCausalLM
__webpack_exports__MistralModel
as
MistralModel
__webpack_exports__MistralPreTrainedModel
as
MistralPreTrainedModel
__webpack_exports__MobileBertForMaskedLM
as
MobileBertForMaskedLM
__webpack_exports__MobileBertForQuestionAnswering
as
MobileBertForQuestionAnswering
__webpack_exports__MobileBertForSequenceClassification
as
MobileBertForSequenceClassification
__webpack_exports__MobileBertModel
as
MobileBertModel
__webpack_exports__MobileBertPreTrainedModel
as
MobileBertPreTrainedModel
__webpack_exports__MobileBertTokenizer
as
MobileBertTokenizer
__webpack_exports__MobileLLMForCausalLM
as
MobileLLMForCausalLM
__webpack_exports__MobileLLMModel
as
MobileLLMModel
__webpack_exports__MobileLLMPreTrainedModel
as
MobileLLMPreTrainedModel
__webpack_exports__MobileNetV1FeatureExtractor
as
MobileNetV1FeatureExtractor
__webpack_exports__MobileNetV1ForImageClassification
as
MobileNetV1ForImageClassification
__webpack_exports__MobileNetV1ImageProcessor
as
MobileNetV1ImageProcessor
__webpack_exports__MobileNetV1Model
as
MobileNetV1Model
__webpack_exports__MobileNetV1PreTrainedModel
as
MobileNetV1PreTrainedModel
__webpack_exports__MobileNetV2FeatureExtractor
as
MobileNetV2FeatureExtractor
__webpack_exports__MobileNetV2ForImageClassification
as
MobileNetV2ForImageClassification
__webpack_exports__MobileNetV2ImageProcessor
as
MobileNetV2ImageProcessor
__webpack_exports__MobileNetV2Model
as
MobileNetV2Model
__webpack_exports__MobileNetV2PreTrainedModel
as
MobileNetV2PreTrainedModel
__webpack_exports__MobileNetV3FeatureExtractor
as
MobileNetV3FeatureExtractor
__webpack_exports__MobileNetV3ForImageClassification
as
MobileNetV3ForImageClassification
__webpack_exports__MobileNetV3ImageProcessor
as
MobileNetV3ImageProcessor
__webpack_exports__MobileNetV3Model
as
MobileNetV3Model
__webpack_exports__MobileNetV3PreTrainedModel
as
MobileNetV3PreTrainedModel
__webpack_exports__MobileNetV4FeatureExtractor
as
MobileNetV4FeatureExtractor
__webpack_exports__MobileNetV4ForImageClassification
as
MobileNetV4ForImageClassification
__webpack_exports__MobileNetV4ImageProcessor
as
MobileNetV4ImageProcessor
__webpack_exports__MobileNetV4Model
as
MobileNetV4Model
__webpack_exports__MobileNetV4PreTrainedModel
as
MobileNetV4PreTrainedModel
__webpack_exports__MobileViTFeatureExtractor
as
MobileViTFeatureExtractor
__webpack_exports__MobileViTForImageClassification
as
MobileViTForImageClassification
__webpack_exports__MobileViTImageProcessor
as
MobileViTImageProcessor
__webpack_exports__MobileViTModel
as
MobileViTModel
__webpack_exports__MobileViTPreTrainedModel
as
MobileViTPreTrainedModel
__webpack_exports__MobileViTV2ForImageClassification
as
MobileViTV2ForImageClassification
__webpack_exports__MobileViTV2Model
as
MobileViTV2Model
__webpack_exports__MobileViTV2PreTrainedModel
as
MobileViTV2PreTrainedModel
__webpack_exports__ModelOutput
as
ModelOutput
__webpack_exports__Moondream1ForConditionalGeneration
as
Moondream1ForConditionalGeneration
__webpack_exports__MptForCausalLM
as
MptForCausalLM
__webpack_exports__MptModel
as
MptModel
__webpack_exports__MptPreTrainedModel
as
MptPreTrainedModel
__webpack_exports__MultiModalityCausalLM
as
MultiModalityCausalLM
__webpack_exports__MultiModalityPreTrainedModel
as
MultiModalityPreTrainedModel
__webpack_exports__MusicgenForCausalLM
as
MusicgenForCausalLM
__webpack_exports__MusicgenForConditionalGeneration
as
MusicgenForConditionalGeneration
__webpack_exports__MusicgenModel
as
MusicgenModel
__webpack_exports__MusicgenPreTrainedModel
as
MusicgenPreTrainedModel
__webpack_exports__NllbTokenizer
as
NllbTokenizer
__webpack_exports__NoBadWordsLogitsProcessor
as
NoBadWordsLogitsProcessor
__webpack_exports__NoRepeatNGramLogitsProcessor
as
NoRepeatNGramLogitsProcessor
__webpack_exports__NomicBertModel
as
NomicBertModel
__webpack_exports__NomicBertPreTrainedModel
as
NomicBertPreTrainedModel
__webpack_exports__NougatImageProcessor
as
NougatImageProcessor
__webpack_exports__NougatTokenizer
as
NougatTokenizer
__webpack_exports__OPTForCausalLM
as
OPTForCausalLM
__webpack_exports__OPTModel
as
OPTModel
__webpack_exports__OPTPreTrainedModel
as
OPTPreTrainedModel
__webpack_exports__ObjectDetectionPipeline
as
ObjectDetectionPipeline
__webpack_exports__OlmoForCausalLM
as
OlmoForCausalLM
__webpack_exports__OlmoModel
as
OlmoModel
__webpack_exports__OlmoPreTrainedModel
as
OlmoPreTrainedModel
__webpack_exports__OpenELMForCausalLM
as
OpenELMForCausalLM
__webpack_exports__OpenELMModel
as
OpenELMModel
__webpack_exports__OpenELMPreTrainedModel
as
OpenELMPreTrainedModel
__webpack_exports__OwlViTFeatureExtractor
as
OwlViTFeatureExtractor
__webpack_exports__OwlViTForObjectDetection
as
OwlViTForObjectDetection
__webpack_exports__OwlViTImageProcessor
as
OwlViTImageProcessor
__webpack_exports__OwlViTModel
as
OwlViTModel
__webpack_exports__OwlViTPreTrainedModel
as
OwlViTPreTrainedModel
__webpack_exports__OwlViTProcessor
as
OwlViTProcessor
__webpack_exports__Owlv2ForObjectDetection
as
Owlv2ForObjectDetection
__webpack_exports__Owlv2ImageProcessor
as
Owlv2ImageProcessor
__webpack_exports__Owlv2Model
as
Owlv2Model
__webpack_exports__Owlv2PreTrainedModel
as
Owlv2PreTrainedModel
__webpack_exports__PatchTSMixerForPrediction
as
PatchTSMixerForPrediction
__webpack_exports__PatchTSMixerModel
as
PatchTSMixerModel
__webpack_exports__PatchTSMixerPreTrainedModel
as
PatchTSMixerPreTrainedModel
__webpack_exports__PatchTSTForPrediction
as
PatchTSTForPrediction
__webpack_exports__PatchTSTModel
as
PatchTSTModel
__webpack_exports__PatchTSTPreTrainedModel
as
PatchTSTPreTrainedModel
__webpack_exports__Phi3ForCausalLM
as
Phi3ForCausalLM
__webpack_exports__Phi3Model
as
Phi3Model
__webpack_exports__Phi3PreTrainedModel
as
Phi3PreTrainedModel
__webpack_exports__PhiForCausalLM
as
PhiForCausalLM
__webpack_exports__PhiModel
as
PhiModel
__webpack_exports__PhiPreTrainedModel
as
PhiPreTrainedModel
__webpack_exports__Pipeline
as
Pipeline
__webpack_exports__PreTrainedModel
as
PreTrainedModel
__webpack_exports__PreTrainedTokenizer
as
PreTrainedTokenizer
__webpack_exports__PretrainedConfig
as
PretrainedConfig
__webpack_exports__PretrainedMixin
as
PretrainedMixin
__webpack_exports__Processor
as
Processor
__webpack_exports__PvtForImageClassification
as
PvtForImageClassification
__webpack_exports__PvtImageProcessor
as
PvtImageProcessor
__webpack_exports__PvtModel
as
PvtModel
__webpack_exports__PvtPreTrainedModel
as
PvtPreTrainedModel
__webpack_exports__PyAnnoteFeatureExtractor
as
PyAnnoteFeatureExtractor
__webpack_exports__PyAnnoteForAudioFrameClassification
as
PyAnnoteForAudioFrameClassification
__webpack_exports__PyAnnoteModel
as
PyAnnoteModel
__webpack_exports__PyAnnotePreTrainedModel
as
PyAnnotePreTrainedModel
__webpack_exports__PyAnnoteProcessor
as
PyAnnoteProcessor
__webpack_exports__QuestionAnsweringModelOutput
as
QuestionAnsweringModelOutput
__webpack_exports__QuestionAnsweringPipeline
as
QuestionAnsweringPipeline
__webpack_exports__Qwen2ForCausalLM
as
Qwen2ForCausalLM
__webpack_exports__Qwen2Model
as
Qwen2Model
__webpack_exports__Qwen2PreTrainedModel
as
Qwen2PreTrainedModel
__webpack_exports__Qwen2Tokenizer
as
Qwen2Tokenizer
__webpack_exports__Qwen2VLForConditionalGeneration
as
Qwen2VLForConditionalGeneration
__webpack_exports__Qwen2VLImageProcessor
as
Qwen2VLImageProcessor
__webpack_exports__Qwen2VLPreTrainedModel
as
Qwen2VLPreTrainedModel
__webpack_exports__Qwen2VLProcessor
as
Qwen2VLProcessor
__webpack_exports__RTDetrForObjectDetection
as
RTDetrForObjectDetection
__webpack_exports__RTDetrImageProcessor
as
RTDetrImageProcessor
__webpack_exports__RTDetrModel
as
RTDetrModel
__webpack_exports__RTDetrObjectDetectionOutput
as
RTDetrObjectDetectionOutput
__webpack_exports__RTDetrPreTrainedModel
as
RTDetrPreTrainedModel
__webpack_exports__RawImage
as
RawImage
__webpack_exports__RepetitionPenaltyLogitsProcessor
as
RepetitionPenaltyLogitsProcessor
__webpack_exports__ResNetForImageClassification
as
ResNetForImageClassification
__webpack_exports__ResNetModel
as
ResNetModel
__webpack_exports__ResNetPreTrainedModel
as
ResNetPreTrainedModel
__webpack_exports__RoFormerForMaskedLM
as
RoFormerForMaskedLM
__webpack_exports__RoFormerForQuestionAnswering
as
RoFormerForQuestionAnswering
__webpack_exports__RoFormerForSequenceClassification
as
RoFormerForSequenceClassification
__webpack_exports__RoFormerForTokenClassification
as
RoFormerForTokenClassification
__webpack_exports__RoFormerModel
as
RoFormerModel
__webpack_exports__RoFormerPreTrainedModel
as
RoFormerPreTrainedModel
__webpack_exports__RoFormerTokenizer
as
RoFormerTokenizer
__webpack_exports__RobertaForMaskedLM
as
RobertaForMaskedLM
__webpack_exports__RobertaForQuestionAnswering
as
RobertaForQuestionAnswering
__webpack_exports__RobertaForSequenceClassification
as
RobertaForSequenceClassification
__webpack_exports__RobertaForTokenClassification
as
RobertaForTokenClassification
__webpack_exports__RobertaModel
as
RobertaModel
__webpack_exports__RobertaPreTrainedModel
as
RobertaPreTrainedModel
__webpack_exports__RobertaTokenizer
as
RobertaTokenizer
__webpack_exports__SamImageProcessor
as
SamImageProcessor
__webpack_exports__SamImageSegmentationOutput
as
SamImageSegmentationOutput
__webpack_exports__SamModel
as
SamModel
__webpack_exports__SamPreTrainedModel
as
SamPreTrainedModel
__webpack_exports__SamProcessor
as
SamProcessor
__webpack_exports__SapiensForDepthEstimation
as
SapiensForDepthEstimation
__webpack_exports__SapiensForNormalEstimation
as
SapiensForNormalEstimation
__webpack_exports__SapiensForSemanticSegmentation
as
SapiensForSemanticSegmentation
__webpack_exports__SapiensPreTrainedModel
as
SapiensPreTrainedModel
__webpack_exports__SeamlessM4TFeatureExtractor
as
SeamlessM4TFeatureExtractor
__webpack_exports__SegformerFeatureExtractor
as
SegformerFeatureExtractor
__webpack_exports__SegformerForImageClassification
as
SegformerForImageClassification
__webpack_exports__SegformerForSemanticSegmentation
as
SegformerForSemanticSegmentation
__webpack_exports__SegformerImageProcessor
as
SegformerImageProcessor
__webpack_exports__SegformerModel
as
SegformerModel
__webpack_exports__SegformerPreTrainedModel
as
SegformerPreTrainedModel
__webpack_exports__Seq2SeqLMOutput
as
Seq2SeqLMOutput
__webpack_exports__SequenceClassifierOutput
as
SequenceClassifierOutput
__webpack_exports__SiglipImageProcessor
as
SiglipImageProcessor
__webpack_exports__SiglipModel
as
SiglipModel
__webpack_exports__SiglipPreTrainedModel
as
SiglipPreTrainedModel
__webpack_exports__SiglipTextModel
as
SiglipTextModel
__webpack_exports__SiglipTokenizer
as
SiglipTokenizer
__webpack_exports__SiglipVisionModel
as
SiglipVisionModel
__webpack_exports__SpeechT5FeatureExtractor
as
SpeechT5FeatureExtractor
__webpack_exports__SpeechT5ForSpeechToText
as
SpeechT5ForSpeechToText
__webpack_exports__SpeechT5ForTextToSpeech
as
SpeechT5ForTextToSpeech
__webpack_exports__SpeechT5HifiGan
as
SpeechT5HifiGan
__webpack_exports__SpeechT5Model
as
SpeechT5Model
__webpack_exports__SpeechT5PreTrainedModel
as
SpeechT5PreTrainedModel
__webpack_exports__SpeechT5Processor
as
SpeechT5Processor
__webpack_exports__SpeechT5Tokenizer
as
SpeechT5Tokenizer
__webpack_exports__SqueezeBertForMaskedLM
as
SqueezeBertForMaskedLM
__webpack_exports__SqueezeBertForQuestionAnswering
as
SqueezeBertForQuestionAnswering
__webpack_exports__SqueezeBertForSequenceClassification
as
SqueezeBertForSequenceClassification
__webpack_exports__SqueezeBertModel
as
SqueezeBertModel
__webpack_exports__SqueezeBertPreTrainedModel
as
SqueezeBertPreTrainedModel
__webpack_exports__SqueezeBertTokenizer
as
SqueezeBertTokenizer
__webpack_exports__StableLmForCausalLM
as
StableLmForCausalLM
__webpack_exports__StableLmModel
as
StableLmModel
__webpack_exports__StableLmPreTrainedModel
as
StableLmPreTrainedModel
__webpack_exports__Starcoder2ForCausalLM
as
Starcoder2ForCausalLM
__webpack_exports__Starcoder2Model
as
Starcoder2Model
__webpack_exports__Starcoder2PreTrainedModel
as
Starcoder2PreTrainedModel
__webpack_exports__StoppingCriteria
as
StoppingCriteria
__webpack_exports__StoppingCriteriaList
as
StoppingCriteriaList
__webpack_exports__SummarizationPipeline
as
SummarizationPipeline
__webpack_exports__SuppressTokensAtBeginLogitsProcessor
as
SuppressTokensAtBeginLogitsProcessor
__webpack_exports__Swin2SRForImageSuperResolution
as
Swin2SRForImageSuperResolution
__webpack_exports__Swin2SRImageProcessor
as
Swin2SRImageProcessor
__webpack_exports__Swin2SRModel
as
Swin2SRModel
__webpack_exports__Swin2SRPreTrainedModel
as
Swin2SRPreTrainedModel
__webpack_exports__SwinForImageClassification
as
SwinForImageClassification
__webpack_exports__SwinModel
as
SwinModel
__webpack_exports__SwinPreTrainedModel
as
SwinPreTrainedModel
__webpack_exports__T5ForConditionalGeneration
as
T5ForConditionalGeneration
__webpack_exports__T5Model
as
T5Model
__webpack_exports__T5PreTrainedModel
as
T5PreTrainedModel
__webpack_exports__T5Tokenizer
as
T5Tokenizer
__webpack_exports__TableTransformerForObjectDetection
as
TableTransformerForObjectDetection
__webpack_exports__TableTransformerModel
as
TableTransformerModel
__webpack_exports__TableTransformerObjectDetectionOutput
as
TableTransformerObjectDetectionOutput
__webpack_exports__TableTransformerPreTrainedModel
as
TableTransformerPreTrainedModel
__webpack_exports__TemperatureLogitsWarper
as
TemperatureLogitsWarper
__webpack_exports__Tensor
as
Tensor
__webpack_exports__Text2TextGenerationPipeline
as
Text2TextGenerationPipeline
__webpack_exports__TextClassificationPipeline
as
TextClassificationPipeline
__webpack_exports__TextGenerationPipeline
as
TextGenerationPipeline
__webpack_exports__TextStreamer
as
TextStreamer
__webpack_exports__TextToAudioPipeline
as
TextToAudioPipeline
__webpack_exports__TokenClassificationPipeline
as
TokenClassificationPipeline
__webpack_exports__TokenClassifierOutput
as
TokenClassifierOutput
__webpack_exports__TokenizerModel
as
TokenizerModel
__webpack_exports__TopKLogitsWarper
as
TopKLogitsWarper
__webpack_exports__TopPLogitsWarper
as
TopPLogitsWarper
__webpack_exports__TrOCRForCausalLM
as
TrOCRForCausalLM
__webpack_exports__TrOCRPreTrainedModel
as
TrOCRPreTrainedModel
__webpack_exports__TranslationPipeline
as
TranslationPipeline
__webpack_exports__UniSpeechForCTC
as
UniSpeechForCTC
__webpack_exports__UniSpeechForSequenceClassification
as
UniSpeechForSequenceClassification
__webpack_exports__UniSpeechModel
as
UniSpeechModel
__webpack_exports__UniSpeechPreTrainedModel
as
UniSpeechPreTrainedModel
__webpack_exports__UniSpeechSatForAudioFrameClassification
as
UniSpeechSatForAudioFrameClassification
__webpack_exports__UniSpeechSatForCTC
as
UniSpeechSatForCTC
__webpack_exports__UniSpeechSatForSequenceClassification
as
UniSpeechSatForSequenceClassification
__webpack_exports__UniSpeechSatModel
as
UniSpeechSatModel
__webpack_exports__UniSpeechSatPreTrainedModel
as
UniSpeechSatPreTrainedModel
__webpack_exports__VLChatProcessor
as
VLChatProcessor
__webpack_exports__VLMImageProcessor
as
VLMImageProcessor
__webpack_exports__ViTFeatureExtractor
as
ViTFeatureExtractor
__webpack_exports__ViTForImageClassification
as
ViTForImageClassification
__webpack_exports__ViTImageProcessor
as
ViTImageProcessor
__webpack_exports__ViTMAEModel
as
ViTMAEModel
__webpack_exports__ViTMAEPreTrainedModel
as
ViTMAEPreTrainedModel
__webpack_exports__ViTMSNForImageClassification
as
ViTMSNForImageClassification
__webpack_exports__ViTMSNModel
as
ViTMSNModel
__webpack_exports__ViTMSNPreTrainedModel
as
ViTMSNPreTrainedModel
__webpack_exports__ViTModel
as
ViTModel
__webpack_exports__ViTPreTrainedModel
as
ViTPreTrainedModel
__webpack_exports__VisionEncoderDecoderModel
as
VisionEncoderDecoderModel
__webpack_exports__VitMatteForImageMatting
as
VitMatteForImageMatting
__webpack_exports__VitMatteImageProcessor
as
VitMatteImageProcessor
__webpack_exports__VitMattePreTrainedModel
as
VitMattePreTrainedModel
__webpack_exports__VitPoseForPoseEstimation
as
VitPoseForPoseEstimation
__webpack_exports__VitPoseImageProcessor
as
VitPoseImageProcessor
__webpack_exports__VitPosePreTrainedModel
as
VitPosePreTrainedModel
__webpack_exports__VitsModel
as
VitsModel
__webpack_exports__VitsModelOutput
as
VitsModelOutput
__webpack_exports__VitsPreTrainedModel
as
VitsPreTrainedModel
__webpack_exports__VitsTokenizer
as
VitsTokenizer
__webpack_exports__Wav2Vec2BertForCTC
as
Wav2Vec2BertForCTC
__webpack_exports__Wav2Vec2BertForSequenceClassification
as
Wav2Vec2BertForSequenceClassification
__webpack_exports__Wav2Vec2BertModel
as
Wav2Vec2BertModel
__webpack_exports__Wav2Vec2BertPreTrainedModel
as
Wav2Vec2BertPreTrainedModel
__webpack_exports__Wav2Vec2CTCTokenizer
as
Wav2Vec2CTCTokenizer
__webpack_exports__Wav2Vec2FeatureExtractor
as
Wav2Vec2FeatureExtractor
__webpack_exports__Wav2Vec2ForAudioFrameClassification
as
Wav2Vec2ForAudioFrameClassification
__webpack_exports__Wav2Vec2ForCTC
as
Wav2Vec2ForCTC
__webpack_exports__Wav2Vec2ForSequenceClassification
as
Wav2Vec2ForSequenceClassification
__webpack_exports__Wav2Vec2Model
as
Wav2Vec2Model
__webpack_exports__Wav2Vec2PreTrainedModel
as
Wav2Vec2PreTrainedModel
__webpack_exports__Wav2Vec2ProcessorWithLM
as
Wav2Vec2ProcessorWithLM
__webpack_exports__WavLMForAudioFrameClassification
as
WavLMForAudioFrameClassification
__webpack_exports__WavLMForCTC
as
WavLMForCTC
__webpack_exports__WavLMForSequenceClassification
as
WavLMForSequenceClassification
__webpack_exports__WavLMForXVector
as
WavLMForXVector
__webpack_exports__WavLMModel
as
WavLMModel
__webpack_exports__WavLMPreTrainedModel
as
WavLMPreTrainedModel
__webpack_exports__WeSpeakerFeatureExtractor
as
WeSpeakerFeatureExtractor
__webpack_exports__WeSpeakerResNetModel
as
WeSpeakerResNetModel
__webpack_exports__WeSpeakerResNetPreTrainedModel
as
WeSpeakerResNetPreTrainedModel
__webpack_exports__WhisperFeatureExtractor
as
WhisperFeatureExtractor
__webpack_exports__WhisperForConditionalGeneration
as
WhisperForConditionalGeneration
__webpack_exports__WhisperModel
as
WhisperModel
__webpack_exports__WhisperPreTrainedModel
as
WhisperPreTrainedModel
__webpack_exports__WhisperProcessor
as
WhisperProcessor
__webpack_exports__WhisperTextStreamer
as
WhisperTextStreamer
__webpack_exports__WhisperTimeStampLogitsProcessor
as
WhisperTimeStampLogitsProcessor
__webpack_exports__WhisperTokenizer
as
WhisperTokenizer
__webpack_exports__XLMForQuestionAnswering
as
XLMForQuestionAnswering
__webpack_exports__XLMForSequenceClassification
as
XLMForSequenceClassification
__webpack_exports__XLMForTokenClassification
as
XLMForTokenClassification
__webpack_exports__XLMModel
as
XLMModel
__webpack_exports__XLMPreTrainedModel
as
XLMPreTrainedModel
__webpack_exports__XLMRobertaForMaskedLM
as
XLMRobertaForMaskedLM
__webpack_exports__XLMRobertaForQuestionAnswering
as
XLMRobertaForQuestionAnswering
__webpack_exports__XLMRobertaForSequenceClassification
as
XLMRobertaForSequenceClassification
__webpack_exports__XLMRobertaForTokenClassification
as
XLMRobertaForTokenClassification
__webpack_exports__XLMRobertaModel
as
XLMRobertaModel
__webpack_exports__XLMRobertaPreTrainedModel
as
XLMRobertaPreTrainedModel
__webpack_exports__XLMRobertaTokenizer
as
XLMRobertaTokenizer
__webpack_exports__XLMTokenizer
as
XLMTokenizer
__webpack_exports__XLMWithLMHeadModel
as
XLMWithLMHeadModel
__webpack_exports__XVectorOutput
as
XVectorOutput
__webpack_exports__YolosFeatureExtractor
as
YolosFeatureExtractor
__webpack_exports__YolosForObjectDetection
as
YolosForObjectDetection
__webpack_exports__YolosImageProcessor
as
YolosImageProcessor
__webpack_exports__YolosModel
as
YolosModel
__webpack_exports__YolosObjectDetectionOutput
as
YolosObjectDetectionOutput
__webpack_exports__YolosPreTrainedModel
as
YolosPreTrainedModel
__webpack_exports__ZeroShotAudioClassificationPipeline
as
ZeroShotAudioClassificationPipeline
__webpack_exports__ZeroShotClassificationPipeline
as
ZeroShotClassificationPipeline
__webpack_exports__ZeroShotImageClassificationPipeline
as
ZeroShotImageClassificationPipeline
__webpack_exports__ZeroShotObjectDetectionPipeline
as
ZeroShotObjectDetectionPipeline
__webpack_exports__bankers_round
as
bankers_round
__webpack_exports__cat
as
cat
__webpack_exports__cos_sim
as
cos_sim
__webpack_exports__dot
as
dot
__webpack_exports__dynamic_time_warping
as
dynamic_time_warping
__webpack_exports__env
as
env
__webpack_exports__full
as
full
__webpack_exports__full_like
as
full_like
__webpack_exports__getKeyValueShapes
as
getKeyValueShapes
__webpack_exports__hamming
as
hamming
__webpack_exports__hanning
as
hanning
__webpack_exports__interpolate
as
interpolate
__webpack_exports__interpolate_4d
as
interpolate_4d
__webpack_exports__interpolate_data
as
interpolate_data
__webpack_exports__is_chinese_char
as
is_chinese_char
__webpack_exports__layer_norm
as
layer_norm
__webpack_exports__log_softmax
as
log_softmax
__webpack_exports__magnitude
as
magnitude
__webpack_exports__matmul
as
matmul
__webpack_exports__max
as
max
__webpack_exports__mean
as
mean
__webpack_exports__mean_pooling
as
mean_pooling
__webpack_exports__medianFilter
as
medianFilter
__webpack_exports__mel_filter_bank
as
mel_filter_bank
__webpack_exports__min
as
min
__webpack_exports__ones
as
ones
__webpack_exports__ones_like
as
ones_like
__webpack_exports__permute
as
permute
__webpack_exports__permute_data
as
permute_data
__webpack_exports__pipeline
as
pipeline
__webpack_exports__quantize_embeddings
as
quantize_embeddings
__webpack_exports__read_audio
as
read_audio
__webpack_exports__rfft
as
rfft
__webpack_exports__round
as
round
__webpack_exports__softmax
as
softmax
__webpack_exports__spectrogram
as
spectrogram
__webpack_exports__stack
as
stack
__webpack_exports__std_mean
as
std_mean
__webpack_exports__topk
as
topk
__webpack_exports__window_function
as
window_function
__webpack_exports__zeros
as
zeros
__webpack_exports__zeros_like
as
zeros_like
}
;
