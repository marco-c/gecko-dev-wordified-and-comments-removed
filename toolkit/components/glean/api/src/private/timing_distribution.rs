use
inherent
:
:
inherent
;
use
std
:
:
collections
:
:
HashMap
;
use
std
:
:
convert
:
:
TryInto
;
use
std
:
:
sync
:
:
{
atomic
:
:
{
AtomicUsize
Ordering
}
Arc
RwLock
}
;
use
std
:
:
time
:
:
{
Duration
Instant
}
;
use
super
:
:
{
CommonMetricData
MetricId
TimeUnit
}
;
use
glean
:
:
{
DistributionData
ErrorType
TimerId
}
;
use
crate
:
:
ipc
:
:
{
need_ipc
with_ipc_payload
}
;
use
glean
:
:
traits
:
:
TimingDistribution
;
#
[
cfg
(
feature
=
"
with_gecko
"
)
]
use
super
:
:
profiler_utils
:
:
{
lookup_canonical_metric_name
truncate_vector_for_marker
LookupError
TelemetryProfilerCategory
}
;
#
[
cfg
(
feature
=
"
with_gecko
"
)
]
#
[
derive
(
serde
:
:
Serialize
serde
:
:
Deserialize
Debug
)
]
pub
(
crate
)
enum
TDMPayload
{
Duration
(
std
:
:
time
:
:
Duration
)
Sample
(
i64
)
Samples
(
Vec
<
i64
>
)
SamplesNS
(
Vec
<
u64
>
)
}
#
[
cfg
(
feature
=
"
with_gecko
"
)
]
impl
TDMPayload
{
pub
fn
from_samples_signed
(
samples
:
&
Vec
<
i64
>
)
-
>
TDMPayload
{
TDMPayload
:
:
Samples
(
truncate_vector_for_marker
(
samples
)
)
}
pub
fn
from_samples_unsigned
(
samples
:
&
Vec
<
u64
>
)
-
>
TDMPayload
{
TDMPayload
:
:
SamplesNS
(
truncate_vector_for_marker
(
samples
)
)
}
}
#
[
cfg
(
feature
=
"
with_gecko
"
)
]
#
[
derive
(
serde
:
:
Serialize
serde
:
:
Deserialize
Debug
)
]
pub
(
crate
)
struct
TimingDistributionMetricMarker
{
id
:
MetricId
label
:
Option
<
String
>
timer_id
:
Option
<
u64
>
value
:
Option
<
TDMPayload
>
}
#
[
cfg
(
feature
=
"
with_gecko
"
)
]
impl
TimingDistributionMetricMarker
{
pub
fn
new
(
id
:
MetricId
label
:
Option
<
String
>
timer_id
:
Option
<
u64
>
value
:
Option
<
TDMPayload
>
)
-
>
TimingDistributionMetricMarker
{
TimingDistributionMetricMarker
{
id
label
timer_id
value
}
}
}
#
[
cfg
(
feature
=
"
with_gecko
"
)
]
impl
gecko_profiler
:
:
ProfilerMarker
for
TimingDistributionMetricMarker
{
fn
marker_type_name
(
)
-
>
&
'
static
str
{
"
TimingDist
"
}
fn
marker_type_display
(
)
-
>
gecko_profiler
:
:
MarkerSchema
{
use
gecko_profiler
:
:
schema
:
:
*
;
let
mut
schema
=
MarkerSchema
:
:
new
(
&
[
Location
:
:
MarkerChart
Location
:
:
MarkerTable
]
)
;
schema
.
set_tooltip_label
(
"
{
marker
.
data
.
id
}
{
marker
.
data
.
label
}
{
marker
.
data
.
duration
}
{
marker
.
data
.
sample
}
"
)
;
schema
.
set_table_label
(
"
{
marker
.
name
}
-
{
marker
.
data
.
id
}
:
{
marker
.
data
.
duration
}
{
marker
.
data
.
sample
}
{
marker
.
data
.
samples
}
"
)
;
schema
.
set_chart_label
(
"
{
marker
.
data
.
id
}
"
)
;
schema
.
add_key_label_format_searchable
(
"
id
"
"
Metric
"
Format
:
:
UniqueString
Searchable
:
:
Searchable
)
;
schema
.
add_key_label_format_searchable
(
"
label
"
"
Label
"
Format
:
:
UniqueString
Searchable
:
:
Searchable
)
;
schema
.
add_key_label_format_searchable
(
"
timer_id
"
"
TimerId
"
Format
:
:
Integer
Searchable
:
:
Searchable
)
;
schema
.
add_key_label_format
(
"
duration
"
"
Duration
"
Format
:
:
String
)
;
schema
.
add_key_label_format
(
"
sample
"
"
Sample
"
Format
:
:
String
)
;
schema
.
add_key_label_format
(
"
samples
"
"
Samples
"
Format
:
:
String
)
;
schema
}
fn
stream_json_marker_data
(
&
self
json_writer
:
&
mut
gecko_profiler
:
:
JSONWriter
)
{
json_writer
.
unique_string_property
(
"
id
"
lookup_canonical_metric_name
(
&
self
.
id
)
.
unwrap_or_else
(
LookupError
:
:
as_str
)
)
;
if
let
Some
(
l
)
=
&
self
.
label
{
json_writer
.
unique_string_property
(
"
label
"
l
.
as_str
(
)
)
;
}
;
if
let
Some
(
id
)
=
&
self
.
timer_id
{
json_writer
.
int_property
(
"
timer_id
"
*
id
as
i64
)
;
}
;
match
&
self
.
value
{
Some
(
p
)
=
>
{
match
p
{
TDMPayload
:
:
Duration
(
d
)
=
>
{
let
s
=
format
!
(
"
{
:
?
}
"
d
)
;
json_writer
.
string_property
(
"
duration
"
s
.
as_str
(
)
)
;
}
TDMPayload
:
:
Sample
(
s
)
=
>
{
let
s
=
format
!
(
"
{
}
"
s
)
;
json_writer
.
string_property
(
"
sample
"
s
.
as_str
(
)
)
;
}
TDMPayload
:
:
Samples
(
s
)
=
>
{
let
s
=
format
!
(
"
[
{
}
]
"
s
.
iter
(
)
.
map
(
|
v
|
v
.
to_string
(
)
)
.
collect
:
:
<
Vec
<
_
>
>
(
)
.
join
(
"
"
)
)
;
json_writer
.
string_property
(
"
samples
"
s
.
as_str
(
)
)
;
}
TDMPayload
:
:
SamplesNS
(
s
)
=
>
{
let
s
=
format
!
(
"
(
ns
)
[
{
}
]
"
s
.
iter
(
)
.
map
(
|
v
|
v
.
to_string
(
)
)
.
collect
:
:
<
Vec
<
_
>
>
(
)
.
join
(
"
"
)
)
;
json_writer
.
string_property
(
"
samples
"
s
.
as_str
(
)
)
;
}
}
;
}
None
=
>
{
}
}
;
}
}
pub
enum
TimingDistributionMetric
{
Parent
{
id
:
MetricId
inner
:
Arc
<
glean
:
:
private
:
:
TimingDistributionMetric
>
}
Child
(
TimingDistributionMetricIpc
)
}
#
[
derive
(
Debug
)
]
pub
struct
TimingDistributionMetricIpc
{
metric_id
:
MetricId
next_timer_id
:
AtomicUsize
instants
:
RwLock
<
HashMap
<
u64
Instant
>
>
}
impl
TimingDistributionMetric
{
pub
(
crate
)
fn
new_child
(
id
:
MetricId
)
-
>
Self
{
debug_assert
!
(
need_ipc
(
)
)
;
TimingDistributionMetric
:
:
Child
(
TimingDistributionMetricIpc
{
metric_id
:
id
next_timer_id
:
AtomicUsize
:
:
new
(
0
)
instants
:
RwLock
:
:
new
(
HashMap
:
:
new
(
)
)
}
)
}
pub
fn
new
(
id
:
MetricId
meta
:
CommonMetricData
time_unit
:
TimeUnit
)
-
>
Self
{
if
need_ipc
(
)
{
Self
:
:
new_child
(
id
)
}
else
{
let
inner
=
glean
:
:
private
:
:
TimingDistributionMetric
:
:
new
(
meta
time_unit
)
;
TimingDistributionMetric
:
:
Parent
{
id
inner
:
Arc
:
:
new
(
inner
)
}
}
}
#
[
cfg
(
test
)
]
pub
(
crate
)
fn
child_metric
(
&
self
)
-
>
Self
{
match
self
{
TimingDistributionMetric
:
:
Parent
{
id
.
.
}
=
>
{
TimingDistributionMetric
:
:
Child
(
TimingDistributionMetricIpc
{
metric_id
:
*
id
next_timer_id
:
AtomicUsize
:
:
new
(
0
)
instants
:
RwLock
:
:
new
(
HashMap
:
:
new
(
)
)
}
)
}
TimingDistributionMetric
:
:
Child
(
_
)
=
>
{
panic
!
(
"
Can
'
t
get
a
child
metric
from
a
child
metric
"
)
}
}
}
pub
(
crate
)
fn
inner_start
(
&
self
)
-
>
TimerId
{
match
self
{
TimingDistributionMetric
:
:
Parent
{
inner
.
.
}
=
>
inner
.
start
(
)
TimingDistributionMetric
:
:
Child
(
c
)
=
>
{
let
id
=
c
.
next_timer_id
.
fetch_add
(
1
Ordering
:
:
SeqCst
)
.
try_into
(
)
.
unwrap
(
)
;
let
mut
map
=
c
.
instants
.
write
(
)
.
expect
(
"
lock
of
instants
map
was
poisoned
"
)
;
if
let
Some
(
_v
)
=
map
.
insert
(
id
Instant
:
:
now
(
)
)
{
}
id
.
into
(
)
}
}
}
pub
(
crate
)
fn
inner_stop_and_accumulate
(
&
self
id
:
TimerId
)
{
match
self
{
TimingDistributionMetric
:
:
Parent
{
inner
.
.
}
=
>
inner
.
stop_and_accumulate
(
id
)
TimingDistributionMetric
:
:
Child
(
c
)
=
>
{
if
let
Some
(
sample
)
=
self
.
child_stop
(
id
)
{
with_ipc_payload
(
move
|
payload
|
{
if
let
Some
(
v
)
=
payload
.
timing_samples
.
get_mut
(
&
c
.
metric_id
)
{
v
.
push
(
sample
)
;
}
else
{
payload
.
timing_samples
.
insert
(
c
.
metric_id
vec
!
[
sample
]
)
;
}
}
)
;
}
else
{
}
}
}
}
pub
(
crate
)
fn
child_stop
(
&
self
id
:
TimerId
)
-
>
Option
<
u64
>
{
match
self
{
TimingDistributionMetric
:
:
Parent
{
.
.
}
=
>
{
panic
!
(
"
Can
'
t
child_stop
a
parent
-
process
timing_distribution
"
)
}
TimingDistributionMetric
:
:
Child
(
c
)
=
>
{
let
mut
map
=
c
.
instants
.
write
(
)
.
expect
(
"
Write
lock
must
'
ve
been
poisoned
.
"
)
;
if
let
Some
(
start
)
=
map
.
remove
(
&
id
.
id
)
{
let
now
=
Instant
:
:
now
(
)
;
let
sample
=
now
.
checked_duration_since
(
start
)
.
map
(
|
s
|
s
.
as_nanos
(
)
.
try_into
(
)
)
;
match
sample
{
Some
(
Ok
(
sample
)
)
=
>
Some
(
sample
)
Some
(
Err
(
_
)
)
=
>
{
log
:
:
warn
!
(
"
Elapsed
time
larger
than
fits
into
64
-
bytes
.
Saturating
at
u64
:
:
MAX
.
"
)
;
Some
(
u64
:
:
MAX
)
}
None
=
>
{
log
:
:
warn
!
(
"
Time
went
backwards
.
Not
recording
.
"
)
;
None
}
}
}
else
{
None
}
}
}
}
pub
(
crate
)
fn
inner_cancel
(
&
self
id
:
TimerId
)
{
match
self
{
TimingDistributionMetric
:
:
Parent
{
inner
.
.
}
=
>
inner
.
cancel
(
id
)
TimingDistributionMetric
:
:
Child
(
c
)
=
>
{
let
mut
map
=
c
.
instants
.
write
(
)
.
expect
(
"
Write
lock
must
'
ve
been
poisoned
.
"
)
;
if
map
.
remove
(
&
id
.
id
)
.
is_none
(
)
{
}
}
}
}
pub
(
crate
)
fn
inner_accumulate_raw_duration
(
&
self
duration
:
Duration
)
{
let
sample
=
duration
.
as_nanos
(
)
.
try_into
(
)
.
unwrap_or_else
(
|
_
|
{
log
:
:
warn
!
(
"
Elapsed
nanoseconds
larger
than
fits
into
64
-
bytes
.
Saturating
at
u64
:
:
MAX
.
"
)
;
u64
:
:
MAX
}
)
;
match
self
{
TimingDistributionMetric
:
:
Parent
{
inner
.
.
}
=
>
{
inner
.
accumulate_raw_duration
(
duration
)
}
TimingDistributionMetric
:
:
Child
(
c
)
=
>
{
with_ipc_payload
(
move
|
payload
|
{
if
let
Some
(
v
)
=
payload
.
timing_samples
.
get_mut
(
&
c
.
metric_id
)
{
v
.
push
(
sample
)
;
}
else
{
payload
.
timing_samples
.
insert
(
c
.
metric_id
vec
!
[
sample
]
)
;
}
}
)
;
}
}
}
}
#
[
inherent
]
impl
TimingDistribution
for
TimingDistributionMetric
{
pub
fn
start
(
&
self
)
-
>
TimerId
{
let
timer_id
=
self
.
inner_start
(
)
;
#
[
cfg
(
feature
=
"
with_gecko
"
)
]
{
let
metric_id
=
match
self
{
TimingDistributionMetric
:
:
Parent
{
id
.
.
}
=
>
id
TimingDistributionMetric
:
:
Child
(
c
)
=
>
&
c
.
metric_id
}
;
extern
"
C
"
{
fn
GIFFT_TimingDistributionStart
(
metric_id
:
u32
timer_id
:
u64
)
;
}
unsafe
{
GIFFT_TimingDistributionStart
(
metric_id
.
0
timer_id
.
id
)
;
}
gecko_profiler
:
:
lazy_add_marker
!
(
"
TimingDistribution
:
:
start
"
TelemetryProfilerCategory
gecko_profiler
:
:
MarkerOptions
:
:
default
(
)
.
with_timing
(
gecko_profiler
:
:
MarkerTiming
:
:
instant_now
(
)
)
TimingDistributionMetricMarker
:
:
new
(
*
metric_id
None
Some
(
timer_id
.
id
)
None
)
)
;
}
timer_id
.
into
(
)
}
pub
fn
stop_and_accumulate
(
&
self
id
:
TimerId
)
{
self
.
inner_stop_and_accumulate
(
id
)
;
#
[
cfg
(
feature
=
"
with_gecko
"
)
]
{
let
metric_id
=
match
self
{
TimingDistributionMetric
:
:
Parent
{
id
.
.
}
=
>
id
TimingDistributionMetric
:
:
Child
(
c
)
=
>
&
c
.
metric_id
}
;
extern
"
C
"
{
fn
GIFFT_TimingDistributionStopAndAccumulate
(
metric_id
:
u32
timer_id
:
u64
)
;
}
unsafe
{
GIFFT_TimingDistributionStopAndAccumulate
(
metric_id
.
0
id
.
id
)
;
}
gecko_profiler
:
:
lazy_add_marker
!
(
"
TimingDistribution
:
:
stop
"
TelemetryProfilerCategory
gecko_profiler
:
:
MarkerOptions
:
:
default
(
)
.
with_timing
(
gecko_profiler
:
:
MarkerTiming
:
:
instant_now
(
)
)
TimingDistributionMetricMarker
:
:
new
(
*
metric_id
None
Some
(
id
.
id
)
None
)
)
;
}
}
pub
fn
cancel
(
&
self
id
:
TimerId
)
{
self
.
inner_cancel
(
id
)
;
#
[
cfg
(
feature
=
"
with_gecko
"
)
]
{
let
metric_id
=
match
self
{
TimingDistributionMetric
:
:
Parent
{
id
.
.
}
=
>
id
TimingDistributionMetric
:
:
Child
(
c
)
=
>
&
c
.
metric_id
}
;
extern
"
C
"
{
fn
GIFFT_TimingDistributionCancel
(
metric_id
:
u32
timer_id
:
u64
)
;
}
unsafe
{
GIFFT_TimingDistributionCancel
(
metric_id
.
0
id
.
id
)
;
}
gecko_profiler
:
:
lazy_add_marker
!
(
"
TimingDistribution
:
:
cancel
"
TelemetryProfilerCategory
gecko_profiler
:
:
MarkerOptions
:
:
default
(
)
.
with_timing
(
gecko_profiler
:
:
MarkerTiming
:
:
instant_now
(
)
)
TimingDistributionMetricMarker
:
:
new
(
*
metric_id
None
Some
(
id
.
id
)
None
)
)
;
}
}
pub
fn
accumulate_samples
(
&
self
samples
:
Vec
<
i64
>
)
{
match
self
{
#
[
allow
(
unused
)
]
TimingDistributionMetric
:
:
Parent
{
id
inner
}
=
>
{
#
[
cfg
(
feature
=
"
with_gecko
"
)
]
gecko_profiler
:
:
lazy_add_marker
!
(
"
TimingDistribution
:
:
accumulate
"
TelemetryProfilerCategory
TimingDistributionMetricMarker
:
:
new
(
*
id
None
None
Some
(
TDMPayload
:
:
from_samples_signed
(
&
samples
)
)
)
)
;
inner
.
accumulate_samples
(
samples
)
}
TimingDistributionMetric
:
:
Child
(
_c
)
=
>
{
log
:
:
error
!
(
"
Can
'
t
record
samples
for
a
timing
distribution
from
a
child
metric
"
)
;
}
}
}
pub
fn
accumulate_raw_samples_nanos
(
&
self
samples
:
Vec
<
u64
>
)
{
match
self
{
#
[
allow
(
unused
)
]
TimingDistributionMetric
:
:
Parent
{
id
inner
}
=
>
{
#
[
cfg
(
feature
=
"
with_gecko
"
)
]
gecko_profiler
:
:
lazy_add_marker
!
(
"
TimingDistribution
:
:
accumulate
"
TelemetryProfilerCategory
TimingDistributionMetricMarker
:
:
new
(
*
id
None
None
Some
(
TDMPayload
:
:
from_samples_unsigned
(
&
samples
)
)
)
)
;
inner
.
accumulate_raw_samples_nanos
(
samples
)
}
TimingDistributionMetric
:
:
Child
(
_c
)
=
>
{
log
:
:
error
!
(
"
Can
'
t
record
samples
for
a
timing
distribution
from
a
child
metric
"
)
;
}
}
}
pub
fn
accumulate_single_sample
(
&
self
sample
:
i64
)
{
match
self
{
#
[
allow
(
unused
)
]
TimingDistributionMetric
:
:
Parent
{
id
inner
}
=
>
{
#
[
cfg
(
feature
=
"
with_gecko
"
)
]
gecko_profiler
:
:
lazy_add_marker
!
(
"
TimingDistribution
:
:
accumulate
"
TelemetryProfilerCategory
TimingDistributionMetricMarker
:
:
new
(
*
id
None
None
Some
(
TDMPayload
:
:
Sample
(
sample
.
clone
(
)
)
)
)
)
;
inner
.
accumulate_single_sample
(
sample
)
}
TimingDistributionMetric
:
:
Child
(
_c
)
=
>
{
log
:
:
error
!
(
"
Can
'
t
record
samples
for
a
timing
distribution
from
a
child
metric
"
)
;
}
}
}
pub
fn
accumulate_raw_duration
(
&
self
duration
:
Duration
)
{
self
.
inner_accumulate_raw_duration
(
duration
)
;
#
[
cfg
(
feature
=
"
with_gecko
"
)
]
{
let
sample_ms
=
duration
.
as_millis
(
)
.
try_into
(
)
.
unwrap_or_else
(
|
_
|
{
log
:
:
warn
!
(
"
Elapsed
milliseconds
larger
than
fits
into
32
-
bytes
.
Saturating
at
u32
:
:
MAX
.
"
)
;
u32
:
:
MAX
}
)
;
let
metric_id
=
match
self
{
TimingDistributionMetric
:
:
Parent
{
id
.
.
}
=
>
id
TimingDistributionMetric
:
:
Child
(
c
)
=
>
&
c
.
metric_id
}
;
extern
"
C
"
{
fn
GIFFT_TimingDistributionAccumulateRawMillis
(
metric_id
:
u32
sample
:
u32
)
;
}
unsafe
{
GIFFT_TimingDistributionAccumulateRawMillis
(
metric_id
.
0
sample_ms
)
;
}
gecko_profiler
:
:
lazy_add_marker
!
(
"
TimingDistribution
:
:
accumulate
"
TelemetryProfilerCategory
TimingDistributionMetricMarker
:
:
new
(
*
metric_id
None
None
Some
(
TDMPayload
:
:
Duration
(
duration
.
clone
(
)
)
)
)
)
;
}
}
pub
fn
test_get_value
<
'
a
S
:
Into
<
Option
<
&
'
a
str
>
>
>
(
&
self
ping_name
:
S
)
-
>
Option
<
DistributionData
>
{
let
ping_name
=
ping_name
.
into
(
)
.
map
(
|
s
|
s
.
to_string
(
)
)
;
match
self
{
TimingDistributionMetric
:
:
Parent
{
inner
.
.
}
=
>
inner
.
test_get_value
(
ping_name
)
TimingDistributionMetric
:
:
Child
(
c
)
=
>
{
panic
!
(
"
Cannot
get
test
value
for
{
:
?
}
in
non
-
parent
process
!
"
c
)
}
}
}
pub
fn
test_get_num_recorded_errors
(
&
self
error
:
ErrorType
)
-
>
i32
{
match
self
{
TimingDistributionMetric
:
:
Parent
{
inner
.
.
}
=
>
{
inner
.
test_get_num_recorded_errors
(
error
)
}
TimingDistributionMetric
:
:
Child
(
c
)
=
>
panic
!
(
"
Cannot
get
number
of
recorded
errors
for
{
:
?
}
in
non
-
parent
process
!
"
c
)
}
}
}
#
[
cfg
(
test
)
]
mod
test
{
use
crate
:
:
{
common_test
:
:
*
ipc
metrics
}
;
#
[
test
]
fn
smoke_test_timing_distribution
(
)
{
let
_lock
=
lock_test
(
)
;
let
metric
=
&
metrics
:
:
test_only_ipc
:
:
a_timing_dist
;
let
id
=
metric
.
start
(
)
;
metric
.
cancel
(
id
)
;
assert
!
(
metric
.
test_get_value
(
"
test
-
ping
"
)
.
is_none
(
)
)
;
}
#
[
test
]
fn
timing_distribution_child
(
)
{
let
_lock
=
lock_test
(
)
;
let
parent_metric
=
&
metrics
:
:
test_only_ipc
:
:
a_timing_dist
;
let
id
=
parent_metric
.
start
(
)
;
std
:
:
thread
:
:
sleep
(
std
:
:
time
:
:
Duration
:
:
from_millis
(
10
)
)
;
parent_metric
.
stop_and_accumulate
(
id
)
;
{
let
child_metric
=
parent_metric
.
child_metric
(
)
;
let
_raii
=
ipc
:
:
test_set_need_ipc
(
true
)
;
let
id
=
child_metric
.
start
(
)
;
let
id2
=
child_metric
.
start
(
)
;
assert_ne
!
(
id
id2
)
;
std
:
:
thread
:
:
sleep
(
std
:
:
time
:
:
Duration
:
:
from_millis
(
10
)
)
;
child_metric
.
stop_and_accumulate
(
id
)
;
child_metric
.
cancel
(
id2
)
;
}
let
buf
=
ipc
:
:
take_buf
(
)
.
unwrap
(
)
;
assert
!
(
buf
.
len
(
)
>
0
)
;
assert
!
(
ipc
:
:
replay_from_buf
(
&
buf
)
.
is_ok
(
)
)
;
let
data
=
parent_metric
.
test_get_value
(
"
test
-
ping
"
)
.
expect
(
"
should
have
some
data
"
)
;
assert_eq
!
(
2
data
.
values
.
values
(
)
.
fold
(
0
|
acc
count
|
acc
+
count
)
"
record
2
values
one
parent
one
child
measurement
"
)
;
assert
!
(
0
<
data
.
sum
"
record
some
time
"
)
;
}
}
