#
include
<
google
/
protobuf
/
arena
.
h
>
#
include
<
algorithm
>
#
include
<
atomic
>
#
include
<
cstddef
>
#
include
<
cstdint
>
#
include
<
limits
>
#
include
<
typeinfo
>
#
include
<
google
/
protobuf
/
arena_impl
.
h
>
#
include
<
google
/
protobuf
/
arenaz_sampler
.
h
>
#
include
<
google
/
protobuf
/
port
.
h
>
#
include
<
google
/
protobuf
/
stubs
/
mutex
.
h
>
#
ifdef
ADDRESS_SANITIZER
#
include
<
sanitizer
/
asan_interface
.
h
>
#
endif
#
include
<
google
/
protobuf
/
port_def
.
inc
>
namespace
google
{
namespace
protobuf
{
namespace
internal
{
static
SerialArena
:
:
Memory
AllocateMemory
(
const
AllocationPolicy
*
policy_ptr
size_t
last_size
size_t
min_bytes
)
{
AllocationPolicy
policy
;
if
(
policy_ptr
)
policy
=
*
policy_ptr
;
size_t
size
;
if
(
last_size
!
=
0
)
{
auto
max_size
=
policy
.
max_block_size
;
size
=
std
:
:
min
(
2
*
last_size
max_size
)
;
}
else
{
size
=
policy
.
start_block_size
;
}
GOOGLE_CHECK_LE
(
min_bytes
std
:
:
numeric_limits
<
size_t
>
:
:
max
(
)
-
SerialArena
:
:
kBlockHeaderSize
)
;
size
=
std
:
:
max
(
size
SerialArena
:
:
kBlockHeaderSize
+
min_bytes
)
;
void
*
mem
;
if
(
policy
.
block_alloc
=
=
nullptr
)
{
mem
=
:
:
operator
new
(
size
)
;
}
else
{
mem
=
policy
.
block_alloc
(
size
)
;
}
return
{
mem
size
}
;
}
class
GetDeallocator
{
public
:
GetDeallocator
(
const
AllocationPolicy
*
policy
size_t
*
space_allocated
)
:
dealloc_
(
policy
?
policy
-
>
block_dealloc
:
nullptr
)
space_allocated_
(
space_allocated
)
{
}
void
operator
(
)
(
SerialArena
:
:
Memory
mem
)
const
{
#
ifdef
ADDRESS_SANITIZER
ASAN_UNPOISON_MEMORY_REGION
(
mem
.
ptr
mem
.
size
)
;
#
endif
if
(
dealloc_
)
{
dealloc_
(
mem
.
ptr
mem
.
size
)
;
}
else
{
internal
:
:
SizedDelete
(
mem
.
ptr
mem
.
size
)
;
}
*
space_allocated_
+
=
mem
.
size
;
}
private
:
void
(
*
dealloc_
)
(
void
*
size_t
)
;
size_t
*
space_allocated_
;
}
;
SerialArena
:
:
SerialArena
(
Block
*
b
void
*
owner
ThreadSafeArenaStats
*
stats
)
:
space_allocated_
(
b
-
>
size
)
{
owner_
=
owner
;
head_
=
b
;
ptr_
=
b
-
>
Pointer
(
kBlockHeaderSize
+
ThreadSafeArena
:
:
kSerialArenaSize
)
;
limit_
=
b
-
>
Pointer
(
b
-
>
size
&
static_cast
<
size_t
>
(
-
8
)
)
;
arena_stats_
=
stats
;
}
SerialArena
*
SerialArena
:
:
New
(
Memory
mem
void
*
owner
ThreadSafeArenaStats
*
stats
)
{
GOOGLE_DCHECK_LE
(
kBlockHeaderSize
+
ThreadSafeArena
:
:
kSerialArenaSize
mem
.
size
)
;
ThreadSafeArenaStats
:
:
RecordAllocateStats
(
stats
mem
.
size
mem
.
size
0
)
;
auto
b
=
new
(
mem
.
ptr
)
Block
{
nullptr
mem
.
size
}
;
return
new
(
b
-
>
Pointer
(
kBlockHeaderSize
)
)
SerialArena
(
b
owner
stats
)
;
}
template
<
typename
Deallocator
>
SerialArena
:
:
Memory
SerialArena
:
:
Free
(
Deallocator
deallocator
)
{
Block
*
b
=
head_
;
Memory
mem
=
{
b
b
-
>
size
}
;
while
(
b
-
>
next
)
{
b
=
b
-
>
next
;
deallocator
(
mem
)
;
mem
=
{
b
b
-
>
size
}
;
}
return
mem
;
}
PROTOBUF_NOINLINE
std
:
:
pair
<
void
*
SerialArena
:
:
CleanupNode
*
>
SerialArena
:
:
AllocateAlignedWithCleanupFallback
(
size_t
n
const
AllocationPolicy
*
policy
)
{
AllocateNewBlock
(
n
+
kCleanupSize
policy
)
;
return
AllocateFromExistingWithCleanupFallback
(
n
)
;
}
PROTOBUF_NOINLINE
void
*
SerialArena
:
:
AllocateAlignedFallback
(
size_t
n
const
AllocationPolicy
*
policy
)
{
AllocateNewBlock
(
n
policy
)
;
return
AllocateFromExisting
(
n
)
;
}
void
SerialArena
:
:
AllocateNewBlock
(
size_t
n
const
AllocationPolicy
*
policy
)
{
head_
-
>
start
=
reinterpret_cast
<
CleanupNode
*
>
(
limit_
)
;
size_t
used
=
ptr_
-
head_
-
>
Pointer
(
kBlockHeaderSize
)
;
size_t
wasted
=
head_
-
>
size
-
used
;
space_used_
+
=
used
;
auto
mem
=
AllocateMemory
(
policy
head_
-
>
size
n
)
;
auto
relaxed
=
std
:
:
memory_order_relaxed
;
space_allocated_
.
store
(
space_allocated_
.
load
(
relaxed
)
+
mem
.
size
relaxed
)
;
ThreadSafeArenaStats
:
:
RecordAllocateStats
(
arena_stats_
n
mem
.
size
wasted
)
;
head_
=
new
(
mem
.
ptr
)
Block
{
head_
mem
.
size
}
;
ptr_
=
head_
-
>
Pointer
(
kBlockHeaderSize
)
;
limit_
=
head_
-
>
Pointer
(
head_
-
>
size
)
;
#
ifdef
ADDRESS_SANITIZER
ASAN_POISON_MEMORY_REGION
(
ptr_
limit_
-
ptr_
)
;
#
endif
}
uint64_t
SerialArena
:
:
SpaceUsed
(
)
const
{
uint64_t
space_used
=
ptr_
-
head_
-
>
Pointer
(
kBlockHeaderSize
)
;
space_used
+
=
space_used_
;
space_used
-
=
ThreadSafeArena
:
:
kSerialArenaSize
;
return
space_used
;
}
void
SerialArena
:
:
CleanupList
(
)
{
Block
*
b
=
head_
;
b
-
>
start
=
reinterpret_cast
<
CleanupNode
*
>
(
limit_
)
;
do
{
auto
*
limit
=
reinterpret_cast
<
CleanupNode
*
>
(
b
-
>
Pointer
(
b
-
>
size
&
static_cast
<
size_t
>
(
-
8
)
)
)
;
auto
it
=
b
-
>
start
;
auto
num
=
limit
-
it
;
if
(
num
>
0
)
{
for
(
;
it
<
limit
;
it
+
+
)
{
it
-
>
cleanup
(
it
-
>
elem
)
;
}
}
b
=
b
-
>
next
;
}
while
(
b
)
;
}
ThreadSafeArena
:
:
CacheAlignedLifecycleIdGenerator
ThreadSafeArena
:
:
lifecycle_id_generator_
;
#
if
defined
(
GOOGLE_PROTOBUF_NO_THREADLOCAL
)
ThreadSafeArena
:
:
ThreadCache
&
ThreadSafeArena
:
:
thread_cache
(
)
{
static
internal
:
:
ThreadLocalStorage
<
ThreadCache
>
*
thread_cache_
=
new
internal
:
:
ThreadLocalStorage
<
ThreadCache
>
(
)
;
return
*
thread_cache_
-
>
Get
(
)
;
}
#
elif
defined
(
PROTOBUF_USE_DLLS
)
ThreadSafeArena
:
:
ThreadCache
&
ThreadSafeArena
:
:
thread_cache
(
)
{
static
PROTOBUF_THREAD_LOCAL
ThreadCache
thread_cache_
=
{
0
static_cast
<
LifecycleIdAtomic
>
(
-
1
)
nullptr
}
;
return
thread_cache_
;
}
#
else
PROTOBUF_THREAD_LOCAL
ThreadSafeArena
:
:
ThreadCache
ThreadSafeArena
:
:
thread_cache_
=
{
0
static_cast
<
LifecycleIdAtomic
>
(
-
1
)
nullptr
}
;
#
endif
void
ThreadSafeArena
:
:
InitializeFrom
(
void
*
mem
size_t
size
)
{
GOOGLE_DCHECK_EQ
(
reinterpret_cast
<
uintptr_t
>
(
mem
)
&
7
0u
)
;
GOOGLE_DCHECK
(
!
AllocPolicy
(
)
)
;
Init
(
)
;
if
(
mem
!
=
nullptr
&
&
size
>
=
kBlockHeaderSize
+
kSerialArenaSize
)
{
alloc_policy_
.
set_is_user_owned_initial_block
(
true
)
;
SetInitialBlock
(
mem
size
)
;
}
}
void
ThreadSafeArena
:
:
InitializeWithPolicy
(
void
*
mem
size_t
size
AllocationPolicy
policy
)
{
#
ifndef
NDEBUG
const
uint64_t
old_alloc_policy
=
alloc_policy_
.
get_raw
(
)
;
#
define
GOOGLE_DCHECK_POLICY_FLAGS_
(
)
\
if
(
old_alloc_policy
>
3
)
\
GOOGLE_CHECK_EQ
(
old_alloc_policy
&
3
alloc_policy_
.
get_raw
(
)
&
3
)
#
else
#
define
GOOGLE_DCHECK_POLICY_FLAGS_
(
)
#
endif
if
(
policy
.
IsDefault
(
)
)
{
InitializeFrom
(
mem
size
)
;
GOOGLE_DCHECK_POLICY_FLAGS_
(
)
;
return
;
}
GOOGLE_DCHECK_EQ
(
reinterpret_cast
<
uintptr_t
>
(
mem
)
&
7
0u
)
;
Init
(
)
;
constexpr
size_t
kAPSize
=
internal
:
:
AlignUpTo8
(
sizeof
(
AllocationPolicy
)
)
;
constexpr
size_t
kMinimumSize
=
kBlockHeaderSize
+
kSerialArenaSize
+
kAPSize
;
alloc_policy_
.
set_should_record_allocs
(
policy
.
metrics_collector
!
=
nullptr
&
&
policy
.
metrics_collector
-
>
RecordAllocs
(
)
)
;
if
(
mem
!
=
nullptr
&
&
size
>
=
kMinimumSize
)
{
alloc_policy_
.
set_is_user_owned_initial_block
(
true
)
;
}
else
{
auto
tmp
=
AllocateMemory
(
&
policy
0
kMinimumSize
)
;
mem
=
tmp
.
ptr
;
size
=
tmp
.
size
;
}
SetInitialBlock
(
mem
size
)
;
auto
sa
=
threads_
.
load
(
std
:
:
memory_order_relaxed
)
;
void
*
p
;
if
(
!
sa
|
|
!
sa
-
>
MaybeAllocateAligned
(
kAPSize
&
p
)
)
{
GOOGLE_LOG
(
FATAL
)
<
<
"
MaybeAllocateAligned
cannot
fail
here
.
"
;
return
;
}
new
(
p
)
AllocationPolicy
{
policy
}
;
GOOGLE_DCHECK_EQ
(
0
reinterpret_cast
<
uintptr_t
>
(
p
)
&
3
)
;
alloc_policy_
.
set_policy
(
reinterpret_cast
<
AllocationPolicy
*
>
(
p
)
)
;
GOOGLE_DCHECK_POLICY_FLAGS_
(
)
;
#
undef
GOOGLE_DCHECK_POLICY_FLAGS_
}
void
ThreadSafeArena
:
:
Init
(
)
{
#
ifndef
NDEBUG
const
bool
was_message_owned
=
IsMessageOwned
(
)
;
#
endif
ThreadCache
&
tc
=
thread_cache
(
)
;
auto
id
=
tc
.
next_lifecycle_id
;
constexpr
uint64_t
kDelta
=
2
;
constexpr
uint64_t
kInc
=
ThreadCache
:
:
kPerThreadIds
*
kDelta
;
if
(
PROTOBUF_PREDICT_FALSE
(
(
id
&
(
kInc
-
1
)
)
=
=
0
)
)
{
constexpr
auto
relaxed
=
std
:
:
memory_order_relaxed
;
id
=
lifecycle_id_generator_
.
id
.
fetch_add
(
1
relaxed
)
*
kInc
;
}
tc
.
next_lifecycle_id
=
id
+
kDelta
;
tag_and_id_
=
id
|
(
tag_and_id_
&
kMessageOwnedArena
)
;
hint_
.
store
(
nullptr
std
:
:
memory_order_relaxed
)
;
threads_
.
store
(
nullptr
std
:
:
memory_order_relaxed
)
;
#
ifndef
NDEBUG
GOOGLE_CHECK_EQ
(
was_message_owned
IsMessageOwned
(
)
)
;
#
endif
arena_stats_
=
Sample
(
)
;
}
void
ThreadSafeArena
:
:
SetInitialBlock
(
void
*
mem
size_t
size
)
{
SerialArena
*
serial
=
SerialArena
:
:
New
(
{
mem
size
}
&
thread_cache
(
)
arena_stats_
.
MutableStats
(
)
)
;
serial
-
>
set_next
(
NULL
)
;
threads_
.
store
(
serial
std
:
:
memory_order_relaxed
)
;
CacheSerialArena
(
serial
)
;
}
ThreadSafeArena
:
:
~
ThreadSafeArena
(
)
{
CleanupList
(
)
;
size_t
space_allocated
=
0
;
auto
mem
=
Free
(
&
space_allocated
)
;
auto
*
p
=
alloc_policy_
.
get
(
)
;
ArenaMetricsCollector
*
collector
=
p
?
p
-
>
metrics_collector
:
nullptr
;
if
(
alloc_policy_
.
is_user_owned_initial_block
(
)
)
{
#
ifdef
ADDRESS_SANITIZER
ASAN_UNPOISON_MEMORY_REGION
(
mem
.
ptr
mem
.
size
)
;
#
endif
space_allocated
+
=
mem
.
size
;
}
else
{
GetDeallocator
(
alloc_policy_
.
get
(
)
&
space_allocated
)
(
mem
)
;
}
if
(
collector
)
collector
-
>
OnDestroy
(
space_allocated
)
;
}
SerialArena
:
:
Memory
ThreadSafeArena
:
:
Free
(
size_t
*
space_allocated
)
{
SerialArena
:
:
Memory
mem
=
{
nullptr
0
}
;
auto
deallocator
=
GetDeallocator
(
alloc_policy_
.
get
(
)
space_allocated
)
;
PerSerialArena
(
[
deallocator
&
mem
]
(
SerialArena
*
a
)
{
if
(
mem
.
ptr
)
deallocator
(
mem
)
;
mem
=
a
-
>
Free
(
deallocator
)
;
}
)
;
return
mem
;
}
uint64_t
ThreadSafeArena
:
:
Reset
(
)
{
CleanupList
(
)
;
size_t
space_allocated
=
0
;
auto
mem
=
Free
(
&
space_allocated
)
;
arena_stats_
.
RecordReset
(
)
;
AllocationPolicy
*
policy
=
alloc_policy_
.
get
(
)
;
if
(
policy
)
{
auto
saved_policy
=
*
policy
;
if
(
alloc_policy_
.
is_user_owned_initial_block
(
)
)
{
space_allocated
+
=
mem
.
size
;
}
else
{
GetDeallocator
(
alloc_policy_
.
get
(
)
&
space_allocated
)
(
mem
)
;
mem
.
ptr
=
nullptr
;
mem
.
size
=
0
;
}
ArenaMetricsCollector
*
collector
=
saved_policy
.
metrics_collector
;
if
(
collector
)
collector
-
>
OnReset
(
space_allocated
)
;
InitializeWithPolicy
(
mem
.
ptr
mem
.
size
saved_policy
)
;
}
else
{
GOOGLE_DCHECK
(
!
alloc_policy_
.
should_record_allocs
(
)
)
;
if
(
alloc_policy_
.
is_user_owned_initial_block
(
)
)
{
space_allocated
+
=
mem
.
size
;
InitializeFrom
(
mem
.
ptr
mem
.
size
)
;
}
else
{
GetDeallocator
(
alloc_policy_
.
get
(
)
&
space_allocated
)
(
mem
)
;
Init
(
)
;
}
}
return
space_allocated
;
}
std
:
:
pair
<
void
*
SerialArena
:
:
CleanupNode
*
>
ThreadSafeArena
:
:
AllocateAlignedWithCleanup
(
size_t
n
const
std
:
:
type_info
*
type
)
{
SerialArena
*
arena
;
if
(
PROTOBUF_PREDICT_TRUE
(
!
alloc_policy_
.
should_record_allocs
(
)
&
&
GetSerialArenaFast
(
&
arena
)
)
)
{
return
arena
-
>
AllocateAlignedWithCleanup
(
n
alloc_policy_
.
get
(
)
)
;
}
else
{
return
AllocateAlignedWithCleanupFallback
(
n
type
)
;
}
}
void
ThreadSafeArena
:
:
AddCleanup
(
void
*
elem
void
(
*
cleanup
)
(
void
*
)
)
{
SerialArena
*
arena
;
if
(
PROTOBUF_PREDICT_FALSE
(
!
GetSerialArenaFast
(
&
arena
)
)
)
{
arena
=
GetSerialArenaFallback
(
&
thread_cache
(
)
)
;
}
arena
-
>
AddCleanup
(
elem
cleanup
AllocPolicy
(
)
)
;
}
PROTOBUF_NOINLINE
void
*
ThreadSafeArena
:
:
AllocateAlignedFallback
(
size_t
n
const
std
:
:
type_info
*
type
)
{
if
(
alloc_policy_
.
should_record_allocs
(
)
)
{
alloc_policy_
.
RecordAlloc
(
type
n
)
;
SerialArena
*
arena
;
if
(
PROTOBUF_PREDICT_TRUE
(
GetSerialArenaFast
(
&
arena
)
)
)
{
return
arena
-
>
AllocateAligned
(
n
alloc_policy_
.
get
(
)
)
;
}
}
return
GetSerialArenaFallback
(
&
thread_cache
(
)
)
-
>
AllocateAligned
(
n
alloc_policy_
.
get
(
)
)
;
}
PROTOBUF_NOINLINE
std
:
:
pair
<
void
*
SerialArena
:
:
CleanupNode
*
>
ThreadSafeArena
:
:
AllocateAlignedWithCleanupFallback
(
size_t
n
const
std
:
:
type_info
*
type
)
{
if
(
alloc_policy_
.
should_record_allocs
(
)
)
{
alloc_policy_
.
RecordAlloc
(
type
n
)
;
SerialArena
*
arena
;
if
(
GetSerialArenaFast
(
&
arena
)
)
{
return
arena
-
>
AllocateAlignedWithCleanup
(
n
alloc_policy_
.
get
(
)
)
;
}
}
return
GetSerialArenaFallback
(
&
thread_cache
(
)
)
-
>
AllocateAlignedWithCleanup
(
n
alloc_policy_
.
get
(
)
)
;
}
uint64_t
ThreadSafeArena
:
:
SpaceAllocated
(
)
const
{
SerialArena
*
serial
=
threads_
.
load
(
std
:
:
memory_order_acquire
)
;
uint64_t
res
=
0
;
for
(
;
serial
;
serial
=
serial
-
>
next
(
)
)
{
res
+
=
serial
-
>
SpaceAllocated
(
)
;
}
return
res
;
}
uint64_t
ThreadSafeArena
:
:
SpaceUsed
(
)
const
{
SerialArena
*
serial
=
threads_
.
load
(
std
:
:
memory_order_acquire
)
;
uint64_t
space_used
=
0
;
for
(
;
serial
;
serial
=
serial
-
>
next
(
)
)
{
space_used
+
=
serial
-
>
SpaceUsed
(
)
;
}
return
space_used
-
(
alloc_policy_
.
get
(
)
?
sizeof
(
AllocationPolicy
)
:
0
)
;
}
void
ThreadSafeArena
:
:
CleanupList
(
)
{
PerSerialArena
(
[
]
(
SerialArena
*
a
)
{
a
-
>
CleanupList
(
)
;
}
)
;
}
PROTOBUF_NOINLINE
SerialArena
*
ThreadSafeArena
:
:
GetSerialArenaFallback
(
void
*
me
)
{
SerialArena
*
serial
=
threads_
.
load
(
std
:
:
memory_order_acquire
)
;
for
(
;
serial
;
serial
=
serial
-
>
next
(
)
)
{
if
(
serial
-
>
owner
(
)
=
=
me
)
{
break
;
}
}
if
(
!
serial
)
{
serial
=
SerialArena
:
:
New
(
AllocateMemory
(
alloc_policy_
.
get
(
)
0
kSerialArenaSize
)
me
arena_stats_
.
MutableStats
(
)
)
;
SerialArena
*
head
=
threads_
.
load
(
std
:
:
memory_order_relaxed
)
;
do
{
serial
-
>
set_next
(
head
)
;
}
while
(
!
threads_
.
compare_exchange_weak
(
head
serial
std
:
:
memory_order_release
std
:
:
memory_order_relaxed
)
)
;
}
CacheSerialArena
(
serial
)
;
return
serial
;
}
}
PROTOBUF_FUNC_ALIGN
(
32
)
void
*
Arena
:
:
AllocateAlignedNoHook
(
size_t
n
)
{
return
impl_
.
AllocateAligned
(
n
nullptr
)
;
}
PROTOBUF_FUNC_ALIGN
(
32
)
void
*
Arena
:
:
AllocateAlignedWithHook
(
size_t
n
const
std
:
:
type_info
*
type
)
{
return
impl_
.
AllocateAligned
(
n
type
)
;
}
PROTOBUF_FUNC_ALIGN
(
32
)
void
*
Arena
:
:
AllocateAlignedWithHookForArray
(
size_t
n
const
std
:
:
type_info
*
type
)
{
return
impl_
.
AllocateAligned
<
internal
:
:
AllocationClient
:
:
kArray
>
(
n
type
)
;
}
PROTOBUF_FUNC_ALIGN
(
32
)
std
:
:
pair
<
void
*
internal
:
:
SerialArena
:
:
CleanupNode
*
>
Arena
:
:
AllocateAlignedWithCleanup
(
size_t
n
const
std
:
:
type_info
*
type
)
{
return
impl_
.
AllocateAlignedWithCleanup
(
n
type
)
;
}
}
}
#
include
<
google
/
protobuf
/
port_undef
.
inc
>
