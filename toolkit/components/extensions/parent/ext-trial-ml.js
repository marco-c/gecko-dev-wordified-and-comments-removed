"
use
strict
"
;
ChromeUtils
.
defineESModuleGetters
(
this
{
createEngine
:
"
chrome
:
/
/
global
/
content
/
ml
/
EngineProcess
.
sys
.
mjs
"
PipelineOptions
:
"
chrome
:
/
/
global
/
content
/
ml
/
EngineProcess
.
sys
.
mjs
"
ModelHub
:
"
chrome
:
/
/
global
/
content
/
ml
/
ModelHub
.
sys
.
mjs
"
addonIdToEngineId
:
"
chrome
:
/
/
global
/
content
/
ml
/
Utils
.
sys
.
mjs
"
}
)
;
const
PREF_EXTENSIONS_ML_ENABLED
=
"
extensions
.
ml
.
enabled
"
;
XPCOMUtils
.
defineLazyPreferenceGetter
(
this
"
extensionInferenceEnabled
"
PREF_EXTENSIONS_ML_ENABLED
false
)
;
const
PREF_BROWSER_ML_ENABLE
=
"
browser
.
ml
.
enable
"
;
XPCOMUtils
.
defineLazyPreferenceGetter
(
this
"
browserInferenceEnable
"
PREF_BROWSER_ML_ENABLE
false
)
;
function
ensureInferenceEnabled
(
)
{
if
(
extensionInferenceEnabled
&
&
browserInferenceEnable
)
{
return
;
}
throw
new
ExtensionError
(
Trial
ML
is
only
available
when
"
{
PREF_EXTENSIONS_ML_ENABLED
}
"
and
{
PREF_BROWSER_ML_ENABLE
}
"
preferences
are
set
to
true
.
)
;
}
var
{
ExtensionError
}
=
ExtensionUtils
;
const
SUPPORTED_TASKS
=
[
"
text
-
classification
"
"
token
-
classification
"
"
question
-
answering
"
"
fill
-
mask
"
"
summarization
"
"
translation
"
"
text2text
-
generation
"
"
text
-
generation
"
"
text
-
to
-
speech
"
"
text
-
to
-
audio
"
"
zero
-
shot
-
classification
"
"
image
-
to
-
text
"
"
image
-
classification
"
"
image
-
segmentation
"
"
zero
-
shot
-
image
-
classification
"
"
object
-
detection
"
"
zero
-
shot
-
object
-
detection
"
"
document
-
question
-
answering
"
"
image
-
to
-
image
"
"
depth
-
estimation
"
"
feature
-
extraction
"
"
image
-
feature
-
extraction
"
]
;
const
ENGINE_EVENT
=
"
MLEngine
:
progress
"
;
const
modelHub
=
new
ModelHub
(
)
;
class
TrialML
extends
ExtensionAPI
{
#
pipelineId
=
null
;
#
engine
=
null
;
#
pipelineOptions
=
null
;
constructor
(
extension
)
{
super
(
extension
)
;
this
.
#
pipelineId
=
TrialML
.
getPipelineId
(
extension
.
id
)
;
this
.
#
engine
=
null
;
}
static
getPipelineId
(
extensionId
)
{
return
addonIdToEngineId
(
extensionId
)
;
}
async
#
createEngine
(
options
)
{
if
(
this
.
#
engine
)
{
throw
new
ExtensionError
(
"
Engine
already
created
"
)
;
}
options
.
engineId
=
this
.
#
pipelineId
;
const
{
extension
}
=
this
;
if
(
!
this
.
extension
|
|
this
.
extension
.
hasShutdown
)
{
throw
new
ExtensionError
(
"
Extension
has
already
shutdown
"
)
;
}
this
.
#
engine
=
await
createEngine
(
options
progressData
=
>
{
extension
.
emit
(
ENGINE_EVENT
progressData
)
;
}
)
;
}
#
runEngine
(
runOptions
)
{
return
this
.
#
engine
.
run
(
runOptions
)
;
}
static
async
onUninstall
(
extensionId
)
{
await
modelHub
.
deleteFilesByEngine
(
TrialML
.
getPipelineId
(
extensionId
)
)
;
return
true
;
}
getAPI
(
context
)
{
ensureInferenceEnabled
(
)
;
return
{
trial
:
{
ml
:
{
createEngine
:
async
request
=
>
{
if
(
!
SUPPORTED_TASKS
.
includes
(
request
.
taskName
)
)
{
throw
new
ExtensionError
(
Unsupported
task
{
request
.
taskName
}
)
;
}
try
{
this
.
#
pipelineOptions
=
new
PipelineOptions
(
request
)
;
await
this
.
#
createEngine
(
this
.
#
pipelineOptions
)
;
}
catch
(
error
)
{
throw
new
ExtensionError
(
error
.
message
)
;
}
}
runEngine
:
async
request
=
>
{
if
(
this
.
#
engine
?
.
engineStatus
=
=
=
"
closed
"
)
{
try
{
this
.
#
engine
=
null
;
await
this
.
#
createEngine
(
this
.
#
pipelineOptions
)
;
}
catch
(
error
)
{
throw
new
ExtensionError
(
error
.
message
)
;
}
}
const
runOptions
=
{
args
:
request
.
args
options
:
request
.
options
|
|
{
}
}
;
return
this
.
#
runEngine
(
runOptions
)
;
}
deleteCachedModels
:
async
(
)
=
>
{
await
modelHub
.
deleteFilesByEngine
(
this
.
#
pipelineId
)
;
return
true
;
}
onProgress
:
new
EventManager
(
{
context
name
:
"
trial
.
ml
.
onProgress
"
register
:
fire
=
>
{
const
callback
=
(
_evtName
progressData
)
=
>
{
fire
.
async
(
progressData
)
;
}
;
this
.
extension
.
on
(
ENGINE_EVENT
callback
)
;
return
(
)
=
>
{
this
.
extension
.
off
(
ENGINE_EVENT
callback
)
;
}
;
}
}
)
.
api
(
)
}
}
}
;
}
}
this
.
trial_ml
=
TrialML
;
