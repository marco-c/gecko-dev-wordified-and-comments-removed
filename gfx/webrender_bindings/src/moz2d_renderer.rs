#
!
[
deny
(
missing_docs
)
]
use
webrender
:
:
api
:
:
*
;
use
webrender
:
:
api
:
:
units
:
:
{
BlobDirtyRect
BlobToDeviceTranslation
DeviceIntRect
}
;
use
bindings
:
:
{
ByteSlice
MutByteSlice
wr_moz2d_render_cb
ArcVecU8
gecko_profiler_start_marker
gecko_profiler_end_marker
}
;
use
rayon
:
:
ThreadPool
;
use
rayon
:
:
prelude
:
:
*
;
use
std
:
:
collections
:
:
hash_map
:
:
HashMap
;
use
std
:
:
collections
:
:
hash_map
;
use
std
:
:
collections
:
:
btree_map
:
:
BTreeMap
;
use
std
:
:
collections
:
:
Bound
:
:
Included
;
use
std
:
:
mem
;
use
std
:
:
os
:
:
raw
:
:
{
c_void
c_char
}
;
use
std
:
:
ptr
;
use
std
:
:
sync
:
:
Arc
;
use
std
:
:
i32
;
use
std
;
use
euclid
:
:
Rect
;
#
[
cfg
(
target_os
=
"
windows
"
)
]
use
dwrote
;
#
[
cfg
(
target_os
=
"
macos
"
)
]
use
foreign_types
:
:
ForeignType
;
#
[
cfg
(
not
(
any
(
target_os
=
"
macos
"
target_os
=
"
windows
"
)
)
)
]
use
std
:
:
ffi
:
:
CString
;
#
[
cfg
(
not
(
any
(
target_os
=
"
macos
"
target_os
=
"
windows
"
)
)
)
]
use
std
:
:
os
:
:
unix
:
:
ffi
:
:
OsStrExt
;
macro_rules
!
dlog
{
(
(
e
:
expr
)
*
)
=
>
{
{
(
let
_
=
e
;
)
*
}
}
}
fn
dump_bounds
(
blob
:
&
[
u8
]
dirty_rect
:
Box2d
)
{
let
mut
index
=
BlobReader
:
:
new
(
blob
)
;
while
index
.
reader
.
has_more
(
)
{
let
e
=
index
.
read_entry
(
)
;
dlog
!
(
"
{
:
?
}
{
}
"
e
.
bounds
if
e
.
bounds
.
contained_by
(
&
dirty_rect
)
{
"
*
"
}
else
{
"
"
}
)
;
}
}
fn
dump_index
(
blob
:
&
[
u8
]
)
-
>
(
)
{
let
mut
index
=
BlobReader
:
:
new
(
blob
)
;
while
index
.
reader
.
has_more
(
)
{
let
e
=
index
.
read_entry
(
)
;
dlog
!
(
"
result
bounds
:
{
}
{
}
{
:
?
}
"
e
.
end
e
.
extra_end
e
.
bounds
)
;
}
}
pub
struct
Moz2dBlobImageHandler
{
workers
:
Arc
<
ThreadPool
>
workers_low_priority
:
Arc
<
ThreadPool
>
blob_commands
:
HashMap
<
BlobImageKey
BlobCommand
>
}
unsafe
fn
convert_from_bytes
<
T
:
Copy
>
(
slice
:
&
[
u8
]
)
-
>
T
{
assert
!
(
mem
:
:
size_of
:
:
<
T
>
(
)
<
=
slice
.
len
(
)
)
;
ptr
:
:
read_unaligned
(
slice
.
as_ptr
(
)
as
*
const
T
)
}
fn
convert_to_bytes
<
T
>
(
x
:
&
T
)
-
>
&
[
u8
]
{
unsafe
{
let
ip
:
*
const
T
=
x
;
let
bp
:
*
const
u8
=
ip
as
*
const
_
;
:
:
std
:
:
slice
:
:
from_raw_parts
(
bp
mem
:
:
size_of
:
:
<
T
>
(
)
)
}
}
struct
BufReader
<
'
a
>
{
buf
:
&
'
a
[
u8
]
pos
:
usize
}
impl
<
'
a
>
BufReader
<
'
a
>
{
fn
new
(
buf
:
&
'
a
[
u8
]
)
-
>
BufReader
<
'
a
>
{
BufReader
{
buf
:
buf
pos
:
0
}
}
unsafe
fn
read
<
T
:
Copy
>
(
&
mut
self
)
-
>
T
{
let
ret
=
convert_from_bytes
(
&
self
.
buf
[
self
.
pos
.
.
]
)
;
self
.
pos
+
=
mem
:
:
size_of
:
:
<
T
>
(
)
;
ret
}
fn
read_blob_font
(
&
mut
self
)
-
>
BlobFont
{
unsafe
{
self
.
read
:
:
<
BlobFont
>
(
)
}
}
fn
read_usize
(
&
mut
self
)
-
>
usize
{
unsafe
{
self
.
read
:
:
<
usize
>
(
)
}
}
fn
read_box
(
&
mut
self
)
-
>
Box2d
{
unsafe
{
self
.
read
:
:
<
Box2d
>
(
)
}
}
fn
has_more
(
&
self
)
-
>
bool
{
self
.
pos
<
self
.
buf
.
len
(
)
}
}
struct
BlobReader
<
'
a
>
{
reader
:
BufReader
<
'
a
>
begin
:
usize
}
#
[
derive
(
PartialEq
Debug
Eq
Clone
Copy
)
]
struct
IntPoint
{
x
:
i32
y
:
i32
}
struct
Entry
{
bounds
:
Box2d
begin
:
usize
end
:
usize
extra_end
:
usize
}
impl
<
'
a
>
BlobReader
<
'
a
>
{
fn
new
(
buf
:
&
'
a
[
u8
]
)
-
>
BlobReader
<
'
a
>
{
let
index_offset_pos
=
buf
.
len
(
)
-
mem
:
:
size_of
:
:
<
usize
>
(
)
;
assert
!
(
index_offset_pos
<
buf
.
len
(
)
)
;
let
index_offset
=
unsafe
{
convert_from_bytes
:
:
<
usize
>
(
&
buf
[
index_offset_pos
.
.
]
)
}
;
BlobReader
{
reader
:
BufReader
:
:
new
(
&
buf
[
index_offset
.
.
index_offset_pos
]
)
begin
:
0
}
}
fn
read_entry
(
&
mut
self
)
-
>
Entry
{
let
end
=
self
.
reader
.
read_usize
(
)
;
let
extra_end
=
self
.
reader
.
read_usize
(
)
;
let
bounds
=
self
.
reader
.
read_box
(
)
;
let
ret
=
Entry
{
begin
:
self
.
begin
end
extra_end
bounds
}
;
self
.
begin
=
extra_end
;
ret
}
}
struct
BlobWriter
{
data
:
Vec
<
u8
>
index
:
Vec
<
u8
>
}
impl
BlobWriter
{
fn
new
(
)
-
>
BlobWriter
{
BlobWriter
{
data
:
Vec
:
:
new
(
)
index
:
Vec
:
:
new
(
)
}
}
fn
new_entry
(
&
mut
self
extra_size
:
usize
bounds
:
Box2d
data
:
&
[
u8
]
)
{
self
.
data
.
extend_from_slice
(
data
)
;
self
.
index
.
extend_from_slice
(
convert_to_bytes
(
&
(
self
.
data
.
len
(
)
-
extra_size
)
)
)
;
self
.
index
.
extend_from_slice
(
convert_to_bytes
(
&
self
.
data
.
len
(
)
)
)
;
self
.
index
.
extend_from_slice
(
convert_to_bytes
(
&
bounds
.
x1
)
)
;
self
.
index
.
extend_from_slice
(
convert_to_bytes
(
&
bounds
.
y1
)
)
;
self
.
index
.
extend_from_slice
(
convert_to_bytes
(
&
bounds
.
x2
)
)
;
self
.
index
.
extend_from_slice
(
convert_to_bytes
(
&
bounds
.
y2
)
)
;
}
fn
finish
(
mut
self
)
-
>
Vec
<
u8
>
{
let
index_begin
=
self
.
data
.
len
(
)
;
self
.
data
.
extend_from_slice
(
&
self
.
index
)
;
self
.
data
.
extend_from_slice
(
convert_to_bytes
(
&
index_begin
)
)
;
self
.
data
}
}
#
[
derive
(
Debug
Eq
PartialEq
Clone
Copy
Ord
PartialOrd
)
]
#
[
repr
(
C
)
]
struct
Box2d
{
x1
:
i32
y1
:
i32
x2
:
i32
y2
:
i32
}
impl
Box2d
{
fn
contained_by
(
&
self
other
:
&
Box2d
)
-
>
bool
{
self
.
is_empty
(
)
|
|
(
self
.
x1
>
=
other
.
x1
&
&
self
.
x2
<
=
other
.
x2
&
&
self
.
y1
>
=
other
.
y1
&
&
self
.
y2
<
=
other
.
y2
)
}
fn
intersection
(
&
self
other
:
&
Box2d
)
-
>
Box2d
{
let
result
=
Box2d
{
x1
:
self
.
x1
.
max
(
other
.
x1
)
y1
:
self
.
y1
.
max
(
other
.
y1
)
x2
:
self
.
x2
.
min
(
other
.
x2
)
y2
:
self
.
y2
.
min
(
other
.
y2
)
}
;
if
self
.
is_empty
(
)
|
|
other
.
is_empty
(
)
{
assert
!
(
result
.
is_empty
(
)
)
;
}
result
}
fn
is_empty
(
&
self
)
-
>
bool
{
self
.
x2
<
=
self
.
x1
|
|
self
.
y2
<
=
self
.
y1
}
}
impl
<
T
>
From
<
Rect
<
i32
T
>
>
for
Box2d
{
fn
from
(
rect
:
Rect
<
i32
T
>
)
-
>
Box2d
{
(
&
rect
)
.
into
(
)
}
}
impl
<
T
>
From
<
&
Rect
<
i32
T
>
>
for
Box2d
{
fn
from
(
rect
:
&
Rect
<
i32
T
>
)
-
>
Box2d
{
Box2d
{
x1
:
rect
.
min_x
(
)
y1
:
rect
.
min_y
(
)
x2
:
rect
.
max_x
(
)
y2
:
rect
.
max_y
(
)
}
}
}
struct
CachedReader
<
'
a
>
{
reader
:
BlobReader
<
'
a
>
cache
:
BTreeMap
<
(
Box2d
u32
)
Entry
>
cache_index_counter
:
u32
}
impl
<
'
a
>
CachedReader
<
'
a
>
{
pub
fn
new
(
buf
:
&
'
a
[
u8
]
)
-
>
CachedReader
{
CachedReader
{
reader
:
BlobReader
:
:
new
(
buf
)
cache
:
BTreeMap
:
:
new
(
)
cache_index_counter
:
0
}
}
fn
take_entry_with_bounds_from_cache
(
&
mut
self
bounds
:
&
Box2d
)
-
>
Option
<
Entry
>
{
if
self
.
cache
.
is_empty
(
)
{
return
None
;
}
let
key_to_delete
=
match
self
.
cache
.
range
(
(
Included
(
(
*
bounds
0u32
)
)
Included
(
(
*
bounds
std
:
:
u32
:
:
MAX
)
)
)
)
.
next
(
)
{
Some
(
(
&
key
_
)
)
=
>
key
None
=
>
return
None
}
;
Some
(
self
.
cache
.
remove
(
&
key_to_delete
)
.
expect
(
"
We
just
got
this
key
from
range
it
needs
to
be
present
"
)
)
}
pub
fn
next_entry_with_bounds
(
&
mut
self
bounds
:
&
Box2d
ignore_rect
:
&
Box2d
)
-
>
Entry
{
if
let
Some
(
entry
)
=
self
.
take_entry_with_bounds_from_cache
(
bounds
)
{
return
entry
;
}
loop
{
let
old
=
self
.
reader
.
read_entry
(
)
;
if
old
.
bounds
=
=
*
bounds
{
return
old
;
}
else
if
!
old
.
bounds
.
contained_by
(
&
ignore_rect
)
{
self
.
cache
.
insert
(
(
old
.
bounds
self
.
cache_index_counter
)
old
)
;
self
.
cache_index_counter
+
=
1
;
}
}
}
}
fn
merge_blob_images
(
old_buf
:
&
[
u8
]
new_buf
:
&
[
u8
]
dirty_rect
:
Box2d
old_visible_rect
:
Box2d
new_visible_rect
:
Box2d
)
-
>
Vec
<
u8
>
{
let
mut
result
=
BlobWriter
:
:
new
(
)
;
dlog
!
(
"
dirty
rect
:
{
:
?
}
"
dirty_rect
)
;
dlog
!
(
"
old
:
"
)
;
dump_bounds
(
old_buf
dirty_rect
)
;
dlog
!
(
"
new
:
"
)
;
dump_bounds
(
new_buf
dirty_rect
)
;
dlog
!
(
"
old
visibile
rect
:
{
:
?
}
"
old_visible_rect
)
;
dlog
!
(
"
new
visibile
rect
:
{
:
?
}
"
new_visible_rect
)
;
let
mut
old_reader
=
CachedReader
:
:
new
(
old_buf
)
;
let
mut
new_reader
=
BlobReader
:
:
new
(
new_buf
)
;
let
preserved_rect
=
old_visible_rect
.
intersection
(
&
new_visible_rect
)
;
while
new_reader
.
reader
.
has_more
(
)
{
let
new
=
new_reader
.
read_entry
(
)
;
dlog
!
(
"
bounds
:
{
}
{
}
{
:
?
}
"
new
.
end
new
.
extra_end
new
.
bounds
)
;
let
preserved_bounds
=
new
.
bounds
.
intersection
(
&
preserved_rect
)
;
if
preserved_bounds
.
contained_by
(
&
dirty_rect
)
{
result
.
new_entry
(
new
.
extra_end
-
new
.
end
new
.
bounds
&
new_buf
[
new
.
begin
.
.
new
.
extra_end
]
)
;
}
else
{
let
old
=
old_reader
.
next_entry_with_bounds
(
&
new
.
bounds
&
dirty_rect
)
;
result
.
new_entry
(
old
.
extra_end
-
old
.
end
new
.
bounds
&
old_buf
[
old
.
begin
.
.
old
.
extra_end
]
)
}
}
while
old_reader
.
reader
.
reader
.
has_more
(
)
{
let
old
=
old_reader
.
reader
.
read_entry
(
)
;
dlog
!
(
"
new
bounds
:
{
}
{
}
{
:
?
}
"
old
.
end
old
.
extra_end
old
.
bounds
)
;
}
let
result
=
result
.
finish
(
)
;
dump_index
(
&
result
)
;
result
}
#
[
repr
(
C
)
]
#
[
derive
(
Copy
Clone
)
]
struct
BlobFont
{
font_instance_key
:
FontInstanceKey
scaled_font_ptr
:
u64
}
#
[
derive
(
Clone
)
]
struct
BlobCommand
{
data
:
Arc
<
BlobImageData
>
visible_rect
:
DeviceIntRect
tile_size
:
Option
<
TileSize
>
}
struct
Job
{
request
:
BlobImageRequest
descriptor
:
BlobImageDescriptor
commands
:
Arc
<
BlobImageData
>
dirty_rect
:
BlobDirtyRect
visible_rect
:
DeviceIntRect
tile_size
:
Option
<
TileSize
>
}
struct
Moz2dBlobRasterizer
{
workers
:
Arc
<
ThreadPool
>
workers_low_priority
:
Arc
<
ThreadPool
>
blob_commands
:
HashMap
<
BlobImageKey
BlobCommand
>
}
struct
GeckoProfilerMarker
{
name
:
&
'
static
[
u8
]
}
impl
GeckoProfilerMarker
{
pub
fn
new
(
name
:
&
'
static
[
u8
]
)
-
>
GeckoProfilerMarker
{
unsafe
{
gecko_profiler_start_marker
(
name
.
as_ptr
(
)
as
*
const
c_char
)
;
}
GeckoProfilerMarker
{
name
}
}
}
impl
Drop
for
GeckoProfilerMarker
{
fn
drop
(
&
mut
self
)
{
unsafe
{
gecko_profiler_end_marker
(
self
.
name
.
as_ptr
(
)
as
*
const
c_char
)
;
}
}
}
impl
AsyncBlobImageRasterizer
for
Moz2dBlobRasterizer
{
fn
rasterize
(
&
mut
self
requests
:
&
[
BlobImageParams
]
low_priority
:
bool
)
-
>
Vec
<
(
BlobImageRequest
BlobImageResult
)
>
{
let
_marker
=
GeckoProfilerMarker
:
:
new
(
b
"
BlobRasterization
\
0
"
)
;
let
requests
:
Vec
<
Job
>
=
requests
.
into_iter
(
)
.
map
(
|
params
|
{
let
command
=
&
self
.
blob_commands
[
&
params
.
request
.
key
]
;
let
blob
=
Arc
:
:
clone
(
&
command
.
data
)
;
assert
!
(
params
.
descriptor
.
rect
.
size
.
width
>
0
&
&
params
.
descriptor
.
rect
.
size
.
height
>
0
)
;
Job
{
request
:
params
.
request
descriptor
:
params
.
descriptor
commands
:
blob
visible_rect
:
command
.
visible_rect
dirty_rect
:
params
.
dirty_rect
tile_size
:
command
.
tile_size
}
}
)
.
collect
(
)
;
let
should_parallelize
=
if
low_priority
{
requests
.
len
(
)
>
2
}
else
{
requests
.
len
(
)
>
4
}
;
if
should_parallelize
{
let
lambda
=
|
|
{
requests
.
into_par_iter
(
)
.
map
(
rasterize_blob
)
.
collect
(
)
}
;
if
low_priority
{
self
.
workers_low_priority
.
install
(
lambda
)
}
else
{
self
.
workers
.
install
(
lambda
)
}
}
else
{
requests
.
into_iter
(
)
.
map
(
rasterize_blob
)
.
collect
(
)
}
}
}
fn
rasterize_blob
(
job
:
Job
)
-
>
(
BlobImageRequest
BlobImageResult
)
{
let
descriptor
=
job
.
descriptor
;
let
buf_size
=
(
descriptor
.
rect
.
size
.
width
*
descriptor
.
rect
.
size
.
height
*
descriptor
.
format
.
bytes_per_pixel
(
)
)
as
usize
;
let
mut
output
=
vec
!
[
0u8
;
buf_size
]
;
let
dirty_rect
=
match
job
.
dirty_rect
{
DirtyRect
:
:
Partial
(
rect
)
=
>
Some
(
rect
)
DirtyRect
:
:
All
=
>
None
}
;
assert
!
(
descriptor
.
rect
.
size
.
width
>
0
&
&
descriptor
.
rect
.
size
.
height
>
0
)
;
let
result
=
unsafe
{
if
wr_moz2d_render_cb
(
ByteSlice
:
:
new
(
&
job
.
commands
[
.
.
]
)
descriptor
.
format
&
descriptor
.
rect
&
job
.
visible_rect
job
.
tile_size
.
as_ref
(
)
job
.
request
.
tile
.
as_ref
(
)
dirty_rect
.
as_ref
(
)
MutByteSlice
:
:
new
(
output
.
as_mut_slice
(
)
)
)
{
let
dirty_rect
=
job
.
dirty_rect
.
to_subrect_of
(
&
descriptor
.
rect
)
;
let
tx
:
BlobToDeviceTranslation
=
(
-
descriptor
.
rect
.
origin
.
to_vector
(
)
)
.
into
(
)
;
let
rasterized_rect
=
tx
.
transform_rect
(
&
dirty_rect
)
;
Ok
(
RasterizedBlobImage
{
rasterized_rect
data
:
Arc
:
:
new
(
output
)
}
)
}
else
{
panic
!
(
"
Moz2D
replay
problem
"
)
;
}
}
;
(
job
.
request
result
)
}
impl
BlobImageHandler
for
Moz2dBlobImageHandler
{
fn
add
(
&
mut
self
key
:
BlobImageKey
data
:
Arc
<
BlobImageData
>
visible_rect
:
&
DeviceIntRect
tile_size
:
Option
<
TileSize
>
)
{
{
let
index
=
BlobReader
:
:
new
(
&
data
)
;
assert
!
(
index
.
reader
.
has_more
(
)
)
;
}
self
.
blob_commands
.
insert
(
key
BlobCommand
{
data
:
Arc
:
:
clone
(
&
data
)
visible_rect
:
*
visible_rect
tile_size
}
)
;
}
fn
update
(
&
mut
self
key
:
BlobImageKey
data
:
Arc
<
BlobImageData
>
visible_rect
:
&
DeviceIntRect
dirty_rect
:
&
BlobDirtyRect
)
{
match
self
.
blob_commands
.
entry
(
key
)
{
hash_map
:
:
Entry
:
:
Occupied
(
mut
e
)
=
>
{
let
command
=
e
.
get_mut
(
)
;
let
dirty_rect
=
if
let
DirtyRect
:
:
Partial
(
rect
)
=
*
dirty_rect
{
Box2d
{
x1
:
rect
.
min_x
(
)
y1
:
rect
.
min_y
(
)
x2
:
rect
.
max_x
(
)
y2
:
rect
.
max_y
(
)
}
}
else
{
Box2d
{
x1
:
i32
:
:
MIN
y1
:
i32
:
:
MIN
x2
:
i32
:
:
MAX
y2
:
i32
:
:
MAX
}
}
;
command
.
data
=
Arc
:
:
new
(
merge_blob_images
(
&
command
.
data
&
data
dirty_rect
command
.
visible_rect
.
into
(
)
visible_rect
.
into
(
)
)
)
;
command
.
visible_rect
=
*
visible_rect
;
}
_
=
>
{
panic
!
(
"
missing
image
key
"
)
;
}
}
}
fn
delete
(
&
mut
self
key
:
BlobImageKey
)
{
self
.
blob_commands
.
remove
(
&
key
)
;
}
fn
create_blob_rasterizer
(
&
mut
self
)
-
>
Box
<
dyn
AsyncBlobImageRasterizer
>
{
Box
:
:
new
(
Moz2dBlobRasterizer
{
workers
:
Arc
:
:
clone
(
&
self
.
workers
)
workers_low_priority
:
Arc
:
:
clone
(
&
self
.
workers_low_priority
)
blob_commands
:
self
.
blob_commands
.
clone
(
)
}
)
}
fn
delete_font
(
&
mut
self
font
:
FontKey
)
{
unsafe
{
DeleteFontData
(
font
)
;
}
}
fn
delete_font_instance
(
&
mut
self
key
:
FontInstanceKey
)
{
unsafe
{
DeleteBlobFont
(
key
)
;
}
}
fn
clear_namespace
(
&
mut
self
namespace
:
IdNamespace
)
{
unsafe
{
ClearBlobImageResources
(
namespace
)
;
}
}
fn
prepare_resources
(
&
mut
self
resources
:
&
dyn
BlobImageResources
requests
:
&
[
BlobImageParams
]
)
{
for
params
in
requests
{
let
commands
=
&
self
.
blob_commands
[
&
params
.
request
.
key
]
;
let
blob
=
Arc
:
:
clone
(
&
commands
.
data
)
;
self
.
prepare_request
(
&
blob
resources
)
;
}
}
}
use
bindings
:
:
{
WrFontKey
WrFontInstanceKey
WrIdNamespace
}
;
#
[
allow
(
improper_ctypes
)
]
extern
"
C
"
{
fn
AddFontData
(
key
:
WrFontKey
data
:
*
const
u8
size
:
usize
index
:
u32
vec
:
&
ArcVecU8
)
;
fn
AddNativeFontHandle
(
key
:
WrFontKey
handle
:
*
mut
c_void
index
:
u32
)
;
fn
DeleteFontData
(
key
:
WrFontKey
)
;
fn
AddBlobFont
(
instance_key
:
WrFontInstanceKey
font_key
:
WrFontKey
size
:
f32
options
:
Option
<
&
FontInstanceOptions
>
platform_options
:
Option
<
&
FontInstancePlatformOptions
>
variations
:
*
const
FontVariation
num_variations
:
usize
)
;
fn
DeleteBlobFont
(
key
:
WrFontInstanceKey
)
;
fn
ClearBlobImageResources
(
namespace
:
WrIdNamespace
)
;
}
impl
Moz2dBlobImageHandler
{
pub
fn
new
(
workers
:
Arc
<
ThreadPool
>
workers_low_priority
:
Arc
<
ThreadPool
>
)
-
>
Self
{
Moz2dBlobImageHandler
{
blob_commands
:
HashMap
:
:
new
(
)
workers
:
workers
workers_low_priority
:
workers_low_priority
}
}
fn
prepare_request
(
&
self
blob
:
&
[
u8
]
resources
:
&
dyn
BlobImageResources
)
{
#
[
cfg
(
target_os
=
"
windows
"
)
]
fn
process_native_font_handle
(
key
:
FontKey
handle
:
&
NativeFontHandle
)
{
let
file
=
dwrote
:
:
FontFile
:
:
new_from_path
(
&
handle
.
path
)
.
unwrap
(
)
;
let
face
=
file
.
create_face
(
handle
.
index
dwrote
:
:
DWRITE_FONT_SIMULATIONS_NONE
)
.
unwrap
(
)
;
unsafe
{
AddNativeFontHandle
(
key
face
.
as_ptr
(
)
as
*
mut
c_void
0
)
}
;
}
#
[
cfg
(
target_os
=
"
macos
"
)
]
fn
process_native_font_handle
(
key
:
FontKey
handle
:
&
NativeFontHandle
)
{
unsafe
{
AddNativeFontHandle
(
key
handle
.
0
.
as_ptr
(
)
as
*
mut
c_void
0
)
}
;
}
#
[
cfg
(
not
(
any
(
target_os
=
"
macos
"
target_os
=
"
windows
"
)
)
)
]
fn
process_native_font_handle
(
key
:
FontKey
handle
:
&
NativeFontHandle
)
{
let
cstr
=
CString
:
:
new
(
handle
.
path
.
as_os_str
(
)
.
as_bytes
(
)
)
.
unwrap
(
)
;
unsafe
{
AddNativeFontHandle
(
key
cstr
.
as_ptr
(
)
as
*
mut
c_void
handle
.
index
)
}
;
}
fn
process_fonts
(
mut
extra_data
:
BufReader
resources
:
&
dyn
BlobImageResources
unscaled_fonts
:
&
mut
Vec
<
FontKey
>
scaled_fonts
:
&
mut
Vec
<
FontInstanceKey
>
)
{
let
font_count
=
extra_data
.
read_usize
(
)
;
for
_
in
0
.
.
font_count
{
let
font
=
extra_data
.
read_blob_font
(
)
;
if
scaled_fonts
.
contains
(
&
font
.
font_instance_key
)
{
continue
;
}
scaled_fonts
.
push
(
font
.
font_instance_key
)
;
if
let
Some
(
instance
)
=
resources
.
get_font_instance_data
(
font
.
font_instance_key
)
{
if
!
unscaled_fonts
.
contains
(
&
instance
.
font_key
)
{
unscaled_fonts
.
push
(
instance
.
font_key
)
;
let
template
=
resources
.
get_font_data
(
instance
.
font_key
)
;
match
template
{
&
FontTemplate
:
:
Raw
(
ref
data
ref
index
)
=
>
{
unsafe
{
AddFontData
(
instance
.
font_key
data
.
as_ptr
(
)
data
.
len
(
)
*
index
data
)
;
}
}
&
FontTemplate
:
:
Native
(
ref
handle
)
=
>
{
process_native_font_handle
(
instance
.
font_key
handle
)
;
}
}
}
unsafe
{
AddBlobFont
(
font
.
font_instance_key
instance
.
font_key
instance
.
size
.
to_f32_px
(
)
instance
.
options
.
as_ref
(
)
instance
.
platform_options
.
as_ref
(
)
instance
.
variations
.
as_ptr
(
)
instance
.
variations
.
len
(
)
)
;
}
}
}
}
{
let
mut
index
=
BlobReader
:
:
new
(
blob
)
;
let
mut
unscaled_fonts
=
Vec
:
:
new
(
)
;
let
mut
scaled_fonts
=
Vec
:
:
new
(
)
;
while
index
.
reader
.
pos
<
index
.
reader
.
buf
.
len
(
)
{
let
e
=
index
.
read_entry
(
)
;
process_fonts
(
BufReader
:
:
new
(
&
blob
[
e
.
end
.
.
e
.
extra_end
]
)
resources
&
mut
unscaled_fonts
&
mut
scaled_fonts
)
;
}
}
}
}
