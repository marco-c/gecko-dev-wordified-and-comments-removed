#
!
[
deny
(
missing_docs
)
]
use
bindings
:
:
{
wr_moz2d_render_cb
ArcVecU8
ByteSlice
MutByteSlice
}
;
use
gecko_profiler
:
:
gecko_profiler_label
;
use
gecko_profiler
:
:
auto_profiler_marker_tracing
;
use
rayon
:
:
prelude
:
:
*
;
use
rayon
:
:
ThreadPool
;
use
webrender
:
:
api
:
:
units
:
:
{
BlobDirtyRect
BlobToDeviceTranslation
DeviceIntRect
}
;
use
webrender
:
:
api
:
:
*
;
use
euclid
:
:
point2
;
use
std
:
:
collections
:
:
btree_map
:
:
BTreeMap
;
use
std
:
:
collections
:
:
hash_map
;
use
std
:
:
collections
:
:
hash_map
:
:
HashMap
;
use
std
:
:
collections
:
:
Bound
:
:
Included
;
use
std
:
:
i32
;
use
std
:
:
mem
;
use
std
:
:
os
:
:
raw
:
:
c_void
;
use
std
:
:
ptr
;
use
std
:
:
sync
:
:
Arc
;
#
[
cfg
(
any
(
target_os
=
"
macos
"
target_os
=
"
ios
"
)
)
]
use
core_foundation
:
:
string
:
:
CFString
;
#
[
cfg
(
any
(
target_os
=
"
macos
"
target_os
=
"
ios
"
)
)
]
use
core_graphics
:
:
font
:
:
CGFont
;
#
[
cfg
(
any
(
target_os
=
"
macos
"
target_os
=
"
ios
"
)
)
]
use
foreign_types
:
:
ForeignType
;
#
[
cfg
(
not
(
any
(
target_os
=
"
macos
"
target_os
=
"
ios
"
target_os
=
"
windows
"
)
)
)
]
use
std
:
:
ffi
:
:
CString
;
#
[
cfg
(
not
(
any
(
target_os
=
"
macos
"
target_os
=
"
ios
"
target_os
=
"
windows
"
)
)
)
]
use
std
:
:
os
:
:
unix
:
:
ffi
:
:
OsStrExt
;
macro_rules
!
dlog
{
(
(
e
:
expr
)
*
)
=
>
{
{
(
let
_
=
e
;
)
*
}
}
}
fn
dump_bounds
(
blob
:
&
[
u8
]
dirty_rect
:
DeviceIntRect
)
{
let
mut
index
=
BlobReader
:
:
new
(
blob
)
;
while
index
.
reader
.
has_more
(
)
{
let
e
=
index
.
read_entry
(
)
;
dlog
!
(
"
{
:
?
}
{
}
"
e
.
bounds
if
dirty_rect
.
contains_box
(
&
e
.
bounds
)
{
"
*
"
}
else
{
"
"
}
)
;
}
}
fn
dump_index
(
blob
:
&
[
u8
]
)
{
let
mut
index
=
BlobReader
:
:
new
(
blob
)
;
while
index
.
reader
.
has_more
(
)
{
let
e
=
index
.
read_entry
(
)
;
dlog
!
(
"
result
bounds
:
{
}
{
}
{
:
?
}
"
e
.
end
e
.
extra_end
e
.
bounds
)
;
}
}
pub
struct
Moz2dBlobImageHandler
{
workers
:
Arc
<
ThreadPool
>
workers_low_priority
:
Arc
<
ThreadPool
>
blob_commands
:
HashMap
<
BlobImageKey
BlobCommand
>
enable_multithreading
:
bool
}
unsafe
fn
convert_from_bytes
<
T
:
Copy
>
(
slice
:
&
[
u8
]
)
-
>
T
{
assert
!
(
mem
:
:
size_of
:
:
<
T
>
(
)
<
=
slice
.
len
(
)
)
;
ptr
:
:
read_unaligned
(
slice
.
as_ptr
(
)
as
*
const
T
)
}
fn
convert_to_bytes
<
T
>
(
x
:
&
T
)
-
>
&
[
u8
]
{
unsafe
{
let
ip
:
*
const
T
=
x
;
let
bp
:
*
const
u8
=
ip
as
*
const
_
;
:
:
std
:
:
slice
:
:
from_raw_parts
(
bp
mem
:
:
size_of
:
:
<
T
>
(
)
)
}
}
struct
BufReader
<
'
a
>
{
buf
:
&
'
a
[
u8
]
pos
:
usize
}
impl
<
'
a
>
BufReader
<
'
a
>
{
fn
new
(
buf
:
&
'
a
[
u8
]
)
-
>
BufReader
<
'
a
>
{
BufReader
{
buf
pos
:
0
}
}
unsafe
fn
read
<
T
:
Copy
>
(
&
mut
self
)
-
>
T
{
let
ret
=
convert_from_bytes
(
&
self
.
buf
[
self
.
pos
.
.
]
)
;
self
.
pos
+
=
mem
:
:
size_of
:
:
<
T
>
(
)
;
ret
}
fn
read_blob_font
(
&
mut
self
)
-
>
BlobFont
{
unsafe
{
self
.
read
:
:
<
BlobFont
>
(
)
}
}
fn
read_usize
(
&
mut
self
)
-
>
usize
{
unsafe
{
self
.
read
:
:
<
usize
>
(
)
}
}
fn
read_box
(
&
mut
self
)
-
>
DeviceIntRect
{
unsafe
{
self
.
read
:
:
<
DeviceIntRect
>
(
)
}
}
fn
has_more
(
&
self
)
-
>
bool
{
self
.
pos
<
self
.
buf
.
len
(
)
}
}
struct
BlobReader
<
'
a
>
{
reader
:
BufReader
<
'
a
>
begin
:
usize
}
struct
Entry
{
bounds
:
DeviceIntRect
begin
:
usize
end
:
usize
extra_end
:
usize
}
impl
<
'
a
>
BlobReader
<
'
a
>
{
fn
new
(
buf
:
&
'
a
[
u8
]
)
-
>
BlobReader
<
'
a
>
{
let
index_offset_pos
=
buf
.
len
(
)
-
mem
:
:
size_of
:
:
<
usize
>
(
)
;
assert
!
(
index_offset_pos
<
buf
.
len
(
)
)
;
let
index_offset
=
unsafe
{
convert_from_bytes
:
:
<
usize
>
(
&
buf
[
index_offset_pos
.
.
]
)
}
;
BlobReader
{
reader
:
BufReader
:
:
new
(
&
buf
[
index_offset
.
.
index_offset_pos
]
)
begin
:
0
}
}
fn
read_entry
(
&
mut
self
)
-
>
Entry
{
let
end
=
self
.
reader
.
read_usize
(
)
;
let
extra_end
=
self
.
reader
.
read_usize
(
)
;
let
bounds
=
self
.
reader
.
read_box
(
)
;
let
ret
=
Entry
{
begin
:
self
.
begin
end
extra_end
bounds
}
;
self
.
begin
=
extra_end
;
ret
}
}
struct
BlobWriter
{
data
:
Vec
<
u8
>
index
:
Vec
<
u8
>
}
impl
BlobWriter
{
fn
new
(
)
-
>
BlobWriter
{
BlobWriter
{
data
:
Vec
:
:
new
(
)
index
:
Vec
:
:
new
(
)
}
}
fn
new_entry
(
&
mut
self
extra_size
:
usize
bounds
:
DeviceIntRect
data
:
&
[
u8
]
)
{
self
.
data
.
extend_from_slice
(
data
)
;
self
.
index
.
extend_from_slice
(
convert_to_bytes
(
&
(
self
.
data
.
len
(
)
-
extra_size
)
)
)
;
self
.
index
.
extend_from_slice
(
convert_to_bytes
(
&
self
.
data
.
len
(
)
)
)
;
self
.
index
.
extend_from_slice
(
convert_to_bytes
(
&
bounds
.
min
.
x
)
)
;
self
.
index
.
extend_from_slice
(
convert_to_bytes
(
&
bounds
.
min
.
y
)
)
;
self
.
index
.
extend_from_slice
(
convert_to_bytes
(
&
bounds
.
max
.
x
)
)
;
self
.
index
.
extend_from_slice
(
convert_to_bytes
(
&
bounds
.
max
.
y
)
)
;
}
fn
finish
(
mut
self
)
-
>
Vec
<
u8
>
{
let
index_begin
=
self
.
data
.
len
(
)
;
self
.
data
.
extend_from_slice
(
&
self
.
index
)
;
self
.
data
.
extend_from_slice
(
convert_to_bytes
(
&
index_begin
)
)
;
self
.
data
}
}
#
[
derive
(
Copy
Clone
Debug
PartialEq
Eq
PartialOrd
Ord
)
]
struct
CacheKey
{
x1
:
i32
y1
:
i32
x2
:
i32
y2
:
i32
cache_order
:
u32
}
impl
CacheKey
{
pub
fn
new
(
bounds
:
DeviceIntRect
cache_order
:
u32
)
-
>
Self
{
CacheKey
{
x1
:
bounds
.
min
.
x
y1
:
bounds
.
min
.
y
x2
:
bounds
.
max
.
x
y2
:
bounds
.
max
.
y
cache_order
}
}
}
struct
CachedReader
<
'
a
>
{
reader
:
BlobReader
<
'
a
>
cache
:
BTreeMap
<
CacheKey
Entry
>
cache_index_counter
:
u32
}
impl
<
'
a
>
CachedReader
<
'
a
>
{
pub
fn
new
(
buf
:
&
'
a
[
u8
]
)
-
>
Self
{
CachedReader
{
reader
:
BlobReader
:
:
new
(
buf
)
cache
:
BTreeMap
:
:
new
(
)
cache_index_counter
:
0
}
}
fn
take_entry_with_bounds_from_cache
(
&
mut
self
bounds
:
&
DeviceIntRect
)
-
>
Option
<
Entry
>
{
if
self
.
cache
.
is_empty
(
)
{
return
None
;
}
let
key_to_delete
=
match
self
.
cache
.
range
(
(
Included
(
CacheKey
:
:
new
(
*
bounds
0u32
)
)
Included
(
CacheKey
:
:
new
(
*
bounds
std
:
:
u32
:
:
MAX
)
)
)
)
.
next
(
)
{
Some
(
(
&
key
_
)
)
=
>
key
None
=
>
return
None
}
;
Some
(
self
.
cache
.
remove
(
&
key_to_delete
)
.
expect
(
"
We
just
got
this
key
from
range
it
needs
to
be
present
"
)
)
}
pub
fn
next_entry_with_bounds
(
&
mut
self
bounds
:
&
DeviceIntRect
ignore_rect
:
&
DeviceIntRect
)
-
>
Entry
{
if
let
Some
(
entry
)
=
self
.
take_entry_with_bounds_from_cache
(
bounds
)
{
return
entry
;
}
loop
{
let
old
=
self
.
reader
.
read_entry
(
)
;
if
old
.
bounds
=
=
*
bounds
{
return
old
;
}
else
if
!
ignore_rect
.
contains_box
(
&
old
.
bounds
)
{
self
.
cache
.
insert
(
CacheKey
:
:
new
(
old
.
bounds
self
.
cache_index_counter
)
old
)
;
self
.
cache_index_counter
+
=
1
;
}
}
}
}
fn
merge_blob_images
(
old_buf
:
&
[
u8
]
new_buf
:
&
[
u8
]
dirty_rect
:
DeviceIntRect
old_visible_rect
:
DeviceIntRect
new_visible_rect
:
DeviceIntRect
)
-
>
Vec
<
u8
>
{
let
mut
result
=
BlobWriter
:
:
new
(
)
;
dlog
!
(
"
dirty
rect
:
{
:
?
}
"
dirty_rect
)
;
dlog
!
(
"
old
:
"
)
;
dump_bounds
(
old_buf
dirty_rect
)
;
dlog
!
(
"
new
:
"
)
;
dump_bounds
(
new_buf
dirty_rect
)
;
dlog
!
(
"
old
visibile
rect
:
{
:
?
}
"
old_visible_rect
)
;
dlog
!
(
"
new
visibile
rect
:
{
:
?
}
"
new_visible_rect
)
;
let
mut
old_reader
=
CachedReader
:
:
new
(
old_buf
)
;
let
mut
new_reader
=
BlobReader
:
:
new
(
new_buf
)
;
let
preserved_rect
=
old_visible_rect
.
intersection_unchecked
(
&
new_visible_rect
)
;
while
new_reader
.
reader
.
has_more
(
)
{
let
new
=
new_reader
.
read_entry
(
)
;
dlog
!
(
"
bounds
:
{
}
{
}
{
:
?
}
"
new
.
end
new
.
extra_end
new
.
bounds
)
;
let
preserved_bounds
=
new
.
bounds
.
intersection_unchecked
(
&
preserved_rect
)
;
if
dirty_rect
.
contains_box
(
&
preserved_bounds
)
{
result
.
new_entry
(
new
.
extra_end
-
new
.
end
new
.
bounds
&
new_buf
[
new
.
begin
.
.
new
.
extra_end
]
)
;
}
else
{
let
old
=
old_reader
.
next_entry_with_bounds
(
&
new
.
bounds
&
dirty_rect
)
;
result
.
new_entry
(
old
.
extra_end
-
old
.
end
new
.
bounds
&
old_buf
[
old
.
begin
.
.
old
.
extra_end
]
)
}
}
while
old_reader
.
reader
.
reader
.
has_more
(
)
{
let
old
=
old_reader
.
reader
.
read_entry
(
)
;
dlog
!
(
"
new
bounds
:
{
}
{
}
{
:
?
}
"
old
.
end
old
.
extra_end
old
.
bounds
)
;
}
let
result
=
result
.
finish
(
)
;
dump_index
(
&
result
)
;
result
}
#
[
repr
(
C
)
]
#
[
derive
(
Copy
Clone
)
]
struct
BlobFont
{
font_instance_key
:
FontInstanceKey
scaled_font_ptr
:
u64
}
#
[
derive
(
Clone
)
]
struct
BlobCommand
{
data
:
Arc
<
BlobImageData
>
visible_rect
:
DeviceIntRect
tile_size
:
TileSize
}
struct
Job
{
request
:
BlobImageRequest
descriptor
:
BlobImageDescriptor
commands
:
Arc
<
BlobImageData
>
dirty_rect
:
BlobDirtyRect
visible_rect
:
DeviceIntRect
tile_size
:
TileSize
output
:
MutableTileBuffer
}
struct
Moz2dBlobRasterizer
{
workers
:
Arc
<
ThreadPool
>
workers_low_priority
:
Arc
<
ThreadPool
>
blob_commands
:
HashMap
<
BlobImageKey
BlobCommand
>
enable_multithreading
:
bool
}
impl
AsyncBlobImageRasterizer
for
Moz2dBlobRasterizer
{
fn
rasterize
(
&
mut
self
requests
:
&
[
BlobImageParams
]
low_priority
:
bool
tile_pool
:
&
mut
BlobTilePool
)
-
>
Vec
<
(
BlobImageRequest
BlobImageResult
)
>
{
gecko_profiler_label
!
(
Graphics
Rasterization
)
;
auto_profiler_marker_tracing
!
(
"
BlobRasterization
"
gecko_profiler
:
:
gecko_profiler_category
!
(
Graphics
)
Default
:
:
default
(
)
"
Webrender
"
.
into
(
)
)
;
let
requests
:
Vec
<
Job
>
=
requests
.
iter
(
)
.
map
(
|
params
|
{
let
command
=
&
self
.
blob_commands
[
&
params
.
request
.
key
]
;
let
blob
=
Arc
:
:
clone
(
&
command
.
data
)
;
assert
!
(
!
params
.
descriptor
.
rect
.
is_empty
(
)
)
;
let
buf_size
=
(
params
.
descriptor
.
rect
.
area
(
)
*
params
.
descriptor
.
format
.
bytes_per_pixel
(
)
)
as
usize
;
Job
{
request
:
params
.
request
descriptor
:
params
.
descriptor
commands
:
blob
visible_rect
:
command
.
visible_rect
dirty_rect
:
params
.
dirty_rect
tile_size
:
command
.
tile_size
output
:
tile_pool
.
get_buffer
(
buf_size
)
}
}
)
.
collect
(
)
;
let
should_parallelize
=
if
!
self
.
enable_multithreading
{
false
}
else
if
low_priority
{
requests
.
len
(
)
>
2
}
else
{
requests
.
len
(
)
>
4
}
;
let
result
=
if
should_parallelize
{
let
lambda
=
|
|
requests
.
into_par_iter
(
)
.
map
(
rasterize_blob
)
.
collect
(
)
;
if
low_priority
{
self
.
workers_low_priority
.
install
(
lambda
)
}
else
{
self
.
workers
.
install
(
lambda
)
}
}
else
{
requests
.
into_iter
(
)
.
map
(
rasterize_blob
)
.
collect
(
)
}
;
result
}
}
fn
autoreleasepool
<
T
F
:
FnOnce
(
)
-
>
T
>
(
f
:
F
)
-
>
T
{
#
[
cfg
(
target_os
=
"
macos
"
)
]
{
objc
:
:
rc
:
:
autoreleasepool
(
f
)
}
#
[
cfg
(
not
(
target_os
=
"
macos
"
)
)
]
{
f
(
)
}
}
fn
rasterize_blob
(
mut
job
:
Job
)
-
>
(
BlobImageRequest
BlobImageResult
)
{
gecko_profiler_label
!
(
Graphics
Rasterization
)
;
let
descriptor
=
job
.
descriptor
;
let
dirty_rect
=
match
job
.
dirty_rect
{
DirtyRect
:
:
Partial
(
rect
)
=
>
Some
(
rect
)
DirtyRect
:
:
All
=
>
None
}
;
assert
!
(
!
descriptor
.
rect
.
is_empty
(
)
)
;
let
request
=
job
.
request
;
let
result
=
autoreleasepool
(
|
|
{
unsafe
{
if
wr_moz2d_render_cb
(
ByteSlice
:
:
new
(
&
job
.
commands
[
.
.
]
)
descriptor
.
format
&
descriptor
.
rect
&
job
.
visible_rect
job
.
tile_size
&
request
.
tile
dirty_rect
.
as_ref
(
)
MutByteSlice
:
:
new
(
job
.
output
.
as_mut_slice
(
)
)
)
{
let
dirty_rect
=
job
.
dirty_rect
.
to_subrect_of
(
&
descriptor
.
rect
)
;
let
tx
:
BlobToDeviceTranslation
=
(
-
descriptor
.
rect
.
min
.
to_vector
(
)
)
.
into
(
)
;
let
rasterized_rect
=
tx
.
transform_box
(
&
dirty_rect
)
;
Ok
(
RasterizedBlobImage
{
rasterized_rect
data
:
job
.
output
.
into_arc
(
)
}
)
}
else
{
panic
!
(
"
Moz2D
replay
problem
"
)
;
}
}
}
)
;
(
request
result
)
}
impl
BlobImageHandler
for
Moz2dBlobImageHandler
{
fn
create_similar
(
&
self
)
-
>
Box
<
dyn
BlobImageHandler
>
{
Box
:
:
new
(
Self
:
:
new
(
Arc
:
:
clone
(
&
self
.
workers
)
Arc
:
:
clone
(
&
self
.
workers_low_priority
)
)
)
}
fn
add
(
&
mut
self
key
:
BlobImageKey
data
:
Arc
<
BlobImageData
>
visible_rect
:
&
DeviceIntRect
tile_size
:
TileSize
)
{
{
let
index
=
BlobReader
:
:
new
(
&
data
)
;
assert
!
(
index
.
reader
.
has_more
(
)
)
;
}
self
.
blob_commands
.
insert
(
key
BlobCommand
{
data
:
Arc
:
:
clone
(
&
data
)
visible_rect
:
*
visible_rect
tile_size
}
)
;
}
fn
update
(
&
mut
self
key
:
BlobImageKey
data
:
Arc
<
BlobImageData
>
visible_rect
:
&
DeviceIntRect
dirty_rect
:
&
BlobDirtyRect
)
{
match
self
.
blob_commands
.
entry
(
key
)
{
hash_map
:
:
Entry
:
:
Occupied
(
mut
e
)
=
>
{
let
command
=
e
.
get_mut
(
)
;
let
dirty_rect
=
if
let
DirtyRect
:
:
Partial
(
rect
)
=
*
dirty_rect
{
rect
.
cast_unit
(
)
}
else
{
DeviceIntRect
{
min
:
point2
(
i32
:
:
MIN
i32
:
:
MIN
)
max
:
point2
(
i32
:
:
MAX
i32
:
:
MAX
)
}
}
;
command
.
data
=
Arc
:
:
new
(
merge_blob_images
(
&
command
.
data
&
data
dirty_rect
command
.
visible_rect
*
visible_rect
)
)
;
command
.
visible_rect
=
*
visible_rect
;
}
_
=
>
{
panic
!
(
"
missing
image
key
"
)
;
}
}
}
fn
delete
(
&
mut
self
key
:
BlobImageKey
)
{
self
.
blob_commands
.
remove
(
&
key
)
;
}
fn
create_blob_rasterizer
(
&
mut
self
)
-
>
Box
<
dyn
AsyncBlobImageRasterizer
>
{
Box
:
:
new
(
Moz2dBlobRasterizer
{
workers
:
Arc
:
:
clone
(
&
self
.
workers
)
workers_low_priority
:
Arc
:
:
clone
(
&
self
.
workers_low_priority
)
blob_commands
:
self
.
blob_commands
.
clone
(
)
enable_multithreading
:
self
.
enable_multithreading
}
)
}
fn
delete_font
(
&
mut
self
font
:
FontKey
)
{
unsafe
{
DeleteFontData
(
font
)
;
}
}
fn
delete_font_instance
(
&
mut
self
key
:
FontInstanceKey
)
{
unsafe
{
DeleteBlobFont
(
key
)
;
}
}
fn
clear_namespace
(
&
mut
self
namespace
:
IdNamespace
)
{
unsafe
{
ClearBlobImageResources
(
namespace
)
;
}
}
fn
prepare_resources
(
&
mut
self
resources
:
&
dyn
BlobImageResources
requests
:
&
[
BlobImageParams
]
)
{
for
params
in
requests
{
let
commands
=
&
self
.
blob_commands
[
&
params
.
request
.
key
]
;
let
blob
=
Arc
:
:
clone
(
&
commands
.
data
)
;
self
.
prepare_request
(
&
blob
resources
)
;
}
}
fn
enable_multithreading
(
&
mut
self
enable
:
bool
)
{
self
.
enable_multithreading
=
enable
;
}
}
use
bindings
:
:
{
WrFontInstanceKey
WrFontKey
WrIdNamespace
}
;
#
[
allow
(
improper_ctypes
)
]
extern
"
C
"
{
fn
HasFontData
(
key
:
WrFontKey
)
-
>
bool
;
fn
AddFontData
(
key
:
WrFontKey
data
:
*
const
u8
size
:
usize
index
:
u32
vec
:
&
ArcVecU8
)
;
fn
AddNativeFontHandle
(
key
:
WrFontKey
handle
:
*
mut
c_void
index
:
u32
)
;
fn
DeleteFontData
(
key
:
WrFontKey
)
;
fn
AddBlobFont
(
instance_key
:
WrFontInstanceKey
font_key
:
WrFontKey
size
:
f32
options
:
Option
<
&
FontInstanceOptions
>
platform_options
:
Option
<
&
FontInstancePlatformOptions
>
variations
:
*
const
FontVariation
num_variations
:
usize
)
;
fn
DeleteBlobFont
(
key
:
WrFontInstanceKey
)
;
fn
ClearBlobImageResources
(
namespace
:
WrIdNamespace
)
;
}
impl
Moz2dBlobImageHandler
{
pub
fn
new
(
workers
:
Arc
<
ThreadPool
>
workers_low_priority
:
Arc
<
ThreadPool
>
)
-
>
Self
{
Moz2dBlobImageHandler
{
blob_commands
:
HashMap
:
:
new
(
)
workers
workers_low_priority
enable_multithreading
:
true
}
}
fn
prepare_request
(
&
self
blob
:
&
[
u8
]
resources
:
&
dyn
BlobImageResources
)
{
#
[
cfg
(
target_os
=
"
windows
"
)
]
fn
process_native_font_handle
(
key
:
FontKey
handle
:
&
NativeFontHandle
)
{
let
file
=
dwrote
:
:
FontFile
:
:
new_from_path
(
&
handle
.
path
)
.
unwrap
(
)
;
let
face
=
file
.
create_face
(
handle
.
index
dwrote
:
:
DWRITE_FONT_SIMULATIONS_NONE
)
.
unwrap
(
)
;
unsafe
{
AddNativeFontHandle
(
key
face
.
as_ptr
(
)
as
*
mut
c_void
0
)
}
;
}
#
[
cfg
(
any
(
target_os
=
"
macos
"
target_os
=
"
ios
"
)
)
]
fn
process_native_font_handle
(
key
:
FontKey
handle
:
&
NativeFontHandle
)
{
let
font
=
match
CGFont
:
:
from_name
(
&
CFString
:
:
new
(
&
handle
.
name
)
)
{
Ok
(
font
)
=
>
font
Err
(
_
)
=
>
{
CGFont
:
:
from_name
(
&
CFString
:
:
from_static_string
(
"
Lucida
Grande
"
)
)
.
expect
(
"
Failed
reading
font
descriptor
and
could
not
load
fallback
font
"
)
}
}
;
unsafe
{
AddNativeFontHandle
(
key
font
.
as_ptr
(
)
as
*
mut
c_void
0
)
}
;
}
#
[
cfg
(
not
(
any
(
target_os
=
"
macos
"
target_os
=
"
ios
"
target_os
=
"
windows
"
)
)
)
]
fn
process_native_font_handle
(
key
:
FontKey
handle
:
&
NativeFontHandle
)
{
let
cstr
=
CString
:
:
new
(
handle
.
path
.
as_os_str
(
)
.
as_bytes
(
)
)
.
unwrap
(
)
;
unsafe
{
AddNativeFontHandle
(
key
cstr
.
as_ptr
(
)
as
*
mut
c_void
handle
.
index
)
}
;
}
fn
process_fonts
(
mut
extra_data
:
BufReader
resources
:
&
dyn
BlobImageResources
unscaled_fonts
:
&
mut
Vec
<
FontKey
>
scaled_fonts
:
&
mut
Vec
<
FontInstanceKey
>
)
{
let
font_count
=
extra_data
.
read_usize
(
)
;
for
_
in
0
.
.
font_count
{
let
font
=
extra_data
.
read_blob_font
(
)
;
if
scaled_fonts
.
contains
(
&
font
.
font_instance_key
)
{
continue
;
}
scaled_fonts
.
push
(
font
.
font_instance_key
)
;
if
let
Some
(
instance
)
=
resources
.
get_font_instance_data
(
font
.
font_instance_key
)
{
if
!
unscaled_fonts
.
contains
(
&
instance
.
font_key
)
{
unscaled_fonts
.
push
(
instance
.
font_key
)
;
if
!
unsafe
{
HasFontData
(
instance
.
font_key
)
}
{
let
template
=
resources
.
get_font_data
(
instance
.
font_key
)
.
unwrap
(
)
;
match
template
{
FontTemplate
:
:
Raw
(
ref
data
ref
index
)
=
>
unsafe
{
AddFontData
(
instance
.
font_key
data
.
as_ptr
(
)
data
.
len
(
)
*
index
data
)
;
}
FontTemplate
:
:
Native
(
ref
handle
)
=
>
{
process_native_font_handle
(
instance
.
font_key
handle
)
;
}
}
}
}
unsafe
{
AddBlobFont
(
font
.
font_instance_key
instance
.
font_key
instance
.
size
instance
.
options
.
as_ref
(
)
instance
.
platform_options
.
as_ref
(
)
instance
.
variations
.
as_ptr
(
)
instance
.
variations
.
len
(
)
)
;
}
}
}
}
{
let
mut
index
=
BlobReader
:
:
new
(
blob
)
;
let
mut
unscaled_fonts
=
Vec
:
:
new
(
)
;
let
mut
scaled_fonts
=
Vec
:
:
new
(
)
;
while
index
.
reader
.
pos
<
index
.
reader
.
buf
.
len
(
)
{
let
e
=
index
.
read_entry
(
)
;
process_fonts
(
BufReader
:
:
new
(
&
blob
[
e
.
end
.
.
e
.
extra_end
]
)
resources
&
mut
unscaled_fonts
&
mut
scaled_fonts
)
;
}
}
}
}
