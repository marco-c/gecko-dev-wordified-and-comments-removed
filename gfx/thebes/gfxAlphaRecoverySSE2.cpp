#
include
"
gfxAlphaRecovery
.
h
"
#
include
"
gfxImageSurface
.
h
"
#
include
"
nsDebug
.
h
"
#
include
<
xsimd
/
xsimd
.
hpp
>
using
arch
=
xsimd
:
:
sse2
;
alignas
(
arch
:
:
alignment
(
)
)
static
const
uint8_t
greenMaski
[
]
=
{
0x00
0xff
0x00
0x00
0x00
0xff
0x00
0x00
0x00
0xff
0x00
0x00
0x00
0xff
0x00
0x00
}
;
alignas
(
arch
:
:
alignment
(
)
)
static
const
uint8_t
alphaMaski
[
]
=
{
0x00
0x00
0x00
0xff
0x00
0x00
0x00
0xff
0x00
0x00
0x00
0xff
0x00
0x00
0x00
0xff
}
;
bool
gfxAlphaRecovery
:
:
RecoverAlphaSSE2
(
gfxImageSurface
*
blackSurf
const
gfxImageSurface
*
whiteSurf
)
{
mozilla
:
:
gfx
:
:
IntSize
size
=
blackSurf
-
>
GetSize
(
)
;
if
(
size
!
=
whiteSurf
-
>
GetSize
(
)
|
|
(
blackSurf
-
>
Format
(
)
!
=
mozilla
:
:
gfx
:
:
SurfaceFormat
:
:
A8R8G8B8_UINT32
&
&
blackSurf
-
>
Format
(
)
!
=
mozilla
:
:
gfx
:
:
SurfaceFormat
:
:
X8R8G8B8_UINT32
)
|
|
(
whiteSurf
-
>
Format
(
)
!
=
mozilla
:
:
gfx
:
:
SurfaceFormat
:
:
A8R8G8B8_UINT32
&
&
whiteSurf
-
>
Format
(
)
!
=
mozilla
:
:
gfx
:
:
SurfaceFormat
:
:
X8R8G8B8_UINT32
)
)
return
false
;
blackSurf
-
>
Flush
(
)
;
whiteSurf
-
>
Flush
(
)
;
unsigned
char
*
blackData
=
blackSurf
-
>
Data
(
)
;
unsigned
char
*
whiteData
=
whiteSurf
-
>
Data
(
)
;
if
(
(
NS_PTR_TO_UINT32
(
blackData
)
&
0xf
)
!
=
(
NS_PTR_TO_UINT32
(
whiteData
)
&
0xf
)
|
|
(
blackSurf
-
>
Stride
(
)
-
whiteSurf
-
>
Stride
(
)
)
&
0xf
)
{
return
false
;
}
using
batch_type
=
xsimd
:
:
batch
<
uint8_t
arch
>
;
constexpr
size_t
batch_size
=
batch_type
:
:
size
;
static_assert
(
batch_size
=
=
16
)
;
batch_type
greenMask
=
batch_type
:
:
load_aligned
(
greenMaski
)
;
batch_type
alphaMask
=
batch_type
:
:
load_aligned
(
alphaMaski
)
;
for
(
int32_t
i
=
0
;
i
<
size
.
height
;
+
+
i
)
{
int32_t
j
=
0
;
while
(
NS_PTR_TO_UINT32
(
blackData
)
&
0xf
&
&
j
<
size
.
width
)
{
*
(
(
uint32_t
*
)
blackData
)
=
RecoverPixel
(
*
reinterpret_cast
<
uint32_t
*
>
(
blackData
)
*
reinterpret_cast
<
uint32_t
*
>
(
whiteData
)
)
;
blackData
+
=
4
;
whiteData
+
=
4
;
j
+
+
;
}
for
(
;
j
<
size
.
width
-
8
;
j
+
=
8
)
{
auto
black1
=
batch_type
:
:
load_aligned
(
blackData
)
;
auto
white1
=
batch_type
:
:
load_aligned
(
whiteData
)
;
auto
black2
=
batch_type
:
:
load_aligned
(
blackData
+
batch_size
)
;
auto
white2
=
batch_type
:
:
load_aligned
(
whiteData
+
batch_size
)
;
white1
=
xsimd
:
:
ssub
(
white1
black1
)
;
white2
=
xsimd
:
:
ssub
(
white2
black2
)
;
white1
=
xsimd
:
:
ssub
(
greenMask
white1
)
;
white2
=
xsimd
:
:
ssub
(
greenMask
white2
)
;
black1
=
xsimd
:
:
bitwise_andnot
(
black1
alphaMask
)
;
black2
=
xsimd
:
:
bitwise_andnot
(
black2
alphaMask
)
;
white1
=
xsimd
:
:
slide_left
<
2
>
(
white1
)
;
white2
=
xsimd
:
:
slide_left
<
2
>
(
white2
)
;
white1
&
=
alphaMask
;
white2
&
=
alphaMask
;
black1
|
=
white1
;
black2
|
=
white2
;
black1
.
store_aligned
(
blackData
)
;
black2
.
store_aligned
(
blackData
+
batch_size
)
;
blackData
+
=
2
*
batch_size
;
whiteData
+
=
2
*
batch_size
;
}
for
(
;
j
<
size
.
width
-
4
;
j
+
=
4
)
{
auto
black
=
batch_type
:
:
load_aligned
(
blackData
)
;
auto
white
=
batch_type
:
:
load_aligned
(
whiteData
)
;
white
=
xsimd
:
:
ssub
(
white
black
)
;
white
=
xsimd
:
:
ssub
(
greenMask
white
)
;
black
=
xsimd
:
:
bitwise_andnot
(
black
alphaMask
)
;
white
=
xsimd
:
:
slide_left
<
2
>
(
white
)
;
white
&
=
alphaMask
;
black
|
=
white
;
black
.
store_aligned
(
blackData
)
;
blackData
+
=
batch_size
;
whiteData
+
=
batch_size
;
}
while
(
j
<
size
.
width
)
{
*
(
(
uint32_t
*
)
blackData
)
=
RecoverPixel
(
*
reinterpret_cast
<
uint32_t
*
>
(
blackData
)
*
reinterpret_cast
<
uint32_t
*
>
(
whiteData
)
)
;
blackData
+
=
4
;
whiteData
+
=
4
;
j
+
+
;
}
blackData
+
=
blackSurf
-
>
Stride
(
)
-
j
*
4
;
whiteData
+
=
whiteSurf
-
>
Stride
(
)
-
j
*
4
;
}
blackSurf
-
>
MarkDirty
(
)
;
return
true
;
}
