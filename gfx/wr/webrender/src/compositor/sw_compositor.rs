use
gleam
:
:
{
gl
gl
:
:
GLenum
gl
:
:
Gl
}
;
use
std
:
:
cell
:
:
{
Cell
UnsafeCell
}
;
use
std
:
:
collections
:
:
{
hash_map
:
:
HashMap
VecDeque
}
;
use
std
:
:
ops
:
:
{
Deref
DerefMut
Range
}
;
use
std
:
:
os
:
:
raw
:
:
c_void
;
use
std
:
:
ptr
;
use
std
:
:
rc
:
:
Rc
;
use
std
:
:
sync
:
:
atomic
:
:
{
AtomicIsize
AtomicPtr
AtomicU32
AtomicU8
Ordering
}
;
use
std
:
:
sync
:
:
{
Arc
Condvar
Mutex
MutexGuard
}
;
use
std
:
:
thread
;
use
crate
:
:
{
api
:
:
units
:
:
*
api
:
:
ColorDepth
api
:
:
ExternalImageId
api
:
:
ImageRendering
api
:
:
YuvColorSpace
Compositor
CompositorCapabilities
CompositorSurfaceTransform
NativeSurfaceId
NativeSurfaceInfo
NativeTileId
host_utils
:
:
{
thread_started
thread_stopped
}
MappableCompositor
SWGLCompositeSurfaceInfo
}
;
pub
struct
SwTile
{
x
:
i32
y
:
i32
fbo_id
:
u32
color_id
:
u32
tex_id
:
u32
pbo_id
:
u32
dirty_rect
:
DeviceIntRect
valid_rect
:
DeviceIntRect
overlaps
:
Cell
<
u32
>
invalid
:
Cell
<
bool
>
graph_node
:
SwCompositeGraphNodeRef
}
impl
SwTile
{
fn
new
(
x
:
i32
y
:
i32
)
-
>
Self
{
SwTile
{
x
y
fbo_id
:
0
color_id
:
0
tex_id
:
0
pbo_id
:
0
dirty_rect
:
DeviceIntRect
:
:
zero
(
)
valid_rect
:
DeviceIntRect
:
:
zero
(
)
overlaps
:
Cell
:
:
new
(
0
)
invalid
:
Cell
:
:
new
(
false
)
graph_node
:
SwCompositeGraphNode
:
:
new
(
)
}
}
fn
origin
(
&
self
surface
:
&
SwSurface
)
-
>
DeviceIntPoint
{
DeviceIntPoint
:
:
new
(
self
.
x
*
surface
.
tile_size
.
width
self
.
y
*
surface
.
tile_size
.
height
)
}
fn
local_bounds
(
&
self
surface
:
&
SwSurface
)
-
>
DeviceIntRect
{
self
.
valid_rect
.
translate
(
self
.
origin
(
surface
)
.
to_vector
(
)
)
}
fn
overlap_rect
(
&
self
surface
:
&
SwSurface
transform
:
&
CompositorSurfaceTransform
clip_rect
:
&
DeviceIntRect
)
-
>
Option
<
DeviceIntRect
>
{
let
bounds
=
self
.
local_bounds
(
surface
)
;
let
device_rect
=
transform
.
outer_transformed_rect
(
&
bounds
.
to_f32
(
)
)
?
.
round_out
(
)
.
to_i32
(
)
;
device_rect
.
intersection
(
clip_rect
)
}
fn
may_overlap
(
&
self
surface
:
&
SwSurface
transform
:
&
CompositorSurfaceTransform
clip_rect
:
&
DeviceIntRect
dep_rect
:
&
DeviceIntRect
)
-
>
bool
{
self
.
overlap_rect
(
surface
transform
clip_rect
)
.
map_or
(
false
|
r
|
r
.
intersects
(
dep_rect
)
)
}
fn
composite_rects
(
&
self
surface
:
&
SwSurface
transform
:
&
CompositorSurfaceTransform
clip_rect
:
&
DeviceIntRect
)
-
>
Option
<
(
DeviceIntRect
DeviceIntRect
bool
)
>
{
let
valid
=
self
.
local_bounds
(
surface
)
;
let
dest_rect
=
transform
.
outer_transformed_rect
(
&
valid
.
to_f32
(
)
)
?
.
round_out
(
)
.
to_i32
(
)
;
if
!
dest_rect
.
intersects
(
clip_rect
)
{
return
None
;
}
let
inv_transform
=
transform
.
inverse
(
)
?
;
let
src_rect
=
inv_transform
.
outer_transformed_rect
(
&
dest_rect
.
to_f32
(
)
)
?
.
round
(
)
.
to_i32
(
)
.
translate
(
-
valid
.
origin
.
to_vector
(
)
)
;
Some
(
(
src_rect
dest_rect
transform
.
m22
<
0
.
0
)
)
}
}
pub
struct
SwSurface
{
tile_size
:
DeviceIntSize
is_opaque
:
bool
tiles
:
Vec
<
SwTile
>
external_image
:
Option
<
ExternalImageId
>
composite_surface
:
Option
<
SWGLCompositeSurfaceInfo
>
}
impl
SwSurface
{
fn
new
(
tile_size
:
DeviceIntSize
is_opaque
:
bool
)
-
>
Self
{
SwSurface
{
tile_size
is_opaque
tiles
:
Vec
:
:
new
(
)
external_image
:
None
composite_surface
:
None
}
}
fn
local_bounds
(
&
self
)
-
>
DeviceIntRect
{
let
mut
bounds
=
DeviceIntRect
:
:
zero
(
)
;
for
tile
in
&
self
.
tiles
{
bounds
=
bounds
.
union
(
&
tile
.
local_bounds
(
self
)
)
;
}
bounds
}
fn
device_bounds
(
&
self
transform
:
&
CompositorSurfaceTransform
clip_rect
:
&
DeviceIntRect
)
-
>
Option
<
DeviceIntRect
>
{
let
bounds
=
self
.
local_bounds
(
)
;
let
device_rect
=
transform
.
outer_transformed_rect
(
&
bounds
.
to_f32
(
)
)
?
.
round_out
(
)
.
to_i32
(
)
;
device_rect
.
intersection
(
clip_rect
)
}
}
fn
image_rendering_to_gl_filter
(
filter
:
ImageRendering
)
-
>
gl
:
:
GLenum
{
match
filter
{
ImageRendering
:
:
Pixelated
=
>
gl
:
:
NEAREST
ImageRendering
:
:
Auto
|
ImageRendering
:
:
CrispEdges
=
>
gl
:
:
LINEAR
}
}
struct
DrawTileHelper
{
gl
:
Rc
<
dyn
gl
:
:
Gl
>
prog
:
u32
quad_vbo
:
u32
quad_vao
:
u32
dest_matrix_loc
:
i32
tex_matrix_loc
:
i32
}
impl
DrawTileHelper
{
fn
new
(
gl
:
Rc
<
dyn
gl
:
:
Gl
>
)
-
>
Self
{
let
quad_vbo
=
gl
.
gen_buffers
(
1
)
[
0
]
;
gl
.
bind_buffer
(
gl
:
:
ARRAY_BUFFER
quad_vbo
)
;
let
quad_data
:
[
f32
;
8
]
=
[
0
.
0
0
.
0
1
.
0
0
.
0
0
.
0
1
.
0
1
.
0
1
.
0
]
;
gl
:
:
buffer_data
(
&
*
gl
gl
:
:
ARRAY_BUFFER
&
quad_data
gl
:
:
STATIC_DRAW
)
;
let
quad_vao
=
gl
.
gen_vertex_arrays
(
1
)
[
0
]
;
gl
.
bind_vertex_array
(
quad_vao
)
;
gl
.
enable_vertex_attrib_array
(
0
)
;
gl
.
vertex_attrib_pointer
(
0
2
gl
:
:
FLOAT
false
0
0
)
;
gl
.
bind_vertex_array
(
0
)
;
let
version
=
match
gl
.
get_type
(
)
{
gl
:
:
GlType
:
:
Gl
=
>
"
#
version
150
"
gl
:
:
GlType
:
:
Gles
=
>
"
#
version
300
es
"
}
;
let
vert_source
=
"
in
vec2
aVert
;
uniform
mat3
uDestMatrix
;
uniform
mat3
uTexMatrix
;
out
vec2
vTexCoord
;
void
main
(
void
)
{
gl_Position
=
vec4
(
(
uDestMatrix
*
vec3
(
aVert
1
.
0
)
)
.
xy
0
.
0
1
.
0
)
;
vTexCoord
=
(
uTexMatrix
*
vec3
(
aVert
1
.
0
)
)
.
xy
;
}
"
;
let
vs
=
gl
.
create_shader
(
gl
:
:
VERTEX_SHADER
)
;
gl
.
shader_source
(
vs
&
[
version
.
as_bytes
(
)
vert_source
.
as_bytes
(
)
]
)
;
gl
.
compile_shader
(
vs
)
;
let
frag_source
=
"
#
ifdef
GL_ES
#
ifdef
GL_FRAGMENT_PRECISION_HIGH
precision
highp
float
;
#
else
precision
mediump
float
;
#
endif
#
endif
in
vec2
vTexCoord
;
out
vec4
oFragColor
;
uniform
sampler2D
uTex
;
void
main
(
void
)
{
oFragColor
=
texture
(
uTex
vTexCoord
)
;
}
"
;
let
fs
=
gl
.
create_shader
(
gl
:
:
FRAGMENT_SHADER
)
;
gl
.
shader_source
(
fs
&
[
version
.
as_bytes
(
)
frag_source
.
as_bytes
(
)
]
)
;
gl
.
compile_shader
(
fs
)
;
let
prog
=
gl
.
create_program
(
)
;
gl
.
attach_shader
(
prog
vs
)
;
gl
.
attach_shader
(
prog
fs
)
;
gl
.
bind_attrib_location
(
prog
0
"
aVert
"
)
;
gl
.
link_program
(
prog
)
;
let
mut
status
=
[
0
]
;
unsafe
{
gl
.
get_program_iv
(
prog
gl
:
:
LINK_STATUS
&
mut
status
)
;
}
assert
!
(
status
[
0
]
!
=
0
)
;
gl
.
use_program
(
prog
)
;
let
dest_matrix_loc
=
gl
.
get_uniform_location
(
prog
"
uDestMatrix
"
)
;
assert
!
(
dest_matrix_loc
!
=
-
1
)
;
let
tex_matrix_loc
=
gl
.
get_uniform_location
(
prog
"
uTexMatrix
"
)
;
assert
!
(
tex_matrix_loc
!
=
-
1
)
;
let
tex_loc
=
gl
.
get_uniform_location
(
prog
"
uTex
"
)
;
assert
!
(
tex_loc
!
=
-
1
)
;
gl
.
uniform_1i
(
tex_loc
0
)
;
gl
.
use_program
(
0
)
;
gl
.
delete_shader
(
vs
)
;
gl
.
delete_shader
(
fs
)
;
DrawTileHelper
{
gl
prog
quad_vao
quad_vbo
dest_matrix_loc
tex_matrix_loc
}
}
fn
deinit
(
&
self
)
{
self
.
gl
.
delete_program
(
self
.
prog
)
;
self
.
gl
.
delete_vertex_arrays
(
&
[
self
.
quad_vao
]
)
;
self
.
gl
.
delete_buffers
(
&
[
self
.
quad_vbo
]
)
;
}
fn
enable
(
&
self
viewport
:
&
DeviceIntRect
)
{
self
.
gl
.
viewport
(
viewport
.
origin
.
x
viewport
.
origin
.
y
viewport
.
size
.
width
viewport
.
size
.
height
)
;
self
.
gl
.
bind_vertex_array
(
self
.
quad_vao
)
;
self
.
gl
.
use_program
(
self
.
prog
)
;
self
.
gl
.
active_texture
(
gl
:
:
TEXTURE0
)
;
}
fn
draw
(
&
self
viewport
:
&
DeviceIntRect
dest
:
&
DeviceIntRect
src
:
&
DeviceIntRect
_clip
:
&
DeviceIntRect
surface
:
&
SwSurface
tile
:
&
SwTile
flip_y
:
bool
filter
:
GLenum
)
{
let
dx
=
dest
.
origin
.
x
as
f32
/
viewport
.
size
.
width
as
f32
;
let
dy
=
dest
.
origin
.
y
as
f32
/
viewport
.
size
.
height
as
f32
;
let
dw
=
dest
.
size
.
width
as
f32
/
viewport
.
size
.
width
as
f32
;
let
dh
=
dest
.
size
.
height
as
f32
/
viewport
.
size
.
height
as
f32
;
self
.
gl
.
uniform_matrix_3fv
(
self
.
dest_matrix_loc
false
&
[
2
.
0
*
dw
0
.
0
0
.
0
0
.
0
if
flip_y
{
2
.
0
*
dh
}
else
{
-
2
.
0
*
dh
}
0
.
0
-
1
.
0
+
2
.
0
*
dx
if
flip_y
{
-
1
.
0
+
2
.
0
*
dy
}
else
{
1
.
0
-
2
.
0
*
dy
}
1
.
0
]
)
;
let
sx
=
src
.
origin
.
x
as
f32
/
surface
.
tile_size
.
width
as
f32
;
let
sy
=
src
.
origin
.
y
as
f32
/
surface
.
tile_size
.
height
as
f32
;
let
sw
=
src
.
size
.
width
as
f32
/
surface
.
tile_size
.
width
as
f32
;
let
sh
=
src
.
size
.
height
as
f32
/
surface
.
tile_size
.
height
as
f32
;
self
.
gl
.
uniform_matrix_3fv
(
self
.
tex_matrix_loc
false
&
[
sw
0
.
0
0
.
0
0
.
0
sh
0
.
0
sx
sy
1
.
0
]
)
;
self
.
gl
.
bind_texture
(
gl
:
:
TEXTURE_2D
tile
.
tex_id
)
;
self
.
gl
.
tex_parameter_i
(
gl
:
:
TEXTURE_2D
gl
:
:
TEXTURE_MIN_FILTER
filter
as
gl
:
:
GLint
)
;
self
.
gl
.
tex_parameter_i
(
gl
:
:
TEXTURE_2D
gl
:
:
TEXTURE_MAG_FILTER
filter
as
gl
:
:
GLint
)
;
self
.
gl
.
draw_arrays
(
gl
:
:
TRIANGLE_STRIP
0
4
)
;
}
fn
disable
(
&
self
)
{
self
.
gl
.
use_program
(
0
)
;
self
.
gl
.
bind_vertex_array
(
0
)
;
}
}
#
[
derive
(
Clone
)
]
enum
SwCompositeSource
{
BGRA
(
swgl
:
:
LockedResource
)
YUV
(
swgl
:
:
LockedResource
swgl
:
:
LockedResource
swgl
:
:
LockedResource
YuvColorSpace
ColorDepth
)
}
unsafe
impl
Send
for
SwCompositeSource
{
}
#
[
derive
(
Clone
)
]
struct
SwCompositeJob
{
locked_src
:
SwCompositeSource
locked_dst
:
swgl
:
:
LockedResource
src_rect
:
DeviceIntRect
dst_rect
:
DeviceIntRect
clipped_dst
:
DeviceIntRect
opaque
:
bool
flip_y
:
bool
filter
:
ImageRendering
num_bands
:
u8
}
impl
SwCompositeJob
{
fn
process
(
&
self
band_index
:
u8
)
{
let
band_index
=
band_index
as
i32
;
let
num_bands
=
self
.
num_bands
as
i32
;
let
band_offset
=
(
self
.
clipped_dst
.
size
.
height
*
band_index
)
/
num_bands
;
let
band_height
=
(
self
.
clipped_dst
.
size
.
height
*
(
band_index
+
1
)
)
/
num_bands
-
band_offset
;
let
band_clip
=
DeviceIntRect
:
:
new
(
DeviceIntPoint
:
:
new
(
self
.
clipped_dst
.
origin
.
x
self
.
clipped_dst
.
origin
.
y
+
band_offset
)
DeviceIntSize
:
:
new
(
self
.
clipped_dst
.
size
.
width
band_height
)
)
;
match
self
.
locked_src
{
SwCompositeSource
:
:
BGRA
(
ref
resource
)
=
>
{
self
.
locked_dst
.
composite
(
resource
self
.
src_rect
.
origin
.
x
self
.
src_rect
.
origin
.
y
self
.
src_rect
.
size
.
width
self
.
src_rect
.
size
.
height
self
.
dst_rect
.
origin
.
x
self
.
dst_rect
.
origin
.
y
self
.
dst_rect
.
size
.
width
self
.
dst_rect
.
size
.
height
self
.
opaque
self
.
flip_y
image_rendering_to_gl_filter
(
self
.
filter
)
band_clip
.
origin
.
x
band_clip
.
origin
.
y
band_clip
.
size
.
width
band_clip
.
size
.
height
)
;
}
SwCompositeSource
:
:
YUV
(
ref
y
ref
u
ref
v
color_space
color_depth
)
=
>
{
let
swgl_color_space
=
match
color_space
{
YuvColorSpace
:
:
Rec601
=
>
swgl
:
:
YUVColorSpace
:
:
Rec601
YuvColorSpace
:
:
Rec709
=
>
swgl
:
:
YUVColorSpace
:
:
Rec709
YuvColorSpace
:
:
Rec2020
=
>
swgl
:
:
YUVColorSpace
:
:
Rec2020
YuvColorSpace
:
:
Identity
=
>
swgl
:
:
YUVColorSpace
:
:
Identity
}
;
self
.
locked_dst
.
composite_yuv
(
y
u
v
swgl_color_space
color_depth
.
bit_depth
(
)
self
.
src_rect
.
origin
.
x
self
.
src_rect
.
origin
.
y
self
.
src_rect
.
size
.
width
self
.
src_rect
.
size
.
height
self
.
dst_rect
.
origin
.
x
self
.
dst_rect
.
origin
.
y
self
.
dst_rect
.
size
.
width
self
.
dst_rect
.
size
.
height
self
.
flip_y
band_clip
.
origin
.
x
band_clip
.
origin
.
y
band_clip
.
size
.
width
band_clip
.
size
.
height
)
;
}
}
}
}
#
[
derive
(
Clone
)
]
struct
SwCompositeGraphNodeRef
(
Arc
<
UnsafeCell
<
SwCompositeGraphNode
>
>
)
;
impl
SwCompositeGraphNodeRef
{
fn
new
(
graph_node
:
SwCompositeGraphNode
)
-
>
Self
{
SwCompositeGraphNodeRef
(
Arc
:
:
new
(
UnsafeCell
:
:
new
(
graph_node
)
)
)
}
fn
get
(
&
self
)
-
>
&
SwCompositeGraphNode
{
unsafe
{
&
*
self
.
0
.
get
(
)
}
}
fn
get_mut
(
&
self
)
-
>
&
mut
SwCompositeGraphNode
{
unsafe
{
&
mut
*
self
.
0
.
get
(
)
}
}
fn
get_ptr_mut
(
&
self
)
-
>
*
mut
SwCompositeGraphNode
{
self
.
0
.
get
(
)
}
}
unsafe
impl
Send
for
SwCompositeGraphNodeRef
{
}
impl
Deref
for
SwCompositeGraphNodeRef
{
type
Target
=
SwCompositeGraphNode
;
fn
deref
(
&
self
)
-
>
&
Self
:
:
Target
{
self
.
get
(
)
}
}
impl
DerefMut
for
SwCompositeGraphNodeRef
{
fn
deref_mut
(
&
mut
self
)
-
>
&
mut
Self
:
:
Target
{
self
.
get_mut
(
)
}
}
struct
SwCompositeGraphNode
{
job
:
Option
<
SwCompositeJob
>
max_bands
:
AtomicU8
remaining_bands
:
AtomicU8
band_index
:
AtomicU8
parents
:
AtomicU32
children
:
Vec
<
SwCompositeGraphNodeRef
>
}
unsafe
impl
Sync
for
SwCompositeGraphNode
{
}
impl
SwCompositeGraphNode
{
fn
new
(
)
-
>
SwCompositeGraphNodeRef
{
SwCompositeGraphNodeRef
:
:
new
(
SwCompositeGraphNode
{
job
:
None
max_bands
:
AtomicU8
:
:
new
(
0
)
remaining_bands
:
AtomicU8
:
:
new
(
0
)
band_index
:
AtomicU8
:
:
new
(
0
)
parents
:
AtomicU32
:
:
new
(
0
)
children
:
Vec
:
:
new
(
)
}
)
}
fn
reset
(
&
mut
self
)
{
self
.
job
=
None
;
self
.
max_bands
.
store
(
0
Ordering
:
:
SeqCst
)
;
self
.
remaining_bands
.
store
(
0
Ordering
:
:
SeqCst
)
;
self
.
band_index
.
store
(
0
Ordering
:
:
SeqCst
)
;
self
.
parents
.
store
(
1
Ordering
:
:
SeqCst
)
;
self
.
children
.
clear
(
)
;
}
fn
add_child
(
&
mut
self
child
:
SwCompositeGraphNodeRef
)
{
child
.
parents
.
fetch_add
(
1
Ordering
:
:
SeqCst
)
;
self
.
children
.
push
(
child
)
;
}
fn
set_job
(
&
mut
self
job
:
SwCompositeJob
num_bands
:
u8
)
-
>
bool
{
self
.
job
=
Some
(
job
)
;
self
.
max_bands
.
store
(
num_bands
Ordering
:
:
SeqCst
)
;
self
.
remaining_bands
.
store
(
num_bands
Ordering
:
:
SeqCst
)
;
self
.
parents
.
fetch_sub
(
1
Ordering
:
:
SeqCst
)
<
=
1
}
fn
take_band
(
&
self
)
-
>
Option
<
u8
>
{
let
band_index
=
self
.
band_index
.
fetch_add
(
1
Ordering
:
:
SeqCst
)
;
if
band_index
<
self
.
max_bands
.
load
(
Ordering
:
:
SeqCst
)
{
Some
(
band_index
)
}
else
{
None
}
}
fn
process_job
(
&
self
band_index
:
u8
)
{
if
let
Some
(
ref
job
)
=
self
.
job
{
job
.
process
(
band_index
)
;
}
}
fn
unblock_children
(
&
mut
self
thread
:
&
SwCompositeThread
)
{
if
self
.
remaining_bands
.
fetch_sub
(
1
Ordering
:
:
SeqCst
)
>
1
{
return
;
}
self
.
job
=
None
;
let
mut
lock
=
None
;
for
child
in
self
.
children
.
drain
(
.
.
)
{
if
child
.
parents
.
fetch_sub
(
1
Ordering
:
:
SeqCst
)
<
=
1
{
if
lock
.
is_none
(
)
{
lock
=
Some
(
thread
.
lock
(
)
)
;
}
thread
.
send_job
(
lock
.
as_mut
(
)
.
unwrap
(
)
child
)
;
}
}
}
}
struct
SwCompositeThread
{
jobs
:
Mutex
<
SwCompositeJobQueue
>
current_job
:
AtomicPtr
<
SwCompositeGraphNode
>
job_count
:
AtomicIsize
jobs_available
:
Condvar
}
unsafe
impl
Sync
for
SwCompositeThread
{
}
type
SwCompositeJobQueue
=
VecDeque
<
SwCompositeGraphNodeRef
>
;
type
SwCompositeThreadLock
<
'
a
>
=
MutexGuard
<
'
a
SwCompositeJobQueue
>
;
impl
SwCompositeThread
{
fn
new
(
)
-
>
Arc
<
SwCompositeThread
>
{
let
info
=
Arc
:
:
new
(
SwCompositeThread
{
jobs
:
Mutex
:
:
new
(
SwCompositeJobQueue
:
:
new
(
)
)
current_job
:
AtomicPtr
:
:
new
(
ptr
:
:
null_mut
(
)
)
job_count
:
AtomicIsize
:
:
new
(
0
)
jobs_available
:
Condvar
:
:
new
(
)
}
)
;
let
result
=
info
.
clone
(
)
;
let
thread_name
=
"
SwComposite
"
;
thread
:
:
Builder
:
:
new
(
)
.
name
(
thread_name
.
into
(
)
)
.
stack_size
(
32
*
1024
)
.
spawn
(
move
|
|
{
thread_started
(
thread_name
)
;
while
let
Some
(
(
job
band
)
)
=
info
.
take_job
(
true
)
{
info
.
process_job
(
job
band
)
;
}
thread_stopped
(
)
;
}
)
.
expect
(
"
Failed
creating
SwComposite
thread
"
)
;
result
}
fn
deinit
(
&
self
)
{
self
.
job_count
.
store
(
isize
:
:
MIN
/
2
Ordering
:
:
SeqCst
)
;
self
.
jobs_available
.
notify_all
(
)
;
}
fn
process_job
(
&
self
graph_node
:
&
mut
SwCompositeGraphNode
band
:
u8
)
{
graph_node
.
process_job
(
band
)
;
graph_node
.
unblock_children
(
self
)
;
self
.
job_count
.
fetch_sub
(
1
Ordering
:
:
SeqCst
)
;
}
fn
queue_composite
(
&
self
locked_src
:
SwCompositeSource
locked_dst
:
swgl
:
:
LockedResource
src_rect
:
DeviceIntRect
dst_rect
:
DeviceIntRect
clip_rect
:
DeviceIntRect
opaque
:
bool
flip_y
:
bool
filter
:
ImageRendering
mut
graph_node
:
SwCompositeGraphNodeRef
job_queue
:
&
mut
SwCompositeJobQueue
)
{
let
clipped_dst
=
match
dst_rect
.
intersection
(
&
clip_rect
)
{
Some
(
clipped_dst
)
=
>
clipped_dst
None
=
>
return
}
;
let
num_bands
=
if
clipped_dst
.
size
.
width
>
=
64
&
&
clipped_dst
.
size
.
height
>
=
64
{
(
clipped_dst
.
size
.
height
/
64
)
.
min
(
4
)
as
u8
}
else
{
1
}
;
let
job
=
SwCompositeJob
{
locked_src
locked_dst
src_rect
dst_rect
clipped_dst
opaque
flip_y
filter
num_bands
}
;
self
.
job_count
.
fetch_add
(
num_bands
as
isize
Ordering
:
:
SeqCst
)
;
if
graph_node
.
set_job
(
job
num_bands
)
{
self
.
send_job
(
job_queue
graph_node
)
;
}
}
fn
prepare_for_composites
(
&
self
)
{
self
.
job_count
.
store
(
1
Ordering
:
:
SeqCst
)
;
}
fn
lock
(
&
self
)
-
>
SwCompositeThreadLock
{
self
.
jobs
.
lock
(
)
.
unwrap
(
)
}
fn
send_job
(
&
self
queue
:
&
mut
SwCompositeJobQueue
job
:
SwCompositeGraphNodeRef
)
{
if
queue
.
is_empty
(
)
{
self
.
jobs_available
.
notify_all
(
)
;
}
queue
.
push_back
(
job
)
;
}
fn
try_take_job
(
&
self
)
-
>
Option
<
(
&
mut
SwCompositeGraphNode
u8
)
>
{
let
current_job_ptr
=
self
.
current_job
.
load
(
Ordering
:
:
SeqCst
)
;
if
let
Some
(
current_job
)
=
unsafe
{
current_job_ptr
.
as_mut
(
)
}
{
if
let
Some
(
band
)
=
current_job
.
take_band
(
)
{
return
Some
(
(
current_job
band
)
)
;
}
let
_
=
self
.
current_job
.
compare_exchange
(
current_job_ptr
ptr
:
:
null_mut
(
)
Ordering
:
:
Relaxed
Ordering
:
:
Relaxed
)
;
}
return
None
;
}
fn
take_job
(
&
self
wait
:
bool
)
-
>
Option
<
(
&
mut
SwCompositeGraphNode
u8
)
>
{
if
let
Some
(
(
job
band
)
)
=
self
.
try_take_job
(
)
{
return
Some
(
(
job
band
)
)
;
}
let
mut
jobs
=
self
.
lock
(
)
;
loop
{
if
let
Some
(
(
job
band
)
)
=
self
.
try_take_job
(
)
{
return
Some
(
(
job
band
)
)
;
}
if
let
Some
(
job
)
=
jobs
.
pop_front
(
)
{
self
.
current_job
.
store
(
job
.
get_ptr_mut
(
)
Ordering
:
:
SeqCst
)
;
continue
;
}
match
self
.
job_count
.
load
(
Ordering
:
:
SeqCst
)
{
0
=
>
{
self
.
jobs_available
.
notify_all
(
)
;
if
!
wait
{
return
None
;
}
}
job_count
if
job_count
<
0
=
>
return
None
_
=
>
{
}
}
jobs
=
self
.
jobs_available
.
wait
(
jobs
)
.
unwrap
(
)
;
}
}
fn
wait_for_composites
(
&
self
sync
:
bool
)
{
self
.
job_count
.
fetch_sub
(
1
Ordering
:
:
SeqCst
)
;
if
!
sync
{
while
let
Some
(
(
job
band
)
)
=
self
.
take_job
(
false
)
{
self
.
process_job
(
job
band
)
;
}
}
let
mut
jobs
=
self
.
lock
(
)
;
while
self
.
job_count
.
load
(
Ordering
:
:
SeqCst
)
>
0
{
jobs
=
self
.
jobs_available
.
wait
(
jobs
)
.
unwrap
(
)
;
}
}
fn
is_busy_compositing
(
&
self
)
-
>
bool
{
self
.
job_count
.
load
(
Ordering
:
:
SeqCst
)
>
0
}
}
type
FrameSurface
=
(
NativeSurfaceId
CompositorSurfaceTransform
DeviceIntRect
ImageRendering
)
;
pub
struct
SwCompositor
{
gl
:
swgl
:
:
Context
native_gl
:
Option
<
Rc
<
dyn
gl
:
:
Gl
>
>
compositor
:
Box
<
dyn
MappableCompositor
>
use_native_compositor
:
bool
surfaces
:
HashMap
<
NativeSurfaceId
SwSurface
>
frame_surfaces
:
Vec
<
FrameSurface
>
late_surfaces
:
Vec
<
FrameSurface
>
cur_tile
:
NativeTileId
draw_tile
:
Option
<
DrawTileHelper
>
max_tile_size
:
DeviceIntSize
depth_id
:
u32
composite_thread
:
Option
<
Arc
<
SwCompositeThread
>
>
locked_framebuffer
:
Option
<
swgl
:
:
LockedResource
>
}
impl
SwCompositor
{
pub
fn
new
(
gl
:
swgl
:
:
Context
native_gl
:
Option
<
Rc
<
dyn
gl
:
:
Gl
>
>
compositor
:
Box
<
dyn
MappableCompositor
>
use_native_compositor
:
bool
)
-
>
Self
{
let
depth_id
=
gl
.
gen_textures
(
1
)
[
0
]
;
assert
!
(
native_gl
.
is_none
(
)
|
|
!
use_native_compositor
)
;
let
composite_thread
=
if
native_gl
.
is_none
(
)
&
&
!
use_native_compositor
{
Some
(
SwCompositeThread
:
:
new
(
)
)
}
else
{
None
}
;
SwCompositor
{
gl
compositor
use_native_compositor
surfaces
:
HashMap
:
:
new
(
)
frame_surfaces
:
Vec
:
:
new
(
)
late_surfaces
:
Vec
:
:
new
(
)
cur_tile
:
NativeTileId
{
surface_id
:
NativeSurfaceId
(
0
)
x
:
0
y
:
0
}
draw_tile
:
native_gl
.
as_ref
(
)
.
map
(
|
gl
|
DrawTileHelper
:
:
new
(
gl
.
clone
(
)
)
)
native_gl
max_tile_size
:
DeviceIntSize
:
:
zero
(
)
depth_id
composite_thread
locked_framebuffer
:
None
}
}
fn
deinit_shader
(
&
mut
self
)
{
if
let
Some
(
draw_tile
)
=
&
self
.
draw_tile
{
draw_tile
.
deinit
(
)
;
}
self
.
draw_tile
=
None
;
}
fn
deinit_tile
(
&
self
tile
:
&
SwTile
)
{
self
.
gl
.
delete_framebuffers
(
&
[
tile
.
fbo_id
]
)
;
self
.
gl
.
delete_textures
(
&
[
tile
.
color_id
]
)
;
if
let
Some
(
native_gl
)
=
&
self
.
native_gl
{
native_gl
.
delete_textures
(
&
[
tile
.
tex_id
]
)
;
native_gl
.
delete_buffers
(
&
[
tile
.
pbo_id
]
)
;
}
}
fn
deinit_surface
(
&
self
surface
:
&
SwSurface
)
{
for
tile
in
&
surface
.
tiles
{
self
.
deinit_tile
(
tile
)
;
}
}
fn
occlude_surfaces
(
&
mut
self
)
{
fn
includes
(
outer
:
&
Range
<
i32
>
inner
:
&
Range
<
i32
>
)
-
>
bool
{
outer
.
start
<
=
inner
.
start
&
&
outer
.
end
>
=
inner
.
end
}
fn
overlaps
(
outer
:
&
Range
<
i32
>
inner
:
&
Range
<
i32
>
)
-
>
Option
<
Range
<
i32
>
>
{
if
outer
.
start
<
=
inner
.
start
&
&
outer
.
end
>
=
inner
.
start
{
Some
(
outer
.
end
.
.
inner
.
end
.
max
(
outer
.
end
)
)
}
else
if
outer
.
start
<
=
inner
.
end
&
&
outer
.
end
>
=
inner
.
end
{
Some
(
inner
.
start
.
.
outer
.
start
.
max
(
inner
.
start
)
)
}
else
{
None
}
}
fn
set_x_range
(
rect
:
&
mut
DeviceIntRect
range
:
&
Range
<
i32
>
)
{
rect
.
origin
.
x
=
range
.
start
;
rect
.
size
.
width
=
range
.
end
-
range
.
start
;
}
fn
set_y_range
(
rect
:
&
mut
DeviceIntRect
range
:
&
Range
<
i32
>
)
{
rect
.
origin
.
y
=
range
.
start
;
rect
.
size
.
height
=
range
.
end
-
range
.
start
;
}
fn
union
(
base
:
Range
<
i32
>
extra
:
Range
<
i32
>
)
-
>
Range
<
i32
>
{
base
.
start
.
min
(
extra
.
start
)
.
.
base
.
end
.
max
(
extra
.
end
)
}
for
&
mut
(
ref
id
ref
transform
ref
mut
clip_rect
_
)
in
&
mut
self
.
frame_surfaces
{
if
let
Some
(
surface
)
=
self
.
surfaces
.
get
(
id
)
{
*
clip_rect
=
surface
.
device_bounds
(
transform
clip_rect
)
.
unwrap_or_default
(
)
;
}
}
for
occlude_index
in
0
.
.
self
.
frame_surfaces
.
len
(
)
{
let
(
ref
occlude_id
_
ref
occlude_rect
_
)
=
self
.
frame_surfaces
[
occlude_index
]
;
match
self
.
surfaces
.
get
(
occlude_id
)
{
Some
(
occluder
)
if
occluder
.
is_opaque
&
&
!
occlude_rect
.
is_empty
(
)
=
>
{
}
_
=
>
continue
}
let
(
mut
occlude_x
mut
occlude_y
)
=
(
occlude_rect
.
x_range
(
)
occlude_rect
.
y_range
(
)
)
;
for
&
mut
(
ref
id
_
ref
mut
clip_rect
_
)
in
self
.
frame_surfaces
[
.
.
occlude_index
]
.
iter_mut
(
)
.
rev
(
)
{
if
let
Some
(
surface
)
=
self
.
surfaces
.
get
(
id
)
{
let
(
clip_x
clip_y
)
=
(
clip_rect
.
x_range
(
)
clip_rect
.
y_range
(
)
)
;
if
includes
(
&
occlude_x
&
clip_x
)
{
if
let
Some
(
visible
)
=
overlaps
(
&
occlude_y
&
clip_y
)
{
set_y_range
(
clip_rect
&
visible
)
;
if
surface
.
is_opaque
&
&
occlude_x
=
=
clip_x
{
occlude_y
=
union
(
occlude_y
visible
)
;
}
}
}
else
if
includes
(
&
occlude_y
&
clip_y
)
{
if
let
Some
(
visible
)
=
overlaps
(
&
occlude_x
&
clip_x
)
{
set_x_range
(
clip_rect
&
visible
)
;
if
surface
.
is_opaque
&
&
occlude_y
=
=
clip_y
{
occlude_x
=
union
(
occlude_x
visible
)
;
}
}
}
}
}
}
}
fn
reset_overlaps
(
&
mut
self
)
{
for
surface
in
self
.
surfaces
.
values_mut
(
)
{
for
tile
in
&
mut
surface
.
tiles
{
tile
.
overlaps
.
set
(
0
)
;
tile
.
invalid
.
set
(
false
)
;
tile
.
graph_node
.
reset
(
)
;
}
}
}
fn
init_overlaps
(
&
self
overlap_id
:
&
NativeSurfaceId
overlap_surface
:
&
SwSurface
overlap_tile
:
&
SwTile
overlap_transform
:
&
CompositorSurfaceTransform
overlap_clip_rect
:
&
DeviceIntRect
)
{
let
mut
overlaps
=
if
overlap_tile
.
invalid
.
get
(
)
{
1
}
else
{
0
}
;
let
overlap_rect
=
match
overlap_tile
.
overlap_rect
(
overlap_surface
overlap_transform
overlap_clip_rect
)
{
Some
(
overlap_rect
)
=
>
overlap_rect
None
=
>
{
overlap_tile
.
overlaps
.
set
(
overlaps
)
;
return
;
}
}
;
for
&
(
ref
id
ref
transform
ref
clip_rect
_
)
in
&
self
.
frame_surfaces
{
if
id
=
=
overlap_id
{
break
;
}
if
!
overlap_rect
.
intersects
(
clip_rect
)
{
continue
;
}
if
let
Some
(
surface
)
=
self
.
surfaces
.
get
(
id
)
{
for
tile
in
&
surface
.
tiles
{
if
tile
.
may_overlap
(
surface
transform
clip_rect
&
overlap_rect
)
{
if
tile
.
overlaps
.
get
(
)
>
0
{
overlaps
+
=
1
;
}
tile
.
graph_node
.
get_mut
(
)
.
add_child
(
overlap_tile
.
graph_node
.
clone
(
)
)
;
}
}
}
}
if
overlaps
>
0
{
overlap_tile
.
overlaps
.
set
(
overlaps
)
;
}
}
fn
queue_composite
(
&
self
surface
:
&
SwSurface
transform
:
&
CompositorSurfaceTransform
clip_rect
:
&
DeviceIntRect
filter
:
ImageRendering
tile
:
&
SwTile
job_queue
:
&
mut
SwCompositeJobQueue
)
{
if
let
Some
(
ref
composite_thread
)
=
self
.
composite_thread
{
if
let
Some
(
(
src_rect
dst_rect
flip_y
)
)
=
tile
.
composite_rects
(
surface
transform
clip_rect
)
{
let
source
=
if
surface
.
external_image
.
is_some
(
)
{
match
surface
.
composite_surface
{
Some
(
ref
info
)
=
>
match
info
.
yuv_planes
{
0
=
>
match
self
.
gl
.
lock_texture
(
info
.
textures
[
0
]
)
{
Some
(
texture
)
=
>
SwCompositeSource
:
:
BGRA
(
texture
)
None
=
>
return
}
3
=
>
match
(
self
.
gl
.
lock_texture
(
info
.
textures
[
0
]
)
self
.
gl
.
lock_texture
(
info
.
textures
[
1
]
)
self
.
gl
.
lock_texture
(
info
.
textures
[
2
]
)
)
{
(
Some
(
y_texture
)
Some
(
u_texture
)
Some
(
v_texture
)
)
=
>
SwCompositeSource
:
:
YUV
(
y_texture
u_texture
v_texture
info
.
color_space
info
.
color_depth
)
_
=
>
return
}
_
=
>
panic
!
(
"
unsupported
number
of
YUV
planes
:
{
}
"
info
.
yuv_planes
)
}
None
=
>
return
}
}
else
if
let
Some
(
texture
)
=
self
.
gl
.
lock_texture
(
tile
.
color_id
)
{
SwCompositeSource
:
:
BGRA
(
texture
)
}
else
{
return
;
}
;
if
let
Some
(
ref
framebuffer
)
=
self
.
locked_framebuffer
{
composite_thread
.
queue_composite
(
source
framebuffer
.
clone
(
)
src_rect
dst_rect
*
clip_rect
surface
.
is_opaque
flip_y
filter
tile
.
graph_node
.
clone
(
)
job_queue
)
;
}
}
}
}
fn
try_lock_composite_surface
(
&
mut
self
id
:
&
NativeSurfaceId
)
{
if
let
Some
(
surface
)
=
self
.
surfaces
.
get_mut
(
id
)
{
if
let
Some
(
external_image
)
=
surface
.
external_image
{
let
mut
info
=
SWGLCompositeSurfaceInfo
{
yuv_planes
:
0
textures
:
[
0
;
3
]
color_space
:
YuvColorSpace
:
:
Identity
color_depth
:
ColorDepth
:
:
Color8
size
:
DeviceIntSize
:
:
zero
(
)
}
;
assert
!
(
!
surface
.
tiles
.
is_empty
(
)
)
;
let
mut
tile
=
&
mut
surface
.
tiles
[
0
]
;
if
self
.
compositor
.
lock_composite_surface
(
self
.
gl
.
into
(
)
external_image
&
mut
info
)
{
tile
.
valid_rect
=
DeviceIntRect
:
:
from_size
(
info
.
size
)
;
surface
.
composite_surface
=
Some
(
info
)
;
}
else
{
tile
.
valid_rect
=
DeviceIntRect
:
:
zero
(
)
;
surface
.
composite_surface
=
None
;
}
}
}
}
fn
unlock_composite_surfaces
(
&
mut
self
)
{
for
&
(
ref
id
_
_
_
)
in
self
.
frame_surfaces
.
iter
(
)
.
chain
(
self
.
late_surfaces
.
iter
(
)
)
{
if
let
Some
(
surface
)
=
self
.
surfaces
.
get_mut
(
id
)
{
if
let
Some
(
external_image
)
=
surface
.
external_image
{
if
surface
.
composite_surface
.
is_some
(
)
{
self
.
compositor
.
unlock_composite_surface
(
self
.
gl
.
into
(
)
external_image
)
;
surface
.
composite_surface
=
None
;
}
}
}
}
}
fn
flush_composites
(
&
self
tile_id
:
&
NativeTileId
surface
:
&
SwSurface
tile
:
&
SwTile
)
{
let
composite_thread
=
match
&
self
.
composite_thread
{
Some
(
composite_thread
)
=
>
composite_thread
None
=
>
return
}
;
let
mut
frame_surfaces
=
self
.
frame_surfaces
.
iter
(
)
.
skip_while
(
|
&
(
ref
id
_
_
_
)
|
*
id
!
=
tile_id
.
surface_id
)
;
let
(
overlap_rect
mut
lock
)
=
match
frame_surfaces
.
next
(
)
{
Some
(
&
(
_
ref
transform
ref
clip_rect
filter
)
)
=
>
{
if
tile
.
invalid
.
get
(
)
{
tile
.
overlaps
.
set
(
tile
.
overlaps
.
get
(
)
-
1
)
;
}
if
tile
.
overlaps
.
get
(
)
>
0
{
return
;
}
let
mut
lock
=
composite_thread
.
lock
(
)
;
self
.
queue_composite
(
surface
transform
clip_rect
filter
tile
&
mut
lock
)
;
match
tile
.
overlap_rect
(
surface
transform
clip_rect
)
{
Some
(
overlap_rect
)
=
>
(
overlap_rect
lock
)
None
=
>
return
}
}
None
=
>
return
}
;
let
mut
flushed_bounds
=
overlap_rect
;
let
mut
flushed_rects
=
vec
!
[
overlap_rect
]
;
for
&
(
ref
id
ref
transform
ref
clip_rect
filter
)
in
frame_surfaces
{
if
!
flushed_bounds
.
intersects
(
clip_rect
)
{
continue
;
}
if
let
Some
(
surface
)
=
self
.
surfaces
.
get
(
&
id
)
{
for
tile
in
&
surface
.
tiles
{
let
mut
overlaps
=
tile
.
overlaps
.
get
(
)
;
if
overlaps
=
=
0
{
continue
;
}
let
overlap_rect
=
match
tile
.
overlap_rect
(
surface
transform
clip_rect
)
{
Some
(
overlap_rect
)
=
>
overlap_rect
None
=
>
continue
}
;
if
!
overlap_rect
.
intersects
(
&
flushed_bounds
)
{
continue
;
}
for
flushed_rect
in
&
flushed_rects
{
if
overlap_rect
.
intersects
(
flushed_rect
)
{
overlaps
-
=
1
;
}
}
if
overlaps
!
=
tile
.
overlaps
.
get
(
)
{
tile
.
overlaps
.
set
(
overlaps
)
;
if
overlaps
=
=
0
{
self
.
queue_composite
(
surface
transform
clip_rect
filter
tile
&
mut
lock
)
;
flushed_bounds
=
flushed_bounds
.
union
(
&
overlap_rect
)
;
flushed_rects
.
push
(
overlap_rect
)
;
}
}
}
}
}
}
}
impl
Compositor
for
SwCompositor
{
fn
create_surface
(
&
mut
self
id
:
NativeSurfaceId
virtual_offset
:
DeviceIntPoint
tile_size
:
DeviceIntSize
is_opaque
:
bool
)
{
if
self
.
use_native_compositor
{
self
.
compositor
.
create_surface
(
id
virtual_offset
tile_size
is_opaque
)
;
}
self
.
max_tile_size
=
DeviceIntSize
:
:
new
(
self
.
max_tile_size
.
width
.
max
(
tile_size
.
width
)
self
.
max_tile_size
.
height
.
max
(
tile_size
.
height
)
)
;
self
.
surfaces
.
insert
(
id
SwSurface
:
:
new
(
tile_size
is_opaque
)
)
;
}
fn
create_external_surface
(
&
mut
self
id
:
NativeSurfaceId
is_opaque
:
bool
)
{
if
self
.
use_native_compositor
{
self
.
compositor
.
create_external_surface
(
id
is_opaque
)
;
}
self
.
surfaces
.
insert
(
id
SwSurface
:
:
new
(
DeviceIntSize
:
:
zero
(
)
is_opaque
)
)
;
}
fn
destroy_surface
(
&
mut
self
id
:
NativeSurfaceId
)
{
if
let
Some
(
surface
)
=
self
.
surfaces
.
remove
(
&
id
)
{
self
.
deinit_surface
(
&
surface
)
;
}
if
self
.
use_native_compositor
{
self
.
compositor
.
destroy_surface
(
id
)
;
}
}
fn
deinit
(
&
mut
self
)
{
if
let
Some
(
ref
composite_thread
)
=
self
.
composite_thread
{
composite_thread
.
deinit
(
)
;
}
for
surface
in
self
.
surfaces
.
values
(
)
{
self
.
deinit_surface
(
surface
)
;
}
self
.
gl
.
delete_textures
(
&
[
self
.
depth_id
]
)
;
self
.
deinit_shader
(
)
;
if
self
.
use_native_compositor
{
self
.
compositor
.
deinit
(
)
;
}
}
fn
create_tile
(
&
mut
self
id
:
NativeTileId
)
{
if
self
.
use_native_compositor
{
self
.
compositor
.
create_tile
(
id
)
;
}
if
let
Some
(
surface
)
=
self
.
surfaces
.
get_mut
(
&
id
.
surface_id
)
{
let
mut
tile
=
SwTile
:
:
new
(
id
.
x
id
.
y
)
;
tile
.
color_id
=
self
.
gl
.
gen_textures
(
1
)
[
0
]
;
tile
.
fbo_id
=
self
.
gl
.
gen_framebuffers
(
1
)
[
0
]
;
self
.
gl
.
bind_framebuffer
(
gl
:
:
DRAW_FRAMEBUFFER
tile
.
fbo_id
)
;
self
.
gl
.
framebuffer_texture_2d
(
gl
:
:
DRAW_FRAMEBUFFER
gl
:
:
COLOR_ATTACHMENT0
gl
:
:
TEXTURE_2D
tile
.
color_id
0
)
;
self
.
gl
.
framebuffer_texture_2d
(
gl
:
:
DRAW_FRAMEBUFFER
gl
:
:
DEPTH_ATTACHMENT
gl
:
:
TEXTURE_2D
self
.
depth_id
0
)
;
self
.
gl
.
bind_framebuffer
(
gl
:
:
DRAW_FRAMEBUFFER
0
)
;
if
let
Some
(
native_gl
)
=
&
self
.
native_gl
{
tile
.
tex_id
=
native_gl
.
gen_textures
(
1
)
[
0
]
;
native_gl
.
bind_texture
(
gl
:
:
TEXTURE_2D
tile
.
tex_id
)
;
native_gl
.
tex_image_2d
(
gl
:
:
TEXTURE_2D
0
gl
:
:
RGBA8
as
gl
:
:
GLint
surface
.
tile_size
.
width
surface
.
tile_size
.
height
0
gl
:
:
RGBA
gl
:
:
UNSIGNED_BYTE
None
)
;
native_gl
.
tex_parameter_i
(
gl
:
:
TEXTURE_2D
gl
:
:
TEXTURE_MIN_FILTER
gl
:
:
LINEAR
as
gl
:
:
GLint
)
;
native_gl
.
tex_parameter_i
(
gl
:
:
TEXTURE_2D
gl
:
:
TEXTURE_MAG_FILTER
gl
:
:
LINEAR
as
gl
:
:
GLint
)
;
native_gl
.
tex_parameter_i
(
gl
:
:
TEXTURE_2D
gl
:
:
TEXTURE_WRAP_S
gl
:
:
CLAMP_TO_EDGE
as
gl
:
:
GLint
)
;
native_gl
.
tex_parameter_i
(
gl
:
:
TEXTURE_2D
gl
:
:
TEXTURE_WRAP_T
gl
:
:
CLAMP_TO_EDGE
as
gl
:
:
GLint
)
;
native_gl
.
bind_texture
(
gl
:
:
TEXTURE_2D
0
)
;
tile
.
pbo_id
=
native_gl
.
gen_buffers
(
1
)
[
0
]
;
native_gl
.
bind_buffer
(
gl
:
:
PIXEL_UNPACK_BUFFER
tile
.
pbo_id
)
;
native_gl
.
buffer_data_untyped
(
gl
:
:
PIXEL_UNPACK_BUFFER
surface
.
tile_size
.
area
(
)
as
isize
*
4
ptr
:
:
null
(
)
gl
:
:
DYNAMIC_DRAW
)
;
native_gl
.
bind_buffer
(
gl
:
:
PIXEL_UNPACK_BUFFER
0
)
;
}
surface
.
tiles
.
push
(
tile
)
;
}
}
fn
destroy_tile
(
&
mut
self
id
:
NativeTileId
)
{
if
let
Some
(
surface
)
=
self
.
surfaces
.
get_mut
(
&
id
.
surface_id
)
{
if
let
Some
(
idx
)
=
surface
.
tiles
.
iter
(
)
.
position
(
|
t
|
t
.
x
=
=
id
.
x
&
&
t
.
y
=
=
id
.
y
)
{
let
tile
=
surface
.
tiles
.
remove
(
idx
)
;
self
.
deinit_tile
(
&
tile
)
;
}
}
if
self
.
use_native_compositor
{
self
.
compositor
.
destroy_tile
(
id
)
;
}
}
fn
attach_external_image
(
&
mut
self
id
:
NativeSurfaceId
external_image
:
ExternalImageId
)
{
if
self
.
use_native_compositor
{
self
.
compositor
.
attach_external_image
(
id
external_image
)
;
}
if
let
Some
(
surface
)
=
self
.
surfaces
.
get_mut
(
&
id
)
{
assert
!
(
surface
.
tile_size
.
is_empty
(
)
)
;
surface
.
external_image
=
Some
(
external_image
)
;
if
surface
.
tiles
.
is_empty
(
)
{
surface
.
tiles
.
push
(
SwTile
:
:
new
(
0
0
)
)
;
}
}
}
fn
invalidate_tile
(
&
mut
self
id
:
NativeTileId
valid_rect
:
DeviceIntRect
)
{
if
self
.
use_native_compositor
{
self
.
compositor
.
invalidate_tile
(
id
valid_rect
)
;
}
if
let
Some
(
surface
)
=
self
.
surfaces
.
get_mut
(
&
id
.
surface_id
)
{
if
let
Some
(
tile
)
=
surface
.
tiles
.
iter_mut
(
)
.
find
(
|
t
|
t
.
x
=
=
id
.
x
&
&
t
.
y
=
=
id
.
y
)
{
tile
.
invalid
.
set
(
true
)
;
tile
.
valid_rect
=
valid_rect
;
}
}
}
fn
bind
(
&
mut
self
id
:
NativeTileId
dirty_rect
:
DeviceIntRect
valid_rect
:
DeviceIntRect
)
-
>
NativeSurfaceInfo
{
let
mut
surface_info
=
NativeSurfaceInfo
{
origin
:
DeviceIntPoint
:
:
zero
(
)
fbo_id
:
0
}
;
self
.
cur_tile
=
id
;
if
let
Some
(
surface
)
=
self
.
surfaces
.
get_mut
(
&
id
.
surface_id
)
{
if
let
Some
(
tile
)
=
surface
.
tiles
.
iter_mut
(
)
.
find
(
|
t
|
t
.
x
=
=
id
.
x
&
&
t
.
y
=
=
id
.
y
)
{
tile
.
dirty_rect
=
dirty_rect
;
assert_eq
!
(
tile
.
valid_rect
valid_rect
)
;
if
valid_rect
.
is_empty
(
)
{
return
surface_info
;
}
let
mut
stride
=
0
;
let
mut
buf
=
ptr
:
:
null_mut
(
)
;
if
self
.
use_native_compositor
{
if
let
Some
(
tile_info
)
=
self
.
compositor
.
map_tile
(
id
dirty_rect
valid_rect
)
{
stride
=
tile_info
.
stride
;
buf
=
tile_info
.
data
;
}
}
else
if
let
Some
(
native_gl
)
=
&
self
.
native_gl
{
if
tile
.
pbo_id
!
=
0
{
native_gl
.
bind_buffer
(
gl
:
:
PIXEL_UNPACK_BUFFER
tile
.
pbo_id
)
;
buf
=
native_gl
.
map_buffer_range
(
gl
:
:
PIXEL_UNPACK_BUFFER
0
valid_rect
.
size
.
area
(
)
as
isize
*
4
gl
:
:
MAP_WRITE_BIT
|
gl
:
:
MAP_INVALIDATE_BUFFER_BIT
)
;
if
buf
!
=
ptr
:
:
null_mut
(
)
{
stride
=
valid_rect
.
size
.
width
*
4
;
}
else
{
native_gl
.
bind_buffer
(
gl
:
:
PIXEL_UNPACK_BUFFER
0
)
;
native_gl
.
delete_buffers
(
&
[
tile
.
pbo_id
]
)
;
tile
.
pbo_id
=
0
;
}
}
}
self
.
gl
.
set_texture_buffer
(
tile
.
color_id
gl
:
:
RGBA8
valid_rect
.
size
.
width
valid_rect
.
size
.
height
stride
buf
surface
.
tile_size
.
width
surface
.
tile_size
.
height
)
;
self
.
gl
.
set_texture_buffer
(
self
.
depth_id
gl
:
:
DEPTH_COMPONENT
valid_rect
.
size
.
width
valid_rect
.
size
.
height
0
ptr
:
:
null_mut
(
)
self
.
max_tile_size
.
width
self
.
max_tile_size
.
height
)
;
surface_info
.
fbo_id
=
tile
.
fbo_id
;
surface_info
.
origin
-
=
valid_rect
.
origin
.
to_vector
(
)
;
}
}
surface_info
}
fn
unbind
(
&
mut
self
)
{
let
id
=
self
.
cur_tile
;
if
let
Some
(
surface
)
=
self
.
surfaces
.
get
(
&
id
.
surface_id
)
{
if
let
Some
(
tile
)
=
surface
.
tiles
.
iter
(
)
.
find
(
|
t
|
t
.
x
=
=
id
.
x
&
&
t
.
y
=
=
id
.
y
)
{
if
tile
.
valid_rect
.
is_empty
(
)
{
self
.
flush_composites
(
&
id
surface
tile
)
;
return
;
}
let
(
swbuf
_
_
stride
)
=
self
.
gl
.
get_color_buffer
(
tile
.
fbo_id
true
)
;
if
self
.
use_native_compositor
{
self
.
compositor
.
unmap_tile
(
)
;
return
;
}
let
native_gl
=
match
&
self
.
native_gl
{
Some
(
native_gl
)
=
>
native_gl
None
=
>
{
self
.
flush_composites
(
&
id
surface
tile
)
;
return
;
}
}
;
assert
!
(
stride
%
4
=
=
0
)
;
let
buf
=
if
tile
.
pbo_id
!
=
0
{
native_gl
.
unmap_buffer
(
gl
:
:
PIXEL_UNPACK_BUFFER
)
;
std
:
:
ptr
:
:
null_mut
:
:
<
c_void
>
(
)
}
else
{
swbuf
}
;
let
dirty
=
tile
.
dirty_rect
;
let
src
=
unsafe
{
(
buf
as
*
mut
u32
)
.
offset
(
(
dirty
.
origin
.
y
-
tile
.
valid_rect
.
origin
.
y
)
as
isize
*
(
stride
/
4
)
as
isize
+
(
dirty
.
origin
.
x
-
tile
.
valid_rect
.
origin
.
x
)
as
isize
)
}
;
native_gl
.
active_texture
(
gl
:
:
TEXTURE0
)
;
native_gl
.
bind_texture
(
gl
:
:
TEXTURE_2D
tile
.
tex_id
)
;
native_gl
.
pixel_store_i
(
gl
:
:
UNPACK_ROW_LENGTH
stride
/
4
)
;
native_gl
.
tex_sub_image_2d_pbo
(
gl
:
:
TEXTURE_2D
0
dirty
.
origin
.
x
dirty
.
origin
.
y
dirty
.
size
.
width
dirty
.
size
.
height
gl
:
:
BGRA
gl
:
:
UNSIGNED_BYTE
src
as
_
)
;
native_gl
.
pixel_store_i
(
gl
:
:
UNPACK_ROW_LENGTH
0
)
;
if
tile
.
pbo_id
!
=
0
{
native_gl
.
bind_buffer
(
gl
:
:
PIXEL_UNPACK_BUFFER
0
)
;
}
native_gl
.
bind_texture
(
gl
:
:
TEXTURE_2D
0
)
;
}
}
}
fn
begin_frame
(
&
mut
self
)
{
if
self
.
use_native_compositor
{
self
.
compositor
.
begin_frame
(
)
;
}
self
.
frame_surfaces
.
clear
(
)
;
self
.
late_surfaces
.
clear
(
)
;
self
.
reset_overlaps
(
)
;
}
fn
add_surface
(
&
mut
self
id
:
NativeSurfaceId
transform
:
CompositorSurfaceTransform
clip_rect
:
DeviceIntRect
filter
:
ImageRendering
)
{
if
self
.
use_native_compositor
{
self
.
compositor
.
add_surface
(
id
transform
clip_rect
filter
)
;
}
if
self
.
composite_thread
.
is_some
(
)
{
self
.
try_lock_composite_surface
(
&
id
)
;
if
self
.
composite_thread
.
as_ref
(
)
.
unwrap
(
)
.
is_busy_compositing
(
)
{
self
.
late_surfaces
.
push
(
(
id
transform
clip_rect
filter
)
)
;
return
;
}
}
self
.
frame_surfaces
.
push
(
(
id
transform
clip_rect
filter
)
)
;
}
fn
start_compositing
(
&
mut
self
dirty_rects
:
&
[
DeviceIntRect
]
_opaque_rects
:
&
[
DeviceIntRect
]
)
{
let
mut
opaque_rects
:
Vec
<
DeviceIntRect
>
=
Vec
:
:
new
(
)
;
for
&
(
ref
id
ref
transform
ref
clip_rect
_filter
)
in
&
self
.
frame_surfaces
{
if
let
Some
(
surface
)
=
self
.
surfaces
.
get
(
id
)
{
if
!
surface
.
is_opaque
{
continue
;
}
for
tile
in
&
surface
.
tiles
{
if
let
Some
(
rect
)
=
tile
.
overlap_rect
(
surface
transform
clip_rect
)
{
opaque_rects
.
push
(
rect
)
;
}
}
}
}
self
.
compositor
.
start_compositing
(
dirty_rects
&
opaque_rects
)
;
if
let
Some
(
dirty_rect
)
=
dirty_rects
.
iter
(
)
.
fold
(
DeviceIntRect
:
:
zero
(
)
|
acc
dirty_rect
|
acc
.
union
(
dirty_rect
)
)
.
to_non_empty
(
)
{
for
&
mut
(
_
_
ref
mut
clip_rect
_
)
in
&
mut
self
.
frame_surfaces
{
*
clip_rect
=
clip_rect
.
intersection
(
&
dirty_rect
)
.
unwrap_or_default
(
)
;
}
}
self
.
occlude_surfaces
(
)
;
self
.
frame_surfaces
.
retain
(
|
&
(
_
_
clip_rect
_
)
|
!
clip_rect
.
is_empty
(
)
)
;
if
let
Some
(
ref
composite_thread
)
=
self
.
composite_thread
{
for
&
(
ref
id
ref
transform
ref
clip_rect
_filter
)
in
&
self
.
frame_surfaces
{
if
let
Some
(
surface
)
=
self
.
surfaces
.
get
(
id
)
{
for
tile
in
&
surface
.
tiles
{
self
.
init_overlaps
(
id
surface
tile
transform
clip_rect
)
;
}
}
}
self
.
locked_framebuffer
=
self
.
gl
.
lock_framebuffer
(
0
)
;
composite_thread
.
prepare_for_composites
(
)
;
let
mut
lock
=
composite_thread
.
lock
(
)
;
for
&
(
ref
id
ref
transform
ref
clip_rect
filter
)
in
&
self
.
frame_surfaces
{
if
let
Some
(
surface
)
=
self
.
surfaces
.
get
(
id
)
{
for
tile
in
&
surface
.
tiles
{
if
tile
.
overlaps
.
get
(
)
=
=
0
{
self
.
queue_composite
(
surface
transform
clip_rect
filter
tile
&
mut
lock
)
;
}
}
}
}
}
}
fn
end_frame
(
&
mut
self
)
{
if
self
.
use_native_compositor
{
self
.
compositor
.
end_frame
(
)
;
}
else
if
let
Some
(
native_gl
)
=
&
self
.
native_gl
{
let
(
_
fw
fh
_
)
=
self
.
gl
.
get_color_buffer
(
0
false
)
;
let
viewport
=
DeviceIntRect
:
:
from_size
(
DeviceIntSize
:
:
new
(
fw
fh
)
)
;
let
draw_tile
=
self
.
draw_tile
.
as_ref
(
)
.
unwrap
(
)
;
draw_tile
.
enable
(
&
viewport
)
;
let
mut
blend
=
false
;
native_gl
.
blend_func
(
gl
:
:
ONE
gl
:
:
ONE_MINUS_SRC_ALPHA
)
;
for
&
(
ref
id
ref
transform
ref
clip_rect
filter
)
in
&
self
.
frame_surfaces
{
if
let
Some
(
surface
)
=
self
.
surfaces
.
get
(
id
)
{
if
surface
.
is_opaque
{
if
blend
{
native_gl
.
disable
(
gl
:
:
BLEND
)
;
blend
=
false
;
}
}
else
if
!
blend
{
native_gl
.
enable
(
gl
:
:
BLEND
)
;
blend
=
true
;
}
for
tile
in
&
surface
.
tiles
{
if
let
Some
(
(
src_rect
dst_rect
flip_y
)
)
=
tile
.
composite_rects
(
surface
transform
clip_rect
)
{
draw_tile
.
draw
(
&
viewport
&
dst_rect
&
src_rect
clip_rect
surface
tile
flip_y
image_rendering_to_gl_filter
(
filter
)
)
;
}
}
}
}
if
blend
{
native_gl
.
disable
(
gl
:
:
BLEND
)
;
}
draw_tile
.
disable
(
)
;
}
else
if
let
Some
(
ref
composite_thread
)
=
self
.
composite_thread
{
composite_thread
.
wait_for_composites
(
false
)
;
if
!
self
.
late_surfaces
.
is_empty
(
)
{
composite_thread
.
prepare_for_composites
(
)
;
{
let
mut
lock
=
composite_thread
.
lock
(
)
;
for
&
(
ref
id
ref
transform
ref
clip_rect
filter
)
in
&
self
.
late_surfaces
{
if
let
Some
(
surface
)
=
self
.
surfaces
.
get
(
id
)
{
for
tile
in
&
surface
.
tiles
{
self
.
queue_composite
(
surface
transform
clip_rect
filter
tile
&
mut
lock
)
;
}
}
}
}
composite_thread
.
wait_for_composites
(
true
)
;
}
self
.
locked_framebuffer
=
None
;
self
.
unlock_composite_surfaces
(
)
;
}
}
fn
enable_native_compositor
(
&
mut
self
enable
:
bool
)
{
self
.
compositor
.
enable_native_compositor
(
enable
)
;
self
.
use_native_compositor
=
enable
;
}
fn
get_capabilities
(
&
self
)
-
>
CompositorCapabilities
{
self
.
compositor
.
get_capabilities
(
)
}
}
