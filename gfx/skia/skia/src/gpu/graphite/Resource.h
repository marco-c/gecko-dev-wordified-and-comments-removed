#
ifndef
skgpu_graphite_Resource_DEFINED
#
define
skgpu_graphite_Resource_DEFINED
#
include
"
include
/
gpu
/
GpuTypes
.
h
"
#
include
"
include
/
private
/
base
/
SkMutex
.
h
"
#
include
"
src
/
gpu
/
graphite
/
GraphiteResourceKey
.
h
"
#
include
"
src
/
gpu
/
graphite
/
ResourceTypes
.
h
"
#
include
<
atomic
>
class
SkMutex
;
namespace
skgpu
:
:
graphite
{
class
ResourceCache
;
class
SharedContext
;
class
Resource
{
public
:
Resource
(
const
Resource
&
)
=
delete
;
Resource
(
Resource
&
&
)
=
delete
;
Resource
&
operator
=
(
const
Resource
&
)
=
delete
;
Resource
&
operator
=
(
Resource
&
&
)
=
delete
;
void
ref
(
)
const
{
SkASSERT
(
this
-
>
hasUsageRef
(
)
)
;
(
void
)
fUsageRefCnt
.
fetch_add
(
+
1
std
:
:
memory_order_relaxed
)
;
}
void
unref
(
)
const
{
bool
shouldFree
=
false
;
{
SkAutoMutexExclusive
locked
(
fUnrefMutex
)
;
SkASSERT
(
this
-
>
hasUsageRef
(
)
)
;
if
(
1
=
=
fUsageRefCnt
.
fetch_add
(
-
1
std
:
:
memory_order_acq_rel
)
)
{
shouldFree
=
this
-
>
notifyARefIsZero
(
LastRemovedRef
:
:
kUsage
)
;
}
}
if
(
shouldFree
)
{
Resource
*
mutableThis
=
const_cast
<
Resource
*
>
(
this
)
;
mutableThis
-
>
internalDispose
(
)
;
}
}
void
refCommandBuffer
(
)
const
{
(
void
)
fCommandBufferRefCnt
.
fetch_add
(
+
1
std
:
:
memory_order_relaxed
)
;
}
void
unrefCommandBuffer
(
)
const
{
bool
shouldFree
=
false
;
{
SkAutoMutexExclusive
locked
(
fUnrefMutex
)
;
SkASSERT
(
this
-
>
hasCommandBufferRef
(
)
)
;
if
(
1
=
=
fCommandBufferRefCnt
.
fetch_add
(
-
1
std
:
:
memory_order_acq_rel
)
)
{
shouldFree
=
this
-
>
notifyARefIsZero
(
LastRemovedRef
:
:
kCommandBuffer
)
;
}
}
if
(
shouldFree
)
{
Resource
*
mutableThis
=
const_cast
<
Resource
*
>
(
this
)
;
mutableThis
-
>
internalDispose
(
)
;
}
}
Ownership
ownership
(
)
const
{
return
fOwnership
;
}
skgpu
:
:
Budgeted
budgeted
(
)
const
{
return
fBudgeted
;
}
size_t
gpuMemorySize
(
)
const
{
return
fGpuMemorySize
;
}
bool
wasDestroyed
(
)
const
{
return
fSharedContext
=
=
nullptr
;
}
const
GraphiteResourceKey
&
key
(
)
const
{
return
fKey
;
}
void
setKey
(
const
GraphiteResourceKey
&
key
)
{
SkASSERT
(
key
.
shareable
(
)
=
=
Shareable
:
:
kNo
|
|
this
-
>
budgeted
(
)
=
=
skgpu
:
:
Budgeted
:
:
kYes
)
;
fKey
=
key
;
}
protected
:
Resource
(
const
SharedContext
*
Ownership
skgpu
:
:
Budgeted
size_t
gpuMemorySize
)
;
virtual
~
Resource
(
)
;
const
SharedContext
*
sharedContext
(
)
const
{
return
fSharedContext
;
}
virtual
void
freeGpuData
(
)
=
0
;
virtual
void
invokeReleaseProc
(
)
{
}
#
ifdef
SK_DEBUG
bool
debugHasCommandBufferRef
(
)
const
{
return
hasCommandBufferRef
(
)
;
}
#
endif
private
:
friend
ResourceCache
;
void
makeBudgeted
(
)
{
fBudgeted
=
skgpu
:
:
Budgeted
:
:
kYes
;
}
void
makeUnbudgeted
(
)
{
fBudgeted
=
skgpu
:
:
Budgeted
:
:
kNo
;
}
void
initialUsageRef
(
)
const
{
SkASSERT
(
fUsageRefCnt
>
=
0
)
;
(
void
)
fUsageRefCnt
.
fetch_add
(
+
1
std
:
:
memory_order_relaxed
)
;
}
bool
isPurgeable
(
)
const
;
int
*
accessReturnIndex
(
)
const
{
return
&
fReturnIndex
;
}
int
*
accessCacheIndex
(
)
const
{
return
&
fCacheArrayIndex
;
}
uint32_t
timestamp
(
)
const
{
return
fTimestamp
;
}
void
setTimestamp
(
uint32_t
ts
)
{
fTimestamp
=
ts
;
}
void
registerWithCache
(
sk_sp
<
ResourceCache
>
)
;
void
refCache
(
)
const
{
(
void
)
fCacheRefCnt
.
fetch_add
(
+
1
std
:
:
memory_order_relaxed
)
;
}
void
unrefCache
(
)
const
{
bool
shouldFree
=
false
;
{
SkAutoMutexExclusive
locked
(
fUnrefMutex
)
;
SkASSERT
(
this
-
>
hasCacheRef
(
)
)
;
if
(
1
=
=
fCacheRefCnt
.
fetch_add
(
-
1
std
:
:
memory_order_acq_rel
)
)
{
shouldFree
=
this
-
>
notifyARefIsZero
(
LastRemovedRef
:
:
kCache
)
;
}
}
if
(
shouldFree
)
{
Resource
*
mutableThis
=
const_cast
<
Resource
*
>
(
this
)
;
mutableThis
-
>
internalDispose
(
)
;
}
}
#
ifdef
SK_DEBUG
bool
isUsableAsScratch
(
)
const
{
return
fKey
.
shareable
(
)
=
=
Shareable
:
:
kNo
&
&
!
this
-
>
hasUsageRef
(
)
&
&
fNonShareableInCache
;
}
#
endif
bool
hasUsageRef
(
)
const
{
if
(
0
=
=
fUsageRefCnt
.
load
(
std
:
:
memory_order_acquire
)
)
{
return
false
;
}
return
true
;
}
bool
hasCommandBufferRef
(
)
const
{
if
(
0
=
=
fCommandBufferRefCnt
.
load
(
std
:
:
memory_order_acquire
)
)
{
return
false
;
}
return
true
;
}
bool
hasCacheRef
(
)
const
{
if
(
0
=
=
fCacheRefCnt
.
load
(
std
:
:
memory_order_acquire
)
)
{
return
false
;
}
return
true
;
}
bool
hasAnyRefs
(
)
const
{
return
this
-
>
hasUsageRef
(
)
|
|
this
-
>
hasCommandBufferRef
(
)
|
|
this
-
>
hasCacheRef
(
)
;
}
bool
notifyARefIsZero
(
LastRemovedRef
removedRef
)
const
;
void
internalDispose
(
)
;
mutable
SkMutex
fUnrefMutex
;
SkDEBUGCODE
(
mutable
bool
fCalledRemovedFromCache
=
false
;
)
const
SharedContext
*
fSharedContext
;
mutable
std
:
:
atomic
<
int32_t
>
fUsageRefCnt
;
mutable
std
:
:
atomic
<
int32_t
>
fCommandBufferRefCnt
;
mutable
std
:
:
atomic
<
int32_t
>
fCacheRefCnt
;
GraphiteResourceKey
fKey
;
sk_sp
<
ResourceCache
>
fReturnCache
;
mutable
int
fReturnIndex
=
-
1
;
Ownership
fOwnership
;
static
const
size_t
kInvalidGpuMemorySize
=
~
static_cast
<
size_t
>
(
0
)
;
mutable
size_t
fGpuMemorySize
=
kInvalidGpuMemorySize
;
skgpu
:
:
Budgeted
fBudgeted
;
mutable
int
fCacheArrayIndex
=
-
1
;
uint32_t
fTimestamp
;
SkDEBUGCODE
(
mutable
bool
fNonShareableInCache
=
false
)
;
}
;
}
#
endif
