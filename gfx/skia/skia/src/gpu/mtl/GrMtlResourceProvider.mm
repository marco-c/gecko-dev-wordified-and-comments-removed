#
include
"
src
/
gpu
/
mtl
/
GrMtlResourceProvider
.
h
"
#
include
"
include
/
gpu
/
GrContextOptions
.
h
"
#
include
"
src
/
gpu
/
GrContextPriv
.
h
"
#
include
"
src
/
gpu
/
mtl
/
GrMtlCommandBuffer
.
h
"
#
include
"
src
/
gpu
/
mtl
/
GrMtlGpu
.
h
"
#
include
"
src
/
gpu
/
mtl
/
GrMtlPipelineState
.
h
"
#
include
"
src
/
gpu
/
mtl
/
GrMtlUtil
.
h
"
#
include
"
src
/
sksl
/
SkSLCompiler
.
h
"
#
if
!
__has_feature
(
objc_arc
)
#
error
This
file
must
be
compiled
with
Arc
.
Use
-
fobjc
-
arc
flag
#
endif
GrMtlResourceProvider
:
:
GrMtlResourceProvider
(
GrMtlGpu
*
gpu
)
:
fGpu
(
gpu
)
{
fPipelineStateCache
.
reset
(
new
PipelineStateCache
(
gpu
)
)
;
fBufferSuballocator
.
reset
(
new
BufferSuballocator
(
gpu
-
>
device
(
)
kBufferSuballocatorStartSize
)
)
;
#
ifdef
SK_BUILD_FOR_MAC
int64_t
maxBufferLength
=
1024
*
1024
*
1024
;
#
else
int64_t
maxBufferLength
=
256
*
1024
*
1024
;
#
endif
if
(
available
(
iOS
12
macOS
10
.
14
*
)
)
{
maxBufferLength
=
gpu
-
>
device
(
)
.
maxBufferLength
;
}
fBufferSuballocatorMaxSize
=
maxBufferLength
/
16
;
}
GrMtlPipelineState
*
GrMtlResourceProvider
:
:
findOrCreateCompatiblePipelineState
(
GrRenderTarget
*
renderTarget
const
GrProgramInfo
&
programInfo
GrPrimitiveType
primitiveType
)
{
return
fPipelineStateCache
-
>
refPipelineState
(
renderTarget
programInfo
primitiveType
)
;
}
GrMtlDepthStencil
*
GrMtlResourceProvider
:
:
findOrCreateCompatibleDepthStencilState
(
const
GrStencilSettings
&
stencil
GrSurfaceOrigin
origin
)
{
GrMtlDepthStencil
*
depthStencilState
;
GrMtlDepthStencil
:
:
Key
key
=
GrMtlDepthStencil
:
:
GenerateKey
(
stencil
origin
)
;
depthStencilState
=
fDepthStencilStates
.
find
(
key
)
;
if
(
!
depthStencilState
)
{
depthStencilState
=
GrMtlDepthStencil
:
:
Create
(
fGpu
stencil
origin
)
;
fDepthStencilStates
.
add
(
depthStencilState
)
;
}
SkASSERT
(
depthStencilState
)
;
return
depthStencilState
;
}
GrMtlSampler
*
GrMtlResourceProvider
:
:
findOrCreateCompatibleSampler
(
const
GrSamplerState
&
params
)
{
GrMtlSampler
*
sampler
;
sampler
=
fSamplers
.
find
(
GrMtlSampler
:
:
GenerateKey
(
params
)
)
;
if
(
!
sampler
)
{
sampler
=
GrMtlSampler
:
:
Create
(
fGpu
params
)
;
fSamplers
.
add
(
sampler
)
;
}
SkASSERT
(
sampler
)
;
return
sampler
;
}
void
GrMtlResourceProvider
:
:
destroyResources
(
)
{
SkTDynamicHash
<
GrMtlSampler
GrMtlSampler
:
:
Key
>
:
:
Iter
samplerIter
(
&
fSamplers
)
;
for
(
;
!
samplerIter
.
done
(
)
;
+
+
samplerIter
)
{
(
*
samplerIter
)
.
unref
(
)
;
}
fSamplers
.
reset
(
)
;
SkTDynamicHash
<
GrMtlDepthStencil
GrMtlDepthStencil
:
:
Key
>
:
:
Iter
dsIter
(
&
fDepthStencilStates
)
;
for
(
;
!
dsIter
.
done
(
)
;
+
+
dsIter
)
{
(
*
dsIter
)
.
unref
(
)
;
}
fDepthStencilStates
.
reset
(
)
;
fPipelineStateCache
-
>
release
(
)
;
}
#
ifdef
GR_PIPELINE_STATE_CACHE_STATS
static
const
bool
c_DisplayMtlPipelineCache
{
false
}
;
#
endif
struct
GrMtlResourceProvider
:
:
PipelineStateCache
:
:
Entry
{
Entry
(
GrMtlGpu
*
gpu
GrMtlPipelineState
*
pipelineState
)
:
fGpu
(
gpu
)
fPipelineState
(
pipelineState
)
{
}
GrMtlGpu
*
fGpu
;
std
:
:
unique_ptr
<
GrMtlPipelineState
>
fPipelineState
;
}
;
GrMtlResourceProvider
:
:
PipelineStateCache
:
:
PipelineStateCache
(
GrMtlGpu
*
gpu
)
:
fMap
(
gpu
-
>
getContext
(
)
-
>
priv
(
)
.
options
(
)
.
fRuntimeProgramCacheSize
)
fGpu
(
gpu
)
#
ifdef
GR_PIPELINE_STATE_CACHE_STATS
fTotalRequests
(
0
)
fCacheMisses
(
0
)
#
endif
{
}
GrMtlResourceProvider
:
:
PipelineStateCache
:
:
~
PipelineStateCache
(
)
{
SkASSERT
(
0
=
=
fMap
.
count
(
)
)
;
#
ifdef
GR_PIPELINE_STATE_CACHE_STATS
if
(
c_DisplayMtlPipelineCache
)
{
SkDebugf
(
"
-
-
-
Pipeline
State
Cache
-
-
-
\
n
"
)
;
SkDebugf
(
"
Total
requests
:
%
d
\
n
"
fTotalRequests
)
;
SkDebugf
(
"
Cache
misses
:
%
d
\
n
"
fCacheMisses
)
;
SkDebugf
(
"
Cache
miss
%
%
:
%
f
\
n
"
(
fTotalRequests
>
0
)
?
100
.
f
*
fCacheMisses
/
fTotalRequests
:
0
.
f
)
;
SkDebugf
(
"
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
\
n
"
)
;
}
#
endif
}
void
GrMtlResourceProvider
:
:
PipelineStateCache
:
:
release
(
)
{
fMap
.
reset
(
)
;
}
GrMtlPipelineState
*
GrMtlResourceProvider
:
:
PipelineStateCache
:
:
refPipelineState
(
GrRenderTarget
*
renderTarget
const
GrProgramInfo
&
programInfo
GrPrimitiveType
primType
)
{
#
ifdef
GR_PIPELINE_STATE_CACHE_STATS
+
+
fTotalRequests
;
#
endif
GrMtlPipelineStateBuilder
:
:
Desc
desc
;
if
(
!
GrMtlPipelineStateBuilder
:
:
Desc
:
:
Build
(
&
desc
renderTarget
programInfo
primType
fGpu
)
)
{
GrCapsDebugf
(
fGpu
-
>
caps
(
)
"
Failed
to
build
mtl
program
descriptor
!
\
n
"
)
;
return
nullptr
;
}
std
:
:
unique_ptr
<
Entry
>
*
entry
=
fMap
.
find
(
desc
)
;
if
(
!
entry
)
{
#
ifdef
GR_PIPELINE_STATE_CACHE_STATS
+
+
fCacheMisses
;
#
endif
GrMtlPipelineState
*
pipelineState
(
GrMtlPipelineStateBuilder
:
:
CreatePipelineState
(
fGpu
renderTarget
programInfo
&
desc
)
)
;
if
(
!
pipelineState
)
{
return
nullptr
;
}
entry
=
fMap
.
insert
(
desc
std
:
:
unique_ptr
<
Entry
>
(
new
Entry
(
fGpu
pipelineState
)
)
)
;
return
(
*
entry
)
-
>
fPipelineState
.
get
(
)
;
}
return
(
*
entry
)
-
>
fPipelineState
.
get
(
)
;
}
static
id
<
MTLBuffer
>
alloc_dynamic_buffer
(
id
<
MTLDevice
>
device
size_t
size
)
{
NSUInteger
options
=
0
;
if
(
available
(
macOS
10
.
11
iOS
9
.
0
*
)
)
{
#
ifdef
SK_BUILD_FOR_MAC
options
|
=
MTLResourceStorageModeManaged
;
#
else
options
|
=
MTLResourceStorageModeShared
;
#
endif
}
return
[
device
newBufferWithLength
:
size
options
:
options
]
;
}
GrMtlResourceProvider
:
:
BufferSuballocator
:
:
BufferSuballocator
(
id
<
MTLDevice
>
device
size_t
size
)
:
fBuffer
(
alloc_dynamic_buffer
(
device
size
)
)
fTotalSize
(
size
)
fHead
(
0
)
fTail
(
0
)
{
SkASSERT
(
SkIsPow2
(
size
)
)
;
}
id
<
MTLBuffer
>
GrMtlResourceProvider
:
:
BufferSuballocator
:
:
getAllocation
(
size_t
size
size_t
*
offset
)
{
size_t
head
tail
;
SkAutoSpinlock
lock
(
fMutex
)
;
head
=
fHead
;
tail
=
fTail
;
size_t
modHead
=
head
&
(
fTotalSize
-
1
)
;
size_t
modTail
=
tail
&
(
fTotalSize
-
1
)
;
bool
full
=
(
head
!
=
tail
&
&
modHead
=
=
modTail
)
;
if
(
full
|
|
size
>
fTotalSize
/
2
)
{
return
nil
;
}
if
(
modHead
>
=
modTail
)
{
if
(
fTotalSize
-
modHead
<
size
)
{
if
(
modTail
<
size
)
{
return
nil
;
}
head
+
=
fTotalSize
-
modHead
;
modHead
=
0
;
}
}
else
if
(
modTail
-
modHead
<
size
)
{
return
nil
;
}
*
offset
=
modHead
;
fHead
=
GrSizeAlignUp
(
head
+
size
16
)
;
return
fBuffer
;
}
void
GrMtlResourceProvider
:
:
BufferSuballocator
:
:
addCompletionHandler
(
GrMtlCommandBuffer
*
cmdBuffer
)
{
this
-
>
ref
(
)
;
SkAutoSpinlock
lock
(
fMutex
)
;
size_t
newTail
=
fHead
;
cmdBuffer
-
>
addCompletedHandler
(
^
(
id
<
MTLCommandBuffer
>
commandBuffer
)
{
{
SkAutoSpinlock
lock
(
fMutex
)
;
fTail
=
newTail
;
}
this
-
>
unref
(
)
;
}
)
;
}
id
<
MTLBuffer
>
GrMtlResourceProvider
:
:
getDynamicBuffer
(
size_t
size
size_t
*
offset
)
{
id
<
MTLBuffer
>
buffer
=
fBufferSuballocator
-
>
getAllocation
(
size
offset
)
;
if
(
buffer
)
{
return
buffer
;
}
if
(
fBufferSuballocator
-
>
size
(
)
<
fBufferSuballocatorMaxSize
&
&
size
<
=
fBufferSuballocator
-
>
size
(
)
)
{
fBufferSuballocator
.
reset
(
new
BufferSuballocator
(
fGpu
-
>
device
(
)
2
*
fBufferSuballocator
-
>
size
(
)
)
)
;
id
<
MTLBuffer
>
buffer
=
fBufferSuballocator
-
>
getAllocation
(
size
offset
)
;
if
(
buffer
)
{
return
buffer
;
}
}
*
offset
=
0
;
return
alloc_dynamic_buffer
(
fGpu
-
>
device
(
)
size
)
;
}
void
GrMtlResourceProvider
:
:
addBufferCompletionHandler
(
GrMtlCommandBuffer
*
cmdBuffer
)
{
fBufferSuballocator
-
>
addCompletionHandler
(
cmdBuffer
)
;
}
