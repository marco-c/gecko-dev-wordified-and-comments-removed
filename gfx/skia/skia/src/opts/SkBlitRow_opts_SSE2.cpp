#
include
<
emmintrin
.
h
>
#
include
"
SkBitmapProcState_opts_SSE2
.
h
"
#
include
"
SkBlitRow_opts_SSE2
.
h
"
#
include
"
SkColorPriv
.
h
"
#
include
"
SkColor_opts_SSE2
.
h
"
#
include
"
SkDither
.
h
"
#
include
"
SkUtils
.
h
"
void
S32_Blend_BlitRow32_SSE2
(
SkPMColor
*
SK_RESTRICT
dst
const
SkPMColor
*
SK_RESTRICT
src
int
count
U8CPU
alpha
)
{
SkASSERT
(
alpha
<
=
255
)
;
if
(
count
<
=
0
)
{
return
;
}
uint32_t
src_scale
=
SkAlpha255To256
(
alpha
)
;
uint32_t
dst_scale
=
256
-
src_scale
;
if
(
count
>
=
4
)
{
SkASSERT
(
(
(
size_t
)
dst
&
0x03
)
=
=
0
)
;
while
(
(
(
size_t
)
dst
&
0x0F
)
!
=
0
)
{
*
dst
=
SkAlphaMulQ
(
*
src
src_scale
)
+
SkAlphaMulQ
(
*
dst
dst_scale
)
;
src
+
+
;
dst
+
+
;
count
-
-
;
}
const
__m128i
*
s
=
reinterpret_cast
<
const
__m128i
*
>
(
src
)
;
__m128i
*
d
=
reinterpret_cast
<
__m128i
*
>
(
dst
)
;
while
(
count
>
=
4
)
{
__m128i
src_pixel
=
_mm_loadu_si128
(
s
)
;
__m128i
dst_pixel
=
_mm_load_si128
(
d
)
;
src_pixel
=
SkAlphaMulQ_SSE2
(
src_pixel
src_scale
)
;
dst_pixel
=
SkAlphaMulQ_SSE2
(
dst_pixel
dst_scale
)
;
__m128i
result
=
_mm_add_epi8
(
src_pixel
dst_pixel
)
;
_mm_store_si128
(
d
result
)
;
s
+
+
;
d
+
+
;
count
-
=
4
;
}
src
=
reinterpret_cast
<
const
SkPMColor
*
>
(
s
)
;
dst
=
reinterpret_cast
<
SkPMColor
*
>
(
d
)
;
}
while
(
count
>
0
)
{
*
dst
=
SkAlphaMulQ
(
*
src
src_scale
)
+
SkAlphaMulQ
(
*
dst
dst_scale
)
;
src
+
+
;
dst
+
+
;
count
-
-
;
}
}
void
S32A_Opaque_BlitRow32_SSE2
(
SkPMColor
*
SK_RESTRICT
dst
const
SkPMColor
*
SK_RESTRICT
src
int
count
U8CPU
alpha
)
{
SkASSERT
(
alpha
=
=
255
)
;
if
(
count
<
=
0
)
{
return
;
}
#
ifdef
SK_USE_ACCURATE_BLENDING
if
(
count
>
=
4
)
{
SkASSERT
(
(
(
size_t
)
dst
&
0x03
)
=
=
0
)
;
while
(
(
(
size_t
)
dst
&
0x0F
)
!
=
0
)
{
*
dst
=
SkPMSrcOver
(
*
src
*
dst
)
;
src
+
+
;
dst
+
+
;
count
-
-
;
}
const
__m128i
*
s
=
reinterpret_cast
<
const
__m128i
*
>
(
src
)
;
__m128i
*
d
=
reinterpret_cast
<
__m128i
*
>
(
dst
)
;
__m128i
rb_mask
=
_mm_set1_epi32
(
0x00FF00FF
)
;
__m128i
c_128
=
_mm_set1_epi16
(
128
)
;
__m128i
c_255
=
_mm_set1_epi16
(
255
)
;
while
(
count
>
=
4
)
{
__m128i
src_pixel
=
_mm_loadu_si128
(
s
)
;
__m128i
dst_pixel
=
_mm_load_si128
(
d
)
;
__m128i
dst_rb
=
_mm_and_si128
(
rb_mask
dst_pixel
)
;
__m128i
dst_ag
=
_mm_srli_epi16
(
dst_pixel
8
)
;
__m128i
alpha
=
_mm_srli_epi32
(
src_pixel
24
)
;
alpha
=
_mm_or_si128
(
alpha
_mm_slli_epi32
(
alpha
16
)
)
;
alpha
=
_mm_sub_epi16
(
c_255
alpha
)
;
dst_rb
=
_mm_mullo_epi16
(
dst_rb
alpha
)
;
dst_ag
=
_mm_mullo_epi16
(
dst_ag
alpha
)
;
__m128i
dst_rb_low
=
_mm_srli_epi16
(
dst_rb
8
)
;
__m128i
dst_ag_low
=
_mm_srli_epi16
(
dst_ag
8
)
;
dst_rb
=
_mm_add_epi16
(
dst_rb
dst_rb_low
)
;
dst_rb
=
_mm_add_epi16
(
dst_rb
c_128
)
;
dst_rb
=
_mm_srli_epi16
(
dst_rb
8
)
;
dst_ag
=
_mm_add_epi16
(
dst_ag
dst_ag_low
)
;
dst_ag
=
_mm_add_epi16
(
dst_ag
c_128
)
;
dst_ag
=
_mm_andnot_si128
(
rb_mask
dst_ag
)
;
dst_pixel
=
_mm_or_si128
(
dst_rb
dst_ag
)
;
__m128i
result
=
_mm_add_epi8
(
src_pixel
dst_pixel
)
;
_mm_store_si128
(
d
result
)
;
s
+
+
;
d
+
+
;
count
-
=
4
;
}
src
=
reinterpret_cast
<
const
SkPMColor
*
>
(
s
)
;
dst
=
reinterpret_cast
<
SkPMColor
*
>
(
d
)
;
}
while
(
count
>
0
)
{
*
dst
=
SkPMSrcOver
(
*
src
*
dst
)
;
src
+
+
;
dst
+
+
;
count
-
-
;
}
#
else
int
count16
=
count
/
16
;
__m128i
*
dst4
=
(
__m128i
*
)
dst
;
const
__m128i
*
src4
=
(
const
__m128i
*
)
src
;
for
(
int
i
=
0
;
i
<
count16
*
4
;
i
+
=
4
)
{
__m128i
s0
=
_mm_loadu_si128
(
src4
+
i
+
0
)
s1
=
_mm_loadu_si128
(
src4
+
i
+
1
)
s2
=
_mm_loadu_si128
(
src4
+
i
+
2
)
s3
=
_mm_loadu_si128
(
src4
+
i
+
3
)
;
const
__m128i
alphaMask
=
_mm_set1_epi32
(
0xFF
<
<
SK_A32_SHIFT
)
;
const
__m128i
ORed
=
_mm_or_si128
(
s3
_mm_or_si128
(
s2
_mm_or_si128
(
s1
s0
)
)
)
;
__m128i
cmp
=
_mm_cmpeq_epi8
(
_mm_and_si128
(
ORed
alphaMask
)
_mm_setzero_si128
(
)
)
;
if
(
0xffff
=
=
_mm_movemask_epi8
(
cmp
)
)
{
continue
;
}
const
__m128i
ANDed
=
_mm_and_si128
(
s3
_mm_and_si128
(
s2
_mm_and_si128
(
s1
s0
)
)
)
;
cmp
=
_mm_cmpeq_epi8
(
_mm_and_si128
(
ANDed
alphaMask
)
alphaMask
)
;
if
(
0xffff
=
=
_mm_movemask_epi8
(
cmp
)
)
{
_mm_storeu_si128
(
dst4
+
i
+
0
s0
)
;
_mm_storeu_si128
(
dst4
+
i
+
1
s1
)
;
_mm_storeu_si128
(
dst4
+
i
+
2
s2
)
;
_mm_storeu_si128
(
dst4
+
i
+
3
s3
)
;
continue
;
}
_mm_storeu_si128
(
dst4
+
i
+
0
SkPMSrcOver_SSE2
(
s0
_mm_loadu_si128
(
dst4
+
i
+
0
)
)
)
;
_mm_storeu_si128
(
dst4
+
i
+
1
SkPMSrcOver_SSE2
(
s1
_mm_loadu_si128
(
dst4
+
i
+
1
)
)
)
;
_mm_storeu_si128
(
dst4
+
i
+
2
SkPMSrcOver_SSE2
(
s2
_mm_loadu_si128
(
dst4
+
i
+
2
)
)
)
;
_mm_storeu_si128
(
dst4
+
i
+
3
SkPMSrcOver_SSE2
(
s3
_mm_loadu_si128
(
dst4
+
i
+
3
)
)
)
;
}
SkASSERT
(
count
-
(
count16
*
16
)
<
=
15
)
;
for
(
int
i
=
count16
*
16
;
i
<
count
;
i
+
+
)
{
if
(
src
[
i
]
&
0xFF000000
)
{
dst
[
i
]
=
SkPMSrcOver
(
src
[
i
]
dst
[
i
]
)
;
}
}
#
endif
}
void
S32A_Blend_BlitRow32_SSE2
(
SkPMColor
*
SK_RESTRICT
dst
const
SkPMColor
*
SK_RESTRICT
src
int
count
U8CPU
alpha
)
{
SkASSERT
(
alpha
<
=
255
)
;
if
(
count
<
=
0
)
{
return
;
}
if
(
count
>
=
4
)
{
while
(
(
(
size_t
)
dst
&
0x0F
)
!
=
0
)
{
*
dst
=
SkBlendARGB32
(
*
src
*
dst
alpha
)
;
src
+
+
;
dst
+
+
;
count
-
-
;
}
const
__m128i
*
s
=
reinterpret_cast
<
const
__m128i
*
>
(
src
)
;
__m128i
*
d
=
reinterpret_cast
<
__m128i
*
>
(
dst
)
;
while
(
count
>
=
4
)
{
__m128i
src_pixel
=
_mm_loadu_si128
(
s
)
;
__m128i
dst_pixel
=
_mm_load_si128
(
d
)
;
__m128i
result
=
SkBlendARGB32_SSE2
(
src_pixel
dst_pixel
alpha
)
;
_mm_store_si128
(
d
result
)
;
s
+
+
;
d
+
+
;
count
-
=
4
;
}
src
=
reinterpret_cast
<
const
SkPMColor
*
>
(
s
)
;
dst
=
reinterpret_cast
<
SkPMColor
*
>
(
d
)
;
}
while
(
count
>
0
)
{
*
dst
=
SkBlendARGB32
(
*
src
*
dst
alpha
)
;
src
+
+
;
dst
+
+
;
count
-
-
;
}
}
void
Color32A_D565_SSE2
(
uint16_t
dst
[
]
SkPMColor
src
int
count
int
x
int
y
)
{
SkASSERT
(
count
>
0
)
;
uint32_t
src_expand
=
(
SkGetPackedG32
(
src
)
<
<
24
)
|
(
SkGetPackedR32
(
src
)
<
<
13
)
|
(
SkGetPackedB32
(
src
)
<
<
2
)
;
unsigned
scale
=
SkAlpha255To256
(
0xFF
-
SkGetPackedA32
(
src
)
)
>
>
3
;
if
(
count
>
=
(
int
)
(
8
+
(
(
(
16
-
(
size_t
)
dst
)
&
0x0F
)
>
>
1
)
)
)
{
__m128i
*
dst_wide
;
const
__m128i
src_R_wide
=
_mm_set1_epi16
(
SkGetPackedR32
(
src
)
<
<
2
)
;
const
__m128i
src_G_wide
=
_mm_set1_epi16
(
SkGetPackedG32
(
src
)
<
<
3
)
;
const
__m128i
src_B_wide
=
_mm_set1_epi16
(
SkGetPackedB32
(
src
)
<
<
2
)
;
const
__m128i
scale_wide
=
_mm_set1_epi16
(
scale
)
;
const
__m128i
mask_blue
=
_mm_set1_epi16
(
SK_B16_MASK
)
;
const
__m128i
mask_green
=
_mm_set1_epi16
(
SK_G16_MASK
<
<
SK_G16_SHIFT
)
;
while
(
(
(
(
(
size_t
)
dst
)
&
0x0F
)
!
=
0
)
&
&
(
count
>
0
)
)
{
*
dst
=
SkBlend32_RGB16
(
src_expand
*
dst
scale
)
;
dst
+
=
1
;
count
-
-
;
}
dst_wide
=
reinterpret_cast
<
__m128i
*
>
(
dst
)
;
do
{
__m128i
pixels
=
_mm_load_si128
(
dst_wide
)
;
__m128i
pixel_R
=
_mm_srli_epi16
(
pixels
SK_R16_SHIFT
)
;
__m128i
pixel_G
=
_mm_slli_epi16
(
pixels
SK_R16_BITS
)
;
pixel_G
=
_mm_srli_epi16
(
pixel_G
SK_R16_BITS
+
SK_B16_BITS
)
;
__m128i
pixel_B
=
_mm_and_si128
(
pixels
mask_blue
)
;
pixel_R
=
_mm_mullo_epi16
(
pixel_R
scale_wide
)
;
pixel_G
=
_mm_mullo_epi16
(
pixel_G
scale_wide
)
;
pixel_B
=
_mm_mullo_epi16
(
pixel_B
scale_wide
)
;
pixel_R
=
_mm_add_epi16
(
pixel_R
src_R_wide
)
;
pixel_R
=
_mm_srli_epi16
(
pixel_R
5
)
;
pixel_G
=
_mm_add_epi16
(
pixel_G
src_G_wide
)
;
pixel_B
=
_mm_add_epi16
(
pixel_B
src_B_wide
)
;
pixel_B
=
_mm_srli_epi16
(
pixel_B
5
)
;
pixel_R
=
_mm_slli_epi16
(
pixel_R
SK_R16_SHIFT
)
;
pixel_G
=
_mm_and_si128
(
pixel_G
mask_green
)
;
pixels
=
_mm_or_si128
(
pixel_R
pixel_G
)
;
pixels
=
_mm_or_si128
(
pixels
pixel_B
)
;
_mm_store_si128
(
dst_wide
pixels
)
;
count
-
=
8
;
dst_wide
+
+
;
}
while
(
count
>
=
8
)
;
dst
=
reinterpret_cast
<
uint16_t
*
>
(
dst_wide
)
;
}
while
(
count
>
0
)
{
*
dst
=
SkBlend32_RGB16
(
src_expand
*
dst
scale
)
;
dst
+
=
1
;
count
-
-
;
}
}
#
define
SK_R16x5_R32x5_SHIFT
(
SK_R32_SHIFT
-
SK_R16_SHIFT
-
SK_R16_BITS
+
5
)
#
define
SK_G16x5_G32x5_SHIFT
(
SK_G32_SHIFT
-
SK_G16_SHIFT
-
SK_G16_BITS
+
5
)
#
define
SK_B16x5_B32x5_SHIFT
(
SK_B32_SHIFT
-
SK_B16_SHIFT
-
SK_B16_BITS
+
5
)
#
if
SK_R16x5_R32x5_SHIFT
=
=
0
#
define
SkPackedR16x5ToUnmaskedR32x5_SSE2
(
x
)
(
x
)
#
elif
SK_R16x5_R32x5_SHIFT
>
0
#
define
SkPackedR16x5ToUnmaskedR32x5_SSE2
(
x
)
(
_mm_slli_epi32
(
x
SK_R16x5_R32x5_SHIFT
)
)
#
else
#
define
SkPackedR16x5ToUnmaskedR32x5_SSE2
(
x
)
(
_mm_srli_epi32
(
x
-
SK_R16x5_R32x5_SHIFT
)
)
#
endif
#
if
SK_G16x5_G32x5_SHIFT
=
=
0
#
define
SkPackedG16x5ToUnmaskedG32x5_SSE2
(
x
)
(
x
)
#
elif
SK_G16x5_G32x5_SHIFT
>
0
#
define
SkPackedG16x5ToUnmaskedG32x5_SSE2
(
x
)
(
_mm_slli_epi32
(
x
SK_G16x5_G32x5_SHIFT
)
)
#
else
#
define
SkPackedG16x5ToUnmaskedG32x5_SSE2
(
x
)
(
_mm_srli_epi32
(
x
-
SK_G16x5_G32x5_SHIFT
)
)
#
endif
#
if
SK_B16x5_B32x5_SHIFT
=
=
0
#
define
SkPackedB16x5ToUnmaskedB32x5_SSE2
(
x
)
(
x
)
#
elif
SK_B16x5_B32x5_SHIFT
>
0
#
define
SkPackedB16x5ToUnmaskedB32x5_SSE2
(
x
)
(
_mm_slli_epi32
(
x
SK_B16x5_B32x5_SHIFT
)
)
#
else
#
define
SkPackedB16x5ToUnmaskedB32x5_SSE2
(
x
)
(
_mm_srli_epi32
(
x
-
SK_B16x5_B32x5_SHIFT
)
)
#
endif
static
__m128i
SkBlendLCD16_SSE2
(
__m128i
&
src
__m128i
&
dst
__m128i
&
mask
__m128i
&
srcA
)
{
__m128i
r
=
_mm_and_si128
(
SkPackedR16x5ToUnmaskedR32x5_SSE2
(
mask
)
_mm_set1_epi32
(
0x1F
<
<
SK_R32_SHIFT
)
)
;
__m128i
g
=
_mm_and_si128
(
SkPackedG16x5ToUnmaskedG32x5_SSE2
(
mask
)
_mm_set1_epi32
(
0x1F
<
<
SK_G32_SHIFT
)
)
;
__m128i
b
=
_mm_and_si128
(
SkPackedB16x5ToUnmaskedB32x5_SSE2
(
mask
)
_mm_set1_epi32
(
0x1F
<
<
SK_B32_SHIFT
)
)
;
mask
=
_mm_or_si128
(
_mm_or_si128
(
r
g
)
b
)
;
__m128i
maskLo
maskHi
;
maskLo
=
_mm_unpacklo_epi8
(
mask
_mm_setzero_si128
(
)
)
;
maskHi
=
_mm_unpackhi_epi8
(
mask
_mm_setzero_si128
(
)
)
;
maskLo
=
_mm_add_epi16
(
maskLo
_mm_srli_epi16
(
maskLo
4
)
)
;
maskHi
=
_mm_add_epi16
(
maskHi
_mm_srli_epi16
(
maskHi
4
)
)
;
maskLo
=
_mm_mullo_epi16
(
maskLo
srcA
)
;
maskHi
=
_mm_mullo_epi16
(
maskHi
srcA
)
;
maskLo
=
_mm_srli_epi16
(
maskLo
8
)
;
maskHi
=
_mm_srli_epi16
(
maskHi
8
)
;
__m128i
dstLo
=
_mm_unpacklo_epi8
(
dst
_mm_setzero_si128
(
)
)
;
__m128i
dstHi
=
_mm_unpackhi_epi8
(
dst
_mm_setzero_si128
(
)
)
;
maskLo
=
_mm_mullo_epi16
(
maskLo
_mm_sub_epi16
(
src
dstLo
)
)
;
maskHi
=
_mm_mullo_epi16
(
maskHi
_mm_sub_epi16
(
src
dstHi
)
)
;
maskLo
=
_mm_srai_epi16
(
maskLo
5
)
;
maskHi
=
_mm_srai_epi16
(
maskHi
5
)
;
__m128i
resultLo
=
_mm_add_epi16
(
dstLo
maskLo
)
;
__m128i
resultHi
=
_mm_add_epi16
(
dstHi
maskHi
)
;
return
_mm_packus_epi16
(
resultLo
resultHi
)
;
}
static
__m128i
SkBlendLCD16Opaque_SSE2
(
__m128i
&
src
__m128i
&
dst
__m128i
&
mask
)
{
__m128i
r
=
_mm_and_si128
(
SkPackedR16x5ToUnmaskedR32x5_SSE2
(
mask
)
_mm_set1_epi32
(
0x1F
<
<
SK_R32_SHIFT
)
)
;
__m128i
g
=
_mm_and_si128
(
SkPackedG16x5ToUnmaskedG32x5_SSE2
(
mask
)
_mm_set1_epi32
(
0x1F
<
<
SK_G32_SHIFT
)
)
;
__m128i
b
=
_mm_and_si128
(
SkPackedB16x5ToUnmaskedB32x5_SSE2
(
mask
)
_mm_set1_epi32
(
0x1F
<
<
SK_B32_SHIFT
)
)
;
mask
=
_mm_or_si128
(
_mm_or_si128
(
r
g
)
b
)
;
__m128i
maskLo
maskHi
;
maskLo
=
_mm_unpacklo_epi8
(
mask
_mm_setzero_si128
(
)
)
;
maskHi
=
_mm_unpackhi_epi8
(
mask
_mm_setzero_si128
(
)
)
;
maskLo
=
_mm_add_epi16
(
maskLo
_mm_srli_epi16
(
maskLo
4
)
)
;
maskHi
=
_mm_add_epi16
(
maskHi
_mm_srli_epi16
(
maskHi
4
)
)
;
__m128i
dstLo
=
_mm_unpacklo_epi8
(
dst
_mm_setzero_si128
(
)
)
;
__m128i
dstHi
=
_mm_unpackhi_epi8
(
dst
_mm_setzero_si128
(
)
)
;
maskLo
=
_mm_mullo_epi16
(
maskLo
_mm_sub_epi16
(
src
dstLo
)
)
;
maskHi
=
_mm_mullo_epi16
(
maskHi
_mm_sub_epi16
(
src
dstHi
)
)
;
maskLo
=
_mm_srai_epi16
(
maskLo
5
)
;
maskHi
=
_mm_srai_epi16
(
maskHi
5
)
;
__m128i
resultLo
=
_mm_add_epi16
(
dstLo
maskLo
)
;
__m128i
resultHi
=
_mm_add_epi16
(
dstHi
maskHi
)
;
return
_mm_or_si128
(
_mm_packus_epi16
(
resultLo
resultHi
)
_mm_set1_epi32
(
SK_A32_MASK
<
<
SK_A32_SHIFT
)
)
;
}
void
SkBlitLCD16Row_SSE2
(
SkPMColor
dst
[
]
const
uint16_t
mask
[
]
SkColor
src
int
width
SkPMColor
)
{
if
(
width
<
=
0
)
{
return
;
}
int
srcA
=
SkColorGetA
(
src
)
;
int
srcR
=
SkColorGetR
(
src
)
;
int
srcG
=
SkColorGetG
(
src
)
;
int
srcB
=
SkColorGetB
(
src
)
;
srcA
=
SkAlpha255To256
(
srcA
)
;
if
(
width
>
=
4
)
{
SkASSERT
(
(
(
size_t
)
dst
&
0x03
)
=
=
0
)
;
while
(
(
(
size_t
)
dst
&
0x0F
)
!
=
0
)
{
*
dst
=
SkBlendLCD16
(
srcA
srcR
srcG
srcB
*
dst
*
mask
)
;
mask
+
+
;
dst
+
+
;
width
-
-
;
}
__m128i
*
d
=
reinterpret_cast
<
__m128i
*
>
(
dst
)
;
__m128i
src_sse
=
_mm_set1_epi32
(
SkPackARGB32
(
0xFF
srcR
srcG
srcB
)
)
;
src_sse
=
_mm_unpacklo_epi8
(
src_sse
_mm_setzero_si128
(
)
)
;
__m128i
srcA_sse
=
_mm_set1_epi16
(
srcA
)
;
while
(
width
>
=
4
)
{
__m128i
dst_sse
=
_mm_load_si128
(
d
)
;
__m128i
mask_sse
=
_mm_loadl_epi64
(
reinterpret_cast
<
const
__m128i
*
>
(
mask
)
)
;
int
pack_cmp
=
_mm_movemask_epi8
(
_mm_cmpeq_epi16
(
mask_sse
_mm_setzero_si128
(
)
)
)
;
if
(
pack_cmp
!
=
0xFFFF
)
{
mask_sse
=
_mm_unpacklo_epi16
(
mask_sse
_mm_setzero_si128
(
)
)
;
__m128i
result
=
SkBlendLCD16_SSE2
(
src_sse
dst_sse
mask_sse
srcA_sse
)
;
_mm_store_si128
(
d
result
)
;
}
d
+
+
;
mask
+
=
4
;
width
-
=
4
;
}
dst
=
reinterpret_cast
<
SkPMColor
*
>
(
d
)
;
}
while
(
width
>
0
)
{
*
dst
=
SkBlendLCD16
(
srcA
srcR
srcG
srcB
*
dst
*
mask
)
;
mask
+
+
;
dst
+
+
;
width
-
-
;
}
}
void
SkBlitLCD16OpaqueRow_SSE2
(
SkPMColor
dst
[
]
const
uint16_t
mask
[
]
SkColor
src
int
width
SkPMColor
opaqueDst
)
{
if
(
width
<
=
0
)
{
return
;
}
int
srcR
=
SkColorGetR
(
src
)
;
int
srcG
=
SkColorGetG
(
src
)
;
int
srcB
=
SkColorGetB
(
src
)
;
if
(
width
>
=
4
)
{
SkASSERT
(
(
(
size_t
)
dst
&
0x03
)
=
=
0
)
;
while
(
(
(
size_t
)
dst
&
0x0F
)
!
=
0
)
{
*
dst
=
SkBlendLCD16Opaque
(
srcR
srcG
srcB
*
dst
*
mask
opaqueDst
)
;
mask
+
+
;
dst
+
+
;
width
-
-
;
}
__m128i
*
d
=
reinterpret_cast
<
__m128i
*
>
(
dst
)
;
__m128i
src_sse
=
_mm_set1_epi32
(
SkPackARGB32
(
0xFF
srcR
srcG
srcB
)
)
;
src_sse
=
_mm_unpacklo_epi8
(
src_sse
_mm_setzero_si128
(
)
)
;
while
(
width
>
=
4
)
{
__m128i
dst_sse
=
_mm_load_si128
(
d
)
;
__m128i
mask_sse
=
_mm_loadl_epi64
(
reinterpret_cast
<
const
__m128i
*
>
(
mask
)
)
;
int
pack_cmp
=
_mm_movemask_epi8
(
_mm_cmpeq_epi16
(
mask_sse
_mm_setzero_si128
(
)
)
)
;
if
(
pack_cmp
!
=
0xFFFF
)
{
mask_sse
=
_mm_unpacklo_epi16
(
mask_sse
_mm_setzero_si128
(
)
)
;
__m128i
result
=
SkBlendLCD16Opaque_SSE2
(
src_sse
dst_sse
mask_sse
)
;
_mm_store_si128
(
d
result
)
;
}
d
+
+
;
mask
+
=
4
;
width
-
=
4
;
}
dst
=
reinterpret_cast
<
SkPMColor
*
>
(
d
)
;
}
while
(
width
>
0
)
{
*
dst
=
SkBlendLCD16Opaque
(
srcR
srcG
srcB
*
dst
*
mask
opaqueDst
)
;
mask
+
+
;
dst
+
+
;
width
-
-
;
}
}
void
S32_D565_Opaque_SSE2
(
uint16_t
*
SK_RESTRICT
dst
const
SkPMColor
*
SK_RESTRICT
src
int
count
U8CPU
alpha
int
int
)
{
SkASSERT
(
255
=
=
alpha
)
;
if
(
count
<
=
0
)
{
return
;
}
if
(
count
>
=
8
)
{
while
(
(
(
size_t
)
dst
&
0x0F
)
!
=
0
)
{
SkPMColor
c
=
*
src
+
+
;
SkPMColorAssert
(
c
)
;
*
dst
+
+
=
SkPixel32ToPixel16_ToU16
(
c
)
;
count
-
-
;
}
const
__m128i
*
s
=
reinterpret_cast
<
const
__m128i
*
>
(
src
)
;
__m128i
*
d
=
reinterpret_cast
<
__m128i
*
>
(
dst
)
;
while
(
count
>
=
8
)
{
__m128i
src_pixel1
=
_mm_loadu_si128
(
s
+
+
)
;
__m128i
src_pixel2
=
_mm_loadu_si128
(
s
+
+
)
;
__m128i
d_pixel
=
SkPixel32ToPixel16_ToU16_SSE2
(
src_pixel1
src_pixel2
)
;
_mm_store_si128
(
d
+
+
d_pixel
)
;
count
-
=
8
;
}
src
=
reinterpret_cast
<
const
SkPMColor
*
>
(
s
)
;
dst
=
reinterpret_cast
<
uint16_t
*
>
(
d
)
;
}
if
(
count
>
0
)
{
do
{
SkPMColor
c
=
*
src
+
+
;
SkPMColorAssert
(
c
)
;
*
dst
+
+
=
SkPixel32ToPixel16_ToU16
(
c
)
;
}
while
(
-
-
count
!
=
0
)
;
}
}
void
S32A_D565_Opaque_SSE2
(
uint16_t
*
SK_RESTRICT
dst
const
SkPMColor
*
SK_RESTRICT
src
int
count
U8CPU
alpha
int
int
)
{
SkASSERT
(
255
=
=
alpha
)
;
if
(
count
<
=
0
)
{
return
;
}
if
(
count
>
=
8
)
{
while
(
(
(
size_t
)
dst
&
0x0F
)
!
=
0
)
{
SkPMColor
c
=
*
src
+
+
;
if
(
c
)
{
*
dst
=
SkSrcOver32To16
(
c
*
dst
)
;
}
dst
+
=
1
;
count
-
-
;
}
const
__m128i
*
s
=
reinterpret_cast
<
const
__m128i
*
>
(
src
)
;
__m128i
*
d
=
reinterpret_cast
<
__m128i
*
>
(
dst
)
;
__m128i
var255
=
_mm_set1_epi16
(
255
)
;
__m128i
r16_mask
=
_mm_set1_epi16
(
SK_R16_MASK
)
;
__m128i
g16_mask
=
_mm_set1_epi16
(
SK_G16_MASK
)
;
__m128i
b16_mask
=
_mm_set1_epi16
(
SK_B16_MASK
)
;
while
(
count
>
=
8
)
{
__m128i
src_pixel1
=
_mm_loadu_si128
(
s
+
+
)
;
__m128i
src_pixel2
=
_mm_loadu_si128
(
s
+
+
)
;
int
src_cmp1
=
_mm_movemask_epi8
(
_mm_cmpeq_epi16
(
src_pixel1
_mm_setzero_si128
(
)
)
)
;
int
src_cmp2
=
_mm_movemask_epi8
(
_mm_cmpeq_epi16
(
src_pixel2
_mm_setzero_si128
(
)
)
)
;
if
(
src_cmp1
=
=
0xFFFF
&
&
src_cmp2
=
=
0xFFFF
)
{
d
+
+
;
count
-
=
8
;
continue
;
}
__m128i
dst_pixel
=
_mm_load_si128
(
d
)
;
__m128i
sa1
=
_mm_slli_epi32
(
src_pixel1
(
24
-
SK_A32_SHIFT
)
)
;
sa1
=
_mm_srli_epi32
(
sa1
24
)
;
__m128i
sa2
=
_mm_slli_epi32
(
src_pixel2
(
24
-
SK_A32_SHIFT
)
)
;
sa2
=
_mm_srli_epi32
(
sa2
24
)
;
__m128i
sa
=
_mm_packs_epi32
(
sa1
sa2
)
;
__m128i
sr1
=
_mm_slli_epi32
(
src_pixel1
(
24
-
SK_R32_SHIFT
)
)
;
sr1
=
_mm_srli_epi32
(
sr1
24
)
;
__m128i
sr2
=
_mm_slli_epi32
(
src_pixel2
(
24
-
SK_R32_SHIFT
)
)
;
sr2
=
_mm_srli_epi32
(
sr2
24
)
;
__m128i
sr
=
_mm_packs_epi32
(
sr1
sr2
)
;
__m128i
sg1
=
_mm_slli_epi32
(
src_pixel1
(
24
-
SK_G32_SHIFT
)
)
;
sg1
=
_mm_srli_epi32
(
sg1
24
)
;
__m128i
sg2
=
_mm_slli_epi32
(
src_pixel2
(
24
-
SK_G32_SHIFT
)
)
;
sg2
=
_mm_srli_epi32
(
sg2
24
)
;
__m128i
sg
=
_mm_packs_epi32
(
sg1
sg2
)
;
__m128i
sb1
=
_mm_slli_epi32
(
src_pixel1
(
24
-
SK_B32_SHIFT
)
)
;
sb1
=
_mm_srli_epi32
(
sb1
24
)
;
__m128i
sb2
=
_mm_slli_epi32
(
src_pixel2
(
24
-
SK_B32_SHIFT
)
)
;
sb2
=
_mm_srli_epi32
(
sb2
24
)
;
__m128i
sb
=
_mm_packs_epi32
(
sb1
sb2
)
;
__m128i
dr
=
_mm_srli_epi16
(
dst_pixel
SK_R16_SHIFT
)
;
dr
=
_mm_and_si128
(
dr
r16_mask
)
;
__m128i
dg
=
_mm_srli_epi16
(
dst_pixel
SK_G16_SHIFT
)
;
dg
=
_mm_and_si128
(
dg
g16_mask
)
;
__m128i
db
=
_mm_srli_epi16
(
dst_pixel
SK_B16_SHIFT
)
;
db
=
_mm_and_si128
(
db
b16_mask
)
;
__m128i
isa
=
_mm_sub_epi16
(
var255
sa
)
;
dr
=
_mm_add_epi16
(
sr
SkMul16ShiftRound_SSE2
(
dr
isa
SK_R16_BITS
)
)
;
dr
=
_mm_srli_epi16
(
dr
8
-
SK_R16_BITS
)
;
dg
=
_mm_add_epi16
(
sg
SkMul16ShiftRound_SSE2
(
dg
isa
SK_G16_BITS
)
)
;
dg
=
_mm_srli_epi16
(
dg
8
-
SK_G16_BITS
)
;
db
=
_mm_add_epi16
(
sb
SkMul16ShiftRound_SSE2
(
db
isa
SK_B16_BITS
)
)
;
db
=
_mm_srli_epi16
(
db
8
-
SK_B16_BITS
)
;
__m128i
d_pixel
=
SkPackRGB16_SSE2
(
dr
dg
db
)
;
_mm_store_si128
(
d
+
+
d_pixel
)
;
count
-
=
8
;
}
src
=
reinterpret_cast
<
const
SkPMColor
*
>
(
s
)
;
dst
=
reinterpret_cast
<
uint16_t
*
>
(
d
)
;
}
if
(
count
>
0
)
{
do
{
SkPMColor
c
=
*
src
+
+
;
SkPMColorAssert
(
c
)
;
if
(
c
)
{
*
dst
=
SkSrcOver32To16
(
c
*
dst
)
;
}
dst
+
=
1
;
}
while
(
-
-
count
!
=
0
)
;
}
}
void
S32_D565_Opaque_Dither_SSE2
(
uint16_t
*
SK_RESTRICT
dst
const
SkPMColor
*
SK_RESTRICT
src
int
count
U8CPU
alpha
int
x
int
y
)
{
SkASSERT
(
255
=
=
alpha
)
;
if
(
count
<
=
0
)
{
return
;
}
if
(
count
>
=
8
)
{
while
(
(
(
size_t
)
dst
&
0x0F
)
!
=
0
)
{
DITHER_565_SCAN
(
y
)
;
SkPMColor
c
=
*
src
+
+
;
SkPMColorAssert
(
c
)
;
unsigned
dither
=
DITHER_VALUE
(
x
)
;
*
dst
+
+
=
SkDitherRGB32To565
(
c
dither
)
;
DITHER_INC_X
(
x
)
;
count
-
-
;
}
unsigned
short
dither_value
[
8
]
;
__m128i
dither
;
#
ifdef
ENABLE_DITHER_MATRIX_4X4
const
uint8_t
*
dither_scan
=
gDitherMatrix_3Bit_4X4
[
(
y
)
&
3
]
;
dither_value
[
0
]
=
dither_value
[
4
]
=
dither_scan
[
(
x
)
&
3
]
;
dither_value
[
1
]
=
dither_value
[
5
]
=
dither_scan
[
(
x
+
1
)
&
3
]
;
dither_value
[
2
]
=
dither_value
[
6
]
=
dither_scan
[
(
x
+
2
)
&
3
]
;
dither_value
[
3
]
=
dither_value
[
7
]
=
dither_scan
[
(
x
+
3
)
&
3
]
;
#
else
const
uint16_t
dither_scan
=
gDitherMatrix_3Bit_16
[
(
y
)
&
3
]
;
dither_value
[
0
]
=
dither_value
[
4
]
=
(
dither_scan
>
>
(
(
(
x
)
&
3
)
<
<
2
)
)
&
0xF
;
dither_value
[
1
]
=
dither_value
[
5
]
=
(
dither_scan
>
>
(
(
(
x
+
1
)
&
3
)
<
<
2
)
)
&
0xF
;
dither_value
[
2
]
=
dither_value
[
6
]
=
(
dither_scan
>
>
(
(
(
x
+
2
)
&
3
)
<
<
2
)
)
&
0xF
;
dither_value
[
3
]
=
dither_value
[
7
]
=
(
dither_scan
>
>
(
(
(
x
+
3
)
&
3
)
<
<
2
)
)
&
0xF
;
#
endif
dither
=
_mm_loadu_si128
(
(
__m128i
*
)
dither_value
)
;
const
__m128i
*
s
=
reinterpret_cast
<
const
__m128i
*
>
(
src
)
;
__m128i
*
d
=
reinterpret_cast
<
__m128i
*
>
(
dst
)
;
while
(
count
>
=
8
)
{
__m128i
src_pixel1
=
_mm_loadu_si128
(
s
+
+
)
;
__m128i
src_pixel2
=
_mm_loadu_si128
(
s
+
+
)
;
__m128i
sr1
=
_mm_slli_epi32
(
src_pixel1
(
24
-
SK_R32_SHIFT
)
)
;
sr1
=
_mm_srli_epi32
(
sr1
24
)
;
__m128i
sr2
=
_mm_slli_epi32
(
src_pixel2
(
24
-
SK_R32_SHIFT
)
)
;
sr2
=
_mm_srli_epi32
(
sr2
24
)
;
__m128i
sr
=
_mm_packs_epi32
(
sr1
sr2
)
;
__m128i
sr_offset
=
_mm_srli_epi16
(
sr
5
)
;
sr
=
_mm_add_epi16
(
sr
dither
)
;
sr
=
_mm_sub_epi16
(
sr
sr_offset
)
;
sr
=
_mm_srli_epi16
(
sr
SK_R32_BITS
-
SK_R16_BITS
)
;
__m128i
sg1
=
_mm_slli_epi32
(
src_pixel1
(
24
-
SK_G32_SHIFT
)
)
;
sg1
=
_mm_srli_epi32
(
sg1
24
)
;
__m128i
sg2
=
_mm_slli_epi32
(
src_pixel2
(
24
-
SK_G32_SHIFT
)
)
;
sg2
=
_mm_srli_epi32
(
sg2
24
)
;
__m128i
sg
=
_mm_packs_epi32
(
sg1
sg2
)
;
__m128i
sg_offset
=
_mm_srli_epi16
(
sg
6
)
;
sg
=
_mm_add_epi16
(
sg
_mm_srli_epi16
(
dither
1
)
)
;
sg
=
_mm_sub_epi16
(
sg
sg_offset
)
;
sg
=
_mm_srli_epi16
(
sg
SK_G32_BITS
-
SK_G16_BITS
)
;
__m128i
sb1
=
_mm_slli_epi32
(
src_pixel1
(
24
-
SK_B32_SHIFT
)
)
;
sb1
=
_mm_srli_epi32
(
sb1
24
)
;
__m128i
sb2
=
_mm_slli_epi32
(
src_pixel2
(
24
-
SK_B32_SHIFT
)
)
;
sb2
=
_mm_srli_epi32
(
sb2
24
)
;
__m128i
sb
=
_mm_packs_epi32
(
sb1
sb2
)
;
__m128i
sb_offset
=
_mm_srli_epi16
(
sb
5
)
;
sb
=
_mm_add_epi16
(
sb
dither
)
;
sb
=
_mm_sub_epi16
(
sb
sb_offset
)
;
sb
=
_mm_srli_epi16
(
sb
SK_B32_BITS
-
SK_B16_BITS
)
;
__m128i
d_pixel
=
SkPackRGB16_SSE2
(
sr
sg
sb
)
;
_mm_store_si128
(
d
+
+
d_pixel
)
;
count
-
=
8
;
x
+
=
8
;
}
src
=
reinterpret_cast
<
const
SkPMColor
*
>
(
s
)
;
dst
=
reinterpret_cast
<
uint16_t
*
>
(
d
)
;
}
if
(
count
>
0
)
{
DITHER_565_SCAN
(
y
)
;
do
{
SkPMColor
c
=
*
src
+
+
;
SkPMColorAssert
(
c
)
;
unsigned
dither
=
DITHER_VALUE
(
x
)
;
*
dst
+
+
=
SkDitherRGB32To565
(
c
dither
)
;
DITHER_INC_X
(
x
)
;
}
while
(
-
-
count
!
=
0
)
;
}
}
void
S32A_D565_Opaque_Dither_SSE2
(
uint16_t
*
SK_RESTRICT
dst
const
SkPMColor
*
SK_RESTRICT
src
int
count
U8CPU
alpha
int
x
int
y
)
{
SkASSERT
(
255
=
=
alpha
)
;
if
(
count
<
=
0
)
{
return
;
}
if
(
count
>
=
8
)
{
while
(
(
(
size_t
)
dst
&
0x0F
)
!
=
0
)
{
DITHER_565_SCAN
(
y
)
;
SkPMColor
c
=
*
src
+
+
;
SkPMColorAssert
(
c
)
;
if
(
c
)
{
unsigned
a
=
SkGetPackedA32
(
c
)
;
int
d
=
SkAlphaMul
(
DITHER_VALUE
(
x
)
SkAlpha255To256
(
a
)
)
;
unsigned
sr
=
SkGetPackedR32
(
c
)
;
unsigned
sg
=
SkGetPackedG32
(
c
)
;
unsigned
sb
=
SkGetPackedB32
(
c
)
;
sr
=
SkDITHER_R32_FOR_565
(
sr
d
)
;
sg
=
SkDITHER_G32_FOR_565
(
sg
d
)
;
sb
=
SkDITHER_B32_FOR_565
(
sb
d
)
;
uint32_t
src_expanded
=
(
sg
<
<
24
)
|
(
sr
<
<
13
)
|
(
sb
<
<
2
)
;
uint32_t
dst_expanded
=
SkExpand_rgb_16
(
*
dst
)
;
dst_expanded
=
dst_expanded
*
(
SkAlpha255To256
(
255
-
a
)
>
>
3
)
;
*
dst
=
SkCompact_rgb_16
(
(
src_expanded
+
dst_expanded
)
>
>
5
)
;
}
dst
+
=
1
;
DITHER_INC_X
(
x
)
;
count
-
-
;
}
unsigned
short
dither_value
[
8
]
;
__m128i
dither
dither_cur
;
#
ifdef
ENABLE_DITHER_MATRIX_4X4
const
uint8_t
*
dither_scan
=
gDitherMatrix_3Bit_4X4
[
(
y
)
&
3
]
;
dither_value
[
0
]
=
dither_value
[
4
]
=
dither_scan
[
(
x
)
&
3
]
;
dither_value
[
1
]
=
dither_value
[
5
]
=
dither_scan
[
(
x
+
1
)
&
3
]
;
dither_value
[
2
]
=
dither_value
[
6
]
=
dither_scan
[
(
x
+
2
)
&
3
]
;
dither_value
[
3
]
=
dither_value
[
7
]
=
dither_scan
[
(
x
+
3
)
&
3
]
;
#
else
const
uint16_t
dither_scan
=
gDitherMatrix_3Bit_16
[
(
y
)
&
3
]
;
dither_value
[
0
]
=
dither_value
[
4
]
=
(
dither_scan
>
>
(
(
(
x
)
&
3
)
<
<
2
)
)
&
0xF
;
dither_value
[
1
]
=
dither_value
[
5
]
=
(
dither_scan
>
>
(
(
(
x
+
1
)
&
3
)
<
<
2
)
)
&
0xF
;
dither_value
[
2
]
=
dither_value
[
6
]
=
(
dither_scan
>
>
(
(
(
x
+
2
)
&
3
)
<
<
2
)
)
&
0xF
;
dither_value
[
3
]
=
dither_value
[
7
]
=
(
dither_scan
>
>
(
(
(
x
+
3
)
&
3
)
<
<
2
)
)
&
0xF
;
#
endif
dither
=
_mm_loadu_si128
(
(
__m128i
*
)
dither_value
)
;
const
__m128i
*
s
=
reinterpret_cast
<
const
__m128i
*
>
(
src
)
;
__m128i
*
d
=
reinterpret_cast
<
__m128i
*
>
(
dst
)
;
__m128i
var256
=
_mm_set1_epi16
(
256
)
;
__m128i
r16_mask
=
_mm_set1_epi16
(
SK_R16_MASK
)
;
__m128i
g16_mask
=
_mm_set1_epi16
(
SK_G16_MASK
)
;
__m128i
b16_mask
=
_mm_set1_epi16
(
SK_B16_MASK
)
;
while
(
count
>
=
8
)
{
__m128i
src_pixel1
=
_mm_loadu_si128
(
s
+
+
)
;
__m128i
src_pixel2
=
_mm_loadu_si128
(
s
+
+
)
;
__m128i
dst_pixel
=
_mm_load_si128
(
d
)
;
__m128i
sa1
=
_mm_slli_epi32
(
src_pixel1
(
24
-
SK_A32_SHIFT
)
)
;
sa1
=
_mm_srli_epi32
(
sa1
24
)
;
__m128i
sa2
=
_mm_slli_epi32
(
src_pixel2
(
24
-
SK_A32_SHIFT
)
)
;
sa2
=
_mm_srli_epi32
(
sa2
24
)
;
__m128i
sa
=
_mm_packs_epi32
(
sa1
sa2
)
;
dither_cur
=
_mm_mullo_epi16
(
dither
_mm_add_epi16
(
sa
_mm_set1_epi16
(
1
)
)
)
;
dither_cur
=
_mm_srli_epi16
(
dither_cur
8
)
;
__m128i
sr1
=
_mm_slli_epi32
(
src_pixel1
(
24
-
SK_R32_SHIFT
)
)
;
sr1
=
_mm_srli_epi32
(
sr1
24
)
;
__m128i
sr2
=
_mm_slli_epi32
(
src_pixel2
(
24
-
SK_R32_SHIFT
)
)
;
sr2
=
_mm_srli_epi32
(
sr2
24
)
;
__m128i
sr
=
_mm_packs_epi32
(
sr1
sr2
)
;
__m128i
sr_offset
=
_mm_srli_epi16
(
sr
5
)
;
sr
=
_mm_add_epi16
(
sr
dither_cur
)
;
sr
=
_mm_sub_epi16
(
sr
sr_offset
)
;
sr
=
_mm_slli_epi16
(
sr
2
)
;
__m128i
sg1
=
_mm_slli_epi32
(
src_pixel1
(
24
-
SK_G32_SHIFT
)
)
;
sg1
=
_mm_srli_epi32
(
sg1
24
)
;
__m128i
sg2
=
_mm_slli_epi32
(
src_pixel2
(
24
-
SK_G32_SHIFT
)
)
;
sg2
=
_mm_srli_epi32
(
sg2
24
)
;
__m128i
sg
=
_mm_packs_epi32
(
sg1
sg2
)
;
__m128i
sg_offset
=
_mm_srli_epi16
(
sg
6
)
;
sg
=
_mm_add_epi16
(
sg
_mm_srli_epi16
(
dither_cur
1
)
)
;
sg
=
_mm_sub_epi16
(
sg
sg_offset
)
;
sg
=
_mm_slli_epi16
(
sg
3
)
;
__m128i
sb1
=
_mm_slli_epi32
(
src_pixel1
(
24
-
SK_B32_SHIFT
)
)
;
sb1
=
_mm_srli_epi32
(
sb1
24
)
;
__m128i
sb2
=
_mm_slli_epi32
(
src_pixel2
(
24
-
SK_B32_SHIFT
)
)
;
sb2
=
_mm_srli_epi32
(
sb2
24
)
;
__m128i
sb
=
_mm_packs_epi32
(
sb1
sb2
)
;
__m128i
sb_offset
=
_mm_srli_epi16
(
sb
5
)
;
sb
=
_mm_add_epi16
(
sb
dither_cur
)
;
sb
=
_mm_sub_epi16
(
sb
sb_offset
)
;
sb
=
_mm_slli_epi16
(
sb
2
)
;
__m128i
dr
=
_mm_srli_epi16
(
dst_pixel
SK_R16_SHIFT
)
;
dr
=
_mm_and_si128
(
dr
r16_mask
)
;
__m128i
dg
=
_mm_srli_epi16
(
dst_pixel
SK_G16_SHIFT
)
;
dg
=
_mm_and_si128
(
dg
g16_mask
)
;
__m128i
db
=
_mm_srli_epi16
(
dst_pixel
SK_B16_SHIFT
)
;
db
=
_mm_and_si128
(
db
b16_mask
)
;
__m128i
isa
=
_mm_sub_epi16
(
var256
sa
)
;
isa
=
_mm_srli_epi16
(
isa
3
)
;
dr
=
_mm_mullo_epi16
(
dr
isa
)
;
dr
=
_mm_add_epi16
(
dr
sr
)
;
dr
=
_mm_srli_epi16
(
dr
5
)
;
dg
=
_mm_mullo_epi16
(
dg
isa
)
;
dg
=
_mm_add_epi16
(
dg
sg
)
;
dg
=
_mm_srli_epi16
(
dg
5
)
;
db
=
_mm_mullo_epi16
(
db
isa
)
;
db
=
_mm_add_epi16
(
db
sb
)
;
db
=
_mm_srli_epi16
(
db
5
)
;
__m128i
d_pixel
=
SkPackRGB16_SSE2
(
dr
dg
db
)
;
_mm_store_si128
(
d
+
+
d_pixel
)
;
count
-
=
8
;
x
+
=
8
;
}
src
=
reinterpret_cast
<
const
SkPMColor
*
>
(
s
)
;
dst
=
reinterpret_cast
<
uint16_t
*
>
(
d
)
;
}
if
(
count
>
0
)
{
DITHER_565_SCAN
(
y
)
;
do
{
SkPMColor
c
=
*
src
+
+
;
SkPMColorAssert
(
c
)
;
if
(
c
)
{
unsigned
a
=
SkGetPackedA32
(
c
)
;
int
d
=
SkAlphaMul
(
DITHER_VALUE
(
x
)
SkAlpha255To256
(
a
)
)
;
unsigned
sr
=
SkGetPackedR32
(
c
)
;
unsigned
sg
=
SkGetPackedG32
(
c
)
;
unsigned
sb
=
SkGetPackedB32
(
c
)
;
sr
=
SkDITHER_R32_FOR_565
(
sr
d
)
;
sg
=
SkDITHER_G32_FOR_565
(
sg
d
)
;
sb
=
SkDITHER_B32_FOR_565
(
sb
d
)
;
uint32_t
src_expanded
=
(
sg
<
<
24
)
|
(
sr
<
<
13
)
|
(
sb
<
<
2
)
;
uint32_t
dst_expanded
=
SkExpand_rgb_16
(
*
dst
)
;
dst_expanded
=
dst_expanded
*
(
SkAlpha255To256
(
255
-
a
)
>
>
3
)
;
*
dst
=
SkCompact_rgb_16
(
(
src_expanded
+
dst_expanded
)
>
>
5
)
;
}
dst
+
=
1
;
DITHER_INC_X
(
x
)
;
}
while
(
-
-
count
!
=
0
)
;
}
}
