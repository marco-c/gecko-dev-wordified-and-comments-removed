"
use
strict
"
;
const
global
=
this
;
this
.
EXPORTED_SYMBOLS
=
[
"
KintoHttpClient
"
]
;
(
function
(
f
)
{
if
(
typeof
exports
=
=
=
"
object
"
&
&
typeof
module
!
=
=
"
undefined
"
)
{
module
.
exports
=
f
(
)
}
else
if
(
typeof
define
=
=
=
"
function
"
&
&
define
.
amd
)
{
define
(
[
]
f
)
}
else
{
var
g
;
if
(
typeof
window
!
=
=
"
undefined
"
)
{
g
=
window
}
else
if
(
typeof
global
!
=
=
"
undefined
"
)
{
g
=
global
}
else
if
(
typeof
self
!
=
=
"
undefined
"
)
{
g
=
self
}
else
{
g
=
this
}
g
.
KintoHttpClient
=
f
(
)
}
}
)
(
function
(
)
{
var
define
module
exports
;
return
(
function
(
)
{
function
r
(
e
n
t
)
{
function
o
(
i
f
)
{
if
(
!
n
[
i
]
)
{
if
(
!
e
[
i
]
)
{
var
c
=
"
function
"
=
=
typeof
require
&
&
require
;
if
(
!
f
&
&
c
)
return
c
(
i
!
0
)
;
if
(
u
)
return
u
(
i
!
0
)
;
var
a
=
new
Error
(
"
Cannot
find
module
'
"
+
i
+
"
'
"
)
;
throw
a
.
code
=
"
MODULE_NOT_FOUND
"
a
}
var
p
=
n
[
i
]
=
{
exports
:
{
}
}
;
e
[
i
]
[
0
]
.
call
(
p
.
exports
function
(
r
)
{
var
n
=
e
[
i
]
[
1
]
[
r
]
;
return
o
(
n
|
|
r
)
}
p
p
.
exports
r
e
n
t
)
}
return
n
[
i
]
.
exports
}
for
(
var
u
=
"
function
"
=
=
typeof
require
&
&
require
i
=
0
;
i
<
t
.
length
;
i
+
+
)
o
(
t
[
i
]
)
;
return
o
}
return
r
}
)
(
)
(
{
1
:
[
function
(
require
module
exports
)
{
"
use
strict
"
;
Object
.
defineProperty
(
exports
"
__esModule
"
{
value
:
true
}
)
;
exports
.
default
=
void
0
;
var
_base
=
_interopRequireDefault
(
require
(
"
.
.
/
src
/
base
"
)
)
;
var
errors
=
_interopRequireWildcard
(
require
(
"
.
.
/
src
/
errors
"
)
)
;
function
_interopRequireWildcard
(
obj
)
{
if
(
obj
&
&
obj
.
__esModule
)
{
return
obj
;
}
else
{
var
newObj
=
{
}
;
if
(
obj
!
=
null
)
{
for
(
var
key
in
obj
)
{
if
(
Object
.
prototype
.
hasOwnProperty
.
call
(
obj
key
)
)
{
var
desc
=
Object
.
defineProperty
&
&
Object
.
getOwnPropertyDescriptor
?
Object
.
getOwnPropertyDescriptor
(
obj
key
)
:
{
}
;
if
(
desc
.
get
|
|
desc
.
set
)
{
Object
.
defineProperty
(
newObj
key
desc
)
;
}
else
{
newObj
[
key
]
=
obj
[
key
]
;
}
}
}
}
newObj
.
default
=
obj
;
return
newObj
;
}
}
function
_interopRequireDefault
(
obj
)
{
return
obj
&
&
obj
.
__esModule
?
obj
:
{
default
:
obj
}
;
}
ChromeUtils
.
import
(
"
resource
:
/
/
gre
/
modules
/
Timer
.
jsm
"
global
)
;
const
{
XPCOMUtils
}
=
ChromeUtils
.
import
(
"
resource
:
/
/
gre
/
modules
/
XPCOMUtils
.
jsm
"
)
;
XPCOMUtils
.
defineLazyGlobalGetters
(
global
[
"
fetch
"
]
)
;
const
{
EventEmitter
}
=
ChromeUtils
.
import
(
"
resource
:
/
/
gre
/
modules
/
EventEmitter
.
jsm
"
)
;
class
KintoHttpClient
extends
_base
.
default
{
constructor
(
remote
options
=
{
}
)
{
const
events
=
{
}
;
EventEmitter
.
decorate
(
events
)
;
super
(
remote
{
events
.
.
.
options
}
)
;
}
}
exports
.
default
=
KintoHttpClient
;
KintoHttpClient
.
errors
=
errors
;
if
(
typeof
module
=
=
=
"
object
"
)
{
module
.
exports
=
KintoHttpClient
;
}
}
{
"
.
.
/
src
/
base
"
:
7
"
.
.
/
src
/
errors
"
:
12
}
]
2
:
[
function
(
require
module
exports
)
{
var
v1
=
require
(
'
.
/
v1
'
)
;
var
v4
=
require
(
'
.
/
v4
'
)
;
var
uuid
=
v4
;
uuid
.
v1
=
v1
;
uuid
.
v4
=
v4
;
module
.
exports
=
uuid
;
}
{
"
.
/
v1
"
:
5
"
.
/
v4
"
:
6
}
]
3
:
[
function
(
require
module
exports
)
{
var
byteToHex
=
[
]
;
for
(
var
i
=
0
;
i
<
256
;
+
+
i
)
{
byteToHex
[
i
]
=
(
i
+
0x100
)
.
toString
(
16
)
.
substr
(
1
)
;
}
function
bytesToUuid
(
buf
offset
)
{
var
i
=
offset
|
|
0
;
var
bth
=
byteToHex
;
return
bth
[
buf
[
i
+
+
]
]
+
bth
[
buf
[
i
+
+
]
]
+
bth
[
buf
[
i
+
+
]
]
+
bth
[
buf
[
i
+
+
]
]
+
'
-
'
+
bth
[
buf
[
i
+
+
]
]
+
bth
[
buf
[
i
+
+
]
]
+
'
-
'
+
bth
[
buf
[
i
+
+
]
]
+
bth
[
buf
[
i
+
+
]
]
+
'
-
'
+
bth
[
buf
[
i
+
+
]
]
+
bth
[
buf
[
i
+
+
]
]
+
'
-
'
+
bth
[
buf
[
i
+
+
]
]
+
bth
[
buf
[
i
+
+
]
]
+
bth
[
buf
[
i
+
+
]
]
+
bth
[
buf
[
i
+
+
]
]
+
bth
[
buf
[
i
+
+
]
]
+
bth
[
buf
[
i
+
+
]
]
;
}
module
.
exports
=
bytesToUuid
;
}
{
}
]
4
:
[
function
(
require
module
exports
)
{
var
getRandomValues
=
(
typeof
(
crypto
)
!
=
'
undefined
'
&
&
crypto
.
getRandomValues
.
bind
(
crypto
)
)
|
|
(
typeof
(
msCrypto
)
!
=
'
undefined
'
&
&
msCrypto
.
getRandomValues
.
bind
(
msCrypto
)
)
;
if
(
getRandomValues
)
{
var
rnds8
=
new
Uint8Array
(
16
)
;
module
.
exports
=
function
whatwgRNG
(
)
{
getRandomValues
(
rnds8
)
;
return
rnds8
;
}
;
}
else
{
var
rnds
=
new
Array
(
16
)
;
module
.
exports
=
function
mathRNG
(
)
{
for
(
var
i
=
0
r
;
i
<
16
;
i
+
+
)
{
if
(
(
i
&
0x03
)
=
=
=
0
)
r
=
Math
.
random
(
)
*
0x100000000
;
rnds
[
i
]
=
r
>
>
>
(
(
i
&
0x03
)
<
<
3
)
&
0xff
;
}
return
rnds
;
}
;
}
}
{
}
]
5
:
[
function
(
require
module
exports
)
{
var
rng
=
require
(
'
.
/
lib
/
rng
'
)
;
var
bytesToUuid
=
require
(
'
.
/
lib
/
bytesToUuid
'
)
;
var
_nodeId
;
var
_clockseq
;
var
_lastMSecs
=
0
;
var
_lastNSecs
=
0
;
function
v1
(
options
buf
offset
)
{
var
i
=
buf
&
&
offset
|
|
0
;
var
b
=
buf
|
|
[
]
;
options
=
options
|
|
{
}
;
var
node
=
options
.
node
|
|
_nodeId
;
var
clockseq
=
options
.
clockseq
!
=
=
undefined
?
options
.
clockseq
:
_clockseq
;
if
(
node
=
=
null
|
|
clockseq
=
=
null
)
{
var
seedBytes
=
rng
(
)
;
if
(
node
=
=
null
)
{
node
=
_nodeId
=
[
seedBytes
[
0
]
|
0x01
seedBytes
[
1
]
seedBytes
[
2
]
seedBytes
[
3
]
seedBytes
[
4
]
seedBytes
[
5
]
]
;
}
if
(
clockseq
=
=
null
)
{
clockseq
=
_clockseq
=
(
seedBytes
[
6
]
<
<
8
|
seedBytes
[
7
]
)
&
0x3fff
;
}
}
var
msecs
=
options
.
msecs
!
=
=
undefined
?
options
.
msecs
:
new
Date
(
)
.
getTime
(
)
;
var
nsecs
=
options
.
nsecs
!
=
=
undefined
?
options
.
nsecs
:
_lastNSecs
+
1
;
var
dt
=
(
msecs
-
_lastMSecs
)
+
(
nsecs
-
_lastNSecs
)
/
10000
;
if
(
dt
<
0
&
&
options
.
clockseq
=
=
=
undefined
)
{
clockseq
=
clockseq
+
1
&
0x3fff
;
}
if
(
(
dt
<
0
|
|
msecs
>
_lastMSecs
)
&
&
options
.
nsecs
=
=
=
undefined
)
{
nsecs
=
0
;
}
if
(
nsecs
>
=
10000
)
{
throw
new
Error
(
'
uuid
.
v1
(
)
:
Can
\
'
t
create
more
than
10M
uuids
/
sec
'
)
;
}
_lastMSecs
=
msecs
;
_lastNSecs
=
nsecs
;
_clockseq
=
clockseq
;
msecs
+
=
12219292800000
;
var
tl
=
(
(
msecs
&
0xfffffff
)
*
10000
+
nsecs
)
%
0x100000000
;
b
[
i
+
+
]
=
tl
>
>
>
24
&
0xff
;
b
[
i
+
+
]
=
tl
>
>
>
16
&
0xff
;
b
[
i
+
+
]
=
tl
>
>
>
8
&
0xff
;
b
[
i
+
+
]
=
tl
&
0xff
;
var
tmh
=
(
msecs
/
0x100000000
*
10000
)
&
0xfffffff
;
b
[
i
+
+
]
=
tmh
>
>
>
8
&
0xff
;
b
[
i
+
+
]
=
tmh
&
0xff
;
b
[
i
+
+
]
=
tmh
>
>
>
24
&
0xf
|
0x10
;
b
[
i
+
+
]
=
tmh
>
>
>
16
&
0xff
;
b
[
i
+
+
]
=
clockseq
>
>
>
8
|
0x80
;
b
[
i
+
+
]
=
clockseq
&
0xff
;
for
(
var
n
=
0
;
n
<
6
;
+
+
n
)
{
b
[
i
+
n
]
=
node
[
n
]
;
}
return
buf
?
buf
:
bytesToUuid
(
b
)
;
}
module
.
exports
=
v1
;
}
{
"
.
/
lib
/
bytesToUuid
"
:
3
"
.
/
lib
/
rng
"
:
4
}
]
6
:
[
function
(
require
module
exports
)
{
var
rng
=
require
(
'
.
/
lib
/
rng
'
)
;
var
bytesToUuid
=
require
(
'
.
/
lib
/
bytesToUuid
'
)
;
function
v4
(
options
buf
offset
)
{
var
i
=
buf
&
&
offset
|
|
0
;
if
(
typeof
(
options
)
=
=
'
string
'
)
{
buf
=
options
=
=
=
'
binary
'
?
new
Array
(
16
)
:
null
;
options
=
null
;
}
options
=
options
|
|
{
}
;
var
rnds
=
options
.
random
|
|
(
options
.
rng
|
|
rng
)
(
)
;
rnds
[
6
]
=
(
rnds
[
6
]
&
0x0f
)
|
0x40
;
rnds
[
8
]
=
(
rnds
[
8
]
&
0x3f
)
|
0x80
;
if
(
buf
)
{
for
(
var
ii
=
0
;
ii
<
16
;
+
+
ii
)
{
buf
[
i
+
ii
]
=
rnds
[
ii
]
;
}
}
return
buf
|
|
bytesToUuid
(
rnds
)
;
}
module
.
exports
=
v4
;
}
{
"
.
/
lib
/
bytesToUuid
"
:
3
"
.
/
lib
/
rng
"
:
4
}
]
7
:
[
function
(
require
module
exports
)
{
"
use
strict
"
;
Object
.
defineProperty
(
exports
"
__esModule
"
{
value
:
true
}
)
;
exports
.
default
=
exports
.
SUPPORTED_PROTOCOL_VERSION
=
void
0
;
var
_utils
=
require
(
"
.
/
utils
"
)
;
var
_http
=
_interopRequireDefault
(
require
(
"
.
/
http
"
)
)
;
var
_endpoint
=
_interopRequireDefault
(
require
(
"
.
/
endpoint
"
)
)
;
var
requests
=
_interopRequireWildcard
(
require
(
"
.
/
requests
"
)
)
;
var
_batch
=
require
(
"
.
/
batch
"
)
;
var
_bucket
=
_interopRequireDefault
(
require
(
"
.
/
bucket
"
)
)
;
var
_dec
_dec2
_dec3
_dec4
_dec5
_dec6
_dec7
_class
;
function
_interopRequireWildcard
(
obj
)
{
if
(
obj
&
&
obj
.
__esModule
)
{
return
obj
;
}
else
{
var
newObj
=
{
}
;
if
(
obj
!
=
null
)
{
for
(
var
key
in
obj
)
{
if
(
Object
.
prototype
.
hasOwnProperty
.
call
(
obj
key
)
)
{
var
desc
=
Object
.
defineProperty
&
&
Object
.
getOwnPropertyDescriptor
?
Object
.
getOwnPropertyDescriptor
(
obj
key
)
:
{
}
;
if
(
desc
.
get
|
|
desc
.
set
)
{
Object
.
defineProperty
(
newObj
key
desc
)
;
}
else
{
newObj
[
key
]
=
obj
[
key
]
;
}
}
}
}
newObj
.
default
=
obj
;
return
newObj
;
}
}
function
_interopRequireDefault
(
obj
)
{
return
obj
&
&
obj
.
__esModule
?
obj
:
{
default
:
obj
}
;
}
function
_applyDecoratedDescriptor
(
target
property
decorators
descriptor
context
)
{
var
desc
=
{
}
;
Object
[
'
ke
'
+
'
ys
'
]
(
descriptor
)
.
forEach
(
function
(
key
)
{
desc
[
key
]
=
descriptor
[
key
]
;
}
)
;
desc
.
enumerable
=
!
!
desc
.
enumerable
;
desc
.
configurable
=
!
!
desc
.
configurable
;
if
(
'
value
'
in
desc
|
|
desc
.
initializer
)
{
desc
.
writable
=
true
;
}
desc
=
decorators
.
slice
(
)
.
reverse
(
)
.
reduce
(
function
(
desc
decorator
)
{
return
decorator
(
target
property
desc
)
|
|
desc
;
}
desc
)
;
if
(
context
&
&
desc
.
initializer
!
=
=
void
0
)
{
desc
.
value
=
desc
.
initializer
?
desc
.
initializer
.
call
(
context
)
:
void
0
;
desc
.
initializer
=
undefined
;
}
if
(
desc
.
initializer
=
=
=
void
0
)
{
Object
[
'
define
'
+
'
Property
'
]
(
target
property
desc
)
;
desc
=
null
;
}
return
desc
;
}
const
SUPPORTED_PROTOCOL_VERSION
=
"
v1
"
;
exports
.
SUPPORTED_PROTOCOL_VERSION
=
SUPPORTED_PROTOCOL_VERSION
;
let
KintoClientBase
=
(
_dec
=
(
0
_utils
.
nobatch
)
(
"
This
operation
is
not
supported
within
a
batch
operation
.
"
)
_dec2
=
(
0
_utils
.
nobatch
)
(
"
This
operation
is
not
supported
within
a
batch
operation
.
"
)
_dec3
=
(
0
_utils
.
nobatch
)
(
"
This
operation
is
not
supported
within
a
batch
operation
.
"
)
_dec4
=
(
0
_utils
.
nobatch
)
(
"
This
operation
is
not
supported
within
a
batch
operation
.
"
)
_dec5
=
(
0
_utils
.
nobatch
)
(
"
Can
'
t
use
batch
within
a
batch
!
"
)
_dec6
=
(
0
_utils
.
capable
)
(
[
"
permissions_endpoint
"
]
)
_dec7
=
(
0
_utils
.
support
)
(
"
1
.
4
"
"
2
.
0
"
)
(
_class
=
class
KintoClientBase
{
constructor
(
remote
options
=
{
}
)
{
if
(
typeof
remote
!
=
=
"
string
"
|
|
!
remote
.
length
)
{
throw
new
Error
(
"
Invalid
remote
URL
:
"
+
remote
)
;
}
if
(
remote
[
remote
.
length
-
1
]
=
=
=
"
/
"
)
{
remote
=
remote
.
slice
(
0
-
1
)
;
}
this
.
_backoffReleaseTime
=
null
;
this
.
_requests
=
[
]
;
this
.
_isBatch
=
!
!
options
.
batch
;
this
.
_retry
=
options
.
retry
|
|
0
;
this
.
_safe
=
!
!
options
.
safe
;
this
.
_headers
=
options
.
headers
|
|
{
}
;
this
.
remote
=
remote
;
this
.
serverInfo
=
null
;
this
.
events
=
options
.
events
;
const
{
requestMode
timeout
}
=
options
;
this
.
http
=
new
_http
.
default
(
this
.
events
{
requestMode
timeout
}
)
;
this
.
_registerHTTPEvents
(
)
;
}
get
remote
(
)
{
return
this
.
_remote
;
}
set
remote
(
url
)
{
let
version
;
try
{
version
=
url
.
match
(
/
\
/
(
v
\
d
+
)
\
/
?
/
)
[
1
]
;
}
catch
(
err
)
{
throw
new
Error
(
"
The
remote
URL
must
contain
the
version
:
"
+
url
)
;
}
if
(
version
!
=
=
SUPPORTED_PROTOCOL_VERSION
)
{
throw
new
Error
(
Unsupported
protocol
version
:
{
version
}
)
;
}
this
.
_remote
=
url
;
this
.
_version
=
version
;
}
get
version
(
)
{
return
this
.
_version
;
}
get
backoff
(
)
{
const
currentTime
=
new
Date
(
)
.
getTime
(
)
;
if
(
this
.
_backoffReleaseTime
&
&
currentTime
<
this
.
_backoffReleaseTime
)
{
return
this
.
_backoffReleaseTime
-
currentTime
;
}
return
0
;
}
_registerHTTPEvents
(
)
{
if
(
!
this
.
_isBatch
)
{
this
.
events
.
on
(
"
backoff
"
backoffMs
=
>
{
this
.
_backoffReleaseTime
=
backoffMs
;
}
)
;
}
}
bucket
(
name
options
=
{
}
)
{
return
new
_bucket
.
default
(
this
name
{
batch
:
this
.
_isBatch
headers
:
this
.
_getHeaders
(
options
)
safe
:
this
.
_getSafe
(
options
)
retry
:
this
.
_getRetry
(
options
)
}
)
;
}
setHeaders
(
headers
)
{
this
.
_headers
=
{
.
.
.
this
.
_headers
.
.
.
headers
}
;
this
.
serverInfo
=
null
;
}
_getHeaders
(
options
)
{
return
{
.
.
.
this
.
_headers
.
.
.
options
.
headers
}
;
}
_getSafe
(
options
)
{
return
{
safe
:
this
.
_safe
.
.
.
options
}
.
safe
;
}
_getRetry
(
options
)
{
return
{
retry
:
this
.
_retry
.
.
.
options
}
.
retry
;
}
async
_getHello
(
options
=
{
}
)
{
const
path
=
this
.
remote
+
(
0
_endpoint
.
default
)
(
"
root
"
)
;
const
{
json
}
=
await
this
.
http
.
request
(
path
{
headers
:
this
.
_getHeaders
(
options
)
}
{
retry
:
this
.
_getRetry
(
options
)
}
)
;
return
json
;
}
async
fetchServerInfo
(
options
=
{
}
)
{
if
(
this
.
serverInfo
)
{
return
this
.
serverInfo
;
}
this
.
serverInfo
=
await
this
.
_getHello
(
{
retry
:
this
.
_getRetry
(
options
)
}
)
;
return
this
.
serverInfo
;
}
async
fetchServerSettings
(
options
)
{
const
{
settings
}
=
await
this
.
fetchServerInfo
(
options
)
;
return
settings
;
}
async
fetchServerCapabilities
(
options
=
{
}
)
{
const
{
capabilities
}
=
await
this
.
fetchServerInfo
(
options
)
;
return
capabilities
;
}
async
fetchUser
(
options
=
{
}
)
{
const
{
user
}
=
await
this
.
_getHello
(
options
)
;
return
user
;
}
async
fetchHTTPApiVersion
(
options
=
{
}
)
{
const
{
http_api_version
}
=
await
this
.
fetchServerInfo
(
options
)
;
return
http_api_version
;
}
async
_batchRequests
(
requests
options
=
{
}
)
{
const
headers
=
this
.
_getHeaders
(
options
)
;
if
(
!
requests
.
length
)
{
return
[
]
;
}
const
serverSettings
=
await
this
.
fetchServerSettings
(
{
retry
:
this
.
_getRetry
(
options
)
}
)
;
const
maxRequests
=
serverSettings
[
"
batch_max_requests
"
]
;
if
(
maxRequests
&
&
requests
.
length
>
maxRequests
)
{
const
chunks
=
(
0
_utils
.
partition
)
(
requests
maxRequests
)
;
return
(
0
_utils
.
pMap
)
(
chunks
chunk
=
>
this
.
_batchRequests
(
chunk
options
)
)
;
}
const
{
responses
}
=
await
this
.
execute
(
{
headers
path
:
(
0
_endpoint
.
default
)
(
"
batch
"
)
method
:
"
POST
"
body
:
{
defaults
:
{
headers
}
requests
}
}
{
retry
:
this
.
_getRetry
(
options
)
}
)
;
return
responses
;
}
async
batch
(
fn
options
=
{
}
)
{
const
rootBatch
=
new
KintoClientBase
(
this
.
remote
{
events
:
this
.
events
batch
:
true
safe
:
this
.
_getSafe
(
options
)
retry
:
this
.
_getRetry
(
options
)
}
)
;
let
bucketBatch
collBatch
;
if
(
options
.
bucket
)
{
bucketBatch
=
rootBatch
.
bucket
(
options
.
bucket
)
;
if
(
options
.
collection
)
{
collBatch
=
bucketBatch
.
collection
(
options
.
collection
)
;
}
}
const
batchClient
=
collBatch
|
|
bucketBatch
|
|
rootBatch
;
fn
(
batchClient
)
;
const
responses
=
await
this
.
_batchRequests
(
rootBatch
.
_requests
options
)
;
if
(
options
.
aggregate
)
{
return
(
0
_batch
.
aggregate
)
(
responses
rootBatch
.
_requests
)
;
}
else
{
return
responses
;
}
}
async
execute
(
request
options
=
{
}
)
{
const
{
raw
=
false
stringify
=
true
}
=
options
;
if
(
this
.
_isBatch
)
{
this
.
_requests
.
push
(
request
)
;
const
msg
=
"
This
result
is
generated
from
within
a
batch
"
+
"
operation
and
should
not
be
consumed
.
"
;
return
raw
?
{
json
:
msg
headers
:
{
get
(
)
{
}
}
}
:
msg
;
}
const
result
=
await
this
.
http
.
request
(
this
.
remote
+
request
.
path
(
0
_utils
.
cleanUndefinedProperties
)
(
{
method
:
request
.
method
headers
:
request
.
headers
body
:
stringify
?
JSON
.
stringify
(
request
.
body
)
:
request
.
body
}
)
{
retry
:
this
.
_getRetry
(
options
)
}
)
;
return
raw
?
result
:
result
.
json
;
}
async
paginatedList
(
path
params
options
=
{
}
)
{
const
{
sort
filters
limit
pages
since
}
=
{
sort
:
"
-
last_modified
"
.
.
.
params
}
;
if
(
since
&
&
typeof
since
!
=
=
"
string
"
)
{
throw
new
Error
(
Invalid
value
for
since
(
{
since
}
)
should
be
ETag
value
.
)
;
}
const
querystring
=
(
0
_utils
.
qsify
)
(
{
.
.
.
filters
_sort
:
sort
_limit
:
limit
_since
:
since
}
)
;
let
results
=
[
]
current
=
0
;
const
next
=
async
function
(
nextPage
)
{
if
(
!
nextPage
)
{
throw
new
Error
(
"
Pagination
exhausted
.
"
)
;
}
return
processNextPage
(
nextPage
)
;
}
;
const
processNextPage
=
async
nextPage
=
>
{
const
{
headers
}
=
options
;
return
handleResponse
(
(
await
this
.
http
.
request
(
nextPage
{
headers
}
)
)
)
;
}
;
const
pageResults
=
(
results
nextPage
etag
totalRecords
)
=
>
{
return
{
last_modified
:
etag
?
etag
.
replace
(
/
"
/
g
"
"
)
:
etag
data
:
results
next
:
next
.
bind
(
null
nextPage
)
hasNextPage
:
!
!
nextPage
totalRecords
}
;
}
;
const
handleResponse
=
async
function
(
{
headers
json
}
)
{
const
nextPage
=
headers
.
get
(
"
Next
-
Page
"
)
;
const
etag
=
headers
.
get
(
"
ETag
"
)
;
const
totalRecords
=
parseInt
(
headers
.
get
(
"
Total
-
Records
"
)
10
)
;
if
(
!
pages
)
{
return
pageResults
(
json
.
data
nextPage
etag
totalRecords
)
;
}
results
=
results
.
concat
(
json
.
data
)
;
current
+
=
1
;
if
(
current
>
=
pages
|
|
!
nextPage
)
{
return
pageResults
(
results
nextPage
etag
totalRecords
)
;
}
return
processNextPage
(
nextPage
)
;
}
;
return
handleResponse
(
(
await
this
.
execute
(
{
headers
:
options
.
headers
path
:
path
+
"
?
"
+
querystring
}
{
raw
:
true
retry
:
options
.
retry
|
|
0
}
)
)
)
;
}
async
listPermissions
(
options
=
{
}
)
{
const
path
=
(
0
_endpoint
.
default
)
(
"
permissions
"
)
;
const
paginationOptions
=
{
sort
:
"
id
"
.
.
.
options
}
;
return
this
.
paginatedList
(
path
paginationOptions
{
headers
:
this
.
_getHeaders
(
options
)
retry
:
this
.
_getRetry
(
options
)
}
)
;
}
async
listBuckets
(
options
=
{
}
)
{
const
path
=
(
0
_endpoint
.
default
)
(
"
bucket
"
)
;
return
this
.
paginatedList
(
path
options
{
headers
:
this
.
_getHeaders
(
options
)
retry
:
this
.
_getRetry
(
options
)
}
)
;
}
async
createBucket
(
id
options
=
{
}
)
{
const
{
data
=
{
}
permissions
}
=
options
;
if
(
id
!
=
null
)
{
data
.
id
=
id
;
}
const
path
=
data
.
id
?
(
0
_endpoint
.
default
)
(
"
bucket
"
data
.
id
)
:
(
0
_endpoint
.
default
)
(
"
bucket
"
)
;
return
this
.
execute
(
requests
.
createRequest
(
path
{
data
permissions
}
{
headers
:
this
.
_getHeaders
(
options
)
safe
:
this
.
_getSafe
(
options
)
}
)
{
retry
:
this
.
_getRetry
(
options
)
}
)
;
}
async
deleteBucket
(
bucket
options
=
{
}
)
{
const
bucketObj
=
(
0
_utils
.
toDataBody
)
(
bucket
)
;
if
(
!
bucketObj
.
id
)
{
throw
new
Error
(
"
A
bucket
id
is
required
.
"
)
;
}
const
path
=
(
0
_endpoint
.
default
)
(
"
bucket
"
bucketObj
.
id
)
;
const
{
last_modified
}
=
{
.
.
.
bucketObj
.
.
.
options
}
;
return
this
.
execute
(
requests
.
deleteRequest
(
path
{
last_modified
headers
:
this
.
_getHeaders
(
options
)
safe
:
this
.
_getSafe
(
options
)
}
)
{
retry
:
this
.
_getRetry
(
options
)
}
)
;
}
async
deleteBuckets
(
options
=
{
}
)
{
const
path
=
(
0
_endpoint
.
default
)
(
"
bucket
"
)
;
return
this
.
execute
(
requests
.
deleteRequest
(
path
{
last_modified
:
options
.
last_modified
headers
:
this
.
_getHeaders
(
options
)
safe
:
this
.
_getSafe
(
options
)
}
)
{
retry
:
this
.
_getRetry
(
options
)
}
)
;
}
}
(
_applyDecoratedDescriptor
(
_class
.
prototype
"
fetchServerSettings
"
[
_dec
]
Object
.
getOwnPropertyDescriptor
(
_class
.
prototype
"
fetchServerSettings
"
)
_class
.
prototype
)
_applyDecoratedDescriptor
(
_class
.
prototype
"
fetchServerCapabilities
"
[
_dec2
]
Object
.
getOwnPropertyDescriptor
(
_class
.
prototype
"
fetchServerCapabilities
"
)
_class
.
prototype
)
_applyDecoratedDescriptor
(
_class
.
prototype
"
fetchUser
"
[
_dec3
]
Object
.
getOwnPropertyDescriptor
(
_class
.
prototype
"
fetchUser
"
)
_class
.
prototype
)
_applyDecoratedDescriptor
(
_class
.
prototype
"
fetchHTTPApiVersion
"
[
_dec4
]
Object
.
getOwnPropertyDescriptor
(
_class
.
prototype
"
fetchHTTPApiVersion
"
)
_class
.
prototype
)
_applyDecoratedDescriptor
(
_class
.
prototype
"
batch
"
[
_dec5
]
Object
.
getOwnPropertyDescriptor
(
_class
.
prototype
"
batch
"
)
_class
.
prototype
)
_applyDecoratedDescriptor
(
_class
.
prototype
"
listPermissions
"
[
_dec6
]
Object
.
getOwnPropertyDescriptor
(
_class
.
prototype
"
listPermissions
"
)
_class
.
prototype
)
_applyDecoratedDescriptor
(
_class
.
prototype
"
deleteBuckets
"
[
_dec7
]
Object
.
getOwnPropertyDescriptor
(
_class
.
prototype
"
deleteBuckets
"
)
_class
.
prototype
)
)
_class
)
)
;
exports
.
default
=
KintoClientBase
;
}
{
"
.
/
batch
"
:
8
"
.
/
bucket
"
:
9
"
.
/
endpoint
"
:
11
"
.
/
http
"
:
13
"
.
/
requests
"
:
14
"
.
/
utils
"
:
15
}
]
8
:
[
function
(
require
module
exports
)
{
"
use
strict
"
;
Object
.
defineProperty
(
exports
"
__esModule
"
{
value
:
true
}
)
;
exports
.
aggregate
=
aggregate
;
function
aggregate
(
responses
=
[
]
requests
=
[
]
)
{
if
(
responses
.
length
!
=
=
requests
.
length
)
{
throw
new
Error
(
"
Responses
length
should
match
requests
one
.
"
)
;
}
const
results
=
{
errors
:
[
]
published
:
[
]
conflicts
:
[
]
skipped
:
[
]
}
;
return
responses
.
reduce
(
(
acc
response
index
)
=
>
{
const
{
status
}
=
response
;
const
request
=
requests
[
index
]
;
if
(
status
>
=
200
&
&
status
<
400
)
{
acc
.
published
.
push
(
response
.
body
)
;
}
else
if
(
status
=
=
=
404
)
{
const
regex
=
/
(
buckets
|
groups
|
collections
|
records
)
\
/
(
[
^
/
]
+
)
/
;
const
extracts
=
request
.
path
.
match
(
regex
)
;
const
id
=
extracts
.
length
=
=
=
3
?
extracts
[
2
]
:
undefined
;
acc
.
skipped
.
push
(
{
id
path
:
request
.
path
error
:
response
.
body
}
)
;
}
else
if
(
status
=
=
=
412
)
{
acc
.
conflicts
.
push
(
{
type
:
"
outgoing
"
local
:
request
.
body
remote
:
response
.
body
.
details
&
&
response
.
body
.
details
.
existing
|
|
null
}
)
;
}
else
{
acc
.
errors
.
push
(
{
path
:
request
.
path
sent
:
request
error
:
response
.
body
}
)
;
}
return
acc
;
}
results
)
;
}
}
{
}
]
9
:
[
function
(
require
module
exports
)
{
"
use
strict
"
;
Object
.
defineProperty
(
exports
"
__esModule
"
{
value
:
true
}
)
;
exports
.
default
=
void
0
;
var
_utils
=
require
(
"
.
/
utils
"
)
;
var
_collection
=
_interopRequireDefault
(
require
(
"
.
/
collection
"
)
)
;
var
requests
=
_interopRequireWildcard
(
require
(
"
.
/
requests
"
)
)
;
var
_endpoint
=
_interopRequireDefault
(
require
(
"
.
/
endpoint
"
)
)
;
var
_dec
_class
;
function
_interopRequireWildcard
(
obj
)
{
if
(
obj
&
&
obj
.
__esModule
)
{
return
obj
;
}
else
{
var
newObj
=
{
}
;
if
(
obj
!
=
null
)
{
for
(
var
key
in
obj
)
{
if
(
Object
.
prototype
.
hasOwnProperty
.
call
(
obj
key
)
)
{
var
desc
=
Object
.
defineProperty
&
&
Object
.
getOwnPropertyDescriptor
?
Object
.
getOwnPropertyDescriptor
(
obj
key
)
:
{
}
;
if
(
desc
.
get
|
|
desc
.
set
)
{
Object
.
defineProperty
(
newObj
key
desc
)
;
}
else
{
newObj
[
key
]
=
obj
[
key
]
;
}
}
}
}
newObj
.
default
=
obj
;
return
newObj
;
}
}
function
_interopRequireDefault
(
obj
)
{
return
obj
&
&
obj
.
__esModule
?
obj
:
{
default
:
obj
}
;
}
function
_applyDecoratedDescriptor
(
target
property
decorators
descriptor
context
)
{
var
desc
=
{
}
;
Object
[
'
ke
'
+
'
ys
'
]
(
descriptor
)
.
forEach
(
function
(
key
)
{
desc
[
key
]
=
descriptor
[
key
]
;
}
)
;
desc
.
enumerable
=
!
!
desc
.
enumerable
;
desc
.
configurable
=
!
!
desc
.
configurable
;
if
(
'
value
'
in
desc
|
|
desc
.
initializer
)
{
desc
.
writable
=
true
;
}
desc
=
decorators
.
slice
(
)
.
reverse
(
)
.
reduce
(
function
(
desc
decorator
)
{
return
decorator
(
target
property
desc
)
|
|
desc
;
}
desc
)
;
if
(
context
&
&
desc
.
initializer
!
=
=
void
0
)
{
desc
.
value
=
desc
.
initializer
?
desc
.
initializer
.
call
(
context
)
:
void
0
;
desc
.
initializer
=
undefined
;
}
if
(
desc
.
initializer
=
=
=
void
0
)
{
Object
[
'
define
'
+
'
Property
'
]
(
target
property
desc
)
;
desc
=
null
;
}
return
desc
;
}
let
Bucket
=
(
_dec
=
(
0
_utils
.
capable
)
(
[
"
history
"
]
)
(
_class
=
class
Bucket
{
constructor
(
client
name
options
=
{
}
)
{
this
.
client
=
client
;
this
.
name
=
name
;
this
.
_isBatch
=
!
!
options
.
batch
;
this
.
_headers
=
options
.
headers
|
|
{
}
;
this
.
_retry
=
options
.
retry
|
|
0
;
this
.
_safe
=
!
!
options
.
safe
;
}
_getHeaders
(
options
)
{
return
{
.
.
.
this
.
_headers
.
.
.
options
.
headers
}
;
}
_getSafe
(
options
)
{
return
{
safe
:
this
.
_safe
.
.
.
options
}
.
safe
;
}
_getRetry
(
options
)
{
return
{
retry
:
this
.
_retry
.
.
.
options
}
.
retry
;
}
collection
(
name
options
=
{
}
)
{
return
new
_collection
.
default
(
this
.
client
this
name
{
batch
:
this
.
_isBatch
headers
:
this
.
_getHeaders
(
options
)
retry
:
this
.
_getRetry
(
options
)
safe
:
this
.
_getSafe
(
options
)
}
)
;
}
async
getData
(
options
=
{
}
)
{
const
request
=
{
headers
:
this
.
_getHeaders
(
options
)
path
:
(
0
_endpoint
.
default
)
(
"
bucket
"
this
.
name
)
}
;
const
{
data
}
=
await
this
.
client
.
execute
(
request
{
retry
:
this
.
_getRetry
(
options
)
}
)
;
return
data
;
}
async
setData
(
data
options
=
{
}
)
{
if
(
!
(
0
_utils
.
isObject
)
(
data
)
)
{
throw
new
Error
(
"
A
bucket
object
is
required
.
"
)
;
}
const
bucket
=
{
.
.
.
data
id
:
this
.
name
}
;
const
bucketId
=
bucket
.
id
;
if
(
bucket
.
id
=
=
=
"
default
"
)
{
delete
bucket
.
id
;
}
const
path
=
(
0
_endpoint
.
default
)
(
"
bucket
"
bucketId
)
;
const
{
patch
permissions
}
=
options
;
const
{
last_modified
}
=
{
.
.
.
data
.
.
.
options
}
;
const
request
=
requests
.
updateRequest
(
path
{
data
:
bucket
permissions
}
{
last_modified
patch
headers
:
this
.
_getHeaders
(
options
)
safe
:
this
.
_getSafe
(
options
)
}
)
;
return
this
.
client
.
execute
(
request
{
retry
:
this
.
_getRetry
(
options
)
}
)
;
}
async
listHistory
(
options
=
{
}
)
{
const
path
=
(
0
_endpoint
.
default
)
(
"
history
"
this
.
name
)
;
return
this
.
client
.
paginatedList
(
path
options
{
headers
:
this
.
_getHeaders
(
options
)
retry
:
this
.
_getRetry
(
options
)
}
)
;
}
async
listCollections
(
options
=
{
}
)
{
const
path
=
(
0
_endpoint
.
default
)
(
"
collection
"
this
.
name
)
;
return
this
.
client
.
paginatedList
(
path
options
{
headers
:
this
.
_getHeaders
(
options
)
retry
:
this
.
_getRetry
(
options
)
}
)
;
}
async
createCollection
(
id
options
=
{
}
)
{
const
{
permissions
data
=
{
}
}
=
options
;
data
.
id
=
id
;
const
path
=
(
0
_endpoint
.
default
)
(
"
collection
"
this
.
name
id
)
;
const
request
=
requests
.
createRequest
(
path
{
data
permissions
}
{
headers
:
this
.
_getHeaders
(
options
)
safe
:
this
.
_getSafe
(
options
)
}
)
;
return
this
.
client
.
execute
(
request
{
retry
:
this
.
_getRetry
(
options
)
}
)
;
}
async
deleteCollection
(
collection
options
=
{
}
)
{
const
collectionObj
=
(
0
_utils
.
toDataBody
)
(
collection
)
;
if
(
!
collectionObj
.
id
)
{
throw
new
Error
(
"
A
collection
id
is
required
.
"
)
;
}
const
{
id
}
=
collectionObj
;
const
{
last_modified
}
=
{
.
.
.
collectionObj
.
.
.
options
}
;
const
path
=
(
0
_endpoint
.
default
)
(
"
collection
"
this
.
name
id
)
;
const
request
=
requests
.
deleteRequest
(
path
{
last_modified
headers
:
this
.
_getHeaders
(
options
)
safe
:
this
.
_getSafe
(
options
)
}
)
;
return
this
.
client
.
execute
(
request
{
retry
:
this
.
_getRetry
(
options
)
}
)
;
}
async
listGroups
(
options
=
{
}
)
{
const
path
=
(
0
_endpoint
.
default
)
(
"
group
"
this
.
name
)
;
return
this
.
client
.
paginatedList
(
path
options
{
headers
:
this
.
_getHeaders
(
options
)
retry
:
this
.
_getRetry
(
options
)
}
)
;
}
async
getGroup
(
id
options
=
{
}
)
{
const
request
=
{
headers
:
this
.
_getHeaders
(
options
)
path
:
(
0
_endpoint
.
default
)
(
"
group
"
this
.
name
id
)
}
;
return
this
.
client
.
execute
(
request
{
retry
:
this
.
_getRetry
(
options
)
}
)
;
}
async
createGroup
(
id
members
=
[
]
options
=
{
}
)
{
const
data
=
{
.
.
.
options
.
data
id
members
}
;
const
path
=
(
0
_endpoint
.
default
)
(
"
group
"
this
.
name
id
)
;
const
{
permissions
}
=
options
;
const
request
=
requests
.
createRequest
(
path
{
data
permissions
}
{
headers
:
this
.
_getHeaders
(
options
)
safe
:
this
.
_getSafe
(
options
)
}
)
;
return
this
.
client
.
execute
(
request
{
retry
:
this
.
_getRetry
(
options
)
}
)
;
}
async
updateGroup
(
group
options
=
{
}
)
{
if
(
!
(
0
_utils
.
isObject
)
(
group
)
)
{
throw
new
Error
(
"
A
group
object
is
required
.
"
)
;
}
if
(
!
group
.
id
)
{
throw
new
Error
(
"
A
group
id
is
required
.
"
)
;
}
const
data
=
{
.
.
.
options
.
data
.
.
.
group
}
;
const
path
=
(
0
_endpoint
.
default
)
(
"
group
"
this
.
name
group
.
id
)
;
const
{
patch
permissions
}
=
options
;
const
{
last_modified
}
=
{
.
.
.
data
.
.
.
options
}
;
const
request
=
requests
.
updateRequest
(
path
{
data
permissions
}
{
last_modified
patch
headers
:
this
.
_getHeaders
(
options
)
safe
:
this
.
_getSafe
(
options
)
}
)
;
return
this
.
client
.
execute
(
request
{
retry
:
this
.
_getRetry
(
options
)
}
)
;
}
async
deleteGroup
(
group
options
=
{
}
)
{
const
groupObj
=
(
0
_utils
.
toDataBody
)
(
group
)
;
const
{
id
}
=
groupObj
;
const
{
last_modified
}
=
{
.
.
.
groupObj
.
.
.
options
}
;
const
path
=
(
0
_endpoint
.
default
)
(
"
group
"
this
.
name
id
)
;
const
request
=
requests
.
deleteRequest
(
path
{
last_modified
headers
:
this
.
_getHeaders
(
options
)
safe
:
this
.
_getSafe
(
options
)
}
)
;
return
this
.
client
.
execute
(
request
{
retry
:
this
.
_getRetry
(
options
)
}
)
;
}
async
getPermissions
(
options
=
{
}
)
{
const
request
=
{
headers
:
this
.
_getHeaders
(
options
)
path
:
(
0
_endpoint
.
default
)
(
"
bucket
"
this
.
name
)
}
;
const
{
permissions
}
=
await
this
.
client
.
execute
(
request
{
retry
:
this
.
_getRetry
(
options
)
}
)
;
return
permissions
;
}
async
setPermissions
(
permissions
options
=
{
}
)
{
if
(
!
(
0
_utils
.
isObject
)
(
permissions
)
)
{
throw
new
Error
(
"
A
permissions
object
is
required
.
"
)
;
}
const
path
=
(
0
_endpoint
.
default
)
(
"
bucket
"
this
.
name
)
;
const
{
last_modified
}
=
options
;
const
data
=
{
last_modified
}
;
const
request
=
requests
.
updateRequest
(
path
{
data
permissions
}
{
headers
:
this
.
_getHeaders
(
options
)
safe
:
this
.
_getSafe
(
options
)
}
)
;
return
this
.
client
.
execute
(
request
{
retry
:
this
.
_getRetry
(
options
)
}
)
;
}
async
addPermissions
(
permissions
options
=
{
}
)
{
if
(
!
(
0
_utils
.
isObject
)
(
permissions
)
)
{
throw
new
Error
(
"
A
permissions
object
is
required
.
"
)
;
}
const
path
=
(
0
_endpoint
.
default
)
(
"
bucket
"
this
.
name
)
;
const
{
last_modified
}
=
options
;
const
request
=
requests
.
jsonPatchPermissionsRequest
(
path
permissions
"
add
"
{
last_modified
headers
:
this
.
_getHeaders
(
options
)
safe
:
this
.
_getSafe
(
options
)
}
)
;
return
this
.
client
.
execute
(
request
{
retry
:
this
.
_getRetry
(
options
)
}
)
;
}
async
removePermissions
(
permissions
options
=
{
}
)
{
if
(
!
(
0
_utils
.
isObject
)
(
permissions
)
)
{
throw
new
Error
(
"
A
permissions
object
is
required
.
"
)
;
}
const
path
=
(
0
_endpoint
.
default
)
(
"
bucket
"
this
.
name
)
;
const
{
last_modified
}
=
options
;
const
request
=
requests
.
jsonPatchPermissionsRequest
(
path
permissions
"
remove
"
{
last_modified
headers
:
this
.
_getHeaders
(
options
)
safe
:
this
.
_getSafe
(
options
)
}
)
;
return
this
.
client
.
execute
(
request
{
retry
:
this
.
_getRetry
(
options
)
}
)
;
}
async
batch
(
fn
options
=
{
}
)
{
return
this
.
client
.
batch
(
fn
{
bucket
:
this
.
name
headers
:
this
.
_getHeaders
(
options
)
retry
:
this
.
_getRetry
(
options
)
safe
:
this
.
_getSafe
(
options
)
aggregate
:
!
!
options
.
aggregate
}
)
;
}
}
(
_applyDecoratedDescriptor
(
_class
.
prototype
"
listHistory
"
[
_dec
]
Object
.
getOwnPropertyDescriptor
(
_class
.
prototype
"
listHistory
"
)
_class
.
prototype
)
)
_class
)
)
;
exports
.
default
=
Bucket
;
}
{
"
.
/
collection
"
:
10
"
.
/
endpoint
"
:
11
"
.
/
requests
"
:
14
"
.
/
utils
"
:
15
}
]
10
:
[
function
(
require
module
exports
)
{
"
use
strict
"
;
Object
.
defineProperty
(
exports
"
__esModule
"
{
value
:
true
}
)
;
exports
.
default
=
void
0
;
var
_uuid
=
require
(
"
uuid
"
)
;
var
_utils
=
require
(
"
.
/
utils
"
)
;
var
requests
=
_interopRequireWildcard
(
require
(
"
.
/
requests
"
)
)
;
var
_endpoint
=
_interopRequireDefault
(
require
(
"
.
/
endpoint
"
)
)
;
var
_dec
_dec2
_dec3
_class
;
function
_interopRequireDefault
(
obj
)
{
return
obj
&
&
obj
.
__esModule
?
obj
:
{
default
:
obj
}
;
}
function
_interopRequireWildcard
(
obj
)
{
if
(
obj
&
&
obj
.
__esModule
)
{
return
obj
;
}
else
{
var
newObj
=
{
}
;
if
(
obj
!
=
null
)
{
for
(
var
key
in
obj
)
{
if
(
Object
.
prototype
.
hasOwnProperty
.
call
(
obj
key
)
)
{
var
desc
=
Object
.
defineProperty
&
&
Object
.
getOwnPropertyDescriptor
?
Object
.
getOwnPropertyDescriptor
(
obj
key
)
:
{
}
;
if
(
desc
.
get
|
|
desc
.
set
)
{
Object
.
defineProperty
(
newObj
key
desc
)
;
}
else
{
newObj
[
key
]
=
obj
[
key
]
;
}
}
}
}
newObj
.
default
=
obj
;
return
newObj
;
}
}
function
_applyDecoratedDescriptor
(
target
property
decorators
descriptor
context
)
{
var
desc
=
{
}
;
Object
[
'
ke
'
+
'
ys
'
]
(
descriptor
)
.
forEach
(
function
(
key
)
{
desc
[
key
]
=
descriptor
[
key
]
;
}
)
;
desc
.
enumerable
=
!
!
desc
.
enumerable
;
desc
.
configurable
=
!
!
desc
.
configurable
;
if
(
'
value
'
in
desc
|
|
desc
.
initializer
)
{
desc
.
writable
=
true
;
}
desc
=
decorators
.
slice
(
)
.
reverse
(
)
.
reduce
(
function
(
desc
decorator
)
{
return
decorator
(
target
property
desc
)
|
|
desc
;
}
desc
)
;
if
(
context
&
&
desc
.
initializer
!
=
=
void
0
)
{
desc
.
value
=
desc
.
initializer
?
desc
.
initializer
.
call
(
context
)
:
void
0
;
desc
.
initializer
=
undefined
;
}
if
(
desc
.
initializer
=
=
=
void
0
)
{
Object
[
'
define
'
+
'
Property
'
]
(
target
property
desc
)
;
desc
=
null
;
}
return
desc
;
}
let
Collection
=
(
_dec
=
(
0
_utils
.
capable
)
(
[
"
attachments
"
]
)
_dec2
=
(
0
_utils
.
capable
)
(
[
"
attachments
"
]
)
_dec3
=
(
0
_utils
.
capable
)
(
[
"
history
"
]
)
(
_class
=
class
Collection
{
constructor
(
client
bucket
name
options
=
{
}
)
{
this
.
client
=
client
;
this
.
bucket
=
bucket
;
this
.
name
=
name
;
this
.
_isBatch
=
!
!
options
.
batch
;
this
.
_retry
=
options
.
retry
|
|
0
;
this
.
_safe
=
!
!
options
.
safe
;
this
.
_headers
=
{
.
.
.
this
.
bucket
.
_headers
.
.
.
options
.
headers
}
;
}
_getHeaders
(
options
)
{
return
{
.
.
.
this
.
_headers
.
.
.
options
.
headers
}
;
}
_getSafe
(
options
)
{
return
{
safe
:
this
.
_safe
.
.
.
options
}
.
safe
;
}
_getRetry
(
options
)
{
return
{
retry
:
this
.
_retry
.
.
.
options
}
.
retry
;
}
async
getTotalRecords
(
options
=
{
}
)
{
const
path
=
(
0
_endpoint
.
default
)
(
"
record
"
this
.
bucket
.
name
this
.
name
)
;
const
request
=
{
headers
:
this
.
_getHeaders
(
options
)
path
method
:
"
HEAD
"
}
;
const
{
headers
}
=
await
this
.
client
.
execute
(
request
{
raw
:
true
retry
:
this
.
_getRetry
(
options
)
}
)
;
return
parseInt
(
headers
.
get
(
"
Total
-
Records
"
)
10
)
;
}
async
getData
(
options
=
{
}
)
{
let
path
=
(
0
_endpoint
.
default
)
(
"
collection
"
this
.
bucket
.
name
this
.
name
)
;
if
(
options
.
query
)
{
const
querystring
=
(
0
_utils
.
qsify
)
(
options
.
query
)
;
path
=
path
+
"
?
"
+
querystring
;
}
const
request
=
{
headers
:
this
.
_getHeaders
(
options
)
path
}
;
const
{
data
}
=
await
this
.
client
.
execute
(
request
{
retry
:
this
.
_getRetry
(
options
)
}
)
;
return
data
;
}
async
setData
(
data
options
=
{
}
)
{
if
(
!
(
0
_utils
.
isObject
)
(
data
)
)
{
throw
new
Error
(
"
A
collection
object
is
required
.
"
)
;
}
const
{
patch
permissions
}
=
options
;
const
{
last_modified
}
=
{
.
.
.
data
.
.
.
options
}
;
const
path
=
(
0
_endpoint
.
default
)
(
"
collection
"
this
.
bucket
.
name
this
.
name
)
;
const
request
=
requests
.
updateRequest
(
path
{
data
permissions
}
{
last_modified
patch
headers
:
this
.
_getHeaders
(
options
)
safe
:
this
.
_getSafe
(
options
)
}
)
;
return
this
.
client
.
execute
(
request
{
retry
:
this
.
_getRetry
(
options
)
}
)
;
}
async
getPermissions
(
options
=
{
}
)
{
const
path
=
(
0
_endpoint
.
default
)
(
"
collection
"
this
.
bucket
.
name
this
.
name
)
;
const
request
=
{
headers
:
this
.
_getHeaders
(
options
)
path
}
;
const
{
permissions
}
=
await
this
.
client
.
execute
(
request
{
retry
:
this
.
_getRetry
(
options
)
}
)
;
return
permissions
;
}
async
setPermissions
(
permissions
options
=
{
}
)
{
if
(
!
(
0
_utils
.
isObject
)
(
permissions
)
)
{
throw
new
Error
(
"
A
permissions
object
is
required
.
"
)
;
}
const
path
=
(
0
_endpoint
.
default
)
(
"
collection
"
this
.
bucket
.
name
this
.
name
)
;
const
data
=
{
last_modified
:
options
.
last_modified
}
;
const
request
=
requests
.
updateRequest
(
path
{
data
permissions
}
{
headers
:
this
.
_getHeaders
(
options
)
safe
:
this
.
_getSafe
(
options
)
}
)
;
return
this
.
client
.
execute
(
request
{
retry
:
this
.
_getRetry
(
options
)
}
)
;
}
async
addPermissions
(
permissions
options
=
{
}
)
{
if
(
!
(
0
_utils
.
isObject
)
(
permissions
)
)
{
throw
new
Error
(
"
A
permissions
object
is
required
.
"
)
;
}
const
path
=
(
0
_endpoint
.
default
)
(
"
collection
"
this
.
bucket
.
name
this
.
name
)
;
const
{
last_modified
}
=
options
;
const
request
=
requests
.
jsonPatchPermissionsRequest
(
path
permissions
"
add
"
{
last_modified
headers
:
this
.
_getHeaders
(
options
)
safe
:
this
.
_getSafe
(
options
)
}
)
;
return
this
.
client
.
execute
(
request
{
retry
:
this
.
_getRetry
(
options
)
}
)
;
}
async
removePermissions
(
permissions
options
=
{
}
)
{
if
(
!
(
0
_utils
.
isObject
)
(
permissions
)
)
{
throw
new
Error
(
"
A
permissions
object
is
required
.
"
)
;
}
const
path
=
(
0
_endpoint
.
default
)
(
"
collection
"
this
.
bucket
.
name
this
.
name
)
;
const
{
last_modified
}
=
options
;
const
request
=
requests
.
jsonPatchPermissionsRequest
(
path
permissions
"
remove
"
{
last_modified
headers
:
this
.
_getHeaders
(
options
)
safe
:
this
.
_getSafe
(
options
)
}
)
;
return
this
.
client
.
execute
(
request
{
retry
:
this
.
_getRetry
(
options
)
}
)
;
}
async
createRecord
(
record
options
=
{
}
)
{
const
{
permissions
}
=
options
;
const
path
=
(
0
_endpoint
.
default
)
(
"
record
"
this
.
bucket
.
name
this
.
name
record
.
id
)
;
const
request
=
requests
.
createRequest
(
path
{
data
:
record
permissions
}
{
headers
:
this
.
_getHeaders
(
options
)
safe
:
this
.
_getSafe
(
options
)
}
)
;
return
this
.
client
.
execute
(
request
{
retry
:
this
.
_getRetry
(
options
)
}
)
;
}
async
addAttachment
(
dataURI
record
=
{
}
options
=
{
}
)
{
const
{
permissions
}
=
options
;
const
id
=
record
.
id
|
|
_uuid
.
v4
.
v4
(
)
;
const
path
=
(
0
_endpoint
.
default
)
(
"
attachment
"
this
.
bucket
.
name
this
.
name
id
)
;
const
{
last_modified
}
=
{
.
.
.
record
.
.
.
options
}
;
const
addAttachmentRequest
=
requests
.
addAttachmentRequest
(
path
dataURI
{
data
:
record
permissions
}
{
last_modified
filename
:
options
.
filename
gzipped
:
options
.
gzipped
headers
:
this
.
_getHeaders
(
options
)
safe
:
this
.
_getSafe
(
options
)
}
)
;
await
this
.
client
.
execute
(
addAttachmentRequest
{
stringify
:
false
retry
:
this
.
_getRetry
(
options
)
}
)
;
return
this
.
getRecord
(
id
)
;
}
async
removeAttachment
(
recordId
options
=
{
}
)
{
const
{
last_modified
}
=
options
;
const
path
=
(
0
_endpoint
.
default
)
(
"
attachment
"
this
.
bucket
.
name
this
.
name
recordId
)
;
const
request
=
requests
.
deleteRequest
(
path
{
last_modified
headers
:
this
.
_getHeaders
(
options
)
safe
:
this
.
_getSafe
(
options
)
}
)
;
return
this
.
client
.
execute
(
request
{
retry
:
this
.
_getRetry
(
options
)
}
)
;
}
async
updateRecord
(
record
options
=
{
}
)
{
if
(
!
(
0
_utils
.
isObject
)
(
record
)
)
{
throw
new
Error
(
"
A
record
object
is
required
.
"
)
;
}
if
(
!
record
.
id
)
{
throw
new
Error
(
"
A
record
id
is
required
.
"
)
;
}
const
{
permissions
}
=
options
;
const
{
last_modified
}
=
{
.
.
.
record
.
.
.
options
}
;
const
path
=
(
0
_endpoint
.
default
)
(
"
record
"
this
.
bucket
.
name
this
.
name
record
.
id
)
;
const
request
=
requests
.
updateRequest
(
path
{
data
:
record
permissions
}
{
headers
:
this
.
_getHeaders
(
options
)
safe
:
this
.
_getSafe
(
options
)
last_modified
patch
:
!
!
options
.
patch
}
)
;
return
this
.
client
.
execute
(
request
{
retry
:
this
.
_getRetry
(
options
)
}
)
;
}
async
deleteRecord
(
record
options
=
{
}
)
{
const
recordObj
=
(
0
_utils
.
toDataBody
)
(
record
)
;
if
(
!
recordObj
.
id
)
{
throw
new
Error
(
"
A
record
id
is
required
.
"
)
;
}
const
{
id
}
=
recordObj
;
const
{
last_modified
}
=
{
.
.
.
recordObj
.
.
.
options
}
;
const
path
=
(
0
_endpoint
.
default
)
(
"
record
"
this
.
bucket
.
name
this
.
name
id
)
;
const
request
=
requests
.
deleteRequest
(
path
{
last_modified
headers
:
this
.
_getHeaders
(
options
)
safe
:
this
.
_getSafe
(
options
)
}
)
;
return
this
.
client
.
execute
(
request
{
retry
:
this
.
_getRetry
(
options
)
}
)
;
}
async
getRecord
(
id
options
=
{
}
)
{
const
path
=
(
0
_endpoint
.
default
)
(
"
record
"
this
.
bucket
.
name
this
.
name
id
)
;
const
request
=
{
headers
:
this
.
_getHeaders
(
options
)
path
}
;
return
this
.
client
.
execute
(
request
{
retry
:
this
.
_getRetry
(
options
)
}
)
;
}
async
listRecords
(
options
=
{
}
)
{
const
path
=
(
0
_endpoint
.
default
)
(
"
record
"
this
.
bucket
.
name
this
.
name
)
;
if
(
options
.
hasOwnProperty
(
"
at
"
)
)
{
return
this
.
getSnapshot
(
options
.
at
)
;
}
else
{
return
this
.
client
.
paginatedList
(
path
options
{
headers
:
this
.
_getHeaders
(
options
)
retry
:
this
.
_getRetry
(
options
)
}
)
;
}
}
async
isHistoryComplete
(
)
{
const
{
data
:
[
oldestHistoryEntry
]
}
=
await
this
.
bucket
.
listHistory
(
{
limit
:
1
filters
:
{
action
:
"
create
"
resource_name
:
"
collection
"
collection_id
:
this
.
name
}
}
)
;
return
!
!
oldestHistoryEntry
;
}
async
listChangesBackTo
(
at
)
{
if
(
!
(
await
this
.
isHistoryComplete
(
)
)
)
{
throw
new
Error
(
"
Computing
a
snapshot
is
only
possible
when
the
full
history
for
a
"
+
"
collection
is
available
.
Here
the
history
plugin
seems
to
have
"
+
"
been
enabled
after
the
creation
of
the
collection
.
"
)
;
}
const
{
data
:
changes
}
=
await
this
.
bucket
.
listHistory
(
{
pages
:
Infinity
sort
:
"
-
target
.
data
.
last_modified
"
filters
:
{
resource_name
:
"
record
"
collection_id
:
this
.
name
"
max_target
.
data
.
last_modified
"
:
String
(
at
)
}
}
)
;
return
changes
;
}
async
getSnapshot
(
at
)
{
if
(
!
Number
.
isInteger
(
at
)
|
|
at
<
=
0
)
{
throw
new
Error
(
"
Invalid
argument
expected
a
positive
integer
.
"
)
;
}
const
changes
=
await
this
.
listChangesBackTo
(
at
)
;
const
seenIds
=
new
Set
(
)
;
let
snapshot
=
[
]
;
for
(
const
{
action
target
:
{
data
:
record
}
}
of
changes
)
{
if
(
action
=
=
"
delete
"
)
{
seenIds
.
add
(
record
.
id
)
;
snapshot
=
snapshot
.
filter
(
r
=
>
r
.
id
!
=
=
record
.
id
)
;
}
else
if
(
!
seenIds
.
has
(
record
.
id
)
)
{
seenIds
.
add
(
record
.
id
)
;
snapshot
.
push
(
record
)
;
}
}
return
{
last_modified
:
String
(
at
)
data
:
snapshot
.
sort
(
(
a
b
)
=
>
b
.
last_modified
-
a
.
last_modified
)
next
:
(
)
=
>
{
throw
new
Error
(
"
Snapshots
don
'
t
support
pagination
"
)
;
}
hasNextPage
:
false
totalRecords
:
snapshot
.
length
}
;
}
async
batch
(
fn
options
=
{
}
)
{
return
this
.
client
.
batch
(
fn
{
bucket
:
this
.
bucket
.
name
collection
:
this
.
name
headers
:
this
.
_getHeaders
(
options
)
retry
:
this
.
_getRetry
(
options
)
safe
:
this
.
_getSafe
(
options
)
aggregate
:
!
!
options
.
aggregate
}
)
;
}
}
(
_applyDecoratedDescriptor
(
_class
.
prototype
"
addAttachment
"
[
_dec
]
Object
.
getOwnPropertyDescriptor
(
_class
.
prototype
"
addAttachment
"
)
_class
.
prototype
)
_applyDecoratedDescriptor
(
_class
.
prototype
"
removeAttachment
"
[
_dec2
]
Object
.
getOwnPropertyDescriptor
(
_class
.
prototype
"
removeAttachment
"
)
_class
.
prototype
)
_applyDecoratedDescriptor
(
_class
.
prototype
"
getSnapshot
"
[
_dec3
]
Object
.
getOwnPropertyDescriptor
(
_class
.
prototype
"
getSnapshot
"
)
_class
.
prototype
)
)
_class
)
)
;
exports
.
default
=
Collection
;
}
{
"
.
/
endpoint
"
:
11
"
.
/
requests
"
:
14
"
.
/
utils
"
:
15
"
uuid
"
:
2
}
]
11
:
[
function
(
require
module
exports
)
{
"
use
strict
"
;
Object
.
defineProperty
(
exports
"
__esModule
"
{
value
:
true
}
)
;
exports
.
default
=
endpoint
;
const
ENDPOINTS
=
{
root
:
(
)
=
>
"
/
"
batch
:
(
)
=
>
"
/
batch
"
permissions
:
(
)
=
>
"
/
permissions
"
bucket
:
bucket
=
>
"
/
buckets
"
+
(
bucket
?
/
{
bucket
}
:
"
"
)
history
:
bucket
=
>
{
ENDPOINTS
.
bucket
(
bucket
)
}
/
history
collection
:
(
bucket
coll
)
=
>
{
ENDPOINTS
.
bucket
(
bucket
)
}
/
collections
+
(
coll
?
/
{
coll
}
:
"
"
)
group
:
(
bucket
group
)
=
>
{
ENDPOINTS
.
bucket
(
bucket
)
}
/
groups
+
(
group
?
/
{
group
}
:
"
"
)
record
:
(
bucket
coll
id
)
=
>
{
ENDPOINTS
.
collection
(
bucket
coll
)
}
/
records
+
(
id
?
/
{
id
}
:
"
"
)
attachment
:
(
bucket
coll
id
)
=
>
{
ENDPOINTS
.
record
(
bucket
coll
id
)
}
/
attachment
}
;
function
endpoint
(
name
.
.
.
args
)
{
return
ENDPOINTS
[
name
]
(
.
.
.
args
)
;
}
}
{
}
]
12
:
[
function
(
require
module
exports
)
{
"
use
strict
"
;
Object
.
defineProperty
(
exports
"
__esModule
"
{
value
:
true
}
)
;
exports
.
UnparseableResponseError
=
exports
.
ServerResponse
=
exports
.
NetworkTimeoutError
=
exports
.
default
=
void
0
;
const
ERROR_CODES
=
{
104
:
"
Missing
Authorization
Token
"
105
:
"
Invalid
Authorization
Token
"
106
:
"
Request
body
was
not
valid
JSON
"
107
:
"
Invalid
request
parameter
"
108
:
"
Missing
request
parameter
"
109
:
"
Invalid
posted
data
"
110
:
"
Invalid
Token
/
id
"
111
:
"
Missing
Token
/
id
"
112
:
"
Content
-
Length
header
was
not
provided
"
113
:
"
Request
body
too
large
"
114
:
"
Resource
was
created
updated
or
deleted
meanwhile
"
115
:
"
Method
not
allowed
on
this
end
point
(
hint
:
server
may
be
readonly
)
"
116
:
"
Requested
version
not
available
on
this
server
"
117
:
"
Client
has
sent
too
many
requests
"
121
:
"
Resource
access
is
forbidden
for
this
user
"
122
:
"
Another
resource
violates
constraint
"
201
:
"
Service
Temporary
unavailable
due
to
high
load
"
202
:
"
Service
deprecated
"
999
:
"
Internal
Server
Error
"
}
;
var
_default
=
ERROR_CODES
;
exports
.
default
=
_default
;
class
NetworkTimeoutError
extends
Error
{
constructor
(
url
options
)
{
super
(
Timeout
while
trying
to
access
{
url
}
with
{
JSON
.
stringify
(
options
)
}
)
;
if
(
Error
.
captureStackTrace
)
{
Error
.
captureStackTrace
(
this
NetworkTimeoutError
)
;
}
this
.
url
=
url
;
this
.
options
=
options
;
}
}
exports
.
NetworkTimeoutError
=
NetworkTimeoutError
;
class
UnparseableResponseError
extends
Error
{
constructor
(
response
body
error
)
{
const
{
status
}
=
response
;
super
(
Response
from
server
unparseable
(
HTTP
{
status
|
|
0
}
;
{
error
}
)
:
{
body
}
)
;
if
(
Error
.
captureStackTrace
)
{
Error
.
captureStackTrace
(
this
UnparseableResponseError
)
;
}
this
.
status
=
status
;
this
.
response
=
response
;
this
.
stack
=
error
.
stack
;
this
.
error
=
error
;
}
}
exports
.
UnparseableResponseError
=
UnparseableResponseError
;
class
ServerResponse
extends
Error
{
constructor
(
response
json
)
{
const
{
status
}
=
response
;
let
{
statusText
}
=
response
;
let
errnoMsg
;
if
(
json
)
{
statusText
=
json
.
error
|
|
statusText
;
if
(
json
.
errno
&
&
json
.
errno
in
ERROR_CODES
)
{
errnoMsg
=
ERROR_CODES
[
json
.
errno
]
;
}
else
if
(
json
.
message
)
{
errnoMsg
=
json
.
message
;
}
if
(
errnoMsg
&
&
json
.
message
&
&
json
.
message
!
=
=
errnoMsg
)
{
errnoMsg
+
=
(
{
json
.
message
}
)
;
}
}
let
message
=
HTTP
{
status
}
{
statusText
}
;
if
(
errnoMsg
)
{
message
+
=
:
{
errnoMsg
}
;
}
super
(
message
.
trim
(
)
)
;
if
(
Error
.
captureStackTrace
)
{
Error
.
captureStackTrace
(
this
ServerResponse
)
;
}
this
.
response
=
response
;
this
.
data
=
json
;
}
}
exports
.
ServerResponse
=
ServerResponse
;
}
{
}
]
13
:
[
function
(
require
module
exports
)
{
"
use
strict
"
;
Object
.
defineProperty
(
exports
"
__esModule
"
{
value
:
true
}
)
;
exports
.
default
=
void
0
;
var
_utils
=
require
(
"
.
/
utils
"
)
;
var
_errors
=
require
(
"
.
/
errors
"
)
;
class
HTTP
{
static
get
DEFAULT_REQUEST_HEADERS
(
)
{
return
{
Accept
:
"
application
/
json
"
"
Content
-
Type
"
:
"
application
/
json
"
}
;
}
static
get
defaultOptions
(
)
{
return
{
timeout
:
null
requestMode
:
"
cors
"
}
;
}
constructor
(
events
options
=
{
}
)
{
if
(
!
events
)
{
throw
new
Error
(
"
No
events
handler
provided
"
)
;
}
this
.
events
=
events
;
this
.
requestMode
=
options
.
requestMode
|
|
HTTP
.
defaultOptions
.
requestMode
;
this
.
timeout
=
options
.
timeout
|
|
HTTP
.
defaultOptions
.
timeout
;
}
timedFetch
(
url
options
)
{
let
hasTimedout
=
false
;
return
new
Promise
(
(
resolve
reject
)
=
>
{
let
_timeoutId
;
if
(
this
.
timeout
)
{
_timeoutId
=
setTimeout
(
(
)
=
>
{
hasTimedout
=
true
;
reject
(
new
_errors
.
NetworkTimeoutError
(
url
options
)
)
;
}
this
.
timeout
)
;
}
function
proceedWithHandler
(
fn
)
{
return
arg
=
>
{
if
(
!
hasTimedout
)
{
if
(
_timeoutId
)
{
clearTimeout
(
_timeoutId
)
;
}
fn
(
arg
)
;
}
}
;
}
fetch
(
url
options
)
.
then
(
proceedWithHandler
(
resolve
)
)
.
catch
(
proceedWithHandler
(
reject
)
)
;
}
)
;
}
async
processResponse
(
response
)
{
const
{
status
headers
}
=
response
;
const
text
=
await
response
.
text
(
)
;
let
json
;
if
(
text
.
length
!
=
=
0
)
{
try
{
json
=
JSON
.
parse
(
text
)
;
}
catch
(
err
)
{
throw
new
_errors
.
UnparseableResponseError
(
response
text
err
)
;
}
}
if
(
status
>
=
400
)
{
throw
new
_errors
.
ServerResponse
(
response
json
)
;
}
return
{
status
json
headers
}
;
}
async
retry
(
url
retryAfter
request
options
)
{
await
(
0
_utils
.
delay
)
(
retryAfter
)
;
return
this
.
request
(
url
request
{
.
.
.
options
retry
:
options
.
retry
-
1
}
)
;
}
async
request
(
url
request
=
{
headers
:
{
}
}
options
=
{
retry
:
0
}
)
{
request
.
headers
=
{
.
.
.
HTTP
.
DEFAULT_REQUEST_HEADERS
.
.
.
request
.
headers
}
;
if
(
request
.
body
&
&
typeof
request
.
body
.
append
=
=
=
"
function
"
)
{
delete
request
.
headers
[
"
Content
-
Type
"
]
;
}
request
.
mode
=
this
.
requestMode
;
const
response
=
await
this
.
timedFetch
(
url
request
)
;
const
{
status
headers
}
=
response
;
this
.
_checkForDeprecationHeader
(
headers
)
;
this
.
_checkForBackoffHeader
(
status
headers
)
;
const
retryAfter
=
this
.
_checkForRetryAfterHeader
(
status
headers
)
;
if
(
retryAfter
&
&
options
.
retry
>
0
)
{
return
this
.
retry
(
url
retryAfter
request
options
)
;
}
else
{
return
this
.
processResponse
(
response
)
;
}
}
_checkForDeprecationHeader
(
headers
)
{
const
alertHeader
=
headers
.
get
(
"
Alert
"
)
;
if
(
!
alertHeader
)
{
return
;
}
let
alert
;
try
{
alert
=
JSON
.
parse
(
alertHeader
)
;
}
catch
(
err
)
{
console
.
warn
(
"
Unable
to
parse
Alert
header
message
"
alertHeader
)
;
return
;
}
console
.
warn
(
alert
.
message
alert
.
url
)
;
this
.
events
.
emit
(
"
deprecated
"
alert
)
;
}
_checkForBackoffHeader
(
status
headers
)
{
let
backoffMs
;
const
backoffSeconds
=
parseInt
(
headers
.
get
(
"
Backoff
"
)
10
)
;
if
(
backoffSeconds
>
0
)
{
backoffMs
=
new
Date
(
)
.
getTime
(
)
+
backoffSeconds
*
1000
;
}
else
{
backoffMs
=
0
;
}
this
.
events
.
emit
(
"
backoff
"
backoffMs
)
;
}
_checkForRetryAfterHeader
(
status
headers
)
{
let
retryAfter
=
headers
.
get
(
"
Retry
-
After
"
)
;
if
(
!
retryAfter
)
{
return
;
}
const
delay
=
parseInt
(
retryAfter
10
)
*
1000
;
retryAfter
=
new
Date
(
)
.
getTime
(
)
+
delay
;
this
.
events
.
emit
(
"
retry
-
after
"
retryAfter
)
;
return
delay
;
}
}
exports
.
default
=
HTTP
;
}
{
"
.
/
errors
"
:
12
"
.
/
utils
"
:
15
}
]
14
:
[
function
(
require
module
exports
)
{
"
use
strict
"
;
Object
.
defineProperty
(
exports
"
__esModule
"
{
value
:
true
}
)
;
exports
.
createRequest
=
createRequest
;
exports
.
updateRequest
=
updateRequest
;
exports
.
jsonPatchPermissionsRequest
=
jsonPatchPermissionsRequest
;
exports
.
deleteRequest
=
deleteRequest
;
exports
.
addAttachmentRequest
=
addAttachmentRequest
;
var
_utils
=
require
(
"
.
/
utils
"
)
;
const
requestDefaults
=
{
safe
:
false
headers
:
{
}
permissions
:
undefined
data
:
undefined
patch
:
false
}
;
function
safeHeader
(
safe
last_modified
)
{
if
(
!
safe
)
{
return
{
}
;
}
if
(
last_modified
)
{
return
{
"
If
-
Match
"
:
"
{
last_modified
}
"
}
;
}
return
{
"
If
-
None
-
Match
"
:
"
*
"
}
;
}
function
createRequest
(
path
{
data
permissions
}
options
=
{
}
)
{
const
{
headers
safe
}
=
{
.
.
.
requestDefaults
.
.
.
options
}
;
return
{
method
:
data
&
&
data
.
id
?
"
PUT
"
:
"
POST
"
path
headers
:
{
.
.
.
headers
.
.
.
safeHeader
(
safe
)
}
body
:
{
data
permissions
}
}
;
}
function
updateRequest
(
path
{
data
permissions
}
options
=
{
}
)
{
const
{
headers
safe
patch
}
=
{
.
.
.
requestDefaults
.
.
.
options
}
;
const
{
last_modified
}
=
{
.
.
.
data
.
.
.
options
}
;
if
(
Object
.
keys
(
(
0
_utils
.
omit
)
(
data
"
id
"
"
last_modified
"
)
)
.
length
=
=
=
0
)
{
data
=
undefined
;
}
return
{
method
:
patch
?
"
PATCH
"
:
"
PUT
"
path
headers
:
{
.
.
.
headers
.
.
.
safeHeader
(
safe
last_modified
)
}
body
:
{
data
permissions
}
}
;
}
function
jsonPatchPermissionsRequest
(
path
permissions
opType
options
=
{
}
)
{
const
{
headers
safe
last_modified
}
=
{
.
.
.
requestDefaults
.
.
.
options
}
;
const
ops
=
[
]
;
for
(
const
[
type
principals
]
of
Object
.
entries
(
permissions
)
)
{
for
(
const
principal
of
principals
)
{
ops
.
push
(
{
op
:
opType
path
:
/
permissions
/
{
type
}
/
{
principal
}
}
)
;
}
}
return
{
method
:
"
PATCH
"
path
headers
:
{
.
.
.
headers
.
.
.
safeHeader
(
safe
last_modified
)
"
Content
-
Type
"
:
"
application
/
json
-
patch
+
json
"
}
body
:
ops
}
;
}
function
deleteRequest
(
path
options
=
{
}
)
{
const
{
headers
safe
last_modified
}
=
{
.
.
.
requestDefaults
.
.
.
options
}
;
if
(
safe
&
&
!
last_modified
)
{
throw
new
Error
(
"
Safe
concurrency
check
requires
a
last_modified
value
.
"
)
;
}
return
{
method
:
"
DELETE
"
path
headers
:
{
.
.
.
headers
.
.
.
safeHeader
(
safe
last_modified
)
}
}
;
}
function
addAttachmentRequest
(
path
dataURI
{
data
permissions
}
=
{
}
options
=
{
}
)
{
const
{
headers
safe
gzipped
}
=
{
.
.
.
requestDefaults
.
.
.
options
}
;
const
{
last_modified
}
=
{
.
.
.
data
.
.
.
options
}
;
const
body
=
{
data
permissions
}
;
const
formData
=
(
0
_utils
.
createFormData
)
(
dataURI
body
options
)
;
let
customPath
=
gzipped
!
=
null
?
customPath
=
path
+
"
?
gzipped
=
"
+
(
gzipped
?
"
true
"
:
"
false
"
)
:
path
;
return
{
method
:
"
POST
"
path
:
customPath
headers
:
{
.
.
.
headers
.
.
.
safeHeader
(
safe
last_modified
)
}
body
:
formData
}
;
}
}
{
"
.
/
utils
"
:
15
}
]
15
:
[
function
(
require
module
exports
)
{
"
use
strict
"
;
Object
.
defineProperty
(
exports
"
__esModule
"
{
value
:
true
}
)
;
exports
.
partition
=
partition
;
exports
.
delay
=
delay
;
exports
.
pMap
=
pMap
;
exports
.
omit
=
omit
;
exports
.
toDataBody
=
toDataBody
;
exports
.
qsify
=
qsify
;
exports
.
checkVersion
=
checkVersion
;
exports
.
support
=
support
;
exports
.
capable
=
capable
;
exports
.
nobatch
=
nobatch
;
exports
.
isObject
=
isObject
;
exports
.
parseDataURL
=
parseDataURL
;
exports
.
extractFileInfo
=
extractFileInfo
;
exports
.
createFormData
=
createFormData
;
exports
.
cleanUndefinedProperties
=
cleanUndefinedProperties
;
function
partition
(
array
n
)
{
if
(
n
<
=
0
)
{
return
array
;
}
return
array
.
reduce
(
(
acc
x
i
)
=
>
{
if
(
i
=
=
=
0
|
|
i
%
n
=
=
=
0
)
{
acc
.
push
(
[
x
]
)
;
}
else
{
acc
[
acc
.
length
-
1
]
.
push
(
x
)
;
}
return
acc
;
}
[
]
)
;
}
function
delay
(
ms
)
{
return
new
Promise
(
resolve
=
>
setTimeout
(
resolve
ms
)
)
;
}
async
function
pMap
(
list
fn
)
{
let
results
=
[
]
;
await
list
.
reduce
(
async
function
(
promise
entry
)
{
await
promise
;
results
=
results
.
concat
(
(
await
fn
(
entry
)
)
)
;
}
Promise
.
resolve
(
)
)
;
return
results
;
}
function
omit
(
obj
.
.
.
keys
)
{
return
Object
.
keys
(
obj
)
.
reduce
(
(
acc
key
)
=
>
{
if
(
!
keys
.
includes
(
key
)
)
{
acc
[
key
]
=
obj
[
key
]
;
}
return
acc
;
}
{
}
)
;
}
function
toDataBody
(
resource
)
{
if
(
isObject
(
resource
)
)
{
return
resource
;
}
if
(
typeof
resource
=
=
=
"
string
"
)
{
return
{
id
:
resource
}
;
}
throw
new
Error
(
"
Invalid
argument
.
"
)
;
}
function
qsify
(
obj
)
{
const
encode
=
v
=
>
encodeURIComponent
(
typeof
v
=
=
=
"
boolean
"
?
String
(
v
)
:
v
)
;
const
stripUndefined
=
o
=
>
JSON
.
parse
(
JSON
.
stringify
(
o
)
)
;
const
stripped
=
stripUndefined
(
obj
)
;
return
Object
.
keys
(
stripped
)
.
map
(
k
=
>
{
const
ks
=
encode
(
k
)
+
"
=
"
;
if
(
Array
.
isArray
(
stripped
[
k
]
)
)
{
return
ks
+
stripped
[
k
]
.
map
(
v
=
>
encode
(
v
)
)
.
join
(
"
"
)
;
}
else
{
return
ks
+
encode
(
stripped
[
k
]
)
;
}
}
)
.
join
(
"
&
"
)
;
}
function
checkVersion
(
version
minVersion
maxVersion
)
{
const
extract
=
str
=
>
str
.
split
(
"
.
"
)
.
map
(
x
=
>
parseInt
(
x
10
)
)
;
const
[
verMajor
verMinor
]
=
extract
(
version
)
;
const
[
minMajor
minMinor
]
=
extract
(
minVersion
)
;
const
[
maxMajor
maxMinor
]
=
extract
(
maxVersion
)
;
const
checks
=
[
verMajor
<
minMajor
verMajor
=
=
=
minMajor
&
&
verMinor
<
minMinor
verMajor
>
maxMajor
verMajor
=
=
=
maxMajor
&
&
verMinor
>
=
maxMinor
]
;
if
(
checks
.
some
(
x
=
>
x
)
)
{
throw
new
Error
(
Version
{
version
}
doesn
'
t
satisfy
{
minVersion
}
<
=
x
<
{
maxVersion
}
)
;
}
}
function
support
(
min
max
)
{
return
function
(
target
key
descriptor
)
{
const
fn
=
descriptor
.
value
;
return
{
configurable
:
true
get
(
)
{
const
wrappedMethod
=
(
.
.
.
args
)
=
>
{
const
client
=
"
client
"
in
this
?
this
.
client
:
this
;
return
client
.
fetchHTTPApiVersion
(
)
.
then
(
version
=
>
checkVersion
(
version
min
max
)
)
.
then
(
(
)
=
>
fn
.
apply
(
this
args
)
)
;
}
;
Object
.
defineProperty
(
this
key
{
value
:
wrappedMethod
configurable
:
true
writable
:
true
}
)
;
return
wrappedMethod
;
}
}
;
}
;
}
function
capable
(
capabilities
)
{
return
function
(
target
key
descriptor
)
{
const
fn
=
descriptor
.
value
;
return
{
configurable
:
true
get
(
)
{
const
wrappedMethod
=
(
.
.
.
args
)
=
>
{
const
client
=
"
client
"
in
this
?
this
.
client
:
this
;
return
client
.
fetchServerCapabilities
(
)
.
then
(
available
=
>
{
const
missing
=
capabilities
.
filter
(
c
=
>
!
(
c
in
available
)
)
;
if
(
missing
.
length
>
0
)
{
const
missingStr
=
missing
.
join
(
"
"
)
;
throw
new
Error
(
Required
capabilities
{
missingStr
}
not
present
on
server
)
;
}
}
)
.
then
(
(
)
=
>
fn
.
apply
(
this
args
)
)
;
}
;
Object
.
defineProperty
(
this
key
{
value
:
wrappedMethod
configurable
:
true
writable
:
true
}
)
;
return
wrappedMethod
;
}
}
;
}
;
}
function
nobatch
(
message
)
{
return
function
(
target
key
descriptor
)
{
const
fn
=
descriptor
.
value
;
return
{
configurable
:
true
get
(
)
{
const
wrappedMethod
=
(
.
.
.
args
)
=
>
{
if
(
this
.
_isBatch
)
{
throw
new
Error
(
message
)
;
}
return
fn
.
apply
(
this
args
)
;
}
;
Object
.
defineProperty
(
this
key
{
value
:
wrappedMethod
configurable
:
true
writable
:
true
}
)
;
return
wrappedMethod
;
}
}
;
}
;
}
function
isObject
(
thing
)
{
return
typeof
thing
=
=
=
"
object
"
&
&
thing
!
=
=
null
&
&
!
Array
.
isArray
(
thing
)
;
}
function
parseDataURL
(
dataURL
)
{
const
regex
=
/
^
data
:
(
.
*
)
;
base64
(
.
*
)
/
;
const
match
=
dataURL
.
match
(
regex
)
;
if
(
!
match
)
{
throw
new
Error
(
Invalid
data
-
url
:
{
String
(
dataURL
)
.
substr
(
0
32
)
}
.
.
.
)
;
}
const
props
=
match
[
1
]
;
const
base64
=
match
[
2
]
;
const
[
type
.
.
.
rawParams
]
=
props
.
split
(
"
;
"
)
;
const
params
=
rawParams
.
reduce
(
(
acc
param
)
=
>
{
const
[
key
value
]
=
param
.
split
(
"
=
"
)
;
return
{
.
.
.
acc
[
key
]
:
value
}
;
}
{
}
)
;
return
{
.
.
.
params
type
base64
}
;
}
function
extractFileInfo
(
dataURL
)
{
const
{
name
type
base64
}
=
parseDataURL
(
dataURL
)
;
const
binary
=
atob
(
base64
)
;
const
array
=
[
]
;
for
(
let
i
=
0
;
i
<
binary
.
length
;
i
+
+
)
{
array
.
push
(
binary
.
charCodeAt
(
i
)
)
;
}
const
blob
=
new
Blob
(
[
new
Uint8Array
(
array
)
]
{
type
}
)
;
return
{
blob
name
}
;
}
function
createFormData
(
dataURL
body
options
=
{
}
)
{
const
{
filename
=
"
untitled
"
}
=
options
;
const
{
blob
name
}
=
extractFileInfo
(
dataURL
)
;
const
formData
=
new
FormData
(
)
;
formData
.
append
(
"
attachment
"
blob
name
|
|
filename
)
;
for
(
const
property
in
body
)
{
if
(
typeof
body
[
property
]
!
=
=
"
undefined
"
)
{
formData
.
append
(
property
JSON
.
stringify
(
body
[
property
]
)
)
;
}
}
return
formData
;
}
function
cleanUndefinedProperties
(
obj
)
{
const
result
=
{
}
;
for
(
const
key
in
obj
)
{
if
(
typeof
obj
[
key
]
!
=
=
"
undefined
"
)
{
result
[
key
]
=
obj
[
key
]
;
}
}
return
result
;
}
}
{
}
]
}
{
}
[
1
]
)
(
1
)
}
)
;
