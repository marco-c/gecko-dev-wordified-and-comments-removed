this
.
EXPORTED_SYMBOLS
=
[
"
EngineManager
"
"
Engine
"
"
SyncEngine
"
"
Tracker
"
"
Store
"
"
Changeset
"
]
;
var
{
classes
:
Cc
interfaces
:
Ci
results
:
Cr
utils
:
Cu
}
=
Components
;
Cu
.
import
(
"
resource
:
/
/
gre
/
modules
/
XPCOMUtils
.
jsm
"
)
;
Cu
.
import
(
"
resource
:
/
/
gre
/
modules
/
JSONFile
.
jsm
"
)
;
Cu
.
import
(
"
resource
:
/
/
gre
/
modules
/
Log
.
jsm
"
)
;
Cu
.
import
(
"
resource
:
/
/
services
-
common
/
async
.
js
"
)
;
Cu
.
import
(
"
resource
:
/
/
services
-
common
/
observers
.
js
"
)
;
Cu
.
import
(
"
resource
:
/
/
services
-
sync
/
constants
.
js
"
)
;
Cu
.
import
(
"
resource
:
/
/
services
-
sync
/
record
.
js
"
)
;
Cu
.
import
(
"
resource
:
/
/
services
-
sync
/
resource
.
js
"
)
;
Cu
.
import
(
"
resource
:
/
/
services
-
sync
/
util
.
js
"
)
;
XPCOMUtils
.
defineLazyModuleGetter
(
this
"
fxAccounts
"
"
resource
:
/
/
gre
/
modules
/
FxAccounts
.
jsm
"
)
;
XPCOMUtils
.
defineLazyModuleGetter
(
this
"
OS
"
"
resource
:
/
/
gre
/
modules
/
osfile
.
jsm
"
)
;
this
.
Tracker
=
function
Tracker
(
name
engine
)
{
if
(
!
engine
)
{
throw
new
Error
(
"
Tracker
must
be
associated
with
an
Engine
instance
.
"
)
;
}
name
=
name
|
|
"
Unnamed
"
;
this
.
name
=
this
.
file
=
name
.
toLowerCase
(
)
;
this
.
engine
=
engine
;
this
.
_log
=
Log
.
repository
.
getLogger
(
"
Sync
.
Tracker
.
"
+
name
)
;
let
level
=
Svc
.
Prefs
.
get
(
"
log
.
logger
.
engine
.
"
+
this
.
name
"
Debug
"
)
;
this
.
_log
.
level
=
Log
.
Level
[
level
]
;
this
.
_score
=
0
;
this
.
_ignored
=
[
]
;
this
.
_storage
=
new
JSONFile
(
{
path
:
Utils
.
jsonFilePath
(
"
changes
/
"
+
this
.
file
)
dataPostProcessor
:
json
=
>
this
.
_dataPostProcessor
(
json
)
beforeSave
:
(
)
=
>
this
.
_beforeSave
(
)
}
)
;
this
.
ignoreAll
=
false
;
Svc
.
Obs
.
add
(
"
weave
:
engine
:
start
-
tracking
"
this
)
;
Svc
.
Obs
.
add
(
"
weave
:
engine
:
stop
-
tracking
"
this
)
;
Svc
.
Prefs
.
observe
(
"
engine
.
"
+
this
.
engine
.
prefName
this
)
;
}
;
Tracker
.
prototype
=
{
get
score
(
)
{
return
this
.
_score
;
}
_dataPostProcessor
(
json
)
{
return
typeof
json
=
=
"
object
"
&
&
json
|
|
{
}
;
}
_beforeSave
(
)
{
let
basename
=
OS
.
Path
.
dirname
(
this
.
_storage
.
path
)
;
return
OS
.
File
.
makeDir
(
basename
{
from
:
OS
.
Constants
.
Path
.
profileDir
}
)
;
}
get
changedIDs
(
)
{
Async
.
promiseSpinningly
(
this
.
_storage
.
load
(
)
)
;
return
this
.
_storage
.
data
;
}
set
score
(
value
)
{
this
.
_score
=
value
;
Observers
.
notify
(
"
weave
:
engine
:
score
:
updated
"
this
.
name
)
;
}
resetScore
(
)
{
this
.
_score
=
0
;
}
persistChangedIDs
:
true
_saveChangedIDs
(
)
{
if
(
!
this
.
persistChangedIDs
)
{
this
.
_log
.
debug
(
"
Not
saving
changedIDs
.
"
)
;
return
;
}
this
.
_storage
.
saveSoon
(
)
;
}
ignoreID
(
id
)
{
this
.
unignoreID
(
id
)
;
this
.
_ignored
.
push
(
id
)
;
}
unignoreID
(
id
)
{
let
index
=
this
.
_ignored
.
indexOf
(
id
)
;
if
(
index
!
=
-
1
)
this
.
_ignored
.
splice
(
index
1
)
;
}
_saveChangedID
(
id
when
)
{
this
.
_log
.
trace
(
Adding
changed
ID
:
{
id
}
{
JSON
.
stringify
(
when
)
}
)
;
this
.
changedIDs
[
id
]
=
when
;
this
.
_saveChangedIDs
(
)
;
}
addChangedID
(
id
when
)
{
if
(
!
id
)
{
this
.
_log
.
warn
(
"
Attempted
to
add
undefined
ID
to
tracker
"
)
;
return
false
;
}
if
(
this
.
ignoreAll
|
|
this
.
_ignored
.
includes
(
id
)
)
{
return
false
;
}
if
(
when
=
=
null
)
{
when
=
this
.
_now
(
)
;
}
if
(
(
this
.
changedIDs
[
id
]
|
|
-
Infinity
)
<
when
)
{
this
.
_saveChangedID
(
id
when
)
;
}
return
true
;
}
removeChangedID
(
.
.
.
ids
)
{
if
(
!
ids
.
length
|
|
this
.
ignoreAll
)
{
return
false
;
}
for
(
let
id
of
ids
)
{
if
(
!
id
)
{
this
.
_log
.
warn
(
"
Attempted
to
remove
undefined
ID
from
tracker
"
)
;
continue
;
}
if
(
this
.
_ignored
.
includes
(
id
)
)
{
this
.
_log
.
debug
(
Not
removing
ignored
ID
{
id
}
from
tracker
)
;
continue
;
}
if
(
this
.
changedIDs
[
id
]
!
=
null
)
{
this
.
_log
.
trace
(
"
Removing
changed
ID
"
+
id
)
;
delete
this
.
changedIDs
[
id
]
;
}
}
this
.
_saveChangedIDs
(
)
;
return
true
;
}
clearChangedIDs
(
)
{
this
.
_log
.
trace
(
"
Clearing
changed
ID
list
"
)
;
this
.
_storage
.
data
=
{
}
;
this
.
_saveChangedIDs
(
)
;
}
_now
(
)
{
return
Date
.
now
(
)
/
1000
;
}
_isTracking
:
false
startTracking
(
)
{
}
stopTracking
(
)
{
}
engineIsEnabled
(
)
{
if
(
!
this
.
engine
)
{
return
true
;
}
return
this
.
engine
.
enabled
;
}
onEngineEnabledChanged
(
engineEnabled
)
{
if
(
engineEnabled
=
=
this
.
_isTracking
)
{
return
;
}
if
(
engineEnabled
)
{
this
.
startTracking
(
)
;
this
.
_isTracking
=
true
;
}
else
{
this
.
stopTracking
(
)
;
this
.
_isTracking
=
false
;
this
.
clearChangedIDs
(
)
;
}
}
observe
(
subject
topic
data
)
{
switch
(
topic
)
{
case
"
weave
:
engine
:
start
-
tracking
"
:
if
(
!
this
.
engineIsEnabled
(
)
)
{
return
;
}
this
.
_log
.
trace
(
"
Got
start
-
tracking
.
"
)
;
if
(
!
this
.
_isTracking
)
{
this
.
startTracking
(
)
;
this
.
_isTracking
=
true
;
}
return
;
case
"
weave
:
engine
:
stop
-
tracking
"
:
this
.
_log
.
trace
(
"
Got
stop
-
tracking
.
"
)
;
if
(
this
.
_isTracking
)
{
this
.
stopTracking
(
)
;
this
.
_isTracking
=
false
;
}
return
;
case
"
nsPref
:
changed
"
:
if
(
data
=
=
PREFS_BRANCH
+
"
engine
.
"
+
this
.
engine
.
prefName
)
{
this
.
onEngineEnabledChanged
(
this
.
engine
.
enabled
)
;
}
}
}
async
finalize
(
)
{
Svc
.
Obs
.
remove
(
"
weave
:
engine
:
start
-
tracking
"
this
)
;
Svc
.
Obs
.
remove
(
"
weave
:
engine
:
stop
-
tracking
"
this
)
;
Svc
.
Prefs
.
ignore
(
"
engine
.
"
+
this
.
engine
.
prefName
this
)
;
this
.
_saveChangedIDs
(
)
;
await
this
.
_storage
.
finalize
(
)
;
}
}
;
this
.
Store
=
function
Store
(
name
engine
)
{
if
(
!
engine
)
{
throw
new
Error
(
"
Store
must
be
associated
with
an
Engine
instance
.
"
)
;
}
name
=
name
|
|
"
Unnamed
"
;
this
.
name
=
name
.
toLowerCase
(
)
;
this
.
engine
=
engine
;
this
.
_log
=
Log
.
repository
.
getLogger
(
"
Sync
.
Store
.
"
+
name
)
;
let
level
=
Svc
.
Prefs
.
get
(
"
log
.
logger
.
engine
.
"
+
this
.
name
"
Debug
"
)
;
this
.
_log
.
level
=
Log
.
Level
[
level
]
;
XPCOMUtils
.
defineLazyGetter
(
this
"
_timer
"
function
(
)
{
return
Cc
[
"
mozilla
.
org
/
timer
;
1
"
]
.
createInstance
(
Ci
.
nsITimer
)
;
}
)
;
}
Store
.
prototype
=
{
async
applyIncomingBatch
(
records
)
{
let
failed
=
[
]
;
let
maybeYield
=
Async
.
jankYielder
(
)
;
for
(
let
record
of
records
)
{
await
maybeYield
(
)
;
try
{
await
this
.
applyIncoming
(
record
)
;
}
catch
(
ex
)
{
if
(
ex
.
code
=
=
Engine
.
prototype
.
eEngineAbortApplyIncoming
)
{
throw
ex
.
cause
;
}
if
(
Async
.
isShutdownException
(
ex
)
)
{
throw
ex
;
}
this
.
_log
.
warn
(
"
Failed
to
apply
incoming
record
"
+
record
.
id
ex
)
;
failed
.
push
(
record
.
id
)
;
}
}
return
failed
;
}
async
applyIncoming
(
record
)
{
if
(
record
.
deleted
)
await
this
.
remove
(
record
)
;
else
if
(
!
(
await
this
.
itemExists
(
record
.
id
)
)
)
await
this
.
create
(
record
)
;
else
await
this
.
update
(
record
)
;
}
async
create
(
record
)
{
throw
new
Error
(
"
override
create
in
a
subclass
"
)
;
}
async
remove
(
record
)
{
throw
new
Error
(
"
override
remove
in
a
subclass
"
)
;
}
async
update
(
record
)
{
throw
new
Error
(
"
override
update
in
a
subclass
"
)
;
}
async
itemExists
(
id
)
{
throw
new
Error
(
"
override
itemExists
in
a
subclass
"
)
;
}
async
createRecord
(
id
collection
)
{
throw
new
Error
(
"
override
createRecord
in
a
subclass
"
)
;
}
async
changeItemID
(
oldID
newID
)
{
throw
new
Error
(
"
override
changeItemID
in
a
subclass
"
)
;
}
async
getAllIDs
(
)
{
throw
new
Error
(
"
override
getAllIDs
in
a
subclass
"
)
;
}
async
wipe
(
)
{
throw
new
Error
(
"
override
wipe
in
a
subclass
"
)
;
}
}
;
this
.
EngineManager
=
function
EngineManager
(
service
)
{
this
.
service
=
service
;
this
.
_engines
=
{
}
;
this
.
_declined
=
new
Set
(
)
;
this
.
_log
=
Log
.
repository
.
getLogger
(
"
Sync
.
EngineManager
"
)
;
this
.
_log
.
level
=
Log
.
Level
[
Svc
.
Prefs
.
get
(
"
log
.
logger
.
service
.
engines
"
"
Debug
"
)
]
;
}
EngineManager
.
prototype
=
{
get
(
name
)
{
if
(
Array
.
isArray
(
name
)
)
{
let
engines
=
[
]
;
name
.
forEach
(
function
(
name
)
{
let
engine
=
this
.
get
(
name
)
;
if
(
engine
)
{
engines
.
push
(
engine
)
;
}
}
this
)
;
return
engines
;
}
let
engine
=
this
.
_engines
[
name
]
;
if
(
!
engine
)
{
this
.
_log
.
debug
(
"
Could
not
get
engine
:
"
+
name
)
;
if
(
Object
.
keys
)
{
this
.
_log
.
debug
(
"
Engines
are
:
"
+
JSON
.
stringify
(
Object
.
keys
(
this
.
_engines
)
)
)
;
}
}
return
engine
;
}
getAll
(
)
{
let
engines
=
[
]
;
for
(
let
[
engine
]
of
Object
.
entries
(
this
.
_engines
)
)
{
engines
.
push
(
engine
)
;
}
return
engines
;
}
getEnabled
(
)
{
return
this
.
getAll
(
)
.
filter
(
(
engine
)
=
>
engine
.
enabled
)
.
sort
(
(
a
b
)
=
>
a
.
syncPriority
-
b
.
syncPriority
)
;
}
get
enabledEngineNames
(
)
{
return
this
.
getEnabled
(
)
.
map
(
e
=
>
e
.
name
)
;
}
persistDeclined
(
)
{
Svc
.
Prefs
.
set
(
"
declinedEngines
"
[
.
.
.
this
.
_declined
]
.
join
(
"
"
)
)
;
}
getDeclined
(
)
{
return
[
.
.
.
this
.
_declined
]
;
}
setDeclined
(
engines
)
{
this
.
_declined
=
new
Set
(
engines
)
;
this
.
persistDeclined
(
)
;
}
isDeclined
(
engineName
)
{
return
this
.
_declined
.
has
(
engineName
)
;
}
decline
(
engines
)
{
for
(
let
e
of
engines
)
{
this
.
_declined
.
add
(
e
)
;
}
this
.
persistDeclined
(
)
;
}
undecline
(
engines
)
{
for
(
let
e
of
engines
)
{
this
.
_declined
.
delete
(
e
)
;
}
this
.
persistDeclined
(
)
;
}
declineDisabled
(
)
{
for
(
let
e
of
this
.
getAll
(
)
)
{
if
(
!
e
.
enabled
)
{
this
.
_log
.
debug
(
"
Declining
disabled
engine
"
+
e
.
name
)
;
this
.
_declined
.
add
(
e
.
name
)
;
}
}
this
.
persistDeclined
(
)
;
}
async
register
(
engineObject
)
{
if
(
Array
.
isArray
(
engineObject
)
)
{
for
(
const
e
of
engineObject
)
{
await
this
.
register
(
e
)
;
}
return
;
}
try
{
let
engine
=
new
engineObject
(
this
.
service
)
;
let
name
=
engine
.
name
;
if
(
name
in
this
.
_engines
)
{
this
.
_log
.
error
(
"
Engine
'
"
+
name
+
"
'
is
already
registered
!
"
)
;
}
else
{
if
(
engine
.
initialize
)
{
await
engine
.
initialize
(
)
;
}
this
.
_engines
[
name
]
=
engine
;
}
}
catch
(
ex
)
{
let
name
=
engineObject
|
|
"
"
;
name
=
name
.
prototype
|
|
"
"
;
name
=
name
.
name
|
|
"
"
;
this
.
_log
.
error
(
Could
not
initialize
engine
{
name
}
ex
)
;
}
}
unregister
(
val
)
{
let
name
=
val
;
if
(
val
instanceof
Engine
)
{
name
=
val
.
name
;
}
if
(
name
in
this
.
_engines
)
{
let
engine
=
this
.
_engines
[
name
]
;
delete
this
.
_engines
[
name
]
;
Async
.
promiseSpinningly
(
engine
.
finalize
(
)
)
;
}
}
clear
(
)
{
for
(
let
name
in
this
.
_engines
)
{
let
engine
=
this
.
_engines
[
name
]
;
delete
this
.
_engines
[
name
]
;
Async
.
promiseSpinningly
(
engine
.
finalize
(
)
)
;
}
}
}
;
this
.
Engine
=
function
Engine
(
name
service
)
{
if
(
!
service
)
{
throw
new
Error
(
"
Engine
must
be
associated
with
a
Service
instance
.
"
)
;
}
this
.
Name
=
name
|
|
"
Unnamed
"
;
this
.
name
=
name
.
toLowerCase
(
)
;
this
.
service
=
service
;
this
.
_notify
=
Utils
.
notify
(
"
weave
:
engine
:
"
)
;
this
.
_log
=
Log
.
repository
.
getLogger
(
"
Sync
.
Engine
.
"
+
this
.
Name
)
;
let
level
=
Svc
.
Prefs
.
get
(
"
log
.
logger
.
engine
.
"
+
this
.
name
"
Debug
"
)
;
this
.
_log
.
level
=
Log
.
Level
[
level
]
;
this
.
_modified
=
this
.
emptyChangeset
(
)
;
this
.
_tracker
;
this
.
_log
.
debug
(
"
Engine
constructed
"
)
;
}
Engine
.
prototype
=
{
_storeObj
:
Store
_trackerObj
:
Tracker
emptyChangeset
(
)
{
return
new
Changeset
(
)
;
}
eEngineAbortApplyIncoming
:
"
error
.
engine
.
abort
.
applyincoming
"
allowSkippedRecord
:
true
get
prefName
(
)
{
return
this
.
name
;
}
get
enabled
(
)
{
return
Svc
.
Prefs
.
get
(
"
engine
.
"
+
this
.
prefName
false
)
;
}
set
enabled
(
val
)
{
Svc
.
Prefs
.
set
(
"
engine
.
"
+
this
.
prefName
!
!
val
)
;
}
get
score
(
)
{
return
this
.
_tracker
.
score
;
}
get
_store
(
)
{
let
store
=
new
this
.
_storeObj
(
this
.
Name
this
)
;
this
.
__defineGetter__
(
"
_store
"
(
)
=
>
store
)
;
return
store
;
}
get
_tracker
(
)
{
let
tracker
=
new
this
.
_trackerObj
(
this
.
Name
this
)
;
this
.
__defineGetter__
(
"
_tracker
"
(
)
=
>
tracker
)
;
return
tracker
;
}
async
sync
(
)
{
if
(
!
this
.
enabled
)
{
return
false
;
}
if
(
!
this
.
_sync
)
{
throw
new
Error
(
"
engine
does
not
implement
_sync
method
"
)
;
}
return
this
.
_notify
(
"
sync
"
this
.
name
this
.
_sync
)
(
)
;
}
async
resetClient
(
)
{
if
(
!
this
.
_resetClient
)
{
throw
new
Error
(
"
engine
does
not
implement
_resetClient
method
"
)
;
}
return
this
.
_notify
(
"
reset
-
client
"
this
.
name
this
.
_resetClient
)
(
)
;
}
async
_wipeClient
(
)
{
await
this
.
resetClient
(
)
;
this
.
_log
.
debug
(
"
Deleting
all
local
data
"
)
;
this
.
_tracker
.
ignoreAll
=
true
;
await
this
.
_store
.
wipe
(
)
;
this
.
_tracker
.
ignoreAll
=
false
;
this
.
_tracker
.
clearChangedIDs
(
)
;
}
async
wipeClient
(
)
{
return
this
.
_notify
(
"
wipe
-
client
"
this
.
name
this
.
_wipeClient
)
(
)
;
}
getValidator
(
)
{
return
null
;
}
async
finalize
(
)
{
await
this
.
_tracker
.
finalize
(
)
;
}
}
;
this
.
SyncEngine
=
function
SyncEngine
(
name
service
)
{
Engine
.
call
(
this
name
|
|
"
SyncEngine
"
service
)
;
this
.
_needWeakUpload
=
new
Map
(
)
;
}
SyncEngine
.
kRecoveryStrategy
=
{
ignore
:
"
ignore
"
retry
:
"
retry
"
error
:
"
error
"
}
;
SyncEngine
.
prototype
=
{
__proto__
:
Engine
.
prototype
_recordObj
:
CryptoWrapper
version
:
1
_defaultSort
:
undefined
syncPriority
:
0
downloadLimit
:
null
guidFetchBatchSize
:
DEFAULT_GUID_FETCH_BATCH_SIZE
applyIncomingBatchSize
:
DEFAULT_STORE_BATCH_SIZE
async
initialize
(
)
{
await
this
.
loadToFetch
(
)
;
await
this
.
loadPreviousFailed
(
)
;
this
.
_log
.
debug
(
"
SyncEngine
initialized
"
this
.
name
)
;
}
get
storageURL
(
)
{
return
this
.
service
.
storageURL
;
}
get
engineURL
(
)
{
return
this
.
storageURL
+
this
.
name
;
}
get
cryptoKeysURL
(
)
{
return
this
.
storageURL
+
"
crypto
/
keys
"
;
}
get
metaURL
(
)
{
return
this
.
storageURL
+
"
meta
/
global
"
;
}
get
syncID
(
)
{
let
syncID
=
Svc
.
Prefs
.
get
(
this
.
name
+
"
.
syncID
"
"
"
)
;
return
syncID
=
=
"
"
?
this
.
syncID
=
Utils
.
makeGUID
(
)
:
syncID
;
}
set
syncID
(
value
)
{
Svc
.
Prefs
.
set
(
this
.
name
+
"
.
syncID
"
value
)
;
}
get
lastSync
(
)
{
return
parseFloat
(
Svc
.
Prefs
.
get
(
this
.
name
+
"
.
lastSync
"
"
0
"
)
)
;
}
set
lastSync
(
value
)
{
Svc
.
Prefs
.
reset
(
this
.
name
+
"
.
lastSync
"
)
;
Svc
.
Prefs
.
set
(
this
.
name
+
"
.
lastSync
"
value
.
toString
(
)
)
;
}
resetLastSync
(
)
{
this
.
_log
.
debug
(
"
Resetting
"
+
this
.
name
+
"
last
sync
time
"
)
;
Svc
.
Prefs
.
reset
(
this
.
name
+
"
.
lastSync
"
)
;
Svc
.
Prefs
.
set
(
this
.
name
+
"
.
lastSync
"
"
0
"
)
;
this
.
lastSyncLocal
=
0
;
}
get
toFetch
(
)
{
return
this
.
_toFetch
;
}
set
toFetch
(
val
)
{
if
(
val
+
"
"
=
=
this
.
_toFetch
)
{
return
;
}
this
.
_toFetch
=
val
;
Utils
.
namedTimer
(
function
(
)
{
try
{
Async
.
promiseSpinningly
(
Utils
.
jsonSave
(
"
toFetch
/
"
+
this
.
name
this
val
)
)
;
}
catch
(
error
)
{
this
.
_log
.
error
(
"
Failed
to
read
JSON
records
to
fetch
"
error
)
;
}
}
0
this
"
_toFetchDelay
"
)
;
}
async
loadToFetch
(
)
{
this
.
_toFetch
=
[
]
;
let
toFetch
=
await
Utils
.
jsonLoad
(
"
toFetch
/
"
+
this
.
name
this
)
;
if
(
toFetch
)
{
this
.
_toFetch
=
toFetch
;
}
}
get
previousFailed
(
)
{
return
this
.
_previousFailed
;
}
set
previousFailed
(
val
)
{
if
(
val
+
"
"
=
=
this
.
_previousFailed
)
{
return
;
}
this
.
_previousFailed
=
val
;
Utils
.
namedTimer
(
function
(
)
{
Utils
.
jsonSave
(
"
failed
/
"
+
this
.
name
this
val
)
.
then
(
(
)
=
>
{
this
.
_log
.
debug
(
"
Successfully
wrote
previousFailed
.
"
)
;
}
)
.
catch
(
(
error
)
=
>
{
this
.
_log
.
error
(
"
Failed
to
set
previousFailed
"
error
)
;
}
)
;
}
0
this
"
_previousFailedDelay
"
)
;
}
async
loadPreviousFailed
(
)
{
this
.
_previousFailed
=
[
]
;
let
previousFailed
=
await
Utils
.
jsonLoad
(
"
failed
/
"
+
this
.
name
this
)
;
if
(
previousFailed
)
{
this
.
_previousFailed
=
previousFailed
;
}
}
get
lastSyncLocal
(
)
{
return
parseInt
(
Svc
.
Prefs
.
get
(
this
.
name
+
"
.
lastSyncLocal
"
"
0
"
)
10
)
;
}
set
lastSyncLocal
(
value
)
{
Svc
.
Prefs
.
set
(
this
.
name
+
"
.
lastSyncLocal
"
value
.
toString
(
)
)
;
}
get
maxRecordPayloadBytes
(
)
{
let
serverConfiguration
=
this
.
service
.
serverConfiguration
;
if
(
serverConfiguration
&
&
serverConfiguration
.
max_record_payload_bytes
)
{
return
serverConfiguration
.
max_record_payload_bytes
;
}
return
DEFAULT_MAX_RECORD_PAYLOAD_BYTES
;
}
async
getChangedIDs
(
)
{
return
this
.
_tracker
.
changedIDs
;
}
async
_createRecord
(
id
)
{
let
record
=
await
this
.
_store
.
createRecord
(
id
this
.
name
)
;
record
.
id
=
id
;
record
.
collection
=
this
.
name
;
return
record
;
}
_createTombstone
(
id
)
{
let
tombstone
=
new
this
.
_recordObj
(
this
.
name
id
)
;
tombstone
.
id
=
id
;
tombstone
.
collection
=
this
.
name
;
tombstone
.
deleted
=
true
;
return
tombstone
;
}
addForWeakUpload
(
id
{
forceTombstone
=
false
}
=
{
}
)
{
this
.
_needWeakUpload
.
set
(
id
{
forceTombstone
}
)
;
}
async
_syncStartup
(
)
{
let
metaGlobal
=
await
this
.
service
.
recordManager
.
get
(
this
.
metaURL
)
;
let
engines
=
metaGlobal
.
payload
.
engines
|
|
{
}
;
let
engineData
=
engines
[
this
.
name
]
|
|
{
}
;
let
needsWipe
=
false
;
if
(
(
engineData
.
version
|
|
0
)
<
this
.
version
)
{
this
.
_log
.
debug
(
"
Old
engine
data
:
"
+
[
engineData
.
version
this
.
version
]
)
;
needsWipe
=
true
;
this
.
syncID
=
"
"
;
engineData
.
version
=
this
.
version
;
engineData
.
syncID
=
this
.
syncID
;
engines
[
this
.
name
]
=
engineData
;
metaGlobal
.
payload
.
engines
=
engines
;
metaGlobal
.
changed
=
true
;
}
else
if
(
engineData
.
version
>
this
.
version
)
{
let
error
=
new
String
(
"
New
data
:
"
+
[
engineData
.
version
this
.
version
]
)
;
error
.
failureCode
=
VERSION_OUT_OF_DATE
;
throw
error
;
}
else
if
(
engineData
.
syncID
!
=
this
.
syncID
)
{
this
.
_log
.
debug
(
"
Engine
syncIDs
:
"
+
[
engineData
.
syncID
this
.
syncID
]
)
;
this
.
syncID
=
engineData
.
syncID
;
await
this
.
_resetClient
(
)
;
}
if
(
needsWipe
)
{
await
this
.
wipeServer
(
)
;
}
this
.
lastSyncLocal
=
Date
.
now
(
)
;
let
initialChanges
;
if
(
this
.
lastSync
)
{
initialChanges
=
await
this
.
pullNewChanges
(
)
;
}
else
{
this
.
_log
.
debug
(
"
First
sync
uploading
all
items
"
)
;
initialChanges
=
await
this
.
pullAllChanges
(
)
;
}
this
.
_modified
.
replace
(
initialChanges
)
;
this
.
_tracker
.
clearChangedIDs
(
)
;
this
.
_log
.
info
(
this
.
_modified
.
count
(
)
+
"
outgoing
items
pre
-
reconciliation
"
)
;
this
.
_delete
=
{
}
;
}
itemSource
(
)
{
return
new
Collection
(
this
.
engineURL
this
.
_recordObj
this
.
service
)
;
}
async
_processIncoming
(
newitems
)
{
this
.
_log
.
trace
(
"
Downloading
&
applying
server
changes
"
)
;
let
batchSize
=
this
.
downloadLimit
|
|
Infinity
;
if
(
!
newitems
)
{
newitems
=
this
.
itemSource
(
)
;
}
if
(
this
.
_defaultSort
)
{
newitems
.
sort
=
this
.
_defaultSort
;
}
newitems
.
newer
=
this
.
lastSync
;
newitems
.
full
=
true
;
newitems
.
limit
=
batchSize
;
let
count
=
{
applied
:
0
failed
:
0
newFailed
:
0
reconciled
:
0
}
;
let
handled
=
[
]
;
let
applyBatch
=
[
]
;
let
failed
=
[
]
;
let
failedInPreviousSync
=
this
.
previousFailed
;
let
fetchBatch
=
Utils
.
arrayUnion
(
this
.
toFetch
failedInPreviousSync
)
;
this
.
previousFailed
=
[
]
;
let
aborting
=
undefined
;
async
function
doApplyBatch
(
)
{
this
.
_tracker
.
ignoreAll
=
true
;
try
{
failed
=
failed
.
concat
(
(
await
this
.
_store
.
applyIncomingBatch
(
applyBatch
)
)
)
;
}
catch
(
ex
)
{
if
(
Async
.
isShutdownException
(
ex
)
)
{
throw
ex
;
}
this
.
_log
.
warn
(
"
Got
exception
aborting
processIncoming
"
ex
)
;
aborting
=
ex
;
}
this
.
_tracker
.
ignoreAll
=
false
;
applyBatch
=
[
]
;
}
async
function
doApplyBatchAndPersistFailed
(
)
{
if
(
applyBatch
.
length
)
{
await
doApplyBatch
.
call
(
this
)
;
}
if
(
failed
.
length
)
{
this
.
previousFailed
=
Utils
.
arrayUnion
(
failed
this
.
previousFailed
)
;
count
.
failed
+
=
failed
.
length
;
this
.
_log
.
debug
(
"
Records
that
failed
to
apply
:
"
+
failed
)
;
failed
=
[
]
;
}
}
let
key
=
this
.
service
.
collectionKeys
.
keyForCollection
(
this
.
name
)
;
let
self
=
this
;
let
recordHandler
=
async
function
(
item
)
{
if
(
aborting
)
{
return
;
}
if
(
self
.
lastModified
=
=
null
|
|
item
.
modified
>
self
.
lastModified
)
self
.
lastModified
=
item
.
modified
;
item
.
collection
=
self
.
name
;
handled
.
push
(
item
.
id
)
;
try
{
try
{
item
.
decrypt
(
key
)
;
}
catch
(
ex
)
{
if
(
!
Utils
.
isHMACMismatch
(
ex
)
)
{
throw
ex
;
}
let
strategy
=
await
self
.
handleHMACMismatch
(
item
true
)
;
if
(
strategy
=
=
SyncEngine
.
kRecoveryStrategy
.
retry
)
{
try
{
self
.
_log
.
info
(
"
Trying
decrypt
again
.
.
.
"
)
;
key
=
self
.
service
.
collectionKeys
.
keyForCollection
(
self
.
name
)
;
item
.
decrypt
(
key
)
;
strategy
=
null
;
}
catch
(
ex
)
{
if
(
!
Utils
.
isHMACMismatch
(
ex
)
)
{
throw
ex
;
}
strategy
=
await
self
.
handleHMACMismatch
(
item
false
)
;
}
}
switch
(
strategy
)
{
case
null
:
break
;
case
SyncEngine
.
kRecoveryStrategy
.
retry
:
self
.
_log
.
debug
(
"
Ignoring
second
retry
suggestion
.
"
)
;
case
SyncEngine
.
kRecoveryStrategy
.
error
:
self
.
_log
.
warn
(
"
Error
decrypting
record
"
ex
)
;
failed
.
push
(
item
.
id
)
;
return
;
case
SyncEngine
.
kRecoveryStrategy
.
ignore
:
self
.
_log
.
debug
(
"
Ignoring
record
"
+
item
.
id
+
"
with
bad
HMAC
:
already
handled
.
"
)
;
return
;
}
}
}
catch
(
ex
)
{
if
(
Async
.
isShutdownException
(
ex
)
)
{
throw
ex
;
}
self
.
_log
.
warn
(
"
Error
decrypting
record
"
ex
)
;
failed
.
push
(
item
.
id
)
;
return
;
}
if
(
self
.
_shouldDeleteRemotely
(
item
)
)
{
self
.
_log
.
trace
(
"
Deleting
item
from
server
without
applying
"
item
)
;
self
.
_deleteId
(
item
.
id
)
;
return
;
}
let
shouldApply
;
try
{
shouldApply
=
await
self
.
_reconcile
(
item
)
;
}
catch
(
ex
)
{
if
(
ex
.
code
=
=
Engine
.
prototype
.
eEngineAbortApplyIncoming
)
{
self
.
_log
.
warn
(
"
Reconciliation
failed
:
aborting
incoming
processing
.
"
)
;
failed
.
push
(
item
.
id
)
;
aborting
=
ex
.
cause
;
}
else
if
(
!
Async
.
isShutdownException
(
ex
)
)
{
self
.
_log
.
warn
(
"
Failed
to
reconcile
incoming
record
"
+
item
.
id
ex
)
;
failed
.
push
(
item
.
id
)
;
return
;
}
else
{
throw
ex
;
}
}
if
(
shouldApply
)
{
count
.
applied
+
+
;
applyBatch
.
push
(
item
)
;
}
else
{
count
.
reconciled
+
+
;
self
.
_log
.
trace
(
"
Skipping
reconciled
incoming
item
"
+
item
.
id
)
;
}
if
(
applyBatch
.
length
=
=
self
.
applyIncomingBatchSize
)
{
await
doApplyBatch
.
call
(
self
)
;
}
}
;
if
(
this
.
lastModified
=
=
null
|
|
this
.
lastModified
>
this
.
lastSync
)
{
let
{
response
records
}
=
await
newitems
.
getBatched
(
)
;
if
(
!
response
.
success
)
{
response
.
failureCode
=
ENGINE_DOWNLOAD_FAIL
;
throw
response
;
}
let
maybeYield
=
Async
.
jankYielder
(
)
;
for
(
let
record
of
records
)
{
await
maybeYield
(
)
;
await
recordHandler
(
record
)
;
}
await
doApplyBatchAndPersistFailed
.
call
(
this
)
;
if
(
aborting
)
{
throw
aborting
;
}
}
if
(
handled
.
length
=
=
newitems
.
limit
)
{
let
guidColl
=
new
Collection
(
this
.
engineURL
null
this
.
service
)
;
guidColl
.
limit
=
this
.
downloadLimit
;
guidColl
.
newer
=
this
.
lastSync
;
guidColl
.
sort
=
"
index
"
;
let
guids
=
await
guidColl
.
get
(
)
;
if
(
!
guids
.
success
)
throw
guids
;
let
extra
=
Utils
.
arraySub
(
guids
.
obj
handled
)
;
if
(
extra
.
length
>
0
)
{
fetchBatch
=
Utils
.
arrayUnion
(
extra
fetchBatch
)
;
this
.
toFetch
=
Utils
.
arrayUnion
(
extra
this
.
toFetch
)
;
}
}
if
(
this
.
lastSync
<
this
.
lastModified
)
{
this
.
lastSync
=
this
.
lastModified
;
}
batchSize
=
this
.
guidFetchBatchSize
;
while
(
fetchBatch
.
length
&
&
!
aborting
)
{
newitems
.
limit
=
0
;
newitems
.
newer
=
0
;
newitems
.
ids
=
fetchBatch
.
slice
(
0
batchSize
)
;
let
resp
=
await
newitems
.
get
(
)
;
if
(
!
resp
.
success
)
{
resp
.
failureCode
=
ENGINE_DOWNLOAD_FAIL
;
throw
resp
;
}
let
maybeYield
=
Async
.
jankYielder
(
)
;
for
(
let
json
of
resp
.
obj
)
{
await
maybeYield
(
)
;
let
record
=
new
this
.
_recordObj
(
)
;
record
.
deserialize
(
json
)
;
await
recordHandler
(
record
)
;
}
fetchBatch
=
fetchBatch
.
slice
(
batchSize
)
;
this
.
toFetch
=
Utils
.
arraySub
(
this
.
toFetch
newitems
.
ids
)
;
this
.
previousFailed
=
Utils
.
arrayUnion
(
this
.
previousFailed
failed
)
;
if
(
failed
.
length
)
{
count
.
failed
+
=
failed
.
length
;
this
.
_log
.
debug
(
"
Records
that
failed
to
apply
:
"
+
failed
)
;
}
failed
=
[
]
;
if
(
aborting
)
{
throw
aborting
;
}
if
(
this
.
lastSync
<
this
.
lastModified
)
{
this
.
lastSync
=
this
.
lastModified
;
}
}
await
doApplyBatchAndPersistFailed
.
call
(
this
)
;
count
.
newFailed
=
this
.
previousFailed
.
reduce
(
(
count
engine
)
=
>
{
if
(
failedInPreviousSync
.
indexOf
(
engine
)
=
=
-
1
)
{
count
+
+
;
}
return
count
;
}
0
)
;
count
.
succeeded
=
Math
.
max
(
0
count
.
applied
-
count
.
failed
)
;
this
.
_log
.
info
(
[
"
Records
:
"
count
.
applied
"
applied
"
count
.
succeeded
"
successfully
"
count
.
failed
"
failed
to
apply
"
count
.
newFailed
"
newly
failed
to
apply
"
count
.
reconciled
"
reconciled
.
"
]
.
join
(
"
"
)
)
;
Observers
.
notify
(
"
weave
:
engine
:
sync
:
applied
"
count
this
.
name
)
;
}
_shouldDeleteRemotely
(
remoteItem
)
{
return
false
;
}
async
_findDupe
(
item
)
{
}
beforeRecordDiscard
(
localRecord
remoteRecord
remoteIsNewer
)
{
}
async
_shouldReviveRemotelyDeletedRecord
(
remoteItem
)
{
return
true
;
}
_deleteId
(
id
)
{
this
.
_tracker
.
removeChangedID
(
id
)
;
this
.
_noteDeletedId
(
id
)
;
}
_noteDeletedId
(
id
)
{
if
(
this
.
_delete
.
ids
=
=
null
)
this
.
_delete
.
ids
=
[
id
]
;
else
this
.
_delete
.
ids
.
push
(
id
)
;
}
async
_switchItemToDupe
(
localDupeGUID
incomingItem
)
{
this
.
_deleteId
(
localDupeGUID
)
;
this
.
_log
.
debug
(
"
Switching
local
ID
to
incoming
:
"
+
localDupeGUID
+
"
-
>
"
+
incomingItem
.
id
)
;
return
this
.
_store
.
changeItemID
(
localDupeGUID
incomingItem
.
id
)
;
}
async
_reconcile
(
item
)
{
if
(
this
.
_log
.
level
<
=
Log
.
Level
.
Trace
)
{
this
.
_log
.
trace
(
"
Incoming
:
"
+
item
)
;
}
let
existsLocally
=
await
this
.
_store
.
itemExists
(
item
.
id
)
;
let
locallyModified
=
this
.
_modified
.
has
(
item
.
id
)
;
let
remoteAge
=
AsyncResource
.
serverTime
-
item
.
modified
;
let
localAge
=
locallyModified
?
(
Date
.
now
(
)
/
1000
-
this
.
_modified
.
getModifiedTimestamp
(
item
.
id
)
)
:
null
;
let
remoteIsNewer
=
remoteAge
<
localAge
;
this
.
_log
.
trace
(
"
Reconciling
"
+
item
.
id
+
"
.
exists
=
"
+
existsLocally
+
"
;
modified
=
"
+
locallyModified
+
"
;
local
age
=
"
+
localAge
+
"
;
incoming
age
=
"
+
remoteAge
)
;
if
(
item
.
deleted
)
{
if
(
!
existsLocally
)
{
this
.
_log
.
trace
(
"
Ignoring
incoming
item
because
it
was
deleted
and
"
+
"
the
item
does
not
exist
locally
.
"
)
;
return
false
;
}
if
(
!
locallyModified
)
{
this
.
_log
.
trace
(
"
Applying
incoming
delete
because
the
local
item
"
+
"
exists
and
isn
'
t
modified
.
"
)
;
return
true
;
}
this
.
_log
.
trace
(
"
Incoming
record
is
deleted
but
we
had
local
changes
.
"
)
;
if
(
remoteIsNewer
)
{
this
.
_log
.
trace
(
"
Remote
record
is
newer
-
-
deleting
local
record
.
"
)
;
return
true
;
}
let
willRevive
=
await
this
.
_shouldReviveRemotelyDeletedRecord
(
item
)
;
this
.
_log
.
trace
(
"
Local
record
is
newer
-
-
reviving
?
"
+
willRevive
)
;
return
!
willRevive
;
}
if
(
!
existsLocally
)
{
let
localDupeGUID
=
await
this
.
_findDupe
(
item
)
;
if
(
localDupeGUID
)
{
this
.
_log
.
trace
(
"
Local
item
"
+
localDupeGUID
+
"
is
a
duplicate
for
"
+
"
incoming
item
"
+
item
.
id
)
;
existsLocally
=
await
this
.
_store
.
itemExists
(
localDupeGUID
)
;
if
(
this
.
_modified
.
has
(
localDupeGUID
)
)
{
locallyModified
=
true
;
localAge
=
this
.
_tracker
.
_now
(
)
-
this
.
_modified
.
getModifiedTimestamp
(
localDupeGUID
)
;
remoteIsNewer
=
remoteAge
<
localAge
;
this
.
_modified
.
changeID
(
localDupeGUID
item
.
id
)
;
}
else
{
locallyModified
=
false
;
localAge
=
null
;
}
await
this
.
_switchItemToDupe
(
localDupeGUID
item
)
;
this
.
_log
.
debug
(
"
Local
item
after
duplication
:
age
=
"
+
localAge
+
"
;
modified
=
"
+
locallyModified
+
"
;
exists
=
"
+
existsLocally
)
;
}
else
{
this
.
_log
.
trace
(
"
No
duplicate
found
for
incoming
item
:
"
+
item
.
id
)
;
}
}
if
(
!
existsLocally
)
{
if
(
!
locallyModified
)
{
this
.
_log
.
trace
(
"
Applying
incoming
because
local
item
does
not
exist
"
+
"
and
was
not
deleted
.
"
)
;
return
true
;
}
if
(
remoteIsNewer
)
{
this
.
_log
.
trace
(
"
Applying
incoming
because
local
item
was
deleted
"
+
"
before
the
incoming
item
was
changed
.
"
)
;
this
.
_modified
.
delete
(
item
.
id
)
;
return
true
;
}
this
.
_log
.
trace
(
"
Ignoring
incoming
item
because
the
local
item
'
s
"
+
"
deletion
is
newer
.
"
)
;
return
false
;
}
let
localRecord
=
await
this
.
_createRecord
(
item
.
id
)
;
let
recordsEqual
=
Utils
.
deepEquals
(
item
.
cleartext
localRecord
.
cleartext
)
;
if
(
recordsEqual
)
{
this
.
_log
.
trace
(
"
Ignoring
incoming
item
because
the
local
item
is
"
+
"
identical
.
"
)
;
this
.
_modified
.
delete
(
item
.
id
)
;
return
false
;
}
if
(
!
locallyModified
)
{
this
.
_log
.
trace
(
"
Applying
incoming
record
because
no
local
conflicts
.
"
)
;
return
true
;
}
this
.
_log
.
warn
(
"
DATA
LOSS
:
Both
local
and
remote
changes
to
record
:
"
+
item
.
id
)
;
if
(
!
remoteIsNewer
)
{
this
.
beforeRecordDiscard
(
localRecord
item
remoteIsNewer
)
;
}
return
remoteIsNewer
;
}
async
_uploadOutgoing
(
)
{
this
.
_log
.
trace
(
"
Uploading
local
changes
to
server
.
"
)
;
let
up
=
new
Collection
(
this
.
engineURL
null
this
.
service
)
;
let
modifiedIDs
=
new
Set
(
this
.
_modified
.
ids
(
)
)
;
for
(
let
id
of
this
.
_needWeakUpload
.
keys
(
)
)
{
modifiedIDs
.
add
(
id
)
;
}
let
counts
=
{
failed
:
0
sent
:
0
}
;
if
(
modifiedIDs
.
size
)
{
this
.
_log
.
trace
(
"
Preparing
"
+
modifiedIDs
.
size
+
"
outgoing
records
"
)
;
counts
.
sent
=
modifiedIDs
.
size
;
let
failed
=
[
]
;
let
successful
=
[
]
;
let
handleResponse
=
async
(
resp
batchOngoing
=
false
)
=
>
{
if
(
!
resp
.
success
)
{
this
.
_log
.
debug
(
"
Uploading
records
failed
:
"
+
resp
)
;
resp
.
failureCode
=
resp
.
status
=
=
412
?
ENGINE_BATCH_INTERRUPTED
:
ENGINE_UPLOAD_FAIL
;
throw
resp
;
}
failed
=
failed
.
concat
(
Object
.
keys
(
resp
.
obj
.
failed
)
)
;
successful
=
successful
.
concat
(
resp
.
obj
.
success
)
;
if
(
batchOngoing
)
{
return
;
}
let
modified
=
resp
.
headers
[
"
x
-
weave
-
timestamp
"
]
;
if
(
modified
>
this
.
lastSync
)
{
this
.
lastSync
=
modified
;
}
if
(
failed
.
length
&
&
this
.
_log
.
level
<
=
Log
.
Level
.
Debug
)
{
this
.
_log
.
debug
(
"
Records
that
will
be
uploaded
again
because
"
+
"
the
server
couldn
'
t
store
them
:
"
+
failed
.
join
(
"
"
)
)
;
}
counts
.
failed
+
=
failed
.
length
;
for
(
let
id
of
successful
)
{
this
.
_modified
.
delete
(
id
)
;
}
await
this
.
_onRecordsWritten
(
successful
failed
)
;
failed
.
length
=
0
;
successful
.
length
=
0
;
}
;
let
postQueue
=
up
.
newPostQueue
(
this
.
_log
this
.
lastSync
handleResponse
)
;
for
(
let
id
of
modifiedIDs
)
{
let
out
;
let
ok
=
false
;
try
{
let
{
forceTombstone
=
false
}
=
this
.
_needWeakUpload
.
get
(
id
)
|
|
{
}
;
if
(
forceTombstone
)
{
out
=
await
this
.
_createTombstone
(
id
)
;
}
else
{
out
=
await
this
.
_createRecord
(
id
)
;
}
if
(
this
.
_log
.
level
<
=
Log
.
Level
.
Trace
)
this
.
_log
.
trace
(
"
Outgoing
:
"
+
out
)
;
out
.
encrypt
(
this
.
service
.
collectionKeys
.
keyForCollection
(
this
.
name
)
)
;
let
payloadLength
=
JSON
.
stringify
(
out
.
payload
)
.
length
;
if
(
payloadLength
>
this
.
maxRecordPayloadBytes
)
{
if
(
this
.
allowSkippedRecord
)
{
this
.
_modified
.
delete
(
id
)
;
}
throw
new
Error
(
Payload
too
big
:
{
payloadLength
}
bytes
)
;
}
ok
=
true
;
}
catch
(
ex
)
{
this
.
_log
.
warn
(
"
Error
creating
record
"
ex
)
;
+
+
counts
.
failed
;
if
(
Async
.
isShutdownException
(
ex
)
|
|
!
this
.
allowSkippedRecord
)
{
if
(
!
this
.
allowSkippedRecord
)
{
Observers
.
notify
(
"
weave
:
engine
:
sync
:
uploaded
"
counts
this
.
name
)
;
}
throw
ex
;
}
}
if
(
ok
)
{
let
{
enqueued
error
}
=
await
postQueue
.
enqueue
(
out
)
;
if
(
!
enqueued
)
{
+
+
counts
.
failed
;
if
(
!
this
.
allowSkippedRecord
)
{
Observers
.
notify
(
"
weave
:
engine
:
sync
:
uploaded
"
counts
this
.
name
)
;
throw
error
;
}
this
.
_modified
.
delete
(
id
)
;
this
.
_log
.
warn
(
Failed
to
enqueue
record
"
{
id
}
"
(
skipping
)
error
)
;
}
}
await
Async
.
promiseYield
(
)
;
}
await
postQueue
.
flush
(
true
)
;
}
this
.
_needWeakUpload
.
clear
(
)
;
if
(
counts
.
sent
|
|
counts
.
failed
)
{
Observers
.
notify
(
"
weave
:
engine
:
sync
:
uploaded
"
counts
this
.
name
)
;
}
}
async
_onRecordsWritten
(
succeeded
failed
)
{
}
async
_syncFinish
(
)
{
this
.
_log
.
trace
(
"
Finishing
up
sync
"
)
;
this
.
_tracker
.
resetScore
(
)
;
let
doDelete
=
async
(
key
val
)
=
>
{
let
coll
=
new
Collection
(
this
.
engineURL
this
.
_recordObj
this
.
service
)
;
coll
[
key
]
=
val
;
await
coll
.
delete
(
)
;
}
;
for
(
let
[
key
val
]
of
Object
.
entries
(
this
.
_delete
)
)
{
delete
this
.
_delete
[
key
]
;
if
(
key
!
=
"
ids
"
|
|
val
.
length
<
=
100
)
await
doDelete
(
key
val
)
;
else
{
while
(
val
.
length
>
0
)
{
await
doDelete
(
key
val
.
slice
(
0
100
)
)
;
val
=
val
.
slice
(
100
)
;
}
}
}
}
async
_syncCleanup
(
)
{
this
.
_needWeakUpload
.
clear
(
)
;
if
(
!
this
.
_modified
)
{
return
;
}
try
{
await
this
.
trackRemainingChanges
(
)
;
}
finally
{
this
.
_modified
.
clear
(
)
;
}
}
async
_sync
(
)
{
try
{
await
this
.
_syncStartup
(
)
;
Observers
.
notify
(
"
weave
:
engine
:
sync
:
status
"
"
process
-
incoming
"
)
;
await
this
.
_processIncoming
(
)
;
Observers
.
notify
(
"
weave
:
engine
:
sync
:
status
"
"
upload
-
outgoing
"
)
;
await
this
.
_uploadOutgoing
(
)
;
await
this
.
_syncFinish
(
)
;
}
finally
{
await
this
.
_syncCleanup
(
)
;
}
}
async
canDecrypt
(
)
{
let
canDecrypt
=
false
;
let
test
=
new
Collection
(
this
.
engineURL
this
.
_recordObj
this
.
service
)
;
test
.
limit
=
1
;
test
.
sort
=
"
newest
"
;
test
.
full
=
true
;
let
key
=
this
.
service
.
collectionKeys
.
keyForCollection
(
this
.
name
)
;
try
{
this
.
_log
.
trace
(
"
Trying
to
decrypt
a
record
from
the
server
.
.
"
)
;
let
json
=
(
await
test
.
get
(
)
)
.
obj
[
0
]
;
let
record
=
new
this
.
_recordObj
(
)
;
record
.
deserialize
(
json
)
;
record
.
decrypt
(
key
)
;
canDecrypt
=
true
;
}
catch
(
ex
)
{
if
(
Async
.
isShutdownException
(
ex
)
)
{
throw
ex
;
}
this
.
_log
.
debug
(
"
Failed
test
decrypt
"
ex
)
;
}
return
canDecrypt
;
}
async
_resetClient
(
)
{
this
.
resetLastSync
(
)
;
this
.
previousFailed
=
[
]
;
this
.
toFetch
=
[
]
;
this
.
_needWeakUpload
.
clear
(
)
;
}
async
wipeServer
(
)
{
let
response
=
await
this
.
service
.
resource
(
this
.
engineURL
)
.
delete
(
)
;
if
(
response
.
status
!
=
200
&
&
response
.
status
!
=
404
)
{
throw
response
;
}
await
this
.
_resetClient
(
)
;
}
async
removeClientData
(
)
{
}
async
handleHMACMismatch
(
item
mayRetry
)
{
return
(
(
await
this
.
service
.
handleHMACEvent
(
)
)
&
&
mayRetry
)
?
SyncEngine
.
kRecoveryStrategy
.
retry
:
SyncEngine
.
kRecoveryStrategy
.
error
;
}
async
pullAllChanges
(
)
{
let
changes
=
{
}
;
let
ids
=
await
this
.
_store
.
getAllIDs
(
)
;
for
(
let
id
in
ids
)
{
changes
[
id
]
=
0
;
}
return
changes
;
}
async
pullNewChanges
(
)
{
return
this
.
getChangedIDs
(
)
;
}
async
trackRemainingChanges
(
)
{
for
(
let
[
id
change
]
of
this
.
_modified
.
entries
(
)
)
{
this
.
_tracker
.
addChangedID
(
id
change
)
;
}
}
}
;
class
Changeset
{
constructor
(
)
{
this
.
changes
=
{
}
;
}
getModifiedTimestamp
(
id
)
{
return
this
.
changes
[
id
]
;
}
set
(
id
change
)
{
this
.
changes
[
id
]
=
change
;
}
insert
(
changes
)
{
Object
.
assign
(
this
.
changes
changes
)
;
}
replace
(
changes
)
{
this
.
changes
=
changes
;
}
has
(
id
)
{
return
id
in
this
.
changes
;
}
delete
(
id
)
{
delete
this
.
changes
[
id
]
;
}
changeID
(
oldID
newID
)
{
this
.
changes
[
newID
]
=
this
.
changes
[
oldID
]
;
delete
this
.
changes
[
oldID
]
;
}
ids
(
)
{
return
Object
.
keys
(
this
.
changes
)
;
}
entries
(
)
{
return
Object
.
entries
(
this
.
changes
)
;
}
count
(
)
{
return
this
.
ids
(
)
.
length
;
}
clear
(
)
{
this
.
changes
=
{
}
;
}
}
