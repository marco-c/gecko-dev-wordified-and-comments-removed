var
EXPORTED_SYMBOLS
=
[
"
EngineManager
"
"
SyncEngine
"
"
Tracker
"
"
Store
"
"
Changeset
"
]
;
const
{
XPCOMUtils
}
=
ChromeUtils
.
import
(
"
resource
:
/
/
gre
/
modules
/
XPCOMUtils
.
jsm
"
)
;
const
{
JSONFile
}
=
ChromeUtils
.
import
(
"
resource
:
/
/
gre
/
modules
/
JSONFile
.
jsm
"
)
;
const
{
Log
}
=
ChromeUtils
.
import
(
"
resource
:
/
/
gre
/
modules
/
Log
.
jsm
"
)
;
const
{
Async
}
=
ChromeUtils
.
import
(
"
resource
:
/
/
services
-
common
/
async
.
js
"
)
;
const
{
Observers
}
=
ChromeUtils
.
import
(
"
resource
:
/
/
services
-
common
/
observers
.
js
"
)
;
const
{
DEFAULT_DOWNLOAD_BATCH_SIZE
DEFAULT_GUID_FETCH_BATCH_SIZE
ENGINE_BATCH_INTERRUPTED
ENGINE_DOWNLOAD_FAIL
ENGINE_UPLOAD_FAIL
VERSION_OUT_OF_DATE
}
=
ChromeUtils
.
import
(
"
resource
:
/
/
services
-
sync
/
constants
.
js
"
)
;
const
{
Collection
CryptoWrapper
}
=
ChromeUtils
.
import
(
"
resource
:
/
/
services
-
sync
/
record
.
js
"
)
;
const
{
Resource
}
=
ChromeUtils
.
import
(
"
resource
:
/
/
services
-
sync
/
resource
.
js
"
)
;
const
{
SerializableSet
Svc
Utils
}
=
ChromeUtils
.
import
(
"
resource
:
/
/
services
-
sync
/
util
.
js
"
)
;
XPCOMUtils
.
defineLazyModuleGetters
(
this
{
fxAccounts
:
"
resource
:
/
/
gre
/
modules
/
FxAccounts
.
jsm
"
OS
:
"
resource
:
/
/
gre
/
modules
/
osfile
.
jsm
"
PlacesUtils
:
"
resource
:
/
/
gre
/
modules
/
PlacesUtils
.
jsm
"
}
)
;
function
ensureDirectory
(
path
)
{
let
basename
=
OS
.
Path
.
dirname
(
path
)
;
return
OS
.
File
.
makeDir
(
basename
{
from
:
OS
.
Constants
.
Path
.
profileDir
}
)
;
}
function
Tracker
(
name
engine
)
{
if
(
!
engine
)
{
throw
new
Error
(
"
Tracker
must
be
associated
with
an
Engine
instance
.
"
)
;
}
name
=
name
|
|
"
Unnamed
"
;
this
.
name
=
this
.
file
=
name
.
toLowerCase
(
)
;
this
.
engine
=
engine
;
this
.
_log
=
Log
.
repository
.
getLogger
(
Sync
.
Engine
.
{
name
}
.
Tracker
)
;
this
.
_score
=
0
;
this
.
_ignored
=
[
]
;
this
.
_storage
=
new
JSONFile
(
{
path
:
Utils
.
jsonFilePath
(
"
changes
/
"
+
this
.
file
)
dataPostProcessor
:
json
=
>
this
.
_dataPostProcessor
(
json
)
beforeSave
:
(
)
=
>
this
.
_beforeSave
(
)
}
)
;
this
.
ignoreAll
=
false
;
this
.
asyncObserver
=
Async
.
asyncObserver
(
this
this
.
_log
)
;
}
Tracker
.
prototype
=
{
get
score
(
)
{
return
this
.
_score
;
}
_dataPostProcessor
(
json
)
{
return
(
typeof
json
=
=
"
object
"
&
&
json
)
|
|
{
}
;
}
_beforeSave
(
)
{
return
ensureDirectory
(
this
.
_storage
.
path
)
;
}
set
score
(
value
)
{
this
.
_score
=
value
;
Observers
.
notify
(
"
weave
:
engine
:
score
:
updated
"
this
.
name
)
;
}
resetScore
(
)
{
this
.
_score
=
0
;
}
persistChangedIDs
:
true
async
getChangedIDs
(
)
{
await
this
.
_storage
.
load
(
)
;
return
this
.
_storage
.
data
;
}
_saveChangedIDs
(
)
{
if
(
!
this
.
persistChangedIDs
)
{
this
.
_log
.
debug
(
"
Not
saving
changedIDs
.
"
)
;
return
;
}
this
.
_storage
.
saveSoon
(
)
;
}
ignoreID
(
id
)
{
this
.
unignoreID
(
id
)
;
this
.
_ignored
.
push
(
id
)
;
}
unignoreID
(
id
)
{
let
index
=
this
.
_ignored
.
indexOf
(
id
)
;
if
(
index
!
=
-
1
)
{
this
.
_ignored
.
splice
(
index
1
)
;
}
}
async
_saveChangedID
(
id
when
)
{
this
.
_log
.
trace
(
Adding
changed
ID
:
{
id
}
{
JSON
.
stringify
(
when
)
}
)
;
const
changedIDs
=
await
this
.
getChangedIDs
(
)
;
changedIDs
[
id
]
=
when
;
this
.
_saveChangedIDs
(
)
;
}
async
addChangedID
(
id
when
)
{
if
(
!
id
)
{
this
.
_log
.
warn
(
"
Attempted
to
add
undefined
ID
to
tracker
"
)
;
return
false
;
}
if
(
this
.
ignoreAll
|
|
this
.
_ignored
.
includes
(
id
)
)
{
return
false
;
}
if
(
when
=
=
null
)
{
when
=
this
.
_now
(
)
;
}
const
changedIDs
=
await
this
.
getChangedIDs
(
)
;
if
(
(
changedIDs
[
id
]
|
|
-
Infinity
)
<
when
)
{
await
this
.
_saveChangedID
(
id
when
)
;
}
return
true
;
}
async
removeChangedID
(
.
.
.
ids
)
{
if
(
!
ids
.
length
|
|
this
.
ignoreAll
)
{
return
false
;
}
for
(
let
id
of
ids
)
{
if
(
!
id
)
{
this
.
_log
.
warn
(
"
Attempted
to
remove
undefined
ID
from
tracker
"
)
;
continue
;
}
if
(
this
.
_ignored
.
includes
(
id
)
)
{
this
.
_log
.
debug
(
Not
removing
ignored
ID
{
id
}
from
tracker
)
;
continue
;
}
const
changedIDs
=
await
this
.
getChangedIDs
(
)
;
if
(
changedIDs
[
id
]
!
=
null
)
{
this
.
_log
.
trace
(
"
Removing
changed
ID
"
+
id
)
;
delete
changedIDs
[
id
]
;
}
}
await
this
.
_saveChangedIDs
(
)
;
return
true
;
}
async
clearChangedIDs
(
)
{
this
.
_log
.
trace
(
"
Clearing
changed
ID
list
"
)
;
this
.
_storage
.
data
=
{
}
;
await
this
.
_saveChangedIDs
(
)
;
}
_now
(
)
{
return
Date
.
now
(
)
/
1000
;
}
_isTracking
:
false
start
(
)
{
if
(
!
this
.
engineIsEnabled
(
)
)
{
return
;
}
this
.
_log
.
trace
(
"
start
(
)
.
"
)
;
if
(
!
this
.
_isTracking
)
{
this
.
onStart
(
)
;
this
.
_isTracking
=
true
;
}
}
async
stop
(
)
{
this
.
_log
.
trace
(
"
stop
(
)
.
"
)
;
if
(
this
.
_isTracking
)
{
await
this
.
asyncObserver
.
promiseObserversComplete
(
)
;
this
.
onStop
(
)
;
this
.
_isTracking
=
false
;
}
}
onStart
(
)
{
}
onStop
(
)
{
}
async
observe
(
subject
topic
data
)
{
}
engineIsEnabled
(
)
{
if
(
!
this
.
engine
)
{
return
true
;
}
return
this
.
engine
.
enabled
;
}
async
onEngineEnabledChanged
(
engineEnabled
)
{
if
(
engineEnabled
=
=
this
.
_isTracking
)
{
return
;
}
if
(
engineEnabled
)
{
this
.
start
(
)
;
}
else
{
await
this
.
stop
(
)
;
await
this
.
clearChangedIDs
(
)
;
}
}
async
finalize
(
)
{
await
this
.
stop
(
)
;
this
.
_saveChangedIDs
(
)
;
await
this
.
_storage
.
finalize
(
)
;
}
}
;
function
Store
(
name
engine
)
{
if
(
!
engine
)
{
throw
new
Error
(
"
Store
must
be
associated
with
an
Engine
instance
.
"
)
;
}
name
=
name
|
|
"
Unnamed
"
;
this
.
name
=
name
.
toLowerCase
(
)
;
this
.
engine
=
engine
;
this
.
_log
=
Log
.
repository
.
getLogger
(
Sync
.
Engine
.
{
name
}
.
Store
)
;
XPCOMUtils
.
defineLazyGetter
(
this
"
_timer
"
function
(
)
{
return
Cc
[
"
mozilla
.
org
/
timer
;
1
"
]
.
createInstance
(
Ci
.
nsITimer
)
;
}
)
;
}
Store
.
prototype
=
{
async
applyIncomingBatch
(
records
)
{
let
failed
=
[
]
;
await
Async
.
yieldingForEach
(
records
async
record
=
>
{
try
{
await
this
.
applyIncoming
(
record
)
;
}
catch
(
ex
)
{
if
(
ex
.
code
=
=
SyncEngine
.
prototype
.
eEngineAbortApplyIncoming
)
{
throw
ex
.
cause
;
}
if
(
Async
.
isShutdownException
(
ex
)
)
{
throw
ex
;
}
this
.
_log
.
warn
(
"
Failed
to
apply
incoming
record
"
+
record
.
id
ex
)
;
failed
.
push
(
record
.
id
)
;
}
}
)
;
return
failed
;
}
async
applyIncoming
(
record
)
{
if
(
record
.
deleted
)
{
await
this
.
remove
(
record
)
;
}
else
if
(
!
(
await
this
.
itemExists
(
record
.
id
)
)
)
{
await
this
.
create
(
record
)
;
}
else
{
await
this
.
update
(
record
)
;
}
}
async
create
(
record
)
{
throw
new
Error
(
"
override
create
in
a
subclass
"
)
;
}
async
remove
(
record
)
{
throw
new
Error
(
"
override
remove
in
a
subclass
"
)
;
}
async
update
(
record
)
{
throw
new
Error
(
"
override
update
in
a
subclass
"
)
;
}
async
itemExists
(
id
)
{
throw
new
Error
(
"
override
itemExists
in
a
subclass
"
)
;
}
async
createRecord
(
id
collection
)
{
throw
new
Error
(
"
override
createRecord
in
a
subclass
"
)
;
}
async
changeItemID
(
oldID
newID
)
{
throw
new
Error
(
"
override
changeItemID
in
a
subclass
"
)
;
}
async
getAllIDs
(
)
{
throw
new
Error
(
"
override
getAllIDs
in
a
subclass
"
)
;
}
async
wipe
(
)
{
throw
new
Error
(
"
override
wipe
in
a
subclass
"
)
;
}
}
;
function
EngineManager
(
service
)
{
this
.
service
=
service
;
this
.
_engines
=
{
}
;
this
.
_altEngineInfo
=
{
}
;
this
.
_declined
=
new
Set
(
)
;
this
.
_log
=
Log
.
repository
.
getLogger
(
"
Sync
.
EngineManager
"
)
;
this
.
_log
.
manageLevelFromPref
(
"
services
.
sync
.
log
.
logger
.
service
.
engines
"
)
;
Log
.
repository
.
getLogger
(
Sync
.
Engine
)
.
manageLevelFromPref
(
"
services
.
sync
.
log
.
logger
.
engine
"
)
;
}
EngineManager
.
prototype
=
{
get
(
name
)
{
if
(
Array
.
isArray
(
name
)
)
{
let
engines
=
[
]
;
name
.
forEach
(
function
(
name
)
{
let
engine
=
this
.
get
(
name
)
;
if
(
engine
)
{
engines
.
push
(
engine
)
;
}
}
this
)
;
return
engines
;
}
return
this
.
_engines
[
name
]
;
}
getAll
(
)
{
let
engines
=
[
]
;
for
(
let
[
engine
]
of
Object
.
entries
(
this
.
_engines
)
)
{
engines
.
push
(
engine
)
;
}
return
engines
;
}
async
switchAlternatives
(
)
{
for
(
let
[
name
info
]
of
Object
.
entries
(
this
.
_altEngineInfo
)
)
{
let
prefValue
=
info
.
prefValue
;
if
(
prefValue
=
=
=
info
.
lastValue
)
{
this
.
_log
.
trace
(
No
change
for
engine
{
name
}
(
{
info
.
pref
}
is
still
{
prefValue
}
)
)
;
continue
;
}
this
.
_log
.
info
(
Switching
{
name
}
engine
(
"
{
info
.
pref
}
"
went
from
{
info
.
lastValue
}
=
>
{
prefValue
}
)
)
;
try
{
await
this
.
_removeAndFinalize
(
name
)
;
}
catch
(
e
)
{
this
.
_log
.
warn
(
Failed
to
remove
previous
{
name
}
engine
.
.
.
e
)
;
}
let
engineType
=
prefValue
?
info
.
whenTrue
:
info
.
whenFalse
;
try
{
await
this
.
register
(
engineType
)
;
info
.
lastValue
=
prefValue
;
this
.
_log
.
info
(
Switched
the
{
name
}
engine
to
use
{
engineType
.
name
}
)
;
}
catch
(
e
)
{
this
.
_log
.
warn
(
Switching
the
{
name
}
engine
to
use
{
engineType
.
name
}
failed
(
couldn
'
t
register
)
e
)
;
}
}
}
async
registerAlternatives
(
name
pref
whenTrue
whenFalse
)
{
let
info
=
{
name
pref
whenTrue
whenFalse
}
;
XPCOMUtils
.
defineLazyPreferenceGetter
(
info
"
prefValue
"
pref
false
)
;
let
chosen
=
info
.
prefValue
?
info
.
whenTrue
:
info
.
whenFalse
;
info
.
lastValue
=
info
.
prefValue
;
this
.
_altEngineInfo
[
name
]
=
info
;
await
this
.
register
(
chosen
)
;
}
getEnabled
(
)
{
return
this
.
getAll
(
)
.
filter
(
engine
=
>
engine
.
enabled
)
.
sort
(
(
a
b
)
=
>
a
.
syncPriority
-
b
.
syncPriority
)
;
}
get
enabledEngineNames
(
)
{
return
this
.
getEnabled
(
)
.
map
(
e
=
>
e
.
name
)
;
}
persistDeclined
(
)
{
Svc
.
Prefs
.
set
(
"
declinedEngines
"
[
.
.
.
this
.
_declined
]
.
join
(
"
"
)
)
;
}
getDeclined
(
)
{
return
[
.
.
.
this
.
_declined
]
;
}
setDeclined
(
engines
)
{
this
.
_declined
=
new
Set
(
engines
)
;
this
.
persistDeclined
(
)
;
}
isDeclined
(
engineName
)
{
return
this
.
_declined
.
has
(
engineName
)
;
}
decline
(
engines
)
{
for
(
let
e
of
engines
)
{
this
.
_declined
.
add
(
e
)
;
}
this
.
persistDeclined
(
)
;
}
undecline
(
engines
)
{
for
(
let
e
of
engines
)
{
this
.
_declined
.
delete
(
e
)
;
}
this
.
persistDeclined
(
)
;
}
async
register
(
engineObject
)
{
if
(
Array
.
isArray
(
engineObject
)
)
{
for
(
const
e
of
engineObject
)
{
await
this
.
register
(
e
)
;
}
return
;
}
try
{
let
engine
=
new
engineObject
(
this
.
service
)
;
let
name
=
engine
.
name
;
if
(
name
in
this
.
_engines
)
{
this
.
_log
.
error
(
"
Engine
'
"
+
name
+
"
'
is
already
registered
!
"
)
;
}
else
{
if
(
engine
.
initialize
)
{
await
engine
.
initialize
(
)
;
}
this
.
_engines
[
name
]
=
engine
;
}
}
catch
(
ex
)
{
let
name
=
engineObject
|
|
"
"
;
name
=
name
.
prototype
|
|
"
"
;
name
=
name
.
name
|
|
"
"
;
this
.
_log
.
error
(
Could
not
initialize
engine
{
name
}
ex
)
;
}
}
async
unregister
(
val
)
{
let
name
=
val
;
if
(
val
instanceof
SyncEngine
)
{
name
=
val
.
name
;
}
await
this
.
_removeAndFinalize
(
name
)
;
delete
this
.
_altEngineInfo
[
name
]
;
}
async
_removeAndFinalize
(
name
)
{
if
(
name
in
this
.
_engines
)
{
let
engine
=
this
.
_engines
[
name
]
;
delete
this
.
_engines
[
name
]
;
await
engine
.
finalize
(
)
;
}
}
async
clear
(
)
{
for
(
let
name
in
this
.
_engines
)
{
let
engine
=
this
.
_engines
[
name
]
;
delete
this
.
_engines
[
name
]
;
await
engine
.
finalize
(
)
;
}
this
.
_altEngineInfo
=
{
}
;
}
}
;
function
SyncEngine
(
name
service
)
{
if
(
!
service
)
{
throw
new
Error
(
"
SyncEngine
must
be
associated
with
a
Service
instance
.
"
)
;
}
this
.
Name
=
name
|
|
"
Unnamed
"
;
this
.
name
=
name
.
toLowerCase
(
)
;
this
.
service
=
service
;
this
.
_notify
=
Utils
.
notify
(
"
weave
:
engine
:
"
)
;
this
.
_log
=
Log
.
repository
.
getLogger
(
"
Sync
.
Engine
.
"
+
this
.
Name
)
;
this
.
_log
.
manageLevelFromPref
(
services
.
sync
.
log
.
logger
.
engine
.
{
this
.
name
}
)
;
this
.
_modified
=
this
.
emptyChangeset
(
)
;
this
.
_tracker
;
this
.
_log
.
debug
(
"
Engine
constructed
"
)
;
this
.
_toFetchStorage
=
new
JSONFile
(
{
path
:
Utils
.
jsonFilePath
(
"
toFetch
/
"
+
this
.
name
)
dataPostProcessor
:
json
=
>
this
.
_metadataPostProcessor
(
json
)
beforeSave
:
(
)
=
>
this
.
_beforeSaveMetadata
(
)
}
)
;
this
.
_previousFailedStorage
=
new
JSONFile
(
{
path
:
Utils
.
jsonFilePath
(
"
failed
/
"
+
this
.
name
)
dataPostProcessor
:
json
=
>
this
.
_metadataPostProcessor
(
json
)
beforeSave
:
(
)
=
>
this
.
_beforeSaveMetadata
(
)
}
)
;
XPCOMUtils
.
defineLazyPreferenceGetter
(
this
"
_enabled
"
services
.
sync
.
engine
.
{
this
.
prefName
}
false
(
data
previous
latest
)
=
>
this
.
_tracker
.
onEngineEnabledChanged
(
latest
)
)
;
XPCOMUtils
.
defineLazyPreferenceGetter
(
this
"
_syncID
"
services
.
sync
.
{
this
.
name
}
.
syncID
"
"
)
;
XPCOMUtils
.
defineLazyPreferenceGetter
(
this
"
_lastSync
"
services
.
sync
.
{
this
.
name
}
.
lastSync
"
0
"
null
v
=
>
parseFloat
(
v
)
)
;
this
.
_needWeakUpload
=
new
Map
(
)
;
}
SyncEngine
.
kRecoveryStrategy
=
{
ignore
:
"
ignore
"
retry
:
"
retry
"
error
:
"
error
"
}
;
SyncEngine
.
prototype
=
{
_recordObj
:
CryptoWrapper
_storeObj
:
Store
_trackerObj
:
Tracker
version
:
1
eEngineAbortApplyIncoming
:
"
error
.
engine
.
abort
.
applyincoming
"
allowSkippedRecord
:
true
_defaultSort
:
undefined
_hasSyncedThisSession
:
false
_metadataPostProcessor
(
json
)
{
if
(
Array
.
isArray
(
json
)
)
{
json
=
{
ids
:
json
}
;
}
if
(
!
json
.
ids
)
{
json
.
ids
=
[
]
;
}
json
.
ids
=
new
SerializableSet
(
json
.
ids
)
;
return
json
;
}
async
_beforeSaveMetadata
(
)
{
await
ensureDirectory
(
this
.
_toFetchStorage
.
path
)
;
await
ensureDirectory
(
this
.
_previousFailedStorage
.
path
)
;
}
syncPriority
:
0
downloadLimit
:
null
guidFetchBatchSize
:
DEFAULT_GUID_FETCH_BATCH_SIZE
downloadBatchSize
:
DEFAULT_DOWNLOAD_BATCH_SIZE
async
initialize
(
)
{
await
this
.
_toFetchStorage
.
load
(
)
;
await
this
.
_previousFailedStorage
.
load
(
)
;
this
.
_log
.
debug
(
"
SyncEngine
initialized
"
this
.
name
)
;
}
get
prefName
(
)
{
return
this
.
name
;
}
get
enabled
(
)
{
return
this
.
_enabled
;
}
set
enabled
(
val
)
{
if
(
!
!
val
!
=
this
.
_enabled
)
{
Svc
.
Prefs
.
set
(
"
engine
.
"
+
this
.
prefName
!
!
val
)
;
}
}
get
score
(
)
{
return
this
.
_tracker
.
score
;
}
get
_store
(
)
{
let
store
=
new
this
.
_storeObj
(
this
.
Name
this
)
;
this
.
__defineGetter__
(
"
_store
"
(
)
=
>
store
)
;
return
store
;
}
get
_tracker
(
)
{
let
tracker
=
new
this
.
_trackerObj
(
this
.
Name
this
)
;
this
.
__defineGetter__
(
"
_tracker
"
(
)
=
>
tracker
)
;
return
tracker
;
}
get
storageURL
(
)
{
return
this
.
service
.
storageURL
;
}
get
engineURL
(
)
{
return
this
.
storageURL
+
this
.
name
;
}
get
cryptoKeysURL
(
)
{
return
this
.
storageURL
+
"
crypto
/
keys
"
;
}
get
metaURL
(
)
{
return
this
.
storageURL
+
"
meta
/
global
"
;
}
startTracking
(
)
{
this
.
_tracker
.
start
(
)
;
}
stopTracking
(
)
{
return
this
.
_tracker
.
stop
(
)
;
}
async
sync
(
)
{
if
(
!
this
.
enabled
)
{
return
false
;
}
if
(
!
this
.
_sync
)
{
throw
new
Error
(
"
engine
does
not
implement
_sync
method
"
)
;
}
return
this
.
_notify
(
"
sync
"
this
.
name
this
.
_sync
)
(
)
;
}
emptyChangeset
(
)
{
return
new
Changeset
(
)
;
}
async
getSyncID
(
)
{
return
this
.
_syncID
;
}
async
ensureCurrentSyncID
(
newSyncID
)
{
let
existingSyncID
=
this
.
_syncID
;
if
(
existingSyncID
=
=
newSyncID
)
{
return
existingSyncID
;
}
this
.
_log
.
debug
(
"
Engine
syncIDs
:
"
+
[
newSyncID
existingSyncID
]
)
;
Svc
.
Prefs
.
set
(
this
.
name
+
"
.
syncID
"
newSyncID
)
;
Svc
.
Prefs
.
set
(
this
.
name
+
"
.
lastSync
"
"
0
"
)
;
return
newSyncID
;
}
async
resetSyncID
(
)
{
let
newSyncID
=
await
this
.
resetLocalSyncID
(
)
;
await
this
.
wipeServer
(
)
;
return
newSyncID
;
}
async
resetLocalSyncID
(
)
{
return
this
.
ensureCurrentSyncID
(
Utils
.
makeGUID
(
)
)
;
}
shouldSkipSync
(
syncReason
)
{
return
false
;
}
async
getLastSync
(
)
{
return
this
.
_lastSync
;
}
async
setLastSync
(
lastSync
)
{
Svc
.
Prefs
.
set
(
this
.
name
+
"
.
lastSync
"
lastSync
.
toString
(
)
)
;
}
async
resetLastSync
(
)
{
this
.
_log
.
debug
(
"
Resetting
"
+
this
.
name
+
"
last
sync
time
"
)
;
await
this
.
setLastSync
(
0
)
;
}
get
hasSyncedThisSession
(
)
{
return
this
.
_hasSyncedThisSession
;
}
set
hasSyncedThisSession
(
hasSynced
)
{
this
.
_hasSyncedThisSession
=
hasSynced
;
}
get
toFetch
(
)
{
this
.
_toFetchStorage
.
ensureDataReady
(
)
;
return
this
.
_toFetchStorage
.
data
.
ids
;
}
set
toFetch
(
ids
)
{
if
(
ids
.
constructor
.
name
!
=
"
SerializableSet
"
)
{
throw
new
Error
(
"
Bug
:
Attempted
to
set
toFetch
to
something
that
isn
'
t
a
SerializableSet
"
)
;
}
this
.
_toFetchStorage
.
data
=
{
ids
}
;
this
.
_toFetchStorage
.
saveSoon
(
)
;
}
get
previousFailed
(
)
{
this
.
_previousFailedStorage
.
ensureDataReady
(
)
;
return
this
.
_previousFailedStorage
.
data
.
ids
;
}
set
previousFailed
(
ids
)
{
if
(
ids
.
constructor
.
name
!
=
"
SerializableSet
"
)
{
throw
new
Error
(
"
Bug
:
Attempted
to
set
previousFailed
to
something
that
isn
'
t
a
SerializableSet
"
)
;
}
this
.
_previousFailedStorage
.
data
=
{
ids
}
;
this
.
_previousFailedStorage
.
saveSoon
(
)
;
}
async
getChangedIDs
(
)
{
return
this
.
_tracker
.
getChangedIDs
(
)
;
}
async
_createRecord
(
id
)
{
let
record
=
await
this
.
_store
.
createRecord
(
id
this
.
name
)
;
record
.
id
=
id
;
record
.
collection
=
this
.
name
;
return
record
;
}
_createTombstone
(
id
)
{
let
tombstone
=
new
this
.
_recordObj
(
this
.
name
id
)
;
tombstone
.
id
=
id
;
tombstone
.
collection
=
this
.
name
;
tombstone
.
deleted
=
true
;
return
tombstone
;
}
addForWeakUpload
(
id
{
forceTombstone
=
false
}
=
{
}
)
{
this
.
_needWeakUpload
.
set
(
id
{
forceTombstone
}
)
;
}
async
_syncStartup
(
)
{
let
metaGlobal
=
await
this
.
service
.
recordManager
.
get
(
this
.
metaURL
)
;
let
engines
=
metaGlobal
.
payload
.
engines
|
|
{
}
;
let
engineData
=
engines
[
this
.
name
]
|
|
{
}
;
if
(
(
engineData
.
version
|
|
0
)
<
this
.
version
)
{
this
.
_log
.
debug
(
"
Old
engine
data
:
"
+
[
engineData
.
version
this
.
version
]
)
;
let
newSyncID
=
await
this
.
resetSyncID
(
)
;
engineData
.
version
=
this
.
version
;
engineData
.
syncID
=
newSyncID
;
engines
[
this
.
name
]
=
engineData
;
metaGlobal
.
payload
.
engines
=
engines
;
metaGlobal
.
changed
=
true
;
}
else
if
(
engineData
.
version
>
this
.
version
)
{
let
error
=
new
Error
(
"
New
data
:
"
+
[
engineData
.
version
this
.
version
]
)
;
error
.
failureCode
=
VERSION_OUT_OF_DATE
;
throw
error
;
}
else
{
let
assignedSyncID
=
await
this
.
ensureCurrentSyncID
(
engineData
.
syncID
)
;
if
(
assignedSyncID
!
=
engineData
.
syncID
)
{
engineData
.
syncID
=
assignedSyncID
;
metaGlobal
.
changed
=
true
;
}
}
let
initialChanges
=
await
this
.
pullChanges
(
)
;
this
.
_modified
.
replace
(
initialChanges
)
;
await
this
.
_tracker
.
clearChangedIDs
(
)
;
this
.
_tracker
.
resetScore
(
)
;
this
.
_log
.
info
(
this
.
_modified
.
count
(
)
+
"
outgoing
items
pre
-
reconciliation
"
)
;
this
.
_delete
=
{
}
;
}
async
pullChanges
(
)
{
let
lastSync
=
await
this
.
getLastSync
(
)
;
if
(
lastSync
)
{
return
this
.
pullNewChanges
(
)
;
}
this
.
_log
.
debug
(
"
First
sync
uploading
all
items
"
)
;
return
this
.
pullAllChanges
(
)
;
}
itemSource
(
)
{
return
new
Collection
(
this
.
engineURL
this
.
_recordObj
this
.
service
)
;
}
async
_processIncoming
(
)
{
this
.
_log
.
trace
(
"
Downloading
&
applying
server
changes
"
)
;
let
newitems
=
this
.
itemSource
(
)
;
let
lastSync
=
await
this
.
getLastSync
(
)
;
newitems
.
newer
=
lastSync
;
newitems
.
full
=
true
;
let
downloadLimit
=
Infinity
;
if
(
this
.
downloadLimit
)
{
if
(
this
.
_defaultSort
)
{
throw
new
Error
(
"
Can
'
t
specify
download
limit
with
default
sort
order
"
)
;
}
newitems
.
sort
=
"
newest
"
;
downloadLimit
=
newitems
.
limit
=
this
.
downloadLimit
;
}
else
if
(
this
.
_defaultSort
)
{
newitems
.
sort
=
this
.
_defaultSort
;
}
let
count
=
{
applied
:
0
failed
:
0
newFailed
:
0
reconciled
:
0
}
;
let
recordsToApply
=
[
]
;
let
failedInCurrentSync
=
new
SerializableSet
(
)
;
let
oldestModified
=
this
.
lastModified
;
let
downloadedIDs
=
new
Set
(
)
;
if
(
this
.
lastModified
=
=
null
|
|
this
.
lastModified
>
lastSync
)
{
let
{
response
records
}
=
await
newitems
.
getBatched
(
this
.
downloadBatchSize
)
;
if
(
!
response
.
success
)
{
response
.
failureCode
=
ENGINE_DOWNLOAD_FAIL
;
throw
response
;
}
await
Async
.
yieldingForEach
(
records
async
record
=
>
{
downloadedIDs
.
add
(
record
.
id
)
;
if
(
record
.
modified
<
oldestModified
)
{
oldestModified
=
record
.
modified
;
}
let
{
shouldApply
error
}
=
await
this
.
_maybeReconcile
(
record
)
;
if
(
error
)
{
failedInCurrentSync
.
add
(
record
.
id
)
;
count
.
failed
+
+
;
return
;
}
if
(
!
shouldApply
)
{
count
.
reconciled
+
+
;
return
;
}
recordsToApply
.
push
(
record
)
;
}
)
;
let
failedToApply
=
await
this
.
_applyRecords
(
recordsToApply
)
;
Utils
.
setAddAll
(
failedInCurrentSync
failedToApply
)
;
count
.
failed
+
=
failedToApply
.
length
;
count
.
applied
+
=
recordsToApply
.
length
;
}
if
(
downloadedIDs
.
size
=
=
downloadLimit
)
{
let
guidColl
=
this
.
itemSource
(
)
;
guidColl
.
newer
=
lastSync
;
guidColl
.
older
=
oldestModified
;
guidColl
.
sort
=
"
oldest
"
;
let
guids
=
await
guidColl
.
get
(
)
;
if
(
!
guids
.
success
)
{
throw
guids
;
}
let
remainingIDs
=
guids
.
obj
.
filter
(
id
=
>
!
downloadedIDs
.
has
(
id
)
)
;
if
(
remainingIDs
.
length
>
0
)
{
this
.
toFetch
=
Utils
.
setAddAll
(
this
.
toFetch
remainingIDs
)
;
}
}
if
(
lastSync
<
this
.
lastModified
)
{
lastSync
=
this
.
lastModified
;
await
this
.
setLastSync
(
lastSync
)
;
}
let
failedInPreviousSync
=
this
.
previousFailed
;
let
idsToBackfill
=
Array
.
from
(
Utils
.
setAddAll
(
Utils
.
subsetOfSize
(
this
.
toFetch
downloadLimit
)
failedInPreviousSync
)
)
;
this
.
previousFailed
=
failedInCurrentSync
;
let
backfilledItems
=
this
.
itemSource
(
)
;
backfilledItems
.
sort
=
"
newest
"
;
backfilledItems
.
full
=
true
;
if
(
this
.
guidFetchBatchSize
)
{
for
(
let
ids
of
PlacesUtils
.
chunkArray
(
idsToBackfill
this
.
guidFetchBatchSize
)
)
{
backfilledItems
.
ids
=
ids
;
let
{
response
records
}
=
await
backfilledItems
.
getBatched
(
this
.
downloadBatchSize
)
;
if
(
!
response
.
success
)
{
response
.
failureCode
=
ENGINE_DOWNLOAD_FAIL
;
throw
response
;
}
let
backfilledRecordsToApply
=
[
]
;
let
failedInBackfill
=
[
]
;
await
Async
.
yieldingForEach
(
records
async
record
=
>
{
let
{
shouldApply
error
}
=
await
this
.
_maybeReconcile
(
record
)
;
if
(
error
)
{
failedInBackfill
.
push
(
record
.
id
)
;
count
.
failed
+
+
;
return
;
}
if
(
!
shouldApply
)
{
count
.
reconciled
+
+
;
return
;
}
backfilledRecordsToApply
.
push
(
record
)
;
}
)
;
let
failedToApply
=
await
this
.
_applyRecords
(
backfilledRecordsToApply
)
;
failedInBackfill
.
push
(
.
.
.
failedToApply
)
;
count
.
failed
+
=
failedToApply
.
length
;
count
.
applied
+
=
backfilledRecordsToApply
.
length
;
this
.
toFetch
=
Utils
.
setDeleteAll
(
this
.
toFetch
ids
)
;
this
.
previousFailed
=
Utils
.
setAddAll
(
this
.
previousFailed
failedInBackfill
)
;
if
(
lastSync
<
this
.
lastModified
)
{
lastSync
=
this
.
lastModified
;
await
this
.
setLastSync
(
lastSync
)
;
}
}
}
count
.
newFailed
=
0
;
for
(
let
item
of
this
.
previousFailed
)
{
if
(
!
failedInPreviousSync
.
has
(
item
)
)
{
+
+
count
.
newFailed
;
}
}
count
.
succeeded
=
Math
.
max
(
0
count
.
applied
-
count
.
failed
)
;
this
.
_log
.
info
(
[
"
Records
:
"
count
.
applied
"
applied
"
count
.
succeeded
"
successfully
"
count
.
failed
"
failed
to
apply
"
count
.
newFailed
"
newly
failed
to
apply
"
count
.
reconciled
"
reconciled
.
"
]
.
join
(
"
"
)
)
;
Observers
.
notify
(
"
weave
:
engine
:
sync
:
applied
"
count
this
.
name
)
;
}
async
_maybeReconcile
(
item
)
{
let
key
=
this
.
service
.
collectionKeys
.
keyForCollection
(
this
.
name
)
;
if
(
this
.
lastModified
=
=
null
|
|
item
.
modified
>
this
.
lastModified
)
{
this
.
lastModified
=
item
.
modified
;
}
try
{
try
{
await
item
.
decrypt
(
key
)
;
}
catch
(
ex
)
{
if
(
!
Utils
.
isHMACMismatch
(
ex
)
)
{
throw
ex
;
}
let
strategy
=
await
this
.
handleHMACMismatch
(
item
true
)
;
if
(
strategy
=
=
SyncEngine
.
kRecoveryStrategy
.
retry
)
{
try
{
this
.
_log
.
info
(
"
Trying
decrypt
again
.
.
.
"
)
;
key
=
this
.
service
.
collectionKeys
.
keyForCollection
(
this
.
name
)
;
await
item
.
decrypt
(
key
)
;
strategy
=
null
;
}
catch
(
ex
)
{
if
(
!
Utils
.
isHMACMismatch
(
ex
)
)
{
throw
ex
;
}
strategy
=
await
this
.
handleHMACMismatch
(
item
false
)
;
}
}
switch
(
strategy
)
{
case
null
:
break
;
case
SyncEngine
.
kRecoveryStrategy
.
retry
:
this
.
_log
.
debug
(
"
Ignoring
second
retry
suggestion
.
"
)
;
case
SyncEngine
.
kRecoveryStrategy
.
error
:
this
.
_log
.
warn
(
"
Error
decrypting
record
"
ex
)
;
return
{
shouldApply
:
false
error
:
ex
}
;
case
SyncEngine
.
kRecoveryStrategy
.
ignore
:
this
.
_log
.
debug
(
"
Ignoring
record
"
+
item
.
id
+
"
with
bad
HMAC
:
already
handled
.
"
)
;
return
{
shouldApply
:
false
error
:
null
}
;
}
}
}
catch
(
ex
)
{
if
(
Async
.
isShutdownException
(
ex
)
)
{
throw
ex
;
}
this
.
_log
.
warn
(
"
Error
decrypting
record
"
ex
)
;
return
{
shouldApply
:
false
error
:
ex
}
;
}
if
(
this
.
_shouldDeleteRemotely
(
item
)
)
{
this
.
_log
.
trace
(
"
Deleting
item
from
server
without
applying
"
item
)
;
await
this
.
_deleteId
(
item
.
id
)
;
return
{
shouldApply
:
false
error
:
null
}
;
}
let
shouldApply
;
try
{
shouldApply
=
await
this
.
_reconcile
(
item
)
;
}
catch
(
ex
)
{
if
(
ex
.
code
=
=
SyncEngine
.
prototype
.
eEngineAbortApplyIncoming
)
{
this
.
_log
.
warn
(
"
Reconciliation
failed
:
aborting
incoming
processing
.
"
)
;
throw
ex
.
cause
;
}
else
if
(
!
Async
.
isShutdownException
(
ex
)
)
{
this
.
_log
.
warn
(
"
Failed
to
reconcile
incoming
record
"
+
item
.
id
ex
)
;
return
{
shouldApply
:
false
error
:
ex
}
;
}
else
{
throw
ex
;
}
}
if
(
!
shouldApply
)
{
this
.
_log
.
trace
(
"
Skipping
reconciled
incoming
item
"
+
item
.
id
)
;
}
return
{
shouldApply
error
:
null
}
;
}
async
_applyRecords
(
records
)
{
this
.
_tracker
.
ignoreAll
=
true
;
try
{
let
failedIDs
=
await
this
.
_store
.
applyIncomingBatch
(
records
)
;
return
failedIDs
;
}
catch
(
ex
)
{
this
.
_log
.
warn
(
"
Got
exception
aborting
processIncoming
"
ex
)
;
throw
ex
;
}
finally
{
this
.
_tracker
.
ignoreAll
=
false
;
}
}
_shouldDeleteRemotely
(
remoteItem
)
{
return
false
;
}
async
_findDupe
(
item
)
{
}
beforeRecordDiscard
(
localRecord
remoteRecord
remoteIsNewer
)
{
}
async
_shouldReviveRemotelyDeletedRecord
(
remoteItem
)
{
return
true
;
}
async
_deleteId
(
id
)
{
await
this
.
_tracker
.
removeChangedID
(
id
)
;
this
.
_noteDeletedId
(
id
)
;
}
_noteDeletedId
(
id
)
{
if
(
this
.
_delete
.
ids
=
=
null
)
{
this
.
_delete
.
ids
=
[
id
]
;
}
else
{
this
.
_delete
.
ids
.
push
(
id
)
;
}
}
async
_switchItemToDupe
(
localDupeGUID
incomingItem
)
{
await
this
.
_deleteId
(
localDupeGUID
)
;
this
.
_log
.
debug
(
"
Switching
local
ID
to
incoming
:
"
+
localDupeGUID
+
"
-
>
"
+
incomingItem
.
id
)
;
return
this
.
_store
.
changeItemID
(
localDupeGUID
incomingItem
.
id
)
;
}
async
_reconcile
(
item
)
{
if
(
this
.
_log
.
level
<
=
Log
.
Level
.
Trace
)
{
this
.
_log
.
trace
(
"
Incoming
:
"
+
item
)
;
}
let
existsLocally
=
await
this
.
_store
.
itemExists
(
item
.
id
)
;
let
locallyModified
=
this
.
_modified
.
has
(
item
.
id
)
;
let
remoteAge
=
Resource
.
serverTime
-
item
.
modified
;
let
localAge
=
locallyModified
?
Date
.
now
(
)
/
1000
-
this
.
_modified
.
getModifiedTimestamp
(
item
.
id
)
:
null
;
let
remoteIsNewer
=
remoteAge
<
localAge
;
this
.
_log
.
trace
(
"
Reconciling
"
+
item
.
id
+
"
.
exists
=
"
+
existsLocally
+
"
;
modified
=
"
+
locallyModified
+
"
;
local
age
=
"
+
localAge
+
"
;
incoming
age
=
"
+
remoteAge
)
;
if
(
item
.
deleted
)
{
if
(
!
existsLocally
)
{
this
.
_log
.
trace
(
"
Ignoring
incoming
item
because
it
was
deleted
and
"
+
"
the
item
does
not
exist
locally
.
"
)
;
return
false
;
}
if
(
!
locallyModified
)
{
this
.
_log
.
trace
(
"
Applying
incoming
delete
because
the
local
item
"
+
"
exists
and
isn
'
t
modified
.
"
)
;
return
true
;
}
this
.
_log
.
trace
(
"
Incoming
record
is
deleted
but
we
had
local
changes
.
"
)
;
if
(
remoteIsNewer
)
{
this
.
_log
.
trace
(
"
Remote
record
is
newer
-
-
deleting
local
record
.
"
)
;
return
true
;
}
let
willRevive
=
await
this
.
_shouldReviveRemotelyDeletedRecord
(
item
)
;
this
.
_log
.
trace
(
"
Local
record
is
newer
-
-
reviving
?
"
+
willRevive
)
;
return
!
willRevive
;
}
if
(
!
existsLocally
)
{
let
localDupeGUID
=
await
this
.
_findDupe
(
item
)
;
if
(
localDupeGUID
)
{
this
.
_log
.
trace
(
"
Local
item
"
+
localDupeGUID
+
"
is
a
duplicate
for
"
+
"
incoming
item
"
+
item
.
id
)
;
existsLocally
=
await
this
.
_store
.
itemExists
(
localDupeGUID
)
;
if
(
this
.
_modified
.
has
(
localDupeGUID
)
)
{
locallyModified
=
true
;
localAge
=
this
.
_tracker
.
_now
(
)
-
this
.
_modified
.
getModifiedTimestamp
(
localDupeGUID
)
;
remoteIsNewer
=
remoteAge
<
localAge
;
this
.
_modified
.
changeID
(
localDupeGUID
item
.
id
)
;
}
else
{
locallyModified
=
false
;
localAge
=
null
;
}
await
this
.
_switchItemToDupe
(
localDupeGUID
item
)
;
this
.
_log
.
debug
(
"
Local
item
after
duplication
:
age
=
"
+
localAge
+
"
;
modified
=
"
+
locallyModified
+
"
;
exists
=
"
+
existsLocally
)
;
}
else
{
this
.
_log
.
trace
(
"
No
duplicate
found
for
incoming
item
:
"
+
item
.
id
)
;
}
}
if
(
!
existsLocally
)
{
if
(
!
locallyModified
)
{
this
.
_log
.
trace
(
"
Applying
incoming
because
local
item
does
not
exist
"
+
"
and
was
not
deleted
.
"
)
;
return
true
;
}
if
(
remoteIsNewer
)
{
this
.
_log
.
trace
(
"
Applying
incoming
because
local
item
was
deleted
"
+
"
before
the
incoming
item
was
changed
.
"
)
;
this
.
_modified
.
delete
(
item
.
id
)
;
return
true
;
}
this
.
_log
.
trace
(
"
Ignoring
incoming
item
because
the
local
item
'
s
"
+
"
deletion
is
newer
.
"
)
;
return
false
;
}
let
localRecord
=
await
this
.
_createRecord
(
item
.
id
)
;
let
recordsEqual
=
Utils
.
deepEquals
(
item
.
cleartext
localRecord
.
cleartext
)
;
if
(
recordsEqual
)
{
this
.
_log
.
trace
(
"
Ignoring
incoming
item
because
the
local
item
is
identical
.
"
)
;
this
.
_modified
.
delete
(
item
.
id
)
;
return
false
;
}
if
(
!
locallyModified
)
{
this
.
_log
.
trace
(
"
Applying
incoming
record
because
no
local
conflicts
.
"
)
;
return
true
;
}
this
.
_log
.
warn
(
"
DATA
LOSS
:
Both
local
and
remote
changes
to
record
:
"
+
item
.
id
)
;
if
(
!
remoteIsNewer
)
{
this
.
beforeRecordDiscard
(
localRecord
item
remoteIsNewer
)
;
}
return
remoteIsNewer
;
}
async
_uploadOutgoing
(
)
{
this
.
_log
.
trace
(
"
Uploading
local
changes
to
server
.
"
)
;
let
up
=
new
Collection
(
this
.
engineURL
null
this
.
service
)
;
let
modifiedIDs
=
new
Set
(
this
.
_modified
.
ids
(
)
)
;
for
(
let
id
of
this
.
_needWeakUpload
.
keys
(
)
)
{
modifiedIDs
.
add
(
id
)
;
}
let
counts
=
{
failed
:
0
sent
:
0
}
;
if
(
modifiedIDs
.
size
)
{
this
.
_log
.
trace
(
"
Preparing
"
+
modifiedIDs
.
size
+
"
outgoing
records
"
)
;
counts
.
sent
=
modifiedIDs
.
size
;
let
failed
=
[
]
;
let
successful
=
[
]
;
let
lastSync
=
await
this
.
getLastSync
(
)
;
let
handleResponse
=
async
(
postQueue
resp
batchOngoing
)
=
>
{
if
(
!
resp
.
success
)
{
this
.
_log
.
debug
(
"
Uploading
records
failed
:
"
+
resp
)
;
resp
.
failureCode
=
resp
.
status
=
=
412
?
ENGINE_BATCH_INTERRUPTED
:
ENGINE_UPLOAD_FAIL
;
throw
resp
;
}
failed
=
failed
.
concat
(
Object
.
keys
(
resp
.
obj
.
failed
)
)
;
successful
=
successful
.
concat
(
resp
.
obj
.
success
)
;
if
(
batchOngoing
)
{
return
;
}
if
(
failed
.
length
&
&
this
.
_log
.
level
<
=
Log
.
Level
.
Debug
)
{
this
.
_log
.
debug
(
"
Records
that
will
be
uploaded
again
because
"
+
"
the
server
couldn
'
t
store
them
:
"
+
failed
.
join
(
"
"
)
)
;
}
counts
.
failed
+
=
failed
.
length
;
for
(
let
id
of
successful
)
{
this
.
_modified
.
delete
(
id
)
;
}
await
this
.
_onRecordsWritten
(
successful
failed
postQueue
.
lastModified
)
;
if
(
postQueue
.
lastModified
>
lastSync
)
{
lastSync
=
postQueue
.
lastModified
;
await
this
.
setLastSync
(
lastSync
)
;
}
failed
.
length
=
0
;
successful
.
length
=
0
;
}
;
let
postQueue
=
up
.
newPostQueue
(
this
.
_log
lastSync
handleResponse
)
;
for
(
let
id
of
modifiedIDs
)
{
let
out
;
let
ok
=
false
;
try
{
let
{
forceTombstone
=
false
}
=
this
.
_needWeakUpload
.
get
(
id
)
|
|
{
}
;
if
(
forceTombstone
)
{
out
=
await
this
.
_createTombstone
(
id
)
;
}
else
{
out
=
await
this
.
_createRecord
(
id
)
;
}
if
(
this
.
_log
.
level
<
=
Log
.
Level
.
Trace
)
{
this
.
_log
.
trace
(
"
Outgoing
:
"
+
out
)
;
}
await
out
.
encrypt
(
this
.
service
.
collectionKeys
.
keyForCollection
(
this
.
name
)
)
;
ok
=
true
;
}
catch
(
ex
)
{
this
.
_log
.
warn
(
"
Error
creating
record
"
ex
)
;
+
+
counts
.
failed
;
if
(
Async
.
isShutdownException
(
ex
)
|
|
!
this
.
allowSkippedRecord
)
{
if
(
!
this
.
allowSkippedRecord
)
{
Observers
.
notify
(
"
weave
:
engine
:
sync
:
uploaded
"
counts
this
.
name
)
;
}
throw
ex
;
}
}
if
(
ok
)
{
let
{
enqueued
error
}
=
await
postQueue
.
enqueue
(
out
)
;
if
(
!
enqueued
)
{
+
+
counts
.
failed
;
if
(
!
this
.
allowSkippedRecord
)
{
Observers
.
notify
(
"
weave
:
engine
:
sync
:
uploaded
"
counts
this
.
name
)
;
this
.
_log
.
warn
(
Failed
to
enqueue
record
"
{
id
}
"
(
aborting
)
error
)
;
throw
error
;
}
this
.
_modified
.
delete
(
id
)
;
this
.
_log
.
warn
(
Failed
to
enqueue
record
"
{
id
}
"
(
skipping
)
error
)
;
}
}
await
Async
.
promiseYield
(
)
;
}
await
postQueue
.
flush
(
true
)
;
}
this
.
_needWeakUpload
.
clear
(
)
;
if
(
counts
.
sent
|
|
counts
.
failed
)
{
Observers
.
notify
(
"
weave
:
engine
:
sync
:
uploaded
"
counts
this
.
name
)
;
}
}
async
_onRecordsWritten
(
succeeded
failed
serverModifiedTime
)
{
}
async
_syncFinish
(
)
{
this
.
_log
.
trace
(
"
Finishing
up
sync
"
)
;
let
doDelete
=
async
(
key
val
)
=
>
{
let
coll
=
new
Collection
(
this
.
engineURL
this
.
_recordObj
this
.
service
)
;
coll
[
key
]
=
val
;
await
coll
.
delete
(
)
;
}
;
for
(
let
[
key
val
]
of
Object
.
entries
(
this
.
_delete
)
)
{
delete
this
.
_delete
[
key
]
;
this
.
_log
.
trace
(
"
doing
post
-
sync
deletions
"
{
key
val
}
)
;
if
(
key
!
=
"
ids
"
|
|
val
.
length
<
=
100
)
{
await
doDelete
(
key
val
)
;
}
else
{
while
(
val
.
length
>
0
)
{
await
doDelete
(
key
val
.
slice
(
0
100
)
)
;
val
=
val
.
slice
(
100
)
;
}
}
}
this
.
hasSyncedThisSession
=
true
;
await
this
.
_tracker
.
asyncObserver
.
promiseObserversComplete
(
)
;
}
async
_syncCleanup
(
)
{
this
.
_needWeakUpload
.
clear
(
)
;
if
(
!
this
.
_modified
)
{
return
;
}
try
{
await
this
.
trackRemainingChanges
(
)
;
}
finally
{
this
.
_modified
.
clear
(
)
;
}
}
async
_sync
(
)
{
try
{
Async
.
checkAppReady
(
)
;
await
this
.
_syncStartup
(
)
;
Async
.
checkAppReady
(
)
;
Observers
.
notify
(
"
weave
:
engine
:
sync
:
status
"
"
process
-
incoming
"
)
;
await
this
.
_processIncoming
(
)
;
Async
.
checkAppReady
(
)
;
Observers
.
notify
(
"
weave
:
engine
:
sync
:
status
"
"
upload
-
outgoing
"
)
;
try
{
await
this
.
_uploadOutgoing
(
)
;
Async
.
checkAppReady
(
)
;
await
this
.
_syncFinish
(
)
;
}
catch
(
ex
)
{
if
(
!
ex
.
status
|
|
ex
.
status
!
=
412
)
{
throw
ex
;
}
this
.
_log
.
warn
(
"
412
error
during
sync
-
will
retry
.
"
)
;
}
}
finally
{
await
this
.
_syncCleanup
(
)
;
}
}
async
canDecrypt
(
)
{
let
canDecrypt
=
false
;
let
test
=
new
Collection
(
this
.
engineURL
this
.
_recordObj
this
.
service
)
;
test
.
limit
=
1
;
test
.
sort
=
"
newest
"
;
test
.
full
=
true
;
let
key
=
this
.
service
.
collectionKeys
.
keyForCollection
(
this
.
name
)
;
try
{
this
.
_log
.
trace
(
"
Trying
to
decrypt
a
record
from
the
server
.
.
"
)
;
let
json
=
(
await
test
.
get
(
)
)
.
obj
[
0
]
;
let
record
=
new
this
.
_recordObj
(
)
;
record
.
deserialize
(
json
)
;
await
record
.
decrypt
(
key
)
;
canDecrypt
=
true
;
}
catch
(
ex
)
{
if
(
Async
.
isShutdownException
(
ex
)
)
{
throw
ex
;
}
this
.
_log
.
debug
(
"
Failed
test
decrypt
"
ex
)
;
}
return
canDecrypt
;
}
async
wipeServer
(
)
{
await
this
.
_deleteServerCollection
(
)
;
await
this
.
_resetClient
(
)
;
}
async
_deleteServerCollection
(
)
{
let
response
=
await
this
.
service
.
resource
(
this
.
engineURL
)
.
delete
(
)
;
if
(
response
.
status
!
=
200
&
&
response
.
status
!
=
404
)
{
throw
response
;
}
}
async
removeClientData
(
)
{
}
async
handleHMACMismatch
(
item
mayRetry
)
{
return
(
await
this
.
service
.
handleHMACEvent
(
)
)
&
&
mayRetry
?
SyncEngine
.
kRecoveryStrategy
.
retry
:
SyncEngine
.
kRecoveryStrategy
.
error
;
}
async
pullAllChanges
(
)
{
let
changes
=
{
}
;
let
ids
=
await
this
.
_store
.
getAllIDs
(
)
;
for
(
let
id
in
ids
)
{
changes
[
id
]
=
0
;
}
return
changes
;
}
async
pullNewChanges
(
)
{
await
this
.
_tracker
.
asyncObserver
.
promiseObserversComplete
(
)
;
return
this
.
getChangedIDs
(
)
;
}
async
trackRemainingChanges
(
)
{
for
(
let
[
id
change
]
of
this
.
_modified
.
entries
(
)
)
{
await
this
.
_tracker
.
addChangedID
(
id
change
)
;
}
}
async
resetClient
(
)
{
return
this
.
_notify
(
"
reset
-
client
"
this
.
name
this
.
_resetClient
)
(
)
;
}
async
_resetClient
(
)
{
await
this
.
resetLastSync
(
)
;
this
.
hasSyncedThisSession
=
false
;
this
.
previousFailed
=
new
SerializableSet
(
)
;
this
.
toFetch
=
new
SerializableSet
(
)
;
this
.
_needWeakUpload
.
clear
(
)
;
}
async
wipeClient
(
)
{
return
this
.
_notify
(
"
wipe
-
client
"
this
.
name
this
.
_wipeClient
)
(
)
;
}
async
_wipeClient
(
)
{
await
this
.
resetClient
(
)
;
this
.
_log
.
debug
(
"
Deleting
all
local
data
"
)
;
this
.
_tracker
.
ignoreAll
=
true
;
await
this
.
_store
.
wipe
(
)
;
this
.
_tracker
.
ignoreAll
=
false
;
await
this
.
_tracker
.
clearChangedIDs
(
)
;
}
getValidator
(
)
{
return
null
;
}
async
finalize
(
)
{
await
this
.
_tracker
.
finalize
(
)
;
await
this
.
_toFetchStorage
.
finalize
(
)
;
await
this
.
_previousFailedStorage
.
finalize
(
)
;
}
}
;
class
Changeset
{
constructor
(
)
{
this
.
changes
=
{
}
;
}
getModifiedTimestamp
(
id
)
{
return
this
.
changes
[
id
]
;
}
set
(
id
change
)
{
this
.
changes
[
id
]
=
change
;
}
insert
(
changes
)
{
Object
.
assign
(
this
.
changes
changes
)
;
}
replace
(
changes
)
{
this
.
changes
=
changes
;
}
has
(
id
)
{
return
id
in
this
.
changes
;
}
delete
(
id
)
{
delete
this
.
changes
[
id
]
;
}
changeID
(
oldID
newID
)
{
this
.
changes
[
newID
]
=
this
.
changes
[
oldID
]
;
delete
this
.
changes
[
oldID
]
;
}
ids
(
)
{
return
Object
.
keys
(
this
.
changes
)
;
}
entries
(
)
{
return
Object
.
entries
(
this
.
changes
)
;
}
count
(
)
{
return
this
.
ids
(
)
.
length
;
}
clear
(
)
{
this
.
changes
=
{
}
;
}
}
