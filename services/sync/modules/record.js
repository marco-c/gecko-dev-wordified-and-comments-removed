var
EXPORTED_SYMBOLS
=
[
"
WBORecord
"
"
RecordManager
"
"
RawCryptoWrapper
"
"
CryptoWrapper
"
"
CollectionKeyManager
"
"
Collection
"
"
PostQueue
"
]
;
const
CRYPTO_COLLECTION
=
"
crypto
"
;
const
KEYS_WBO
=
"
keys
"
;
const
{
Log
}
=
ChromeUtils
.
import
(
"
resource
:
/
/
gre
/
modules
/
Log
.
jsm
"
)
;
const
{
DEFAULT_DOWNLOAD_BATCH_SIZE
DEFAULT_KEYBUNDLE_NAME
}
=
ChromeUtils
.
import
(
"
resource
:
/
/
services
-
sync
/
constants
.
js
"
)
;
const
{
BulkKeyBundle
}
=
ChromeUtils
.
import
(
"
resource
:
/
/
services
-
sync
/
keys
.
js
"
)
;
const
{
Weave
}
=
ChromeUtils
.
import
(
"
resource
:
/
/
services
-
sync
/
main
.
js
"
)
;
const
{
Resource
}
=
ChromeUtils
.
import
(
"
resource
:
/
/
services
-
sync
/
resource
.
js
"
)
;
const
{
Utils
}
=
ChromeUtils
.
import
(
"
resource
:
/
/
services
-
sync
/
util
.
js
"
)
;
const
{
Async
}
=
ChromeUtils
.
import
(
"
resource
:
/
/
services
-
common
/
async
.
js
"
)
;
const
{
CommonUtils
}
=
ChromeUtils
.
import
(
"
resource
:
/
/
services
-
common
/
utils
.
js
"
)
;
const
{
CryptoUtils
}
=
ChromeUtils
.
import
(
"
resource
:
/
/
services
-
crypto
/
utils
.
js
"
)
;
function
WBORecord
(
collection
id
)
{
this
.
data
=
{
}
;
this
.
payload
=
{
}
;
this
.
collection
=
collection
;
this
.
id
=
id
;
}
WBORecord
.
prototype
=
{
_logName
:
"
Sync
.
Record
.
WBO
"
get
sortindex
(
)
{
if
(
this
.
data
.
sortindex
)
{
return
this
.
data
.
sortindex
;
}
return
0
;
}
async
fetch
(
resource
)
{
if
(
!
(
resource
instanceof
Resource
)
)
{
throw
new
Error
(
"
First
argument
must
be
a
Resource
instance
.
"
)
;
}
let
r
=
await
resource
.
get
(
)
;
if
(
r
.
success
)
{
this
.
deserialize
(
r
.
obj
)
;
}
this
.
response
=
r
;
return
this
;
}
upload
(
resource
)
{
if
(
!
(
resource
instanceof
Resource
)
)
{
throw
new
Error
(
"
First
argument
must
be
a
Resource
instance
.
"
)
;
}
return
resource
.
put
(
this
)
;
}
uri
(
base
)
{
if
(
this
.
collection
&
&
this
.
id
)
{
let
url
=
CommonUtils
.
makeURI
(
base
+
this
.
collection
+
"
/
"
+
this
.
id
)
;
url
.
QueryInterface
(
Ci
.
nsIURL
)
;
return
url
;
}
return
null
;
}
deserialize
:
function
deserialize
(
json
)
{
if
(
!
json
|
|
typeof
json
!
=
=
"
object
"
)
{
throw
new
TypeError
(
"
Can
'
t
deserialize
record
from
:
"
+
json
)
;
}
this
.
data
=
json
;
try
{
this
.
payload
=
JSON
.
parse
(
this
.
payload
)
;
}
catch
(
ex
)
{
}
}
toJSON
:
function
toJSON
(
)
{
let
obj
=
{
}
;
for
(
let
[
key
val
]
of
Object
.
entries
(
this
.
data
)
)
{
obj
[
key
]
=
key
=
=
"
payload
"
?
JSON
.
stringify
(
val
)
:
val
;
}
if
(
this
.
ttl
)
{
obj
.
ttl
=
this
.
ttl
;
}
return
obj
;
}
toString
:
function
toString
(
)
{
return
(
"
{
"
+
"
id
:
"
+
this
.
id
+
"
"
+
"
index
:
"
+
this
.
sortindex
+
"
"
+
"
modified
:
"
+
this
.
modified
+
"
"
+
"
ttl
:
"
+
this
.
ttl
+
"
"
+
"
payload
:
"
+
JSON
.
stringify
(
this
.
payload
)
+
"
}
"
)
;
}
}
;
Utils
.
deferGetSet
(
WBORecord
"
data
"
[
"
id
"
"
modified
"
"
sortindex
"
"
payload
"
]
)
;
function
RawCryptoWrapper
(
collection
id
)
{
this
.
cleartext
=
this
.
defaultCleartext
(
)
;
WBORecord
.
call
(
this
collection
id
)
;
this
.
ciphertext
=
null
;
}
RawCryptoWrapper
.
prototype
=
{
__proto__
:
WBORecord
.
prototype
_logName
:
"
Sync
.
Record
.
RawCryptoWrapper
"
defaultCleartext
(
)
{
return
null
;
}
transformBeforeEncrypt
(
outgoingCleartext
)
{
throw
new
TypeError
(
"
Override
to
stringify
outgoing
records
"
)
;
}
transformAfterDecrypt
(
incomingCleartext
)
{
throw
new
TypeError
(
"
Override
to
parse
incoming
records
"
)
;
}
ciphertextHMAC
:
async
function
ciphertextHMAC
(
keyBundle
)
{
let
hmacKeyByteString
=
keyBundle
.
hmacKey
;
if
(
!
hmacKeyByteString
)
{
throw
new
Error
(
"
Cannot
compute
HMAC
without
an
HMAC
key
.
"
)
;
}
let
hmacKey
=
CommonUtils
.
byteStringToArrayBuffer
(
hmacKeyByteString
)
;
let
data
=
CommonUtils
.
byteStringToArrayBuffer
(
this
.
ciphertext
)
;
let
hmac
=
await
CryptoUtils
.
hmac
(
"
SHA
-
256
"
hmacKey
data
)
;
return
CommonUtils
.
bytesAsHex
(
CommonUtils
.
arrayBufferToByteString
(
hmac
)
)
;
}
async
encrypt
(
keyBundle
)
{
if
(
!
keyBundle
)
{
throw
new
Error
(
"
A
key
bundle
must
be
supplied
to
encrypt
.
"
)
;
}
this
.
IV
=
Weave
.
Crypto
.
generateRandomIV
(
)
;
this
.
ciphertext
=
await
Weave
.
Crypto
.
encrypt
(
this
.
transformBeforeEncrypt
(
this
.
cleartext
)
keyBundle
.
encryptionKeyB64
this
.
IV
)
;
this
.
hmac
=
await
this
.
ciphertextHMAC
(
keyBundle
)
;
this
.
cleartext
=
null
;
}
async
decrypt
(
keyBundle
)
{
if
(
!
this
.
ciphertext
)
{
throw
new
Error
(
"
No
ciphertext
:
nothing
to
decrypt
?
"
)
;
}
if
(
!
keyBundle
)
{
throw
new
Error
(
"
A
key
bundle
must
be
supplied
to
decrypt
.
"
)
;
}
let
computedHMAC
=
await
this
.
ciphertextHMAC
(
keyBundle
)
;
if
(
computedHMAC
!
=
this
.
hmac
)
{
Utils
.
throwHMACMismatch
(
this
.
hmac
computedHMAC
)
;
}
let
cleartext
=
await
Weave
.
Crypto
.
decrypt
(
this
.
ciphertext
keyBundle
.
encryptionKeyB64
this
.
IV
)
;
this
.
cleartext
=
this
.
transformAfterDecrypt
(
cleartext
)
;
this
.
ciphertext
=
null
;
return
this
.
cleartext
;
}
}
;
Utils
.
deferGetSet
(
RawCryptoWrapper
"
payload
"
[
"
ciphertext
"
"
IV
"
"
hmac
"
]
)
;
function
CryptoWrapper
(
collection
id
)
{
RawCryptoWrapper
.
call
(
this
collection
id
)
;
}
CryptoWrapper
.
prototype
=
{
__proto__
:
RawCryptoWrapper
.
prototype
_logName
:
"
Sync
.
Record
.
CryptoWrapper
"
defaultCleartext
(
)
{
return
{
}
;
}
transformBeforeEncrypt
(
cleartext
)
{
return
JSON
.
stringify
(
cleartext
)
;
}
transformAfterDecrypt
(
cleartext
)
{
let
json_result
=
JSON
.
parse
(
cleartext
)
;
if
(
!
(
json_result
&
&
json_result
instanceof
Object
)
)
{
throw
new
Error
(
Decryption
failed
:
result
is
<
{
json_result
}
>
not
an
object
.
)
;
}
if
(
json_result
.
id
!
=
this
.
id
)
{
throw
new
Error
(
Record
id
mismatch
:
{
json_result
.
id
}
!
=
{
this
.
id
}
)
;
}
return
json_result
;
}
cleartextToString
(
)
{
return
JSON
.
stringify
(
this
.
cleartext
)
;
}
toString
:
function
toString
(
)
{
let
payload
=
this
.
deleted
?
"
DELETED
"
:
this
.
cleartextToString
(
)
;
return
(
"
{
"
+
"
id
:
"
+
this
.
id
+
"
"
+
"
index
:
"
+
this
.
sortindex
+
"
"
+
"
modified
:
"
+
this
.
modified
+
"
"
+
"
ttl
:
"
+
this
.
ttl
+
"
"
+
"
payload
:
"
+
payload
+
"
"
+
"
collection
:
"
+
(
this
.
collection
|
|
"
undefined
"
)
+
"
}
"
)
;
}
get
id
(
)
{
return
super
.
id
;
}
set
id
(
val
)
{
super
.
id
=
val
;
this
.
cleartext
.
id
=
val
;
}
}
;
Utils
.
deferGetSet
(
CryptoWrapper
"
cleartext
"
"
deleted
"
)
;
function
RecordManager
(
service
)
{
this
.
service
=
service
;
this
.
_log
=
Log
.
repository
.
getLogger
(
this
.
_logName
)
;
this
.
_records
=
{
}
;
}
RecordManager
.
prototype
=
{
_recordType
:
CryptoWrapper
_logName
:
"
Sync
.
RecordManager
"
async
import
(
url
)
{
this
.
_log
.
trace
(
"
Importing
record
:
"
+
(
url
.
spec
?
url
.
spec
:
url
)
)
;
try
{
this
.
response
=
{
}
;
this
.
response
=
await
this
.
service
.
resource
(
url
)
.
get
(
)
;
if
(
!
this
.
response
.
success
)
{
return
null
;
}
let
record
=
new
this
.
_recordType
(
url
)
;
record
.
deserialize
(
this
.
response
.
obj
)
;
return
this
.
set
(
url
record
)
;
}
catch
(
ex
)
{
if
(
Async
.
isShutdownException
(
ex
)
)
{
throw
ex
;
}
this
.
_log
.
debug
(
"
Failed
to
import
record
"
ex
)
;
return
null
;
}
}
get
(
url
)
{
let
spec
=
url
.
spec
?
url
.
spec
:
url
;
if
(
spec
in
this
.
_records
)
{
return
Promise
.
resolve
(
this
.
_records
[
spec
]
)
;
}
return
this
.
import
(
url
)
;
}
set
:
function
RecordMgr_set
(
url
record
)
{
let
spec
=
url
.
spec
?
url
.
spec
:
url
;
return
(
this
.
_records
[
spec
]
=
record
)
;
}
contains
:
function
RecordMgr_contains
(
url
)
{
if
(
(
url
.
spec
|
|
url
)
in
this
.
_records
)
{
return
true
;
}
return
false
;
}
clearCache
:
function
recordMgr_clearCache
(
)
{
this
.
_records
=
{
}
;
}
del
:
function
RecordMgr_del
(
url
)
{
delete
this
.
_records
[
url
]
;
}
}
;
function
CollectionKeyManager
(
lastModified
default_
collections
)
{
this
.
lastModified
=
lastModified
|
|
0
;
this
.
_default
=
default_
|
|
null
;
this
.
_collections
=
collections
|
|
{
}
;
this
.
_log
=
Log
.
repository
.
getLogger
(
"
Sync
.
CollectionKeyManager
"
)
;
}
CollectionKeyManager
.
prototype
=
{
clone
(
)
{
const
newCollections
=
{
}
;
for
(
let
c
in
this
.
_collections
)
{
newCollections
[
c
]
=
this
.
_collections
[
c
]
;
}
return
new
CollectionKeyManager
(
this
.
lastModified
this
.
_default
newCollections
)
;
}
_compareKeyBundleCollections
:
function
_compareKeyBundleCollections
(
m1
m2
)
{
let
changed
=
[
]
;
function
process
(
m1
m2
)
{
for
(
let
k1
in
m1
)
{
let
v1
=
m1
[
k1
]
;
let
v2
=
m2
[
k1
]
;
if
(
!
(
v1
&
&
v2
&
&
v1
.
equals
(
v2
)
)
)
{
changed
.
push
(
k1
)
;
}
}
}
process
(
m1
m2
)
;
process
(
m2
m1
)
;
changed
.
sort
(
)
;
let
last
;
changed
=
changed
.
filter
(
x
=
>
x
!
=
last
&
&
(
last
=
x
)
)
;
return
{
same
:
!
changed
.
length
changed
}
;
}
get
isClear
(
)
{
return
!
this
.
_default
;
}
clear
:
function
clear
(
)
{
this
.
_log
.
info
(
"
Clearing
collection
keys
.
.
.
"
)
;
this
.
lastModified
=
0
;
this
.
_collections
=
{
}
;
this
.
_default
=
null
;
}
keyForCollection
(
collection
)
{
if
(
collection
&
&
this
.
_collections
[
collection
]
)
{
return
this
.
_collections
[
collection
]
;
}
return
this
.
_default
;
}
_makeWBO
(
collections
defaultBundle
)
{
let
wbo
=
new
CryptoWrapper
(
CRYPTO_COLLECTION
KEYS_WBO
)
;
let
c
=
{
}
;
for
(
let
k
in
collections
)
{
c
[
k
]
=
collections
[
k
]
.
keyPairB64
;
}
wbo
.
cleartext
=
{
default
:
defaultBundle
?
defaultBundle
.
keyPairB64
:
null
collections
:
c
collection
:
CRYPTO_COLLECTION
id
:
KEYS_WBO
}
;
return
wbo
;
}
asWBO
(
collection
id
)
{
return
this
.
_makeWBO
(
this
.
_collections
this
.
_default
)
;
}
async
newKeys
(
collections
)
{
let
newDefaultKeyBundle
=
await
this
.
newDefaultKeyBundle
(
)
;
let
newColls
=
{
}
;
if
(
collections
)
{
for
(
let
c
of
collections
)
{
let
b
=
new
BulkKeyBundle
(
c
)
;
await
b
.
generateRandom
(
)
;
newColls
[
c
]
=
b
;
}
}
return
[
newDefaultKeyBundle
newColls
]
;
}
async
generateNewKeysWBO
(
collections
)
{
let
newDefaultKey
newColls
;
[
newDefaultKey
newColls
]
=
await
this
.
newKeys
(
collections
)
;
return
this
.
_makeWBO
(
newColls
newDefaultKey
)
;
}
async
newDefaultKeyBundle
(
)
{
const
key
=
new
BulkKeyBundle
(
DEFAULT_KEYBUNDLE_NAME
)
;
await
key
.
generateRandom
(
)
;
return
key
;
}
async
generateDefaultKey
(
)
{
this
.
_default
=
await
this
.
newDefaultKeyBundle
(
)
;
}
hasKeysFor
(
collections
)
{
for
(
let
collection
of
collections
)
{
if
(
!
this
.
_collections
[
collection
]
)
{
return
false
;
}
}
return
true
;
}
async
ensureKeysFor
(
collections
)
{
const
newKeys
=
Object
.
assign
(
{
}
this
.
_collections
)
;
for
(
let
c
of
collections
)
{
if
(
newKeys
[
c
]
)
{
continue
;
}
const
b
=
new
BulkKeyBundle
(
c
)
;
await
b
.
generateRandom
(
)
;
newKeys
[
c
]
=
b
;
}
return
new
CollectionKeyManager
(
this
.
lastModified
this
.
_default
newKeys
)
;
}
updateNeeded
(
info_collections
)
{
this
.
_log
.
info
(
"
Testing
for
updateNeeded
.
Last
modified
:
"
+
this
.
lastModified
)
;
if
(
!
this
.
lastModified
)
{
return
true
;
}
if
(
!
(
CRYPTO_COLLECTION
in
info_collections
)
)
{
return
true
;
}
return
info_collections
[
CRYPTO_COLLECTION
]
>
this
.
lastModified
;
}
setContents
:
function
setContents
(
payload
modified
)
{
let
self
=
this
;
this
.
_log
.
info
(
"
Setting
collection
keys
contents
.
Our
last
modified
:
"
+
this
.
lastModified
+
"
input
modified
:
"
+
modified
+
"
.
"
)
;
if
(
!
payload
)
{
throw
new
Error
(
"
No
payload
in
CollectionKeyManager
.
setContents
(
)
.
"
)
;
}
if
(
!
payload
.
default
)
{
this
.
_log
.
warn
(
"
No
downloaded
default
key
:
this
should
not
occur
.
"
)
;
this
.
_log
.
warn
(
"
Not
clearing
local
keys
.
"
)
;
throw
new
Error
(
"
No
default
key
in
CollectionKeyManager
.
setContents
(
)
.
Cannot
proceed
.
"
)
;
}
let
b
=
new
BulkKeyBundle
(
DEFAULT_KEYBUNDLE_NAME
)
;
b
.
keyPairB64
=
payload
.
default
;
let
newDefault
=
b
;
let
newCollections
=
{
}
;
if
(
"
collections
"
in
payload
)
{
this
.
_log
.
info
(
"
Processing
downloaded
per
-
collection
keys
.
"
)
;
let
colls
=
payload
.
collections
;
for
(
let
k
in
colls
)
{
let
v
=
colls
[
k
]
;
if
(
v
)
{
let
keyObj
=
new
BulkKeyBundle
(
k
)
;
keyObj
.
keyPairB64
=
v
;
newCollections
[
k
]
=
keyObj
;
}
}
}
let
sameDefault
=
this
.
_default
&
&
this
.
_default
.
equals
(
newDefault
)
;
let
collComparison
=
this
.
_compareKeyBundleCollections
(
newCollections
this
.
_collections
)
;
let
sameColls
=
collComparison
.
same
;
if
(
sameDefault
&
&
sameColls
)
{
self
.
_log
.
info
(
"
New
keys
are
the
same
as
our
old
keys
!
"
)
;
if
(
modified
)
{
self
.
_log
.
info
(
"
Bumped
local
modified
time
.
"
)
;
self
.
lastModified
=
modified
;
}
return
false
;
}
this
.
clear
(
)
;
this
.
_log
.
info
(
"
Saving
downloaded
keys
.
"
)
;
this
.
_default
=
newDefault
;
this
.
_collections
=
newCollections
;
if
(
modified
)
{
self
.
_log
.
info
(
"
Bumping
last
modified
to
"
+
modified
)
;
self
.
lastModified
=
modified
;
}
return
sameDefault
?
collComparison
.
changed
:
true
;
}
async
updateContents
(
syncKeyBundle
storage_keys
)
{
let
log
=
this
.
_log
;
log
.
info
(
"
Updating
collection
keys
.
.
.
"
)
;
let
payload
;
try
{
payload
=
await
storage_keys
.
decrypt
(
syncKeyBundle
)
;
}
catch
(
ex
)
{
log
.
warn
(
"
Got
exception
decrypting
storage
keys
with
sync
key
.
"
ex
)
;
log
.
info
(
"
Aborting
updateContents
.
Rethrowing
.
"
)
;
throw
ex
;
}
let
r
=
this
.
setContents
(
payload
storage_keys
.
modified
)
;
log
.
info
(
"
Collection
keys
updated
.
"
)
;
return
r
;
}
}
;
function
Collection
(
uri
recordObj
service
)
{
if
(
!
service
)
{
throw
new
Error
(
"
Collection
constructor
requires
a
service
.
"
)
;
}
Resource
.
call
(
this
uri
)
;
let
res
=
service
.
resource
(
uri
)
;
this
.
authenticator
=
res
.
authenticator
;
this
.
_recordObj
=
recordObj
;
this
.
_service
=
service
;
this
.
_full
=
false
;
this
.
_ids
=
null
;
this
.
_limit
=
0
;
this
.
_older
=
0
;
this
.
_newer
=
0
;
this
.
_data
=
[
]
;
this
.
_batch
=
null
;
this
.
_commit
=
false
;
this
.
_offset
=
null
;
}
Collection
.
prototype
=
{
__proto__
:
Resource
.
prototype
_logName
:
"
Sync
.
Collection
"
_rebuildURL
:
function
Coll__rebuildURL
(
)
{
this
.
uri
.
QueryInterface
(
Ci
.
nsIURL
)
;
let
args
=
[
]
;
if
(
this
.
older
)
{
args
.
push
(
"
older
=
"
+
this
.
older
)
;
}
if
(
this
.
newer
)
{
args
.
push
(
"
newer
=
"
+
this
.
newer
)
;
}
if
(
this
.
full
)
{
args
.
push
(
"
full
=
1
"
)
;
}
if
(
this
.
sort
)
{
args
.
push
(
"
sort
=
"
+
this
.
sort
)
;
}
if
(
this
.
ids
!
=
null
)
{
args
.
push
(
"
ids
=
"
+
this
.
ids
)
;
}
if
(
this
.
limit
>
0
&
&
this
.
limit
!
=
Infinity
)
{
args
.
push
(
"
limit
=
"
+
this
.
limit
)
;
}
if
(
this
.
_batch
)
{
args
.
push
(
"
batch
=
"
+
encodeURIComponent
(
this
.
_batch
)
)
;
}
if
(
this
.
_commit
)
{
args
.
push
(
"
commit
=
true
"
)
;
}
if
(
this
.
_offset
)
{
args
.
push
(
"
offset
=
"
+
encodeURIComponent
(
this
.
_offset
)
)
;
}
this
.
uri
=
this
.
uri
.
mutate
(
)
.
setQuery
(
args
.
length
?
"
?
"
+
args
.
join
(
"
&
"
)
:
"
"
)
.
finalize
(
)
;
}
get
full
(
)
{
return
this
.
_full
;
}
set
full
(
value
)
{
this
.
_full
=
value
;
this
.
_rebuildURL
(
)
;
}
get
ids
(
)
{
return
this
.
_ids
;
}
set
ids
(
value
)
{
this
.
_ids
=
value
;
this
.
_rebuildURL
(
)
;
}
get
limit
(
)
{
return
this
.
_limit
;
}
set
limit
(
value
)
{
this
.
_limit
=
value
;
this
.
_rebuildURL
(
)
;
}
get
older
(
)
{
return
this
.
_older
;
}
set
older
(
value
)
{
this
.
_older
=
value
;
this
.
_rebuildURL
(
)
;
}
get
newer
(
)
{
return
this
.
_newer
;
}
set
newer
(
value
)
{
this
.
_newer
=
value
;
this
.
_rebuildURL
(
)
;
}
get
sort
(
)
{
return
this
.
_sort
;
}
set
sort
(
value
)
{
if
(
value
&
&
value
!
=
"
oldest
"
&
&
value
!
=
"
newest
"
&
&
value
!
=
"
index
"
)
{
throw
new
TypeError
(
Illegal
value
for
sort
:
"
{
value
}
"
(
should
be
"
oldest
"
"
newest
"
or
"
index
"
)
.
)
;
}
this
.
_sort
=
value
;
this
.
_rebuildURL
(
)
;
}
get
offset
(
)
{
return
this
.
_offset
;
}
set
offset
(
value
)
{
this
.
_offset
=
value
;
this
.
_rebuildURL
(
)
;
}
get
batch
(
)
{
return
this
.
_batch
;
}
set
batch
(
value
)
{
this
.
_batch
=
value
;
this
.
_rebuildURL
(
)
;
}
get
commit
(
)
{
return
this
.
_commit
;
}
set
commit
(
value
)
{
this
.
_commit
=
value
&
&
true
;
this
.
_rebuildURL
(
)
;
}
async
getBatched
(
batchSize
=
DEFAULT_DOWNLOAD_BATCH_SIZE
)
{
let
totalLimit
=
Number
(
this
.
limit
)
|
|
Infinity
;
if
(
batchSize
<
=
0
|
|
batchSize
>
=
totalLimit
)
{
throw
new
Error
(
"
Invalid
batch
size
"
)
;
}
if
(
!
this
.
full
)
{
throw
new
Error
(
"
getBatched
is
unimplemented
for
guid
-
only
GETs
"
)
;
}
let
{
_onComplete
_onProgress
}
=
this
;
let
recordBuffer
=
[
]
;
let
resp
;
try
{
let
lastModifiedTime
;
this
.
limit
=
batchSize
;
do
{
this
.
_onProgress
=
_onProgress
;
this
.
_onComplete
=
_onComplete
;
if
(
batchSize
+
recordBuffer
.
length
>
totalLimit
)
{
this
.
limit
=
totalLimit
-
recordBuffer
.
length
;
}
this
.
_log
.
trace
(
"
Performing
batched
GET
"
{
limit
:
this
.
limit
offset
:
this
.
offset
}
)
;
resp
=
await
this
.
get
(
)
;
if
(
!
resp
.
success
)
{
recordBuffer
=
[
]
;
break
;
}
for
(
let
json
of
resp
.
obj
)
{
let
record
=
new
this
.
_recordObj
(
)
;
record
.
deserialize
(
json
)
;
recordBuffer
.
push
(
record
)
;
}
let
lastModified
=
resp
.
headers
[
"
x
-
last
-
modified
"
]
;
if
(
!
lastModifiedTime
)
{
lastModifiedTime
=
lastModified
;
this
.
setHeader
(
"
X
-
If
-
Unmodified
-
Since
"
lastModified
)
;
}
else
if
(
lastModified
!
=
lastModifiedTime
)
{
throw
new
Error
(
"
X
-
Last
-
Modified
changed
in
the
middle
of
a
download
batch
!
"
+
{
lastModified
}
=
>
{
lastModifiedTime
}
)
;
}
this
.
offset
=
resp
.
headers
[
"
x
-
weave
-
next
-
offset
"
]
;
}
while
(
this
.
offset
&
&
totalLimit
>
recordBuffer
.
length
)
;
}
finally
{
this
.
_limit
=
totalLimit
;
this
.
_offset
=
null
;
delete
this
.
_headers
[
"
x
-
if
-
unmodified
-
since
"
]
;
this
.
_rebuildURL
(
)
;
}
return
{
response
:
resp
records
:
recordBuffer
}
;
}
post
(
)
{
throw
new
Error
(
"
Don
'
t
directly
post
to
a
collection
-
use
newPostQueue
instead
"
)
;
}
newPostQueue
(
log
timestamp
postCallback
)
{
let
poster
=
(
data
headers
batch
commit
)
=
>
{
this
.
batch
=
batch
;
this
.
commit
=
commit
;
for
(
let
[
header
value
]
of
headers
)
{
this
.
setHeader
(
header
value
)
;
}
return
Resource
.
prototype
.
post
.
call
(
this
data
)
;
}
;
return
new
PostQueue
(
poster
timestamp
this
.
_service
.
serverConfiguration
|
|
{
}
log
postCallback
)
;
}
}
;
const
DefaultPostQueueConfig
=
Object
.
freeze
(
{
max_request_bytes
:
260
*
1024
max_record_payload_bytes
:
256
*
1024
max_post_bytes
:
Infinity
max_post_records
:
Infinity
max_total_bytes
:
Infinity
max_total_records
:
Infinity
}
)
;
class
LimitTracker
{
constructor
(
maxBytes
maxRecords
)
{
this
.
maxBytes
=
maxBytes
;
this
.
maxRecords
=
maxRecords
;
this
.
curBytes
=
0
;
this
.
curRecords
=
0
;
}
clear
(
)
{
this
.
curBytes
=
0
;
this
.
curRecords
=
0
;
}
canAddRecord
(
payloadSize
)
{
return
(
this
.
curRecords
+
1
<
=
this
.
maxRecords
&
&
this
.
curBytes
+
payloadSize
<
this
.
maxBytes
)
;
}
canNeverAdd
(
recordSize
)
{
return
recordSize
>
=
this
.
maxBytes
;
}
didAddRecord
(
recordSize
)
{
if
(
!
this
.
canAddRecord
(
recordSize
)
)
{
throw
new
Error
(
"
LimitTracker
.
canAddRecord
must
be
checked
before
adding
record
"
)
;
}
this
.
curRecords
+
=
1
;
this
.
curBytes
+
=
recordSize
;
}
}
function
PostQueue
(
poster
timestamp
serverConfig
log
postCallback
)
{
this
.
poster
=
poster
;
this
.
log
=
log
;
let
config
=
Object
.
assign
(
{
}
DefaultPostQueueConfig
serverConfig
)
;
if
(
!
serverConfig
.
max_request_bytes
&
&
serverConfig
.
max_post_bytes
)
{
config
.
max_request_bytes
=
serverConfig
.
max_post_bytes
;
}
this
.
log
.
trace
(
"
new
PostQueue
config
(
after
defaults
)
:
"
config
)
;
this
.
postCallback
=
postCallback
;
this
.
postLimits
=
new
LimitTracker
(
config
.
max_post_bytes
config
.
max_post_records
)
;
this
.
batchLimits
=
new
LimitTracker
(
config
.
max_total_bytes
config
.
max_total_records
)
;
this
.
maxRequestBytes
=
config
.
max_request_bytes
;
this
.
maxPayloadBytes
=
config
.
max_record_payload_bytes
;
this
.
queued
=
"
"
;
this
.
batchID
=
undefined
;
this
.
lastModified
=
timestamp
;
}
PostQueue
.
prototype
=
{
async
enqueue
(
record
)
{
let
jsonRepr
=
record
.
toJSON
(
)
;
if
(
!
jsonRepr
)
{
throw
new
Error
(
"
You
must
only
call
this
with
objects
that
explicitly
support
JSON
"
)
;
}
let
bytes
=
JSON
.
stringify
(
jsonRepr
)
;
let
payloadLength
=
jsonRepr
.
payload
.
length
;
let
encodedLength
=
bytes
.
length
+
2
;
let
isTooBig
=
this
.
postLimits
.
canNeverAdd
(
payloadLength
)
|
|
this
.
batchLimits
.
canNeverAdd
(
payloadLength
)
|
|
encodedLength
>
=
this
.
maxRequestBytes
|
|
payloadLength
>
=
this
.
maxPayloadBytes
;
if
(
isTooBig
)
{
return
{
enqueued
:
false
error
:
new
Error
(
"
Single
record
too
large
to
submit
to
server
"
)
}
;
}
let
canPostRecord
=
this
.
postLimits
.
canAddRecord
(
payloadLength
)
;
let
canBatchRecord
=
this
.
batchLimits
.
canAddRecord
(
payloadLength
)
;
let
canSendRecord
=
this
.
queued
.
length
+
encodedLength
<
this
.
maxRequestBytes
;
if
(
!
canPostRecord
|
|
!
canBatchRecord
|
|
!
canSendRecord
)
{
this
.
log
.
trace
(
"
PostQueue
flushing
:
"
{
canPostRecord
canSendRecord
canBatchRecord
}
)
;
await
this
.
flush
(
!
canBatchRecord
)
;
}
this
.
postLimits
.
didAddRecord
(
payloadLength
)
;
this
.
batchLimits
.
didAddRecord
(
payloadLength
)
;
this
.
queued
+
=
this
.
queued
.
length
?
"
"
:
"
[
"
;
this
.
queued
+
=
bytes
;
return
{
enqueued
:
true
}
;
}
async
flush
(
finalBatchPost
)
{
if
(
!
this
.
queued
)
{
if
(
this
.
batchID
)
{
throw
new
Error
(
Flush
called
when
no
queued
records
but
we
are
in
a
batch
{
this
.
batchID
}
)
;
}
return
;
}
let
batch
;
let
headers
=
[
]
;
if
(
this
.
batchID
=
=
=
undefined
)
{
batch
=
"
true
"
;
}
else
if
(
this
.
batchID
)
{
batch
=
this
.
batchID
;
}
else
{
batch
=
null
;
}
headers
.
push
(
[
"
x
-
if
-
unmodified
-
since
"
this
.
lastModified
]
)
;
let
numQueued
=
this
.
postLimits
.
curRecords
;
this
.
log
.
info
(
Posting
{
numQueued
}
records
of
{
this
.
queued
.
length
+
1
}
bytes
with
batch
=
{
batch
}
)
;
let
queued
=
this
.
queued
+
"
]
"
;
if
(
finalBatchPost
)
{
this
.
batchLimits
.
clear
(
)
;
}
this
.
postLimits
.
clear
(
)
;
this
.
queued
=
"
"
;
let
response
=
await
this
.
poster
(
queued
headers
batch
!
!
(
finalBatchPost
&
&
this
.
batchID
!
=
=
null
)
)
;
if
(
!
response
.
success
)
{
this
.
log
.
trace
(
"
Server
error
response
during
a
batch
"
response
)
;
await
this
.
postCallback
(
this
response
!
finalBatchPost
)
;
return
;
}
if
(
finalBatchPost
)
{
this
.
log
.
trace
(
"
Committed
batch
"
this
.
batchID
)
;
this
.
batchID
=
undefined
;
this
.
lastModified
=
response
.
headers
[
"
x
-
last
-
modified
"
]
;
await
this
.
postCallback
(
this
response
false
)
;
return
;
}
if
(
response
.
status
!
=
202
)
{
if
(
this
.
batchID
)
{
throw
new
Error
(
"
Server
responded
non
-
202
success
code
while
a
batch
was
in
progress
"
)
;
}
this
.
batchID
=
null
;
this
.
lastModified
=
response
.
headers
[
"
x
-
last
-
modified
"
]
;
await
this
.
postCallback
(
this
response
false
)
;
return
;
}
let
responseBatchID
=
response
.
obj
.
batch
;
this
.
log
.
trace
(
"
Server
responsed
202
with
batch
"
responseBatchID
)
;
if
(
!
responseBatchID
)
{
this
.
log
.
error
(
"
Invalid
server
response
:
202
without
a
batch
ID
"
response
)
;
throw
new
Error
(
"
Invalid
server
response
:
202
without
a
batch
ID
"
)
;
}
if
(
this
.
batchID
=
=
=
undefined
)
{
this
.
batchID
=
responseBatchID
;
if
(
!
this
.
lastModified
)
{
this
.
lastModified
=
response
.
headers
[
"
x
-
last
-
modified
"
]
;
if
(
!
this
.
lastModified
)
{
throw
new
Error
(
"
Batch
response
without
x
-
last
-
modified
"
)
;
}
}
}
if
(
this
.
batchID
!
=
responseBatchID
)
{
throw
new
Error
(
Invalid
client
/
server
batch
state
-
client
has
{
this
.
batchID
}
server
has
{
responseBatchID
}
)
;
}
await
this
.
postCallback
(
this
response
true
)
;
}
}
;
