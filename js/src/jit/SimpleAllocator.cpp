#
include
"
jit
/
SimpleAllocator
.
h
"
#
include
"
mozilla
/
Maybe
.
h
"
#
include
<
algorithm
>
#
include
"
jit
/
BitSet
.
h
"
#
include
"
jit
/
CompileInfo
.
h
"
#
include
"
js
/
Printf
.
h
"
using
namespace
js
;
using
namespace
js
:
:
jit
;
using
mozilla
:
:
DebugOnly
;
using
mozilla
:
:
Maybe
;
static
AnyRegister
MaybeGetRegisterFromSet
(
AllocatableRegisterSet
regs
LDefinition
:
:
Type
type
)
{
switch
(
type
)
{
case
LDefinition
:
:
Type
:
:
FLOAT32
:
if
(
regs
.
hasAny
<
RegTypeName
:
:
Float32
>
(
)
)
{
return
AnyRegister
(
regs
.
getAnyFloat
<
RegTypeName
:
:
Float32
>
(
)
)
;
}
break
;
case
LDefinition
:
:
Type
:
:
DOUBLE
:
if
(
regs
.
hasAny
<
RegTypeName
:
:
Float64
>
(
)
)
{
return
AnyRegister
(
regs
.
getAnyFloat
<
RegTypeName
:
:
Float64
>
(
)
)
;
}
break
;
case
LDefinition
:
:
Type
:
:
SIMD128
:
if
(
regs
.
hasAny
<
RegTypeName
:
:
Vector128
>
(
)
)
{
return
AnyRegister
(
regs
.
getAnyFloat
<
RegTypeName
:
:
Vector128
>
(
)
)
;
}
break
;
default
:
MOZ_ASSERT
(
!
LDefinition
:
:
isFloatReg
(
type
)
)
;
if
(
regs
.
hasAny
<
RegTypeName
:
:
GPR
>
(
)
)
{
return
AnyRegister
(
regs
.
getAnyGeneral
(
)
)
;
}
break
;
}
return
AnyRegister
(
)
;
}
bool
SimpleAllocator
:
:
init
(
)
{
size_t
numBlocks
=
graph
.
numBlocks
(
)
;
if
(
!
liveGCIn_
.
growBy
(
numBlocks
)
)
{
return
false
;
}
size_t
numVregs
=
graph
.
numVirtualRegisters
(
)
;
if
(
!
vregs_
.
initCapacity
(
numVregs
)
)
{
return
false
;
}
for
(
size_t
i
=
0
;
i
<
numVregs
;
i
+
+
)
{
vregs_
.
infallibleEmplaceBack
(
)
;
}
for
(
size_t
blockIndex
=
0
;
blockIndex
<
numBlocks
;
blockIndex
+
+
)
{
if
(
mir
-
>
shouldCancel
(
"
init
(
block
loop
)
"
)
)
{
return
false
;
}
LBlock
*
block
=
graph
.
getBlock
(
blockIndex
)
;
for
(
uint32_t
i
=
0
numPhis
=
block
-
>
numPhis
(
)
;
i
<
numPhis
;
i
+
+
)
{
LPhi
*
phi
=
block
-
>
getPhi
(
i
)
;
LDefinition
*
def
=
phi
-
>
getDef
(
0
)
;
vregs_
[
def
-
>
virtualRegister
(
)
]
.
init
(
phi
def
false
)
;
}
for
(
LInstructionIterator
iter
=
block
-
>
begin
(
)
;
iter
!
=
block
-
>
end
(
)
;
iter
+
+
)
{
LInstruction
*
ins
=
*
iter
;
for
(
LInstruction
:
:
OutputIter
output
(
ins
)
;
!
output
.
done
(
)
;
output
+
+
)
{
LDefinition
*
def
=
*
output
;
vregs_
[
def
-
>
virtualRegister
(
)
]
.
init
(
ins
def
false
)
;
}
for
(
LInstruction
:
:
TempIter
temp
(
ins
)
;
!
temp
.
done
(
)
;
temp
+
+
)
{
LDefinition
*
def
=
*
temp
;
vregs_
[
def
-
>
virtualRegister
(
)
]
.
init
(
ins
def
true
)
;
}
}
}
return
true
;
}
bool
SimpleAllocator
:
:
analyzeLiveness
(
)
{
JitSpew
(
JitSpew_RegAlloc
"
Beginning
liveness
analysis
"
)
;
struct
LoopState
{
uint32_t
firstId
;
uint32_t
lastId
;
explicit
LoopState
(
LBlock
*
header
uint32_t
lastId
)
:
firstId
(
header
-
>
firstId
(
)
)
lastId
(
lastId
)
{
}
}
;
Vector
<
LoopState
4
BackgroundSystemAllocPolicy
>
loopStack
;
#
ifdef
DEBUG
uint32_t
lastInsId
=
UINT32_MAX
;
#
endif
for
(
size_t
i
=
graph
.
numBlocks
(
)
;
i
>
0
;
i
-
-
)
{
if
(
mir
-
>
shouldCancel
(
"
analyzeLiveness
(
block
loop
)
"
)
)
{
return
false
;
}
LBlock
*
block
=
graph
.
getBlock
(
i
-
1
)
;
MBasicBlock
*
mblock
=
block
-
>
mir
(
)
;
VirtualRegBitSet
&
liveGC
=
liveGCIn_
[
mblock
-
>
id
(
)
]
;
if
(
mblock
-
>
isLoopBackedge
(
)
)
{
if
(
!
loopStack
.
emplaceBack
(
mblock
-
>
loopHeaderOfBackedge
(
)
-
>
lir
(
)
block
-
>
lastId
(
)
)
)
{
return
false
;
}
}
for
(
size_t
i
=
0
;
i
<
mblock
-
>
lastIns
(
)
-
>
numSuccessors
(
)
;
i
+
+
)
{
MBasicBlock
*
successor
=
mblock
-
>
lastIns
(
)
-
>
getSuccessor
(
i
)
;
if
(
mblock
-
>
id
(
)
<
successor
-
>
id
(
)
)
{
if
(
!
liveGC
.
insertAll
(
liveGCIn_
[
successor
-
>
id
(
)
]
)
)
{
return
false
;
}
}
}
uint32_t
blockFirstId
=
block
-
>
firstId
(
)
;
auto
handleUseOfVreg
=
[
&
]
(
uint32_t
insId
uint32_t
vregId
)
{
uint32_t
defId
=
vregs_
[
vregId
]
.
insId
(
)
;
const
LoopState
*
outerLoop
=
nullptr
;
if
(
defId
<
blockFirstId
)
{
if
(
vregs_
[
vregId
]
.
isGCType
(
)
&
&
!
liveGC
.
insert
(
vregId
)
)
{
return
false
;
}
for
(
size_t
i
=
loopStack
.
length
(
)
;
i
>
0
;
i
-
-
)
{
const
LoopState
&
loop
=
loopStack
[
i
-
1
]
;
if
(
defId
>
=
loop
.
firstId
)
{
break
;
}
outerLoop
=
&
loop
;
}
}
vregs_
[
vregId
]
.
updateLastUseId
(
outerLoop
?
outerLoop
-
>
lastId
:
insId
)
;
return
true
;
}
;
if
(
MBasicBlock
*
successor
=
mblock
-
>
successorWithPhis
(
)
)
{
LBlock
*
phiSuccessor
=
successor
-
>
lir
(
)
;
uint32_t
blockLastInsId
=
block
-
>
lastId
(
)
;
for
(
size_t
j
=
0
;
j
<
phiSuccessor
-
>
numPhis
(
)
;
j
+
+
)
{
LPhi
*
phi
=
phiSuccessor
-
>
getPhi
(
j
)
;
LAllocation
*
use
=
phi
-
>
getOperand
(
mblock
-
>
positionInPhiSuccessor
(
)
)
;
if
(
!
handleUseOfVreg
(
blockLastInsId
use
-
>
toUse
(
)
-
>
virtualRegister
(
)
)
)
{
return
false
;
}
}
}
for
(
LInstructionReverseIterator
ins
=
block
-
>
rbegin
(
)
;
ins
!
=
block
-
>
rend
(
)
;
ins
+
+
)
{
if
(
mir
-
>
shouldCancel
(
"
analyzeLiveness
(
instruction
loop
)
"
)
)
{
return
false
;
}
#
ifdef
DEBUG
MOZ_ASSERT
(
ins
-
>
id
(
)
<
lastInsId
)
;
lastInsId
=
ins
-
>
id
(
)
;
#
endif
for
(
LInstruction
:
:
OutputIter
output
(
*
ins
)
;
!
output
.
done
(
)
;
output
+
+
)
{
uint32_t
vregId
=
output
-
>
virtualRegister
(
)
;
if
(
vregs_
[
vregId
]
.
isGCType
(
)
)
{
liveGC
.
remove
(
vregId
)
;
}
}
for
(
LInstruction
:
:
InputIter
inputAlloc
(
*
*
ins
)
;
inputAlloc
.
more
(
)
;
inputAlloc
.
next
(
)
)
{
if
(
!
inputAlloc
-
>
isUse
(
)
)
{
continue
;
}
LUse
*
use
=
inputAlloc
-
>
toUse
(
)
;
uint32_t
vregId
=
use
-
>
virtualRegister
(
)
;
if
(
!
handleUseOfVreg
(
ins
-
>
id
(
)
vregId
)
)
{
return
false
;
}
if
(
use
-
>
policy
(
)
=
=
LUse
:
:
FIXED
)
{
VirtualRegister
&
vreg
=
vregs_
[
vregId
]
;
AnyRegister
fixedReg
=
GetFixedRegister
(
vreg
.
def
(
)
use
)
;
if
(
vreg
.
fixedUseHint
(
)
.
isNothing
(
)
)
{
vreg
.
setFixedUseHint
(
fixedReg
)
;
}
else
if
(
*
vreg
.
fixedUseHint
(
)
!
=
fixedReg
)
{
vreg
.
setFixedUseHint
(
AnyRegister
(
)
)
;
}
}
}
}
for
(
size_t
i
=
0
;
i
<
block
-
>
numPhis
(
)
;
i
+
+
)
{
LPhi
*
phi
=
block
-
>
getPhi
(
i
)
;
LDefinition
*
def
=
phi
-
>
getDef
(
0
)
;
uint32_t
vregId
=
def
-
>
virtualRegister
(
)
;
if
(
vregs_
[
vregId
]
.
isGCType
(
)
)
{
liveGC
.
remove
(
vregId
)
;
}
if
(
mblock
-
>
isLoopHeader
(
)
)
{
vregs_
[
vregId
]
.
updateLastUseId
(
loopStack
.
back
(
)
.
lastId
)
;
}
}
if
(
mblock
-
>
isLoopHeader
(
)
)
{
MBasicBlock
*
backedge
=
mblock
-
>
backedge
(
)
;
MOZ_ASSERT
(
loopStack
.
back
(
)
.
firstId
=
=
block
-
>
firstId
(
)
)
;
loopStack
.
popBack
(
)
;
if
(
mblock
!
=
backedge
&
&
!
liveGC
.
empty
(
)
)
{
MOZ_ASSERT
(
graph
.
getBlock
(
i
-
1
)
=
=
mblock
-
>
lir
(
)
)
;
size_t
j
=
i
;
while
(
true
)
{
MBasicBlock
*
loopBlock
=
graph
.
getBlock
(
j
)
-
>
mir
(
)
;
if
(
!
liveGCIn_
[
loopBlock
-
>
id
(
)
]
.
insertAll
(
liveGC
)
)
{
return
false
;
}
if
(
loopBlock
=
=
backedge
)
{
break
;
}
j
+
+
;
}
}
}
MOZ_ASSERT_IF
(
!
mblock
-
>
numPredecessors
(
)
liveGC
.
empty
(
)
)
;
}
MOZ_ASSERT
(
loopStack
.
empty
(
)
)
;
uint32_t
numVregs
=
vregs_
.
length
(
)
;
if
(
!
vregLastUses_
.
reserve
(
numVregs
)
)
{
return
false
;
}
for
(
uint32_t
vregId
=
1
;
vregId
<
numVregs
;
vregId
+
+
)
{
vregLastUses_
.
infallibleEmplaceBack
(
vregs_
[
vregId
]
.
lastUseInsId
(
)
vregId
)
;
}
auto
compareEntries
=
[
]
(
VregLastUse
a
VregLastUse
b
)
{
return
a
.
instructionId
>
b
.
instructionId
;
}
;
std
:
:
sort
(
vregLastUses_
.
begin
(
)
vregLastUses_
.
end
(
)
compareEntries
)
;
return
true
;
}
void
SimpleAllocator
:
:
removeAllocatedRegisterAtIndex
(
size_t
index
)
{
AllocatedRegister
allocated
=
allocatedRegs_
[
index
]
;
uint32_t
vregId
=
allocated
.
vregId
(
)
;
availableRegs_
.
add
(
allocated
.
reg
(
)
)
;
size_t
lastIndex
=
allocatedRegs_
.
length
(
)
-
1
;
if
(
index
!
=
lastIndex
)
{
uint32_t
lastVregId
=
allocatedRegs_
.
back
(
)
.
vregId
(
)
;
allocatedRegs_
[
index
]
=
allocatedRegs_
.
back
(
)
;
if
(
vregs_
[
lastVregId
]
.
registerIndex
(
)
=
=
lastIndex
)
{
vregs_
[
lastVregId
]
.
setRegisterIndex
(
index
)
;
}
}
allocatedRegs_
.
popBack
(
)
;
vregs_
[
vregId
]
.
clearRegisterIndex
(
)
;
if
(
MOZ_UNLIKELY
(
hasMultipleRegsForVreg_
)
)
{
for
(
size_t
j
=
0
;
j
<
allocatedRegs_
.
length
(
)
;
j
+
+
)
{
if
(
allocatedRegs_
[
j
]
.
vregId
(
)
=
=
vregId
)
{
vregs_
[
vregId
]
.
setRegisterIndex
(
j
)
;
break
;
}
}
}
}
LAllocation
SimpleAllocator
:
:
ensureStackLocation
(
uint32_t
vregId
)
{
VirtualRegister
&
vreg
=
vregs_
[
vregId
]
;
if
(
vreg
.
hasStackLocation
(
)
)
{
return
vreg
.
stackLocation
(
)
;
}
LStackSlot
:
:
Width
width
=
LStackSlot
:
:
width
(
vreg
.
def
(
)
-
>
type
(
)
)
;
LStackSlot
:
:
SlotAndWidth
slot
(
stackSlotAllocator_
.
allocateSlot
(
width
)
width
)
;
vreg
.
setAllocatedStackSlot
(
slot
)
;
return
LStackSlot
(
slot
)
;
}
LAllocation
SimpleAllocator
:
:
registerOrStackLocation
(
LInstruction
*
ins
uint32_t
vregId
bool
trackRegUse
)
{
const
VirtualRegister
&
vreg
=
vregs_
[
vregId
]
;
if
(
vreg
.
hasRegister
(
)
)
{
AllocatedRegister
&
allocated
=
allocatedRegs_
[
vreg
.
registerIndex
(
)
]
;
if
(
trackRegUse
)
{
allocated
.
setLastUsedAtInsId
(
ins
-
>
id
(
)
)
;
}
return
LAllocation
(
allocated
.
reg
(
)
)
;
}
return
vreg
.
stackLocation
(
)
;
}
bool
SimpleAllocator
:
:
spillRegister
(
LInstruction
*
ins
AllocatedRegister
allocated
)
{
VirtualRegister
&
vreg
=
vregs_
[
allocated
.
vregId
(
)
]
;
MOZ_ASSERT
(
vreg
.
insId
(
)
<
ins
-
>
id
(
)
)
;
if
(
vreg
.
hasStackLocation
(
)
)
{
return
true
;
}
LMoveGroup
*
input
=
getInputMoveGroup
(
ins
)
;
LAllocation
dest
=
ensureStackLocation
(
allocated
.
vregId
(
)
)
;
return
input
-
>
addAfter
(
LAllocation
(
allocated
.
reg
(
)
)
dest
vreg
.
def
(
)
-
>
type
(
)
)
;
}
bool
SimpleAllocator
:
:
allocateForBlockEnd
(
LBlock
*
block
LInstruction
*
ins
)
{
#
ifdef
DEBUG
for
(
const
AllocatedRegister
&
allocated
:
allocatedRegs_
)
{
MOZ_ASSERT_IF
(
vregs_
[
allocated
.
vregId
(
)
]
.
lastUseInsId
(
)
>
ins
-
>
id
(
)
vregs_
[
allocated
.
vregId
(
)
]
.
hasStackLocation
(
)
)
;
}
#
endif
MBasicBlock
*
successor
=
block
-
>
mir
(
)
-
>
successorWithPhis
(
)
;
if
(
!
successor
)
{
return
true
;
}
uint32_t
position
=
block
-
>
mir
(
)
-
>
positionInPhiSuccessor
(
)
;
LBlock
*
lirSuccessor
=
successor
-
>
lir
(
)
;
LMoveGroup
*
group
=
nullptr
;
for
(
size_t
i
=
0
numPhis
=
lirSuccessor
-
>
numPhis
(
)
;
i
<
numPhis
;
i
+
+
)
{
LPhi
*
phi
=
lirSuccessor
-
>
getPhi
(
i
)
;
uint32_t
sourceVreg
=
phi
-
>
getOperand
(
position
)
-
>
toUse
(
)
-
>
virtualRegister
(
)
;
uint32_t
destVreg
=
phi
-
>
getDef
(
0
)
-
>
virtualRegister
(
)
;
if
(
sourceVreg
=
=
destVreg
)
{
continue
;
}
if
(
!
group
)
{
LMoveGroup
*
input
=
getInputMoveGroup
(
ins
)
;
if
(
input
-
>
numMoves
(
)
=
=
0
)
{
group
=
input
;
}
else
{
group
=
LMoveGroup
:
:
New
(
alloc
(
)
)
;
block
-
>
insertAfter
(
input
group
)
;
}
}
LAllocation
source
=
registerOrStackLocation
(
ins
sourceVreg
true
)
;
LAllocation
dest
=
ensureStackLocation
(
destVreg
)
;
if
(
!
group
-
>
add
(
source
dest
phi
-
>
getDef
(
0
)
-
>
type
(
)
)
)
{
return
false
;
}
}
return
true
;
}
void
SimpleAllocator
:
:
scanDefinition
(
LInstruction
*
ins
LDefinition
*
def
bool
isTemp
)
{
if
(
def
-
>
policy
(
)
=
=
LDefinition
:
:
FIXED
&
&
def
-
>
output
(
)
-
>
isAnyRegister
(
)
)
{
AnyRegister
reg
=
def
-
>
output
(
)
-
>
toAnyRegister
(
)
;
if
(
isTemp
)
{
fixedTempRegs_
.
add
(
reg
)
;
}
fixedOutputAndTempRegs_
.
addUnchecked
(
reg
)
;
return
;
}
if
(
def
-
>
policy
(
)
=
=
LDefinition
:
:
MUST_REUSE_INPUT
)
{
ins
-
>
changePolicyOfReusedInputToAny
(
def
)
;
}
}
bool
SimpleAllocator
:
:
allocateForNonFixedDefOrUse
(
LInstruction
*
ins
uint32_t
vregId
AllocationKind
kind
AnyRegister
*
reg
)
{
const
VirtualRegister
&
vreg
=
vregs_
[
vregId
]
;
MOZ_ASSERT_IF
(
!
hasMultipleRegsForVreg_
!
vreg
.
hasRegister
(
)
)
;
bool
isUseAtStart
=
(
kind
=
=
AllocationKind
:
:
UseAtStart
)
;
RegisterSet
fixedDefs
=
isUseAtStart
?
fixedTempRegs_
.
set
(
)
:
fixedOutputAndTempRegs_
.
set
(
)
;
AllocatableRegisterSet
available
(
RegisterSet
:
:
Subtract
(
availableRegs_
.
set
(
)
fixedDefs
)
)
;
if
(
vreg
.
fixedUseHint
(
)
.
isSome
(
)
&
&
vreg
.
fixedUseHint
(
)
-
>
isValid
(
)
)
{
AnyRegister
regHint
=
*
vreg
.
fixedUseHint
(
)
;
if
(
available
.
has
(
regHint
)
)
{
*
reg
=
regHint
;
return
addAllocatedReg
(
ins
vregId
isUseAtStart
*
reg
)
;
}
}
*
reg
=
MaybeGetRegisterFromSet
(
available
vreg
.
def
(
)
-
>
type
(
)
)
;
if
(
reg
-
>
isValid
(
)
)
{
return
addAllocatedReg
(
ins
vregId
isUseAtStart
*
reg
)
;
}
AllocatableRegisterSet
notEvictable
;
if
(
kind
=
=
AllocationKind
:
:
Output
)
{
notEvictable
.
set
(
)
=
RegisterSet
:
:
Union
(
fixedDefs
currentInsRegsNotAtStart_
.
set
(
)
)
;
}
else
{
notEvictable
.
set
(
)
=
RegisterSet
:
:
Union
(
fixedDefs
currentInsRegs_
.
set
(
)
)
;
}
LDefinition
*
def
=
vreg
.
def
(
)
;
const
AllocatedRegister
*
bestToEvict
=
nullptr
;
for
(
size_t
i
=
0
len
=
allocatedRegs_
.
length
(
)
;
i
<
len
;
i
+
+
)
{
AllocatedRegister
&
allocated
=
allocatedRegs_
[
i
]
;
if
(
!
def
-
>
isCompatibleReg
(
allocated
.
reg
(
)
)
|
|
notEvictable
.
has
(
allocated
.
reg
(
)
)
)
{
continue
;
}
if
(
!
bestToEvict
|
|
vregs_
[
allocated
.
vregId
(
)
]
.
registerIndex
(
)
!
=
i
|
|
(
vregs_
[
allocated
.
vregId
(
)
]
.
hasStackLocation
(
)
&
&
!
vregs_
[
bestToEvict
-
>
vregId
(
)
]
.
hasStackLocation
(
)
)
|
|
allocated
.
lastUsedAtInsId
(
)
<
bestToEvict
-
>
lastUsedAtInsId
(
)
)
{
bestToEvict
=
&
allocated
;
}
}
if
(
bestToEvict
)
{
*
reg
=
bestToEvict
-
>
reg
(
)
;
}
else
{
AllocatableRegisterSet
evictable
;
evictable
.
set
(
)
=
RegisterSet
:
:
Subtract
(
allRegisters_
.
set
(
)
notEvictable
.
set
(
)
)
;
*
reg
=
MaybeGetRegisterFromSet
(
evictable
def
-
>
type
(
)
)
;
MOZ_ASSERT
(
reg
-
>
numAliased
(
)
>
1
)
;
}
if
(
!
evictRegister
(
ins
*
reg
)
)
{
return
false
;
}
return
addAllocatedReg
(
ins
vregId
isUseAtStart
*
reg
)
;
}
bool
SimpleAllocator
:
:
allocateForFixedUse
(
LInstruction
*
ins
const
LUse
*
use
AnyRegister
*
reg
)
{
uint32_t
vregId
=
use
-
>
virtualRegister
(
)
;
VirtualRegister
&
vreg
=
vregs_
[
vregId
]
;
*
reg
=
GetFixedRegister
(
vreg
.
def
(
)
use
)
;
LAllocation
alloc
;
if
(
vreg
.
hasRegister
(
)
)
{
AllocatedRegister
&
allocated
=
allocatedRegs_
[
vreg
.
registerIndex
(
)
]
;
if
(
allocated
.
reg
(
)
=
=
*
reg
)
{
markUseOfAllocatedReg
(
ins
allocated
use
-
>
usedAtStart
(
)
)
;
return
true
;
}
alloc
=
LAllocation
(
allocated
.
reg
(
)
)
;
if
(
currentInsRegs_
.
has
(
allocated
.
reg
(
)
)
)
{
hasMultipleRegsForVreg_
=
true
;
}
else
{
removeAllocatedRegisterAtIndex
(
vreg
.
registerIndex
(
)
)
;
}
}
else
{
alloc
=
vreg
.
stackLocation
(
)
;
}
if
(
!
availableRegs_
.
has
(
*
reg
)
&
&
!
evictRegister
(
ins
*
reg
)
)
{
return
false
;
}
if
(
!
addAllocatedReg
(
ins
vregId
use
-
>
usedAtStart
(
)
*
reg
)
)
{
return
false
;
}
LMoveGroup
*
input
=
getInputMoveGroup
(
ins
)
;
return
input
-
>
addAfter
(
alloc
LAllocation
(
*
reg
)
vreg
.
def
(
)
-
>
type
(
)
)
;
}
bool
SimpleAllocator
:
:
allocateForRegisterUse
(
LInstruction
*
ins
const
LUse
*
use
AnyRegister
*
reg
)
{
uint32_t
vregId
=
use
-
>
virtualRegister
(
)
;
VirtualRegister
&
vreg
=
vregs_
[
vregId
]
;
bool
useAtStart
=
use
-
>
usedAtStart
(
)
;
LAllocation
alloc
;
if
(
vreg
.
hasRegister
(
)
)
{
AllocatedRegister
&
allocated
=
allocatedRegs_
[
vreg
.
registerIndex
(
)
]
;
bool
isReserved
=
useAtStart
?
fixedTempRegs_
.
has
(
allocated
.
reg
(
)
)
:
fixedOutputAndTempRegs_
.
has
(
allocated
.
reg
(
)
)
;
if
(
!
isReserved
)
{
markUseOfAllocatedReg
(
ins
allocated
useAtStart
)
;
*
reg
=
allocated
.
reg
(
)
;
return
true
;
}
alloc
=
LAllocation
(
allocated
.
reg
(
)
)
;
if
(
currentInsRegs_
.
has
(
allocated
.
reg
(
)
)
)
{
hasMultipleRegsForVreg_
=
true
;
}
else
{
removeAllocatedRegisterAtIndex
(
vreg
.
registerIndex
(
)
)
;
}
}
else
{
alloc
=
vreg
.
stackLocation
(
)
;
}
AllocationKind
kind
=
useAtStart
?
AllocationKind
:
:
UseAtStart
:
AllocationKind
:
:
UseOrTemp
;
if
(
!
allocateForNonFixedDefOrUse
(
ins
vregId
kind
reg
)
)
{
return
false
;
}
LMoveGroup
*
input
=
getInputMoveGroup
(
ins
)
;
return
input
-
>
addAfter
(
alloc
LAllocation
(
*
reg
)
vreg
.
def
(
)
-
>
type
(
)
)
;
}
bool
SimpleAllocator
:
:
evictRegister
(
LInstruction
*
ins
AnyRegister
reg
)
{
MOZ_ASSERT
(
reg
.
isValid
(
)
)
;
MOZ_ASSERT
(
!
availableRegs_
.
has
(
reg
)
)
;
for
(
size_t
i
=
0
;
i
<
allocatedRegs_
.
length
(
)
;
)
{
AllocatedRegister
allocated
=
allocatedRegs_
[
i
]
;
if
(
!
allocated
.
reg
(
)
.
aliases
(
reg
)
)
{
i
+
+
;
continue
;
}
if
(
ins
-
>
safepoint
(
)
&
&
!
ins
-
>
isCall
(
)
&
&
currentInsRegs_
.
has
(
allocated
.
reg
(
)
)
)
{
MOZ_ASSERT
(
!
currentInsRegsNotAtStart_
.
has
(
allocated
.
reg
(
)
)
)
;
if
(
!
addLiveRegisterToSafepoint
(
ins
-
>
safepoint
(
)
allocated
)
)
{
return
false
;
}
}
uint32_t
vregId
=
allocated
.
vregId
(
)
;
if
(
vregs_
[
vregId
]
.
registerIndex
(
)
=
=
i
)
{
if
(
!
spillRegister
(
ins
allocated
)
)
{
return
false
;
}
}
else
{
MOZ_ASSERT
(
hasMultipleRegsForVreg_
)
;
}
removeAllocatedRegisterAtIndex
(
i
)
;
if
(
availableRegs_
.
has
(
reg
)
)
{
return
true
;
}
}
MOZ_CRASH
(
"
failed
to
evict
register
"
)
;
}
bool
SimpleAllocator
:
:
allocateForDefinition
(
uint32_t
blockLastId
LInstruction
*
ins
LDefinition
*
def
bool
isTemp
)
{
uint32_t
vregId
=
def
-
>
virtualRegister
(
)
;
AnyRegister
reg
;
switch
(
def
-
>
policy
(
)
)
{
case
LDefinition
:
:
FIXED
:
{
if
(
!
def
-
>
output
(
)
-
>
isAnyRegister
(
)
)
{
MOZ_ASSERT
(
!
isTemp
)
;
vregs_
[
vregId
]
.
setHasStackLocation
(
)
;
return
true
;
}
reg
=
def
-
>
output
(
)
-
>
toAnyRegister
(
)
;
if
(
!
availableRegs_
.
has
(
reg
)
)
{
if
(
!
isTemp
&
&
fixedTempRegs_
.
has
(
reg
)
)
{
MOZ_ASSERT
(
ins
-
>
isCall
(
)
)
;
for
(
size_t
i
=
0
;
i
<
allocatedRegs_
.
length
(
)
;
i
+
+
)
{
if
(
allocatedRegs_
[
i
]
.
reg
(
)
=
=
reg
)
{
removeAllocatedRegisterAtIndex
(
i
)
;
break
;
}
}
MOZ_ASSERT
(
availableRegs_
.
has
(
reg
)
)
;
}
else
{
if
(
!
evictRegister
(
ins
reg
)
)
{
return
false
;
}
}
}
if
(
!
addAllocatedReg
(
ins
vregId
false
reg
)
)
{
return
false
;
}
break
;
}
case
LDefinition
:
:
REGISTER
:
{
AllocationKind
kind
=
isTemp
?
AllocationKind
:
:
UseOrTemp
:
AllocationKind
:
:
Output
;
if
(
!
allocateForNonFixedDefOrUse
(
ins
vregId
kind
&
reg
)
)
{
return
false
;
}
break
;
}
case
LDefinition
:
:
MUST_REUSE_INPUT
:
{
AllocationKind
kind
=
isTemp
?
AllocationKind
:
:
UseOrTemp
:
AllocationKind
:
:
Output
;
if
(
!
allocateForNonFixedDefOrUse
(
ins
vregId
kind
&
reg
)
)
{
return
false
;
}
LAllocation
*
useAlloc
=
ins
-
>
getOperand
(
def
-
>
getReusedInput
(
)
)
;
uint32_t
useVregId
=
useAlloc
-
>
toUse
(
)
-
>
virtualRegister
(
)
;
LDefinition
:
:
Type
type
=
vregs_
[
useVregId
]
.
def
(
)
-
>
type
(
)
;
if
(
!
reusedInputs_
.
emplaceBack
(
useAlloc
reg
type
)
)
{
return
false
;
}
break
;
}
case
LDefinition
:
:
STACK
:
{
MOZ_ASSERT
(
!
isTemp
)
;
if
(
def
-
>
type
(
)
=
=
LDefinition
:
:
STACKRESULTS
)
{
LStackArea
alloc
(
ins
-
>
toInstruction
(
)
)
;
stackSlotAllocator_
.
allocateStackArea
(
&
alloc
)
;
def
-
>
setOutput
(
alloc
)
;
}
else
{
const
LUse
*
use
=
ins
-
>
getOperand
(
0
)
-
>
toUse
(
)
;
VirtualRegister
&
area
=
vregs_
[
use
-
>
virtualRegister
(
)
]
;
const
LStackArea
*
areaAlloc
=
area
.
def
(
)
-
>
output
(
)
-
>
toStackArea
(
)
;
def
-
>
setOutput
(
areaAlloc
-
>
resultAlloc
(
ins
def
)
)
;
}
vregs_
[
vregId
]
.
setHasStackLocation
(
)
;
return
true
;
}
}
def
-
>
setOutput
(
LAllocation
(
reg
)
)
;
if
(
!
isTemp
&
&
vregs_
[
vregId
]
.
lastUseInsId
(
)
>
blockLastId
)
{
if
(
!
eagerSpillOutputs_
.
append
(
def
)
)
{
return
false
;
}
}
return
true
;
}
bool
SimpleAllocator
:
:
allocateForInstruction
(
VirtualRegBitSet
&
liveGC
uint32_t
blockLastId
LInstruction
*
ins
)
{
if
(
!
alloc
(
)
.
ensureBallast
(
)
)
{
return
false
;
}
assertValidRegisterStateBeforeInstruction
(
)
;
MOZ_ASSERT
(
reusedInputs_
.
empty
(
)
)
;
if
(
!
eagerSpillOutputs_
.
empty
(
)
&
&
!
ins
-
>
isOsiPoint
(
)
)
{
LMoveGroup
*
moves
=
getInputMoveGroup
(
ins
)
;
for
(
LDefinition
*
def
:
eagerSpillOutputs_
)
{
MOZ_ASSERT
(
!
vregs_
[
def
-
>
virtualRegister
(
)
]
.
hasStackLocation
(
)
)
;
LAllocation
dest
=
ensureStackLocation
(
def
-
>
virtualRegister
(
)
)
;
if
(
!
moves
-
>
add
(
*
def
-
>
output
(
)
dest
def
-
>
type
(
)
)
)
{
return
false
;
}
}
eagerSpillOutputs_
.
clear
(
)
;
}
currentInsRegs_
=
AllocatableRegisterSet
(
)
;
currentInsRegsNotAtStart_
=
AllocatableRegisterSet
(
)
;
fixedTempRegs_
=
AllocatableRegisterSet
(
)
;
fixedOutputAndTempRegs_
=
AllocatableRegisterSet
(
)
;
for
(
LInstruction
:
:
NonSnapshotInputIter
alloc
(
*
ins
)
;
alloc
.
more
(
)
;
alloc
.
next
(
)
)
{
if
(
!
alloc
-
>
isUse
(
)
|
|
alloc
-
>
toUse
(
)
-
>
policy
(
)
!
=
LUse
:
:
FIXED
)
{
continue
;
}
AnyRegister
reg
;
if
(
!
allocateForFixedUse
(
ins
alloc
-
>
toUse
(
)
&
reg
)
)
{
return
false
;
}
alloc
.
replace
(
LAllocation
(
reg
)
)
;
}
for
(
LInstruction
:
:
TempIter
temp
(
ins
)
;
!
temp
.
done
(
)
;
temp
+
+
)
{
scanDefinition
(
ins
*
temp
true
)
;
}
for
(
LInstruction
:
:
OutputIter
output
(
ins
)
;
!
output
.
done
(
)
;
output
+
+
)
{
scanDefinition
(
ins
*
output
false
)
;
}
for
(
LInstruction
:
:
NonSnapshotInputIter
alloc
(
*
ins
)
;
alloc
.
more
(
)
;
alloc
.
next
(
)
)
{
if
(
!
alloc
-
>
isUse
(
)
|
|
alloc
-
>
toUse
(
)
-
>
policy
(
)
!
=
LUse
:
:
REGISTER
)
{
continue
;
}
AnyRegister
reg
;
if
(
!
allocateForRegisterUse
(
ins
alloc
-
>
toUse
(
)
&
reg
)
)
{
return
false
;
}
alloc
.
replace
(
LAllocation
(
reg
)
)
;
}
for
(
LInstruction
:
:
TempIter
temp
(
ins
)
;
!
temp
.
done
(
)
;
temp
+
+
)
{
if
(
!
allocateForDefinition
(
blockLastId
ins
*
temp
true
)
)
{
return
false
;
}
}
for
(
LInstruction
:
:
OutputIter
output
(
ins
)
;
!
output
.
done
(
)
;
output
+
+
)
{
LDefinition
*
def
=
*
output
;
if
(
!
allocateForDefinition
(
blockLastId
ins
def
false
)
)
{
return
false
;
}
if
(
vregs_
[
def
-
>
virtualRegister
(
)
]
.
isGCType
(
)
)
{
if
(
!
liveGC
.
insert
(
def
-
>
virtualRegister
(
)
)
)
{
return
false
;
}
}
}
if
(
ins
-
>
isCall
(
)
)
{
for
(
size_t
i
=
0
;
i
<
allocatedRegs_
.
length
(
)
;
)
{
AllocatedRegister
allocated
=
allocatedRegs_
[
i
]
;
if
(
ins
-
>
isCallPreserved
(
allocated
.
reg
(
)
)
|
|
vregs_
[
allocated
.
vregId
(
)
]
.
insId
(
)
=
=
ins
-
>
id
(
)
)
{
i
+
+
;
continue
;
}
if
(
!
spillRegister
(
ins
allocated
)
)
{
return
false
;
}
removeAllocatedRegisterAtIndex
(
i
)
;
}
}
for
(
LInstruction
:
:
InputIter
alloc
(
*
ins
)
;
alloc
.
more
(
)
;
alloc
.
next
(
)
)
{
if
(
!
alloc
-
>
isUse
(
)
)
{
continue
;
}
LUse
*
use
=
alloc
-
>
toUse
(
)
;
MOZ_ASSERT
(
use
-
>
policy
(
)
!
=
LUse
:
:
REGISTER
&
&
use
-
>
policy
(
)
!
=
LUse
:
:
FIXED
)
;
uint32_t
vreg
=
use
-
>
virtualRegister
(
)
;
bool
trackRegUse
=
(
use
-
>
policy
(
)
!
=
LUse
:
:
KEEPALIVE
)
;
LAllocation
allocated
=
registerOrStackLocation
(
ins
vreg
trackRegUse
)
;
alloc
.
replace
(
allocated
)
;
}
while
(
!
reusedInputs_
.
empty
(
)
)
{
auto
entry
=
reusedInputs_
.
popCopy
(
)
;
LMoveGroup
*
input
=
getInputMoveGroup
(
ins
)
;
if
(
!
input
-
>
addAfter
(
*
entry
.
source
LAllocation
(
entry
.
dest
)
entry
.
type
)
)
{
return
false
;
}
*
entry
.
source
=
LAllocation
(
entry
.
dest
)
;
}
if
(
LSafepoint
*
safepoint
=
ins
-
>
safepoint
(
)
)
{
if
(
!
populateSafepoint
(
liveGC
ins
safepoint
)
)
{
return
false
;
}
}
if
(
hasMultipleRegsForVreg_
)
{
for
(
size_t
i
=
0
;
i
<
allocatedRegs_
.
length
(
)
;
)
{
VirtualRegister
&
vreg
=
vregs_
[
allocatedRegs_
[
i
]
.
vregId
(
)
]
;
if
(
vreg
.
registerIndex
(
)
!
=
i
)
{
removeAllocatedRegisterAtIndex
(
i
)
;
continue
;
}
i
+
+
;
}
hasMultipleRegsForVreg_
=
false
;
}
return
true
;
}
bool
SimpleAllocator
:
:
addLiveRegisterToSafepoint
(
LSafepoint
*
safepoint
AllocatedRegister
allocated
)
{
safepoint
-
>
addLiveRegister
(
allocated
.
reg
(
)
)
;
const
VirtualRegister
&
vreg
=
vregs_
[
allocated
.
vregId
(
)
]
;
if
(
vreg
.
isGCType
(
)
)
{
if
(
!
safepoint
-
>
addGCAllocation
(
allocated
.
vregId
(
)
vreg
.
def
(
)
LAllocation
(
allocated
.
reg
(
)
)
)
)
{
return
false
;
}
}
return
true
;
}
bool
SimpleAllocator
:
:
populateSafepoint
(
VirtualRegBitSet
&
liveGC
LInstruction
*
ins
LSafepoint
*
safepoint
)
{
if
(
!
ins
-
>
isCall
(
)
)
{
for
(
AllocatedRegister
allocated
:
allocatedRegs_
)
{
const
VirtualRegister
&
vreg
=
vregs_
[
allocated
.
vregId
(
)
]
;
if
(
vreg
.
insId
(
)
=
=
ins
-
>
id
(
)
)
{
#
ifdef
CHECK_OSIPOINT_REGISTERS
safepoint
-
>
addClobberedRegister
(
allocated
.
reg
(
)
)
;
#
endif
if
(
!
vreg
.
isTemp
(
)
)
{
continue
;
}
}
if
(
!
addLiveRegisterToSafepoint
(
safepoint
allocated
)
)
{
return
false
;
}
}
}
for
(
VirtualRegBitSet
:
:
Iterator
liveRegId
(
liveGC
)
;
liveRegId
;
+
+
liveRegId
)
{
uint32_t
vregId
=
*
liveRegId
;
const
VirtualRegister
&
vreg
=
vregs_
[
vregId
]
;
MOZ_ASSERT
(
vreg
.
isGCType
(
)
)
;
if
(
!
vreg
.
hasStackLocation
(
)
|
|
vreg
.
insId
(
)
=
=
ins
-
>
id
(
)
)
{
continue
;
}
if
(
!
safepoint
-
>
addGCAllocation
(
vregId
vreg
.
def
(
)
vreg
.
stackLocation
(
)
)
)
{
return
false
;
}
}
return
true
;
}
void
SimpleAllocator
:
:
freeDeadVregsAfterInstruction
(
VirtualRegBitSet
&
liveGC
LNode
*
ins
)
{
while
(
!
vregLastUses_
.
empty
(
)
&
&
vregLastUses_
.
back
(
)
.
instructionId
<
=
ins
-
>
id
(
)
)
{
VregLastUse
entry
=
vregLastUses_
.
popCopy
(
)
;
VirtualRegister
&
vreg
=
vregs_
[
entry
.
vregId
]
;
if
(
vreg
.
hasRegister
(
)
)
{
removeAllocatedRegisterAtIndex
(
vreg
.
registerIndex
(
)
)
;
}
if
(
vreg
.
hasAllocatedStackSlot
(
)
)
{
LStackSlot
:
:
SlotAndWidth
stackSlot
=
vreg
.
stackSlot
(
)
;
stackSlotAllocator_
.
freeSlot
(
stackSlot
.
width
(
)
stackSlot
.
slot
(
)
)
;
}
if
(
vreg
.
isGCType
(
)
)
{
liveGC
.
remove
(
entry
.
vregId
)
;
}
vreg
.
markDead
(
)
;
}
}
bool
SimpleAllocator
:
:
tryReuseRegistersFromPredecessor
(
MBasicBlock
*
block
)
{
if
(
block
-
>
numPredecessors
(
)
!
=
1
)
{
return
true
;
}
auto
findBlockState
=
[
this
]
(
uint32_t
predId
)
-
>
const
BlockState
*
{
for
(
const
BlockState
&
state
:
blockStates_
)
{
if
(
state
.
blockIndex
=
=
predId
)
{
return
&
state
;
}
}
return
nullptr
;
}
;
const
BlockState
*
state
=
findBlockState
(
block
-
>
getPredecessor
(
0
)
-
>
id
(
)
)
;
if
(
!
state
)
{
return
true
;
}
MOZ_ASSERT
(
allocatedRegs_
.
empty
(
)
)
;
availableRegs_
=
state
-
>
availableRegs
;
for
(
AllocatedRegister
allocated
:
state
-
>
allocatedRegs
)
{
if
(
vregs_
[
allocated
.
vregId
(
)
]
.
isDead
(
)
)
{
availableRegs_
.
add
(
allocated
.
reg
(
)
)
;
}
else
{
VirtualRegister
&
vreg
=
vregs_
[
allocated
.
vregId
(
)
]
;
MOZ_ASSERT
(
!
vreg
.
hasRegister
(
)
)
;
vreg
.
setRegisterIndex
(
allocatedRegs_
.
length
(
)
)
;
if
(
!
allocatedRegs_
.
append
(
allocated
)
)
{
return
false
;
}
}
}
return
true
;
}
void
SimpleAllocator
:
:
saveAndClearAllocatedRegisters
(
MBasicBlock
*
block
)
{
if
(
allocatedRegs_
.
empty
(
)
)
{
return
;
}
for
(
AllocatedRegister
allocated
:
allocatedRegs_
)
{
vregs_
[
allocated
.
vregId
(
)
]
.
clearRegisterIndex
(
)
;
}
bool
shouldSave
=
false
;
for
(
size_t
i
=
0
;
i
<
block
-
>
numSuccessors
(
)
;
i
+
+
)
{
if
(
block
-
>
getSuccessor
(
i
)
-
>
numPredecessors
(
)
=
=
1
&
&
block
-
>
getSuccessor
(
i
)
-
>
id
(
)
>
block
-
>
id
(
)
)
{
shouldSave
=
true
;
break
;
}
}
if
(
shouldSave
)
{
BlockState
&
state
=
blockStates_
[
nextBlockStateIndex_
]
;
std
:
:
swap
(
allocatedRegs_
state
.
allocatedRegs
)
;
state
.
availableRegs
=
availableRegs_
;
state
.
blockIndex
=
block
-
>
id
(
)
;
nextBlockStateIndex_
=
(
nextBlockStateIndex_
+
1
)
%
BlockStateLength
;
}
allocatedRegs_
.
clear
(
)
;
availableRegs_
=
allRegisters_
;
}
bool
SimpleAllocator
:
:
allocateRegisters
(
)
{
MOZ_ASSERT
(
allocatedRegs_
.
empty
(
)
)
;
availableRegs_
=
allRegisters_
;
size_t
numBlocks
=
graph
.
numBlocks
(
)
;
bool
fuseWithNextBlock
=
false
;
for
(
size_t
blockIndex
=
0
;
blockIndex
<
numBlocks
;
blockIndex
+
+
)
{
if
(
mir
-
>
shouldCancel
(
"
allocateRegisters
(
block
loop
)
"
)
)
{
return
false
;
}
LBlock
*
block
=
graph
.
getBlock
(
blockIndex
)
;
MBasicBlock
*
mblock
=
block
-
>
mir
(
)
;
MOZ_ASSERT
(
mblock
-
>
id
(
)
=
=
blockIndex
)
;
VirtualRegBitSet
&
liveGC
=
liveGCIn_
[
blockIndex
]
;
if
(
!
fuseWithNextBlock
)
{
MOZ_ASSERT
(
allocatedRegs_
.
empty
(
)
)
;
if
(
!
tryReuseRegistersFromPredecessor
(
mblock
)
)
{
return
false
;
}
}
fuseWithNextBlock
=
mblock
-
>
numSuccessors
(
)
=
=
1
&
&
mblock
-
>
getSuccessor
(
0
)
-
>
id
(
)
=
=
blockIndex
+
1
&
&
mblock
-
>
getSuccessor
(
0
)
-
>
numPredecessors
(
)
=
=
1
&
&
graph
.
getBlock
(
blockIndex
+
1
)
-
>
numPhis
(
)
=
=
0
;
uint32_t
blockLastId
=
fuseWithNextBlock
?
graph
.
getBlock
(
blockIndex
+
1
)
-
>
lastId
(
)
:
block
-
>
lastId
(
)
;
for
(
uint32_t
i
=
0
numPhis
=
block
-
>
numPhis
(
)
;
i
<
numPhis
;
i
+
+
)
{
LPhi
*
phi
=
block
-
>
getPhi
(
i
)
;
LDefinition
*
def
=
phi
-
>
getDef
(
0
)
;
uint32_t
vregId
=
def
-
>
virtualRegister
(
)
;
bool
isGCType
=
vregs_
[
vregId
]
.
isGCType
(
)
;
def
-
>
setOutput
(
ensureStackLocation
(
vregId
)
)
;
if
(
isGCType
&
&
!
liveGC
.
insert
(
vregId
)
)
{
return
false
;
}
if
(
i
=
=
numPhis
-
1
)
{
freeDeadVregsAfterInstruction
(
liveGC
phi
)
;
}
}
for
(
LInstructionIterator
iter
=
block
-
>
begin
(
)
;
iter
!
=
block
-
>
end
(
)
;
iter
+
+
)
{
if
(
mir
-
>
shouldCancel
(
"
allocateRegisters
(
instruction
loop
)
"
)
)
{
return
false
;
}
LInstruction
*
ins
=
*
iter
;
if
(
!
allocateForInstruction
(
liveGC
blockLastId
ins
)
)
{
return
false
;
}
if
(
ins
=
=
*
block
-
>
rbegin
(
)
&
&
!
fuseWithNextBlock
)
{
if
(
!
allocateForBlockEnd
(
block
ins
)
)
{
return
false
;
}
}
freeDeadVregsAfterInstruction
(
liveGC
ins
)
;
}
if
(
!
fuseWithNextBlock
)
{
saveAndClearAllocatedRegisters
(
mblock
)
;
}
}
MOZ_ASSERT
(
vregLastUses_
.
empty
(
)
)
;
#
ifdef
DEBUG
for
(
size_t
i
=
1
;
i
<
vregs_
.
length
(
)
;
i
+
+
)
{
MOZ_ASSERT
(
vregs_
[
i
]
.
isDead
(
)
)
;
}
#
endif
graph
.
setLocalSlotsSize
(
stackSlotAllocator_
.
stackHeight
(
)
)
;
return
true
;
}
void
SimpleAllocator
:
:
assertValidRegisterStateBeforeInstruction
(
)
const
{
#
ifdef
DEBUG
MOZ_ASSERT
(
!
hasMultipleRegsForVreg_
)
;
AllocatableRegisterSet
available
=
allRegisters_
;
for
(
size_t
i
=
0
;
i
<
allocatedRegs_
.
length
(
)
;
i
+
+
)
{
AllocatedRegister
allocated
=
allocatedRegs_
[
i
]
;
available
.
take
(
allocated
.
reg
(
)
)
;
const
VirtualRegister
&
vreg
=
vregs_
[
allocated
.
vregId
(
)
]
;
MOZ_ASSERT
(
vreg
.
registerIndex
(
)
=
=
i
)
;
MOZ_ASSERT
(
!
vreg
.
isTemp
(
)
)
;
}
MOZ_ASSERT
(
availableRegs_
.
set
(
)
=
=
available
.
set
(
)
)
;
size_t
numVregsToCheck
=
std
:
:
min
<
size_t
>
(
20
vregs_
.
length
(
)
)
;
for
(
size_t
i
=
1
;
i
<
numVregsToCheck
;
i
+
+
)
{
if
(
!
vregs_
[
i
]
.
isDead
(
)
&
&
vregs_
[
i
]
.
hasRegister
(
)
)
{
size_t
index
=
vregs_
[
i
]
.
registerIndex
(
)
;
MOZ_ASSERT
(
allocatedRegs_
[
index
]
.
vregId
(
)
=
=
i
)
;
}
}
#
endif
}
bool
SimpleAllocator
:
:
go
(
)
{
JitSpewCont
(
JitSpew_RegAlloc
"
\
n
"
)
;
JitSpew
(
JitSpew_RegAlloc
"
Beginning
register
allocation
"
)
;
JitSpewCont
(
JitSpew_RegAlloc
"
\
n
"
)
;
if
(
JitSpewEnabled
(
JitSpew_RegAlloc
)
)
{
dumpInstructions
(
"
(
Pre
-
allocation
LIR
)
"
)
;
}
if
(
!
init
(
)
)
{
return
false
;
}
if
(
!
analyzeLiveness
(
)
)
{
return
false
;
}
if
(
!
allocateRegisters
(
)
)
{
return
false
;
}
return
true
;
}
