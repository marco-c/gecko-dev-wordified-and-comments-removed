#
ifndef
jit_shared_IonAssemblerBufferWithConstantPools_h
#
define
jit_shared_IonAssemblerBufferWithConstantPools_h
#
include
"
mozilla
/
DebugOnly
.
h
"
#
include
<
algorithm
>
#
include
"
jit
/
JitSpewer
.
h
"
#
include
"
jit
/
shared
/
IonAssemblerBuffer
.
h
"
namespace
js
{
namespace
jit
{
typedef
Vector
<
BufferOffset
512
OldJitAllocPolicy
>
LoadOffsets
;
typedef
int32_t
PoolAllocUnit
;
struct
Pool
:
public
OldJitAllocPolicy
{
private
:
const
size_t
maxOffset_
;
const
unsigned
bias_
;
unsigned
numEntries_
;
unsigned
buffSize
;
PoolAllocUnit
*
poolData_
;
bool
oom_
;
BufferOffset
limitingUser
;
unsigned
limitingUsee
;
public
:
LoadOffsets
loadOffsets
;
explicit
Pool
(
size_t
maxOffset
unsigned
bias
LifoAlloc
&
lifoAlloc
)
:
maxOffset_
(
maxOffset
)
bias_
(
bias
)
numEntries_
(
0
)
buffSize
(
8
)
poolData_
(
lifoAlloc
.
newArrayUninitialized
<
PoolAllocUnit
>
(
buffSize
)
)
oom_
(
false
)
limitingUser
(
)
limitingUsee
(
INT_MIN
)
loadOffsets
(
)
{
if
(
poolData_
=
=
nullptr
)
{
buffSize
=
0
;
oom_
=
true
;
}
}
static
const
unsigned
Garbage
=
0xa5a5a5a5
;
Pool
(
)
:
maxOffset_
(
Garbage
)
bias_
(
Garbage
)
{
}
PoolAllocUnit
*
poolData
(
)
const
{
return
poolData_
;
}
unsigned
numEntries
(
)
const
{
return
numEntries_
;
}
size_t
getPoolSize
(
)
const
{
return
numEntries_
*
sizeof
(
PoolAllocUnit
)
;
}
bool
oom
(
)
const
{
return
oom_
;
}
void
updateLimiter
(
BufferOffset
nextInst
)
{
ptrdiff_t
oldRange
=
limitingUsee
*
sizeof
(
PoolAllocUnit
)
-
limitingUser
.
getOffset
(
)
;
ptrdiff_t
newRange
=
numEntries_
*
sizeof
(
PoolAllocUnit
)
-
nextInst
.
getOffset
(
)
;
if
(
!
limitingUser
.
assigned
(
)
|
|
newRange
>
oldRange
)
{
limitingUser
=
nextInst
;
limitingUsee
=
numEntries_
;
}
}
bool
checkFull
(
size_t
poolOffset
)
const
{
if
(
!
limitingUser
.
assigned
(
)
)
return
false
;
size_t
offset
=
poolOffset
+
limitingUsee
*
sizeof
(
PoolAllocUnit
)
-
(
limitingUser
.
getOffset
(
)
+
bias_
)
;
return
offset
>
=
maxOffset_
;
}
static
const
unsigned
OOM_FAIL
=
unsigned
(
-
1
)
;
unsigned
insertEntry
(
unsigned
num
uint8_t
*
data
BufferOffset
off
LifoAlloc
&
lifoAlloc
)
{
if
(
oom_
)
return
OOM_FAIL
;
if
(
numEntries_
+
num
>
=
buffSize
)
{
unsigned
newSize
=
buffSize
*
2
;
PoolAllocUnit
*
tmp
=
lifoAlloc
.
newArrayUninitialized
<
PoolAllocUnit
>
(
newSize
)
;
if
(
tmp
=
=
nullptr
)
{
oom_
=
true
;
return
OOM_FAIL
;
}
mozilla
:
:
PodCopy
(
tmp
poolData_
numEntries_
)
;
poolData_
=
tmp
;
buffSize
=
newSize
;
}
mozilla
:
:
PodCopy
(
&
poolData_
[
numEntries_
]
(
PoolAllocUnit
*
)
data
num
)
;
loadOffsets
.
append
(
off
.
getOffset
(
)
)
;
unsigned
ret
=
numEntries_
;
numEntries_
+
=
num
;
return
ret
;
}
bool
reset
(
LifoAlloc
&
a
)
{
numEntries_
=
0
;
buffSize
=
8
;
poolData_
=
static_cast
<
PoolAllocUnit
*
>
(
a
.
alloc
(
buffSize
*
sizeof
(
PoolAllocUnit
)
)
)
;
if
(
poolData_
=
=
nullptr
)
{
oom_
=
true
;
buffSize
=
0
;
return
false
;
}
new
(
&
loadOffsets
)
LoadOffsets
;
limitingUser
=
BufferOffset
(
)
;
limitingUsee
=
-
1
;
return
true
;
}
}
;
template
<
size_t
SliceSize
size_t
InstSize
class
Inst
class
Asm
>
struct
AssemblerBufferWithConstantPools
:
public
AssemblerBuffer
<
SliceSize
Inst
>
{
private
:
size_t
poolEntryCount
;
public
:
class
PoolEntry
{
size_t
index_
;
public
:
explicit
PoolEntry
(
size_t
index
)
:
index_
(
index
)
{
}
PoolEntry
(
)
:
index_
(
-
1
)
{
}
size_t
index
(
)
const
{
return
index_
;
}
}
;
private
:
typedef
AssemblerBuffer
<
SliceSize
Inst
>
Parent
;
using
typename
Parent
:
:
Slice
;
const
unsigned
guardSize_
;
const
unsigned
headerSize_
;
const
size_t
poolMaxOffset_
;
const
unsigned
pcBias_
;
Pool
pool_
;
const
size_t
instBufferAlign_
;
struct
PoolInfo
{
unsigned
firstEntryIndex
;
BufferOffset
offset
;
explicit
PoolInfo
(
unsigned
index
BufferOffset
data
)
:
firstEntryIndex
(
index
)
offset
(
data
)
{
}
}
;
unsigned
numDumps_
;
size_t
poolInfoSize_
;
PoolInfo
*
poolInfo_
;
bool
canNotPlacePool_
;
#
ifdef
DEBUG
size_t
canNotPlacePoolStartOffset_
;
size_t
canNotPlacePoolMaxInst_
;
#
endif
const
uint32_t
alignFillInst_
;
const
uint32_t
nopFillInst_
;
const
unsigned
nopFill_
;
bool
inhibitNops_
;
public
:
int
id
;
private
:
Slice
*
getHead
(
)
const
{
return
this
-
>
head
;
}
Slice
*
getTail
(
)
const
{
return
this
-
>
tail
;
}
public
:
AssemblerBufferWithConstantPools
(
unsigned
guardSize
unsigned
headerSize
size_t
instBufferAlign
size_t
poolMaxOffset
unsigned
pcBias
uint32_t
alignFillInst
uint32_t
nopFillInst
unsigned
nopFill
=
0
)
:
poolEntryCount
(
0
)
guardSize_
(
guardSize
)
headerSize_
(
headerSize
)
poolMaxOffset_
(
poolMaxOffset
)
pcBias_
(
pcBias
)
pool_
(
)
instBufferAlign_
(
instBufferAlign
)
numDumps_
(
0
)
poolInfoSize_
(
8
)
poolInfo_
(
nullptr
)
canNotPlacePool_
(
false
)
#
ifdef
DEBUG
canNotPlacePoolStartOffset_
(
0
)
canNotPlacePoolMaxInst_
(
0
)
#
endif
alignFillInst_
(
alignFillInst
)
nopFillInst_
(
nopFillInst
)
nopFill_
(
nopFill
)
inhibitNops_
(
false
)
id
(
-
1
)
{
}
void
initWithAllocator
(
)
{
poolInfo_
=
this
-
>
lifoAlloc_
.
template
newArrayUninitialized
<
PoolInfo
>
(
poolInfoSize_
)
;
if
(
!
poolInfo_
)
{
this
-
>
fail_oom
(
)
;
return
;
}
new
(
&
pool_
)
Pool
(
poolMaxOffset_
pcBias_
this
-
>
lifoAlloc_
)
;
if
(
pool_
.
poolData
(
)
=
=
nullptr
)
this
-
>
fail_oom
(
)
;
}
private
:
const
PoolInfo
&
getLastPoolInfo
(
)
const
{
static
const
PoolInfo
nil
=
{
0
0
0
nullptr
}
;
if
(
numDumps_
>
0
)
return
poolInfo_
[
numDumps_
-
1
]
;
return
nil
;
}
size_t
sizeExcludingCurrentPool
(
)
const
{
return
this
-
>
nextOffset
(
)
.
getOffset
(
)
;
}
public
:
size_t
size
(
)
const
{
MOZ_ASSERT_IF
(
!
this
-
>
oom
(
)
pool_
.
numEntries
(
)
=
=
0
)
;
return
sizeExcludingCurrentPool
(
)
;
}
private
:
void
insertNopFill
(
)
{
if
(
nopFill_
>
0
&
&
!
inhibitNops_
&
&
!
canNotPlacePool_
)
{
inhibitNops_
=
true
;
for
(
size_t
i
=
0
;
i
<
nopFill_
;
i
+
+
)
putInt
(
nopFillInst_
)
;
inhibitNops_
=
false
;
}
}
static
const
unsigned
OOM_FAIL
=
unsigned
(
-
1
)
;
static
const
unsigned
NO_DATA
=
unsigned
(
-
2
)
;
unsigned
insertEntryForwards
(
unsigned
numInst
unsigned
numPoolEntries
uint8_t
*
inst
uint8_t
*
data
)
{
size_t
nextOffset
=
sizeExcludingCurrentPool
(
)
;
size_t
poolOffset
=
nextOffset
+
(
numInst
+
guardSize_
+
headerSize_
)
*
InstSize
;
if
(
numPoolEntries
)
pool_
.
updateLimiter
(
BufferOffset
(
nextOffset
)
)
;
if
(
pool_
.
checkFull
(
poolOffset
)
)
{
if
(
numPoolEntries
)
JitSpew
(
JitSpew_Pools
"
[
%
d
]
Inserting
pool
entry
caused
a
spill
"
id
)
;
else
JitSpew
(
JitSpew_Pools
"
[
%
d
]
Inserting
instruction
(
%
d
)
caused
a
spill
"
id
sizeExcludingCurrentPool
(
)
)
;
finishPool
(
)
;
if
(
this
-
>
oom
(
)
)
return
OOM_FAIL
;
return
insertEntryForwards
(
numInst
numPoolEntries
inst
data
)
;
}
if
(
numPoolEntries
)
{
unsigned
result
=
pool_
.
insertEntry
(
numPoolEntries
data
this
-
>
nextOffset
(
)
this
-
>
lifoAlloc_
)
;
if
(
result
=
=
Pool
:
:
OOM_FAIL
)
{
this
-
>
fail_oom
(
)
;
return
OOM_FAIL
;
}
return
result
;
}
return
NO_DATA
;
}
public
:
BufferOffset
nextInstrOffset
(
)
{
size_t
nextOffset
=
sizeExcludingCurrentPool
(
)
;
size_t
poolOffset
=
nextOffset
+
(
1
+
guardSize_
+
headerSize_
)
*
InstSize
;
if
(
pool_
.
checkFull
(
poolOffset
)
)
{
JitSpew
(
JitSpew_Pools
"
[
%
d
]
nextInstrOffset
%
d
caused
a
constant
pool
spill
"
id
nextOffset
)
;
finishPool
(
)
;
}
return
this
-
>
nextOffset
(
)
;
}
BufferOffset
allocEntry
(
size_t
numInst
unsigned
numPoolEntries
uint8_t
*
inst
uint8_t
*
data
PoolEntry
*
pe
=
nullptr
bool
markAsBranch
=
false
)
{
MOZ_ASSERT_IF
(
numPoolEntries
!
canNotPlacePool_
)
;
if
(
this
-
>
oom
(
)
&
&
!
this
-
>
bail
(
)
)
return
BufferOffset
(
)
;
insertNopFill
(
)
;
#
ifdef
DEBUG
if
(
numPoolEntries
)
{
JitSpew
(
JitSpew_Pools
"
[
%
d
]
Inserting
%
d
entries
into
pool
"
id
numPoolEntries
)
;
JitSpewStart
(
JitSpew_Pools
"
[
%
d
]
data
is
:
0x
"
id
)
;
size_t
length
=
numPoolEntries
*
sizeof
(
PoolAllocUnit
)
;
for
(
unsigned
idx
=
0
;
idx
<
length
;
idx
+
+
)
{
JitSpewCont
(
JitSpew_Pools
"
%
02x
"
data
[
length
-
idx
-
1
]
)
;
if
(
(
(
idx
&
3
)
=
=
3
)
&
&
(
idx
+
1
!
=
length
)
)
JitSpewCont
(
JitSpew_Pools
"
_
"
)
;
}
JitSpewFin
(
JitSpew_Pools
)
;
}
#
endif
unsigned
index
=
insertEntryForwards
(
numInst
numPoolEntries
inst
data
)
;
if
(
this
-
>
oom
(
)
)
return
BufferOffset
(
)
;
PoolEntry
retPE
;
if
(
numPoolEntries
)
{
JitSpew
(
JitSpew_Pools
"
[
%
d
]
Entry
has
index
%
u
offset
%
u
"
id
index
sizeExcludingCurrentPool
(
)
)
;
Asm
:
:
InsertIndexIntoTag
(
inst
index
)
;
retPE
=
PoolEntry
(
poolEntryCount
)
;
poolEntryCount
+
=
numPoolEntries
;
}
if
(
pe
!
=
nullptr
)
*
pe
=
retPE
;
return
this
-
>
putBytes
(
numInst
*
InstSize
inst
)
;
}
BufferOffset
putInt
(
uint32_t
value
bool
markAsBranch
=
false
)
{
return
allocEntry
(
1
0
(
uint8_t
*
)
&
value
nullptr
nullptr
markAsBranch
)
;
}
private
:
void
finishPool
(
)
{
JitSpew
(
JitSpew_Pools
"
[
%
d
]
Attempting
to
finish
pool
%
d
with
%
d
entries
.
"
id
numDumps_
pool_
.
numEntries
(
)
)
;
if
(
pool_
.
numEntries
(
)
=
=
0
)
{
JitSpew
(
JitSpew_Pools
"
[
%
d
]
Aborting
because
the
pool
is
empty
"
id
)
;
return
;
}
MOZ_ASSERT
(
!
canNotPlacePool_
)
;
BufferOffset
guard
=
this
-
>
putBytes
(
guardSize_
*
InstSize
nullptr
)
;
BufferOffset
header
=
this
-
>
putBytes
(
headerSize_
*
InstSize
nullptr
)
;
BufferOffset
data
=
this
-
>
putBytesLarge
(
pool_
.
getPoolSize
(
)
(
const
uint8_t
*
)
pool_
.
poolData
(
)
)
;
if
(
this
-
>
oom
(
)
)
return
;
BufferOffset
afterPool
=
this
-
>
nextOffset
(
)
;
Asm
:
:
WritePoolGuard
(
guard
this
-
>
getInst
(
guard
)
afterPool
)
;
Asm
:
:
WritePoolHeader
(
(
uint8_t
*
)
this
-
>
getInst
(
header
)
&
pool_
false
)
;
BufferOffset
perforation
=
this
-
>
nextOffset
(
)
;
Parent
:
:
perforate
(
)
;
JitSpew
(
JitSpew_Pools
"
[
%
d
]
Adding
a
perforation
at
offset
%
d
"
id
perforation
.
getOffset
(
)
)
;
size_t
poolOffset
=
data
.
getOffset
(
)
;
unsigned
idx
=
0
;
for
(
BufferOffset
*
iter
=
pool_
.
loadOffsets
.
begin
(
)
;
iter
!
=
pool_
.
loadOffsets
.
end
(
)
;
+
+
iter
+
+
idx
)
{
MOZ_ASSERT
(
iter
-
>
getOffset
(
)
<
guard
.
getOffset
(
)
)
;
Inst
*
inst
=
this
-
>
getInst
(
*
iter
)
;
size_t
codeOffset
=
poolOffset
-
iter
-
>
getOffset
(
)
;
JitSpew
(
JitSpew_Pools
"
[
%
d
]
Fixing
entry
%
d
offset
to
%
u
"
id
idx
codeOffset
)
;
Asm
:
:
PatchConstantPoolLoad
(
inst
(
uint8_t
*
)
inst
+
codeOffset
)
;
}
if
(
numDumps_
>
=
poolInfoSize_
)
{
poolInfoSize_
*
=
2
;
PoolInfo
*
tmp
=
this
-
>
lifoAlloc_
.
template
newArrayUninitialized
<
PoolInfo
>
(
poolInfoSize_
)
;
if
(
tmp
=
=
nullptr
)
{
this
-
>
fail_oom
(
)
;
return
;
}
mozilla
:
:
PodCopy
(
tmp
poolInfo_
numDumps_
)
;
poolInfo_
=
tmp
;
}
unsigned
firstEntry
=
poolEntryCount
-
pool_
.
numEntries
(
)
;
MOZ_ASSERT
(
numDumps_
<
poolInfoSize_
)
;
poolInfo_
[
numDumps_
]
=
PoolInfo
(
firstEntry
data
)
;
numDumps_
+
+
;
if
(
!
pool_
.
reset
(
this
-
>
lifoAlloc_
)
)
{
this
-
>
fail_oom
(
)
;
return
;
}
}
public
:
void
flushPool
(
)
{
if
(
this
-
>
oom
(
)
)
return
;
JitSpew
(
JitSpew_Pools
"
[
%
d
]
Requesting
a
pool
flush
"
id
)
;
finishPool
(
)
;
}
void
enterNoPool
(
size_t
maxInst
)
{
MOZ_ASSERT
(
!
canNotPlacePool_
)
;
insertNopFill
(
)
;
size_t
poolOffset
=
sizeExcludingCurrentPool
(
)
+
(
maxInst
+
guardSize_
+
headerSize_
)
*
InstSize
;
if
(
pool_
.
checkFull
(
poolOffset
)
)
{
JitSpew
(
JitSpew_Pools
"
[
%
d
]
No
-
Pool
instruction
(
%
d
)
caused
a
spill
.
"
id
sizeExcludingCurrentPool
(
)
)
;
finishPool
(
)
;
}
#
ifdef
DEBUG
canNotPlacePoolStartOffset_
=
this
-
>
nextOffset
(
)
.
getOffset
(
)
;
canNotPlacePoolMaxInst_
=
maxInst
;
#
endif
canNotPlacePool_
=
true
;
}
void
leaveNoPool
(
)
{
MOZ_ASSERT
(
canNotPlacePool_
)
;
canNotPlacePool_
=
false
;
MOZ_ASSERT
(
this
-
>
nextOffset
(
)
.
getOffset
(
)
-
canNotPlacePoolStartOffset_
<
=
canNotPlacePoolMaxInst_
*
InstSize
)
;
}
size_t
poolSizeBefore
(
size_t
offset
)
const
{
return
0
;
}
void
align
(
unsigned
alignment
)
{
MOZ_ASSERT
(
IsPowerOfTwo
(
alignment
)
)
;
insertNopFill
(
)
;
unsigned
requiredFill
=
sizeExcludingCurrentPool
(
)
&
(
alignment
-
1
)
;
if
(
requiredFill
=
=
0
)
return
;
requiredFill
=
alignment
-
requiredFill
;
uint32_t
poolOffset
=
sizeExcludingCurrentPool
(
)
+
requiredFill
+
(
1
+
guardSize_
+
headerSize_
)
*
InstSize
;
if
(
pool_
.
checkFull
(
poolOffset
)
)
{
JitSpew
(
JitSpew_Pools
"
[
%
d
]
Alignment
of
%
d
at
%
d
caused
a
spill
.
"
id
alignment
sizeExcludingCurrentPool
(
)
)
;
finishPool
(
)
;
}
inhibitNops_
=
true
;
while
(
(
sizeExcludingCurrentPool
(
)
&
(
alignment
-
1
)
)
&
&
!
this
-
>
oom
(
)
)
putInt
(
alignFillInst_
)
;
inhibitNops_
=
false
;
}
public
:
void
executableCopy
(
uint8_t
*
dest
)
{
if
(
this
-
>
oom
(
)
)
return
;
MOZ_ASSERT
(
pool_
.
numEntries
(
)
=
=
0
)
;
for
(
Slice
*
cur
=
getHead
(
)
;
cur
!
=
nullptr
;
cur
=
cur
-
>
getNext
(
)
)
{
memcpy
(
dest
&
cur
-
>
instructions
[
0
]
cur
-
>
length
(
)
)
;
dest
+
=
cur
-
>
length
(
)
;
}
}
public
:
size_t
poolEntryOffset
(
PoolEntry
pe
)
const
{
MOZ_ASSERT
(
pe
.
index
(
)
<
poolEntryCount
-
pool_
.
numEntries
(
)
"
Invalid
pool
entry
or
not
flushed
yet
.
"
)
;
auto
b
=
poolInfo_
e
=
poolInfo_
+
numDumps_
;
auto
i
=
std
:
:
upper_bound
(
b
e
pe
.
index
(
)
[
]
(
size_t
value
const
PoolInfo
&
entry
)
{
return
value
<
entry
.
firstEntryIndex
;
}
)
;
MOZ_ASSERT
(
i
!
=
b
"
PoolInfo
not
sorted
or
empty
?
"
)
;
-
-
i
;
MOZ_ASSERT
(
i
-
>
firstEntryIndex
<
=
pe
.
index
(
)
&
&
(
i
+
1
=
=
e
|
|
(
i
+
1
)
-
>
firstEntryIndex
>
pe
.
index
(
)
)
)
;
unsigned
relativeIndex
=
pe
.
index
(
)
-
i
-
>
firstEntryIndex
;
return
i
-
>
offset
.
getOffset
(
)
+
relativeIndex
*
sizeof
(
PoolAllocUnit
)
;
}
}
;
}
}
#
endif
