#
include
"
jit
/
Bailouts
.
h
"
#
include
"
jit
/
JitFrames
.
h
"
#
include
"
jit
/
JitRealm
.
h
"
#
include
"
jit
/
Linker
.
h
"
#
ifdef
JS_ION_PERF
#
include
"
jit
/
PerfSpewer
.
h
"
#
endif
#
include
"
jit
/
arm64
/
SharedICHelpers
-
arm64
.
h
"
#
include
"
jit
/
VMFunctions
.
h
"
#
include
"
vm
/
JitActivation
.
h
"
#
include
"
jit
/
MacroAssembler
-
inl
.
h
"
using
namespace
js
;
using
namespace
js
:
:
jit
;
void
JitRuntime
:
:
generateEnterJIT
(
JSContext
*
cx
MacroAssembler
&
masm
)
{
enterJITOffset_
=
startTrampolineCode
(
masm
)
;
const
Register
reg_code
=
IntArgReg0
;
const
Register
reg_argc
=
IntArgReg1
;
const
Register
reg_argv
=
IntArgReg2
;
const
Register
reg_osrFrame
=
IntArgReg3
;
const
Register
reg_callee
=
IntArgReg4
;
const
Register
reg_scope
=
IntArgReg5
;
const
Register
reg_osrNStack
=
IntArgReg6
;
const
Register
reg_vp
=
IntArgReg7
;
static_assert
(
OsrFrameReg
=
=
IntArgReg3
)
;
masm
.
SetStackPointer64
(
sp
)
;
masm
.
push
(
r29
r30
)
;
masm
.
moveStackPtrTo
(
r29
)
;
masm
.
push
(
r19
r20
r21
r22
)
;
masm
.
push
(
r23
r24
r25
r26
)
;
masm
.
push
(
r27
r28
r7
r30
)
;
masm
.
push
(
d8
d9
d10
d11
)
;
masm
.
push
(
d12
d13
d14
d15
)
;
#
ifdef
DEBUG
masm
.
movePtr
(
ImmWord
(
0xdeadd00d
)
r23
)
;
masm
.
movePtr
(
ImmWord
(
0xdeadd11d
)
r24
)
;
masm
.
push
(
r23
r24
)
;
#
endif
masm
.
Mov
(
PseudoStackPointer64
sp
)
;
masm
.
SetStackPointer64
(
PseudoStackPointer64
)
;
masm
.
moveStackPtrTo
(
BaselineFrameReg
)
;
masm
.
moveStackPtrTo
(
r19
)
;
{
Label
noNewTarget
;
Imm32
constructingToken
(
CalleeToken_FunctionConstructing
)
;
masm
.
branchTest32
(
Assembler
:
:
Zero
reg_callee
constructingToken
&
noNewTarget
)
;
masm
.
add32
(
Imm32
(
1
)
reg_argc
)
;
masm
.
bind
(
&
noNewTarget
)
;
}
masm
.
andToStackPtr
(
Imm32
(
~
0xf
)
)
;
masm
.
touchFrameValues
(
reg_argc
r20
r21
)
;
masm
.
moveToStackPtr
(
r19
)
;
{
vixl
:
:
UseScratchRegisterScope
temps
(
&
masm
.
asVIXL
(
)
)
;
const
ARMRegister
tmp_argc
=
temps
.
AcquireX
(
)
;
const
ARMRegister
tmp_sp
=
temps
.
AcquireX
(
)
;
Label
noArguments
;
Label
loopHead
;
masm
.
movePtr
(
reg_argc
tmp_argc
.
asUnsized
(
)
)
;
masm
.
subFromStackPtr
(
Imm32
(
8
)
)
;
masm
.
Sub
(
PseudoStackPointer64
PseudoStackPointer64
Operand
(
tmp_argc
vixl
:
:
SXTX
3
)
)
;
masm
.
andToStackPtr
(
Imm32
(
~
0xf
)
)
;
masm
.
moveStackPtrTo
(
tmp_sp
.
asUnsized
(
)
)
;
masm
.
branchTestPtr
(
Assembler
:
:
Zero
reg_argc
reg_argc
&
noArguments
)
;
{
masm
.
bind
(
&
loopHead
)
;
masm
.
Ldr
(
x24
MemOperand
(
ARMRegister
(
reg_argv
64
)
Operand
(
8
)
vixl
:
:
PostIndex
)
)
;
masm
.
Str
(
x24
MemOperand
(
tmp_sp
Operand
(
8
)
vixl
:
:
PostIndex
)
)
;
masm
.
Subs
(
tmp_argc
tmp_argc
Operand
(
1
)
)
;
masm
.
B
(
&
loopHead
vixl
:
:
Condition
:
:
NonZero
)
;
}
masm
.
bind
(
&
noArguments
)
;
}
masm
.
checkStackAlignment
(
)
;
masm
.
unboxInt32
(
Address
(
reg_vp
0x0
)
ip0
)
;
masm
.
push
(
ip0
reg_callee
)
;
masm
.
checkStackAlignment
(
)
;
masm
.
subStackPtrFrom
(
r19
)
;
masm
.
makeFrameDescriptor
(
r19
FrameType
:
:
CppToJSJit
JitFrameLayout
:
:
Size
(
)
)
;
masm
.
Push
(
r19
)
;
Label
osrReturnPoint
;
{
Label
notOsr
;
masm
.
branchTestPtr
(
Assembler
:
:
Zero
OsrFrameReg
OsrFrameReg
&
notOsr
)
;
masm
.
Adr
(
ScratchReg2_64
&
osrReturnPoint
)
;
masm
.
push
(
ScratchReg2
BaselineFrameReg
)
;
masm
.
subFromStackPtr
(
Imm32
(
BaselineFrame
:
:
Size
(
)
)
)
;
masm
.
touchFrameValues
(
reg_osrNStack
ScratchReg2
BaselineFrameReg
)
;
masm
.
moveStackPtrTo
(
BaselineFrameReg
)
;
masm
.
Lsl
(
w19
ARMRegister
(
reg_osrNStack
32
)
3
)
;
masm
.
subFromStackPtr
(
r19
)
;
masm
.
addPtr
(
Imm32
(
BaselineFrame
:
:
Size
(
)
+
BaselineFrame
:
:
FramePointerOffset
)
r19
)
;
masm
.
makeFrameDescriptor
(
r19
FrameType
:
:
BaselineJS
ExitFrameLayout
:
:
Size
(
)
)
;
masm
.
asVIXL
(
)
.
Push
(
x19
xzr
)
;
masm
.
loadJSContext
(
r19
)
;
masm
.
enterFakeExitFrame
(
r19
r19
ExitFrameType
:
:
Bare
)
;
masm
.
push
(
BaselineFrameReg
reg_code
)
;
using
Fn
=
bool
(
*
)
(
BaselineFrame
*
frame
InterpreterFrame
*
interpFrame
uint32_t
numStackValues
)
;
masm
.
setupUnalignedABICall
(
r19
)
;
masm
.
passABIArg
(
BaselineFrameReg
)
;
masm
.
passABIArg
(
reg_osrFrame
)
;
masm
.
passABIArg
(
reg_osrNStack
)
;
masm
.
callWithABI
<
Fn
jit
:
:
InitBaselineFrameForOsr
>
(
MoveOp
:
:
GENERAL
CheckUnsafeCallWithABI
:
:
DontCheckHasExitFrame
)
;
masm
.
pop
(
r19
BaselineFrameReg
)
;
MOZ_ASSERT
(
r19
!
=
ReturnReg
)
;
masm
.
addToStackPtr
(
Imm32
(
ExitFrameLayout
:
:
SizeWithFooter
(
)
)
)
;
masm
.
addPtr
(
Imm32
(
BaselineFrame
:
:
Size
(
)
)
BaselineFrameReg
)
;
Label
error
;
masm
.
branchIfFalseBool
(
ReturnReg
&
error
)
;
masm
.
jump
(
r19
)
;
masm
.
bind
(
&
error
)
;
masm
.
Add
(
masm
.
GetStackPointer64
(
)
BaselineFrameReg64
Operand
(
2
*
sizeof
(
uintptr_t
)
)
)
;
masm
.
syncStackPtr
(
)
;
masm
.
moveValue
(
MagicValue
(
JS_ION_ERROR
)
JSReturnOperand
)
;
masm
.
B
(
&
osrReturnPoint
)
;
masm
.
bind
(
&
notOsr
)
;
masm
.
movePtr
(
reg_scope
R1_
)
;
}
masm
.
callJitNoProfiler
(
reg_code
)
;
masm
.
bind
(
&
osrReturnPoint
)
;
masm
.
Pop
(
r19
)
;
masm
.
Add
(
masm
.
GetStackPointer64
(
)
masm
.
GetStackPointer64
(
)
Operand
(
x19
vixl
:
:
LSR
FRAMESIZE_SHIFT
)
)
;
masm
.
syncStackPtr
(
)
;
masm
.
SetStackPointer64
(
sp
)
;
#
ifdef
DEBUG
masm
.
pop
(
r24
r23
)
;
Label
x23OK
x24OK
;
masm
.
branchPtr
(
Assembler
:
:
Equal
r23
ImmWord
(
0xdeadd00d
)
&
x23OK
)
;
masm
.
breakpoint
(
)
;
masm
.
bind
(
&
x23OK
)
;
masm
.
branchPtr
(
Assembler
:
:
Equal
r24
ImmWord
(
0xdeadd11d
)
&
x24OK
)
;
masm
.
breakpoint
(
)
;
masm
.
bind
(
&
x24OK
)
;
#
endif
masm
.
pop
(
d15
d14
d13
d12
)
;
masm
.
pop
(
d11
d10
d9
d8
)
;
masm
.
pop
(
r30
r7
r28
r27
)
;
masm
.
pop
(
r26
r25
r24
r23
)
;
masm
.
pop
(
r22
r21
r20
r19
)
;
masm
.
storeValue
(
JSReturnOperand
Address
(
reg_vp
0
)
)
;
masm
.
pop
(
r30
r29
)
;
masm
.
abiret
(
)
;
masm
.
SetStackPointer64
(
PseudoStackPointer64
)
;
}
static
void
PushRegisterDump
(
MacroAssembler
&
masm
)
{
const
LiveRegisterSet
First28GeneralRegisters
=
LiveRegisterSet
(
GeneralRegisterSet
(
Registers
:
:
AllMask
&
~
(
1
<
<
31
|
1
<
<
30
|
1
<
<
29
|
1
<
<
28
)
)
FloatRegisterSet
(
FloatRegisters
:
:
NoneMask
)
)
;
const
LiveRegisterSet
AllFloatRegisters
=
LiveRegisterSet
(
GeneralRegisterSet
(
Registers
:
:
NoneMask
)
FloatRegisterSet
(
FloatRegisters
:
:
AllMask
)
)
;
masm
.
asVIXL
(
)
.
Push
(
xzr
x30
x29
xzr
)
;
masm
.
PushRegsInMask
(
First28GeneralRegisters
)
;
masm
.
PushRegsInMask
(
AllFloatRegisters
)
;
}
void
JitRuntime
:
:
generateInvalidator
(
MacroAssembler
&
masm
Label
*
bailoutTail
)
{
invalidatorOffset_
=
startTrampolineCode
(
masm
)
;
PushRegisterDump
(
masm
)
;
masm
.
moveStackPtrTo
(
r0
)
;
masm
.
Sub
(
x1
masm
.
GetStackPointer64
(
)
Operand
(
sizeof
(
size_t
)
)
)
;
masm
.
Sub
(
x2
masm
.
GetStackPointer64
(
)
Operand
(
sizeof
(
size_t
)
+
sizeof
(
void
*
)
)
)
;
masm
.
moveToStackPtr
(
r2
)
;
using
Fn
=
bool
(
*
)
(
InvalidationBailoutStack
*
sp
size_t
*
frameSizeOut
BaselineBailoutInfo
*
*
info
)
;
masm
.
setupUnalignedABICall
(
r10
)
;
masm
.
passABIArg
(
r0
)
;
masm
.
passABIArg
(
r1
)
;
masm
.
passABIArg
(
r2
)
;
masm
.
callWithABI
<
Fn
InvalidationBailout
>
(
MoveOp
:
:
GENERAL
CheckUnsafeCallWithABI
:
:
DontCheckOther
)
;
masm
.
pop
(
r2
r1
)
;
masm
.
Add
(
masm
.
GetStackPointer64
(
)
masm
.
GetStackPointer64
(
)
x1
)
;
masm
.
Add
(
masm
.
GetStackPointer64
(
)
masm
.
GetStackPointer64
(
)
Operand
(
sizeof
(
InvalidationBailoutStack
)
)
)
;
masm
.
syncStackPtr
(
)
;
masm
.
jump
(
bailoutTail
)
;
}
void
JitRuntime
:
:
generateArgumentsRectifier
(
MacroAssembler
&
masm
ArgumentsRectifierKind
kind
)
{
switch
(
kind
)
{
case
ArgumentsRectifierKind
:
:
Normal
:
argumentsRectifierOffset_
=
startTrampolineCode
(
masm
)
;
break
;
case
ArgumentsRectifierKind
:
:
TrialInlining
:
trialInliningArgumentsRectifierOffset_
=
startTrampolineCode
(
masm
)
;
break
;
}
masm
.
push
(
lr
)
;
masm
.
Ldr
(
w0
MemOperand
(
masm
.
GetStackPointer64
(
)
RectifierFrameLayout
:
:
offsetOfNumActualArgs
(
)
)
)
;
masm
.
Ldr
(
x1
MemOperand
(
masm
.
GetStackPointer64
(
)
RectifierFrameLayout
:
:
offsetOfCalleeToken
(
)
)
)
;
masm
.
And
(
x5
x1
Operand
(
CalleeTokenMask
)
)
;
masm
.
Ldrh
(
x6
MemOperand
(
x5
JSFunction
:
:
offsetOfNargs
(
)
)
)
;
static_assert
(
CalleeToken_FunctionConstructing
=
=
0x1
"
Constructing
must
be
low
-
order
bit
"
)
;
masm
.
And
(
x4
x1
Operand
(
CalleeToken_FunctionConstructing
)
)
;
masm
.
Add
(
x7
x6
x4
)
;
masm
.
mov
(
r0
r8
)
;
masm
.
Add
(
x3
masm
.
GetStackPointer64
(
)
Operand
(
x8
vixl
:
:
LSL
3
)
)
;
masm
.
Add
(
x3
x3
Operand
(
sizeof
(
RectifierFrameLayout
)
)
)
;
Label
noPadding
;
masm
.
Tbnz
(
x7
0
&
noPadding
)
;
masm
.
asVIXL
(
)
.
Push
(
xzr
)
;
masm
.
Add
(
x7
x7
Operand
(
1
)
)
;
masm
.
bind
(
&
noPadding
)
;
{
Label
notConstructing
;
masm
.
Cbz
(
x4
&
notConstructing
)
;
masm
.
loadPtr
(
Address
(
r3
sizeof
(
Value
)
)
r4
)
;
masm
.
Push
(
r4
)
;
masm
.
bind
(
&
notConstructing
)
;
}
masm
.
Sub
(
w2
w6
w8
)
;
masm
.
moveValue
(
UndefinedValue
(
)
ValueOperand
(
r4
)
)
;
{
Label
undefLoopTop
;
masm
.
bind
(
&
undefLoopTop
)
;
masm
.
Push
(
r4
)
;
masm
.
Subs
(
w2
w2
Operand
(
1
)
)
;
masm
.
B
(
&
undefLoopTop
Assembler
:
:
NonZero
)
;
}
{
Label
copyLoopTop
;
masm
.
bind
(
&
copyLoopTop
)
;
masm
.
Ldr
(
x4
MemOperand
(
x3
-
sizeof
(
Value
)
vixl
:
:
PostIndex
)
)
;
masm
.
Push
(
r4
)
;
masm
.
Subs
(
x8
x8
Operand
(
1
)
)
;
masm
.
B
(
&
copyLoopTop
Assembler
:
:
NotSigned
)
;
}
masm
.
Add
(
x6
x7
Operand
(
1
)
)
;
masm
.
Lsl
(
x6
x6
3
)
;
masm
.
makeFrameDescriptor
(
r6
FrameType
:
:
Rectifier
JitFrameLayout
:
:
Size
(
)
)
;
masm
.
push
(
r0
r1
r6
)
;
switch
(
kind
)
{
case
ArgumentsRectifierKind
:
:
Normal
:
masm
.
loadJitCodeRaw
(
r5
r3
)
;
argumentsRectifierReturnOffset_
=
masm
.
callJitNoProfiler
(
r3
)
;
break
;
case
ArgumentsRectifierKind
:
:
TrialInlining
:
Label
noBaselineScript
done
;
masm
.
loadBaselineJitCodeRaw
(
r5
r3
&
noBaselineScript
)
;
masm
.
callJitNoProfiler
(
r3
)
;
masm
.
jump
(
&
done
)
;
masm
.
bind
(
&
noBaselineScript
)
;
masm
.
loadJitCodeRaw
(
r5
r3
)
;
masm
.
callJitNoProfiler
(
r3
)
;
masm
.
bind
(
&
done
)
;
break
;
}
masm
.
Ldr
(
x4
MemOperand
(
masm
.
GetStackPointer64
(
)
24
vixl
:
:
PostIndex
)
)
;
masm
.
Add
(
masm
.
GetStackPointer64
(
)
masm
.
GetStackPointer64
(
)
Operand
(
x4
vixl
:
:
LSR
FRAMESIZE_SHIFT
)
)
;
masm
.
ret
(
)
;
}
static
void
PushBailoutFrame
(
MacroAssembler
&
masm
Register
spArg
)
{
PushRegisterDump
(
masm
)
;
masm
.
moveStackPtrTo
(
spArg
)
;
}
static
void
GenerateBailoutThunk
(
MacroAssembler
&
masm
Label
*
bailoutTail
)
{
PushBailoutFrame
(
masm
r0
)
;
masm
.
reserveStack
(
sizeof
(
void
*
)
)
;
masm
.
moveStackPtrTo
(
r1
)
;
using
Fn
=
bool
(
*
)
(
BailoutStack
*
sp
BaselineBailoutInfo
*
*
info
)
;
masm
.
setupUnalignedABICall
(
r2
)
;
masm
.
passABIArg
(
r0
)
;
masm
.
passABIArg
(
r1
)
;
masm
.
callWithABI
<
Fn
Bailout
>
(
MoveOp
:
:
GENERAL
CheckUnsafeCallWithABI
:
:
DontCheckOther
)
;
masm
.
pop
(
r2
)
;
static
const
uint32_t
BailoutDataSize
=
sizeof
(
RegisterDump
)
;
masm
.
addToStackPtr
(
Imm32
(
BailoutDataSize
)
)
;
vixl
:
:
UseScratchRegisterScope
temps
(
&
masm
.
asVIXL
(
)
)
;
const
ARMRegister
scratch64
=
temps
.
AcquireX
(
)
;
masm
.
Ldr
(
scratch64
MemOperand
(
masm
.
GetStackPointer64
(
)
0x0
)
)
;
masm
.
addPtr
(
Imm32
(
2
*
sizeof
(
void
*
)
)
scratch64
.
asUnsized
(
)
)
;
masm
.
addToStackPtr
(
scratch64
.
asUnsized
(
)
)
;
masm
.
jump
(
bailoutTail
)
;
}
JitRuntime
:
:
BailoutTable
JitRuntime
:
:
generateBailoutTable
(
MacroAssembler
&
masm
Label
*
bailoutTail
uint32_t
frameClass
)
{
MOZ_CRASH
(
"
arm64
does
not
use
bailout
tables
"
)
;
}
void
JitRuntime
:
:
generateBailoutHandler
(
MacroAssembler
&
masm
Label
*
bailoutTail
)
{
bailoutHandlerOffset_
=
startTrampolineCode
(
masm
)
;
GenerateBailoutThunk
(
masm
bailoutTail
)
;
}
bool
JitRuntime
:
:
generateVMWrapper
(
JSContext
*
cx
MacroAssembler
&
masm
const
VMFunctionData
&
f
DynFn
nativeFun
uint32_t
*
wrapperOffset
)
{
*
wrapperOffset
=
startTrampolineCode
(
masm
)
;
AllocatableGeneralRegisterSet
regs
(
Register
:
:
Codes
:
:
WrapperMask
)
;
static_assert
(
(
Register
:
:
Codes
:
:
VolatileMask
&
~
Register
:
:
Codes
:
:
WrapperMask
)
=
=
0
"
Wrapper
register
set
must
be
a
superset
of
the
Volatile
register
set
.
"
)
;
masm
.
push
(
lr
)
;
Register
reg_cx
=
IntArgReg0
;
regs
.
take
(
reg_cx
)
;
masm
.
loadJSContext
(
reg_cx
)
;
masm
.
enterExitFrame
(
reg_cx
regs
.
getAny
(
)
&
f
)
;
Register
argsBase
=
InvalidReg
;
if
(
f
.
explicitArgs
)
{
argsBase
=
r8
;
regs
.
take
(
argsBase
)
;
masm
.
Add
(
ARMRegister
(
argsBase
64
)
masm
.
GetStackPointer64
(
)
Operand
(
ExitFrameLayout
:
:
SizeWithFooter
(
)
)
)
;
}
Register
outReg
=
InvalidReg
;
switch
(
f
.
outParam
)
{
case
Type_Value
:
outReg
=
regs
.
takeAny
(
)
;
masm
.
reserveStack
(
sizeof
(
Value
)
)
;
masm
.
moveStackPtrTo
(
outReg
)
;
break
;
case
Type_Handle
:
outReg
=
regs
.
takeAny
(
)
;
masm
.
PushEmptyRooted
(
f
.
outParamRootType
)
;
masm
.
moveStackPtrTo
(
outReg
)
;
break
;
case
Type_Int32
:
case
Type_Bool
:
outReg
=
regs
.
takeAny
(
)
;
masm
.
reserveStack
(
sizeof
(
int64_t
)
)
;
masm
.
moveStackPtrTo
(
outReg
)
;
break
;
case
Type_Double
:
outReg
=
regs
.
takeAny
(
)
;
masm
.
reserveStack
(
sizeof
(
double
)
)
;
masm
.
moveStackPtrTo
(
outReg
)
;
break
;
case
Type_Pointer
:
outReg
=
regs
.
takeAny
(
)
;
masm
.
reserveStack
(
sizeof
(
uintptr_t
)
)
;
masm
.
moveStackPtrTo
(
outReg
)
;
break
;
default
:
MOZ_ASSERT
(
f
.
outParam
=
=
Type_Void
)
;
break
;
}
if
(
!
generateTLEnterVM
(
masm
f
)
)
{
return
false
;
}
masm
.
setupUnalignedABICall
(
regs
.
getAny
(
)
)
;
masm
.
passABIArg
(
reg_cx
)
;
size_t
argDisp
=
0
;
for
(
uint32_t
explicitArg
=
0
;
explicitArg
<
f
.
explicitArgs
;
explicitArg
+
+
)
{
switch
(
f
.
argProperties
(
explicitArg
)
)
{
case
VMFunctionData
:
:
WordByValue
:
masm
.
passABIArg
(
MoveOperand
(
argsBase
argDisp
)
(
f
.
argPassedInFloatReg
(
explicitArg
)
?
MoveOp
:
:
DOUBLE
:
MoveOp
:
:
GENERAL
)
)
;
argDisp
+
=
sizeof
(
void
*
)
;
break
;
case
VMFunctionData
:
:
WordByRef
:
masm
.
passABIArg
(
MoveOperand
(
argsBase
argDisp
MoveOperand
:
:
EFFECTIVE_ADDRESS
)
MoveOp
:
:
GENERAL
)
;
argDisp
+
=
sizeof
(
void
*
)
;
break
;
case
VMFunctionData
:
:
DoubleByValue
:
case
VMFunctionData
:
:
DoubleByRef
:
MOZ_CRASH
(
"
NYI
:
AArch64
callVM
should
not
be
used
with
128bit
values
.
"
)
;
}
}
if
(
outReg
!
=
InvalidReg
)
{
masm
.
passABIArg
(
outReg
)
;
}
masm
.
callWithABI
(
nativeFun
MoveOp
:
:
GENERAL
CheckUnsafeCallWithABI
:
:
DontCheckHasExitFrame
)
;
if
(
!
generateTLExitVM
(
masm
f
)
)
{
return
false
;
}
masm
.
initPseudoStackPtr
(
)
;
switch
(
f
.
failType
(
)
)
{
case
Type_Object
:
masm
.
branchTestPtr
(
Assembler
:
:
Zero
r0
r0
masm
.
failureLabel
(
)
)
;
break
;
case
Type_Bool
:
masm
.
branchIfFalseBool
(
r0
masm
.
failureLabel
(
)
)
;
break
;
case
Type_Void
:
break
;
default
:
MOZ_CRASH
(
"
unknown
failure
kind
"
)
;
}
switch
(
f
.
outParam
)
{
case
Type_Value
:
masm
.
Ldr
(
ARMRegister
(
JSReturnReg
64
)
MemOperand
(
masm
.
GetStackPointer64
(
)
)
)
;
masm
.
freeStack
(
sizeof
(
Value
)
)
;
break
;
case
Type_Handle
:
masm
.
popRooted
(
f
.
outParamRootType
ReturnReg
JSReturnOperand
)
;
break
;
case
Type_Int32
:
masm
.
Ldr
(
ARMRegister
(
ReturnReg
32
)
MemOperand
(
masm
.
GetStackPointer64
(
)
)
)
;
masm
.
freeStack
(
sizeof
(
int64_t
)
)
;
break
;
case
Type_Bool
:
masm
.
Ldrb
(
ARMRegister
(
ReturnReg
32
)
MemOperand
(
masm
.
GetStackPointer64
(
)
)
)
;
masm
.
freeStack
(
sizeof
(
int64_t
)
)
;
break
;
case
Type_Double
:
MOZ_ASSERT
(
JitOptions
.
supportsFloatingPoint
)
;
masm
.
Ldr
(
ARMFPRegister
(
ReturnDoubleReg
64
)
MemOperand
(
masm
.
GetStackPointer64
(
)
)
)
;
masm
.
freeStack
(
sizeof
(
double
)
)
;
break
;
case
Type_Pointer
:
masm
.
Ldr
(
ARMRegister
(
ReturnReg
64
)
MemOperand
(
masm
.
GetStackPointer64
(
)
)
)
;
masm
.
freeStack
(
sizeof
(
uintptr_t
)
)
;
break
;
default
:
MOZ_ASSERT
(
f
.
outParam
=
=
Type_Void
)
;
break
;
}
if
(
f
.
returnsData
(
)
&
&
JitOptions
.
spectreJitToCxxCalls
)
{
masm
.
speculationBarrier
(
)
;
}
masm
.
leaveExitFrame
(
)
;
masm
.
retn
(
Imm32
(
sizeof
(
ExitFrameLayout
)
+
f
.
explicitStackSlots
(
)
*
sizeof
(
void
*
)
+
f
.
extraValuesToPop
*
sizeof
(
Value
)
)
)
;
return
true
;
}
uint32_t
JitRuntime
:
:
generatePreBarrier
(
JSContext
*
cx
MacroAssembler
&
masm
MIRType
type
)
{
uint32_t
offset
=
startTrampolineCode
(
masm
)
;
static_assert
(
PreBarrierReg
=
=
r1
)
;
Register
temp1
=
r2
;
Register
temp2
=
r3
;
Register
temp3
=
r4
;
masm
.
push
(
temp1
)
;
masm
.
push
(
temp2
)
;
masm
.
push
(
temp3
)
;
Label
noBarrier
;
masm
.
emitPreBarrierFastPath
(
cx
-
>
runtime
(
)
type
temp1
temp2
temp3
&
noBarrier
)
;
masm
.
pop
(
temp3
)
;
masm
.
pop
(
temp2
)
;
masm
.
pop
(
temp1
)
;
LiveRegisterSet
regs
=
LiveRegisterSet
(
GeneralRegisterSet
(
Registers
:
:
VolatileMask
)
FloatRegisterSet
(
FloatRegisters
:
:
VolatileMask
)
)
;
regs
.
add
(
lr
)
;
masm
.
PushRegsInMask
(
regs
)
;
masm
.
movePtr
(
ImmPtr
(
cx
-
>
runtime
(
)
)
r3
)
;
masm
.
setupUnalignedABICall
(
r0
)
;
masm
.
passABIArg
(
r3
)
;
masm
.
passABIArg
(
PreBarrierReg
)
;
masm
.
callWithABI
(
JitMarkFunction
(
type
)
)
;
masm
.
PopRegsInMask
(
regs
)
;
masm
.
abiret
(
)
;
masm
.
bind
(
&
noBarrier
)
;
masm
.
pop
(
temp3
)
;
masm
.
pop
(
temp2
)
;
masm
.
pop
(
temp1
)
;
masm
.
abiret
(
)
;
return
offset
;
}
void
JitRuntime
:
:
generateExceptionTailStub
(
MacroAssembler
&
masm
Label
*
profilerExitTail
)
{
exceptionTailOffset_
=
startTrampolineCode
(
masm
)
;
masm
.
bind
(
masm
.
failureLabel
(
)
)
;
masm
.
handleFailureWithHandlerTail
(
profilerExitTail
)
;
}
void
JitRuntime
:
:
generateBailoutTailStub
(
MacroAssembler
&
masm
Label
*
bailoutTail
)
{
bailoutTailOffset_
=
startTrampolineCode
(
masm
)
;
masm
.
bind
(
bailoutTail
)
;
masm
.
generateBailoutTail
(
r1
r2
)
;
}
void
JitRuntime
:
:
generateProfilerExitFrameTailStub
(
MacroAssembler
&
masm
Label
*
profilerExitTail
)
{
profilerExitFrameTailOffset_
=
startTrampolineCode
(
masm
)
;
masm
.
bind
(
profilerExitTail
)
;
Register
scratch1
=
r8
;
Register
scratch2
=
r9
;
Register
scratch3
=
r10
;
Register
scratch4
=
r11
;
Register
actReg
=
scratch4
;
masm
.
loadJSContext
(
actReg
)
;
masm
.
loadPtr
(
Address
(
actReg
offsetof
(
JSContext
profilingActivation_
)
)
actReg
)
;
Address
lastProfilingFrame
(
actReg
JitActivation
:
:
offsetOfLastProfilingFrame
(
)
)
;
Address
lastProfilingCallSite
(
actReg
JitActivation
:
:
offsetOfLastProfilingCallSite
(
)
)
;
#
ifdef
DEBUG
{
masm
.
loadPtr
(
lastProfilingFrame
scratch1
)
;
Label
checkOk
;
masm
.
branchPtr
(
Assembler
:
:
Equal
scratch1
ImmWord
(
0
)
&
checkOk
)
;
masm
.
branchStackPtr
(
Assembler
:
:
Equal
scratch1
&
checkOk
)
;
masm
.
assumeUnreachable
(
"
Mismatch
between
stored
lastProfilingFrame
and
current
stack
"
"
pointer
.
"
)
;
masm
.
bind
(
&
checkOk
)
;
}
#
endif
masm
.
loadPtr
(
Address
(
masm
.
getStackPointer
(
)
JitFrameLayout
:
:
offsetOfDescriptor
(
)
)
scratch1
)
;
masm
.
and32
(
Imm32
(
(
1
<
<
FRAMETYPE_BITS
)
-
1
)
scratch1
scratch2
)
;
masm
.
rshiftPtr
(
Imm32
(
FRAMESIZE_SHIFT
)
scratch1
)
;
Label
handle_IonJS
;
Label
handle_BaselineStub
;
Label
handle_Rectifier
;
Label
handle_IonICCall
;
Label
handle_Entry
;
Label
end
;
masm
.
branch32
(
Assembler
:
:
Equal
scratch2
Imm32
(
FrameType
:
:
IonJS
)
&
handle_IonJS
)
;
masm
.
branch32
(
Assembler
:
:
Equal
scratch2
Imm32
(
FrameType
:
:
BaselineJS
)
&
handle_IonJS
)
;
masm
.
branch32
(
Assembler
:
:
Equal
scratch2
Imm32
(
FrameType
:
:
BaselineStub
)
&
handle_BaselineStub
)
;
masm
.
branch32
(
Assembler
:
:
Equal
scratch2
Imm32
(
FrameType
:
:
Rectifier
)
&
handle_Rectifier
)
;
masm
.
branch32
(
Assembler
:
:
Equal
scratch2
Imm32
(
FrameType
:
:
IonICCall
)
&
handle_IonICCall
)
;
masm
.
branch32
(
Assembler
:
:
Equal
scratch2
Imm32
(
FrameType
:
:
CppToJSJit
)
&
handle_Entry
)
;
masm
.
branch32
(
Assembler
:
:
Equal
scratch2
Imm32
(
FrameType
:
:
WasmToJSJit
)
&
handle_Entry
)
;
masm
.
assumeUnreachable
(
"
Invalid
caller
frame
type
when
exiting
from
Ion
frame
.
"
)
;
masm
.
bind
(
&
handle_IonJS
)
;
{
masm
.
loadPtr
(
Address
(
masm
.
getStackPointer
(
)
JitFrameLayout
:
:
offsetOfReturnAddress
(
)
)
scratch2
)
;
masm
.
storePtr
(
scratch2
lastProfilingCallSite
)
;
masm
.
Add
(
ARMRegister
(
scratch2
64
)
masm
.
GetStackPointer64
(
)
ARMRegister
(
scratch1
64
)
)
;
masm
.
syncStackPtr
(
)
;
masm
.
addPtr
(
Imm32
(
JitFrameLayout
:
:
Size
(
)
)
scratch2
scratch2
)
;
masm
.
storePtr
(
scratch2
lastProfilingFrame
)
;
masm
.
ret
(
)
;
}
masm
.
bind
(
&
handle_BaselineStub
)
;
{
masm
.
Add
(
ARMRegister
(
scratch3
64
)
masm
.
GetStackPointer64
(
)
ARMRegister
(
scratch1
64
)
)
;
masm
.
syncStackPtr
(
)
;
Address
stubFrameReturnAddr
(
scratch3
JitFrameLayout
:
:
Size
(
)
+
BaselineStubFrameLayout
:
:
offsetOfReturnAddress
(
)
)
;
masm
.
loadPtr
(
stubFrameReturnAddr
scratch2
)
;
masm
.
storePtr
(
scratch2
lastProfilingCallSite
)
;
Address
stubFrameSavedFramePtr
(
scratch3
JitFrameLayout
:
:
Size
(
)
-
(
2
*
sizeof
(
void
*
)
)
)
;
masm
.
loadPtr
(
stubFrameSavedFramePtr
scratch2
)
;
masm
.
addPtr
(
Imm32
(
sizeof
(
void
*
)
)
scratch2
)
;
masm
.
storePtr
(
scratch2
lastProfilingFrame
)
;
masm
.
ret
(
)
;
}
masm
.
bind
(
&
handle_Rectifier
)
;
{
masm
.
Add
(
ARMRegister
(
scratch2
64
)
masm
.
GetStackPointer64
(
)
ARMRegister
(
scratch1
64
)
)
;
masm
.
syncStackPtr
(
)
;
masm
.
addPtr
(
Imm32
(
JitFrameLayout
:
:
Size
(
)
)
scratch2
)
;
masm
.
loadPtr
(
Address
(
scratch2
RectifierFrameLayout
:
:
offsetOfDescriptor
(
)
)
scratch3
)
;
masm
.
rshiftPtr
(
Imm32
(
FRAMESIZE_SHIFT
)
scratch3
scratch1
)
;
masm
.
and32
(
Imm32
(
(
1
<
<
FRAMETYPE_BITS
)
-
1
)
scratch3
)
;
masm
.
assertRectifierFrameParentType
(
scratch3
)
;
Label
notIonFrame
;
masm
.
branch32
(
Assembler
:
:
NotEqual
scratch3
Imm32
(
FrameType
:
:
IonJS
)
&
notIonFrame
)
;
masm
.
loadPtr
(
Address
(
scratch2
RectifierFrameLayout
:
:
offsetOfReturnAddress
(
)
)
scratch3
)
;
masm
.
storePtr
(
scratch3
lastProfilingCallSite
)
;
masm
.
addPtr
(
scratch2
scratch1
scratch3
)
;
masm
.
addPtr
(
Imm32
(
RectifierFrameLayout
:
:
Size
(
)
)
scratch3
)
;
masm
.
storePtr
(
scratch3
lastProfilingFrame
)
;
masm
.
ret
(
)
;
masm
.
bind
(
&
notIonFrame
)
;
masm
.
branch32
(
Assembler
:
:
NotEqual
scratch3
Imm32
(
FrameType
:
:
BaselineStub
)
&
handle_Entry
)
;
masm
.
addPtr
(
scratch2
scratch1
scratch3
)
;
Address
stubFrameReturnAddr
(
scratch3
RectifierFrameLayout
:
:
Size
(
)
+
BaselineStubFrameLayout
:
:
offsetOfReturnAddress
(
)
)
;
masm
.
loadPtr
(
stubFrameReturnAddr
scratch2
)
;
masm
.
storePtr
(
scratch2
lastProfilingCallSite
)
;
Address
stubFrameSavedFramePtr
(
scratch3
RectifierFrameLayout
:
:
Size
(
)
-
(
2
*
sizeof
(
void
*
)
)
)
;
masm
.
loadPtr
(
stubFrameSavedFramePtr
scratch2
)
;
masm
.
addPtr
(
Imm32
(
sizeof
(
void
*
)
)
scratch2
)
;
masm
.
storePtr
(
scratch2
lastProfilingFrame
)
;
masm
.
ret
(
)
;
}
masm
.
bind
(
&
handle_IonICCall
)
;
{
masm
.
Add
(
ARMRegister
(
scratch2
64
)
masm
.
GetStackPointer64
(
)
ARMRegister
(
scratch1
64
)
)
;
masm
.
syncStackPtr
(
)
;
masm
.
addPtr
(
Imm32
(
JitFrameLayout
:
:
Size
(
)
)
scratch2
)
;
masm
.
loadPtr
(
Address
(
scratch2
IonICCallFrameLayout
:
:
offsetOfDescriptor
(
)
)
scratch3
)
;
#
ifdef
DEBUG
masm
.
movePtr
(
scratch3
scratch1
)
;
masm
.
and32
(
Imm32
(
(
1
<
<
FRAMETYPE_BITS
)
-
1
)
scratch1
)
;
{
Label
checkOk
;
masm
.
branch32
(
Assembler
:
:
Equal
scratch1
Imm32
(
FrameType
:
:
IonJS
)
&
checkOk
)
;
masm
.
assumeUnreachable
(
"
IonICCall
frame
must
be
preceded
by
IonJS
frame
"
)
;
masm
.
bind
(
&
checkOk
)
;
}
#
endif
masm
.
rshiftPtr
(
Imm32
(
FRAMESIZE_SHIFT
)
scratch3
)
;
masm
.
loadPtr
(
Address
(
scratch2
IonICCallFrameLayout
:
:
offsetOfReturnAddress
(
)
)
scratch1
)
;
masm
.
storePtr
(
scratch1
lastProfilingCallSite
)
;
masm
.
addPtr
(
scratch2
scratch3
scratch1
)
;
masm
.
addPtr
(
Imm32
(
IonICCallFrameLayout
:
:
Size
(
)
)
scratch1
)
;
masm
.
storePtr
(
scratch1
lastProfilingFrame
)
;
masm
.
ret
(
)
;
}
masm
.
bind
(
&
handle_Entry
)
;
{
masm
.
movePtr
(
ImmPtr
(
nullptr
)
scratch1
)
;
masm
.
storePtr
(
scratch1
lastProfilingCallSite
)
;
masm
.
storePtr
(
scratch1
lastProfilingFrame
)
;
masm
.
ret
(
)
;
}
}
