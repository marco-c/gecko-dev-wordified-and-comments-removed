#
include
"
jit
/
ExecutableAllocator
.
h
"
#
include
"
jit
/
JitCompartment
.
h
"
#
include
"
js
/
MemoryMetrics
.
h
"
using
namespace
js
:
:
jit
;
ExecutablePool
:
:
~
ExecutablePool
(
)
{
MOZ_ASSERT
(
m_ionCodeBytes
=
=
0
)
;
MOZ_ASSERT
(
m_baselineCodeBytes
=
=
0
)
;
MOZ_ASSERT
(
m_regexpCodeBytes
=
=
0
)
;
MOZ_ASSERT
(
m_otherCodeBytes
=
=
0
)
;
MOZ_ASSERT
(
!
isMarked
(
)
)
;
m_allocator
-
>
releasePoolPages
(
this
)
;
}
void
ExecutablePool
:
:
release
(
bool
willDestroy
)
{
MOZ_ASSERT
(
m_refCount
!
=
0
)
;
MOZ_ASSERT_IF
(
willDestroy
m_refCount
=
=
1
)
;
if
(
-
-
m_refCount
=
=
0
)
js_delete
(
this
)
;
}
void
ExecutablePool
:
:
release
(
size_t
n
CodeKind
kind
)
{
switch
(
kind
)
{
case
CodeKind
:
:
Ion
:
m_ionCodeBytes
-
=
n
;
MOZ_ASSERT
(
m_ionCodeBytes
<
m_allocation
.
size
)
;
break
;
case
CodeKind
:
:
Baseline
:
m_baselineCodeBytes
-
=
n
;
MOZ_ASSERT
(
m_baselineCodeBytes
<
m_allocation
.
size
)
;
break
;
case
CodeKind
:
:
RegExp
:
m_regexpCodeBytes
-
=
n
;
MOZ_ASSERT
(
m_regexpCodeBytes
<
m_allocation
.
size
)
;
break
;
case
CodeKind
:
:
Other
:
m_otherCodeBytes
-
=
n
;
MOZ_ASSERT
(
m_otherCodeBytes
<
m_allocation
.
size
)
;
break
;
default
:
MOZ_CRASH
(
"
bad
code
kind
"
)
;
}
release
(
)
;
}
void
ExecutablePool
:
:
addRef
(
)
{
MOZ_ASSERT
(
m_refCount
)
;
+
+
m_refCount
;
MOZ_ASSERT
(
m_refCount
"
refcount
overflow
"
)
;
}
void
*
ExecutablePool
:
:
alloc
(
size_t
n
CodeKind
kind
)
{
MOZ_ASSERT
(
n
<
=
available
(
)
)
;
void
*
result
=
m_freePtr
;
m_freePtr
+
=
n
;
switch
(
kind
)
{
case
CodeKind
:
:
Ion
:
m_ionCodeBytes
+
=
n
;
break
;
case
CodeKind
:
:
Baseline
:
m_baselineCodeBytes
+
=
n
;
break
;
case
CodeKind
:
:
RegExp
:
m_regexpCodeBytes
+
=
n
;
break
;
case
CodeKind
:
:
Other
:
m_otherCodeBytes
+
=
n
;
break
;
default
:
MOZ_CRASH
(
"
bad
code
kind
"
)
;
}
return
result
;
}
size_t
ExecutablePool
:
:
available
(
)
const
{
MOZ_ASSERT
(
m_end
>
=
m_freePtr
)
;
return
m_end
-
m_freePtr
;
}
ExecutableAllocator
:
:
ExecutableAllocator
(
JSRuntime
*
rt
)
:
rt_
(
rt
)
{
MOZ_ASSERT
(
m_smallPools
.
empty
(
)
)
;
}
ExecutableAllocator
:
:
~
ExecutableAllocator
(
)
{
for
(
size_t
i
=
0
;
i
<
m_smallPools
.
length
(
)
;
i
+
+
)
m_smallPools
[
i
]
-
>
release
(
true
)
;
MOZ_ASSERT_IF
(
m_pools
.
initialized
(
)
&
&
rt_
-
>
gc
.
shutdownCollectedEverything
(
)
m_pools
.
empty
(
)
)
;
}
ExecutablePool
*
ExecutableAllocator
:
:
poolForSize
(
size_t
n
)
{
ExecutablePool
*
minPool
=
nullptr
;
for
(
size_t
i
=
0
;
i
<
m_smallPools
.
length
(
)
;
i
+
+
)
{
ExecutablePool
*
pool
=
m_smallPools
[
i
]
;
if
(
n
<
=
pool
-
>
available
(
)
&
&
(
!
minPool
|
|
pool
-
>
available
(
)
<
minPool
-
>
available
(
)
)
)
minPool
=
pool
;
}
if
(
minPool
)
{
minPool
-
>
addRef
(
)
;
return
minPool
;
}
if
(
n
>
ExecutableCodePageSize
)
return
createPool
(
n
)
;
ExecutablePool
*
pool
=
createPool
(
ExecutableCodePageSize
)
;
if
(
!
pool
)
return
nullptr
;
if
(
m_smallPools
.
length
(
)
<
maxSmallPools
)
{
if
(
m_smallPools
.
append
(
pool
)
)
pool
-
>
addRef
(
)
;
}
else
{
int
iMin
=
0
;
for
(
size_t
i
=
1
;
i
<
m_smallPools
.
length
(
)
;
i
+
+
)
{
if
(
m_smallPools
[
i
]
-
>
available
(
)
<
m_smallPools
[
iMin
]
-
>
available
(
)
)
iMin
=
i
;
}
ExecutablePool
*
minPool
=
m_smallPools
[
iMin
]
;
if
(
(
pool
-
>
available
(
)
-
n
)
>
minPool
-
>
available
(
)
)
{
minPool
-
>
release
(
)
;
m_smallPools
[
iMin
]
=
pool
;
pool
-
>
addRef
(
)
;
}
}
return
pool
;
}
size_t
ExecutableAllocator
:
:
roundUpAllocationSize
(
size_t
request
size_t
granularity
)
{
if
(
(
std
:
:
numeric_limits
<
size_t
>
:
:
max
(
)
-
granularity
)
<
=
request
)
return
OVERSIZE_ALLOCATION
;
size_t
size
=
request
+
(
granularity
-
1
)
;
size
=
size
&
~
(
granularity
-
1
)
;
MOZ_ASSERT
(
size
>
=
request
)
;
return
size
;
}
ExecutablePool
*
ExecutableAllocator
:
:
createPool
(
size_t
n
)
{
MOZ_ASSERT
(
rt_
-
>
jitRuntime
(
)
-
>
preventBackedgePatching
(
)
)
;
size_t
allocSize
=
roundUpAllocationSize
(
n
ExecutableCodePageSize
)
;
if
(
allocSize
=
=
OVERSIZE_ALLOCATION
)
return
nullptr
;
if
(
!
m_pools
.
initialized
(
)
&
&
!
m_pools
.
init
(
)
)
return
nullptr
;
ExecutablePool
:
:
Allocation
a
=
systemAlloc
(
allocSize
)
;
if
(
!
a
.
pages
)
return
nullptr
;
ExecutablePool
*
pool
=
js_new
<
ExecutablePool
>
(
this
a
)
;
if
(
!
pool
)
{
systemRelease
(
a
)
;
return
nullptr
;
}
if
(
!
m_pools
.
put
(
pool
)
)
{
js_delete
(
pool
)
;
return
nullptr
;
}
return
pool
;
}
void
*
ExecutableAllocator
:
:
alloc
(
JSContext
*
cx
size_t
n
ExecutablePool
*
*
poolp
CodeKind
type
)
{
JitRuntime
:
:
AutoPreventBackedgePatching
apbp
(
rt_
)
;
MOZ_ASSERT
(
roundUpAllocationSize
(
n
sizeof
(
void
*
)
)
=
=
n
)
;
if
(
n
=
=
OVERSIZE_ALLOCATION
)
{
*
poolp
=
nullptr
;
return
nullptr
;
}
*
poolp
=
poolForSize
(
n
)
;
if
(
!
*
poolp
)
return
nullptr
;
void
*
result
=
(
*
poolp
)
-
>
alloc
(
n
type
)
;
MOZ_ASSERT
(
result
)
;
cx
-
>
zone
(
)
-
>
updateJitCodeMallocBytes
(
n
)
;
return
result
;
}
void
ExecutableAllocator
:
:
releasePoolPages
(
ExecutablePool
*
pool
)
{
JitRuntime
:
:
AutoPreventBackedgePatching
apbp
(
rt_
)
;
MOZ_ASSERT
(
pool
-
>
m_allocation
.
pages
)
;
systemRelease
(
pool
-
>
m_allocation
)
;
MOZ_ASSERT
(
m_pools
.
initialized
(
)
)
;
if
(
auto
ptr
=
m_pools
.
lookup
(
pool
)
)
m_pools
.
remove
(
ptr
)
;
}
void
ExecutableAllocator
:
:
purge
(
)
{
JitRuntime
:
:
AutoPreventBackedgePatching
apbp
(
rt_
)
;
for
(
size_t
i
=
0
;
i
<
m_smallPools
.
length
(
)
;
i
+
+
)
m_smallPools
[
i
]
-
>
release
(
)
;
m_smallPools
.
clear
(
)
;
}
void
ExecutableAllocator
:
:
addSizeOfCode
(
JS
:
:
CodeSizes
*
sizes
)
const
{
if
(
m_pools
.
initialized
(
)
)
{
for
(
ExecPoolHashSet
:
:
Range
r
=
m_pools
.
all
(
)
;
!
r
.
empty
(
)
;
r
.
popFront
(
)
)
{
ExecutablePool
*
pool
=
r
.
front
(
)
;
sizes
-
>
ion
+
=
pool
-
>
m_ionCodeBytes
;
sizes
-
>
baseline
+
=
pool
-
>
m_baselineCodeBytes
;
sizes
-
>
regexp
+
=
pool
-
>
m_regexpCodeBytes
;
sizes
-
>
other
+
=
pool
-
>
m_otherCodeBytes
;
sizes
-
>
unused
+
=
pool
-
>
m_allocation
.
size
-
pool
-
>
m_ionCodeBytes
-
pool
-
>
m_baselineCodeBytes
-
pool
-
>
m_regexpCodeBytes
-
pool
-
>
m_otherCodeBytes
;
}
}
}
void
ExecutableAllocator
:
:
reprotectAll
(
ProtectionSetting
protection
)
{
if
(
!
m_pools
.
initialized
(
)
)
return
;
for
(
ExecPoolHashSet
:
:
Range
r
=
m_pools
.
all
(
)
;
!
r
.
empty
(
)
;
r
.
popFront
(
)
)
reprotectPool
(
rt_
r
.
front
(
)
protection
)
;
}
void
ExecutableAllocator
:
:
reprotectPool
(
JSRuntime
*
rt
ExecutablePool
*
pool
ProtectionSetting
protection
)
{
MOZ_ASSERT
(
rt
-
>
jitRuntime
(
)
-
>
preventBackedgePatching
(
)
|
|
rt
-
>
activeContext
(
)
-
>
handlingJitInterrupt
(
)
)
;
char
*
start
=
pool
-
>
m_allocation
.
pages
;
if
(
!
ReprotectRegion
(
start
pool
-
>
m_freePtr
-
start
protection
)
)
MOZ_CRASH
(
)
;
}
void
ExecutableAllocator
:
:
poisonCode
(
JSRuntime
*
rt
JitPoisonRangeVector
&
ranges
)
{
MOZ_ASSERT
(
CurrentThreadCanAccessRuntime
(
rt
)
)
;
JitRuntime
:
:
AutoPreventBackedgePatching
apbp
(
rt
)
;
#
ifdef
DEBUG
for
(
size_t
i
=
0
;
i
<
ranges
.
length
(
)
;
i
+
+
)
MOZ_ASSERT
(
!
ranges
[
i
]
.
pool
-
>
isMarked
(
)
)
;
#
endif
for
(
size_t
i
=
0
;
i
<
ranges
.
length
(
)
;
i
+
+
)
{
ExecutablePool
*
pool
=
ranges
[
i
]
.
pool
;
if
(
pool
-
>
m_refCount
=
=
1
)
{
continue
;
}
MOZ_ASSERT
(
pool
-
>
m_refCount
>
1
)
;
if
(
!
pool
-
>
isMarked
(
)
)
{
reprotectPool
(
rt
pool
ProtectionSetting
:
:
Writable
)
;
pool
-
>
mark
(
)
;
}
memset
(
ranges
[
i
]
.
start
JS_SWEPT_CODE_PATTERN
ranges
[
i
]
.
size
)
;
}
for
(
size_t
i
=
0
;
i
<
ranges
.
length
(
)
;
i
+
+
)
{
ExecutablePool
*
pool
=
ranges
[
i
]
.
pool
;
if
(
pool
-
>
isMarked
(
)
)
{
reprotectPool
(
rt
pool
ProtectionSetting
:
:
Executable
)
;
pool
-
>
unmark
(
)
;
}
pool
-
>
release
(
)
;
}
}
ExecutablePool
:
:
Allocation
ExecutableAllocator
:
:
systemAlloc
(
size_t
n
)
{
void
*
allocation
=
AllocateExecutableMemory
(
n
ProtectionSetting
:
:
Executable
)
;
ExecutablePool
:
:
Allocation
alloc
=
{
reinterpret_cast
<
char
*
>
(
allocation
)
n
}
;
return
alloc
;
}
void
ExecutableAllocator
:
:
systemRelease
(
const
ExecutablePool
:
:
Allocation
&
alloc
)
{
DeallocateExecutableMemory
(
alloc
.
pages
alloc
.
size
)
;
}
