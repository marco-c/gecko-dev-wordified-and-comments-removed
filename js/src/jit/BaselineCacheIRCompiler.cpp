#
include
"
jit
/
BaselineCacheIRCompiler
.
h
"
#
include
"
jit
/
CacheIR
.
h
"
#
include
"
jit
/
Linker
.
h
"
#
include
"
jit
/
SharedICHelpers
.
h
"
#
include
"
proxy
/
Proxy
.
h
"
#
include
"
jscntxtinlines
.
h
"
#
include
"
jit
/
MacroAssembler
-
inl
.
h
"
using
namespace
js
;
using
namespace
js
:
:
jit
;
using
mozilla
:
:
Maybe
;
class
AutoStubFrame
;
Address
CacheRegisterAllocator
:
:
addressOf
(
MacroAssembler
&
masm
BaselineFrameSlot
slot
)
const
{
uint32_t
offset
=
stackPushed_
+
ICStackValueOffset
+
slot
.
slot
(
)
*
sizeof
(
JS
:
:
Value
)
;
return
Address
(
masm
.
getStackPointer
(
)
offset
)
;
}
class
MOZ_RAII
BaselineCacheIRCompiler
:
public
CacheIRCompiler
{
#
ifdef
DEBUG
ICStubEngine
engine_
;
#
endif
uint32_t
stubDataOffset_
;
bool
inStubFrame_
;
bool
makesGCCalls_
;
MOZ_MUST_USE
bool
callVM
(
MacroAssembler
&
masm
const
VMFunction
&
fun
)
;
MOZ_MUST_USE
bool
callTypeUpdateIC
(
Register
obj
ValueOperand
val
Register
scratch
LiveGeneralRegisterSet
saveRegs
)
;
MOZ_MUST_USE
bool
emitStoreSlotShared
(
bool
isFixed
)
;
MOZ_MUST_USE
bool
emitAddAndStoreSlotShared
(
CacheOp
op
)
;
public
:
friend
class
AutoStubFrame
;
BaselineCacheIRCompiler
(
JSContext
*
cx
const
CacheIRWriter
&
writer
ICStubEngine
engine
uint32_t
stubDataOffset
)
:
CacheIRCompiler
(
cx
writer
Mode
:
:
Baseline
)
#
ifdef
DEBUG
engine_
(
engine
)
#
endif
stubDataOffset_
(
stubDataOffset
)
inStubFrame_
(
false
)
makesGCCalls_
(
false
)
{
}
MOZ_MUST_USE
bool
init
(
CacheKind
kind
)
;
JitCode
*
compile
(
)
;
bool
makesGCCalls
(
)
const
{
return
makesGCCalls_
;
}
private
:
#
define
DEFINE_OP
(
op
)
MOZ_MUST_USE
bool
emit
#
#
op
(
)
;
CACHE_IR_OPS
(
DEFINE_OP
)
#
undef
DEFINE_OP
Address
stubAddress
(
uint32_t
offset
)
const
{
return
Address
(
ICStubReg
stubDataOffset_
+
offset
)
;
}
}
;
#
define
DEFINE_SHARED_OP
(
op
)
\
bool
BaselineCacheIRCompiler
:
:
emit
#
#
op
(
)
{
return
CacheIRCompiler
:
:
emit
#
#
op
(
)
;
}
CACHE_IR_SHARED_OPS
(
DEFINE_SHARED_OP
)
#
undef
DEFINE_SHARED_OP
enum
class
CallCanGC
{
CanGC
CanNotGC
}
;
class
MOZ_RAII
AutoStubFrame
{
BaselineCacheIRCompiler
&
compiler
;
#
ifdef
DEBUG
uint32_t
framePushedAtEnterStubFrame_
;
#
endif
AutoStubFrame
(
const
AutoStubFrame
&
)
=
delete
;
void
operator
=
(
const
AutoStubFrame
&
)
=
delete
;
public
:
explicit
AutoStubFrame
(
BaselineCacheIRCompiler
&
compiler
)
:
compiler
(
compiler
)
#
ifdef
DEBUG
framePushedAtEnterStubFrame_
(
0
)
#
endif
{
}
void
enter
(
MacroAssembler
&
masm
Register
scratch
CallCanGC
canGC
=
CallCanGC
:
:
CanGC
)
{
MOZ_ASSERT
(
compiler
.
allocator
.
stackPushed
(
)
=
=
0
)
;
MOZ_ASSERT
(
compiler
.
engine_
=
=
ICStubEngine
:
:
Baseline
)
;
EmitBaselineEnterStubFrame
(
masm
scratch
)
;
#
ifdef
DEBUG
framePushedAtEnterStubFrame_
=
masm
.
framePushed
(
)
;
#
endif
MOZ_ASSERT
(
!
compiler
.
inStubFrame_
)
;
compiler
.
inStubFrame_
=
true
;
if
(
canGC
=
=
CallCanGC
:
:
CanGC
)
compiler
.
makesGCCalls_
=
true
;
}
void
leave
(
MacroAssembler
&
masm
bool
calledIntoIon
=
false
)
{
MOZ_ASSERT
(
compiler
.
inStubFrame_
)
;
compiler
.
inStubFrame_
=
false
;
#
ifdef
DEBUG
masm
.
setFramePushed
(
framePushedAtEnterStubFrame_
)
;
if
(
calledIntoIon
)
masm
.
adjustFrame
(
sizeof
(
intptr_t
)
)
;
#
endif
EmitBaselineLeaveStubFrame
(
masm
calledIntoIon
)
;
}
#
ifdef
DEBUG
~
AutoStubFrame
(
)
{
MOZ_ASSERT
(
!
compiler
.
inStubFrame_
)
;
}
#
endif
}
;
bool
BaselineCacheIRCompiler
:
:
callVM
(
MacroAssembler
&
masm
const
VMFunction
&
fun
)
{
MOZ_ASSERT
(
inStubFrame_
)
;
JitCode
*
code
=
cx_
-
>
runtime
(
)
-
>
jitRuntime
(
)
-
>
getVMWrapper
(
fun
)
;
if
(
!
code
)
return
false
;
MOZ_ASSERT
(
fun
.
expectTailCall
=
=
NonTailCall
)
;
MOZ_ASSERT
(
engine_
=
=
ICStubEngine
:
:
Baseline
)
;
EmitBaselineCallVM
(
code
masm
)
;
return
true
;
}
JitCode
*
BaselineCacheIRCompiler
:
:
compile
(
)
{
#
ifndef
JS_USE_LINK_REGISTER
masm
.
adjustFrame
(
sizeof
(
intptr_t
)
)
;
#
endif
#
ifdef
JS_CODEGEN_ARM
masm
.
setSecondScratchReg
(
BaselineSecondScratchReg
)
;
#
endif
do
{
switch
(
reader
.
readOp
(
)
)
{
#
define
DEFINE_OP
(
op
)
\
case
CacheOp
:
:
op
:
\
if
(
!
emit
#
#
op
(
)
)
\
return
nullptr
;
\
break
;
CACHE_IR_OPS
(
DEFINE_OP
)
#
undef
DEFINE_OP
default
:
MOZ_CRASH
(
"
Invalid
op
"
)
;
}
allocator
.
nextOp
(
)
;
}
while
(
reader
.
more
(
)
)
;
MOZ_ASSERT
(
!
inStubFrame_
)
;
masm
.
assumeUnreachable
(
"
Should
have
returned
from
IC
"
)
;
for
(
size_t
i
=
0
;
i
<
failurePaths
.
length
(
)
;
i
+
+
)
{
if
(
!
emitFailurePath
(
i
)
)
return
nullptr
;
EmitStubGuardFailure
(
masm
)
;
}
Linker
linker
(
masm
)
;
AutoFlushICache
afc
(
"
getStubCode
"
)
;
Rooted
<
JitCode
*
>
newStubCode
(
cx_
linker
.
newCode
<
NoGC
>
(
cx_
BASELINE_CODE
)
)
;
if
(
!
newStubCode
)
{
cx_
-
>
recoverFromOutOfMemory
(
)
;
return
nullptr
;
}
if
(
cx_
-
>
zone
(
)
-
>
needsIncrementalBarrier
(
)
)
newStubCode
-
>
togglePreBarriers
(
true
DontReprotect
)
;
return
newStubCode
;
}
bool
BaselineCacheIRCompiler
:
:
emitGuardShape
(
)
{
Register
obj
=
allocator
.
useRegister
(
masm
reader
.
objOperandId
(
)
)
;
AutoScratchRegister
scratch
(
allocator
masm
)
;
FailurePath
*
failure
;
if
(
!
addFailurePath
(
&
failure
)
)
return
false
;
Address
addr
(
stubAddress
(
reader
.
stubOffset
(
)
)
)
;
masm
.
loadPtr
(
addr
scratch
)
;
masm
.
branchTestObjShape
(
Assembler
:
:
NotEqual
obj
scratch
failure
-
>
label
(
)
)
;
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
emitGuardGroup
(
)
{
Register
obj
=
allocator
.
useRegister
(
masm
reader
.
objOperandId
(
)
)
;
AutoScratchRegister
scratch
(
allocator
masm
)
;
FailurePath
*
failure
;
if
(
!
addFailurePath
(
&
failure
)
)
return
false
;
Address
addr
(
stubAddress
(
reader
.
stubOffset
(
)
)
)
;
masm
.
loadPtr
(
addr
scratch
)
;
masm
.
branchTestObjGroup
(
Assembler
:
:
NotEqual
obj
scratch
failure
-
>
label
(
)
)
;
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
emitGuardProto
(
)
{
Register
obj
=
allocator
.
useRegister
(
masm
reader
.
objOperandId
(
)
)
;
AutoScratchRegister
scratch
(
allocator
masm
)
;
FailurePath
*
failure
;
if
(
!
addFailurePath
(
&
failure
)
)
return
false
;
Address
addr
(
stubAddress
(
reader
.
stubOffset
(
)
)
)
;
masm
.
loadObjProto
(
obj
scratch
)
;
masm
.
branchPtr
(
Assembler
:
:
NotEqual
addr
scratch
failure
-
>
label
(
)
)
;
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
emitGuardSpecificObject
(
)
{
Register
obj
=
allocator
.
useRegister
(
masm
reader
.
objOperandId
(
)
)
;
FailurePath
*
failure
;
if
(
!
addFailurePath
(
&
failure
)
)
return
false
;
Address
addr
(
stubAddress
(
reader
.
stubOffset
(
)
)
)
;
masm
.
branchPtr
(
Assembler
:
:
NotEqual
addr
obj
failure
-
>
label
(
)
)
;
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
emitGuardSpecificAtom
(
)
{
Register
str
=
allocator
.
useRegister
(
masm
reader
.
stringOperandId
(
)
)
;
AutoScratchRegister
scratch
(
allocator
masm
)
;
FailurePath
*
failure
;
if
(
!
addFailurePath
(
&
failure
)
)
return
false
;
Address
atomAddr
(
stubAddress
(
reader
.
stubOffset
(
)
)
)
;
Label
done
;
masm
.
branchPtr
(
Assembler
:
:
Equal
atomAddr
str
&
done
)
;
masm
.
branchTest32
(
Assembler
:
:
NonZero
Address
(
str
JSString
:
:
offsetOfFlags
(
)
)
Imm32
(
JSString
:
:
ATOM_BIT
)
failure
-
>
label
(
)
)
;
masm
.
loadPtr
(
atomAddr
scratch
)
;
masm
.
loadStringLength
(
scratch
scratch
)
;
masm
.
branch32
(
Assembler
:
:
NotEqual
Address
(
str
JSString
:
:
offsetOfLength
(
)
)
scratch
failure
-
>
label
(
)
)
;
LiveRegisterSet
volatileRegs
(
RegisterSet
:
:
Volatile
(
)
)
;
masm
.
PushRegsInMask
(
volatileRegs
)
;
masm
.
setupUnalignedABICall
(
scratch
)
;
masm
.
loadPtr
(
atomAddr
scratch
)
;
masm
.
passABIArg
(
scratch
)
;
masm
.
passABIArg
(
str
)
;
masm
.
callWithABI
(
JS_FUNC_TO_DATA_PTR
(
void
*
EqualStringsHelper
)
)
;
masm
.
mov
(
ReturnReg
scratch
)
;
LiveRegisterSet
ignore
;
ignore
.
add
(
scratch
)
;
masm
.
PopRegsInMaskIgnore
(
volatileRegs
ignore
)
;
masm
.
branchIfFalseBool
(
scratch
failure
-
>
label
(
)
)
;
masm
.
bind
(
&
done
)
;
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
emitGuardSpecificSymbol
(
)
{
Register
sym
=
allocator
.
useRegister
(
masm
reader
.
symbolOperandId
(
)
)
;
FailurePath
*
failure
;
if
(
!
addFailurePath
(
&
failure
)
)
return
false
;
Address
addr
(
stubAddress
(
reader
.
stubOffset
(
)
)
)
;
masm
.
branchPtr
(
Assembler
:
:
NotEqual
addr
sym
failure
-
>
label
(
)
)
;
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
emitLoadFixedSlotResult
(
)
{
AutoOutputRegister
output
(
*
this
)
;
Register
obj
=
allocator
.
useRegister
(
masm
reader
.
objOperandId
(
)
)
;
AutoScratchRegisterMaybeOutput
scratch
(
allocator
masm
output
)
;
masm
.
load32
(
stubAddress
(
reader
.
stubOffset
(
)
)
scratch
)
;
masm
.
loadValue
(
BaseIndex
(
obj
scratch
TimesOne
)
output
.
valueReg
(
)
)
;
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
emitLoadDynamicSlotResult
(
)
{
AutoOutputRegister
output
(
*
this
)
;
Register
obj
=
allocator
.
useRegister
(
masm
reader
.
objOperandId
(
)
)
;
AutoScratchRegisterMaybeOutput
scratch
(
allocator
masm
output
)
;
masm
.
load32
(
stubAddress
(
reader
.
stubOffset
(
)
)
scratch
)
;
masm
.
loadPtr
(
Address
(
obj
NativeObject
:
:
offsetOfSlots
(
)
)
obj
)
;
masm
.
loadValue
(
BaseIndex
(
obj
scratch
TimesOne
)
output
.
valueReg
(
)
)
;
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
emitCallScriptedGetterResult
(
)
{
MOZ_ASSERT
(
engine_
=
=
ICStubEngine
:
:
Baseline
)
;
Register
obj
=
allocator
.
useRegister
(
masm
reader
.
objOperandId
(
)
)
;
Address
getterAddr
(
stubAddress
(
reader
.
stubOffset
(
)
)
)
;
AutoScratchRegisterExcluding
code
(
allocator
masm
ArgumentsRectifierReg
)
;
AutoScratchRegister
callee
(
allocator
masm
)
;
AutoScratchRegister
scratch
(
allocator
masm
)
;
{
FailurePath
*
failure
;
if
(
!
addFailurePath
(
&
failure
)
)
return
false
;
masm
.
loadPtr
(
getterAddr
callee
)
;
masm
.
branchIfFunctionHasNoScript
(
callee
failure
-
>
label
(
)
)
;
masm
.
loadPtr
(
Address
(
callee
JSFunction
:
:
offsetOfNativeOrScript
(
)
)
code
)
;
masm
.
loadBaselineOrIonRaw
(
code
code
failure
-
>
label
(
)
)
;
}
allocator
.
discardStack
(
masm
)
;
AutoStubFrame
stubFrame
(
*
this
)
;
stubFrame
.
enter
(
masm
scratch
)
;
masm
.
alignJitStackBasedOnNArgs
(
0
)
;
masm
.
Push
(
TypedOrValueRegister
(
MIRType
:
:
Object
AnyRegister
(
obj
)
)
)
;
EmitBaselineCreateStubFrameDescriptor
(
masm
scratch
JitFrameLayout
:
:
Size
(
)
)
;
masm
.
Push
(
Imm32
(
0
)
)
;
masm
.
Push
(
callee
)
;
masm
.
Push
(
scratch
)
;
Label
noUnderflow
;
masm
.
load16ZeroExtend
(
Address
(
callee
JSFunction
:
:
offsetOfNargs
(
)
)
callee
)
;
masm
.
branch32
(
Assembler
:
:
Equal
callee
Imm32
(
0
)
&
noUnderflow
)
;
{
MOZ_ASSERT
(
ArgumentsRectifierReg
!
=
code
)
;
JitCode
*
argumentsRectifier
=
cx_
-
>
runtime
(
)
-
>
jitRuntime
(
)
-
>
getArgumentsRectifier
(
)
;
masm
.
movePtr
(
ImmGCPtr
(
argumentsRectifier
)
code
)
;
masm
.
loadPtr
(
Address
(
code
JitCode
:
:
offsetOfCode
(
)
)
code
)
;
masm
.
movePtr
(
ImmWord
(
0
)
ArgumentsRectifierReg
)
;
}
masm
.
bind
(
&
noUnderflow
)
;
masm
.
callJit
(
code
)
;
stubFrame
.
leave
(
masm
true
)
;
return
true
;
}
typedef
bool
(
*
CallNativeGetterFn
)
(
JSContext
*
HandleFunction
HandleObject
MutableHandleValue
)
;
static
const
VMFunction
CallNativeGetterInfo
=
FunctionInfo
<
CallNativeGetterFn
>
(
CallNativeGetter
"
CallNativeGetter
"
)
;
bool
BaselineCacheIRCompiler
:
:
emitCallNativeGetterResult
(
)
{
Register
obj
=
allocator
.
useRegister
(
masm
reader
.
objOperandId
(
)
)
;
Address
getterAddr
(
stubAddress
(
reader
.
stubOffset
(
)
)
)
;
AutoScratchRegister
scratch
(
allocator
masm
)
;
allocator
.
discardStack
(
masm
)
;
AutoStubFrame
stubFrame
(
*
this
)
;
stubFrame
.
enter
(
masm
scratch
)
;
masm
.
loadPtr
(
getterAddr
scratch
)
;
masm
.
Push
(
obj
)
;
masm
.
Push
(
scratch
)
;
if
(
!
callVM
(
masm
CallNativeGetterInfo
)
)
return
false
;
stubFrame
.
leave
(
masm
)
;
return
true
;
}
typedef
bool
(
*
ProxyGetPropertyFn
)
(
JSContext
*
HandleObject
HandleId
MutableHandleValue
)
;
static
const
VMFunction
ProxyGetPropertyInfo
=
FunctionInfo
<
ProxyGetPropertyFn
>
(
ProxyGetProperty
"
ProxyGetProperty
"
)
;
bool
BaselineCacheIRCompiler
:
:
emitCallProxyGetResult
(
)
{
Register
obj
=
allocator
.
useRegister
(
masm
reader
.
objOperandId
(
)
)
;
Address
idAddr
(
stubAddress
(
reader
.
stubOffset
(
)
)
)
;
AutoScratchRegister
scratch
(
allocator
masm
)
;
allocator
.
discardStack
(
masm
)
;
AutoStubFrame
stubFrame
(
*
this
)
;
stubFrame
.
enter
(
masm
scratch
)
;
masm
.
loadPtr
(
idAddr
scratch
)
;
masm
.
Push
(
scratch
)
;
masm
.
Push
(
obj
)
;
if
(
!
callVM
(
masm
ProxyGetPropertyInfo
)
)
return
false
;
stubFrame
.
leave
(
masm
)
;
return
true
;
}
typedef
bool
(
*
ProxyGetPropertyByValueFn
)
(
JSContext
*
HandleObject
HandleValue
MutableHandleValue
)
;
static
const
VMFunction
ProxyGetPropertyByValueInfo
=
FunctionInfo
<
ProxyGetPropertyByValueFn
>
(
ProxyGetPropertyByValue
"
ProxyGetPropertyByValue
"
)
;
bool
BaselineCacheIRCompiler
:
:
emitCallProxyGetByValueResult
(
)
{
Register
obj
=
allocator
.
useRegister
(
masm
reader
.
objOperandId
(
)
)
;
ValueOperand
idVal
=
allocator
.
useValueRegister
(
masm
reader
.
valOperandId
(
)
)
;
AutoScratchRegister
scratch
(
allocator
masm
)
;
allocator
.
discardStack
(
masm
)
;
AutoStubFrame
stubFrame
(
*
this
)
;
stubFrame
.
enter
(
masm
scratch
)
;
masm
.
Push
(
idVal
)
;
masm
.
Push
(
obj
)
;
if
(
!
callVM
(
masm
ProxyGetPropertyByValueInfo
)
)
return
false
;
stubFrame
.
leave
(
masm
)
;
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
emitLoadUnboxedPropertyResult
(
)
{
AutoOutputRegister
output
(
*
this
)
;
Register
obj
=
allocator
.
useRegister
(
masm
reader
.
objOperandId
(
)
)
;
AutoScratchRegisterMaybeOutput
scratch
(
allocator
masm
output
)
;
JSValueType
fieldType
=
reader
.
valueType
(
)
;
Address
fieldOffset
(
stubAddress
(
reader
.
stubOffset
(
)
)
)
;
masm
.
load32
(
fieldOffset
scratch
)
;
masm
.
loadUnboxedProperty
(
BaseIndex
(
obj
scratch
TimesOne
)
fieldType
output
)
;
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
emitGuardFrameHasNoArgumentsObject
(
)
{
FailurePath
*
failure
;
if
(
!
addFailurePath
(
&
failure
)
)
return
false
;
masm
.
branchTest32
(
Assembler
:
:
NonZero
Address
(
BaselineFrameReg
BaselineFrame
:
:
reverseOffsetOfFlags
(
)
)
Imm32
(
BaselineFrame
:
:
HAS_ARGS_OBJ
)
failure
-
>
label
(
)
)
;
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
emitLoadFrameCalleeResult
(
)
{
AutoOutputRegister
output
(
*
this
)
;
AutoScratchRegisterMaybeOutput
scratch
(
allocator
masm
output
)
;
Address
callee
(
BaselineFrameReg
BaselineFrame
:
:
offsetOfCalleeToken
(
)
)
;
masm
.
loadFunctionFromCalleeToken
(
callee
scratch
)
;
masm
.
tagValue
(
JSVAL_TYPE_OBJECT
scratch
output
.
valueReg
(
)
)
;
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
emitLoadFrameNumActualArgsResult
(
)
{
AutoOutputRegister
output
(
*
this
)
;
AutoScratchRegisterMaybeOutput
scratch
(
allocator
masm
output
)
;
Address
actualArgs
(
BaselineFrameReg
BaselineFrame
:
:
offsetOfNumActualArgs
(
)
)
;
masm
.
loadPtr
(
actualArgs
scratch
)
;
masm
.
tagValue
(
JSVAL_TYPE_INT32
scratch
output
.
valueReg
(
)
)
;
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
emitLoadTypedObjectResult
(
)
{
AutoOutputRegister
output
(
*
this
)
;
Register
obj
=
allocator
.
useRegister
(
masm
reader
.
objOperandId
(
)
)
;
AutoScratchRegister
scratch1
(
allocator
masm
)
;
AutoScratchRegister
scratch2
(
allocator
masm
)
;
TypedThingLayout
layout
=
reader
.
typedThingLayout
(
)
;
uint32_t
typeDescr
=
reader
.
typeDescrKey
(
)
;
Address
fieldOffset
(
stubAddress
(
reader
.
stubOffset
(
)
)
)
;
LoadTypedThingData
(
masm
layout
obj
scratch1
)
;
masm
.
load32
(
fieldOffset
scratch2
)
;
masm
.
addPtr
(
scratch2
scratch1
)
;
Address
fieldAddr
(
scratch1
0
)
;
emitLoadTypedObjectResultShared
(
fieldAddr
scratch2
layout
typeDescr
output
)
;
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
emitLoadFrameArgumentResult
(
)
{
AutoOutputRegister
output
(
*
this
)
;
Register
index
=
allocator
.
useRegister
(
masm
reader
.
int32OperandId
(
)
)
;
AutoScratchRegisterMaybeOutput
scratch
(
allocator
masm
output
)
;
FailurePath
*
failure
;
if
(
!
addFailurePath
(
&
failure
)
)
return
false
;
masm
.
loadPtr
(
Address
(
BaselineFrameReg
BaselineFrame
:
:
offsetOfNumActualArgs
(
)
)
scratch
)
;
masm
.
branch32
(
Assembler
:
:
AboveOrEqual
index
scratch
failure
-
>
label
(
)
)
;
masm
.
loadValue
(
BaseValueIndex
(
BaselineFrameReg
index
BaselineFrame
:
:
offsetOfArg
(
0
)
)
output
.
valueReg
(
)
)
;
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
emitLoadEnvironmentFixedSlotResult
(
)
{
AutoOutputRegister
output
(
*
this
)
;
Register
obj
=
allocator
.
useRegister
(
masm
reader
.
objOperandId
(
)
)
;
AutoScratchRegisterMaybeOutput
scratch
(
allocator
masm
output
)
;
FailurePath
*
failure
;
if
(
!
addFailurePath
(
&
failure
)
)
return
false
;
masm
.
load32
(
stubAddress
(
reader
.
stubOffset
(
)
)
scratch
)
;
BaseIndex
slot
(
obj
scratch
TimesOne
)
;
masm
.
branchTestMagic
(
Assembler
:
:
Equal
slot
failure
-
>
label
(
)
)
;
masm
.
loadValue
(
slot
output
.
valueReg
(
)
)
;
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
emitLoadEnvironmentDynamicSlotResult
(
)
{
AutoOutputRegister
output
(
*
this
)
;
Register
obj
=
allocator
.
useRegister
(
masm
reader
.
objOperandId
(
)
)
;
AutoScratchRegister
scratch
(
allocator
masm
)
;
AutoScratchRegisterMaybeOutput
scratch2
(
allocator
masm
output
)
;
FailurePath
*
failure
;
if
(
!
addFailurePath
(
&
failure
)
)
return
false
;
masm
.
load32
(
stubAddress
(
reader
.
stubOffset
(
)
)
scratch
)
;
masm
.
loadPtr
(
Address
(
obj
NativeObject
:
:
offsetOfSlots
(
)
)
scratch2
)
;
BaseIndex
slot
(
scratch2
scratch
TimesOne
)
;
masm
.
branchTestMagic
(
Assembler
:
:
Equal
slot
failure
-
>
label
(
)
)
;
masm
.
loadValue
(
slot
output
.
valueReg
(
)
)
;
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
callTypeUpdateIC
(
Register
obj
ValueOperand
val
Register
scratch
LiveGeneralRegisterSet
saveRegs
)
{
allocator
.
discardStack
(
masm
)
;
MOZ_ASSERT
(
val
=
=
R0
)
;
MOZ_ASSERT
(
scratch
=
=
R1
.
scratchReg
(
)
)
;
#
if
defined
(
JS_CODEGEN_X86
)
|
|
defined
(
JS_CODEGEN_X64
)
static
const
bool
CallClobbersTailReg
=
false
;
#
else
static
const
bool
CallClobbersTailReg
=
true
;
#
endif
if
(
CallClobbersTailReg
)
masm
.
push
(
ICTailCallReg
)
;
masm
.
push
(
ICStubReg
)
;
masm
.
loadPtr
(
Address
(
ICStubReg
ICUpdatedStub
:
:
offsetOfFirstUpdateStub
(
)
)
ICStubReg
)
;
masm
.
call
(
Address
(
ICStubReg
ICStub
:
:
offsetOfStubCode
(
)
)
)
;
masm
.
pop
(
ICStubReg
)
;
if
(
CallClobbersTailReg
)
masm
.
pop
(
ICTailCallReg
)
;
Label
done
;
masm
.
branch32
(
Assembler
:
:
Equal
scratch
Imm32
(
1
)
&
done
)
;
AutoStubFrame
stubFrame
(
*
this
)
;
stubFrame
.
enter
(
masm
scratch
CallCanGC
:
:
CanNotGC
)
;
masm
.
PushRegsInMask
(
saveRegs
)
;
masm
.
Push
(
val
)
;
masm
.
Push
(
TypedOrValueRegister
(
MIRType
:
:
Object
AnyRegister
(
obj
)
)
)
;
masm
.
Push
(
ICStubReg
)
;
masm
.
loadPtr
(
Address
(
BaselineFrameReg
0
)
scratch
)
;
masm
.
pushBaselineFramePtr
(
scratch
scratch
)
;
if
(
!
callVM
(
masm
DoTypeUpdateFallbackInfo
)
)
return
false
;
masm
.
PopRegsInMask
(
saveRegs
)
;
stubFrame
.
leave
(
masm
)
;
masm
.
bind
(
&
done
)
;
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
emitStoreSlotShared
(
bool
isFixed
)
{
ObjOperandId
objId
=
reader
.
objOperandId
(
)
;
Address
offsetAddr
=
stubAddress
(
reader
.
stubOffset
(
)
)
;
AutoScratchRegister
scratch1
(
allocator
masm
R1
.
scratchReg
(
)
)
;
ValueOperand
val
=
allocator
.
useFixedValueRegister
(
masm
reader
.
valOperandId
(
)
R0
)
;
Register
obj
=
allocator
.
useRegister
(
masm
objId
)
;
Maybe
<
AutoScratchRegister
>
scratch2
;
if
(
!
isFixed
)
scratch2
.
emplace
(
allocator
masm
)
;
LiveGeneralRegisterSet
saveRegs
;
saveRegs
.
add
(
obj
)
;
saveRegs
.
add
(
val
)
;
if
(
!
callTypeUpdateIC
(
obj
val
scratch1
saveRegs
)
)
return
false
;
masm
.
load32
(
offsetAddr
scratch1
)
;
if
(
isFixed
)
{
BaseIndex
slot
(
obj
scratch1
TimesOne
)
;
EmitPreBarrier
(
masm
slot
MIRType
:
:
Value
)
;
masm
.
storeValue
(
val
slot
)
;
}
else
{
masm
.
loadPtr
(
Address
(
obj
NativeObject
:
:
offsetOfSlots
(
)
)
scratch2
.
ref
(
)
)
;
BaseIndex
slot
(
scratch2
.
ref
(
)
scratch1
TimesOne
)
;
EmitPreBarrier
(
masm
slot
MIRType
:
:
Value
)
;
masm
.
storeValue
(
val
slot
)
;
}
BaselineEmitPostWriteBarrierSlot
(
masm
obj
val
scratch1
LiveGeneralRegisterSet
(
)
cx_
)
;
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
emitStoreFixedSlot
(
)
{
return
emitStoreSlotShared
(
true
)
;
}
bool
BaselineCacheIRCompiler
:
:
emitStoreDynamicSlot
(
)
{
return
emitStoreSlotShared
(
false
)
;
}
bool
BaselineCacheIRCompiler
:
:
emitAddAndStoreSlotShared
(
CacheOp
op
)
{
ObjOperandId
objId
=
reader
.
objOperandId
(
)
;
Address
offsetAddr
=
stubAddress
(
reader
.
stubOffset
(
)
)
;
AutoScratchRegister
scratch1
(
allocator
masm
R1
.
scratchReg
(
)
)
;
ValueOperand
val
=
allocator
.
useFixedValueRegister
(
masm
reader
.
valOperandId
(
)
R0
)
;
Register
obj
=
allocator
.
useRegister
(
masm
objId
)
;
AutoScratchRegister
scratch2
(
allocator
masm
)
;
bool
changeGroup
=
reader
.
readBool
(
)
;
Address
newGroupAddr
=
stubAddress
(
reader
.
stubOffset
(
)
)
;
Address
newShapeAddr
=
stubAddress
(
reader
.
stubOffset
(
)
)
;
if
(
op
=
=
CacheOp
:
:
AllocateAndStoreDynamicSlot
)
{
Address
numNewSlotsAddr
=
stubAddress
(
reader
.
stubOffset
(
)
)
;
FailurePath
*
failure
;
if
(
!
addFailurePath
(
&
failure
)
)
return
false
;
AllocatableRegisterSet
regs
(
RegisterSet
:
:
Volatile
(
)
)
;
LiveRegisterSet
save
(
regs
.
asLiveSet
(
)
)
;
masm
.
PushRegsInMask
(
save
)
;
masm
.
setupUnalignedABICall
(
scratch1
)
;
masm
.
loadJSContext
(
scratch1
)
;
masm
.
passABIArg
(
scratch1
)
;
masm
.
passABIArg
(
obj
)
;
masm
.
load32
(
numNewSlotsAddr
scratch2
)
;
masm
.
passABIArg
(
scratch2
)
;
masm
.
callWithABI
(
JS_FUNC_TO_DATA_PTR
(
void
*
NativeObject
:
:
growSlotsDontReportOOM
)
)
;
masm
.
mov
(
ReturnReg
scratch1
)
;
LiveRegisterSet
ignore
;
ignore
.
add
(
scratch1
)
;
masm
.
PopRegsInMaskIgnore
(
save
ignore
)
;
masm
.
branchIfFalseBool
(
scratch1
failure
-
>
label
(
)
)
;
}
LiveGeneralRegisterSet
saveRegs
;
saveRegs
.
add
(
obj
)
;
saveRegs
.
add
(
val
)
;
if
(
!
callTypeUpdateIC
(
obj
val
scratch1
saveRegs
)
)
return
false
;
if
(
changeGroup
)
{
Label
noGroupChange
;
masm
.
loadPtr
(
Address
(
obj
JSObject
:
:
offsetOfGroup
(
)
)
scratch1
)
;
masm
.
branchPtr
(
Assembler
:
:
Equal
Address
(
scratch1
ObjectGroup
:
:
offsetOfAddendum
(
)
)
ImmWord
(
0
)
&
noGroupChange
)
;
masm
.
loadPtr
(
newGroupAddr
scratch1
)
;
Address
groupAddr
(
obj
JSObject
:
:
offsetOfGroup
(
)
)
;
EmitPreBarrier
(
masm
groupAddr
MIRType
:
:
ObjectGroup
)
;
masm
.
storePtr
(
scratch1
groupAddr
)
;
masm
.
bind
(
&
noGroupChange
)
;
}
Address
shapeAddr
(
obj
ShapedObject
:
:
offsetOfShape
(
)
)
;
masm
.
loadPtr
(
newShapeAddr
scratch1
)
;
EmitPreBarrier
(
masm
shapeAddr
MIRType
:
:
Shape
)
;
masm
.
storePtr
(
scratch1
shapeAddr
)
;
masm
.
load32
(
offsetAddr
scratch1
)
;
if
(
op
=
=
CacheOp
:
:
AddAndStoreFixedSlot
)
{
BaseIndex
slot
(
obj
scratch1
TimesOne
)
;
masm
.
storeValue
(
val
slot
)
;
}
else
{
MOZ_ASSERT
(
op
=
=
CacheOp
:
:
AddAndStoreDynamicSlot
|
|
op
=
=
CacheOp
:
:
AllocateAndStoreDynamicSlot
)
;
masm
.
loadPtr
(
Address
(
obj
NativeObject
:
:
offsetOfSlots
(
)
)
scratch2
)
;
BaseIndex
slot
(
scratch2
scratch1
TimesOne
)
;
masm
.
storeValue
(
val
slot
)
;
}
BaselineEmitPostWriteBarrierSlot
(
masm
obj
val
scratch1
LiveGeneralRegisterSet
(
)
cx_
)
;
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
emitAddAndStoreFixedSlot
(
)
{
return
emitAddAndStoreSlotShared
(
CacheOp
:
:
AddAndStoreFixedSlot
)
;
}
bool
BaselineCacheIRCompiler
:
:
emitAddAndStoreDynamicSlot
(
)
{
return
emitAddAndStoreSlotShared
(
CacheOp
:
:
AddAndStoreDynamicSlot
)
;
}
bool
BaselineCacheIRCompiler
:
:
emitAllocateAndStoreDynamicSlot
(
)
{
return
emitAddAndStoreSlotShared
(
CacheOp
:
:
AllocateAndStoreDynamicSlot
)
;
}
bool
BaselineCacheIRCompiler
:
:
emitStoreUnboxedProperty
(
)
{
ObjOperandId
objId
=
reader
.
objOperandId
(
)
;
JSValueType
fieldType
=
reader
.
valueType
(
)
;
Address
offsetAddr
=
stubAddress
(
reader
.
stubOffset
(
)
)
;
AutoScratchRegister
scratch
(
allocator
masm
R1
.
scratchReg
(
)
)
;
ValueOperand
val
=
allocator
.
useFixedValueRegister
(
masm
reader
.
valOperandId
(
)
R0
)
;
Register
obj
=
allocator
.
useRegister
(
masm
objId
)
;
if
(
fieldType
=
=
JSVAL_TYPE_OBJECT
)
{
LiveGeneralRegisterSet
saveRegs
;
saveRegs
.
add
(
obj
)
;
saveRegs
.
add
(
val
)
;
if
(
!
callTypeUpdateIC
(
obj
val
scratch
saveRegs
)
)
return
false
;
}
masm
.
load32
(
offsetAddr
scratch
)
;
BaseIndex
fieldAddr
(
obj
scratch
TimesOne
)
;
EmitUnboxedPreBarrierForBaseline
(
masm
fieldAddr
fieldType
)
;
masm
.
storeUnboxedProperty
(
fieldAddr
fieldType
ConstantOrRegister
(
TypedOrValueRegister
(
val
)
)
nullptr
)
;
if
(
UnboxedTypeNeedsPostBarrier
(
fieldType
)
)
BaselineEmitPostWriteBarrierSlot
(
masm
obj
val
scratch
LiveGeneralRegisterSet
(
)
cx_
)
;
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
emitStoreTypedObjectReferenceProperty
(
)
{
ObjOperandId
objId
=
reader
.
objOperandId
(
)
;
Address
offsetAddr
=
stubAddress
(
reader
.
stubOffset
(
)
)
;
TypedThingLayout
layout
=
reader
.
typedThingLayout
(
)
;
ReferenceTypeDescr
:
:
Type
type
=
reader
.
referenceTypeDescrType
(
)
;
AutoScratchRegister
scratch1
(
allocator
masm
R1
.
scratchReg
(
)
)
;
ValueOperand
val
=
allocator
.
useFixedValueRegister
(
masm
reader
.
valOperandId
(
)
R0
)
;
Register
obj
=
allocator
.
useRegister
(
masm
objId
)
;
AutoScratchRegister
scratch2
(
allocator
masm
)
;
if
(
type
!
=
ReferenceTypeDescr
:
:
TYPE_STRING
)
{
LiveGeneralRegisterSet
saveRegs
;
saveRegs
.
add
(
obj
)
;
saveRegs
.
add
(
val
)
;
if
(
!
callTypeUpdateIC
(
obj
val
scratch1
saveRegs
)
)
return
false
;
}
LoadTypedThingData
(
masm
layout
obj
scratch1
)
;
masm
.
addPtr
(
offsetAddr
scratch1
)
;
Address
dest
(
scratch1
0
)
;
switch
(
type
)
{
case
ReferenceTypeDescr
:
:
TYPE_ANY
:
EmitPreBarrier
(
masm
dest
MIRType
:
:
Value
)
;
masm
.
storeValue
(
val
dest
)
;
break
;
case
ReferenceTypeDescr
:
:
TYPE_OBJECT
:
{
EmitPreBarrier
(
masm
dest
MIRType
:
:
Object
)
;
Label
isNull
done
;
masm
.
branchTestObject
(
Assembler
:
:
NotEqual
val
&
isNull
)
;
masm
.
unboxObject
(
val
scratch2
)
;
masm
.
storePtr
(
scratch2
dest
)
;
masm
.
jump
(
&
done
)
;
masm
.
bind
(
&
isNull
)
;
masm
.
storePtr
(
ImmWord
(
0
)
dest
)
;
masm
.
bind
(
&
done
)
;
break
;
}
case
ReferenceTypeDescr
:
:
TYPE_STRING
:
EmitPreBarrier
(
masm
dest
MIRType
:
:
String
)
;
masm
.
unboxString
(
val
scratch2
)
;
masm
.
storePtr
(
scratch2
dest
)
;
break
;
}
if
(
type
!
=
ReferenceTypeDescr
:
:
TYPE_STRING
)
BaselineEmitPostWriteBarrierSlot
(
masm
obj
val
scratch1
LiveGeneralRegisterSet
(
)
cx_
)
;
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
emitStoreTypedObjectScalarProperty
(
)
{
Register
obj
=
allocator
.
useRegister
(
masm
reader
.
objOperandId
(
)
)
;
Address
offsetAddr
=
stubAddress
(
reader
.
stubOffset
(
)
)
;
TypedThingLayout
layout
=
reader
.
typedThingLayout
(
)
;
Scalar
:
:
Type
type
=
reader
.
scalarType
(
)
;
ValueOperand
val
=
allocator
.
useValueRegister
(
masm
reader
.
valOperandId
(
)
)
;
AutoScratchRegister
scratch1
(
allocator
masm
)
;
AutoScratchRegister
scratch2
(
allocator
masm
)
;
FailurePath
*
failure
;
if
(
!
addFailurePath
(
&
failure
)
)
return
false
;
LoadTypedThingData
(
masm
layout
obj
scratch1
)
;
masm
.
addPtr
(
offsetAddr
scratch1
)
;
Address
dest
(
scratch1
0
)
;
BaselineStoreToTypedArray
(
cx_
masm
type
val
dest
scratch2
failure
-
>
label
(
)
failure
-
>
label
(
)
)
;
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
emitStoreDenseElement
(
)
{
ObjOperandId
objId
=
reader
.
objOperandId
(
)
;
Int32OperandId
indexId
=
reader
.
int32OperandId
(
)
;
AutoScratchRegister
scratch
(
allocator
masm
R1
.
scratchReg
(
)
)
;
ValueOperand
val
=
allocator
.
useFixedValueRegister
(
masm
reader
.
valOperandId
(
)
R0
)
;
Register
obj
=
allocator
.
useRegister
(
masm
objId
)
;
Register
index
=
allocator
.
useRegister
(
masm
indexId
)
;
FailurePath
*
failure
;
if
(
!
addFailurePath
(
&
failure
)
)
return
false
;
masm
.
loadPtr
(
Address
(
obj
NativeObject
:
:
offsetOfElements
(
)
)
scratch
)
;
Address
initLength
(
scratch
ObjectElements
:
:
offsetOfInitializedLength
(
)
)
;
masm
.
branch32
(
Assembler
:
:
BelowOrEqual
initLength
index
failure
-
>
label
(
)
)
;
BaseObjectElementIndex
element
(
scratch
index
)
;
masm
.
branchTestMagic
(
Assembler
:
:
Equal
element
failure
-
>
label
(
)
)
;
Label
noSpecialHandling
;
Address
elementsFlags
(
scratch
ObjectElements
:
:
offsetOfFlags
(
)
)
;
masm
.
branchTest32
(
Assembler
:
:
Zero
elementsFlags
Imm32
(
ObjectElements
:
:
CONVERT_DOUBLE_ELEMENTS
|
ObjectElements
:
:
COPY_ON_WRITE
|
ObjectElements
:
:
FROZEN
)
&
noSpecialHandling
)
;
masm
.
branchTest32
(
Assembler
:
:
NonZero
elementsFlags
Imm32
(
ObjectElements
:
:
COPY_ON_WRITE
|
ObjectElements
:
:
FROZEN
)
failure
-
>
label
(
)
)
;
if
(
cx_
-
>
runtime
(
)
-
>
jitSupportsFloatingPoint
)
{
masm
.
convertInt32ValueToDouble
(
val
)
;
}
else
{
masm
.
assumeUnreachable
(
"
There
shouldn
'
t
be
double
arrays
when
there
is
no
FP
support
.
"
)
;
}
masm
.
bind
(
&
noSpecialHandling
)
;
LiveGeneralRegisterSet
saveRegs
;
saveRegs
.
add
(
obj
)
;
saveRegs
.
add
(
index
)
;
saveRegs
.
add
(
val
)
;
if
(
!
callTypeUpdateIC
(
obj
val
scratch
saveRegs
)
)
return
false
;
masm
.
loadPtr
(
Address
(
obj
NativeObject
:
:
offsetOfElements
(
)
)
scratch
)
;
EmitPreBarrier
(
masm
element
MIRType
:
:
Value
)
;
masm
.
storeValue
(
val
element
)
;
BaselineEmitPostWriteBarrierSlot
(
masm
obj
val
scratch
LiveGeneralRegisterSet
(
)
cx_
)
;
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
emitStoreDenseElementHole
(
)
{
ObjOperandId
objId
=
reader
.
objOperandId
(
)
;
Int32OperandId
indexId
=
reader
.
int32OperandId
(
)
;
AutoScratchRegister
scratch
(
allocator
masm
R1
.
scratchReg
(
)
)
;
ValueOperand
val
=
allocator
.
useFixedValueRegister
(
masm
reader
.
valOperandId
(
)
R0
)
;
Register
obj
=
allocator
.
useRegister
(
masm
objId
)
;
Register
index
=
allocator
.
useRegister
(
masm
indexId
)
;
bool
handleAdd
=
reader
.
readBool
(
)
;
FailurePath
*
failure
;
if
(
!
addFailurePath
(
&
failure
)
)
return
false
;
masm
.
loadPtr
(
Address
(
obj
NativeObject
:
:
offsetOfElements
(
)
)
scratch
)
;
BaseObjectElementIndex
element
(
scratch
index
)
;
Address
initLength
(
scratch
ObjectElements
:
:
offsetOfInitializedLength
(
)
)
;
Address
elementsFlags
(
scratch
ObjectElements
:
:
offsetOfFlags
(
)
)
;
masm
.
branchTest32
(
Assembler
:
:
NonZero
elementsFlags
Imm32
(
ObjectElements
:
:
COPY_ON_WRITE
|
ObjectElements
:
:
FROZEN
)
failure
-
>
label
(
)
)
;
if
(
handleAdd
)
{
masm
.
branch32
(
Assembler
:
:
Below
initLength
index
failure
-
>
label
(
)
)
;
Address
capacity
(
scratch
ObjectElements
:
:
offsetOfCapacity
(
)
)
;
masm
.
branch32
(
Assembler
:
:
BelowOrEqual
capacity
index
failure
-
>
label
(
)
)
;
}
else
{
masm
.
branch32
(
Assembler
:
:
BelowOrEqual
initLength
index
failure
-
>
label
(
)
)
;
}
Label
noConversion
;
masm
.
branchTest32
(
Assembler
:
:
Zero
elementsFlags
Imm32
(
ObjectElements
:
:
CONVERT_DOUBLE_ELEMENTS
)
&
noConversion
)
;
if
(
cx_
-
>
runtime
(
)
-
>
jitSupportsFloatingPoint
)
{
masm
.
convertInt32ValueToDouble
(
val
)
;
}
else
{
masm
.
assumeUnreachable
(
"
There
shouldn
'
t
be
double
arrays
when
there
is
no
FP
support
.
"
)
;
}
masm
.
bind
(
&
noConversion
)
;
LiveGeneralRegisterSet
saveRegs
;
saveRegs
.
add
(
obj
)
;
saveRegs
.
add
(
index
)
;
saveRegs
.
add
(
val
)
;
if
(
!
callTypeUpdateIC
(
obj
val
scratch
saveRegs
)
)
return
false
;
masm
.
loadPtr
(
Address
(
obj
NativeObject
:
:
offsetOfElements
(
)
)
scratch
)
;
Label
doStore
;
if
(
handleAdd
)
{
Label
inBounds
;
masm
.
branch32
(
Assembler
:
:
NotEqual
initLength
index
&
inBounds
)
;
masm
.
add32
(
Imm32
(
1
)
initLength
)
;
Label
skipIncrementLength
;
Address
length
(
scratch
ObjectElements
:
:
offsetOfLength
(
)
)
;
masm
.
branch32
(
Assembler
:
:
Above
length
index
&
skipIncrementLength
)
;
masm
.
add32
(
Imm32
(
1
)
length
)
;
masm
.
bind
(
&
skipIncrementLength
)
;
masm
.
jump
(
&
doStore
)
;
masm
.
bind
(
&
inBounds
)
;
}
EmitPreBarrier
(
masm
element
MIRType
:
:
Value
)
;
masm
.
bind
(
&
doStore
)
;
masm
.
storeValue
(
val
element
)
;
BaselineEmitPostWriteBarrierSlot
(
masm
obj
val
scratch
LiveGeneralRegisterSet
(
)
cx_
)
;
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
emitStoreUnboxedArrayElement
(
)
{
ObjOperandId
objId
=
reader
.
objOperandId
(
)
;
Int32OperandId
indexId
=
reader
.
int32OperandId
(
)
;
AutoScratchRegister
scratch
(
allocator
masm
R1
.
scratchReg
(
)
)
;
ValueOperand
val
=
allocator
.
useFixedValueRegister
(
masm
reader
.
valOperandId
(
)
R0
)
;
JSValueType
elementType
=
reader
.
valueType
(
)
;
Register
obj
=
allocator
.
useRegister
(
masm
objId
)
;
Register
index
=
allocator
.
useRegister
(
masm
indexId
)
;
FailurePath
*
failure
;
if
(
!
addFailurePath
(
&
failure
)
)
return
false
;
Address
initLength
(
obj
UnboxedArrayObject
:
:
offsetOfCapacityIndexAndInitializedLength
(
)
)
;
masm
.
load32
(
initLength
scratch
)
;
masm
.
and32
(
Imm32
(
UnboxedArrayObject
:
:
InitializedLengthMask
)
scratch
)
;
masm
.
branch32
(
Assembler
:
:
BelowOrEqual
scratch
index
failure
-
>
label
(
)
)
;
if
(
elementType
=
=
JSVAL_TYPE_OBJECT
)
{
LiveGeneralRegisterSet
saveRegs
;
saveRegs
.
add
(
obj
)
;
saveRegs
.
add
(
index
)
;
saveRegs
.
add
(
val
)
;
if
(
!
callTypeUpdateIC
(
obj
val
scratch
saveRegs
)
)
return
false
;
}
masm
.
loadPtr
(
Address
(
obj
UnboxedArrayObject
:
:
offsetOfElements
(
)
)
scratch
)
;
BaseIndex
element
(
scratch
index
ScaleFromElemWidth
(
UnboxedTypeSize
(
elementType
)
)
)
;
EmitUnboxedPreBarrierForBaseline
(
masm
element
elementType
)
;
masm
.
storeUnboxedProperty
(
element
elementType
ConstantOrRegister
(
TypedOrValueRegister
(
val
)
)
nullptr
)
;
if
(
UnboxedTypeNeedsPostBarrier
(
elementType
)
)
BaselineEmitPostWriteBarrierSlot
(
masm
obj
val
scratch
LiveGeneralRegisterSet
(
)
cx_
)
;
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
emitStoreUnboxedArrayElementHole
(
)
{
ObjOperandId
objId
=
reader
.
objOperandId
(
)
;
Int32OperandId
indexId
=
reader
.
int32OperandId
(
)
;
AutoScratchRegister
scratch
(
allocator
masm
R1
.
scratchReg
(
)
)
;
ValueOperand
val
=
allocator
.
useFixedValueRegister
(
masm
reader
.
valOperandId
(
)
R0
)
;
JSValueType
elementType
=
reader
.
valueType
(
)
;
Register
obj
=
allocator
.
useRegister
(
masm
objId
)
;
Register
index
=
allocator
.
useRegister
(
masm
indexId
)
;
FailurePath
*
failure
;
if
(
!
addFailurePath
(
&
failure
)
)
return
false
;
Address
initLength
(
obj
UnboxedArrayObject
:
:
offsetOfCapacityIndexAndInitializedLength
(
)
)
;
masm
.
load32
(
initLength
scratch
)
;
masm
.
and32
(
Imm32
(
UnboxedArrayObject
:
:
InitializedLengthMask
)
scratch
)
;
masm
.
branch32
(
Assembler
:
:
Below
scratch
index
failure
-
>
label
(
)
)
;
masm
.
checkUnboxedArrayCapacity
(
obj
RegisterOrInt32Constant
(
index
)
scratch
failure
-
>
label
(
)
)
;
if
(
elementType
=
=
JSVAL_TYPE_OBJECT
)
{
LiveGeneralRegisterSet
saveRegs
;
saveRegs
.
add
(
obj
)
;
saveRegs
.
add
(
index
)
;
saveRegs
.
add
(
val
)
;
if
(
!
callTypeUpdateIC
(
obj
val
scratch
saveRegs
)
)
return
false
;
}
masm
.
loadPtr
(
Address
(
obj
UnboxedArrayObject
:
:
offsetOfElements
(
)
)
scratch
)
;
Label
inBounds
doStore
;
masm
.
load32
(
initLength
scratch
)
;
masm
.
and32
(
Imm32
(
UnboxedArrayObject
:
:
InitializedLengthMask
)
scratch
)
;
masm
.
branch32
(
Assembler
:
:
NotEqual
scratch
index
&
inBounds
)
;
masm
.
add32
(
Imm32
(
1
)
initLength
)
;
Address
length
(
obj
UnboxedArrayObject
:
:
offsetOfLength
(
)
)
;
Label
skipIncrementLength
;
masm
.
branch32
(
Assembler
:
:
Above
length
index
&
skipIncrementLength
)
;
masm
.
add32
(
Imm32
(
1
)
length
)
;
masm
.
bind
(
&
skipIncrementLength
)
;
masm
.
jump
(
&
doStore
)
;
masm
.
bind
(
&
inBounds
)
;
BaseIndex
element
(
scratch
index
ScaleFromElemWidth
(
UnboxedTypeSize
(
elementType
)
)
)
;
EmitUnboxedPreBarrierForBaseline
(
masm
element
elementType
)
;
masm
.
bind
(
&
doStore
)
;
masm
.
storeUnboxedProperty
(
element
elementType
ConstantOrRegister
(
TypedOrValueRegister
(
val
)
)
nullptr
)
;
if
(
UnboxedTypeNeedsPostBarrier
(
elementType
)
)
BaselineEmitPostWriteBarrierSlot
(
masm
obj
val
scratch
LiveGeneralRegisterSet
(
)
cx_
)
;
return
true
;
}
typedef
bool
(
*
CallNativeSetterFn
)
(
JSContext
*
HandleFunction
HandleObject
HandleValue
)
;
static
const
VMFunction
CallNativeSetterInfo
=
FunctionInfo
<
CallNativeSetterFn
>
(
CallNativeSetter
"
CallNativeSetter
"
)
;
bool
BaselineCacheIRCompiler
:
:
emitCallNativeSetter
(
)
{
Register
obj
=
allocator
.
useRegister
(
masm
reader
.
objOperandId
(
)
)
;
Address
setterAddr
(
stubAddress
(
reader
.
stubOffset
(
)
)
)
;
ValueOperand
val
=
allocator
.
useValueRegister
(
masm
reader
.
valOperandId
(
)
)
;
AutoScratchRegister
scratch
(
allocator
masm
)
;
allocator
.
discardStack
(
masm
)
;
AutoStubFrame
stubFrame
(
*
this
)
;
stubFrame
.
enter
(
masm
scratch
)
;
masm
.
loadPtr
(
setterAddr
scratch
)
;
masm
.
Push
(
val
)
;
masm
.
Push
(
obj
)
;
masm
.
Push
(
scratch
)
;
if
(
!
callVM
(
masm
CallNativeSetterInfo
)
)
return
false
;
stubFrame
.
leave
(
masm
)
;
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
emitCallScriptedSetter
(
)
{
AutoScratchRegisterExcluding
scratch1
(
allocator
masm
ArgumentsRectifierReg
)
;
AutoScratchRegister
scratch2
(
allocator
masm
)
;
Register
obj
=
allocator
.
useRegister
(
masm
reader
.
objOperandId
(
)
)
;
Address
setterAddr
(
stubAddress
(
reader
.
stubOffset
(
)
)
)
;
ValueOperand
val
=
allocator
.
useValueRegister
(
masm
reader
.
valOperandId
(
)
)
;
{
FailurePath
*
failure
;
if
(
!
addFailurePath
(
&
failure
)
)
return
false
;
masm
.
loadPtr
(
setterAddr
scratch1
)
;
masm
.
branchIfFunctionHasNoScript
(
scratch1
failure
-
>
label
(
)
)
;
masm
.
loadPtr
(
Address
(
scratch1
JSFunction
:
:
offsetOfNativeOrScript
(
)
)
scratch2
)
;
masm
.
loadBaselineOrIonRaw
(
scratch2
scratch2
failure
-
>
label
(
)
)
;
}
allocator
.
discardStack
(
masm
)
;
AutoStubFrame
stubFrame
(
*
this
)
;
stubFrame
.
enter
(
masm
scratch2
)
;
masm
.
alignJitStackBasedOnNArgs
(
1
)
;
masm
.
Push
(
val
)
;
masm
.
Push
(
TypedOrValueRegister
(
MIRType
:
:
Object
AnyRegister
(
obj
)
)
)
;
EmitBaselineCreateStubFrameDescriptor
(
masm
scratch2
JitFrameLayout
:
:
Size
(
)
)
;
masm
.
Push
(
Imm32
(
1
)
)
;
masm
.
Push
(
scratch1
)
;
masm
.
Push
(
scratch2
)
;
Label
noUnderflow
;
masm
.
load16ZeroExtend
(
Address
(
scratch1
JSFunction
:
:
offsetOfNargs
(
)
)
scratch2
)
;
masm
.
loadPtr
(
Address
(
scratch1
JSFunction
:
:
offsetOfNativeOrScript
(
)
)
scratch1
)
;
masm
.
loadBaselineOrIonRaw
(
scratch1
scratch1
nullptr
)
;
masm
.
branch32
(
Assembler
:
:
BelowOrEqual
scratch2
Imm32
(
1
)
&
noUnderflow
)
;
{
MOZ_ASSERT
(
ArgumentsRectifierReg
!
=
scratch1
)
;
JitCode
*
argumentsRectifier
=
cx_
-
>
runtime
(
)
-
>
jitRuntime
(
)
-
>
getArgumentsRectifier
(
)
;
masm
.
movePtr
(
ImmGCPtr
(
argumentsRectifier
)
scratch1
)
;
masm
.
loadPtr
(
Address
(
scratch1
JitCode
:
:
offsetOfCode
(
)
)
scratch1
)
;
masm
.
movePtr
(
ImmWord
(
1
)
ArgumentsRectifierReg
)
;
}
masm
.
bind
(
&
noUnderflow
)
;
masm
.
callJit
(
scratch1
)
;
stubFrame
.
leave
(
masm
true
)
;
return
true
;
}
typedef
bool
(
*
SetArrayLengthFn
)
(
JSContext
*
HandleObject
HandleValue
bool
)
;
static
const
VMFunction
SetArrayLengthInfo
=
FunctionInfo
<
SetArrayLengthFn
>
(
SetArrayLength
"
SetArrayLength
"
)
;
bool
BaselineCacheIRCompiler
:
:
emitCallSetArrayLength
(
)
{
Register
obj
=
allocator
.
useRegister
(
masm
reader
.
objOperandId
(
)
)
;
bool
strict
=
reader
.
readBool
(
)
;
ValueOperand
val
=
allocator
.
useValueRegister
(
masm
reader
.
valOperandId
(
)
)
;
AutoScratchRegister
scratch
(
allocator
masm
)
;
allocator
.
discardStack
(
masm
)
;
AutoStubFrame
stubFrame
(
*
this
)
;
stubFrame
.
enter
(
masm
scratch
)
;
masm
.
Push
(
Imm32
(
strict
)
)
;
masm
.
Push
(
val
)
;
masm
.
Push
(
obj
)
;
if
(
!
callVM
(
masm
SetArrayLengthInfo
)
)
return
false
;
stubFrame
.
leave
(
masm
)
;
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
emitTypeMonitorResult
(
)
{
allocator
.
discardStack
(
masm
)
;
EmitEnterTypeMonitorIC
(
masm
)
;
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
emitReturnFromIC
(
)
{
allocator
.
discardStack
(
masm
)
;
EmitReturnFromIC
(
masm
)
;
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
emitLoadObject
(
)
{
Register
reg
=
allocator
.
defineRegister
(
masm
reader
.
objOperandId
(
)
)
;
masm
.
loadPtr
(
stubAddress
(
reader
.
stubOffset
(
)
)
reg
)
;
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
emitGuardDOMExpandoMissingOrGuardShape
(
)
{
ValueOperand
val
=
allocator
.
useValueRegister
(
masm
reader
.
valOperandId
(
)
)
;
AutoScratchRegister
shapeScratch
(
allocator
masm
)
;
AutoScratchRegister
objScratch
(
allocator
masm
)
;
Address
shapeAddr
(
stubAddress
(
reader
.
stubOffset
(
)
)
)
;
FailurePath
*
failure
;
if
(
!
addFailurePath
(
&
failure
)
)
return
false
;
Label
done
;
masm
.
branchTestUndefined
(
Assembler
:
:
Equal
val
&
done
)
;
masm
.
debugAssertIsObject
(
val
)
;
masm
.
loadPtr
(
shapeAddr
shapeScratch
)
;
masm
.
unboxObject
(
val
objScratch
)
;
masm
.
branchTestObjShape
(
Assembler
:
:
NotEqual
objScratch
shapeScratch
failure
-
>
label
(
)
)
;
masm
.
bind
(
&
done
)
;
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
emitLoadDOMExpandoValueGuardGeneration
(
)
{
Register
obj
=
allocator
.
useRegister
(
masm
reader
.
objOperandId
(
)
)
;
Address
expandoAndGenerationAddr
(
stubAddress
(
reader
.
stubOffset
(
)
)
)
;
Address
generationAddr
(
stubAddress
(
reader
.
stubOffset
(
)
)
)
;
AutoScratchRegister
scratch
(
allocator
masm
)
;
ValueOperand
output
=
allocator
.
defineValueRegister
(
masm
reader
.
valOperandId
(
)
)
;
FailurePath
*
failure
;
if
(
!
addFailurePath
(
&
failure
)
)
return
false
;
masm
.
loadPtr
(
Address
(
obj
ProxyObject
:
:
offsetOfValues
(
)
)
scratch
)
;
Address
expandoAddr
(
scratch
ProxyObject
:
:
offsetOfExtraSlotInValues
(
GetDOMProxyExpandoSlot
(
)
)
)
;
masm
.
loadPtr
(
expandoAndGenerationAddr
output
.
scratchReg
(
)
)
;
masm
.
branchPrivatePtr
(
Assembler
:
:
NotEqual
expandoAddr
output
.
scratchReg
(
)
failure
-
>
label
(
)
)
;
masm
.
branch64
(
Assembler
:
:
NotEqual
Address
(
output
.
scratchReg
(
)
ExpandoAndGeneration
:
:
offsetOfGeneration
(
)
)
generationAddr
scratch
failure
-
>
label
(
)
)
;
masm
.
loadValue
(
Address
(
output
.
scratchReg
(
)
ExpandoAndGeneration
:
:
offsetOfExpando
(
)
)
output
)
;
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
init
(
CacheKind
kind
)
{
if
(
!
allocator
.
init
(
)
)
return
false
;
allowDoubleResult_
.
emplace
(
true
)
;
size_t
numInputs
=
writer_
.
numInputOperands
(
)
;
size_t
numInputsInRegs
=
std
:
:
min
(
numInputs
size_t
(
2
)
)
;
AllocatableGeneralRegisterSet
available
(
ICStubCompiler
:
:
availableGeneralRegs
(
numInputsInRegs
)
)
;
switch
(
kind
)
{
case
CacheKind
:
:
GetProp
:
MOZ_ASSERT
(
numInputs
=
=
1
)
;
allocator
.
initInputLocation
(
0
R0
)
;
break
;
case
CacheKind
:
:
GetElem
:
case
CacheKind
:
:
SetProp
:
case
CacheKind
:
:
In
:
MOZ_ASSERT
(
numInputs
=
=
2
)
;
allocator
.
initInputLocation
(
0
R0
)
;
allocator
.
initInputLocation
(
1
R1
)
;
break
;
case
CacheKind
:
:
SetElem
:
MOZ_ASSERT
(
numInputs
=
=
3
)
;
allocator
.
initInputLocation
(
0
R0
)
;
allocator
.
initInputLocation
(
1
R1
)
;
allocator
.
initInputLocation
(
2
BaselineFrameSlot
(
0
)
)
;
break
;
case
CacheKind
:
:
GetName
:
MOZ_ASSERT
(
numInputs
=
=
1
)
;
allocator
.
initInputLocation
(
0
R0
.
scratchReg
(
)
JSVAL_TYPE_OBJECT
)
;
#
if
defined
(
JS_NUNBOX32
)
available
.
add
(
R0
.
typeReg
(
)
)
;
#
endif
break
;
}
allocator
.
initAvailableRegs
(
available
)
;
outputUnchecked_
.
emplace
(
R0
)
;
return
true
;
}
static
const
size_t
MaxOptimizedCacheIRStubs
=
16
;
ICStub
*
jit
:
:
AttachBaselineCacheIRStub
(
JSContext
*
cx
const
CacheIRWriter
&
writer
CacheKind
kind
ICStubEngine
engine
JSScript
*
outerScript
ICFallbackStub
*
stub
)
{
AutoAssertNoPendingException
aanpe
(
cx
)
;
JS
:
:
AutoCheckCannotGC
nogc
;
if
(
writer
.
failed
(
)
)
return
nullptr
;
MOZ_ASSERT
(
stub
-
>
numOptimizedStubs
(
)
<
MaxOptimizedCacheIRStubs
)
;
enum
class
CacheIRStubKind
{
Regular
Monitored
Updated
}
;
uint32_t
stubDataOffset
;
CacheIRStubKind
stubKind
;
switch
(
kind
)
{
case
CacheKind
:
:
In
:
stubDataOffset
=
sizeof
(
ICCacheIR_Regular
)
;
stubKind
=
CacheIRStubKind
:
:
Regular
;
break
;
case
CacheKind
:
:
GetProp
:
case
CacheKind
:
:
GetElem
:
case
CacheKind
:
:
GetName
:
stubDataOffset
=
sizeof
(
ICCacheIR_Monitored
)
;
stubKind
=
CacheIRStubKind
:
:
Monitored
;
break
;
case
CacheKind
:
:
SetProp
:
case
CacheKind
:
:
SetElem
:
stubDataOffset
=
sizeof
(
ICCacheIR_Updated
)
;
stubKind
=
CacheIRStubKind
:
:
Updated
;
break
;
}
JitCompartment
*
jitCompartment
=
cx
-
>
compartment
(
)
-
>
jitCompartment
(
)
;
CacheIRStubInfo
*
stubInfo
;
CacheIRStubKey
:
:
Lookup
lookup
(
kind
engine
writer
.
codeStart
(
)
writer
.
codeLength
(
)
)
;
JitCode
*
code
=
jitCompartment
-
>
getCacheIRStubCode
(
lookup
&
stubInfo
)
;
if
(
!
code
)
{
JitContext
jctx
(
cx
nullptr
)
;
BaselineCacheIRCompiler
comp
(
cx
writer
engine
stubDataOffset
)
;
if
(
!
comp
.
init
(
kind
)
)
return
nullptr
;
code
=
comp
.
compile
(
)
;
if
(
!
code
)
return
nullptr
;
MOZ_ASSERT
(
!
stubInfo
)
;
stubInfo
=
CacheIRStubInfo
:
:
New
(
kind
engine
comp
.
makesGCCalls
(
)
stubDataOffset
writer
)
;
if
(
!
stubInfo
)
return
nullptr
;
CacheIRStubKey
key
(
stubInfo
)
;
if
(
!
jitCompartment
-
>
putCacheIRStubCode
(
lookup
key
code
)
)
return
nullptr
;
}
MOZ_ASSERT
(
code
)
;
MOZ_ASSERT
(
stubInfo
)
;
MOZ_ASSERT
(
stubInfo
-
>
stubDataSize
(
)
=
=
writer
.
stubDataSize
(
)
)
;
for
(
ICStubConstIterator
iter
=
stub
-
>
beginChainConst
(
)
;
!
iter
.
atEnd
(
)
;
iter
+
+
)
{
switch
(
stubKind
)
{
case
CacheIRStubKind
:
:
Regular
:
{
if
(
!
iter
-
>
isCacheIR_Regular
(
)
)
continue
;
auto
otherStub
=
iter
-
>
toCacheIR_Regular
(
)
;
if
(
otherStub
-
>
stubInfo
(
)
!
=
stubInfo
)
continue
;
if
(
!
writer
.
stubDataEqualsMaybeUpdate
(
otherStub
-
>
stubDataStart
(
)
)
)
continue
;
break
;
}
case
CacheIRStubKind
:
:
Monitored
:
{
if
(
!
iter
-
>
isCacheIR_Monitored
(
)
)
continue
;
auto
otherStub
=
iter
-
>
toCacheIR_Monitored
(
)
;
if
(
otherStub
-
>
stubInfo
(
)
!
=
stubInfo
)
continue
;
if
(
!
writer
.
stubDataEqualsMaybeUpdate
(
otherStub
-
>
stubDataStart
(
)
)
)
continue
;
break
;
}
case
CacheIRStubKind
:
:
Updated
:
{
if
(
!
iter
-
>
isCacheIR_Updated
(
)
)
continue
;
auto
otherStub
=
iter
-
>
toCacheIR_Updated
(
)
;
if
(
otherStub
-
>
stubInfo
(
)
!
=
stubInfo
)
continue
;
if
(
!
writer
.
stubDataEqualsMaybeUpdate
(
otherStub
-
>
stubDataStart
(
)
)
)
continue
;
break
;
}
}
return
nullptr
;
}
size_t
bytesNeeded
=
stubInfo
-
>
stubDataOffset
(
)
+
stubInfo
-
>
stubDataSize
(
)
;
ICStubSpace
*
stubSpace
=
ICStubCompiler
:
:
StubSpaceForStub
(
stubInfo
-
>
makesGCCalls
(
)
outerScript
engine
)
;
void
*
newStubMem
=
stubSpace
-
>
alloc
(
bytesNeeded
)
;
if
(
!
newStubMem
)
return
nullptr
;
switch
(
stubKind
)
{
case
CacheIRStubKind
:
:
Regular
:
{
auto
newStub
=
new
(
newStubMem
)
ICCacheIR_Regular
(
code
stubInfo
)
;
writer
.
copyStubData
(
newStub
-
>
stubDataStart
(
)
)
;
stub
-
>
addNewStub
(
newStub
)
;
return
newStub
;
}
case
CacheIRStubKind
:
:
Monitored
:
{
ICStub
*
monitorStub
=
stub
-
>
toMonitoredFallbackStub
(
)
-
>
fallbackMonitorStub
(
)
-
>
firstMonitorStub
(
)
;
auto
newStub
=
new
(
newStubMem
)
ICCacheIR_Monitored
(
code
monitorStub
stubInfo
)
;
writer
.
copyStubData
(
newStub
-
>
stubDataStart
(
)
)
;
stub
-
>
addNewStub
(
newStub
)
;
return
newStub
;
}
case
CacheIRStubKind
:
:
Updated
:
{
auto
newStub
=
new
(
newStubMem
)
ICCacheIR_Updated
(
code
stubInfo
)
;
if
(
!
newStub
-
>
initUpdatingChain
(
cx
stubSpace
)
)
{
cx
-
>
recoverFromOutOfMemory
(
)
;
return
nullptr
;
}
writer
.
copyStubData
(
newStub
-
>
stubDataStart
(
)
)
;
stub
-
>
addNewStub
(
newStub
)
;
return
newStub
;
}
}
MOZ_CRASH
(
"
Invalid
kind
"
)
;
}
uint8_t
*
ICCacheIR_Regular
:
:
stubDataStart
(
)
{
return
reinterpret_cast
<
uint8_t
*
>
(
this
)
+
stubInfo_
-
>
stubDataOffset
(
)
;
}
uint8_t
*
ICCacheIR_Monitored
:
:
stubDataStart
(
)
{
return
reinterpret_cast
<
uint8_t
*
>
(
this
)
+
stubInfo_
-
>
stubDataOffset
(
)
;
}
uint8_t
*
ICCacheIR_Updated
:
:
stubDataStart
(
)
{
return
reinterpret_cast
<
uint8_t
*
>
(
this
)
+
stubInfo_
-
>
stubDataOffset
(
)
;
}
ICCacheIR_Monitored
*
ICCacheIR_Monitored
:
:
Clone
(
JSContext
*
cx
ICStubSpace
*
space
ICStub
*
firstMonitorStub
ICCacheIR_Monitored
&
other
)
{
const
CacheIRStubInfo
*
stubInfo
=
other
.
stubInfo
(
)
;
MOZ_ASSERT
(
stubInfo
-
>
makesGCCalls
(
)
)
;
size_t
bytesNeeded
=
stubInfo
-
>
stubDataOffset
(
)
+
stubInfo
-
>
stubDataSize
(
)
;
void
*
newStub
=
space
-
>
alloc
(
bytesNeeded
)
;
if
(
!
newStub
)
return
nullptr
;
ICCacheIR_Monitored
*
res
=
new
(
newStub
)
ICCacheIR_Monitored
(
other
.
jitCode
(
)
firstMonitorStub
stubInfo
)
;
stubInfo
-
>
copyStubData
(
&
other
res
)
;
return
res
;
}
ICCacheIR_Updated
*
ICCacheIR_Updated
:
:
Clone
(
JSContext
*
cx
ICStubSpace
*
space
ICStub
*
firstMonitorStub
ICCacheIR_Updated
&
other
)
{
const
CacheIRStubInfo
*
stubInfo
=
other
.
stubInfo
(
)
;
MOZ_ASSERT
(
stubInfo
-
>
makesGCCalls
(
)
)
;
size_t
bytesNeeded
=
stubInfo
-
>
stubDataOffset
(
)
+
stubInfo
-
>
stubDataSize
(
)
;
void
*
newStub
=
space
-
>
alloc
(
bytesNeeded
)
;
if
(
!
newStub
)
return
nullptr
;
ICCacheIR_Updated
*
res
=
new
(
newStub
)
ICCacheIR_Updated
(
other
.
jitCode
(
)
stubInfo
)
;
res
-
>
updateStubGroup
(
)
=
other
.
updateStubGroup
(
)
;
res
-
>
updateStubId
(
)
=
other
.
updateStubId
(
)
;
stubInfo
-
>
copyStubData
(
&
other
res
)
;
return
res
;
}
