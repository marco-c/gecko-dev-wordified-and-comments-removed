#
include
"
jit
/
BaselineCacheIRCompiler
.
h
"
#
include
"
gc
/
GC
.
h
"
#
include
"
jit
/
CacheIR
.
h
"
#
include
"
jit
/
CacheIRCloner
.
h
"
#
include
"
jit
/
CacheIRWriter
.
h
"
#
include
"
jit
/
JitFrames
.
h
"
#
include
"
jit
/
JitRuntime
.
h
"
#
include
"
jit
/
JitZone
.
h
"
#
include
"
jit
/
Linker
.
h
"
#
include
"
jit
/
MoveEmitter
.
h
"
#
include
"
jit
/
RegExpStubConstants
.
h
"
#
include
"
jit
/
SharedICHelpers
.
h
"
#
include
"
jit
/
VMFunctions
.
h
"
#
include
"
js
/
experimental
/
JitInfo
.
h
"
#
include
"
js
/
friend
/
DOMProxy
.
h
"
#
include
"
proxy
/
DeadObjectProxy
.
h
"
#
include
"
proxy
/
Proxy
.
h
"
#
include
"
util
/
Unicode
.
h
"
#
include
"
vm
/
StaticStrings
.
h
"
#
include
"
jit
/
JitScript
-
inl
.
h
"
#
include
"
jit
/
MacroAssembler
-
inl
.
h
"
#
include
"
jit
/
SharedICHelpers
-
inl
.
h
"
#
include
"
jit
/
VMFunctionList
-
inl
.
h
"
#
include
"
vm
/
List
-
inl
.
h
"
using
namespace
js
;
using
namespace
js
:
:
jit
;
using
mozilla
:
:
Maybe
;
using
JS
:
:
ExpandoAndGeneration
;
namespace
js
{
namespace
jit
{
static
uint32_t
GetICStackValueOffset
(
)
{
uint32_t
offset
=
ICStackValueOffset
;
if
(
JitOptions
.
enableICFramePointers
)
{
#
ifdef
JS_USE_LINK_REGISTER
offset
+
=
2
*
sizeof
(
uintptr_t
)
;
#
else
offset
+
=
sizeof
(
uintptr_t
)
;
#
endif
}
return
offset
;
}
static
void
PushICFrameRegs
(
MacroAssembler
&
masm
)
{
MOZ_ASSERT
(
JitOptions
.
enableICFramePointers
)
;
#
ifdef
JS_USE_LINK_REGISTER
masm
.
pushReturnAddress
(
)
;
#
endif
masm
.
push
(
FramePointer
)
;
}
static
void
PopICFrameRegs
(
MacroAssembler
&
masm
)
{
MOZ_ASSERT
(
JitOptions
.
enableICFramePointers
)
;
masm
.
pop
(
FramePointer
)
;
#
ifdef
JS_USE_LINK_REGISTER
masm
.
popReturnAddress
(
)
;
#
endif
}
Address
CacheRegisterAllocator
:
:
addressOf
(
MacroAssembler
&
masm
BaselineFrameSlot
slot
)
const
{
uint32_t
offset
=
stackPushed_
+
GetICStackValueOffset
(
)
+
slot
.
slot
(
)
*
sizeof
(
JS
:
:
Value
)
;
return
Address
(
masm
.
getStackPointer
(
)
offset
)
;
}
BaseValueIndex
CacheRegisterAllocator
:
:
addressOf
(
MacroAssembler
&
masm
Register
argcReg
BaselineFrameSlot
slot
)
const
{
uint32_t
offset
=
stackPushed_
+
GetICStackValueOffset
(
)
+
slot
.
slot
(
)
*
sizeof
(
JS
:
:
Value
)
;
return
BaseValueIndex
(
masm
.
getStackPointer
(
)
argcReg
offset
)
;
}
BaselineCacheIRCompiler
:
:
BaselineCacheIRCompiler
(
JSContext
*
cx
TempAllocator
&
alloc
const
CacheIRWriter
&
writer
uint32_t
stubDataOffset
)
:
CacheIRCompiler
(
cx
alloc
writer
stubDataOffset
Mode
:
:
Baseline
StubFieldPolicy
:
:
Address
)
makesGCCalls_
(
false
)
{
}
AutoStubFrame
:
:
AutoStubFrame
(
BaselineCacheIRCompiler
&
compiler
)
:
compiler
(
compiler
)
#
ifdef
DEBUG
framePushedAtEnterStubFrame_
(
0
)
#
endif
{
}
void
AutoStubFrame
:
:
enter
(
MacroAssembler
&
masm
Register
scratch
)
{
MOZ_ASSERT
(
compiler
.
allocator
.
stackPushed
(
)
=
=
0
)
;
if
(
JitOptions
.
enableICFramePointers
)
{
PopICFrameRegs
(
masm
)
;
}
EmitBaselineEnterStubFrame
(
masm
scratch
)
;
#
ifdef
DEBUG
framePushedAtEnterStubFrame_
=
masm
.
framePushed
(
)
;
#
endif
MOZ_ASSERT
(
!
compiler
.
enteredStubFrame_
)
;
compiler
.
enteredStubFrame_
=
true
;
compiler
.
makesGCCalls_
=
true
;
}
void
AutoStubFrame
:
:
leave
(
MacroAssembler
&
masm
)
{
MOZ_ASSERT
(
compiler
.
enteredStubFrame_
)
;
compiler
.
enteredStubFrame_
=
false
;
#
ifdef
DEBUG
masm
.
setFramePushed
(
framePushedAtEnterStubFrame_
)
;
#
endif
EmitBaselineLeaveStubFrame
(
masm
)
;
if
(
JitOptions
.
enableICFramePointers
)
{
PushICFrameRegs
(
masm
)
;
}
}
void
AutoStubFrame
:
:
storeTracedValue
(
MacroAssembler
&
masm
ValueOperand
value
)
{
MOZ_ASSERT
(
compiler
.
localTracingSlots_
<
255
)
;
MOZ_ASSERT
(
masm
.
framePushed
(
)
-
framePushedAtEnterStubFrame_
=
=
compiler
.
localTracingSlots_
*
sizeof
(
Value
)
)
;
masm
.
Push
(
value
)
;
compiler
.
localTracingSlots_
+
+
;
}
void
AutoStubFrame
:
:
loadTracedValue
(
MacroAssembler
&
masm
uint8_t
slotIndex
ValueOperand
value
)
{
MOZ_ASSERT
(
slotIndex
<
=
compiler
.
localTracingSlots_
)
;
int32_t
offset
=
BaselineStubFrameLayout
:
:
LocallyTracedValueOffset
+
slotIndex
*
sizeof
(
Value
)
;
masm
.
loadValue
(
Address
(
FramePointer
-
offset
)
value
)
;
}
#
ifdef
DEBUG
AutoStubFrame
:
:
~
AutoStubFrame
(
)
{
MOZ_ASSERT
(
!
compiler
.
enteredStubFrame_
)
;
}
#
endif
}
}
bool
BaselineCacheIRCompiler
:
:
makesGCCalls
(
)
const
{
return
makesGCCalls_
;
}
Address
BaselineCacheIRCompiler
:
:
stubAddress
(
uint32_t
offset
)
const
{
return
Address
(
ICStubReg
stubDataOffset_
+
offset
)
;
}
template
<
typename
Fn
Fn
fn
>
void
BaselineCacheIRCompiler
:
:
callVM
(
MacroAssembler
&
masm
)
{
VMFunctionId
id
=
VMFunctionToId
<
Fn
fn
>
:
:
id
;
callVMInternal
(
masm
id
)
;
}
JitCode
*
BaselineCacheIRCompiler
:
:
compile
(
)
{
AutoCreatedBy
acb
(
masm
"
BaselineCacheIRCompiler
:
:
compile
"
)
;
#
ifndef
JS_USE_LINK_REGISTER
masm
.
adjustFrame
(
sizeof
(
intptr_t
)
)
;
#
endif
#
ifdef
JS_CODEGEN_ARM
AutoNonDefaultSecondScratchRegister
andssr
(
masm
BaselineSecondScratchReg
)
;
#
endif
if
(
JitOptions
.
enableICFramePointers
)
{
PushICFrameRegs
(
masm
)
;
masm
.
moveStackPtrTo
(
FramePointer
)
;
MOZ_ASSERT
(
baselineFrameReg
(
)
!
=
FramePointer
)
;
masm
.
loadPtr
(
Address
(
FramePointer
0
)
baselineFrameReg
(
)
)
;
}
Address
enteredCount
(
ICStubReg
ICCacheIRStub
:
:
offsetOfEnteredCount
(
)
)
;
masm
.
add32
(
Imm32
(
1
)
enteredCount
)
;
CacheIRReader
reader
(
writer_
)
;
do
{
CacheOp
op
=
reader
.
readOp
(
)
;
perfSpewer_
.
recordInstruction
(
masm
op
)
;
switch
(
op
)
{
#
define
DEFINE_OP
(
op
.
.
.
)
\
case
CacheOp
:
:
op
:
\
if
(
!
emit
#
#
op
(
reader
)
)
return
nullptr
;
\
break
;
CACHE_IR_OPS
(
DEFINE_OP
)
#
undef
DEFINE_OP
default
:
MOZ_CRASH
(
"
Invalid
op
"
)
;
}
allocator
.
nextOp
(
)
;
}
while
(
reader
.
more
(
)
)
;
MOZ_ASSERT
(
!
enteredStubFrame_
)
;
masm
.
assumeUnreachable
(
"
Should
have
returned
from
IC
"
)
;
for
(
size_t
i
=
0
;
i
<
failurePaths
.
length
(
)
;
i
+
+
)
{
if
(
!
emitFailurePath
(
i
)
)
{
return
nullptr
;
}
if
(
JitOptions
.
enableICFramePointers
)
{
PopICFrameRegs
(
masm
)
;
}
EmitStubGuardFailure
(
masm
)
;
}
Linker
linker
(
masm
)
;
Rooted
<
JitCode
*
>
newStubCode
(
cx_
linker
.
newCode
(
cx_
CodeKind
:
:
Baseline
)
)
;
if
(
!
newStubCode
)
{
cx_
-
>
recoverFromOutOfMemory
(
)
;
return
nullptr
;
}
newStubCode
-
>
setLocalTracingSlots
(
localTracingSlots_
)
;
return
newStubCode
;
}
bool
BaselineCacheIRCompiler
:
:
emitGuardShape
(
ObjOperandId
objId
uint32_t
shapeOffset
)
{
JitSpew
(
JitSpew_Codegen
"
%
s
"
__FUNCTION__
)
;
Register
obj
=
allocator
.
useRegister
(
masm
objId
)
;
AutoScratchRegister
scratch1
(
allocator
masm
)
;
bool
needSpectreMitigations
=
objectGuardNeedsSpectreMitigations
(
objId
)
;
Maybe
<
AutoScratchRegister
>
maybeScratch2
;
if
(
needSpectreMitigations
)
{
maybeScratch2
.
emplace
(
allocator
masm
)
;
}
FailurePath
*
failure
;
if
(
!
addFailurePath
(
&
failure
)
)
{
return
false
;
}
Address
addr
(
stubAddress
(
shapeOffset
)
)
;
masm
.
loadPtr
(
addr
scratch1
)
;
if
(
needSpectreMitigations
)
{
masm
.
branchTestObjShape
(
Assembler
:
:
NotEqual
obj
scratch1
*
maybeScratch2
obj
failure
-
>
label
(
)
)
;
}
else
{
masm
.
branchTestObjShapeNoSpectreMitigations
(
Assembler
:
:
NotEqual
obj
scratch1
failure
-
>
label
(
)
)
;
}
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
emitGuardProto
(
ObjOperandId
objId
uint32_t
protoOffset
)
{
JitSpew
(
JitSpew_Codegen
"
%
s
"
__FUNCTION__
)
;
Register
obj
=
allocator
.
useRegister
(
masm
objId
)
;
AutoScratchRegister
scratch
(
allocator
masm
)
;
FailurePath
*
failure
;
if
(
!
addFailurePath
(
&
failure
)
)
{
return
false
;
}
Address
addr
(
stubAddress
(
protoOffset
)
)
;
masm
.
loadObjProto
(
obj
scratch
)
;
masm
.
branchPtr
(
Assembler
:
:
NotEqual
addr
scratch
failure
-
>
label
(
)
)
;
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
emitGuardCompartment
(
ObjOperandId
objId
uint32_t
globalOffset
uint32_t
compartmentOffset
)
{
JitSpew
(
JitSpew_Codegen
"
%
s
"
__FUNCTION__
)
;
Register
obj
=
allocator
.
useRegister
(
masm
objId
)
;
AutoScratchRegister
scratch
(
allocator
masm
)
;
FailurePath
*
failure
;
if
(
!
addFailurePath
(
&
failure
)
)
{
return
false
;
}
Address
globalWrapper
(
stubAddress
(
globalOffset
)
)
;
masm
.
loadPtr
(
globalWrapper
scratch
)
;
Address
handlerAddr
(
scratch
ProxyObject
:
:
offsetOfHandler
(
)
)
;
masm
.
branchPtr
(
Assembler
:
:
Equal
handlerAddr
ImmPtr
(
&
DeadObjectProxy
:
:
singleton
)
failure
-
>
label
(
)
)
;
Address
addr
(
stubAddress
(
compartmentOffset
)
)
;
masm
.
branchTestObjCompartment
(
Assembler
:
:
NotEqual
obj
addr
scratch
failure
-
>
label
(
)
)
;
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
emitGuardAnyClass
(
ObjOperandId
objId
uint32_t
claspOffset
)
{
JitSpew
(
JitSpew_Codegen
"
%
s
"
__FUNCTION__
)
;
Register
obj
=
allocator
.
useRegister
(
masm
objId
)
;
AutoScratchRegister
scratch
(
allocator
masm
)
;
FailurePath
*
failure
;
if
(
!
addFailurePath
(
&
failure
)
)
{
return
false
;
}
Address
testAddr
(
stubAddress
(
claspOffset
)
)
;
if
(
objectGuardNeedsSpectreMitigations
(
objId
)
)
{
masm
.
branchTestObjClass
(
Assembler
:
:
NotEqual
obj
testAddr
scratch
obj
failure
-
>
label
(
)
)
;
}
else
{
masm
.
branchTestObjClassNoSpectreMitigations
(
Assembler
:
:
NotEqual
obj
testAddr
scratch
failure
-
>
label
(
)
)
;
}
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
emitGuardHasProxyHandler
(
ObjOperandId
objId
uint32_t
handlerOffset
)
{
JitSpew
(
JitSpew_Codegen
"
%
s
"
__FUNCTION__
)
;
Register
obj
=
allocator
.
useRegister
(
masm
objId
)
;
AutoScratchRegister
scratch
(
allocator
masm
)
;
FailurePath
*
failure
;
if
(
!
addFailurePath
(
&
failure
)
)
{
return
false
;
}
Address
testAddr
(
stubAddress
(
handlerOffset
)
)
;
masm
.
loadPtr
(
testAddr
scratch
)
;
Address
handlerAddr
(
obj
ProxyObject
:
:
offsetOfHandler
(
)
)
;
masm
.
branchPtr
(
Assembler
:
:
NotEqual
handlerAddr
scratch
failure
-
>
label
(
)
)
;
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
emitGuardSpecificObject
(
ObjOperandId
objId
uint32_t
expectedOffset
)
{
JitSpew
(
JitSpew_Codegen
"
%
s
"
__FUNCTION__
)
;
Register
obj
=
allocator
.
useRegister
(
masm
objId
)
;
FailurePath
*
failure
;
if
(
!
addFailurePath
(
&
failure
)
)
{
return
false
;
}
Address
addr
(
stubAddress
(
expectedOffset
)
)
;
masm
.
branchPtr
(
Assembler
:
:
NotEqual
addr
obj
failure
-
>
label
(
)
)
;
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
emitGuardSpecificFunction
(
ObjOperandId
objId
uint32_t
expectedOffset
uint32_t
nargsAndFlagsOffset
)
{
return
emitGuardSpecificObject
(
objId
expectedOffset
)
;
}
bool
BaselineCacheIRCompiler
:
:
emitGuardFunctionScript
(
ObjOperandId
funId
uint32_t
expectedOffset
uint32_t
nargsAndFlagsOffset
)
{
JitSpew
(
JitSpew_Codegen
"
%
s
"
__FUNCTION__
)
;
Register
fun
=
allocator
.
useRegister
(
masm
funId
)
;
AutoScratchRegister
scratch
(
allocator
masm
)
;
FailurePath
*
failure
;
if
(
!
addFailurePath
(
&
failure
)
)
{
return
false
;
}
Address
addr
(
stubAddress
(
expectedOffset
)
)
;
masm
.
loadPrivate
(
Address
(
fun
JSFunction
:
:
offsetOfJitInfoOrScript
(
)
)
scratch
)
;
masm
.
branchPtr
(
Assembler
:
:
NotEqual
addr
scratch
failure
-
>
label
(
)
)
;
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
emitGuardSpecificAtom
(
StringOperandId
strId
uint32_t
expectedOffset
)
{
JitSpew
(
JitSpew_Codegen
"
%
s
"
__FUNCTION__
)
;
Register
str
=
allocator
.
useRegister
(
masm
strId
)
;
AutoScratchRegister
scratch
(
allocator
masm
)
;
FailurePath
*
failure
;
if
(
!
addFailurePath
(
&
failure
)
)
{
return
false
;
}
Address
atomAddr
(
stubAddress
(
expectedOffset
)
)
;
Label
done
notCachedAtom
;
masm
.
branchPtr
(
Assembler
:
:
Equal
atomAddr
str
&
done
)
;
masm
.
branchTest32
(
Assembler
:
:
NonZero
Address
(
str
JSString
:
:
offsetOfFlags
(
)
)
Imm32
(
JSString
:
:
ATOM_BIT
)
failure
-
>
label
(
)
)
;
masm
.
tryFastAtomize
(
str
scratch
scratch
&
notCachedAtom
)
;
masm
.
branchPtr
(
Assembler
:
:
Equal
atomAddr
scratch
&
done
)
;
masm
.
jump
(
failure
-
>
label
(
)
)
;
masm
.
bind
(
&
notCachedAtom
)
;
masm
.
loadPtr
(
atomAddr
scratch
)
;
masm
.
loadStringLength
(
scratch
scratch
)
;
masm
.
branch32
(
Assembler
:
:
NotEqual
Address
(
str
JSString
:
:
offsetOfLength
(
)
)
scratch
failure
-
>
label
(
)
)
;
LiveRegisterSet
volatileRegs
=
liveVolatileRegs
(
)
;
masm
.
PushRegsInMask
(
volatileRegs
)
;
using
Fn
=
bool
(
*
)
(
JSString
*
str1
JSString
*
str2
)
;
masm
.
setupUnalignedABICall
(
scratch
)
;
masm
.
loadPtr
(
atomAddr
scratch
)
;
masm
.
passABIArg
(
scratch
)
;
masm
.
passABIArg
(
str
)
;
masm
.
callWithABI
<
Fn
EqualStringsHelperPure
>
(
)
;
masm
.
storeCallPointerResult
(
scratch
)
;
LiveRegisterSet
ignore
;
ignore
.
add
(
scratch
)
;
masm
.
PopRegsInMaskIgnore
(
volatileRegs
ignore
)
;
masm
.
branchIfFalseBool
(
scratch
failure
-
>
label
(
)
)
;
masm
.
bind
(
&
done
)
;
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
emitGuardSpecificSymbol
(
SymbolOperandId
symId
uint32_t
expectedOffset
)
{
JitSpew
(
JitSpew_Codegen
"
%
s
"
__FUNCTION__
)
;
Register
sym
=
allocator
.
useRegister
(
masm
symId
)
;
FailurePath
*
failure
;
if
(
!
addFailurePath
(
&
failure
)
)
{
return
false
;
}
Address
addr
(
stubAddress
(
expectedOffset
)
)
;
masm
.
branchPtr
(
Assembler
:
:
NotEqual
addr
sym
failure
-
>
label
(
)
)
;
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
emitLoadValueResult
(
uint32_t
valOffset
)
{
JitSpew
(
JitSpew_Codegen
"
%
s
"
__FUNCTION__
)
;
AutoOutputRegister
output
(
*
this
)
;
masm
.
loadValue
(
stubAddress
(
valOffset
)
output
.
valueReg
(
)
)
;
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
emitLoadFixedSlotResult
(
ObjOperandId
objId
uint32_t
offsetOffset
)
{
JitSpew
(
JitSpew_Codegen
"
%
s
"
__FUNCTION__
)
;
AutoOutputRegister
output
(
*
this
)
;
Register
obj
=
allocator
.
useRegister
(
masm
objId
)
;
AutoScratchRegisterMaybeOutput
scratch
(
allocator
masm
output
)
;
masm
.
load32
(
stubAddress
(
offsetOffset
)
scratch
)
;
masm
.
loadValue
(
BaseIndex
(
obj
scratch
TimesOne
)
output
.
valueReg
(
)
)
;
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
emitLoadFixedSlotTypedResult
(
ObjOperandId
objId
uint32_t
offsetOffset
ValueType
)
{
return
emitLoadFixedSlotResult
(
objId
offsetOffset
)
;
}
bool
BaselineCacheIRCompiler
:
:
emitLoadDynamicSlotResult
(
ObjOperandId
objId
uint32_t
offsetOffset
)
{
JitSpew
(
JitSpew_Codegen
"
%
s
"
__FUNCTION__
)
;
AutoOutputRegister
output
(
*
this
)
;
Register
obj
=
allocator
.
useRegister
(
masm
objId
)
;
AutoScratchRegisterMaybeOutput
scratch
(
allocator
masm
output
)
;
AutoScratchRegister
scratch2
(
allocator
masm
)
;
masm
.
load32
(
stubAddress
(
offsetOffset
)
scratch
)
;
masm
.
loadPtr
(
Address
(
obj
NativeObject
:
:
offsetOfSlots
(
)
)
scratch2
)
;
masm
.
loadValue
(
BaseIndex
(
scratch2
scratch
TimesOne
)
output
.
valueReg
(
)
)
;
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
emitCallScriptedGetterShared
(
ValOperandId
receiverId
uint32_t
getterOffset
bool
sameRealm
uint32_t
nargsAndFlagsOffset
Maybe
<
uint32_t
>
icScriptOffset
)
{
ValueOperand
receiver
=
allocator
.
useValueRegister
(
masm
receiverId
)
;
Address
getterAddr
(
stubAddress
(
getterOffset
)
)
;
AutoScratchRegister
code
(
allocator
masm
)
;
AutoScratchRegister
callee
(
allocator
masm
)
;
AutoScratchRegister
scratch
(
allocator
masm
)
;
bool
isInlined
=
icScriptOffset
.
isSome
(
)
;
masm
.
loadPtr
(
getterAddr
callee
)
;
if
(
isInlined
)
{
FailurePath
*
failure
;
if
(
!
addFailurePath
(
&
failure
)
)
{
return
false
;
}
masm
.
loadBaselineJitCodeRaw
(
callee
code
failure
-
>
label
(
)
)
;
}
else
{
masm
.
loadJitCodeRaw
(
callee
code
)
;
}
allocator
.
discardStack
(
masm
)
;
AutoStubFrame
stubFrame
(
*
this
)
;
stubFrame
.
enter
(
masm
scratch
)
;
if
(
!
sameRealm
)
{
masm
.
switchToObjectRealm
(
callee
scratch
)
;
}
masm
.
alignJitStackBasedOnNArgs
(
0
false
)
;
masm
.
Push
(
receiver
)
;
if
(
isInlined
)
{
Address
icScriptAddr
(
stubAddress
(
*
icScriptOffset
)
)
;
masm
.
loadPtr
(
icScriptAddr
scratch
)
;
masm
.
storeICScriptInJSContext
(
scratch
)
;
}
masm
.
Push
(
callee
)
;
masm
.
PushFrameDescriptorForJitCall
(
FrameType
:
:
BaselineStub
0
)
;
Label
noUnderflow
;
masm
.
loadFunctionArgCount
(
callee
callee
)
;
masm
.
branch32
(
Assembler
:
:
Equal
callee
Imm32
(
0
)
&
noUnderflow
)
;
ArgumentsRectifierKind
kind
=
isInlined
?
ArgumentsRectifierKind
:
:
TrialInlining
:
ArgumentsRectifierKind
:
:
Normal
;
TrampolinePtr
argumentsRectifier
=
cx_
-
>
runtime
(
)
-
>
jitRuntime
(
)
-
>
getArgumentsRectifier
(
kind
)
;
masm
.
movePtr
(
argumentsRectifier
code
)
;
masm
.
bind
(
&
noUnderflow
)
;
masm
.
callJit
(
code
)
;
stubFrame
.
leave
(
masm
)
;
if
(
!
sameRealm
)
{
masm
.
switchToBaselineFrameRealm
(
R1
.
scratchReg
(
)
)
;
}
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
emitCallScriptedGetterResult
(
ValOperandId
receiverId
uint32_t
getterOffset
bool
sameRealm
uint32_t
nargsAndFlagsOffset
)
{
JitSpew
(
JitSpew_Codegen
"
%
s
"
__FUNCTION__
)
;
Maybe
<
uint32_t
>
icScriptOffset
=
mozilla
:
:
Nothing
(
)
;
return
emitCallScriptedGetterShared
(
receiverId
getterOffset
sameRealm
nargsAndFlagsOffset
icScriptOffset
)
;
}
bool
BaselineCacheIRCompiler
:
:
emitCallInlinedGetterResult
(
ValOperandId
receiverId
uint32_t
getterOffset
uint32_t
icScriptOffset
bool
sameRealm
uint32_t
nargsAndFlagsOffset
)
{
JitSpew
(
JitSpew_Codegen
"
%
s
"
__FUNCTION__
)
;
return
emitCallScriptedGetterShared
(
receiverId
getterOffset
sameRealm
nargsAndFlagsOffset
mozilla
:
:
Some
(
icScriptOffset
)
)
;
}
bool
BaselineCacheIRCompiler
:
:
emitCallNativeGetterResult
(
ValOperandId
receiverId
uint32_t
getterOffset
bool
sameRealm
uint32_t
nargsAndFlagsOffset
)
{
JitSpew
(
JitSpew_Codegen
"
%
s
"
__FUNCTION__
)
;
ValueOperand
receiver
=
allocator
.
useValueRegister
(
masm
receiverId
)
;
Address
getterAddr
(
stubAddress
(
getterOffset
)
)
;
AutoScratchRegister
scratch
(
allocator
masm
)
;
allocator
.
discardStack
(
masm
)
;
AutoStubFrame
stubFrame
(
*
this
)
;
stubFrame
.
enter
(
masm
scratch
)
;
masm
.
loadPtr
(
getterAddr
scratch
)
;
masm
.
Push
(
receiver
)
;
masm
.
Push
(
scratch
)
;
using
Fn
=
bool
(
*
)
(
JSContext
*
HandleFunction
HandleValue
MutableHandleValue
)
;
callVM
<
Fn
CallNativeGetter
>
(
masm
)
;
stubFrame
.
leave
(
masm
)
;
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
emitCallDOMGetterResult
(
ObjOperandId
objId
uint32_t
jitInfoOffset
)
{
JitSpew
(
JitSpew_Codegen
"
%
s
"
__FUNCTION__
)
;
Register
obj
=
allocator
.
useRegister
(
masm
objId
)
;
Address
jitInfoAddr
(
stubAddress
(
jitInfoOffset
)
)
;
AutoScratchRegister
scratch
(
allocator
masm
)
;
allocator
.
discardStack
(
masm
)
;
AutoStubFrame
stubFrame
(
*
this
)
;
stubFrame
.
enter
(
masm
scratch
)
;
masm
.
loadPtr
(
jitInfoAddr
scratch
)
;
masm
.
Push
(
obj
)
;
masm
.
Push
(
scratch
)
;
using
Fn
=
bool
(
*
)
(
JSContext
*
const
JSJitInfo
*
HandleObject
MutableHandleValue
)
;
callVM
<
Fn
CallDOMGetter
>
(
masm
)
;
stubFrame
.
leave
(
masm
)
;
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
emitProxyGetResult
(
ObjOperandId
objId
uint32_t
idOffset
)
{
JitSpew
(
JitSpew_Codegen
"
%
s
"
__FUNCTION__
)
;
Register
obj
=
allocator
.
useRegister
(
masm
objId
)
;
Address
idAddr
(
stubAddress
(
idOffset
)
)
;
AutoScratchRegister
scratch
(
allocator
masm
)
;
allocator
.
discardStack
(
masm
)
;
AutoStubFrame
stubFrame
(
*
this
)
;
stubFrame
.
enter
(
masm
scratch
)
;
masm
.
loadPtr
(
idAddr
scratch
)
;
masm
.
Push
(
scratch
)
;
masm
.
Push
(
obj
)
;
using
Fn
=
bool
(
*
)
(
JSContext
*
HandleObject
HandleId
MutableHandleValue
)
;
callVM
<
Fn
ProxyGetProperty
>
(
masm
)
;
stubFrame
.
leave
(
masm
)
;
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
emitFrameIsConstructingResult
(
)
{
JitSpew
(
JitSpew_Codegen
"
%
s
"
__FUNCTION__
)
;
AutoOutputRegister
output
(
*
this
)
;
Register
outputScratch
=
output
.
valueReg
(
)
.
scratchReg
(
)
;
Address
tokenAddr
(
baselineFrameReg
(
)
JitFrameLayout
:
:
offsetOfCalleeToken
(
)
)
;
masm
.
loadPtr
(
tokenAddr
outputScratch
)
;
static_assert
(
CalleeToken_Function
=
=
0x0
)
;
static_assert
(
CalleeToken_FunctionConstructing
=
=
0x1
)
;
masm
.
andPtr
(
Imm32
(
0x1
)
outputScratch
)
;
masm
.
tagValue
(
JSVAL_TYPE_BOOLEAN
outputScratch
output
.
valueReg
(
)
)
;
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
emitLoadConstantStringResult
(
uint32_t
strOffset
)
{
JitSpew
(
JitSpew_Codegen
"
%
s
"
__FUNCTION__
)
;
AutoOutputRegister
output
(
*
this
)
;
AutoScratchRegisterMaybeOutput
scratch
(
allocator
masm
output
)
;
masm
.
loadPtr
(
stubAddress
(
strOffset
)
scratch
)
;
masm
.
tagValue
(
JSVAL_TYPE_STRING
scratch
output
.
valueReg
(
)
)
;
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
emitCompareStringResult
(
JSOp
op
StringOperandId
lhsId
StringOperandId
rhsId
)
{
JitSpew
(
JitSpew_Codegen
"
%
s
"
__FUNCTION__
)
;
AutoOutputRegister
output
(
*
this
)
;
Register
left
=
allocator
.
useRegister
(
masm
lhsId
)
;
Register
right
=
allocator
.
useRegister
(
masm
rhsId
)
;
AutoScratchRegisterMaybeOutput
scratch
(
allocator
masm
output
)
;
allocator
.
discardStack
(
masm
)
;
Label
slow
done
;
masm
.
compareStrings
(
op
left
right
scratch
&
slow
)
;
masm
.
jump
(
&
done
)
;
masm
.
bind
(
&
slow
)
;
{
AutoStubFrame
stubFrame
(
*
this
)
;
stubFrame
.
enter
(
masm
scratch
)
;
if
(
op
=
=
JSOp
:
:
Le
|
|
op
=
=
JSOp
:
:
Gt
)
{
masm
.
Push
(
left
)
;
masm
.
Push
(
right
)
;
}
else
{
masm
.
Push
(
right
)
;
masm
.
Push
(
left
)
;
}
using
Fn
=
bool
(
*
)
(
JSContext
*
HandleString
HandleString
bool
*
)
;
if
(
op
=
=
JSOp
:
:
Eq
|
|
op
=
=
JSOp
:
:
StrictEq
)
{
callVM
<
Fn
jit
:
:
StringsEqual
<
EqualityKind
:
:
Equal
>
>
(
masm
)
;
}
else
if
(
op
=
=
JSOp
:
:
Ne
|
|
op
=
=
JSOp
:
:
StrictNe
)
{
callVM
<
Fn
jit
:
:
StringsEqual
<
EqualityKind
:
:
NotEqual
>
>
(
masm
)
;
}
else
if
(
op
=
=
JSOp
:
:
Lt
|
|
op
=
=
JSOp
:
:
Gt
)
{
callVM
<
Fn
jit
:
:
StringsCompare
<
ComparisonKind
:
:
LessThan
>
>
(
masm
)
;
}
else
{
MOZ_ASSERT
(
op
=
=
JSOp
:
:
Le
|
|
op
=
=
JSOp
:
:
Ge
)
;
callVM
<
Fn
jit
:
:
StringsCompare
<
ComparisonKind
:
:
GreaterThanOrEqual
>
>
(
masm
)
;
}
stubFrame
.
leave
(
masm
)
;
masm
.
storeCallPointerResult
(
scratch
)
;
}
masm
.
bind
(
&
done
)
;
masm
.
tagValue
(
JSVAL_TYPE_BOOLEAN
scratch
output
.
valueReg
(
)
)
;
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
emitSameValueResult
(
ValOperandId
lhsId
ValOperandId
rhsId
)
{
JitSpew
(
JitSpew_Codegen
"
%
s
"
__FUNCTION__
)
;
AutoOutputRegister
output
(
*
this
)
;
AutoScratchRegister
scratch
(
allocator
masm
)
;
ValueOperand
lhs
=
allocator
.
useValueRegister
(
masm
lhsId
)
;
#
ifdef
JS_CODEGEN_X86
allocator
.
copyToScratchValueRegister
(
masm
rhsId
output
.
valueReg
(
)
)
;
ValueOperand
rhs
=
output
.
valueReg
(
)
;
#
else
ValueOperand
rhs
=
allocator
.
useValueRegister
(
masm
rhsId
)
;
#
endif
allocator
.
discardStack
(
masm
)
;
Label
done
;
Label
call
;
masm
.
branch64
(
Assembler
:
:
NotEqual
lhs
.
toRegister64
(
)
rhs
.
toRegister64
(
)
&
call
)
;
masm
.
moveValue
(
BooleanValue
(
true
)
output
.
valueReg
(
)
)
;
masm
.
jump
(
&
done
)
;
{
masm
.
bind
(
&
call
)
;
AutoStubFrame
stubFrame
(
*
this
)
;
stubFrame
.
enter
(
masm
scratch
)
;
masm
.
pushValue
(
lhs
)
;
masm
.
pushValue
(
rhs
)
;
using
Fn
=
bool
(
*
)
(
JSContext
*
HandleValue
HandleValue
bool
*
)
;
callVM
<
Fn
SameValue
>
(
masm
)
;
stubFrame
.
leave
(
masm
)
;
masm
.
tagValue
(
JSVAL_TYPE_BOOLEAN
ReturnReg
output
.
valueReg
(
)
)
;
}
masm
.
bind
(
&
done
)
;
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
emitStoreSlotShared
(
bool
isFixed
ObjOperandId
objId
uint32_t
offsetOffset
ValOperandId
rhsId
)
{
Register
obj
=
allocator
.
useRegister
(
masm
objId
)
;
ValueOperand
val
=
allocator
.
useValueRegister
(
masm
rhsId
)
;
AutoScratchRegister
scratch1
(
allocator
masm
)
;
Maybe
<
AutoScratchRegister
>
scratch2
;
if
(
!
isFixed
)
{
scratch2
.
emplace
(
allocator
masm
)
;
}
Address
offsetAddr
=
stubAddress
(
offsetOffset
)
;
masm
.
load32
(
offsetAddr
scratch1
)
;
if
(
isFixed
)
{
BaseIndex
slot
(
obj
scratch1
TimesOne
)
;
EmitPreBarrier
(
masm
slot
MIRType
:
:
Value
)
;
masm
.
storeValue
(
val
slot
)
;
}
else
{
masm
.
loadPtr
(
Address
(
obj
NativeObject
:
:
offsetOfSlots
(
)
)
scratch2
.
ref
(
)
)
;
BaseIndex
slot
(
scratch2
.
ref
(
)
scratch1
TimesOne
)
;
EmitPreBarrier
(
masm
slot
MIRType
:
:
Value
)
;
masm
.
storeValue
(
val
slot
)
;
}
emitPostBarrierSlot
(
obj
val
scratch1
)
;
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
emitStoreFixedSlot
(
ObjOperandId
objId
uint32_t
offsetOffset
ValOperandId
rhsId
)
{
JitSpew
(
JitSpew_Codegen
"
%
s
"
__FUNCTION__
)
;
return
emitStoreSlotShared
(
true
objId
offsetOffset
rhsId
)
;
}
bool
BaselineCacheIRCompiler
:
:
emitStoreDynamicSlot
(
ObjOperandId
objId
uint32_t
offsetOffset
ValOperandId
rhsId
)
{
JitSpew
(
JitSpew_Codegen
"
%
s
"
__FUNCTION__
)
;
return
emitStoreSlotShared
(
false
objId
offsetOffset
rhsId
)
;
}
bool
BaselineCacheIRCompiler
:
:
emitAddAndStoreSlotShared
(
CacheOp
op
ObjOperandId
objId
uint32_t
offsetOffset
ValOperandId
rhsId
uint32_t
newShapeOffset
Maybe
<
uint32_t
>
numNewSlotsOffset
)
{
Register
obj
=
allocator
.
useRegister
(
masm
objId
)
;
ValueOperand
val
=
allocator
.
useValueRegister
(
masm
rhsId
)
;
AutoScratchRegister
scratch1
(
allocator
masm
)
;
AutoScratchRegister
scratch2
(
allocator
masm
)
;
Address
newShapeAddr
=
stubAddress
(
newShapeOffset
)
;
Address
offsetAddr
=
stubAddress
(
offsetOffset
)
;
if
(
op
=
=
CacheOp
:
:
AllocateAndStoreDynamicSlot
)
{
Address
numNewSlotsAddr
=
stubAddress
(
*
numNewSlotsOffset
)
;
FailurePath
*
failure
;
if
(
!
addFailurePath
(
&
failure
)
)
{
return
false
;
}
LiveRegisterSet
save
=
liveVolatileRegs
(
)
;
masm
.
PushRegsInMask
(
save
)
;
using
Fn
=
bool
(
*
)
(
JSContext
*
cx
NativeObject
*
obj
uint32_t
newCount
)
;
masm
.
setupUnalignedABICall
(
scratch1
)
;
masm
.
loadJSContext
(
scratch1
)
;
masm
.
passABIArg
(
scratch1
)
;
masm
.
passABIArg
(
obj
)
;
masm
.
load32
(
numNewSlotsAddr
scratch2
)
;
masm
.
passABIArg
(
scratch2
)
;
masm
.
callWithABI
<
Fn
NativeObject
:
:
growSlotsPure
>
(
)
;
masm
.
storeCallPointerResult
(
scratch1
)
;
LiveRegisterSet
ignore
;
ignore
.
add
(
scratch1
)
;
masm
.
PopRegsInMaskIgnore
(
save
ignore
)
;
masm
.
branchIfFalseBool
(
scratch1
failure
-
>
label
(
)
)
;
}
masm
.
loadPtr
(
newShapeAddr
scratch1
)
;
masm
.
storeObjShape
(
scratch1
obj
[
]
(
MacroAssembler
&
masm
const
Address
&
addr
)
{
EmitPreBarrier
(
masm
addr
MIRType
:
:
Shape
)
;
}
)
;
masm
.
load32
(
offsetAddr
scratch1
)
;
if
(
op
=
=
CacheOp
:
:
AddAndStoreFixedSlot
)
{
BaseIndex
slot
(
obj
scratch1
TimesOne
)
;
masm
.
storeValue
(
val
slot
)
;
}
else
{
MOZ_ASSERT
(
op
=
=
CacheOp
:
:
AddAndStoreDynamicSlot
|
|
op
=
=
CacheOp
:
:
AllocateAndStoreDynamicSlot
)
;
masm
.
loadPtr
(
Address
(
obj
NativeObject
:
:
offsetOfSlots
(
)
)
scratch2
)
;
BaseIndex
slot
(
scratch2
scratch1
TimesOne
)
;
masm
.
storeValue
(
val
slot
)
;
}
emitPostBarrierSlot
(
obj
val
scratch1
)
;
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
emitAddAndStoreFixedSlot
(
ObjOperandId
objId
uint32_t
offsetOffset
ValOperandId
rhsId
uint32_t
newShapeOffset
)
{
JitSpew
(
JitSpew_Codegen
"
%
s
"
__FUNCTION__
)
;
Maybe
<
uint32_t
>
numNewSlotsOffset
=
mozilla
:
:
Nothing
(
)
;
return
emitAddAndStoreSlotShared
(
CacheOp
:
:
AddAndStoreFixedSlot
objId
offsetOffset
rhsId
newShapeOffset
numNewSlotsOffset
)
;
}
bool
BaselineCacheIRCompiler
:
:
emitAddAndStoreDynamicSlot
(
ObjOperandId
objId
uint32_t
offsetOffset
ValOperandId
rhsId
uint32_t
newShapeOffset
)
{
JitSpew
(
JitSpew_Codegen
"
%
s
"
__FUNCTION__
)
;
Maybe
<
uint32_t
>
numNewSlotsOffset
=
mozilla
:
:
Nothing
(
)
;
return
emitAddAndStoreSlotShared
(
CacheOp
:
:
AddAndStoreDynamicSlot
objId
offsetOffset
rhsId
newShapeOffset
numNewSlotsOffset
)
;
}
bool
BaselineCacheIRCompiler
:
:
emitAllocateAndStoreDynamicSlot
(
ObjOperandId
objId
uint32_t
offsetOffset
ValOperandId
rhsId
uint32_t
newShapeOffset
uint32_t
numNewSlotsOffset
)
{
JitSpew
(
JitSpew_Codegen
"
%
s
"
__FUNCTION__
)
;
return
emitAddAndStoreSlotShared
(
CacheOp
:
:
AllocateAndStoreDynamicSlot
objId
offsetOffset
rhsId
newShapeOffset
mozilla
:
:
Some
(
numNewSlotsOffset
)
)
;
}
bool
BaselineCacheIRCompiler
:
:
emitArrayJoinResult
(
ObjOperandId
objId
StringOperandId
sepId
)
{
JitSpew
(
JitSpew_Codegen
"
%
s
"
__FUNCTION__
)
;
AutoOutputRegister
output
(
*
this
)
;
Register
obj
=
allocator
.
useRegister
(
masm
objId
)
;
Register
sep
=
allocator
.
useRegister
(
masm
sepId
)
;
AutoScratchRegisterMaybeOutput
scratch
(
allocator
masm
output
)
;
allocator
.
discardStack
(
masm
)
;
masm
.
loadPtr
(
Address
(
obj
NativeObject
:
:
offsetOfElements
(
)
)
scratch
)
;
Address
lengthAddr
(
scratch
ObjectElements
:
:
offsetOfLength
(
)
)
;
Label
finished
;
{
Label
arrayNotEmpty
;
masm
.
branch32
(
Assembler
:
:
NotEqual
lengthAddr
Imm32
(
0
)
&
arrayNotEmpty
)
;
masm
.
movePtr
(
ImmGCPtr
(
cx_
-
>
names
(
)
.
empty_
)
scratch
)
;
masm
.
tagValue
(
JSVAL_TYPE_STRING
scratch
output
.
valueReg
(
)
)
;
masm
.
jump
(
&
finished
)
;
masm
.
bind
(
&
arrayNotEmpty
)
;
}
Label
vmCall
;
masm
.
branch32
(
Assembler
:
:
NotEqual
lengthAddr
Imm32
(
1
)
&
vmCall
)
;
Address
initLength
(
scratch
ObjectElements
:
:
offsetOfInitializedLength
(
)
)
;
masm
.
branch32
(
Assembler
:
:
NotEqual
initLength
Imm32
(
1
)
&
vmCall
)
;
Address
elementAddr
(
scratch
0
)
;
masm
.
branchTestString
(
Assembler
:
:
NotEqual
elementAddr
&
vmCall
)
;
masm
.
loadValue
(
elementAddr
output
.
valueReg
(
)
)
;
masm
.
jump
(
&
finished
)
;
{
masm
.
bind
(
&
vmCall
)
;
AutoStubFrame
stubFrame
(
*
this
)
;
stubFrame
.
enter
(
masm
scratch
)
;
masm
.
Push
(
sep
)
;
masm
.
Push
(
obj
)
;
using
Fn
=
JSString
*
(
*
)
(
JSContext
*
HandleObject
HandleString
)
;
callVM
<
Fn
jit
:
:
ArrayJoin
>
(
masm
)
;
stubFrame
.
leave
(
masm
)
;
masm
.
tagValue
(
JSVAL_TYPE_STRING
ReturnReg
output
.
valueReg
(
)
)
;
}
masm
.
bind
(
&
finished
)
;
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
emitPackedArraySliceResult
(
uint32_t
templateObjectOffset
ObjOperandId
arrayId
Int32OperandId
beginId
Int32OperandId
endId
)
{
JitSpew
(
JitSpew_Codegen
"
%
s
"
__FUNCTION__
)
;
AutoOutputRegister
output
(
*
this
)
;
AutoScratchRegisterMaybeOutput
scratch1
(
allocator
masm
output
)
;
AutoScratchRegisterMaybeOutputType
scratch2
(
allocator
masm
output
)
;
Register
array
=
allocator
.
useRegister
(
masm
arrayId
)
;
Register
begin
=
allocator
.
useRegister
(
masm
beginId
)
;
Register
end
=
allocator
.
useRegister
(
masm
endId
)
;
FailurePath
*
failure
;
if
(
!
addFailurePath
(
&
failure
)
)
{
return
false
;
}
masm
.
branchArrayIsNotPacked
(
array
scratch1
scratch2
failure
-
>
label
(
)
)
;
allocator
.
discardStack
(
masm
)
;
AutoStubFrame
stubFrame
(
*
this
)
;
stubFrame
.
enter
(
masm
scratch1
)
;
ImmPtr
result
(
nullptr
)
;
masm
.
Push
(
result
)
;
masm
.
Push
(
end
)
;
masm
.
Push
(
begin
)
;
masm
.
Push
(
array
)
;
using
Fn
=
JSObject
*
(
*
)
(
JSContext
*
HandleObject
int32_t
int32_t
HandleObject
)
;
callVM
<
Fn
ArraySliceDense
>
(
masm
)
;
stubFrame
.
leave
(
masm
)
;
masm
.
tagValue
(
JSVAL_TYPE_OBJECT
ReturnReg
output
.
valueReg
(
)
)
;
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
emitArgumentsSliceResult
(
uint32_t
templateObjectOffset
ObjOperandId
argsId
Int32OperandId
beginId
Int32OperandId
endId
)
{
JitSpew
(
JitSpew_Codegen
"
%
s
"
__FUNCTION__
)
;
AutoOutputRegister
output
(
*
this
)
;
AutoScratchRegisterMaybeOutput
scratch
(
allocator
masm
output
)
;
Register
args
=
allocator
.
useRegister
(
masm
argsId
)
;
Register
begin
=
allocator
.
useRegister
(
masm
beginId
)
;
Register
end
=
allocator
.
useRegister
(
masm
endId
)
;
allocator
.
discardStack
(
masm
)
;
AutoStubFrame
stubFrame
(
*
this
)
;
stubFrame
.
enter
(
masm
scratch
)
;
ImmPtr
result
(
nullptr
)
;
masm
.
Push
(
result
)
;
masm
.
Push
(
end
)
;
masm
.
Push
(
begin
)
;
masm
.
Push
(
args
)
;
using
Fn
=
JSObject
*
(
*
)
(
JSContext
*
HandleObject
int32_t
int32_t
HandleObject
)
;
callVM
<
Fn
ArgumentsSliceDense
>
(
masm
)
;
stubFrame
.
leave
(
masm
)
;
masm
.
tagValue
(
JSVAL_TYPE_OBJECT
ReturnReg
output
.
valueReg
(
)
)
;
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
emitIsArrayResult
(
ValOperandId
inputId
)
{
JitSpew
(
JitSpew_Codegen
"
%
s
"
__FUNCTION__
)
;
AutoOutputRegister
output
(
*
this
)
;
AutoScratchRegister
scratch1
(
allocator
masm
)
;
AutoScratchRegisterMaybeOutput
scratch2
(
allocator
masm
output
)
;
ValueOperand
val
=
allocator
.
useValueRegister
(
masm
inputId
)
;
allocator
.
discardStack
(
masm
)
;
Label
isNotArray
;
masm
.
fallibleUnboxObject
(
val
scratch1
&
isNotArray
)
;
Label
isArray
;
masm
.
branchTestObjClass
(
Assembler
:
:
Equal
scratch1
&
ArrayObject
:
:
class_
scratch2
scratch1
&
isArray
)
;
masm
.
branchTestObjectIsProxy
(
false
scratch1
scratch2
&
isNotArray
)
;
Label
done
;
{
AutoStubFrame
stubFrame
(
*
this
)
;
stubFrame
.
enter
(
masm
scratch2
)
;
masm
.
Push
(
scratch1
)
;
using
Fn
=
bool
(
*
)
(
JSContext
*
HandleObject
bool
*
)
;
callVM
<
Fn
js
:
:
IsArrayFromJit
>
(
masm
)
;
stubFrame
.
leave
(
masm
)
;
masm
.
tagValue
(
JSVAL_TYPE_BOOLEAN
ReturnReg
output
.
valueReg
(
)
)
;
masm
.
jump
(
&
done
)
;
}
masm
.
bind
(
&
isNotArray
)
;
masm
.
moveValue
(
BooleanValue
(
false
)
output
.
valueReg
(
)
)
;
masm
.
jump
(
&
done
)
;
masm
.
bind
(
&
isArray
)
;
masm
.
moveValue
(
BooleanValue
(
true
)
output
.
valueReg
(
)
)
;
masm
.
bind
(
&
done
)
;
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
emitIsTypedArrayResult
(
ObjOperandId
objId
bool
isPossiblyWrapped
)
{
JitSpew
(
JitSpew_Codegen
"
%
s
"
__FUNCTION__
)
;
AutoOutputRegister
output
(
*
this
)
;
AutoScratchRegisterMaybeOutput
scratch
(
allocator
masm
output
)
;
Register
obj
=
allocator
.
useRegister
(
masm
objId
)
;
allocator
.
discardStack
(
masm
)
;
Label
notTypedArray
isProxy
done
;
masm
.
loadObjClassUnsafe
(
obj
scratch
)
;
masm
.
branchIfClassIsNotTypedArray
(
scratch
&
notTypedArray
)
;
masm
.
moveValue
(
BooleanValue
(
true
)
output
.
valueReg
(
)
)
;
masm
.
jump
(
&
done
)
;
masm
.
bind
(
&
notTypedArray
)
;
if
(
isPossiblyWrapped
)
{
masm
.
branchTestClassIsProxy
(
true
scratch
&
isProxy
)
;
}
masm
.
moveValue
(
BooleanValue
(
false
)
output
.
valueReg
(
)
)
;
if
(
isPossiblyWrapped
)
{
masm
.
jump
(
&
done
)
;
masm
.
bind
(
&
isProxy
)
;
AutoStubFrame
stubFrame
(
*
this
)
;
stubFrame
.
enter
(
masm
scratch
)
;
masm
.
Push
(
obj
)
;
using
Fn
=
bool
(
*
)
(
JSContext
*
JSObject
*
bool
*
)
;
callVM
<
Fn
jit
:
:
IsPossiblyWrappedTypedArray
>
(
masm
)
;
stubFrame
.
leave
(
masm
)
;
masm
.
tagValue
(
JSVAL_TYPE_BOOLEAN
ReturnReg
output
.
valueReg
(
)
)
;
}
masm
.
bind
(
&
done
)
;
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
emitLoadStringCharResult
(
StringOperandId
strId
Int32OperandId
indexId
StringCharOutOfBounds
outOfBounds
)
{
AutoOutputRegister
output
(
*
this
)
;
Register
str
=
allocator
.
useRegister
(
masm
strId
)
;
Register
index
=
allocator
.
useRegister
(
masm
indexId
)
;
AutoScratchRegisterMaybeOutput
scratch1
(
allocator
masm
output
)
;
AutoScratchRegisterMaybeOutputType
scratch2
(
allocator
masm
output
)
;
AutoScratchRegister
scratch3
(
allocator
masm
)
;
Label
done
;
Label
tagResult
;
Label
loadFailed
;
if
(
outOfBounds
=
=
StringCharOutOfBounds
:
:
Failure
)
{
FailurePath
*
failure
;
if
(
!
addFailurePath
(
&
failure
)
)
{
return
false
;
}
masm
.
spectreBoundsCheck32
(
index
Address
(
str
JSString
:
:
offsetOfLength
(
)
)
scratch3
failure
-
>
label
(
)
)
;
masm
.
loadStringChar
(
str
index
scratch2
scratch1
scratch3
failure
-
>
label
(
)
)
;
allocator
.
discardStack
(
masm
)
;
}
else
{
allocator
.
discardStack
(
masm
)
;
if
(
outOfBounds
=
=
StringCharOutOfBounds
:
:
EmptyString
)
{
masm
.
movePtr
(
ImmGCPtr
(
cx_
-
>
names
(
)
.
empty_
)
scratch1
)
;
}
else
{
masm
.
moveValue
(
UndefinedValue
(
)
output
.
valueReg
(
)
)
;
}
masm
.
spectreBoundsCheck32
(
index
Address
(
str
JSString
:
:
offsetOfLength
(
)
)
scratch3
&
done
)
;
masm
.
loadStringChar
(
str
index
scratch2
scratch1
scratch3
&
loadFailed
)
;
}
Label
vmCall
;
masm
.
lookupStaticString
(
scratch2
scratch1
cx_
-
>
staticStrings
(
)
&
vmCall
)
;
masm
.
jump
(
&
tagResult
)
;
if
(
outOfBounds
!
=
StringCharOutOfBounds
:
:
Failure
)
{
masm
.
bind
(
&
loadFailed
)
;
masm
.
assumeUnreachable
(
"
loadStringChar
can
'
t
fail
for
linear
strings
"
)
;
}
{
masm
.
bind
(
&
vmCall
)
;
AutoStubFrame
stubFrame
(
*
this
)
;
stubFrame
.
enter
(
masm
scratch3
)
;
masm
.
Push
(
scratch2
)
;
using
Fn
=
JSLinearString
*
(
*
)
(
JSContext
*
int32_t
)
;
callVM
<
Fn
js
:
:
StringFromCharCode
>
(
masm
)
;
stubFrame
.
leave
(
masm
)
;
masm
.
storeCallPointerResult
(
scratch1
)
;
}
if
(
outOfBounds
!
=
StringCharOutOfBounds
:
:
UndefinedValue
)
{
masm
.
bind
(
&
tagResult
)
;
masm
.
bind
(
&
done
)
;
masm
.
tagValue
(
JSVAL_TYPE_STRING
scratch1
output
.
valueReg
(
)
)
;
}
else
{
masm
.
bind
(
&
tagResult
)
;
masm
.
tagValue
(
JSVAL_TYPE_STRING
scratch1
output
.
valueReg
(
)
)
;
masm
.
bind
(
&
done
)
;
}
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
emitLoadStringCharResult
(
StringOperandId
strId
Int32OperandId
indexId
bool
handleOOB
)
{
JitSpew
(
JitSpew_Codegen
"
%
s
"
__FUNCTION__
)
;
auto
outOfBounds
=
handleOOB
?
StringCharOutOfBounds
:
:
EmptyString
:
StringCharOutOfBounds
:
:
Failure
;
return
emitLoadStringCharResult
(
strId
indexId
outOfBounds
)
;
}
bool
BaselineCacheIRCompiler
:
:
emitLoadStringAtResult
(
StringOperandId
strId
Int32OperandId
indexId
bool
handleOOB
)
{
JitSpew
(
JitSpew_Codegen
"
%
s
"
__FUNCTION__
)
;
auto
outOfBounds
=
handleOOB
?
StringCharOutOfBounds
:
:
UndefinedValue
:
StringCharOutOfBounds
:
:
Failure
;
return
emitLoadStringCharResult
(
strId
indexId
outOfBounds
)
;
}
bool
BaselineCacheIRCompiler
:
:
emitStringFromCodeResult
(
Int32OperandId
codeId
StringCode
stringCode
)
{
AutoOutputRegister
output
(
*
this
)
;
AutoScratchRegisterMaybeOutput
scratch
(
allocator
masm
output
)
;
Register
code
=
allocator
.
useRegister
(
masm
codeId
)
;
FailurePath
*
failure
=
nullptr
;
if
(
stringCode
=
=
StringCode
:
:
CodePoint
)
{
if
(
!
addFailurePath
(
&
failure
)
)
{
return
false
;
}
}
if
(
stringCode
=
=
StringCode
:
:
CodePoint
)
{
masm
.
branch32
(
Assembler
:
:
Above
code
Imm32
(
unicode
:
:
NonBMPMax
)
failure
-
>
label
(
)
)
;
}
allocator
.
discardStack
(
masm
)
;
Label
vmCall
;
masm
.
lookupStaticString
(
code
scratch
cx_
-
>
staticStrings
(
)
&
vmCall
)
;
Label
done
;
masm
.
jump
(
&
done
)
;
{
masm
.
bind
(
&
vmCall
)
;
AutoStubFrame
stubFrame
(
*
this
)
;
stubFrame
.
enter
(
masm
scratch
)
;
masm
.
Push
(
code
)
;
if
(
stringCode
=
=
StringCode
:
:
CodeUnit
)
{
using
Fn
=
JSLinearString
*
(
*
)
(
JSContext
*
int32_t
)
;
callVM
<
Fn
js
:
:
StringFromCharCode
>
(
masm
)
;
}
else
{
using
Fn
=
JSLinearString
*
(
*
)
(
JSContext
*
char32_t
)
;
callVM
<
Fn
js
:
:
StringFromCodePoint
>
(
masm
)
;
}
stubFrame
.
leave
(
masm
)
;
masm
.
storeCallPointerResult
(
scratch
)
;
}
masm
.
bind
(
&
done
)
;
masm
.
tagValue
(
JSVAL_TYPE_STRING
scratch
output
.
valueReg
(
)
)
;
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
emitStringFromCharCodeResult
(
Int32OperandId
codeId
)
{
JitSpew
(
JitSpew_Codegen
"
%
s
"
__FUNCTION__
)
;
return
emitStringFromCodeResult
(
codeId
StringCode
:
:
CodeUnit
)
;
}
bool
BaselineCacheIRCompiler
:
:
emitStringFromCodePointResult
(
Int32OperandId
codeId
)
{
JitSpew
(
JitSpew_Codegen
"
%
s
"
__FUNCTION__
)
;
return
emitStringFromCodeResult
(
codeId
StringCode
:
:
CodePoint
)
;
}
bool
BaselineCacheIRCompiler
:
:
emitMathRandomResult
(
uint32_t
rngOffset
)
{
JitSpew
(
JitSpew_Codegen
"
%
s
"
__FUNCTION__
)
;
AutoOutputRegister
output
(
*
this
)
;
AutoScratchRegister
scratch1
(
allocator
masm
)
;
AutoScratchRegister64
scratch2
(
allocator
masm
)
;
AutoAvailableFloatRegister
scratchFloat
(
*
this
FloatReg0
)
;
Address
rngAddr
(
stubAddress
(
rngOffset
)
)
;
masm
.
loadPtr
(
rngAddr
scratch1
)
;
masm
.
randomDouble
(
scratch1
scratchFloat
scratch2
output
.
valueReg
(
)
.
toRegister64
(
)
)
;
if
(
js
:
:
SupportDifferentialTesting
(
)
)
{
masm
.
loadConstantDouble
(
0
.
0
scratchFloat
)
;
}
masm
.
boxDouble
(
scratchFloat
output
.
valueReg
(
)
scratchFloat
)
;
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
emitReflectGetPrototypeOfResult
(
ObjOperandId
objId
)
{
JitSpew
(
JitSpew_Codegen
"
%
s
"
__FUNCTION__
)
;
AutoOutputRegister
output
(
*
this
)
;
AutoScratchRegisterMaybeOutput
scratch
(
allocator
masm
output
)
;
Register
obj
=
allocator
.
useRegister
(
masm
objId
)
;
allocator
.
discardStack
(
masm
)
;
MOZ_ASSERT
(
uintptr_t
(
TaggedProto
:
:
LazyProto
)
=
=
1
)
;
masm
.
loadObjProto
(
obj
scratch
)
;
Label
hasProto
;
masm
.
branchPtr
(
Assembler
:
:
Above
scratch
ImmWord
(
1
)
&
hasProto
)
;
Label
slow
done
;
masm
.
branchPtr
(
Assembler
:
:
Equal
scratch
ImmWord
(
1
)
&
slow
)
;
masm
.
moveValue
(
NullValue
(
)
output
.
valueReg
(
)
)
;
masm
.
jump
(
&
done
)
;
masm
.
bind
(
&
hasProto
)
;
masm
.
tagValue
(
JSVAL_TYPE_OBJECT
scratch
output
.
valueReg
(
)
)
;
masm
.
jump
(
&
done
)
;
{
masm
.
bind
(
&
slow
)
;
AutoStubFrame
stubFrame
(
*
this
)
;
stubFrame
.
enter
(
masm
scratch
)
;
masm
.
Push
(
obj
)
;
using
Fn
=
bool
(
*
)
(
JSContext
*
HandleObject
MutableHandleValue
)
;
callVM
<
Fn
jit
:
:
GetPrototypeOf
>
(
masm
)
;
stubFrame
.
leave
(
masm
)
;
}
masm
.
bind
(
&
done
)
;
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
emitHasClassResult
(
ObjOperandId
objId
uint32_t
claspOffset
)
{
JitSpew
(
JitSpew_Codegen
"
%
s
"
__FUNCTION__
)
;
AutoOutputRegister
output
(
*
this
)
;
Register
obj
=
allocator
.
useRegister
(
masm
objId
)
;
AutoScratchRegisterMaybeOutput
scratch
(
allocator
masm
output
)
;
Address
claspAddr
(
stubAddress
(
claspOffset
)
)
;
masm
.
loadObjClassUnsafe
(
obj
scratch
)
;
masm
.
cmpPtrSet
(
Assembler
:
:
Equal
claspAddr
scratch
.
get
(
)
scratch
)
;
masm
.
tagValue
(
JSVAL_TYPE_BOOLEAN
scratch
output
.
valueReg
(
)
)
;
return
true
;
}
void
BaselineCacheIRCompiler
:
:
emitAtomizeString
(
Register
str
Register
temp
Label
*
failure
)
{
Label
isAtom
notCachedAtom
;
masm
.
branchTest32
(
Assembler
:
:
NonZero
Address
(
str
JSString
:
:
offsetOfFlags
(
)
)
Imm32
(
JSString
:
:
ATOM_BIT
)
&
isAtom
)
;
masm
.
tryFastAtomize
(
str
temp
str
&
notCachedAtom
)
;
masm
.
jump
(
&
isAtom
)
;
masm
.
bind
(
&
notCachedAtom
)
;
{
LiveRegisterSet
save
=
liveVolatileRegs
(
)
;
masm
.
PushRegsInMask
(
save
)
;
using
Fn
=
JSAtom
*
(
*
)
(
JSContext
*
cx
JSString
*
str
)
;
masm
.
setupUnalignedABICall
(
temp
)
;
masm
.
loadJSContext
(
temp
)
;
masm
.
passABIArg
(
temp
)
;
masm
.
passABIArg
(
str
)
;
masm
.
callWithABI
<
Fn
jit
:
:
AtomizeStringNoGC
>
(
)
;
masm
.
storeCallPointerResult
(
temp
)
;
LiveRegisterSet
ignore
;
ignore
.
add
(
temp
)
;
masm
.
PopRegsInMaskIgnore
(
save
ignore
)
;
masm
.
branchPtr
(
Assembler
:
:
Equal
temp
ImmWord
(
0
)
failure
)
;
masm
.
mov
(
temp
str
)
;
}
masm
.
bind
(
&
isAtom
)
;
}
bool
BaselineCacheIRCompiler
:
:
emitSetHasStringResult
(
ObjOperandId
setId
StringOperandId
strId
)
{
JitSpew
(
JitSpew_Codegen
"
%
s
"
__FUNCTION__
)
;
AutoOutputRegister
output
(
*
this
)
;
Register
set
=
allocator
.
useRegister
(
masm
setId
)
;
Register
str
=
allocator
.
useRegister
(
masm
strId
)
;
AutoScratchRegister
scratch1
(
allocator
masm
)
;
AutoScratchRegister
scratch2
(
allocator
masm
)
;
AutoScratchRegister
scratch3
(
allocator
masm
)
;
AutoScratchRegister
scratch4
(
allocator
masm
)
;
FailurePath
*
failure
;
if
(
!
addFailurePath
(
&
failure
)
)
{
return
false
;
}
emitAtomizeString
(
str
scratch1
failure
-
>
label
(
)
)
;
masm
.
prepareHashString
(
str
scratch1
scratch2
)
;
masm
.
tagValue
(
JSVAL_TYPE_STRING
str
output
.
valueReg
(
)
)
;
masm
.
setObjectHasNonBigInt
(
set
output
.
valueReg
(
)
scratch1
scratch2
scratch3
scratch4
)
;
masm
.
tagValue
(
JSVAL_TYPE_BOOLEAN
scratch2
output
.
valueReg
(
)
)
;
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
emitMapHasStringResult
(
ObjOperandId
mapId
StringOperandId
strId
)
{
JitSpew
(
JitSpew_Codegen
"
%
s
"
__FUNCTION__
)
;
AutoOutputRegister
output
(
*
this
)
;
Register
map
=
allocator
.
useRegister
(
masm
mapId
)
;
Register
str
=
allocator
.
useRegister
(
masm
strId
)
;
AutoScratchRegister
scratch1
(
allocator
masm
)
;
AutoScratchRegister
scratch2
(
allocator
masm
)
;
AutoScratchRegister
scratch3
(
allocator
masm
)
;
AutoScratchRegister
scratch4
(
allocator
masm
)
;
FailurePath
*
failure
;
if
(
!
addFailurePath
(
&
failure
)
)
{
return
false
;
}
emitAtomizeString
(
str
scratch1
failure
-
>
label
(
)
)
;
masm
.
prepareHashString
(
str
scratch1
scratch2
)
;
masm
.
tagValue
(
JSVAL_TYPE_STRING
str
output
.
valueReg
(
)
)
;
masm
.
mapObjectHasNonBigInt
(
map
output
.
valueReg
(
)
scratch1
scratch2
scratch3
scratch4
)
;
masm
.
tagValue
(
JSVAL_TYPE_BOOLEAN
scratch2
output
.
valueReg
(
)
)
;
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
emitMapGetStringResult
(
ObjOperandId
mapId
StringOperandId
strId
)
{
JitSpew
(
JitSpew_Codegen
"
%
s
"
__FUNCTION__
)
;
AutoOutputRegister
output
(
*
this
)
;
Register
map
=
allocator
.
useRegister
(
masm
mapId
)
;
Register
str
=
allocator
.
useRegister
(
masm
strId
)
;
AutoScratchRegister
scratch1
(
allocator
masm
)
;
AutoScratchRegister
scratch2
(
allocator
masm
)
;
AutoScratchRegister
scratch3
(
allocator
masm
)
;
AutoScratchRegister
scratch4
(
allocator
masm
)
;
FailurePath
*
failure
;
if
(
!
addFailurePath
(
&
failure
)
)
{
return
false
;
}
emitAtomizeString
(
str
scratch1
failure
-
>
label
(
)
)
;
masm
.
prepareHashString
(
str
scratch1
scratch2
)
;
masm
.
tagValue
(
JSVAL_TYPE_STRING
str
output
.
valueReg
(
)
)
;
masm
.
mapObjectGetNonBigInt
(
map
output
.
valueReg
(
)
scratch1
output
.
valueReg
(
)
scratch2
scratch3
scratch4
)
;
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
emitCallNativeSetter
(
ObjOperandId
receiverId
uint32_t
setterOffset
ValOperandId
rhsId
bool
sameRealm
uint32_t
nargsAndFlagsOffset
)
{
JitSpew
(
JitSpew_Codegen
"
%
s
"
__FUNCTION__
)
;
Register
receiver
=
allocator
.
useRegister
(
masm
receiverId
)
;
Address
setterAddr
(
stubAddress
(
setterOffset
)
)
;
ValueOperand
val
=
allocator
.
useValueRegister
(
masm
rhsId
)
;
AutoScratchRegister
scratch
(
allocator
masm
)
;
allocator
.
discardStack
(
masm
)
;
AutoStubFrame
stubFrame
(
*
this
)
;
stubFrame
.
enter
(
masm
scratch
)
;
masm
.
loadPtr
(
setterAddr
scratch
)
;
masm
.
Push
(
val
)
;
masm
.
Push
(
receiver
)
;
masm
.
Push
(
scratch
)
;
using
Fn
=
bool
(
*
)
(
JSContext
*
HandleFunction
HandleObject
HandleValue
)
;
callVM
<
Fn
CallNativeSetter
>
(
masm
)
;
stubFrame
.
leave
(
masm
)
;
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
emitCallScriptedSetterShared
(
ObjOperandId
receiverId
uint32_t
setterOffset
ValOperandId
rhsId
bool
sameRealm
uint32_t
nargsAndFlagsOffset
Maybe
<
uint32_t
>
icScriptOffset
)
{
AutoScratchRegister
callee
(
allocator
masm
)
;
AutoScratchRegister
scratch
(
allocator
masm
)
;
#
if
defined
(
JS_CODEGEN_X86
)
Register
code
=
scratch
;
#
else
AutoScratchRegister
code
(
allocator
masm
)
;
#
endif
Register
receiver
=
allocator
.
useRegister
(
masm
receiverId
)
;
Address
setterAddr
(
stubAddress
(
setterOffset
)
)
;
ValueOperand
val
=
allocator
.
useValueRegister
(
masm
rhsId
)
;
bool
isInlined
=
icScriptOffset
.
isSome
(
)
;
masm
.
loadPtr
(
setterAddr
callee
)
;
if
(
isInlined
)
{
FailurePath
*
failure
;
if
(
!
addFailurePath
(
&
failure
)
)
{
return
false
;
}
masm
.
loadBaselineJitCodeRaw
(
callee
code
failure
-
>
label
(
)
)
;
}
allocator
.
discardStack
(
masm
)
;
AutoStubFrame
stubFrame
(
*
this
)
;
stubFrame
.
enter
(
masm
scratch
)
;
if
(
!
sameRealm
)
{
masm
.
switchToObjectRealm
(
callee
scratch
)
;
}
masm
.
alignJitStackBasedOnNArgs
(
1
false
)
;
masm
.
Push
(
val
)
;
masm
.
Push
(
TypedOrValueRegister
(
MIRType
:
:
Object
AnyRegister
(
receiver
)
)
)
;
masm
.
Push
(
callee
)
;
masm
.
PushFrameDescriptorForJitCall
(
FrameType
:
:
BaselineStub
1
)
;
if
(
isInlined
)
{
Address
icScriptAddr
(
stubAddress
(
*
icScriptOffset
)
)
;
masm
.
loadPtr
(
icScriptAddr
scratch
)
;
masm
.
storeICScriptInJSContext
(
scratch
)
;
}
if
(
isInlined
)
{
#
ifdef
JS_CODEGEN_X86
masm
.
loadBaselineJitCodeRaw
(
callee
code
)
;
#
endif
}
else
{
masm
.
loadJitCodeRaw
(
callee
code
)
;
}
Label
noUnderflow
;
Register
scratch2
=
val
.
scratchReg
(
)
;
masm
.
loadFunctionArgCount
(
callee
scratch2
)
;
masm
.
branch32
(
Assembler
:
:
BelowOrEqual
scratch2
Imm32
(
1
)
&
noUnderflow
)
;
ArgumentsRectifierKind
kind
=
isInlined
?
ArgumentsRectifierKind
:
:
TrialInlining
:
ArgumentsRectifierKind
:
:
Normal
;
TrampolinePtr
argumentsRectifier
=
cx_
-
>
runtime
(
)
-
>
jitRuntime
(
)
-
>
getArgumentsRectifier
(
kind
)
;
masm
.
movePtr
(
argumentsRectifier
code
)
;
masm
.
bind
(
&
noUnderflow
)
;
masm
.
callJit
(
code
)
;
stubFrame
.
leave
(
masm
)
;
if
(
!
sameRealm
)
{
masm
.
switchToBaselineFrameRealm
(
R1
.
scratchReg
(
)
)
;
}
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
emitCallScriptedSetter
(
ObjOperandId
receiverId
uint32_t
setterOffset
ValOperandId
rhsId
bool
sameRealm
uint32_t
nargsAndFlagsOffset
)
{
JitSpew
(
JitSpew_Codegen
"
%
s
"
__FUNCTION__
)
;
Maybe
<
uint32_t
>
icScriptOffset
=
mozilla
:
:
Nothing
(
)
;
return
emitCallScriptedSetterShared
(
receiverId
setterOffset
rhsId
sameRealm
nargsAndFlagsOffset
icScriptOffset
)
;
}
bool
BaselineCacheIRCompiler
:
:
emitCallInlinedSetter
(
ObjOperandId
receiverId
uint32_t
setterOffset
ValOperandId
rhsId
uint32_t
icScriptOffset
bool
sameRealm
uint32_t
nargsAndFlagsOffset
)
{
JitSpew
(
JitSpew_Codegen
"
%
s
"
__FUNCTION__
)
;
return
emitCallScriptedSetterShared
(
receiverId
setterOffset
rhsId
sameRealm
nargsAndFlagsOffset
mozilla
:
:
Some
(
icScriptOffset
)
)
;
}
bool
BaselineCacheIRCompiler
:
:
emitCallDOMSetter
(
ObjOperandId
objId
uint32_t
jitInfoOffset
ValOperandId
rhsId
)
{
JitSpew
(
JitSpew_Codegen
"
%
s
"
__FUNCTION__
)
;
Register
obj
=
allocator
.
useRegister
(
masm
objId
)
;
ValueOperand
val
=
allocator
.
useValueRegister
(
masm
rhsId
)
;
Address
jitInfoAddr
(
stubAddress
(
jitInfoOffset
)
)
;
AutoScratchRegister
scratch
(
allocator
masm
)
;
allocator
.
discardStack
(
masm
)
;
AutoStubFrame
stubFrame
(
*
this
)
;
stubFrame
.
enter
(
masm
scratch
)
;
masm
.
loadPtr
(
jitInfoAddr
scratch
)
;
masm
.
Push
(
val
)
;
masm
.
Push
(
obj
)
;
masm
.
Push
(
scratch
)
;
using
Fn
=
bool
(
*
)
(
JSContext
*
const
JSJitInfo
*
HandleObject
HandleValue
)
;
callVM
<
Fn
CallDOMSetter
>
(
masm
)
;
stubFrame
.
leave
(
masm
)
;
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
emitCallSetArrayLength
(
ObjOperandId
objId
bool
strict
ValOperandId
rhsId
)
{
JitSpew
(
JitSpew_Codegen
"
%
s
"
__FUNCTION__
)
;
Register
obj
=
allocator
.
useRegister
(
masm
objId
)
;
ValueOperand
val
=
allocator
.
useValueRegister
(
masm
rhsId
)
;
AutoScratchRegister
scratch
(
allocator
masm
)
;
allocator
.
discardStack
(
masm
)
;
AutoStubFrame
stubFrame
(
*
this
)
;
stubFrame
.
enter
(
masm
scratch
)
;
masm
.
Push
(
Imm32
(
strict
)
)
;
masm
.
Push
(
val
)
;
masm
.
Push
(
obj
)
;
using
Fn
=
bool
(
*
)
(
JSContext
*
HandleObject
HandleValue
bool
)
;
callVM
<
Fn
jit
:
:
SetArrayLength
>
(
masm
)
;
stubFrame
.
leave
(
masm
)
;
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
emitProxySet
(
ObjOperandId
objId
uint32_t
idOffset
ValOperandId
rhsId
bool
strict
)
{
JitSpew
(
JitSpew_Codegen
"
%
s
"
__FUNCTION__
)
;
Register
obj
=
allocator
.
useRegister
(
masm
objId
)
;
ValueOperand
val
=
allocator
.
useValueRegister
(
masm
rhsId
)
;
Address
idAddr
(
stubAddress
(
idOffset
)
)
;
AutoScratchRegister
scratch
(
allocator
masm
)
;
allocator
.
discardStack
(
masm
)
;
AutoStubFrame
stubFrame
(
*
this
)
;
stubFrame
.
enter
(
masm
scratch
)
;
masm
.
loadPtr
(
idAddr
scratch
)
;
masm
.
Push
(
Imm32
(
strict
)
)
;
masm
.
Push
(
val
)
;
masm
.
Push
(
scratch
)
;
masm
.
Push
(
obj
)
;
using
Fn
=
bool
(
*
)
(
JSContext
*
HandleObject
HandleId
HandleValue
bool
)
;
callVM
<
Fn
ProxySetProperty
>
(
masm
)
;
stubFrame
.
leave
(
masm
)
;
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
emitProxySetByValue
(
ObjOperandId
objId
ValOperandId
idId
ValOperandId
rhsId
bool
strict
)
{
JitSpew
(
JitSpew_Codegen
"
%
s
"
__FUNCTION__
)
;
Register
obj
=
allocator
.
useRegister
(
masm
objId
)
;
ValueOperand
idVal
=
allocator
.
useValueRegister
(
masm
idId
)
;
ValueOperand
val
=
allocator
.
useValueRegister
(
masm
rhsId
)
;
allocator
.
discardStack
(
masm
)
;
int
scratchOffset
=
BaselineFrame
:
:
reverseOffsetOfScratchValue
(
)
;
masm
.
storePtr
(
obj
Address
(
baselineFrameReg
(
)
scratchOffset
)
)
;
AutoStubFrame
stubFrame
(
*
this
)
;
stubFrame
.
enter
(
masm
obj
)
;
masm
.
loadPtr
(
Address
(
FramePointer
0
)
obj
)
;
masm
.
loadPtr
(
Address
(
obj
scratchOffset
)
obj
)
;
masm
.
Push
(
Imm32
(
strict
)
)
;
masm
.
Push
(
val
)
;
masm
.
Push
(
idVal
)
;
masm
.
Push
(
obj
)
;
using
Fn
=
bool
(
*
)
(
JSContext
*
HandleObject
HandleValue
HandleValue
bool
)
;
callVM
<
Fn
ProxySetPropertyByValue
>
(
masm
)
;
stubFrame
.
leave
(
masm
)
;
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
emitCallAddOrUpdateSparseElementHelper
(
ObjOperandId
objId
Int32OperandId
idId
ValOperandId
rhsId
bool
strict
)
{
JitSpew
(
JitSpew_Codegen
"
%
s
"
__FUNCTION__
)
;
Register
obj
=
allocator
.
useRegister
(
masm
objId
)
;
Register
id
=
allocator
.
useRegister
(
masm
idId
)
;
ValueOperand
val
=
allocator
.
useValueRegister
(
masm
rhsId
)
;
AutoScratchRegister
scratch
(
allocator
masm
)
;
allocator
.
discardStack
(
masm
)
;
AutoStubFrame
stubFrame
(
*
this
)
;
stubFrame
.
enter
(
masm
scratch
)
;
masm
.
Push
(
Imm32
(
strict
)
)
;
masm
.
Push
(
val
)
;
masm
.
Push
(
id
)
;
masm
.
Push
(
obj
)
;
using
Fn
=
bool
(
*
)
(
JSContext
*
cx
Handle
<
NativeObject
*
>
obj
int32_t
int_id
HandleValue
v
bool
strict
)
;
callVM
<
Fn
AddOrUpdateSparseElementHelper
>
(
masm
)
;
stubFrame
.
leave
(
masm
)
;
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
emitMegamorphicSetElement
(
ObjOperandId
objId
ValOperandId
idId
ValOperandId
rhsId
bool
strict
)
{
JitSpew
(
JitSpew_Codegen
"
%
s
"
__FUNCTION__
)
;
Register
obj
=
allocator
.
useRegister
(
masm
objId
)
;
ValueOperand
idVal
=
allocator
.
useValueRegister
(
masm
idId
)
;
ValueOperand
val
=
allocator
.
useValueRegister
(
masm
rhsId
)
;
#
ifdef
JS_CODEGEN_X86
allocator
.
discardStack
(
masm
)
;
int
scratchOffset
=
BaselineFrame
:
:
reverseOffsetOfScratchValue
(
)
;
masm
.
storePtr
(
obj
Address
(
baselineFrameReg_
scratchOffset
)
)
;
AutoStubFrame
stubFrame
(
*
this
)
;
stubFrame
.
enter
(
masm
obj
)
;
masm
.
loadPtr
(
Address
(
FramePointer
0
)
obj
)
;
masm
.
loadPtr
(
Address
(
obj
scratchOffset
)
obj
)
;
#
else
AutoScratchRegister
scratch
(
allocator
masm
)
;
allocator
.
discardStack
(
masm
)
;
AutoStubFrame
stubFrame
(
*
this
)
;
stubFrame
.
enter
(
masm
scratch
)
;
#
endif
masm
.
Push
(
Imm32
(
strict
)
)
;
masm
.
Push
(
val
)
;
masm
.
Push
(
idVal
)
;
masm
.
Push
(
obj
)
;
using
Fn
=
bool
(
*
)
(
JSContext
*
HandleObject
HandleValue
HandleValue
bool
)
;
callVM
<
Fn
SetElementMegamorphic
<
false
>
>
(
masm
)
;
stubFrame
.
leave
(
masm
)
;
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
emitReturnFromIC
(
)
{
JitSpew
(
JitSpew_Codegen
"
%
s
"
__FUNCTION__
)
;
allocator
.
discardStack
(
masm
)
;
if
(
JitOptions
.
enableICFramePointers
)
{
PopICFrameRegs
(
masm
)
;
}
EmitReturnFromIC
(
masm
)
;
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
emitLoadArgumentFixedSlot
(
ValOperandId
resultId
uint8_t
slotIndex
)
{
JitSpew
(
JitSpew_Codegen
"
%
s
"
__FUNCTION__
)
;
ValueOperand
resultReg
=
allocator
.
defineValueRegister
(
masm
resultId
)
;
Address
addr
=
allocator
.
addressOf
(
masm
BaselineFrameSlot
(
slotIndex
)
)
;
masm
.
loadValue
(
addr
resultReg
)
;
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
emitLoadArgumentDynamicSlot
(
ValOperandId
resultId
Int32OperandId
argcId
uint8_t
slotIndex
)
{
JitSpew
(
JitSpew_Codegen
"
%
s
"
__FUNCTION__
)
;
ValueOperand
resultReg
=
allocator
.
defineValueRegister
(
masm
resultId
)
;
Register
argcReg
=
allocator
.
useRegister
(
masm
argcId
)
;
BaseValueIndex
addr
=
allocator
.
addressOf
(
masm
argcReg
BaselineFrameSlot
(
slotIndex
)
)
;
masm
.
loadValue
(
addr
resultReg
)
;
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
emitGuardDOMExpandoMissingOrGuardShape
(
ValOperandId
expandoId
uint32_t
shapeOffset
)
{
JitSpew
(
JitSpew_Codegen
"
%
s
"
__FUNCTION__
)
;
ValueOperand
val
=
allocator
.
useValueRegister
(
masm
expandoId
)
;
AutoScratchRegister
shapeScratch
(
allocator
masm
)
;
AutoScratchRegister
objScratch
(
allocator
masm
)
;
Address
shapeAddr
(
stubAddress
(
shapeOffset
)
)
;
FailurePath
*
failure
;
if
(
!
addFailurePath
(
&
failure
)
)
{
return
false
;
}
Label
done
;
masm
.
branchTestUndefined
(
Assembler
:
:
Equal
val
&
done
)
;
masm
.
debugAssertIsObject
(
val
)
;
masm
.
loadPtr
(
shapeAddr
shapeScratch
)
;
masm
.
unboxObject
(
val
objScratch
)
;
masm
.
branchTestObjShapeNoSpectreMitigations
(
Assembler
:
:
NotEqual
objScratch
shapeScratch
failure
-
>
label
(
)
)
;
masm
.
bind
(
&
done
)
;
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
emitLoadDOMExpandoValueGuardGeneration
(
ObjOperandId
objId
uint32_t
expandoAndGenerationOffset
uint32_t
generationOffset
ValOperandId
resultId
)
{
JitSpew
(
JitSpew_Codegen
"
%
s
"
__FUNCTION__
)
;
Register
obj
=
allocator
.
useRegister
(
masm
objId
)
;
Address
expandoAndGenerationAddr
(
stubAddress
(
expandoAndGenerationOffset
)
)
;
Address
generationAddr
(
stubAddress
(
generationOffset
)
)
;
AutoScratchRegister
scratch
(
allocator
masm
)
;
ValueOperand
output
=
allocator
.
defineValueRegister
(
masm
resultId
)
;
FailurePath
*
failure
;
if
(
!
addFailurePath
(
&
failure
)
)
{
return
false
;
}
masm
.
loadPtr
(
Address
(
obj
ProxyObject
:
:
offsetOfReservedSlots
(
)
)
scratch
)
;
Address
expandoAddr
(
scratch
js
:
:
detail
:
:
ProxyReservedSlots
:
:
offsetOfPrivateSlot
(
)
)
;
masm
.
loadPtr
(
expandoAndGenerationAddr
output
.
scratchReg
(
)
)
;
masm
.
branchPrivatePtr
(
Assembler
:
:
NotEqual
expandoAddr
output
.
scratchReg
(
)
failure
-
>
label
(
)
)
;
masm
.
branch64
(
Assembler
:
:
NotEqual
Address
(
output
.
scratchReg
(
)
ExpandoAndGeneration
:
:
offsetOfGeneration
(
)
)
generationAddr
scratch
failure
-
>
label
(
)
)
;
masm
.
loadValue
(
Address
(
output
.
scratchReg
(
)
ExpandoAndGeneration
:
:
offsetOfExpando
(
)
)
output
)
;
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
init
(
CacheKind
kind
)
{
if
(
!
allocator
.
init
(
)
)
{
return
false
;
}
size_t
numInputs
=
writer_
.
numInputOperands
(
)
;
MOZ_ASSERT
(
numInputs
=
=
NumInputsForCacheKind
(
kind
)
)
;
size_t
numInputsInRegs
=
std
:
:
min
(
numInputs
size_t
(
2
)
)
;
AllocatableGeneralRegisterSet
available
=
BaselineICAvailableGeneralRegs
(
numInputsInRegs
)
;
switch
(
kind
)
{
case
CacheKind
:
:
NewArray
:
case
CacheKind
:
:
NewObject
:
case
CacheKind
:
:
GetIntrinsic
:
MOZ_ASSERT
(
numInputs
=
=
0
)
;
outputUnchecked_
.
emplace
(
R0
)
;
break
;
case
CacheKind
:
:
GetProp
:
case
CacheKind
:
:
TypeOf
:
case
CacheKind
:
:
TypeOfEq
:
case
CacheKind
:
:
ToPropertyKey
:
case
CacheKind
:
:
GetIterator
:
case
CacheKind
:
:
OptimizeSpreadCall
:
case
CacheKind
:
:
OptimizeGetIterator
:
case
CacheKind
:
:
ToBool
:
case
CacheKind
:
:
UnaryArith
:
MOZ_ASSERT
(
numInputs
=
=
1
)
;
allocator
.
initInputLocation
(
0
R0
)
;
outputUnchecked_
.
emplace
(
R0
)
;
break
;
case
CacheKind
:
:
Compare
:
case
CacheKind
:
:
GetElem
:
case
CacheKind
:
:
GetPropSuper
:
case
CacheKind
:
:
In
:
case
CacheKind
:
:
HasOwn
:
case
CacheKind
:
:
CheckPrivateField
:
case
CacheKind
:
:
InstanceOf
:
case
CacheKind
:
:
BinaryArith
:
MOZ_ASSERT
(
numInputs
=
=
2
)
;
allocator
.
initInputLocation
(
0
R0
)
;
allocator
.
initInputLocation
(
1
R1
)
;
outputUnchecked_
.
emplace
(
R0
)
;
break
;
case
CacheKind
:
:
SetProp
:
MOZ_ASSERT
(
numInputs
=
=
2
)
;
allocator
.
initInputLocation
(
0
R0
)
;
allocator
.
initInputLocation
(
1
R1
)
;
break
;
case
CacheKind
:
:
GetElemSuper
:
MOZ_ASSERT
(
numInputs
=
=
3
)
;
allocator
.
initInputLocation
(
0
BaselineFrameSlot
(
0
)
)
;
allocator
.
initInputLocation
(
1
R1
)
;
allocator
.
initInputLocation
(
2
R0
)
;
outputUnchecked_
.
emplace
(
R0
)
;
break
;
case
CacheKind
:
:
SetElem
:
MOZ_ASSERT
(
numInputs
=
=
3
)
;
allocator
.
initInputLocation
(
0
R0
)
;
allocator
.
initInputLocation
(
1
R1
)
;
allocator
.
initInputLocation
(
2
BaselineFrameSlot
(
0
)
)
;
break
;
case
CacheKind
:
:
GetName
:
case
CacheKind
:
:
BindName
:
MOZ_ASSERT
(
numInputs
=
=
1
)
;
allocator
.
initInputLocation
(
0
R0
.
scratchReg
(
)
JSVAL_TYPE_OBJECT
)
;
#
if
defined
(
JS_NUNBOX32
)
available
.
add
(
R0
.
typeReg
(
)
)
;
#
endif
outputUnchecked_
.
emplace
(
R0
)
;
break
;
case
CacheKind
:
:
Call
:
MOZ_ASSERT
(
numInputs
=
=
1
)
;
allocator
.
initInputLocation
(
0
R0
.
scratchReg
(
)
JSVAL_TYPE_INT32
)
;
#
if
defined
(
JS_NUNBOX32
)
available
.
add
(
R0
.
typeReg
(
)
)
;
#
endif
outputUnchecked_
.
emplace
(
R0
)
;
break
;
case
CacheKind
:
:
CloseIter
:
MOZ_ASSERT
(
numInputs
=
=
1
)
;
allocator
.
initInputLocation
(
0
R0
.
scratchReg
(
)
JSVAL_TYPE_OBJECT
)
;
#
if
defined
(
JS_NUNBOX32
)
available
.
add
(
R0
.
typeReg
(
)
)
;
#
endif
break
;
}
liveFloatRegs_
=
LiveFloatRegisterSet
(
FloatRegisterSet
(
)
)
;
if
(
JitOptions
.
enableICFramePointers
)
{
baselineFrameReg_
=
available
.
takeAny
(
)
;
}
allocator
.
initAvailableRegs
(
available
)
;
return
true
;
}
static
void
ResetEnteredCounts
(
const
ICEntry
*
icEntry
)
{
ICStub
*
stub
=
icEntry
-
>
firstStub
(
)
;
while
(
true
)
{
stub
-
>
resetEnteredCount
(
)
;
if
(
stub
-
>
isFallback
(
)
)
{
return
;
}
stub
=
stub
-
>
toCacheIRStub
(
)
-
>
next
(
)
;
}
}
static
const
uint32_t
MaxFoldedShapes
=
16
;
const
JSClass
ShapeListObject
:
:
class_
=
{
"
JIT
ShapeList
"
0
&
classOps_
}
;
const
JSClassOps
ShapeListObject
:
:
classOps_
=
{
nullptr
nullptr
nullptr
nullptr
nullptr
nullptr
nullptr
nullptr
nullptr
ShapeListObject
:
:
trace
}
;
ShapeListObject
*
ShapeListObject
:
:
create
(
JSContext
*
cx
)
{
NativeObject
*
obj
=
NewTenuredObjectWithGivenProto
(
cx
&
class_
nullptr
)
;
if
(
!
obj
)
{
return
nullptr
;
}
if
(
!
cx
-
>
zone
(
)
-
>
registerObjectWithWeakPointers
(
obj
)
)
{
return
nullptr
;
}
return
&
obj
-
>
as
<
ShapeListObject
>
(
)
;
}
Shape
*
ShapeListObject
:
:
get
(
uint32_t
index
)
{
Value
value
=
ListObject
:
:
get
(
index
)
;
return
static_cast
<
Shape
*
>
(
value
.
toPrivate
(
)
)
;
}
void
ShapeListObject
:
:
trace
(
JSTracer
*
trc
JSObject
*
obj
)
{
if
(
trc
-
>
traceWeakEdges
(
)
)
{
obj
-
>
as
<
ShapeListObject
>
(
)
.
traceWeak
(
trc
)
;
}
}
bool
ShapeListObject
:
:
traceWeak
(
JSTracer
*
trc
)
{
uint32_t
length
=
getDenseInitializedLength
(
)
;
if
(
length
=
=
0
)
{
return
false
;
}
const
HeapSlot
*
src
=
elements_
;
const
HeapSlot
*
end
=
src
+
length
;
HeapSlot
*
dst
=
elements_
;
while
(
src
!
=
end
)
{
Shape
*
shape
=
static_cast
<
Shape
*
>
(
src
-
>
toPrivate
(
)
)
;
MOZ_ASSERT
(
shape
-
>
is
<
Shape
>
(
)
)
;
if
(
TraceManuallyBarrieredWeakEdge
(
trc
&
shape
"
ShapeListObject
shape
"
)
)
{
dst
-
>
unbarrieredSet
(
PrivateValue
(
shape
)
)
;
dst
+
+
;
}
src
+
+
;
}
MOZ_ASSERT
(
dst
<
=
end
)
;
uint32_t
newLength
=
dst
-
elements_
;
setDenseInitializedLength
(
newLength
)
;
if
(
length
!
=
newLength
)
{
JitSpew
(
JitSpew_StubFolding
"
Cleared
%
u
/
%
u
shapes
from
%
p
"
length
-
newLength
length
this
)
;
}
return
length
!
=
0
;
}
bool
js
:
:
jit
:
:
TryFoldingStubs
(
JSContext
*
cx
ICFallbackStub
*
fallback
JSScript
*
script
ICScript
*
icScript
)
{
ICEntry
*
icEntry
=
icScript
-
>
icEntryForStub
(
fallback
)
;
ICStub
*
entryStub
=
icEntry
-
>
firstStub
(
)
;
if
(
entryStub
=
=
fallback
)
{
return
true
;
}
ICCacheIRStub
*
firstStub
=
entryStub
-
>
toCacheIRStub
(
)
;
if
(
firstStub
-
>
next
(
)
-
>
isFallback
(
)
)
{
return
true
;
}
const
uint8_t
*
firstStubData
=
firstStub
-
>
stubDataStart
(
)
;
const
CacheIRStubInfo
*
stubInfo
=
firstStub
-
>
stubInfo
(
)
;
uint32_t
numActive
=
0
;
Maybe
<
uint32_t
>
foldableFieldOffset
;
RootedValue
shape
(
cx
)
;
RootedValueVector
shapeList
(
cx
)
;
auto
addShape
=
[
&
shapeList
cx
]
(
uintptr_t
rawShape
)
-
>
bool
{
Shape
*
shape
=
reinterpret_cast
<
Shape
*
>
(
rawShape
)
;
if
(
shape
-
>
realm
(
)
!
=
cx
-
>
realm
(
)
)
{
return
false
;
}
gc
:
:
ReadBarrier
(
shape
)
;
if
(
!
shapeList
.
append
(
PrivateValue
(
shape
)
)
)
{
cx
-
>
recoverFromOutOfMemory
(
)
;
return
false
;
}
return
true
;
}
;
for
(
ICCacheIRStub
*
other
=
firstStub
-
>
nextCacheIR
(
)
;
other
;
other
=
other
-
>
nextCacheIR
(
)
)
{
if
(
other
-
>
stubInfo
(
)
!
=
stubInfo
)
{
return
true
;
}
const
uint8_t
*
otherStubData
=
other
-
>
stubDataStart
(
)
;
if
(
other
-
>
enteredCount
(
)
>
0
)
{
numActive
+
+
;
}
uint32_t
fieldIndex
=
0
;
size_t
offset
=
0
;
while
(
stubInfo
-
>
fieldType
(
fieldIndex
)
!
=
StubField
:
:
Type
:
:
Limit
)
{
StubField
:
:
Type
fieldType
=
stubInfo
-
>
fieldType
(
fieldIndex
)
;
if
(
StubField
:
:
sizeIsWord
(
fieldType
)
)
{
uintptr_t
firstRaw
=
stubInfo
-
>
getStubRawWord
(
firstStubData
offset
)
;
uintptr_t
otherRaw
=
stubInfo
-
>
getStubRawWord
(
otherStubData
offset
)
;
if
(
firstRaw
!
=
otherRaw
)
{
if
(
fieldType
!
=
StubField
:
:
Type
:
:
WeakShape
)
{
return
true
;
}
if
(
foldableFieldOffset
.
isNothing
(
)
)
{
foldableFieldOffset
.
emplace
(
offset
)
;
if
(
!
addShape
(
firstRaw
)
|
|
!
addShape
(
otherRaw
)
)
{
return
true
;
}
}
else
if
(
*
foldableFieldOffset
=
=
offset
)
{
if
(
!
addShape
(
otherRaw
)
)
{
return
true
;
}
}
else
{
return
true
;
}
}
}
else
{
MOZ_ASSERT
(
StubField
:
:
sizeIsInt64
(
fieldType
)
)
;
if
(
stubInfo
-
>
getStubRawInt64
(
firstStubData
offset
)
!
=
stubInfo
-
>
getStubRawInt64
(
otherStubData
offset
)
)
{
return
true
;
}
}
offset
+
=
StubField
:
:
sizeInBytes
(
fieldType
)
;
fieldIndex
+
+
;
}
MOZ_ASSERT
(
foldableFieldOffset
.
isSome
(
)
)
;
}
if
(
numActive
=
=
0
)
{
return
true
;
}
CacheIRWriter
writer
(
cx
)
;
CacheIRReader
reader
(
stubInfo
)
;
CacheIRCloner
cloner
(
firstStub
)
;
CacheKind
cacheKind
=
stubInfo
-
>
kind
(
)
;
for
(
uint32_t
i
=
0
;
i
<
NumInputsForCacheKind
(
cacheKind
)
;
i
+
+
)
{
writer
.
setInputOperandId
(
i
)
;
}
bool
success
=
false
;
while
(
reader
.
more
(
)
)
{
CacheOp
op
=
reader
.
readOp
(
)
;
switch
(
op
)
{
case
CacheOp
:
:
GuardShape
:
{
ObjOperandId
objId
=
reader
.
objOperandId
(
)
;
uint32_t
shapeOffset
=
reader
.
stubOffset
(
)
;
if
(
shapeOffset
=
=
*
foldableFieldOffset
)
{
gc
:
:
AutoSuppressGC
suppressGC
(
cx
)
;
Rooted
<
ShapeListObject
*
>
shapeObj
(
cx
ShapeListObject
:
:
create
(
cx
)
)
;
if
(
!
shapeObj
)
{
return
false
;
}
for
(
uint32_t
i
=
0
;
i
<
shapeList
.
length
(
)
;
i
+
+
)
{
if
(
!
shapeObj
-
>
append
(
cx
shapeList
[
i
]
)
)
{
return
false
;
}
MOZ_ASSERT
(
static_cast
<
Shape
*
>
(
shapeList
[
i
]
.
toPrivate
(
)
)
-
>
realm
(
)
=
=
shapeObj
-
>
realm
(
)
)
;
}
writer
.
guardMultipleShapes
(
objId
shapeObj
)
;
success
=
true
;
}
else
{
WeakHeapPtr
<
Shape
*
>
&
ptr
=
stubInfo
-
>
getStubField
<
StubField
:
:
Type
:
:
WeakShape
>
(
firstStub
shapeOffset
)
;
writer
.
guardShape
(
objId
ptr
.
unbarrieredGet
(
)
)
;
}
break
;
}
default
:
cloner
.
cloneOp
(
op
reader
writer
)
;
break
;
}
}
if
(
!
success
)
{
return
true
;
}
fallback
-
>
discardStubs
(
cx
-
>
zone
(
)
icEntry
)
;
ICAttachResult
result
=
AttachBaselineCacheIRStub
(
cx
writer
cacheKind
script
icScript
fallback
"
StubFold
"
)
;
if
(
result
=
=
ICAttachResult
:
:
OOM
)
{
ReportOutOfMemory
(
cx
)
;
return
false
;
}
MOZ_ASSERT
(
result
=
=
ICAttachResult
:
:
Attached
)
;
JitSpew
(
JitSpew_StubFolding
"
Folded
stub
at
offset
%
u
(
icScript
:
%
p
)
with
%
zu
shapes
(
%
s
:
%
u
:
%
u
)
"
fallback
-
>
pcOffset
(
)
icScript
shapeList
.
length
(
)
script
-
>
filename
(
)
script
-
>
lineno
(
)
script
-
>
column
(
)
.
oneOriginValue
(
)
)
;
fallback
-
>
setMayHaveFoldedStub
(
)
;
return
true
;
}
static
bool
AddToFoldedStub
(
JSContext
*
cx
const
CacheIRWriter
&
writer
ICScript
*
icScript
ICFallbackStub
*
fallback
)
{
ICEntry
*
icEntry
=
icScript
-
>
icEntryForStub
(
fallback
)
;
ICStub
*
entryStub
=
icEntry
-
>
firstStub
(
)
;
if
(
entryStub
=
=
fallback
)
{
return
false
;
}
ICCacheIRStub
*
stub
=
entryStub
-
>
toCacheIRStub
(
)
;
if
(
!
stub
-
>
next
(
)
-
>
isFallback
(
)
)
{
return
false
;
}
const
CacheIRStubInfo
*
stubInfo
=
stub
-
>
stubInfo
(
)
;
const
uint8_t
*
stubData
=
stub
-
>
stubDataStart
(
)
;
Maybe
<
uint32_t
>
shapeFieldOffset
;
RootedValue
newShape
(
cx
)
;
Rooted
<
ShapeListObject
*
>
foldedShapes
(
cx
)
;
CacheIRReader
stubReader
(
stubInfo
)
;
CacheIRReader
newReader
(
writer
)
;
while
(
newReader
.
more
(
)
&
&
stubReader
.
more
(
)
)
{
CacheOp
newOp
=
newReader
.
readOp
(
)
;
CacheOp
stubOp
=
stubReader
.
readOp
(
)
;
switch
(
stubOp
)
{
case
CacheOp
:
:
GuardMultipleShapes
:
{
if
(
newOp
!
=
CacheOp
:
:
GuardShape
)
{
return
false
;
}
if
(
newReader
.
objOperandId
(
)
!
=
stubReader
.
objOperandId
(
)
)
{
return
false
;
}
uint32_t
newShapeOffset
=
newReader
.
stubOffset
(
)
;
uint32_t
stubShapesOffset
=
stubReader
.
stubOffset
(
)
;
if
(
newShapeOffset
!
=
stubShapesOffset
)
{
return
false
;
}
MOZ_ASSERT
(
shapeFieldOffset
.
isNothing
(
)
)
;
shapeFieldOffset
.
emplace
(
newShapeOffset
)
;
StubField
shapeField
=
writer
.
readStubField
(
newShapeOffset
StubField
:
:
Type
:
:
WeakShape
)
;
Shape
*
shape
=
reinterpret_cast
<
Shape
*
>
(
shapeField
.
asWord
(
)
)
;
newShape
=
PrivateValue
(
shape
)
;
JSObject
*
shapeList
=
stubInfo
-
>
getStubField
<
StubField
:
:
Type
:
:
JSObject
>
(
stub
stubShapesOffset
)
;
foldedShapes
=
&
shapeList
-
>
as
<
ShapeListObject
>
(
)
;
MOZ_ASSERT
(
foldedShapes
-
>
compartment
(
)
=
=
shape
-
>
compartment
(
)
)
;
MOZ_ASSERT_IF
(
!
foldedShapes
-
>
isEmpty
(
)
foldedShapes
-
>
get
(
0
)
-
>
realm
(
)
=
=
foldedShapes
-
>
realm
(
)
)
;
if
(
foldedShapes
-
>
realm
(
)
!
=
shape
-
>
realm
(
)
)
{
return
false
;
}
break
;
}
default
:
{
if
(
newOp
!
=
stubOp
)
{
return
false
;
}
uint32_t
argLength
=
CacheIROpInfos
[
size_t
(
newOp
)
]
.
argLength
;
for
(
uint32_t
i
=
0
;
i
<
argLength
;
i
+
+
)
{
if
(
newReader
.
readByte
(
)
!
=
stubReader
.
readByte
(
)
)
{
return
false
;
}
}
}
}
}
if
(
shapeFieldOffset
.
isNothing
(
)
)
{
return
false
;
}
if
(
!
writer
.
stubDataEqualsIgnoring
(
stubData
*
shapeFieldOffset
)
)
{
return
false
;
}
if
(
foldedShapes
-
>
length
(
)
=
=
MaxFoldedShapes
)
{
return
false
;
}
if
(
!
foldedShapes
-
>
append
(
cx
newShape
)
)
{
cx
-
>
recoverFromOutOfMemory
(
)
;
return
false
;
}
JitSpew
(
JitSpew_StubFolding
"
ShapeListObject
%
p
:
new
length
:
%
u
"
foldedShapes
.
get
(
)
foldedShapes
-
>
length
(
)
)
;
return
true
;
}
ICAttachResult
js
:
:
jit
:
:
AttachBaselineCacheIRStub
(
JSContext
*
cx
const
CacheIRWriter
&
writer
CacheKind
kind
JSScript
*
outerScript
ICScript
*
icScript
ICFallbackStub
*
stub
const
char
*
name
)
{
AutoAssertNoPendingException
aanpe
(
cx
)
;
JS
:
:
AutoCheckCannotGC
nogc
;
if
(
writer
.
tooLarge
(
)
)
{
return
ICAttachResult
:
:
TooLarge
;
}
if
(
writer
.
oom
(
)
)
{
return
ICAttachResult
:
:
OOM
;
}
MOZ_ASSERT
(
!
writer
.
failed
(
)
)
;
#
ifdef
DEBUG
static
const
size_t
MaxOptimizedCacheIRStubs
=
16
;
MOZ_ASSERT
(
stub
-
>
numOptimizedStubs
(
)
<
MaxOptimizedCacheIRStubs
)
;
#
endif
constexpr
uint32_t
stubDataOffset
=
sizeof
(
ICCacheIRStub
)
;
static_assert
(
stubDataOffset
%
sizeof
(
uint64_t
)
=
=
0
"
Stub
fields
must
be
aligned
"
)
;
JitZone
*
jitZone
=
cx
-
>
zone
(
)
-
>
jitZone
(
)
;
CacheIRStubInfo
*
stubInfo
;
CacheIRStubKey
:
:
Lookup
lookup
(
kind
ICStubEngine
:
:
Baseline
writer
.
codeStart
(
)
writer
.
codeLength
(
)
)
;
JitCode
*
code
=
jitZone
-
>
getBaselineCacheIRStubCode
(
lookup
&
stubInfo
)
;
if
(
!
code
&
&
!
IsPortableBaselineInterpreterEnabled
(
)
)
{
TempAllocator
temp
(
&
cx
-
>
tempLifoAlloc
(
)
)
;
JitContext
jctx
(
cx
)
;
BaselineCacheIRCompiler
comp
(
cx
temp
writer
stubDataOffset
)
;
if
(
!
comp
.
init
(
kind
)
)
{
return
ICAttachResult
:
:
OOM
;
}
code
=
comp
.
compile
(
)
;
if
(
!
code
)
{
return
ICAttachResult
:
:
OOM
;
}
comp
.
perfSpewer
(
)
.
saveProfile
(
code
name
)
;
MOZ_ASSERT
(
!
stubInfo
)
;
stubInfo
=
CacheIRStubInfo
:
:
New
(
kind
ICStubEngine
:
:
Baseline
comp
.
makesGCCalls
(
)
stubDataOffset
writer
)
;
if
(
!
stubInfo
)
{
return
ICAttachResult
:
:
OOM
;
}
CacheIRStubKey
key
(
stubInfo
)
;
if
(
!
jitZone
-
>
putBaselineCacheIRStubCode
(
lookup
key
code
)
)
{
return
ICAttachResult
:
:
OOM
;
}
}
else
if
(
!
stubInfo
)
{
MOZ_ASSERT
(
IsPortableBaselineInterpreterEnabled
(
)
)
;
stubInfo
=
CacheIRStubInfo
:
:
New
(
kind
ICStubEngine
:
:
Baseline
true
stubDataOffset
writer
)
;
if
(
!
stubInfo
)
{
return
ICAttachResult
:
:
OOM
;
}
CacheIRStubKey
key
(
stubInfo
)
;
if
(
!
jitZone
-
>
putBaselineCacheIRStubCode
(
lookup
key
nullptr
)
)
{
return
ICAttachResult
:
:
OOM
;
}
}
MOZ_ASSERT_IF
(
IsBaselineInterpreterEnabled
(
)
code
)
;
MOZ_ASSERT
(
stubInfo
)
;
MOZ_ASSERT
(
stubInfo
-
>
stubDataSize
(
)
=
=
writer
.
stubDataSize
(
)
)
;
ICEntry
*
icEntry
=
icScript
-
>
icEntryForStub
(
stub
)
;
for
(
ICStub
*
iter
=
icEntry
-
>
firstStub
(
)
;
iter
!
=
stub
;
iter
=
iter
-
>
toCacheIRStub
(
)
-
>
next
(
)
)
{
auto
otherStub
=
iter
-
>
toCacheIRStub
(
)
;
if
(
otherStub
-
>
stubInfo
(
)
!
=
stubInfo
)
{
continue
;
}
if
(
!
writer
.
stubDataEquals
(
otherStub
-
>
stubDataStart
(
)
)
)
{
continue
;
}
JitSpew
(
JitSpew_BaselineICFallback
"
Tried
attaching
identical
stub
for
(
%
s
:
%
u
:
%
u
)
"
outerScript
-
>
filename
(
)
outerScript
-
>
lineno
(
)
outerScript
-
>
column
(
)
.
oneOriginValue
(
)
)
;
return
ICAttachResult
:
:
DuplicateStub
;
}
if
(
stub
-
>
mayHaveFoldedStub
(
)
&
&
AddToFoldedStub
(
cx
writer
icScript
stub
)
)
{
JitSpew
(
JitSpew_StubFolding
"
Added
to
folded
stub
at
offset
%
u
(
icScript
:
%
p
)
(
%
s
:
%
u
:
%
u
)
"
stub
-
>
pcOffset
(
)
icScript
outerScript
-
>
filename
(
)
outerScript
-
>
lineno
(
)
outerScript
-
>
column
(
)
.
oneOriginValue
(
)
)
;
stub
-
>
resetEnteredCount
(
)
;
JSScript
*
owningScript
=
nullptr
;
if
(
cx
-
>
zone
(
)
-
>
jitZone
(
)
-
>
hasStubFoldingBailoutData
(
outerScript
)
)
{
owningScript
=
cx
-
>
zone
(
)
-
>
jitZone
(
)
-
>
stubFoldingBailoutParent
(
)
;
JitSpew
(
JitSpew_StubFolding
"
Found
stub
folding
bailout
parent
:
%
s
:
%
u
:
%
u
"
owningScript
-
>
filename
(
)
owningScript
-
>
lineno
(
)
owningScript
-
>
column
(
)
.
oneOriginValue
(
)
)
;
}
else
{
owningScript
=
icScript
-
>
isInlined
(
)
?
icScript
-
>
inliningRoot
(
)
-
>
owningScript
(
)
:
outerScript
;
}
cx
-
>
zone
(
)
-
>
jitZone
(
)
-
>
clearStubFoldingBailoutData
(
)
;
if
(
stub
-
>
usedByTranspiler
(
)
)
{
if
(
owningScript
-
>
hasIonScript
(
)
)
{
owningScript
-
>
ionScript
(
)
-
>
resetNumFixableBailouts
(
)
;
}
else
if
(
owningScript
-
>
hasJitScript
(
)
)
{
owningScript
-
>
jitScript
(
)
-
>
clearFailedICHash
(
)
;
}
}
else
{
owningScript
-
>
updateLastICStubCounter
(
)
;
}
return
ICAttachResult
:
:
Attached
;
}
size_t
bytesNeeded
=
stubInfo
-
>
stubDataOffset
(
)
+
stubInfo
-
>
stubDataSize
(
)
;
void
*
newStubMem
=
jitZone
-
>
stubSpace
(
)
-
>
alloc
(
bytesNeeded
)
;
if
(
!
newStubMem
)
{
return
ICAttachResult
:
:
OOM
;
}
ResetEnteredCounts
(
icEntry
)
;
switch
(
stub
-
>
trialInliningState
(
)
)
{
case
TrialInliningState
:
:
Initial
:
case
TrialInliningState
:
:
Candidate
:
stub
-
>
setTrialInliningState
(
writer
.
trialInliningState
(
)
)
;
break
;
case
TrialInliningState
:
:
MonomorphicInlined
:
stub
-
>
setTrialInliningState
(
TrialInliningState
:
:
Failure
)
;
break
;
case
TrialInliningState
:
:
Inlined
:
stub
-
>
setTrialInliningState
(
TrialInliningState
:
:
Failure
)
;
icScript
-
>
removeInlinedChild
(
stub
-
>
pcOffset
(
)
)
;
break
;
case
TrialInliningState
:
:
Failure
:
break
;
}
auto
newStub
=
new
(
newStubMem
)
ICCacheIRStub
(
code
stubInfo
)
;
writer
.
copyStubData
(
newStub
-
>
stubDataStart
(
)
)
;
newStub
-
>
setTypeData
(
writer
.
typeData
(
)
)
;
stub
-
>
addNewStub
(
icEntry
newStub
)
;
JSScript
*
owningScript
=
icScript
-
>
isInlined
(
)
?
icScript
-
>
inliningRoot
(
)
-
>
owningScript
(
)
:
outerScript
;
owningScript
-
>
updateLastICStubCounter
(
)
;
return
ICAttachResult
:
:
Attached
;
}
uint8_t
*
ICCacheIRStub
:
:
stubDataStart
(
)
{
return
reinterpret_cast
<
uint8_t
*
>
(
this
)
+
stubInfo_
-
>
stubDataOffset
(
)
;
}
bool
BaselineCacheIRCompiler
:
:
emitCallStringObjectConcatResult
(
ValOperandId
lhsId
ValOperandId
rhsId
)
{
JitSpew
(
JitSpew_Codegen
"
%
s
"
__FUNCTION__
)
;
ValueOperand
lhs
=
allocator
.
useValueRegister
(
masm
lhsId
)
;
ValueOperand
rhs
=
allocator
.
useValueRegister
(
masm
rhsId
)
;
AutoScratchRegister
scratch
(
allocator
masm
)
;
allocator
.
discardStack
(
masm
)
;
AutoStubFrame
stubFrame
(
*
this
)
;
stubFrame
.
enter
(
masm
scratch
)
;
masm
.
pushValue
(
rhs
)
;
masm
.
pushValue
(
lhs
)
;
using
Fn
=
bool
(
*
)
(
JSContext
*
HandleValue
HandleValue
MutableHandleValue
)
;
callVM
<
Fn
DoConcatStringObject
>
(
masm
)
;
stubFrame
.
leave
(
masm
)
;
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
updateArgc
(
CallFlags
flags
Register
argcReg
Register
scratch
)
{
CallFlags
:
:
ArgFormat
format
=
flags
.
getArgFormat
(
)
;
switch
(
format
)
{
case
CallFlags
:
:
Standard
:
return
true
;
case
CallFlags
:
:
FunCall
:
return
true
;
case
CallFlags
:
:
FunApplyNullUndefined
:
masm
.
move32
(
Imm32
(
0
)
argcReg
)
;
return
true
;
default
:
break
;
}
FailurePath
*
failure
;
if
(
!
addFailurePath
(
&
failure
)
)
{
return
false
;
}
switch
(
flags
.
getArgFormat
(
)
)
{
case
CallFlags
:
:
Spread
:
case
CallFlags
:
:
FunApplyArray
:
{
BaselineFrameSlot
slot
(
flags
.
isConstructing
(
)
)
;
masm
.
unboxObject
(
allocator
.
addressOf
(
masm
slot
)
scratch
)
;
masm
.
loadPtr
(
Address
(
scratch
NativeObject
:
:
offsetOfElements
(
)
)
scratch
)
;
masm
.
load32
(
Address
(
scratch
ObjectElements
:
:
offsetOfLength
(
)
)
scratch
)
;
break
;
}
case
CallFlags
:
:
FunApplyArgsObj
:
{
BaselineFrameSlot
slot
(
0
)
;
masm
.
unboxObject
(
allocator
.
addressOf
(
masm
slot
)
scratch
)
;
masm
.
loadArgumentsObjectLength
(
scratch
scratch
failure
-
>
label
(
)
)
;
break
;
}
default
:
MOZ_CRASH
(
"
Unknown
arg
format
"
)
;
}
masm
.
branch32
(
Assembler
:
:
Above
scratch
Imm32
(
JIT_ARGS_LENGTH_MAX
)
failure
-
>
label
(
)
)
;
masm
.
move32
(
scratch
argcReg
)
;
return
true
;
}
void
BaselineCacheIRCompiler
:
:
pushArguments
(
Register
argcReg
Register
calleeReg
Register
scratch
Register
scratch2
CallFlags
flags
uint32_t
argcFixed
bool
isJitCall
)
{
switch
(
flags
.
getArgFormat
(
)
)
{
case
CallFlags
:
:
Standard
:
pushStandardArguments
(
argcReg
scratch
scratch2
argcFixed
isJitCall
flags
.
isConstructing
(
)
)
;
break
;
case
CallFlags
:
:
Spread
:
pushArrayArguments
(
argcReg
scratch
scratch2
isJitCall
flags
.
isConstructing
(
)
)
;
break
;
case
CallFlags
:
:
FunCall
:
pushFunCallArguments
(
argcReg
calleeReg
scratch
scratch2
argcFixed
isJitCall
)
;
break
;
case
CallFlags
:
:
FunApplyArgsObj
:
pushFunApplyArgsObj
(
argcReg
calleeReg
scratch
scratch2
isJitCall
)
;
break
;
case
CallFlags
:
:
FunApplyArray
:
pushArrayArguments
(
argcReg
scratch
scratch2
isJitCall
false
)
;
break
;
case
CallFlags
:
:
FunApplyNullUndefined
:
pushFunApplyNullUndefinedArguments
(
calleeReg
isJitCall
)
;
break
;
default
:
MOZ_CRASH
(
"
Invalid
arg
format
"
)
;
}
}
void
BaselineCacheIRCompiler
:
:
pushStandardArguments
(
Register
argcReg
Register
scratch
Register
scratch2
uint32_t
argcFixed
bool
isJitCall
bool
isConstructing
)
{
MOZ_ASSERT
(
enteredStubFrame_
)
;
int
additionalArgc
=
1
+
!
isJitCall
+
isConstructing
;
if
(
argcFixed
<
MaxUnrolledArgCopy
)
{
#
ifdef
DEBUG
Label
ok
;
masm
.
branch32
(
Assembler
:
:
Equal
argcReg
Imm32
(
argcFixed
)
&
ok
)
;
masm
.
assumeUnreachable
(
"
Invalid
argcFixed
value
"
)
;
masm
.
bind
(
&
ok
)
;
#
endif
size_t
realArgc
=
argcFixed
+
additionalArgc
;
if
(
isJitCall
)
{
masm
.
alignJitStackBasedOnNArgs
(
realArgc
true
)
;
}
for
(
size_t
i
=
0
;
i
<
realArgc
;
+
+
i
)
{
masm
.
pushValue
(
Address
(
FramePointer
BaselineStubFrameLayout
:
:
Size
(
)
+
i
*
sizeof
(
Value
)
)
)
;
}
}
else
{
MOZ_ASSERT
(
argcFixed
=
=
MaxUnrolledArgCopy
)
;
Register
argPtr
=
scratch2
;
Address
argAddress
(
FramePointer
BaselineStubFrameLayout
:
:
Size
(
)
)
;
masm
.
computeEffectiveAddress
(
argAddress
argPtr
)
;
Register
countReg
=
scratch
;
masm
.
move32
(
argcReg
countReg
)
;
masm
.
add32
(
Imm32
(
additionalArgc
)
countReg
)
;
if
(
isJitCall
)
{
masm
.
alignJitStackBasedOnNArgs
(
countReg
true
)
;
}
Label
loop
done
;
masm
.
branchTest32
(
Assembler
:
:
Zero
countReg
countReg
&
done
)
;
masm
.
bind
(
&
loop
)
;
{
masm
.
pushValue
(
Address
(
argPtr
0
)
)
;
masm
.
addPtr
(
Imm32
(
sizeof
(
Value
)
)
argPtr
)
;
masm
.
branchSub32
(
Assembler
:
:
NonZero
Imm32
(
1
)
countReg
&
loop
)
;
}
masm
.
bind
(
&
done
)
;
}
}
void
BaselineCacheIRCompiler
:
:
pushArrayArguments
(
Register
argcReg
Register
scratch
Register
scratch2
bool
isJitCall
bool
isConstructing
)
{
MOZ_ASSERT
(
enteredStubFrame_
)
;
Register
startReg
=
scratch
;
size_t
arrayOffset
=
(
isConstructing
*
sizeof
(
Value
)
)
+
BaselineStubFrameLayout
:
:
Size
(
)
;
masm
.
unboxObject
(
Address
(
FramePointer
arrayOffset
)
startReg
)
;
masm
.
loadPtr
(
Address
(
startReg
NativeObject
:
:
offsetOfElements
(
)
)
startReg
)
;
if
(
isJitCall
)
{
Register
alignReg
=
argcReg
;
if
(
isConstructing
)
{
alignReg
=
scratch2
;
masm
.
computeEffectiveAddress
(
Address
(
argcReg
1
)
alignReg
)
;
}
masm
.
alignJitStackBasedOnNArgs
(
alignReg
false
)
;
}
if
(
isConstructing
)
{
masm
.
pushValue
(
Address
(
FramePointer
BaselineStubFrameLayout
:
:
Size
(
)
)
)
;
}
Register
endReg
=
scratch2
;
BaseValueIndex
endAddr
(
startReg
argcReg
)
;
masm
.
computeEffectiveAddress
(
endAddr
endReg
)
;
Label
copyDone
;
Label
copyStart
;
masm
.
bind
(
&
copyStart
)
;
masm
.
branchPtr
(
Assembler
:
:
Equal
endReg
startReg
&
copyDone
)
;
masm
.
subPtr
(
Imm32
(
sizeof
(
Value
)
)
endReg
)
;
masm
.
pushValue
(
Address
(
endReg
0
)
)
;
masm
.
jump
(
&
copyStart
)
;
masm
.
bind
(
&
copyDone
)
;
size_t
thisvOffset
=
BaselineStubFrameLayout
:
:
Size
(
)
+
(
1
+
isConstructing
)
*
sizeof
(
Value
)
;
masm
.
pushValue
(
Address
(
FramePointer
thisvOffset
)
)
;
if
(
!
isJitCall
)
{
size_t
calleeOffset
=
BaselineStubFrameLayout
:
:
Size
(
)
+
(
2
+
isConstructing
)
*
sizeof
(
Value
)
;
masm
.
pushValue
(
Address
(
FramePointer
calleeOffset
)
)
;
}
}
void
BaselineCacheIRCompiler
:
:
pushFunApplyNullUndefinedArguments
(
Register
calleeReg
bool
isJitCall
)
{
MOZ_ASSERT
(
enteredStubFrame_
)
;
if
(
isJitCall
)
{
masm
.
alignJitStackBasedOnNArgs
(
0
false
)
;
}
size_t
thisvOffset
=
BaselineStubFrameLayout
:
:
Size
(
)
+
1
*
sizeof
(
Value
)
;
masm
.
pushValue
(
Address
(
FramePointer
thisvOffset
)
)
;
if
(
!
isJitCall
)
{
masm
.
Push
(
TypedOrValueRegister
(
MIRType
:
:
Object
AnyRegister
(
calleeReg
)
)
)
;
}
}
void
BaselineCacheIRCompiler
:
:
pushFunCallArguments
(
Register
argcReg
Register
calleeReg
Register
scratch
Register
scratch2
uint32_t
argcFixed
bool
isJitCall
)
{
if
(
argcFixed
=
=
0
)
{
if
(
isJitCall
)
{
masm
.
alignJitStackBasedOnNArgs
(
0
false
)
;
}
masm
.
pushValue
(
UndefinedValue
(
)
)
;
if
(
!
isJitCall
)
{
masm
.
Push
(
TypedOrValueRegister
(
MIRType
:
:
Object
AnyRegister
(
calleeReg
)
)
)
;
}
}
else
if
(
argcFixed
<
MaxUnrolledArgCopy
)
{
argcFixed
-
=
1
;
masm
.
sub32
(
Imm32
(
1
)
argcReg
)
;
pushStandardArguments
(
argcReg
scratch
scratch2
argcFixed
isJitCall
false
)
;
}
else
{
Label
zeroArgs
done
;
masm
.
branchTest32
(
Assembler
:
:
Zero
argcReg
argcReg
&
zeroArgs
)
;
masm
.
sub32
(
Imm32
(
1
)
argcReg
)
;
pushStandardArguments
(
argcReg
scratch
scratch2
argcFixed
isJitCall
false
)
;
masm
.
jump
(
&
done
)
;
masm
.
bind
(
&
zeroArgs
)
;
if
(
isJitCall
)
{
masm
.
alignJitStackBasedOnNArgs
(
0
false
)
;
}
masm
.
pushValue
(
UndefinedValue
(
)
)
;
if
(
!
isJitCall
)
{
masm
.
Push
(
TypedOrValueRegister
(
MIRType
:
:
Object
AnyRegister
(
calleeReg
)
)
)
;
}
masm
.
bind
(
&
done
)
;
}
}
void
BaselineCacheIRCompiler
:
:
pushFunApplyArgsObj
(
Register
argcReg
Register
calleeReg
Register
scratch
Register
scratch2
bool
isJitCall
)
{
MOZ_ASSERT
(
enteredStubFrame_
)
;
Register
argsReg
=
scratch
;
masm
.
unboxObject
(
Address
(
FramePointer
BaselineStubFrameLayout
:
:
Size
(
)
)
argsReg
)
;
if
(
isJitCall
)
{
masm
.
alignJitStackBasedOnNArgs
(
argcReg
false
)
;
}
masm
.
loadPrivate
(
Address
(
argsReg
ArgumentsObject
:
:
getDataSlotOffset
(
)
)
argsReg
)
;
Register
currReg
=
scratch2
;
Address
argsStartAddr
(
argsReg
ArgumentsData
:
:
offsetOfArgs
(
)
)
;
masm
.
computeEffectiveAddress
(
argsStartAddr
argsReg
)
;
BaseValueIndex
argsEndAddr
(
argsReg
argcReg
)
;
masm
.
computeEffectiveAddress
(
argsEndAddr
currReg
)
;
Label
done
loop
;
masm
.
bind
(
&
loop
)
;
masm
.
branchPtr
(
Assembler
:
:
Equal
currReg
argsReg
&
done
)
;
masm
.
subPtr
(
Imm32
(
sizeof
(
Value
)
)
currReg
)
;
Address
currArgAddr
(
currReg
0
)
;
#
ifdef
DEBUG
Label
notForwarded
;
masm
.
branchTestMagic
(
Assembler
:
:
NotEqual
currArgAddr
&
notForwarded
)
;
masm
.
assumeUnreachable
(
"
Should
have
checked
for
overridden
elements
"
)
;
masm
.
bind
(
&
notForwarded
)
;
#
endif
masm
.
pushValue
(
currArgAddr
)
;
masm
.
jump
(
&
loop
)
;
masm
.
bind
(
&
done
)
;
masm
.
pushValue
(
Address
(
FramePointer
BaselineStubFrameLayout
:
:
Size
(
)
+
sizeof
(
Value
)
)
)
;
if
(
!
isJitCall
)
{
masm
.
Push
(
TypedOrValueRegister
(
MIRType
:
:
Object
AnyRegister
(
calleeReg
)
)
)
;
}
}
void
BaselineCacheIRCompiler
:
:
pushBoundFunctionArguments
(
Register
argcReg
Register
calleeReg
Register
scratch
Register
scratch2
CallFlags
flags
uint32_t
numBoundArgs
bool
isJitCall
)
{
bool
isConstructing
=
flags
.
isConstructing
(
)
;
uint32_t
additionalArgc
=
1
+
isConstructing
;
Register
countReg
=
scratch
;
masm
.
computeEffectiveAddress
(
Address
(
argcReg
numBoundArgs
+
additionalArgc
)
countReg
)
;
if
(
isJitCall
)
{
masm
.
alignJitStackBasedOnNArgs
(
countReg
true
)
;
}
if
(
isConstructing
)
{
Address
boundTarget
(
calleeReg
BoundFunctionObject
:
:
offsetOfTargetSlot
(
)
)
;
masm
.
pushValue
(
boundTarget
)
;
}
Register
argPtr
=
scratch2
;
Address
argAddress
(
FramePointer
BaselineStubFrameLayout
:
:
Size
(
)
)
;
if
(
isConstructing
)
{
argAddress
.
offset
+
=
sizeof
(
Value
)
;
}
masm
.
computeEffectiveAddress
(
argAddress
argPtr
)
;
Label
loop
done
;
masm
.
branchTest32
(
Assembler
:
:
Zero
argcReg
argcReg
&
done
)
;
masm
.
move32
(
argcReg
countReg
)
;
masm
.
bind
(
&
loop
)
;
{
masm
.
pushValue
(
Address
(
argPtr
0
)
)
;
masm
.
addPtr
(
Imm32
(
sizeof
(
Value
)
)
argPtr
)
;
masm
.
branchSub32
(
Assembler
:
:
NonZero
Imm32
(
1
)
countReg
&
loop
)
;
}
masm
.
bind
(
&
done
)
;
constexpr
size_t
inlineArgsOffset
=
BoundFunctionObject
:
:
offsetOfFirstInlineBoundArg
(
)
;
if
(
numBoundArgs
<
=
BoundFunctionObject
:
:
MaxInlineBoundArgs
)
{
for
(
size_t
i
=
0
;
i
<
numBoundArgs
;
i
+
+
)
{
size_t
argIndex
=
numBoundArgs
-
i
-
1
;
Address
argAddr
(
calleeReg
inlineArgsOffset
+
argIndex
*
sizeof
(
Value
)
)
;
masm
.
pushValue
(
argAddr
)
;
}
}
else
{
masm
.
unboxObject
(
Address
(
calleeReg
inlineArgsOffset
)
scratch
)
;
masm
.
loadPtr
(
Address
(
scratch
NativeObject
:
:
offsetOfElements
(
)
)
scratch
)
;
for
(
size_t
i
=
0
;
i
<
numBoundArgs
;
i
+
+
)
{
size_t
argIndex
=
numBoundArgs
-
i
-
1
;
Address
argAddr
(
scratch
argIndex
*
sizeof
(
Value
)
)
;
masm
.
pushValue
(
argAddr
)
;
}
}
if
(
isConstructing
)
{
BaseValueIndex
thisAddress
(
FramePointer
argcReg
BaselineStubFrameLayout
:
:
Size
(
)
+
sizeof
(
Value
)
)
;
masm
.
pushValue
(
thisAddress
scratch
)
;
}
else
{
Address
boundThis
(
calleeReg
BoundFunctionObject
:
:
offsetOfBoundThisSlot
(
)
)
;
masm
.
pushValue
(
boundThis
)
;
}
}
bool
BaselineCacheIRCompiler
:
:
emitCallNativeShared
(
NativeCallType
callType
ObjOperandId
calleeId
Int32OperandId
argcId
CallFlags
flags
uint32_t
argcFixed
Maybe
<
bool
>
ignoresReturnValue
Maybe
<
uint32_t
>
targetOffset
)
{
AutoOutputRegister
output
(
*
this
)
;
AutoScratchRegisterMaybeOutput
scratch
(
allocator
masm
output
)
;
AutoScratchRegister
scratch2
(
allocator
masm
)
;
Register
calleeReg
=
allocator
.
useRegister
(
masm
calleeId
)
;
Register
argcReg
=
allocator
.
useRegister
(
masm
argcId
)
;
bool
isConstructing
=
flags
.
isConstructing
(
)
;
bool
isSameRealm
=
flags
.
isSameRealm
(
)
;
if
(
!
updateArgc
(
flags
argcReg
scratch
)
)
{
return
false
;
}
allocator
.
discardStack
(
masm
)
;
AutoStubFrame
stubFrame
(
*
this
)
;
stubFrame
.
enter
(
masm
scratch
)
;
if
(
!
isSameRealm
)
{
masm
.
switchToObjectRealm
(
calleeReg
scratch
)
;
}
pushArguments
(
argcReg
calleeReg
scratch
scratch2
flags
argcFixed
false
)
;
masm
.
moveStackPtrTo
(
scratch2
.
get
(
)
)
;
masm
.
push
(
argcReg
)
;
masm
.
pushFrameDescriptor
(
FrameType
:
:
BaselineStub
)
;
masm
.
push
(
ICTailCallReg
)
;
masm
.
push
(
FramePointer
)
;
masm
.
loadJSContext
(
scratch
)
;
masm
.
enterFakeExitFrameForNative
(
scratch
scratch
isConstructing
)
;
masm
.
setupUnalignedABICall
(
scratch
)
;
masm
.
loadJSContext
(
scratch
)
;
masm
.
passABIArg
(
scratch
)
;
masm
.
passABIArg
(
argcReg
)
;
masm
.
passABIArg
(
scratch2
)
;
switch
(
callType
)
{
case
NativeCallType
:
:
Native
:
{
#
ifdef
JS_SIMULATOR
Address
redirectedAddr
(
stubAddress
(
*
targetOffset
)
)
;
masm
.
callWithABI
(
redirectedAddr
)
;
#
else
if
(
*
ignoresReturnValue
)
{
masm
.
loadPrivate
(
Address
(
calleeReg
JSFunction
:
:
offsetOfJitInfoOrScript
(
)
)
calleeReg
)
;
masm
.
callWithABI
(
Address
(
calleeReg
JSJitInfo
:
:
offsetOfIgnoresReturnValueNative
(
)
)
)
;
}
else
{
masm
.
callWithABI
(
Address
(
calleeReg
JSFunction
:
:
offsetOfNativeOrEnv
(
)
)
)
;
}
#
endif
}
break
;
case
NativeCallType
:
:
ClassHook
:
{
Address
nativeAddr
(
stubAddress
(
*
targetOffset
)
)
;
masm
.
callWithABI
(
nativeAddr
)
;
}
break
;
}
masm
.
branchIfFalseBool
(
ReturnReg
masm
.
exceptionLabel
(
)
)
;
masm
.
loadValue
(
Address
(
masm
.
getStackPointer
(
)
NativeExitFrameLayout
:
:
offsetOfResult
(
)
)
output
.
valueReg
(
)
)
;
stubFrame
.
leave
(
masm
)
;
if
(
!
isSameRealm
)
{
masm
.
switchToBaselineFrameRealm
(
scratch2
)
;
}
return
true
;
}
#
ifdef
JS_SIMULATOR
bool
BaselineCacheIRCompiler
:
:
emitCallNativeFunction
(
ObjOperandId
calleeId
Int32OperandId
argcId
CallFlags
flags
uint32_t
argcFixed
uint32_t
targetOffset
)
{
JitSpew
(
JitSpew_Codegen
"
%
s
"
__FUNCTION__
)
;
Maybe
<
bool
>
ignoresReturnValue
;
Maybe
<
uint32_t
>
targetOffset_
=
mozilla
:
:
Some
(
targetOffset
)
;
return
emitCallNativeShared
(
NativeCallType
:
:
Native
calleeId
argcId
flags
argcFixed
ignoresReturnValue
targetOffset_
)
;
}
bool
BaselineCacheIRCompiler
:
:
emitCallDOMFunction
(
ObjOperandId
calleeId
Int32OperandId
argcId
ObjOperandId
thisObjId
CallFlags
flags
uint32_t
argcFixed
uint32_t
targetOffset
)
{
JitSpew
(
JitSpew_Codegen
"
%
s
"
__FUNCTION__
)
;
Maybe
<
bool
>
ignoresReturnValue
;
Maybe
<
uint32_t
>
targetOffset_
=
mozilla
:
:
Some
(
targetOffset
)
;
return
emitCallNativeShared
(
NativeCallType
:
:
Native
calleeId
argcId
flags
argcFixed
ignoresReturnValue
targetOffset_
)
;
}
#
else
bool
BaselineCacheIRCompiler
:
:
emitCallNativeFunction
(
ObjOperandId
calleeId
Int32OperandId
argcId
CallFlags
flags
uint32_t
argcFixed
bool
ignoresReturnValue
)
{
JitSpew
(
JitSpew_Codegen
"
%
s
"
__FUNCTION__
)
;
Maybe
<
bool
>
ignoresReturnValue_
=
mozilla
:
:
Some
(
ignoresReturnValue
)
;
Maybe
<
uint32_t
>
targetOffset
;
return
emitCallNativeShared
(
NativeCallType
:
:
Native
calleeId
argcId
flags
argcFixed
ignoresReturnValue_
targetOffset
)
;
}
bool
BaselineCacheIRCompiler
:
:
emitCallDOMFunction
(
ObjOperandId
calleeId
Int32OperandId
argcId
ObjOperandId
thisObjId
CallFlags
flags
uint32_t
argcFixed
)
{
JitSpew
(
JitSpew_Codegen
"
%
s
"
__FUNCTION__
)
;
Maybe
<
bool
>
ignoresReturnValue
=
mozilla
:
:
Some
(
false
)
;
Maybe
<
uint32_t
>
targetOffset
;
return
emitCallNativeShared
(
NativeCallType
:
:
Native
calleeId
argcId
flags
argcFixed
ignoresReturnValue
targetOffset
)
;
}
#
endif
bool
BaselineCacheIRCompiler
:
:
emitCallClassHook
(
ObjOperandId
calleeId
Int32OperandId
argcId
CallFlags
flags
uint32_t
argcFixed
uint32_t
targetOffset
)
{
JitSpew
(
JitSpew_Codegen
"
%
s
"
__FUNCTION__
)
;
Maybe
<
bool
>
ignoresReturnValue
;
Maybe
<
uint32_t
>
targetOffset_
=
mozilla
:
:
Some
(
targetOffset
)
;
return
emitCallNativeShared
(
NativeCallType
:
:
ClassHook
calleeId
argcId
flags
argcFixed
ignoresReturnValue
targetOffset_
)
;
}
void
BaselineCacheIRCompiler
:
:
loadStackObject
(
ArgumentKind
kind
CallFlags
flags
Register
argcReg
Register
dest
)
{
MOZ_ASSERT
(
enteredStubFrame_
)
;
bool
addArgc
=
false
;
int32_t
slotIndex
=
GetIndexOfArgument
(
kind
flags
&
addArgc
)
;
if
(
addArgc
)
{
int32_t
slotOffset
=
slotIndex
*
sizeof
(
JS
:
:
Value
)
+
BaselineStubFrameLayout
:
:
Size
(
)
;
BaseValueIndex
slotAddr
(
FramePointer
argcReg
slotOffset
)
;
masm
.
unboxObject
(
slotAddr
dest
)
;
}
else
{
int32_t
slotOffset
=
slotIndex
*
sizeof
(
JS
:
:
Value
)
+
BaselineStubFrameLayout
:
:
Size
(
)
;
Address
slotAddr
(
FramePointer
slotOffset
)
;
masm
.
unboxObject
(
slotAddr
dest
)
;
}
}
template
<
typename
T
>
void
BaselineCacheIRCompiler
:
:
storeThis
(
const
T
&
newThis
Register
argcReg
CallFlags
flags
)
{
switch
(
flags
.
getArgFormat
(
)
)
{
case
CallFlags
:
:
Standard
:
{
BaseValueIndex
thisAddress
(
FramePointer
argcReg
1
*
sizeof
(
Value
)
+
BaselineStubFrameLayout
:
:
Size
(
)
)
;
masm
.
storeValue
(
newThis
thisAddress
)
;
}
break
;
case
CallFlags
:
:
Spread
:
{
Address
thisAddress
(
FramePointer
2
*
sizeof
(
Value
)
+
BaselineStubFrameLayout
:
:
Size
(
)
)
;
masm
.
storeValue
(
newThis
thisAddress
)
;
}
break
;
default
:
MOZ_CRASH
(
"
Invalid
arg
format
for
scripted
constructor
"
)
;
}
}
void
BaselineCacheIRCompiler
:
:
createThis
(
Register
argcReg
Register
calleeReg
Register
scratch
CallFlags
flags
bool
isBoundFunction
)
{
MOZ_ASSERT
(
flags
.
isConstructing
(
)
)
;
if
(
flags
.
needsUninitializedThis
(
)
)
{
storeThis
(
MagicValue
(
JS_UNINITIALIZED_LEXICAL
)
argcReg
flags
)
;
return
;
}
LiveGeneralRegisterSet
liveNonGCRegs
;
liveNonGCRegs
.
add
(
argcReg
)
;
masm
.
PushRegsInMask
(
liveNonGCRegs
)
;
if
(
isBoundFunction
)
{
Address
boundTarget
(
calleeReg
BoundFunctionObject
:
:
offsetOfTargetSlot
(
)
)
;
masm
.
unboxObject
(
boundTarget
scratch
)
;
masm
.
push
(
scratch
)
;
masm
.
push
(
scratch
)
;
}
else
{
loadStackObject
(
ArgumentKind
:
:
NewTarget
flags
argcReg
scratch
)
;
masm
.
push
(
scratch
)
;
loadStackObject
(
ArgumentKind
:
:
Callee
flags
argcReg
scratch
)
;
masm
.
push
(
scratch
)
;
}
using
Fn
=
bool
(
*
)
(
JSContext
*
HandleObject
HandleObject
MutableHandleValue
)
;
callVM
<
Fn
CreateThisFromIC
>
(
masm
)
;
#
ifdef
DEBUG
Label
createdThisOK
;
masm
.
branchTestObject
(
Assembler
:
:
Equal
JSReturnOperand
&
createdThisOK
)
;
masm
.
branchTestMagic
(
Assembler
:
:
Equal
JSReturnOperand
&
createdThisOK
)
;
masm
.
assumeUnreachable
(
"
The
return
of
CreateThis
must
be
an
object
or
uninitialized
.
"
)
;
masm
.
bind
(
&
createdThisOK
)
;
#
endif
masm
.
PopRegsInMask
(
liveNonGCRegs
)
;
Address
stubAddr
(
FramePointer
BaselineStubFrameLayout
:
:
ICStubOffsetFromFP
)
;
masm
.
loadPtr
(
stubAddr
ICStubReg
)
;
MOZ_ASSERT
(
!
liveNonGCRegs
.
aliases
(
JSReturnOperand
)
)
;
storeThis
(
JSReturnOperand
argcReg
flags
)
;
loadStackObject
(
ArgumentKind
:
:
Callee
flags
argcReg
calleeReg
)
;
}
void
BaselineCacheIRCompiler
:
:
updateReturnValue
(
)
{
Label
skipThisReplace
;
masm
.
branchTestObject
(
Assembler
:
:
Equal
JSReturnOperand
&
skipThisReplace
)
;
size_t
thisvOffset
=
JitFrameLayout
:
:
offsetOfThis
(
)
-
JitFrameLayout
:
:
bytesPoppedAfterCall
(
)
;
Address
thisAddress
(
masm
.
getStackPointer
(
)
thisvOffset
)
;
masm
.
loadValue
(
thisAddress
JSReturnOperand
)
;
#
ifdef
DEBUG
masm
.
branchTestObject
(
Assembler
:
:
Equal
JSReturnOperand
&
skipThisReplace
)
;
masm
.
assumeUnreachable
(
"
Return
of
constructing
call
should
be
an
object
.
"
)
;
#
endif
masm
.
bind
(
&
skipThisReplace
)
;
}
bool
BaselineCacheIRCompiler
:
:
emitCallScriptedFunction
(
ObjOperandId
calleeId
Int32OperandId
argcId
CallFlags
flags
uint32_t
argcFixed
)
{
JitSpew
(
JitSpew_Codegen
"
%
s
"
__FUNCTION__
)
;
AutoOutputRegister
output
(
*
this
)
;
AutoScratchRegisterMaybeOutput
scratch
(
allocator
masm
output
)
;
AutoScratchRegister
scratch2
(
allocator
masm
)
;
Register
calleeReg
=
allocator
.
useRegister
(
masm
calleeId
)
;
Register
argcReg
=
allocator
.
useRegister
(
masm
argcId
)
;
bool
isConstructing
=
flags
.
isConstructing
(
)
;
bool
isSameRealm
=
flags
.
isSameRealm
(
)
;
if
(
!
updateArgc
(
flags
argcReg
scratch
)
)
{
return
false
;
}
allocator
.
discardStack
(
masm
)
;
AutoStubFrame
stubFrame
(
*
this
)
;
stubFrame
.
enter
(
masm
scratch
)
;
if
(
!
isSameRealm
)
{
masm
.
switchToObjectRealm
(
calleeReg
scratch
)
;
}
if
(
isConstructing
)
{
createThis
(
argcReg
calleeReg
scratch
flags
false
)
;
}
pushArguments
(
argcReg
calleeReg
scratch
scratch2
flags
argcFixed
true
)
;
Register
code
=
scratch2
;
masm
.
loadJitCodeRaw
(
calleeReg
code
)
;
masm
.
PushCalleeToken
(
calleeReg
isConstructing
)
;
masm
.
PushFrameDescriptorForJitCall
(
FrameType
:
:
BaselineStub
argcReg
scratch
)
;
Label
noUnderflow
;
masm
.
loadFunctionArgCount
(
calleeReg
calleeReg
)
;
masm
.
branch32
(
Assembler
:
:
AboveOrEqual
argcReg
calleeReg
&
noUnderflow
)
;
{
TrampolinePtr
argumentsRectifier
=
cx_
-
>
runtime
(
)
-
>
jitRuntime
(
)
-
>
getArgumentsRectifier
(
)
;
masm
.
movePtr
(
argumentsRectifier
code
)
;
}
masm
.
bind
(
&
noUnderflow
)
;
masm
.
callJit
(
code
)
;
if
(
isConstructing
)
{
updateReturnValue
(
)
;
}
stubFrame
.
leave
(
masm
)
;
if
(
!
isSameRealm
)
{
masm
.
switchToBaselineFrameRealm
(
scratch2
)
;
}
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
emitCallWasmFunction
(
ObjOperandId
calleeId
Int32OperandId
argcId
CallFlags
flags
uint32_t
argcFixed
uint32_t
funcExportOffset
uint32_t
instanceOffset
)
{
return
emitCallScriptedFunction
(
calleeId
argcId
flags
argcFixed
)
;
}
bool
BaselineCacheIRCompiler
:
:
emitCallInlinedFunction
(
ObjOperandId
calleeId
Int32OperandId
argcId
uint32_t
icScriptOffset
CallFlags
flags
uint32_t
argcFixed
)
{
JitSpew
(
JitSpew_Codegen
"
%
s
"
__FUNCTION__
)
;
AutoOutputRegister
output
(
*
this
)
;
AutoScratchRegisterMaybeOutput
scratch
(
allocator
masm
output
)
;
AutoScratchRegisterMaybeOutputType
scratch2
(
allocator
masm
output
)
;
AutoScratchRegister
codeReg
(
allocator
masm
)
;
Register
calleeReg
=
allocator
.
useRegister
(
masm
calleeId
)
;
Register
argcReg
=
allocator
.
useRegister
(
masm
argcId
)
;
bool
isConstructing
=
flags
.
isConstructing
(
)
;
bool
isSameRealm
=
flags
.
isSameRealm
(
)
;
FailurePath
*
failure
;
if
(
!
addFailurePath
(
&
failure
)
)
{
return
false
;
}
masm
.
loadBaselineJitCodeRaw
(
calleeReg
codeReg
failure
-
>
label
(
)
)
;
if
(
!
updateArgc
(
flags
argcReg
scratch
)
)
{
return
false
;
}
allocator
.
discardStack
(
masm
)
;
AutoStubFrame
stubFrame
(
*
this
)
;
stubFrame
.
enter
(
masm
scratch
)
;
if
(
!
isSameRealm
)
{
masm
.
switchToObjectRealm
(
calleeReg
scratch
)
;
}
Label
baselineScriptDiscarded
;
if
(
isConstructing
)
{
createThis
(
argcReg
calleeReg
scratch
flags
false
)
;
masm
.
loadBaselineJitCodeRaw
(
calleeReg
codeReg
&
baselineScriptDiscarded
)
;
}
Address
icScriptAddr
(
stubAddress
(
icScriptOffset
)
)
;
masm
.
loadPtr
(
icScriptAddr
scratch
)
;
masm
.
storeICScriptInJSContext
(
scratch
)
;
if
(
isConstructing
)
{
Label
skip
;
masm
.
jump
(
&
skip
)
;
masm
.
bind
(
&
baselineScriptDiscarded
)
;
masm
.
loadJitCodeRaw
(
calleeReg
codeReg
)
;
masm
.
bind
(
&
skip
)
;
}
pushArguments
(
argcReg
calleeReg
scratch
scratch2
flags
argcFixed
true
)
;
masm
.
PushCalleeToken
(
calleeReg
isConstructing
)
;
masm
.
PushFrameDescriptorForJitCall
(
FrameType
:
:
BaselineStub
argcReg
scratch
)
;
Label
noUnderflow
;
masm
.
loadFunctionArgCount
(
calleeReg
calleeReg
)
;
masm
.
branch32
(
Assembler
:
:
AboveOrEqual
argcReg
calleeReg
&
noUnderflow
)
;
ArgumentsRectifierKind
kind
=
ArgumentsRectifierKind
:
:
TrialInlining
;
TrampolinePtr
argumentsRectifier
=
cx_
-
>
runtime
(
)
-
>
jitRuntime
(
)
-
>
getArgumentsRectifier
(
kind
)
;
masm
.
movePtr
(
argumentsRectifier
codeReg
)
;
masm
.
bind
(
&
noUnderflow
)
;
masm
.
callJit
(
codeReg
)
;
if
(
isConstructing
)
{
updateReturnValue
(
)
;
}
stubFrame
.
leave
(
masm
)
;
if
(
!
isSameRealm
)
{
masm
.
switchToBaselineFrameRealm
(
codeReg
)
;
}
return
true
;
}
#
ifdef
JS_PUNBOX64
template
<
typename
IdType
>
bool
BaselineCacheIRCompiler
:
:
emitCallScriptedProxyGetShared
(
ValOperandId
targetId
ObjOperandId
receiverId
ObjOperandId
handlerId
ObjOperandId
trapId
IdType
id
uint32_t
nargsAndFlags
)
{
Register
handler
=
allocator
.
useRegister
(
masm
handlerId
)
;
ValueOperand
target
=
allocator
.
useValueRegister
(
masm
targetId
)
;
Register
receiver
=
allocator
.
useRegister
(
masm
receiverId
)
;
Register
callee
=
allocator
.
useRegister
(
masm
trapId
)
;
ValueOperand
idVal
;
if
constexpr
(
std
:
:
is_same_v
<
IdType
ValOperandId
>
)
{
idVal
=
allocator
.
useValueRegister
(
masm
id
)
;
}
AutoScratchRegister
code
(
allocator
masm
)
;
AutoScratchRegister
scratch
(
allocator
masm
)
;
ValueOperand
scratchVal
(
scratch
)
;
allocator
.
discardStack
(
masm
)
;
AutoStubFrame
stubFrame
(
*
this
)
;
stubFrame
.
enter
(
masm
scratch
)
;
stubFrame
.
storeTracedValue
(
masm
target
)
;
if
constexpr
(
std
:
:
is_same_v
<
IdType
ValOperandId
>
)
{
stubFrame
.
storeTracedValue
(
masm
idVal
)
;
}
else
{
Address
idAddr
(
stubAddress
(
id
)
)
;
masm
.
loadPtr
(
idAddr
scratch
)
;
masm
.
tagValue
(
JSVAL_TYPE_STRING
scratch
scratchVal
)
;
stubFrame
.
storeTracedValue
(
masm
scratchVal
)
;
}
uint16_t
nargs
=
nargsAndFlags
>
>
JSFunction
:
:
ArgCountShift
;
masm
.
alignJitStackBasedOnNArgs
(
std
:
:
max
(
uint16_t
(
3
)
nargs
)
false
)
;
for
(
size_t
i
=
3
;
i
<
nargs
;
i
+
+
)
{
masm
.
Push
(
UndefinedValue
(
)
)
;
}
masm
.
tagValue
(
JSVAL_TYPE_OBJECT
receiver
scratchVal
)
;
masm
.
Push
(
scratchVal
)
;
if
constexpr
(
std
:
:
is_same_v
<
IdType
ValOperandId
>
)
{
masm
.
Push
(
idVal
)
;
}
else
{
stubFrame
.
loadTracedValue
(
masm
1
scratchVal
)
;
masm
.
Push
(
scratchVal
)
;
}
masm
.
Push
(
target
)
;
masm
.
tagValue
(
JSVAL_TYPE_OBJECT
handler
scratchVal
)
;
masm
.
Push
(
scratchVal
)
;
masm
.
loadJitCodeRaw
(
callee
code
)
;
masm
.
Push
(
callee
)
;
masm
.
PushFrameDescriptorForJitCall
(
FrameType
:
:
BaselineStub
3
)
;
masm
.
callJit
(
code
)
;
Register
scratch2
=
code
;
Label
success
;
stubFrame
.
loadTracedValue
(
masm
0
scratchVal
)
;
masm
.
unboxObject
(
scratchVal
scratch
)
;
masm
.
branchTestObjectNeedsProxyResultValidation
(
Assembler
:
:
Zero
scratch
scratch2
&
success
)
;
ValueOperand
scratchVal2
(
scratch2
)
;
stubFrame
.
loadTracedValue
(
masm
1
scratchVal2
)
;
masm
.
Push
(
JSReturnOperand
)
;
masm
.
Push
(
scratchVal2
)
;
masm
.
Push
(
scratch
)
;
using
Fn
=
bool
(
*
)
(
JSContext
*
HandleObject
HandleValue
HandleValue
MutableHandleValue
)
;
callVM
<
Fn
CheckProxyGetByValueResult
>
(
masm
)
;
masm
.
bind
(
&
success
)
;
stubFrame
.
leave
(
masm
)
;
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
emitCallScriptedProxyGetResult
(
ValOperandId
targetId
ObjOperandId
receiverId
ObjOperandId
handlerId
ObjOperandId
trapId
uint32_t
idOffset
uint32_t
nargsAndFlags
)
{
JitSpew
(
JitSpew_Codegen
"
%
s
"
__FUNCTION__
)
;
return
emitCallScriptedProxyGetShared
(
targetId
receiverId
handlerId
trapId
idOffset
nargsAndFlags
)
;
}
bool
BaselineCacheIRCompiler
:
:
emitCallScriptedProxyGetByValueResult
(
ValOperandId
targetId
ObjOperandId
receiverId
ObjOperandId
handlerId
ValOperandId
idId
ObjOperandId
trapId
uint32_t
nargsAndFlags
)
{
JitSpew
(
JitSpew_Codegen
"
%
s
"
__FUNCTION__
)
;
return
emitCallScriptedProxyGetShared
(
targetId
receiverId
handlerId
trapId
idId
nargsAndFlags
)
;
}
#
endif
bool
BaselineCacheIRCompiler
:
:
emitCallBoundScriptedFunction
(
ObjOperandId
calleeId
ObjOperandId
targetId
Int32OperandId
argcId
CallFlags
flags
uint32_t
numBoundArgs
)
{
JitSpew
(
JitSpew_Codegen
"
%
s
"
__FUNCTION__
)
;
AutoOutputRegister
output
(
*
this
)
;
AutoScratchRegisterMaybeOutput
scratch
(
allocator
masm
output
)
;
AutoScratchRegister
scratch2
(
allocator
masm
)
;
Register
calleeReg
=
allocator
.
useRegister
(
masm
calleeId
)
;
Register
argcReg
=
allocator
.
useRegister
(
masm
argcId
)
;
bool
isConstructing
=
flags
.
isConstructing
(
)
;
bool
isSameRealm
=
flags
.
isSameRealm
(
)
;
allocator
.
discardStack
(
masm
)
;
AutoStubFrame
stubFrame
(
*
this
)
;
stubFrame
.
enter
(
masm
scratch
)
;
Address
boundTarget
(
calleeReg
BoundFunctionObject
:
:
offsetOfTargetSlot
(
)
)
;
if
(
isConstructing
)
{
if
(
!
isSameRealm
)
{
masm
.
unboxObject
(
boundTarget
scratch
)
;
masm
.
switchToObjectRealm
(
scratch
scratch
)
;
}
createThis
(
argcReg
calleeReg
scratch
flags
true
)
;
}
pushBoundFunctionArguments
(
argcReg
calleeReg
scratch
scratch2
flags
numBoundArgs
true
)
;
masm
.
unboxObject
(
boundTarget
calleeReg
)
;
if
(
!
isConstructing
&
&
!
isSameRealm
)
{
masm
.
switchToObjectRealm
(
calleeReg
scratch
)
;
}
masm
.
add32
(
Imm32
(
numBoundArgs
)
argcReg
)
;
Register
code
=
scratch2
;
masm
.
loadJitCodeRaw
(
calleeReg
code
)
;
masm
.
PushCalleeToken
(
calleeReg
isConstructing
)
;
masm
.
PushFrameDescriptorForJitCall
(
FrameType
:
:
BaselineStub
argcReg
scratch
)
;
Label
noUnderflow
;
masm
.
loadFunctionArgCount
(
calleeReg
calleeReg
)
;
masm
.
branch32
(
Assembler
:
:
AboveOrEqual
argcReg
calleeReg
&
noUnderflow
)
;
{
TrampolinePtr
argumentsRectifier
=
cx_
-
>
runtime
(
)
-
>
jitRuntime
(
)
-
>
getArgumentsRectifier
(
)
;
masm
.
movePtr
(
argumentsRectifier
code
)
;
}
masm
.
bind
(
&
noUnderflow
)
;
masm
.
callJit
(
code
)
;
if
(
isConstructing
)
{
updateReturnValue
(
)
;
}
stubFrame
.
leave
(
masm
)
;
if
(
!
isSameRealm
)
{
masm
.
switchToBaselineFrameRealm
(
scratch2
)
;
}
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
emitNewArrayObjectResult
(
uint32_t
arrayLength
uint32_t
shapeOffset
uint32_t
siteOffset
)
{
JitSpew
(
JitSpew_Codegen
"
%
s
"
__FUNCTION__
)
;
gc
:
:
AllocKind
allocKind
=
GuessArrayGCKind
(
arrayLength
)
;
MOZ_ASSERT
(
CanChangeToBackgroundAllocKind
(
allocKind
&
ArrayObject
:
:
class_
)
)
;
allocKind
=
ForegroundToBackgroundAllocKind
(
allocKind
)
;
uint32_t
slotCount
=
GetGCKindSlots
(
allocKind
)
;
MOZ_ASSERT
(
slotCount
>
=
ObjectElements
:
:
VALUES_PER_HEADER
)
;
uint32_t
arrayCapacity
=
slotCount
-
ObjectElements
:
:
VALUES_PER_HEADER
;
AutoOutputRegister
output
(
*
this
)
;
AutoScratchRegister
result
(
allocator
masm
)
;
AutoScratchRegister
scratch
(
allocator
masm
)
;
AutoScratchRegister
site
(
allocator
masm
)
;
AutoScratchRegisterMaybeOutput
shape
(
allocator
masm
output
)
;
Address
shapeAddr
(
stubAddress
(
shapeOffset
)
)
;
masm
.
loadPtr
(
shapeAddr
shape
)
;
Address
siteAddr
(
stubAddress
(
siteOffset
)
)
;
masm
.
loadPtr
(
siteAddr
site
)
;
allocator
.
discardStack
(
masm
)
;
Label
done
;
Label
fail
;
masm
.
createArrayWithFixedElements
(
result
shape
scratch
InvalidReg
arrayLength
arrayCapacity
0
0
allocKind
gc
:
:
Heap
:
:
Default
&
fail
AllocSiteInput
(
site
)
)
;
masm
.
jump
(
&
done
)
;
{
masm
.
bind
(
&
fail
)
;
AutoStubFrame
stubFrame
(
*
this
)
;
stubFrame
.
enter
(
masm
scratch
)
;
masm
.
Push
(
site
)
;
masm
.
Push
(
Imm32
(
int32_t
(
allocKind
)
)
)
;
masm
.
Push
(
Imm32
(
arrayLength
)
)
;
using
Fn
=
ArrayObject
*
(
*
)
(
JSContext
*
uint32_t
gc
:
:
AllocKind
gc
:
:
AllocSite
*
)
;
callVM
<
Fn
NewArrayObjectBaselineFallback
>
(
masm
)
;
stubFrame
.
leave
(
masm
)
;
masm
.
storeCallPointerResult
(
result
)
;
}
masm
.
bind
(
&
done
)
;
masm
.
tagValue
(
JSVAL_TYPE_OBJECT
result
output
.
valueReg
(
)
)
;
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
emitNewPlainObjectResult
(
uint32_t
numFixedSlots
uint32_t
numDynamicSlots
gc
:
:
AllocKind
allocKind
uint32_t
shapeOffset
uint32_t
siteOffset
)
{
JitSpew
(
JitSpew_Codegen
"
%
s
"
__FUNCTION__
)
;
AutoOutputRegister
output
(
*
this
)
;
AutoScratchRegister
obj
(
allocator
masm
)
;
AutoScratchRegister
scratch
(
allocator
masm
)
;
AutoScratchRegister
site
(
allocator
masm
)
;
AutoScratchRegisterMaybeOutput
shape
(
allocator
masm
output
)
;
Address
shapeAddr
(
stubAddress
(
shapeOffset
)
)
;
masm
.
loadPtr
(
shapeAddr
shape
)
;
Address
siteAddr
(
stubAddress
(
siteOffset
)
)
;
masm
.
loadPtr
(
siteAddr
site
)
;
allocator
.
discardStack
(
masm
)
;
Label
done
;
Label
fail
;
masm
.
createPlainGCObject
(
obj
shape
scratch
shape
numFixedSlots
numDynamicSlots
allocKind
gc
:
:
Heap
:
:
Default
&
fail
AllocSiteInput
(
site
)
)
;
masm
.
jump
(
&
done
)
;
{
masm
.
bind
(
&
fail
)
;
AutoStubFrame
stubFrame
(
*
this
)
;
stubFrame
.
enter
(
masm
scratch
)
;
masm
.
Push
(
site
)
;
masm
.
Push
(
Imm32
(
int32_t
(
allocKind
)
)
)
;
masm
.
loadPtr
(
shapeAddr
shape
)
;
masm
.
Push
(
shape
)
;
using
Fn
=
JSObject
*
(
*
)
(
JSContext
*
Handle
<
SharedShape
*
>
gc
:
:
AllocKind
gc
:
:
AllocSite
*
)
;
callVM
<
Fn
NewPlainObjectBaselineFallback
>
(
masm
)
;
stubFrame
.
leave
(
masm
)
;
masm
.
storeCallPointerResult
(
obj
)
;
}
masm
.
bind
(
&
done
)
;
masm
.
tagValue
(
JSVAL_TYPE_OBJECT
obj
output
.
valueReg
(
)
)
;
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
emitBindFunctionResult
(
ObjOperandId
targetId
uint32_t
argc
uint32_t
templateObjectOffset
)
{
JitSpew
(
JitSpew_Codegen
"
%
s
"
__FUNCTION__
)
;
AutoOutputRegister
output
(
*
this
)
;
AutoScratchRegister
scratch
(
allocator
masm
)
;
Register
target
=
allocator
.
useRegister
(
masm
targetId
)
;
allocator
.
discardStack
(
masm
)
;
AutoStubFrame
stubFrame
(
*
this
)
;
stubFrame
.
enter
(
masm
scratch
)
;
for
(
uint32_t
i
=
0
;
i
<
argc
;
i
+
+
)
{
Address
argAddress
(
FramePointer
BaselineStubFrameLayout
:
:
Size
(
)
+
i
*
sizeof
(
Value
)
)
;
masm
.
pushValue
(
argAddress
)
;
}
masm
.
moveStackPtrTo
(
scratch
.
get
(
)
)
;
masm
.
Push
(
ImmWord
(
0
)
)
;
masm
.
Push
(
Imm32
(
argc
)
)
;
masm
.
Push
(
scratch
)
;
masm
.
Push
(
target
)
;
using
Fn
=
BoundFunctionObject
*
(
*
)
(
JSContext
*
Handle
<
JSObject
*
>
Value
*
uint32_t
Handle
<
BoundFunctionObject
*
>
)
;
callVM
<
Fn
BoundFunctionObject
:
:
functionBindImpl
>
(
masm
)
;
stubFrame
.
leave
(
masm
)
;
masm
.
storeCallPointerResult
(
scratch
)
;
masm
.
tagValue
(
JSVAL_TYPE_OBJECT
scratch
output
.
valueReg
(
)
)
;
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
emitSpecializedBindFunctionResult
(
ObjOperandId
targetId
uint32_t
argc
uint32_t
templateObjectOffset
)
{
JitSpew
(
JitSpew_Codegen
"
%
s
"
__FUNCTION__
)
;
AutoOutputRegister
output
(
*
this
)
;
AutoScratchRegisterMaybeOutput
scratch1
(
allocator
masm
)
;
AutoScratchRegister
scratch2
(
allocator
masm
)
;
Register
target
=
allocator
.
useRegister
(
masm
targetId
)
;
StubFieldOffset
objectField
(
templateObjectOffset
StubField
:
:
Type
:
:
JSObject
)
;
emitLoadStubField
(
objectField
scratch2
)
;
allocator
.
discardStack
(
masm
)
;
AutoStubFrame
stubFrame
(
*
this
)
;
stubFrame
.
enter
(
masm
scratch1
)
;
for
(
uint32_t
i
=
0
;
i
<
argc
;
i
+
+
)
{
Address
argAddress
(
FramePointer
BaselineStubFrameLayout
:
:
Size
(
)
+
i
*
sizeof
(
Value
)
)
;
masm
.
pushValue
(
argAddress
)
;
}
masm
.
moveStackPtrTo
(
scratch1
.
get
(
)
)
;
masm
.
Push
(
scratch2
)
;
masm
.
Push
(
Imm32
(
argc
)
)
;
masm
.
Push
(
scratch1
)
;
masm
.
Push
(
target
)
;
using
Fn
=
BoundFunctionObject
*
(
*
)
(
JSContext
*
Handle
<
JSObject
*
>
Value
*
uint32_t
Handle
<
BoundFunctionObject
*
>
)
;
callVM
<
Fn
BoundFunctionObject
:
:
functionBindSpecializedBaseline
>
(
masm
)
;
stubFrame
.
leave
(
masm
)
;
masm
.
storeCallPointerResult
(
scratch1
)
;
masm
.
tagValue
(
JSVAL_TYPE_OBJECT
scratch1
output
.
valueReg
(
)
)
;
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
emitCloseIterScriptedResult
(
ObjOperandId
iterId
ObjOperandId
calleeId
CompletionKind
kind
uint32_t
calleeNargs
)
{
JitSpew
(
JitSpew_Codegen
"
%
s
"
__FUNCTION__
)
;
Register
iter
=
allocator
.
useRegister
(
masm
iterId
)
;
Register
callee
=
allocator
.
useRegister
(
masm
calleeId
)
;
AutoScratchRegister
code
(
allocator
masm
)
;
AutoScratchRegister
scratch
(
allocator
masm
)
;
masm
.
loadJitCodeRaw
(
callee
code
)
;
allocator
.
discardStack
(
masm
)
;
AutoStubFrame
stubFrame
(
*
this
)
;
stubFrame
.
enter
(
masm
scratch
)
;
masm
.
alignJitStackBasedOnNArgs
(
calleeNargs
false
)
;
for
(
uint32_t
i
=
0
;
i
<
calleeNargs
;
i
+
+
)
{
masm
.
pushValue
(
UndefinedValue
(
)
)
;
}
masm
.
Push
(
TypedOrValueRegister
(
MIRType
:
:
Object
AnyRegister
(
iter
)
)
)
;
masm
.
Push
(
callee
)
;
masm
.
PushFrameDescriptorForJitCall
(
FrameType
:
:
BaselineStub
0
)
;
masm
.
callJit
(
code
)
;
if
(
kind
!
=
CompletionKind
:
:
Throw
)
{
Label
success
;
masm
.
branchTestObject
(
Assembler
:
:
Equal
JSReturnOperand
&
success
)
;
masm
.
Push
(
Imm32
(
int32_t
(
CheckIsObjectKind
:
:
IteratorReturn
)
)
)
;
using
Fn
=
bool
(
*
)
(
JSContext
*
CheckIsObjectKind
)
;
callVM
<
Fn
ThrowCheckIsObject
>
(
masm
)
;
masm
.
bind
(
&
success
)
;
}
stubFrame
.
leave
(
masm
)
;
return
true
;
}
static
void
CallRegExpStub
(
MacroAssembler
&
masm
size_t
jitZoneStubOffset
Register
temp
Label
*
vmCall
)
{
masm
.
loadJSContext
(
temp
)
;
masm
.
loadPtr
(
Address
(
temp
JSContext
:
:
offsetOfZone
(
)
)
temp
)
;
masm
.
loadPtr
(
Address
(
temp
Zone
:
:
offsetOfJitZone
(
)
)
temp
)
;
masm
.
loadPtr
(
Address
(
temp
jitZoneStubOffset
)
temp
)
;
masm
.
branchTestPtr
(
Assembler
:
:
Zero
temp
temp
vmCall
)
;
masm
.
call
(
Address
(
temp
JitCode
:
:
offsetOfCode
(
)
)
)
;
}
static
void
SetRegExpStubInputRegisters
(
MacroAssembler
&
masm
Register
*
regexpSrc
Register
regexpDest
Register
*
inputSrc
Register
inputDest
Register
*
lastIndexSrc
Register
lastIndexDest
)
{
MoveResolver
&
moves
=
masm
.
moveResolver
(
)
;
if
(
*
regexpSrc
!
=
regexpDest
)
{
masm
.
propagateOOM
(
moves
.
addMove
(
MoveOperand
(
*
regexpSrc
)
MoveOperand
(
regexpDest
)
MoveOp
:
:
GENERAL
)
)
;
*
regexpSrc
=
regexpDest
;
}
if
(
*
inputSrc
!
=
inputDest
)
{
masm
.
propagateOOM
(
moves
.
addMove
(
MoveOperand
(
*
inputSrc
)
MoveOperand
(
inputDest
)
MoveOp
:
:
GENERAL
)
)
;
*
inputSrc
=
inputDest
;
}
if
(
lastIndexSrc
&
&
*
lastIndexSrc
!
=
lastIndexDest
)
{
masm
.
propagateOOM
(
moves
.
addMove
(
MoveOperand
(
*
lastIndexSrc
)
MoveOperand
(
lastIndexDest
)
MoveOp
:
:
INT32
)
)
;
*
lastIndexSrc
=
lastIndexDest
;
}
masm
.
propagateOOM
(
moves
.
resolve
(
)
)
;
MoveEmitter
emitter
(
masm
)
;
emitter
.
emit
(
moves
)
;
emitter
.
finish
(
)
;
}
bool
BaselineCacheIRCompiler
:
:
emitCallRegExpMatcherResult
(
ObjOperandId
regexpId
StringOperandId
inputId
Int32OperandId
lastIndexId
uint32_t
stubOffset
)
{
JitSpew
(
JitSpew_Codegen
"
%
s
"
__FUNCTION__
)
;
AutoOutputRegister
output
(
*
this
)
;
Register
regexp
=
allocator
.
useRegister
(
masm
regexpId
)
;
Register
input
=
allocator
.
useRegister
(
masm
inputId
)
;
Register
lastIndex
=
allocator
.
useRegister
(
masm
lastIndexId
)
;
Register
scratch
=
output
.
valueReg
(
)
.
scratchReg
(
)
;
allocator
.
discardStack
(
masm
)
;
AutoStubFrame
stubFrame
(
*
this
)
;
stubFrame
.
enter
(
masm
scratch
)
;
SetRegExpStubInputRegisters
(
masm
&
regexp
RegExpMatcherRegExpReg
&
input
RegExpMatcherStringReg
&
lastIndex
RegExpMatcherLastIndexReg
)
;
masm
.
reserveStack
(
RegExpReservedStack
)
;
Label
done
vmCall
vmCallNoMatches
;
CallRegExpStub
(
masm
JitZone
:
:
offsetOfRegExpMatcherStub
(
)
scratch
&
vmCallNoMatches
)
;
masm
.
branchTestUndefined
(
Assembler
:
:
Equal
JSReturnOperand
&
vmCall
)
;
masm
.
jump
(
&
done
)
;
{
Label
pushedMatches
;
masm
.
bind
(
&
vmCallNoMatches
)
;
masm
.
push
(
ImmWord
(
0
)
)
;
masm
.
jump
(
&
pushedMatches
)
;
masm
.
bind
(
&
vmCall
)
;
masm
.
computeEffectiveAddress
(
Address
(
masm
.
getStackPointer
(
)
InputOutputDataSize
)
scratch
)
;
masm
.
Push
(
scratch
)
;
masm
.
bind
(
&
pushedMatches
)
;
masm
.
Push
(
lastIndex
)
;
masm
.
Push
(
input
)
;
masm
.
Push
(
regexp
)
;
using
Fn
=
bool
(
*
)
(
JSContext
*
HandleObject
regexp
HandleString
input
int32_t
lastIndex
MatchPairs
*
pairs
MutableHandleValue
output
)
;
callVM
<
Fn
RegExpMatcherRaw
>
(
masm
)
;
}
masm
.
bind
(
&
done
)
;
static_assert
(
R0
=
=
JSReturnOperand
)
;
stubFrame
.
leave
(
masm
)
;
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
emitCallRegExpSearcherResult
(
ObjOperandId
regexpId
StringOperandId
inputId
Int32OperandId
lastIndexId
uint32_t
stubOffset
)
{
JitSpew
(
JitSpew_Codegen
"
%
s
"
__FUNCTION__
)
;
AutoOutputRegister
output
(
*
this
)
;
Register
regexp
=
allocator
.
useRegister
(
masm
regexpId
)
;
Register
input
=
allocator
.
useRegister
(
masm
inputId
)
;
Register
lastIndex
=
allocator
.
useRegister
(
masm
lastIndexId
)
;
Register
scratch
=
output
.
valueReg
(
)
.
scratchReg
(
)
;
allocator
.
discardStack
(
masm
)
;
AutoStubFrame
stubFrame
(
*
this
)
;
stubFrame
.
enter
(
masm
scratch
)
;
SetRegExpStubInputRegisters
(
masm
&
regexp
RegExpSearcherRegExpReg
&
input
RegExpSearcherStringReg
&
lastIndex
RegExpSearcherLastIndexReg
)
;
scratch
=
ReturnReg
;
masm
.
reserveStack
(
RegExpReservedStack
)
;
Label
done
vmCall
vmCallNoMatches
;
CallRegExpStub
(
masm
JitZone
:
:
offsetOfRegExpSearcherStub
(
)
scratch
&
vmCallNoMatches
)
;
masm
.
branch32
(
Assembler
:
:
Equal
scratch
Imm32
(
RegExpSearcherResultFailed
)
&
vmCall
)
;
masm
.
jump
(
&
done
)
;
{
Label
pushedMatches
;
masm
.
bind
(
&
vmCallNoMatches
)
;
masm
.
push
(
ImmWord
(
0
)
)
;
masm
.
jump
(
&
pushedMatches
)
;
masm
.
bind
(
&
vmCall
)
;
masm
.
computeEffectiveAddress
(
Address
(
masm
.
getStackPointer
(
)
InputOutputDataSize
)
scratch
)
;
masm
.
Push
(
scratch
)
;
masm
.
bind
(
&
pushedMatches
)
;
masm
.
Push
(
lastIndex
)
;
masm
.
Push
(
input
)
;
masm
.
Push
(
regexp
)
;
using
Fn
=
bool
(
*
)
(
JSContext
*
HandleObject
regexp
HandleString
input
int32_t
lastIndex
MatchPairs
*
pairs
int32_t
*
result
)
;
callVM
<
Fn
RegExpSearcherRaw
>
(
masm
)
;
}
masm
.
bind
(
&
done
)
;
masm
.
tagValue
(
JSVAL_TYPE_INT32
ReturnReg
output
.
valueReg
(
)
)
;
stubFrame
.
leave
(
masm
)
;
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
emitRegExpBuiltinExecMatchResult
(
ObjOperandId
regexpId
StringOperandId
inputId
uint32_t
stubOffset
)
{
JitSpew
(
JitSpew_Codegen
"
%
s
"
__FUNCTION__
)
;
AutoOutputRegister
output
(
*
this
)
;
Register
regexp
=
allocator
.
useRegister
(
masm
regexpId
)
;
Register
input
=
allocator
.
useRegister
(
masm
inputId
)
;
Register
scratch
=
output
.
valueReg
(
)
.
scratchReg
(
)
;
allocator
.
discardStack
(
masm
)
;
AutoStubFrame
stubFrame
(
*
this
)
;
stubFrame
.
enter
(
masm
scratch
)
;
SetRegExpStubInputRegisters
(
masm
&
regexp
RegExpMatcherRegExpReg
&
input
RegExpMatcherStringReg
nullptr
InvalidReg
)
;
masm
.
reserveStack
(
RegExpReservedStack
)
;
Label
done
vmCall
vmCallNoMatches
;
CallRegExpStub
(
masm
JitZone
:
:
offsetOfRegExpExecMatchStub
(
)
scratch
&
vmCallNoMatches
)
;
masm
.
branchTestUndefined
(
Assembler
:
:
Equal
JSReturnOperand
&
vmCall
)
;
masm
.
jump
(
&
done
)
;
{
Label
pushedMatches
;
masm
.
bind
(
&
vmCallNoMatches
)
;
masm
.
push
(
ImmWord
(
0
)
)
;
masm
.
jump
(
&
pushedMatches
)
;
masm
.
bind
(
&
vmCall
)
;
masm
.
computeEffectiveAddress
(
Address
(
masm
.
getStackPointer
(
)
InputOutputDataSize
)
scratch
)
;
masm
.
Push
(
scratch
)
;
masm
.
bind
(
&
pushedMatches
)
;
masm
.
Push
(
input
)
;
masm
.
Push
(
regexp
)
;
using
Fn
=
bool
(
*
)
(
JSContext
*
Handle
<
RegExpObject
*
>
regexp
HandleString
input
MatchPairs
*
pairs
MutableHandleValue
output
)
;
callVM
<
Fn
RegExpBuiltinExecMatchFromJit
>
(
masm
)
;
}
masm
.
bind
(
&
done
)
;
static_assert
(
R0
=
=
JSReturnOperand
)
;
stubFrame
.
leave
(
masm
)
;
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
emitRegExpBuiltinExecTestResult
(
ObjOperandId
regexpId
StringOperandId
inputId
uint32_t
stubOffset
)
{
JitSpew
(
JitSpew_Codegen
"
%
s
"
__FUNCTION__
)
;
AutoOutputRegister
output
(
*
this
)
;
Register
regexp
=
allocator
.
useRegister
(
masm
regexpId
)
;
Register
input
=
allocator
.
useRegister
(
masm
inputId
)
;
Register
scratch
=
output
.
valueReg
(
)
.
scratchReg
(
)
;
allocator
.
discardStack
(
masm
)
;
AutoStubFrame
stubFrame
(
*
this
)
;
stubFrame
.
enter
(
masm
scratch
)
;
SetRegExpStubInputRegisters
(
masm
&
regexp
RegExpExecTestRegExpReg
&
input
RegExpExecTestStringReg
nullptr
InvalidReg
)
;
scratch
=
ReturnReg
;
Label
done
vmCall
;
CallRegExpStub
(
masm
JitZone
:
:
offsetOfRegExpExecTestStub
(
)
scratch
&
vmCall
)
;
masm
.
branch32
(
Assembler
:
:
Equal
scratch
Imm32
(
RegExpExecTestResultFailed
)
&
vmCall
)
;
masm
.
jump
(
&
done
)
;
{
masm
.
bind
(
&
vmCall
)
;
masm
.
Push
(
input
)
;
masm
.
Push
(
regexp
)
;
using
Fn
=
bool
(
*
)
(
JSContext
*
Handle
<
RegExpObject
*
>
regexp
HandleString
input
bool
*
result
)
;
callVM
<
Fn
RegExpBuiltinExecTestFromJit
>
(
masm
)
;
}
masm
.
bind
(
&
done
)
;
masm
.
tagValue
(
JSVAL_TYPE_BOOLEAN
ReturnReg
output
.
valueReg
(
)
)
;
stubFrame
.
leave
(
masm
)
;
return
true
;
}
bool
BaselineCacheIRCompiler
:
:
emitRegExpHasCaptureGroupsResult
(
ObjOperandId
regexpId
StringOperandId
inputId
)
{
JitSpew
(
JitSpew_Codegen
"
%
s
"
__FUNCTION__
)
;
AutoOutputRegister
output
(
*
this
)
;
Register
regexp
=
allocator
.
useRegister
(
masm
regexpId
)
;
Register
input
=
allocator
.
useRegister
(
masm
inputId
)
;
AutoScratchRegisterMaybeOutput
scratch
(
allocator
masm
output
)
;
allocator
.
discardStack
(
masm
)
;
Label
vmCall
;
masm
.
loadParsedRegExpShared
(
regexp
scratch
&
vmCall
)
;
Label
returnTrue
done
;
masm
.
branch32
(
Assembler
:
:
Above
Address
(
scratch
RegExpShared
:
:
offsetOfPairCount
(
)
)
Imm32
(
1
)
&
returnTrue
)
;
masm
.
moveValue
(
BooleanValue
(
false
)
output
.
valueReg
(
)
)
;
masm
.
jump
(
&
done
)
;
masm
.
bind
(
&
returnTrue
)
;
masm
.
moveValue
(
BooleanValue
(
true
)
output
.
valueReg
(
)
)
;
masm
.
jump
(
&
done
)
;
{
masm
.
bind
(
&
vmCall
)
;
AutoStubFrame
stubFrame
(
*
this
)
;
stubFrame
.
enter
(
masm
scratch
)
;
masm
.
Push
(
input
)
;
masm
.
Push
(
regexp
)
;
using
Fn
=
bool
(
*
)
(
JSContext
*
Handle
<
RegExpObject
*
>
Handle
<
JSString
*
>
bool
*
)
;
callVM
<
Fn
RegExpHasCaptureGroups
>
(
masm
)
;
stubFrame
.
leave
(
masm
)
;
masm
.
storeCallBoolResult
(
scratch
)
;
masm
.
tagValue
(
JSVAL_TYPE_BOOLEAN
scratch
output
.
valueReg
(
)
)
;
}
masm
.
bind
(
&
done
)
;
return
true
;
}
