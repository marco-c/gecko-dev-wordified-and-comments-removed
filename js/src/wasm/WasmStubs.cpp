#
include
"
wasm
/
WasmStubs
.
h
"
#
include
"
mozilla
/
ArrayUtils
.
h
"
#
include
"
mozilla
/
EnumeratedRange
.
h
"
#
include
"
wasm
/
WasmCode
.
h
"
#
include
"
wasm
/
WasmGenerator
.
h
"
#
include
"
wasm
/
WasmInstance
.
h
"
#
include
"
jit
/
MacroAssembler
-
inl
.
h
"
using
namespace
js
;
using
namespace
js
:
:
jit
;
using
namespace
js
:
:
wasm
;
using
mozilla
:
:
ArrayLength
;
using
mozilla
:
:
MakeEnumeratedRange
;
typedef
Vector
<
jit
:
:
MIRType
8
SystemAllocPolicy
>
MIRTypeVector
;
typedef
jit
:
:
ABIArgIter
<
MIRTypeVector
>
ABIArgMIRTypeIter
;
typedef
jit
:
:
ABIArgIter
<
ValTypeVector
>
ABIArgValTypeIter
;
static
bool
FinishOffsets
(
MacroAssembler
&
masm
Offsets
*
offsets
)
{
masm
.
flushBuffer
(
)
;
offsets
-
>
end
=
masm
.
size
(
)
;
return
!
masm
.
oom
(
)
;
}
static
void
AssertStackAlignment
(
MacroAssembler
&
masm
uint32_t
alignment
uint32_t
addBeforeAssert
=
0
)
{
MOZ_ASSERT
(
(
sizeof
(
Frame
)
+
masm
.
framePushed
(
)
+
addBeforeAssert
)
%
alignment
=
=
0
)
;
masm
.
assertStackAlignment
(
alignment
addBeforeAssert
)
;
}
static
unsigned
StackDecrementForCall
(
MacroAssembler
&
masm
uint32_t
alignment
unsigned
bytesToPush
)
{
return
StackDecrementForCall
(
alignment
sizeof
(
Frame
)
+
masm
.
framePushed
(
)
bytesToPush
)
;
}
template
<
class
VectorT
>
static
unsigned
StackArgBytes
(
const
VectorT
&
args
)
{
ABIArgIter
<
VectorT
>
iter
(
args
)
;
while
(
!
iter
.
done
(
)
)
iter
+
+
;
return
iter
.
stackBytesConsumedSoFar
(
)
;
}
template
<
class
VectorT
>
static
unsigned
StackDecrementForCall
(
MacroAssembler
&
masm
uint32_t
alignment
const
VectorT
&
args
unsigned
extraBytes
=
0
)
{
return
StackDecrementForCall
(
masm
alignment
StackArgBytes
(
args
)
+
extraBytes
)
;
}
static
void
SetupABIArguments
(
MacroAssembler
&
masm
const
FuncExport
&
fe
Register
argv
Register
scratch
)
{
for
(
ABIArgValTypeIter
iter
(
fe
.
sig
(
)
.
args
(
)
)
;
!
iter
.
done
(
)
;
iter
+
+
)
{
unsigned
argOffset
=
iter
.
index
(
)
*
sizeof
(
ExportArg
)
;
Address
src
(
argv
argOffset
)
;
MIRType
type
=
iter
.
mirType
(
)
;
switch
(
iter
-
>
kind
(
)
)
{
case
ABIArg
:
:
GPR
:
if
(
type
=
=
MIRType
:
:
Int32
)
masm
.
load32
(
src
iter
-
>
gpr
(
)
)
;
else
if
(
type
=
=
MIRType
:
:
Int64
)
masm
.
load64
(
src
iter
-
>
gpr64
(
)
)
;
break
;
#
ifdef
JS_CODEGEN_REGISTER_PAIR
case
ABIArg
:
:
GPR_PAIR
:
if
(
type
=
=
MIRType
:
:
Int64
)
masm
.
load64
(
src
iter
-
>
gpr64
(
)
)
;
else
MOZ_CRASH
(
"
wasm
uses
hardfp
for
function
calls
.
"
)
;
break
;
#
endif
case
ABIArg
:
:
FPU
:
{
static_assert
(
sizeof
(
ExportArg
)
>
=
jit
:
:
Simd128DataSize
"
ExportArg
must
be
big
enough
to
store
SIMD
values
"
)
;
switch
(
type
)
{
case
MIRType
:
:
Int8x16
:
case
MIRType
:
:
Int16x8
:
case
MIRType
:
:
Int32x4
:
case
MIRType
:
:
Bool8x16
:
case
MIRType
:
:
Bool16x8
:
case
MIRType
:
:
Bool32x4
:
masm
.
loadUnalignedSimd128Int
(
src
iter
-
>
fpu
(
)
)
;
break
;
case
MIRType
:
:
Float32x4
:
masm
.
loadUnalignedSimd128Float
(
src
iter
-
>
fpu
(
)
)
;
break
;
case
MIRType
:
:
Double
:
masm
.
loadDouble
(
src
iter
-
>
fpu
(
)
)
;
break
;
case
MIRType
:
:
Float32
:
masm
.
loadFloat32
(
src
iter
-
>
fpu
(
)
)
;
break
;
default
:
MOZ_MAKE_COMPILER_ASSUME_IS_UNREACHABLE
(
"
unexpected
FPU
type
"
)
;
break
;
}
break
;
}
case
ABIArg
:
:
Stack
:
switch
(
type
)
{
case
MIRType
:
:
Int32
:
masm
.
load32
(
src
scratch
)
;
masm
.
storePtr
(
scratch
Address
(
masm
.
getStackPointer
(
)
iter
-
>
offsetFromArgBase
(
)
)
)
;
break
;
case
MIRType
:
:
Int64
:
{
Register
sp
=
masm
.
getStackPointer
(
)
;
#
if
JS_BITS_PER_WORD
=
=
32
masm
.
load32
(
LowWord
(
src
)
scratch
)
;
masm
.
store32
(
scratch
LowWord
(
Address
(
sp
iter
-
>
offsetFromArgBase
(
)
)
)
)
;
masm
.
load32
(
HighWord
(
src
)
scratch
)
;
masm
.
store32
(
scratch
HighWord
(
Address
(
sp
iter
-
>
offsetFromArgBase
(
)
)
)
)
;
#
else
Register64
scratch64
(
scratch
)
;
masm
.
load64
(
src
scratch64
)
;
masm
.
store64
(
scratch64
Address
(
sp
iter
-
>
offsetFromArgBase
(
)
)
)
;
#
endif
break
;
}
case
MIRType
:
:
Double
:
masm
.
loadDouble
(
src
ScratchDoubleReg
)
;
masm
.
storeDouble
(
ScratchDoubleReg
Address
(
masm
.
getStackPointer
(
)
iter
-
>
offsetFromArgBase
(
)
)
)
;
break
;
case
MIRType
:
:
Float32
:
masm
.
loadFloat32
(
src
ScratchFloat32Reg
)
;
masm
.
storeFloat32
(
ScratchFloat32Reg
Address
(
masm
.
getStackPointer
(
)
iter
-
>
offsetFromArgBase
(
)
)
)
;
break
;
case
MIRType
:
:
Int8x16
:
case
MIRType
:
:
Int16x8
:
case
MIRType
:
:
Int32x4
:
case
MIRType
:
:
Bool8x16
:
case
MIRType
:
:
Bool16x8
:
case
MIRType
:
:
Bool32x4
:
masm
.
loadUnalignedSimd128Int
(
src
ScratchSimd128Reg
)
;
masm
.
storeAlignedSimd128Int
(
ScratchSimd128Reg
Address
(
masm
.
getStackPointer
(
)
iter
-
>
offsetFromArgBase
(
)
)
)
;
break
;
case
MIRType
:
:
Float32x4
:
masm
.
loadUnalignedSimd128Float
(
src
ScratchSimd128Reg
)
;
masm
.
storeAlignedSimd128Float
(
ScratchSimd128Reg
Address
(
masm
.
getStackPointer
(
)
iter
-
>
offsetFromArgBase
(
)
)
)
;
break
;
default
:
MOZ_MAKE_COMPILER_ASSUME_IS_UNREACHABLE
(
"
unexpected
stack
arg
type
"
)
;
}
break
;
case
ABIArg
:
:
Uninitialized
:
MOZ_CRASH
(
"
Uninitialized
ABIArg
kind
"
)
;
}
}
}
static
void
StoreABIReturn
(
MacroAssembler
&
masm
const
FuncExport
&
fe
Register
argv
)
{
switch
(
fe
.
sig
(
)
.
ret
(
)
)
{
case
ExprType
:
:
Void
:
break
;
case
ExprType
:
:
I32
:
masm
.
store32
(
ReturnReg
Address
(
argv
0
)
)
;
break
;
case
ExprType
:
:
I64
:
masm
.
store64
(
ReturnReg64
Address
(
argv
0
)
)
;
break
;
case
ExprType
:
:
F32
:
masm
.
canonicalizeFloat
(
ReturnFloat32Reg
)
;
masm
.
storeFloat32
(
ReturnFloat32Reg
Address
(
argv
0
)
)
;
break
;
case
ExprType
:
:
F64
:
masm
.
canonicalizeDouble
(
ReturnDoubleReg
)
;
masm
.
storeDouble
(
ReturnDoubleReg
Address
(
argv
0
)
)
;
break
;
case
ExprType
:
:
I8x16
:
case
ExprType
:
:
I16x8
:
case
ExprType
:
:
I32x4
:
case
ExprType
:
:
B8x16
:
case
ExprType
:
:
B16x8
:
case
ExprType
:
:
B32x4
:
masm
.
storeUnalignedSimd128Int
(
ReturnSimd128Reg
Address
(
argv
0
)
)
;
break
;
case
ExprType
:
:
F32x4
:
masm
.
storeUnalignedSimd128Float
(
ReturnSimd128Reg
Address
(
argv
0
)
)
;
break
;
case
ExprType
:
:
Limit
:
MOZ_CRASH
(
"
Limit
"
)
;
}
}
#
if
defined
(
JS_CODEGEN_ARM
)
static
const
LiveRegisterSet
NonVolatileRegs
=
LiveRegisterSet
(
GeneralRegisterSet
(
Registers
:
:
NonVolatileMask
&
~
(
uint32_t
(
1
)
<
<
Registers
:
:
lr
)
)
FloatRegisterSet
(
FloatRegisters
:
:
NonVolatileMask
|
(
1ULL
<
<
FloatRegisters
:
:
d15
)
|
(
1ULL
<
<
FloatRegisters
:
:
s31
)
)
)
;
#
else
static
const
LiveRegisterSet
NonVolatileRegs
=
LiveRegisterSet
(
GeneralRegisterSet
(
Registers
:
:
NonVolatileMask
)
FloatRegisterSet
(
FloatRegisters
:
:
NonVolatileMask
)
)
;
#
endif
#
if
defined
(
JS_CODEGEN_MIPS32
)
static
const
unsigned
NonVolatileRegsPushSize
=
NonVolatileRegs
.
gprs
(
)
.
size
(
)
*
sizeof
(
intptr_t
)
+
NonVolatileRegs
.
fpus
(
)
.
getPushSizeInBytes
(
)
+
sizeof
(
double
)
;
#
elif
defined
(
JS_CODEGEN_NONE
)
static
const
unsigned
NonVolatileRegsPushSize
=
0
;
#
else
static
const
unsigned
NonVolatileRegsPushSize
=
NonVolatileRegs
.
gprs
(
)
.
size
(
)
*
sizeof
(
intptr_t
)
+
NonVolatileRegs
.
fpus
(
)
.
getPushSizeInBytes
(
)
;
#
endif
static
const
unsigned
FramePushedBeforeAlign
=
NonVolatileRegsPushSize
+
sizeof
(
void
*
)
;
static
bool
GenerateInterpEntry
(
MacroAssembler
&
masm
const
FuncExport
&
fe
Offsets
*
offsets
)
{
masm
.
haltingAlign
(
CodeAlignment
)
;
offsets
-
>
begin
=
masm
.
currentOffset
(
)
;
#
ifdef
JS_USE_LINK_REGISTER
masm
.
pushReturnAddress
(
)
;
#
endif
masm
.
setFramePushed
(
0
)
;
masm
.
PushRegsInMask
(
NonVolatileRegs
)
;
MOZ_ASSERT
(
masm
.
framePushed
(
)
=
=
NonVolatileRegsPushSize
)
;
Register
argv
=
ABINonArgReturnReg0
;
Register
scratch
=
ABINonArgReturnReg1
;
const
unsigned
argBase
=
sizeof
(
void
*
)
+
masm
.
framePushed
(
)
;
ABIArgGenerator
abi
;
ABIArg
arg
;
arg
=
abi
.
next
(
MIRType
:
:
Pointer
)
;
if
(
arg
.
kind
(
)
=
=
ABIArg
:
:
GPR
)
masm
.
movePtr
(
arg
.
gpr
(
)
argv
)
;
else
masm
.
loadPtr
(
Address
(
masm
.
getStackPointer
(
)
argBase
+
arg
.
offsetFromArgBase
(
)
)
argv
)
;
arg
=
abi
.
next
(
MIRType
:
:
Pointer
)
;
if
(
arg
.
kind
(
)
=
=
ABIArg
:
:
GPR
)
masm
.
movePtr
(
arg
.
gpr
(
)
WasmTlsReg
)
;
else
masm
.
loadPtr
(
Address
(
masm
.
getStackPointer
(
)
argBase
+
arg
.
offsetFromArgBase
(
)
)
WasmTlsReg
)
;
masm
.
Push
(
argv
)
;
MOZ_ASSERT
(
masm
.
framePushed
(
)
=
=
FramePushedBeforeAlign
)
;
masm
.
setFramePushed
(
0
)
;
masm
.
moveStackPtrTo
(
scratch
)
;
masm
.
andToStackPtr
(
Imm32
(
~
(
WasmStackAlignment
-
1
)
)
)
;
masm
.
Push
(
scratch
)
;
unsigned
argDecrement
=
StackDecrementForCall
(
WasmStackAlignment
masm
.
framePushed
(
)
StackArgBytes
(
fe
.
sig
(
)
.
args
(
)
)
)
;
masm
.
reserveStack
(
argDecrement
)
;
SetupABIArguments
(
masm
fe
argv
scratch
)
;
masm
.
movePtr
(
ImmWord
(
0
)
FramePointer
)
;
masm
.
loadWasmPinnedRegsFromTls
(
)
;
masm
.
assertStackAlignment
(
WasmStackAlignment
)
;
masm
.
call
(
CallSiteDesc
(
CallSiteDesc
:
:
Func
)
fe
.
funcIndex
(
)
)
;
masm
.
assertStackAlignment
(
WasmStackAlignment
)
;
masm
.
freeStack
(
argDecrement
)
;
masm
.
PopStackPtr
(
)
;
MOZ_ASSERT
(
masm
.
framePushed
(
)
=
=
0
)
;
masm
.
setFramePushed
(
FramePushedBeforeAlign
)
;
masm
.
Pop
(
argv
)
;
StoreABIReturn
(
masm
fe
argv
)
;
Label
success
join
;
masm
.
branchTestPtr
(
Assembler
:
:
Zero
FramePointer
FramePointer
&
success
)
;
#
ifdef
DEBUG
Label
ok
;
masm
.
branchPtr
(
Assembler
:
:
Equal
FramePointer
Imm32
(
FailFP
)
&
ok
)
;
masm
.
breakpoint
(
)
;
masm
.
bind
(
&
ok
)
;
#
endif
masm
.
move32
(
Imm32
(
false
)
ReturnReg
)
;
masm
.
jump
(
&
join
)
;
masm
.
bind
(
&
success
)
;
masm
.
move32
(
Imm32
(
true
)
ReturnReg
)
;
masm
.
bind
(
&
join
)
;
masm
.
PopRegsInMask
(
NonVolatileRegs
)
;
MOZ_ASSERT
(
masm
.
framePushed
(
)
=
=
0
)
;
masm
.
ret
(
)
;
return
FinishOffsets
(
masm
offsets
)
;
}
static
void
StackCopy
(
MacroAssembler
&
masm
MIRType
type
Register
scratch
Address
src
Address
dst
)
{
if
(
type
=
=
MIRType
:
:
Int32
)
{
masm
.
load32
(
src
scratch
)
;
masm
.
store32
(
scratch
dst
)
;
}
else
if
(
type
=
=
MIRType
:
:
Int64
)
{
#
if
JS_BITS_PER_WORD
=
=
32
masm
.
load32
(
LowWord
(
src
)
scratch
)
;
masm
.
store32
(
scratch
LowWord
(
dst
)
)
;
masm
.
load32
(
HighWord
(
src
)
scratch
)
;
masm
.
store32
(
scratch
HighWord
(
dst
)
)
;
#
else
Register64
scratch64
(
scratch
)
;
masm
.
load64
(
src
scratch64
)
;
masm
.
store64
(
scratch64
dst
)
;
#
endif
}
else
if
(
type
=
=
MIRType
:
:
Float32
)
{
masm
.
loadFloat32
(
src
ScratchFloat32Reg
)
;
masm
.
storeFloat32
(
ScratchFloat32Reg
dst
)
;
}
else
{
MOZ_ASSERT
(
type
=
=
MIRType
:
:
Double
)
;
masm
.
loadDouble
(
src
ScratchDoubleReg
)
;
masm
.
storeDouble
(
ScratchDoubleReg
dst
)
;
}
}
typedef
bool
ToValue
;
static
void
FillArgumentArray
(
MacroAssembler
&
masm
const
ValTypeVector
&
args
unsigned
argOffset
unsigned
offsetToCallerStackArgs
Register
scratch
ToValue
toValue
)
{
for
(
ABIArgValTypeIter
i
(
args
)
;
!
i
.
done
(
)
;
i
+
+
)
{
Address
dst
(
masm
.
getStackPointer
(
)
argOffset
+
i
.
index
(
)
*
sizeof
(
Value
)
)
;
MIRType
type
=
i
.
mirType
(
)
;
switch
(
i
-
>
kind
(
)
)
{
case
ABIArg
:
:
GPR
:
if
(
type
=
=
MIRType
:
:
Int32
)
{
if
(
toValue
)
masm
.
storeValue
(
JSVAL_TYPE_INT32
i
-
>
gpr
(
)
dst
)
;
else
masm
.
store32
(
i
-
>
gpr
(
)
dst
)
;
}
else
if
(
type
=
=
MIRType
:
:
Int64
)
{
if
(
toValue
)
masm
.
breakpoint
(
)
;
else
masm
.
store64
(
i
-
>
gpr64
(
)
dst
)
;
}
else
{
MOZ_CRASH
(
"
unexpected
input
type
?
"
)
;
}
break
;
#
ifdef
JS_CODEGEN_REGISTER_PAIR
case
ABIArg
:
:
GPR_PAIR
:
if
(
type
=
=
MIRType
:
:
Int64
)
masm
.
store64
(
i
-
>
gpr64
(
)
dst
)
;
else
MOZ_CRASH
(
"
wasm
uses
hardfp
for
function
calls
.
"
)
;
break
;
#
endif
case
ABIArg
:
:
FPU
:
{
MOZ_ASSERT
(
IsFloatingPointType
(
type
)
)
;
FloatRegister
srcReg
=
i
-
>
fpu
(
)
;
if
(
type
=
=
MIRType
:
:
Double
)
{
if
(
toValue
)
{
masm
.
moveDouble
(
srcReg
ScratchDoubleReg
)
;
srcReg
=
ScratchDoubleReg
;
masm
.
canonicalizeDouble
(
srcReg
)
;
}
masm
.
storeDouble
(
srcReg
dst
)
;
}
else
{
MOZ_ASSERT
(
type
=
=
MIRType
:
:
Float32
)
;
if
(
toValue
)
{
masm
.
convertFloat32ToDouble
(
srcReg
ScratchDoubleReg
)
;
masm
.
canonicalizeDouble
(
ScratchDoubleReg
)
;
masm
.
storeDouble
(
ScratchDoubleReg
dst
)
;
}
else
{
masm
.
moveFloat32
(
srcReg
ScratchFloat32Reg
)
;
masm
.
canonicalizeFloat
(
ScratchFloat32Reg
)
;
masm
.
storeFloat32
(
ScratchFloat32Reg
dst
)
;
}
}
break
;
}
case
ABIArg
:
:
Stack
:
{
Address
src
(
masm
.
getStackPointer
(
)
offsetToCallerStackArgs
+
i
-
>
offsetFromArgBase
(
)
)
;
if
(
toValue
)
{
if
(
type
=
=
MIRType
:
:
Int32
)
{
masm
.
load32
(
src
scratch
)
;
masm
.
storeValue
(
JSVAL_TYPE_INT32
scratch
dst
)
;
}
else
if
(
type
=
=
MIRType
:
:
Int64
)
{
masm
.
breakpoint
(
)
;
}
else
{
MOZ_ASSERT
(
IsFloatingPointType
(
type
)
)
;
if
(
type
=
=
MIRType
:
:
Float32
)
{
masm
.
loadFloat32
(
src
ScratchFloat32Reg
)
;
masm
.
convertFloat32ToDouble
(
ScratchFloat32Reg
ScratchDoubleReg
)
;
}
else
{
masm
.
loadDouble
(
src
ScratchDoubleReg
)
;
}
masm
.
canonicalizeDouble
(
ScratchDoubleReg
)
;
masm
.
storeDouble
(
ScratchDoubleReg
dst
)
;
}
}
else
{
StackCopy
(
masm
type
scratch
src
dst
)
;
}
break
;
}
case
ABIArg
:
:
Uninitialized
:
MOZ_CRASH
(
"
Uninitialized
ABIArg
kind
"
)
;
}
}
}
static
bool
GenerateImportFunction
(
jit
:
:
MacroAssembler
&
masm
const
FuncImport
&
fi
SigIdDesc
sigId
FuncOffsets
*
offsets
)
{
masm
.
setFramePushed
(
0
)
;
unsigned
framePushed
=
StackDecrementForCall
(
masm
WasmStackAlignment
fi
.
sig
(
)
.
args
(
)
)
;
GenerateFunctionPrologue
(
masm
framePushed
sigId
offsets
)
;
Register
scratch
=
ABINonArgReg0
;
unsigned
offsetToCallerStackArgs
=
sizeof
(
Frame
)
+
masm
.
framePushed
(
)
;
ABIArgValTypeIter
i
(
fi
.
sig
(
)
.
args
(
)
)
;
for
(
;
!
i
.
done
(
)
;
i
+
+
)
{
if
(
i
-
>
kind
(
)
!
=
ABIArg
:
:
Stack
)
continue
;
Address
src
(
masm
.
getStackPointer
(
)
offsetToCallerStackArgs
+
i
-
>
offsetFromArgBase
(
)
)
;
Address
dst
(
masm
.
getStackPointer
(
)
i
-
>
offsetFromArgBase
(
)
)
;
StackCopy
(
masm
i
.
mirType
(
)
scratch
src
dst
)
;
}
CallSiteDesc
desc
(
CallSiteDesc
:
:
Dynamic
)
;
masm
.
wasmCallImport
(
desc
CalleeDesc
:
:
import
(
fi
.
tlsDataOffset
(
)
)
)
;
masm
.
loadWasmTlsRegFromFrame
(
)
;
masm
.
loadWasmPinnedRegsFromTls
(
)
;
GenerateFunctionEpilogue
(
masm
framePushed
offsets
)
;
masm
.
wasmEmitTrapOutOfLineCode
(
)
;
return
FinishOffsets
(
masm
offsets
)
;
}
static
const
unsigned
STUBS_LIFO_DEFAULT_CHUNK_SIZE
=
4
*
1024
;
bool
wasm
:
:
GenerateImportFunctions
(
const
ModuleEnvironment
&
env
const
FuncImportVector
&
imports
CompiledCode
*
code
)
{
LifoAlloc
lifo
(
STUBS_LIFO_DEFAULT_CHUNK_SIZE
)
;
TempAllocator
alloc
(
&
lifo
)
;
MacroAssembler
masm
(
MacroAssembler
:
:
WasmToken
(
)
alloc
)
;
for
(
uint32_t
funcIndex
=
0
;
funcIndex
<
imports
.
length
(
)
;
funcIndex
+
+
)
{
const
FuncImport
&
fi
=
imports
[
funcIndex
]
;
FuncOffsets
offsets
;
if
(
!
GenerateImportFunction
(
masm
fi
env
.
funcSigs
[
funcIndex
]
-
>
id
&
offsets
)
)
return
false
;
if
(
!
code
-
>
codeRanges
.
emplaceBack
(
funcIndex
0
offsets
)
)
return
false
;
}
masm
.
finish
(
)
;
if
(
masm
.
oom
(
)
)
return
false
;
return
code
-
>
swap
(
masm
)
;
}
static
bool
GenerateImportInterpExit
(
MacroAssembler
&
masm
const
FuncImport
&
fi
uint32_t
funcImportIndex
Label
*
throwLabel
CallableOffsets
*
offsets
)
{
masm
.
setFramePushed
(
0
)
;
static
const
MIRType
typeArray
[
]
=
{
MIRType
:
:
Pointer
MIRType
:
:
Pointer
MIRType
:
:
Int32
MIRType
:
:
Pointer
}
;
MIRTypeVector
invokeArgTypes
;
MOZ_ALWAYS_TRUE
(
invokeArgTypes
.
append
(
typeArray
ArrayLength
(
typeArray
)
)
)
;
unsigned
argOffset
=
AlignBytes
(
StackArgBytes
(
invokeArgTypes
)
sizeof
(
double
)
)
;
unsigned
argBytes
=
Max
<
size_t
>
(
1
fi
.
sig
(
)
.
args
(
)
.
length
(
)
)
*
sizeof
(
Value
)
;
unsigned
framePushed
=
StackDecrementForCall
(
masm
ABIStackAlignment
argOffset
+
argBytes
)
;
GenerateExitPrologue
(
masm
framePushed
ExitReason
:
:
Fixed
:
:
ImportInterp
offsets
)
;
unsigned
offsetToCallerStackArgs
=
sizeof
(
Frame
)
+
masm
.
framePushed
(
)
;
Register
scratch
=
ABINonArgReturnReg0
;
FillArgumentArray
(
masm
fi
.
sig
(
)
.
args
(
)
argOffset
offsetToCallerStackArgs
scratch
ToValue
(
false
)
)
;
ABIArgMIRTypeIter
i
(
invokeArgTypes
)
;
Address
instancePtr
(
WasmTlsReg
offsetof
(
TlsData
instance
)
)
;
if
(
i
-
>
kind
(
)
=
=
ABIArg
:
:
GPR
)
{
masm
.
loadPtr
(
instancePtr
i
-
>
gpr
(
)
)
;
}
else
{
masm
.
loadPtr
(
instancePtr
scratch
)
;
masm
.
storePtr
(
scratch
Address
(
masm
.
getStackPointer
(
)
i
-
>
offsetFromArgBase
(
)
)
)
;
}
i
+
+
;
if
(
i
-
>
kind
(
)
=
=
ABIArg
:
:
GPR
)
masm
.
mov
(
ImmWord
(
funcImportIndex
)
i
-
>
gpr
(
)
)
;
else
masm
.
store32
(
Imm32
(
funcImportIndex
)
Address
(
masm
.
getStackPointer
(
)
i
-
>
offsetFromArgBase
(
)
)
)
;
i
+
+
;
unsigned
argc
=
fi
.
sig
(
)
.
args
(
)
.
length
(
)
;
if
(
i
-
>
kind
(
)
=
=
ABIArg
:
:
GPR
)
masm
.
mov
(
ImmWord
(
argc
)
i
-
>
gpr
(
)
)
;
else
masm
.
store32
(
Imm32
(
argc
)
Address
(
masm
.
getStackPointer
(
)
i
-
>
offsetFromArgBase
(
)
)
)
;
i
+
+
;
Address
argv
(
masm
.
getStackPointer
(
)
argOffset
)
;
if
(
i
-
>
kind
(
)
=
=
ABIArg
:
:
GPR
)
{
masm
.
computeEffectiveAddress
(
argv
i
-
>
gpr
(
)
)
;
}
else
{
masm
.
computeEffectiveAddress
(
argv
scratch
)
;
masm
.
storePtr
(
scratch
Address
(
masm
.
getStackPointer
(
)
i
-
>
offsetFromArgBase
(
)
)
)
;
}
i
+
+
;
MOZ_ASSERT
(
i
.
done
(
)
)
;
AssertStackAlignment
(
masm
ABIStackAlignment
)
;
switch
(
fi
.
sig
(
)
.
ret
(
)
)
{
case
ExprType
:
:
Void
:
masm
.
call
(
SymbolicAddress
:
:
CallImport_Void
)
;
masm
.
branchTest32
(
Assembler
:
:
Zero
ReturnReg
ReturnReg
throwLabel
)
;
break
;
case
ExprType
:
:
I32
:
masm
.
call
(
SymbolicAddress
:
:
CallImport_I32
)
;
masm
.
branchTest32
(
Assembler
:
:
Zero
ReturnReg
ReturnReg
throwLabel
)
;
masm
.
load32
(
argv
ReturnReg
)
;
break
;
case
ExprType
:
:
I64
:
masm
.
call
(
SymbolicAddress
:
:
CallImport_I64
)
;
masm
.
jump
(
throwLabel
)
;
break
;
case
ExprType
:
:
F32
:
masm
.
call
(
SymbolicAddress
:
:
CallImport_F64
)
;
masm
.
branchTest32
(
Assembler
:
:
Zero
ReturnReg
ReturnReg
throwLabel
)
;
masm
.
loadDouble
(
argv
ReturnDoubleReg
)
;
masm
.
convertDoubleToFloat32
(
ReturnDoubleReg
ReturnFloat32Reg
)
;
break
;
case
ExprType
:
:
F64
:
masm
.
call
(
SymbolicAddress
:
:
CallImport_F64
)
;
masm
.
branchTest32
(
Assembler
:
:
Zero
ReturnReg
ReturnReg
throwLabel
)
;
masm
.
loadDouble
(
argv
ReturnDoubleReg
)
;
break
;
case
ExprType
:
:
I8x16
:
case
ExprType
:
:
I16x8
:
case
ExprType
:
:
I32x4
:
case
ExprType
:
:
F32x4
:
case
ExprType
:
:
B8x16
:
case
ExprType
:
:
B16x8
:
case
ExprType
:
:
B32x4
:
MOZ_CRASH
(
"
SIMD
types
shouldn
'
t
be
returned
from
a
FFI
"
)
;
case
ExprType
:
:
Limit
:
MOZ_CRASH
(
"
Limit
"
)
;
}
MOZ_ASSERT
(
NonVolatileRegs
.
has
(
WasmTlsReg
)
)
;
#
if
defined
(
JS_CODEGEN_X64
)
|
|
\
defined
(
JS_CODEGEN_ARM
)
|
|
defined
(
JS_CODEGEN_ARM64
)
|
|
\
defined
(
JS_CODEGEN_MIPS32
)
|
|
defined
(
JS_CODEGEN_MIPS64
)
MOZ_ASSERT
(
NonVolatileRegs
.
has
(
HeapReg
)
)
;
#
endif
GenerateExitEpilogue
(
masm
framePushed
ExitReason
:
:
Fixed
:
:
ImportInterp
offsets
)
;
return
FinishOffsets
(
masm
offsets
)
;
}
static
bool
GenerateImportJitExit
(
MacroAssembler
&
masm
const
FuncImport
&
fi
Label
*
throwLabel
JitExitOffsets
*
offsets
)
{
masm
.
setFramePushed
(
0
)
;
static_assert
(
WasmStackAlignment
>
=
JitStackAlignment
"
subsumes
"
)
;
unsigned
sizeOfRetAddr
=
sizeof
(
void
*
)
;
unsigned
sizeOfPreFrame
=
WasmToJSJitFrameLayout
:
:
Size
(
)
-
sizeOfRetAddr
;
unsigned
sizeOfThisAndArgs
=
(
1
+
fi
.
sig
(
)
.
args
(
)
.
length
(
)
)
*
sizeof
(
Value
)
;
unsigned
totalJitFrameBytes
=
sizeOfRetAddr
+
sizeOfPreFrame
+
sizeOfThisAndArgs
;
unsigned
jitFramePushed
=
StackDecrementForCall
(
masm
JitStackAlignment
totalJitFrameBytes
)
-
sizeOfRetAddr
;
unsigned
sizeOfThisAndArgsAndPadding
=
jitFramePushed
-
sizeOfPreFrame
;
GenerateJitExitPrologue
(
masm
jitFramePushed
offsets
)
;
size_t
argOffset
=
0
;
uint32_t
descriptor
=
MakeFrameDescriptor
(
sizeOfThisAndArgsAndPadding
JitFrame_WasmToJSJit
WasmToJSJitFrameLayout
:
:
Size
(
)
)
;
masm
.
storePtr
(
ImmWord
(
uintptr_t
(
descriptor
)
)
Address
(
masm
.
getStackPointer
(
)
argOffset
)
)
;
argOffset
+
=
sizeof
(
size_t
)
;
Register
callee
=
ABINonArgReturnReg0
;
Register
scratch
=
ABINonArgReturnReg1
;
masm
.
loadWasmGlobalPtr
(
fi
.
tlsDataOffset
(
)
+
offsetof
(
FuncImportTls
obj
)
callee
)
;
masm
.
storePtr
(
callee
Address
(
masm
.
getStackPointer
(
)
argOffset
)
)
;
argOffset
+
=
sizeof
(
size_t
)
;
unsigned
argc
=
fi
.
sig
(
)
.
args
(
)
.
length
(
)
;
masm
.
storePtr
(
ImmWord
(
uintptr_t
(
argc
)
)
Address
(
masm
.
getStackPointer
(
)
argOffset
)
)
;
argOffset
+
=
sizeof
(
size_t
)
;
MOZ_ASSERT
(
argOffset
=
=
sizeOfPreFrame
)
;
masm
.
storeValue
(
UndefinedValue
(
)
Address
(
masm
.
getStackPointer
(
)
argOffset
)
)
;
argOffset
+
=
sizeof
(
Value
)
;
unsigned
offsetToCallerStackArgs
=
jitFramePushed
+
sizeof
(
Frame
)
;
FillArgumentArray
(
masm
fi
.
sig
(
)
.
args
(
)
argOffset
offsetToCallerStackArgs
scratch
ToValue
(
true
)
)
;
argOffset
+
=
fi
.
sig
(
)
.
args
(
)
.
length
(
)
*
sizeof
(
Value
)
;
MOZ_ASSERT
(
argOffset
=
=
sizeOfThisAndArgs
+
sizeOfPreFrame
)
;
masm
.
load16ZeroExtend
(
Address
(
callee
JSFunction
:
:
offsetOfNargs
(
)
)
scratch
)
;
Label
rectify
;
masm
.
branch32
(
Assembler
:
:
Above
scratch
Imm32
(
fi
.
sig
(
)
.
args
(
)
.
length
(
)
)
&
rectify
)
;
masm
.
loadJitCodeNoArgCheck
(
callee
callee
nullptr
)
;
Label
rejoinBeforeCall
;
masm
.
bind
(
&
rejoinBeforeCall
)
;
AssertStackAlignment
(
masm
JitStackAlignment
sizeOfRetAddr
)
;
masm
.
callJitNoProfiler
(
callee
)
;
offsets
-
>
untrustedFPStart
=
masm
.
currentOffset
(
)
;
AssertStackAlignment
(
masm
JitStackAlignment
sizeOfRetAddr
)
;
masm
.
loadWasmTlsRegFromFrame
(
)
;
masm
.
moveStackPtrTo
(
FramePointer
)
;
masm
.
addPtr
(
Imm32
(
masm
.
framePushed
(
)
)
FramePointer
)
;
offsets
-
>
untrustedFPEnd
=
masm
.
currentOffset
(
)
;
static_assert
(
ABIStackAlignment
<
=
JitStackAlignment
"
subsumes
"
)
;
masm
.
reserveStack
(
sizeOfRetAddr
)
;
unsigned
nativeFramePushed
=
masm
.
framePushed
(
)
;
AssertStackAlignment
(
masm
ABIStackAlignment
)
;
#
ifdef
DEBUG
{
Label
ok
;
masm
.
branchTestMagic
(
Assembler
:
:
NotEqual
JSReturnOperand
&
ok
)
;
masm
.
breakpoint
(
)
;
masm
.
bind
(
&
ok
)
;
}
#
endif
Label
oolConvert
;
switch
(
fi
.
sig
(
)
.
ret
(
)
)
{
case
ExprType
:
:
Void
:
break
;
case
ExprType
:
:
I32
:
masm
.
convertValueToInt32
(
JSReturnOperand
ReturnDoubleReg
ReturnReg
&
oolConvert
false
)
;
break
;
case
ExprType
:
:
I64
:
masm
.
breakpoint
(
)
;
break
;
case
ExprType
:
:
F32
:
masm
.
convertValueToFloat
(
JSReturnOperand
ReturnFloat32Reg
&
oolConvert
)
;
break
;
case
ExprType
:
:
F64
:
masm
.
convertValueToDouble
(
JSReturnOperand
ReturnDoubleReg
&
oolConvert
)
;
break
;
case
ExprType
:
:
I8x16
:
case
ExprType
:
:
I16x8
:
case
ExprType
:
:
I32x4
:
case
ExprType
:
:
F32x4
:
case
ExprType
:
:
B8x16
:
case
ExprType
:
:
B16x8
:
case
ExprType
:
:
B32x4
:
MOZ_CRASH
(
"
SIMD
types
shouldn
'
t
be
returned
from
an
import
"
)
;
case
ExprType
:
:
Limit
:
MOZ_CRASH
(
"
Limit
"
)
;
}
Label
done
;
masm
.
bind
(
&
done
)
;
GenerateJitExitEpilogue
(
masm
masm
.
framePushed
(
)
offsets
)
;
{
masm
.
bind
(
&
rectify
)
;
masm
.
loadPtr
(
Address
(
WasmTlsReg
offsetof
(
TlsData
instance
)
)
callee
)
;
masm
.
loadPtr
(
Address
(
callee
Instance
:
:
offsetOfJSJitArgsRectifier
(
)
)
callee
)
;
masm
.
jump
(
&
rejoinBeforeCall
)
;
}
if
(
oolConvert
.
used
(
)
)
{
masm
.
bind
(
&
oolConvert
)
;
masm
.
setFramePushed
(
nativeFramePushed
)
;
MIRTypeVector
coerceArgTypes
;
JS_ALWAYS_TRUE
(
coerceArgTypes
.
append
(
MIRType
:
:
Pointer
)
)
;
unsigned
offsetToCoerceArgv
=
AlignBytes
(
StackArgBytes
(
coerceArgTypes
)
sizeof
(
Value
)
)
;
MOZ_ASSERT
(
nativeFramePushed
>
=
offsetToCoerceArgv
+
sizeof
(
Value
)
)
;
AssertStackAlignment
(
masm
ABIStackAlignment
)
;
masm
.
storeValue
(
JSReturnOperand
Address
(
masm
.
getStackPointer
(
)
offsetToCoerceArgv
)
)
;
SetExitFP
(
masm
ExitReason
:
:
Fixed
:
:
ImportJit
scratch
)
;
ABIArgMIRTypeIter
i
(
coerceArgTypes
)
;
Address
argv
(
masm
.
getStackPointer
(
)
offsetToCoerceArgv
)
;
if
(
i
-
>
kind
(
)
=
=
ABIArg
:
:
GPR
)
{
masm
.
computeEffectiveAddress
(
argv
i
-
>
gpr
(
)
)
;
}
else
{
masm
.
computeEffectiveAddress
(
argv
scratch
)
;
masm
.
storePtr
(
scratch
Address
(
masm
.
getStackPointer
(
)
i
-
>
offsetFromArgBase
(
)
)
)
;
}
i
+
+
;
MOZ_ASSERT
(
i
.
done
(
)
)
;
AssertStackAlignment
(
masm
ABIStackAlignment
)
;
switch
(
fi
.
sig
(
)
.
ret
(
)
)
{
case
ExprType
:
:
I32
:
masm
.
call
(
SymbolicAddress
:
:
CoerceInPlace_ToInt32
)
;
masm
.
branchTest32
(
Assembler
:
:
Zero
ReturnReg
ReturnReg
throwLabel
)
;
masm
.
unboxInt32
(
Address
(
masm
.
getStackPointer
(
)
offsetToCoerceArgv
)
ReturnReg
)
;
break
;
case
ExprType
:
:
F64
:
case
ExprType
:
:
F32
:
masm
.
call
(
SymbolicAddress
:
:
CoerceInPlace_ToNumber
)
;
masm
.
branchTest32
(
Assembler
:
:
Zero
ReturnReg
ReturnReg
throwLabel
)
;
masm
.
loadDouble
(
Address
(
masm
.
getStackPointer
(
)
offsetToCoerceArgv
)
ReturnDoubleReg
)
;
if
(
fi
.
sig
(
)
.
ret
(
)
=
=
ExprType
:
:
F32
)
masm
.
convertDoubleToFloat32
(
ReturnDoubleReg
ReturnFloat32Reg
)
;
break
;
default
:
MOZ_CRASH
(
"
Unsupported
convert
type
"
)
;
}
ClearExitFP
(
masm
scratch
)
;
masm
.
jump
(
&
done
)
;
masm
.
setFramePushed
(
0
)
;
}
MOZ_ASSERT
(
masm
.
framePushed
(
)
=
=
0
)
;
return
FinishOffsets
(
masm
offsets
)
;
}
struct
ABIFunctionArgs
{
ABIFunctionType
abiType
;
size_t
len
;
explicit
ABIFunctionArgs
(
ABIFunctionType
sig
)
:
abiType
(
ABIFunctionType
(
sig
>
>
ArgType_Shift
)
)
{
len
=
0
;
uint32_t
i
=
uint32_t
(
abiType
)
;
while
(
i
)
{
i
=
i
>
>
ArgType_Shift
;
len
+
+
;
}
}
size_t
length
(
)
const
{
return
len
;
}
MIRType
operator
[
]
(
size_t
i
)
const
{
MOZ_ASSERT
(
i
<
len
)
;
uint32_t
abi
=
uint32_t
(
abiType
)
;
while
(
i
-
-
)
abi
=
abi
>
>
ArgType_Shift
;
return
ToMIRType
(
ABIArgType
(
abi
&
ArgType_Mask
)
)
;
}
}
;
bool
wasm
:
:
GenerateBuiltinThunk
(
MacroAssembler
&
masm
ABIFunctionType
abiType
ExitReason
exitReason
void
*
funcPtr
CallableOffsets
*
offsets
)
{
masm
.
setFramePushed
(
0
)
;
ABIFunctionArgs
args
(
abiType
)
;
uint32_t
framePushed
=
StackDecrementForCall
(
masm
ABIStackAlignment
args
)
;
GenerateExitPrologue
(
masm
framePushed
exitReason
offsets
)
;
unsigned
offsetToCallerStackArgs
=
sizeof
(
Frame
)
+
masm
.
framePushed
(
)
;
Register
scratch
=
ABINonArgReturnReg0
;
for
(
ABIArgIter
<
ABIFunctionArgs
>
i
(
args
)
;
!
i
.
done
(
)
;
i
+
+
)
{
if
(
i
-
>
argInRegister
(
)
)
{
#
ifdef
JS_CODEGEN_ARM
if
(
!
UseHardFpABI
(
)
&
&
IsFloatingPointType
(
i
.
mirType
(
)
)
)
{
FloatRegister
input
=
i
-
>
fpu
(
)
;
if
(
i
.
mirType
(
)
=
=
MIRType
:
:
Float32
)
{
masm
.
ma_vxfer
(
input
Register
:
:
FromCode
(
input
.
id
(
)
)
)
;
}
else
if
(
i
.
mirType
(
)
=
=
MIRType
:
:
Double
)
{
uint32_t
regId
=
input
.
singleOverlay
(
)
.
id
(
)
;
masm
.
ma_vxfer
(
input
Register
:
:
FromCode
(
regId
)
Register
:
:
FromCode
(
regId
+
1
)
)
;
}
}
#
endif
continue
;
}
Address
src
(
masm
.
getStackPointer
(
)
offsetToCallerStackArgs
+
i
-
>
offsetFromArgBase
(
)
)
;
Address
dst
(
masm
.
getStackPointer
(
)
i
-
>
offsetFromArgBase
(
)
)
;
StackCopy
(
masm
i
.
mirType
(
)
scratch
src
dst
)
;
}
AssertStackAlignment
(
masm
ABIStackAlignment
)
;
masm
.
call
(
ImmPtr
(
funcPtr
ImmPtr
:
:
NoCheckToken
(
)
)
)
;
#
if
defined
(
JS_CODEGEN_X86
)
Operand
op
(
esp
0
)
;
MIRType
retType
=
ToMIRType
(
ABIArgType
(
abiType
&
ArgType_Mask
)
)
;
if
(
retType
=
=
MIRType
:
:
Float32
)
{
masm
.
fstp32
(
op
)
;
masm
.
loadFloat32
(
op
ReturnFloat32Reg
)
;
}
else
if
(
retType
=
=
MIRType
:
:
Double
)
{
masm
.
fstp
(
op
)
;
masm
.
loadDouble
(
op
ReturnDoubleReg
)
;
}
#
elif
defined
(
JS_CODEGEN_ARM
)
MIRType
retType
=
ToMIRType
(
ABIArgType
(
abiType
&
ArgType_Mask
)
)
;
if
(
!
UseHardFpABI
(
)
&
&
IsFloatingPointType
(
retType
)
)
masm
.
ma_vxfer
(
r0
r1
d0
)
;
#
endif
GenerateExitEpilogue
(
masm
framePushed
exitReason
offsets
)
;
return
FinishOffsets
(
masm
offsets
)
;
}
static
bool
GenerateTrapExit
(
MacroAssembler
&
masm
Trap
trap
Label
*
throwLabel
CallableOffsets
*
offsets
)
{
masm
.
haltingAlign
(
CodeAlignment
)
;
masm
.
setFramePushed
(
0
)
;
MIRTypeVector
args
;
MOZ_ALWAYS_TRUE
(
args
.
append
(
MIRType
:
:
Int32
)
)
;
uint32_t
framePushed
=
StackDecrementForCall
(
masm
ABIStackAlignment
args
)
;
GenerateExitPrologue
(
masm
framePushed
ExitReason
:
:
Fixed
:
:
Trap
offsets
)
;
ABIArgMIRTypeIter
i
(
args
)
;
if
(
i
-
>
kind
(
)
=
=
ABIArg
:
:
GPR
)
masm
.
move32
(
Imm32
(
int32_t
(
trap
)
)
i
-
>
gpr
(
)
)
;
else
masm
.
store32
(
Imm32
(
int32_t
(
trap
)
)
Address
(
masm
.
getStackPointer
(
)
i
-
>
offsetFromArgBase
(
)
)
)
;
i
+
+
;
MOZ_ASSERT
(
i
.
done
(
)
)
;
masm
.
assertStackAlignment
(
ABIStackAlignment
)
;
masm
.
call
(
SymbolicAddress
:
:
ReportTrap
)
;
masm
.
jump
(
throwLabel
)
;
GenerateExitEpilogue
(
masm
framePushed
ExitReason
:
:
Fixed
:
:
Trap
offsets
)
;
return
FinishOffsets
(
masm
offsets
)
;
}
static
bool
GenerateGenericMemoryAccessTrap
(
MacroAssembler
&
masm
SymbolicAddress
reporter
Label
*
throwLabel
Offsets
*
offsets
)
{
masm
.
haltingAlign
(
CodeAlignment
)
;
offsets
-
>
begin
=
masm
.
currentOffset
(
)
;
masm
.
andToStackPtr
(
Imm32
(
~
(
ABIStackAlignment
-
1
)
)
)
;
if
(
ShadowStackSpace
)
masm
.
subFromStackPtr
(
Imm32
(
ShadowStackSpace
)
)
;
masm
.
call
(
reporter
)
;
masm
.
jump
(
throwLabel
)
;
return
FinishOffsets
(
masm
offsets
)
;
}
static
bool
GenerateOutOfBoundsExit
(
MacroAssembler
&
masm
Label
*
throwLabel
Offsets
*
offsets
)
{
return
GenerateGenericMemoryAccessTrap
(
masm
SymbolicAddress
:
:
ReportOutOfBounds
throwLabel
offsets
)
;
}
static
bool
GenerateUnalignedExit
(
MacroAssembler
&
masm
Label
*
throwLabel
Offsets
*
offsets
)
{
return
GenerateGenericMemoryAccessTrap
(
masm
SymbolicAddress
:
:
ReportUnalignedAccess
throwLabel
offsets
)
;
}
#
if
defined
(
JS_CODEGEN_ARM
)
static
const
LiveRegisterSet
AllRegsExceptPCSP
(
GeneralRegisterSet
(
Registers
:
:
AllMask
&
~
(
(
uint32_t
(
1
)
<
<
Registers
:
:
sp
)
|
(
uint32_t
(
1
)
<
<
Registers
:
:
pc
)
)
)
FloatRegisterSet
(
FloatRegisters
:
:
AllDoubleMask
)
)
;
static_assert
(
!
SupportsSimd
"
high
lanes
of
SIMD
registers
need
to
be
saved
too
.
"
)
;
#
else
static
const
LiveRegisterSet
AllRegsExceptSP
(
GeneralRegisterSet
(
Registers
:
:
AllMask
&
~
(
uint32_t
(
1
)
<
<
Registers
:
:
StackPointer
)
)
FloatRegisterSet
(
FloatRegisters
:
:
AllMask
)
)
;
#
endif
static
bool
GenerateInterruptExit
(
MacroAssembler
&
masm
Label
*
throwLabel
Offsets
*
offsets
)
{
masm
.
haltingAlign
(
CodeAlignment
)
;
offsets
-
>
begin
=
masm
.
currentOffset
(
)
;
#
if
defined
(
JS_CODEGEN_X86
)
|
|
defined
(
JS_CODEGEN_X64
)
masm
.
push
(
Imm32
(
0
)
)
;
masm
.
setFramePushed
(
0
)
;
masm
.
PushFlags
(
)
;
masm
.
PushRegsInMask
(
AllRegsExceptSP
)
;
masm
.
moveStackPtrTo
(
ABINonVolatileReg
)
;
masm
.
andToStackPtr
(
Imm32
(
~
(
ABIStackAlignment
-
1
)
)
)
;
if
(
ShadowStackSpace
)
masm
.
subFromStackPtr
(
Imm32
(
ShadowStackSpace
)
)
;
masm
.
assertStackAlignment
(
ABIStackAlignment
)
;
masm
.
call
(
SymbolicAddress
:
:
HandleExecutionInterrupt
)
;
masm
.
branchTestPtr
(
Assembler
:
:
Zero
ReturnReg
ReturnReg
throwLabel
)
;
masm
.
moveToStackPtr
(
ABINonVolatileReg
)
;
masm
.
storePtr
(
ReturnReg
Address
(
StackPointer
masm
.
framePushed
(
)
)
)
;
masm
.
PopRegsInMask
(
AllRegsExceptSP
)
;
masm
.
PopFlags
(
)
;
MOZ_ASSERT
(
masm
.
framePushed
(
)
=
=
0
)
;
masm
.
ret
(
)
;
#
elif
defined
(
JS_CODEGEN_MIPS32
)
|
|
defined
(
JS_CODEGEN_MIPS64
)
masm
.
subFromStackPtr
(
Imm32
(
2
*
sizeof
(
intptr_t
)
)
)
;
masm
.
setFramePushed
(
0
)
;
static_assert
(
!
SupportsSimd
"
high
lanes
of
SIMD
registers
need
to
be
saved
too
.
"
)
;
masm
.
PushRegsInMask
(
AllRegsExceptSP
)
;
masm
.
moveStackPtrTo
(
s0
)
;
masm
.
ma_and
(
StackPointer
StackPointer
Imm32
(
~
(
ABIStackAlignment
-
1
)
)
)
;
masm
.
storePtr
(
HeapReg
Address
(
s0
masm
.
framePushed
(
)
+
sizeof
(
intptr_t
)
)
)
;
#
ifdef
USES_O32_ABI
masm
.
subFromStackPtr
(
Imm32
(
4
*
sizeof
(
intptr_t
)
)
)
;
#
endif
masm
.
assertStackAlignment
(
ABIStackAlignment
)
;
masm
.
call
(
SymbolicAddress
:
:
HandleExecutionInterrupt
)
;
#
ifdef
USES_O32_ABI
masm
.
addToStackPtr
(
Imm32
(
4
*
sizeof
(
intptr_t
)
)
)
;
#
endif
masm
.
branchTestPtr
(
Assembler
:
:
Zero
ReturnReg
ReturnReg
throwLabel
)
;
masm
.
moveToStackPtr
(
s0
)
;
masm
.
storePtr
(
ReturnReg
Address
(
s0
masm
.
framePushed
(
)
)
)
;
masm
.
PopRegsInMask
(
AllRegsExceptSP
)
;
masm
.
loadPtr
(
Address
(
StackPointer
0
)
HeapReg
)
;
masm
.
addToStackPtr
(
Imm32
(
2
*
sizeof
(
intptr_t
)
)
)
;
masm
.
as_jr
(
HeapReg
)
;
masm
.
loadPtr
(
Address
(
StackPointer
-
int32_t
(
sizeof
(
intptr_t
)
)
)
HeapReg
)
;
#
elif
defined
(
JS_CODEGEN_ARM
)
{
ScratchRegisterScope
scratch
(
masm
)
;
SecondScratchRegisterScope
secondScratch
(
masm
)
;
masm
.
as_alu
(
StackPointer
StackPointer
Imm8
(
4
)
OpSub
)
;
masm
.
setFramePushed
(
0
)
;
masm
.
PushRegsInMask
(
AllRegsExceptPCSP
)
;
}
masm
.
as_mrs
(
r4
)
;
masm
.
as_vmrs
(
r5
)
;
masm
.
mov
(
sp
r6
)
;
masm
.
andToStackPtr
(
Imm32
(
~
(
ABIStackAlignment
-
1
)
)
)
;
masm
.
assertStackAlignment
(
ABIStackAlignment
)
;
masm
.
call
(
SymbolicAddress
:
:
HandleExecutionInterrupt
)
;
masm
.
branchTestPtr
(
Assembler
:
:
Zero
ReturnReg
ReturnReg
throwLabel
)
;
masm
.
mov
(
r6
sp
)
;
masm
.
storePtr
(
ReturnReg
Address
(
sp
masm
.
framePushed
(
)
)
)
;
masm
.
as_vmsr
(
r5
)
;
masm
.
as_msr
(
r4
)
;
masm
.
PopRegsInMask
(
AllRegsExceptPCSP
)
;
MOZ_ASSERT
(
masm
.
framePushed
(
)
=
=
0
)
;
masm
.
ret
(
)
;
#
elif
defined
(
JS_CODEGEN_ARM64
)
MOZ_CRASH
(
)
;
#
elif
defined
(
JS_CODEGEN_NONE
)
MOZ_CRASH
(
)
;
#
else
#
error
"
Unknown
architecture
!
"
#
endif
return
FinishOffsets
(
masm
offsets
)
;
}
static
bool
GenerateThrowStub
(
MacroAssembler
&
masm
Label
*
throwLabel
Offsets
*
offsets
)
{
masm
.
haltingAlign
(
CodeAlignment
)
;
masm
.
bind
(
throwLabel
)
;
offsets
-
>
begin
=
masm
.
currentOffset
(
)
;
masm
.
andToStackPtr
(
Imm32
(
~
(
ABIStackAlignment
-
1
)
)
)
;
if
(
ShadowStackSpace
)
masm
.
subFromStackPtr
(
Imm32
(
ShadowStackSpace
)
)
;
masm
.
call
(
SymbolicAddress
:
:
HandleThrow
)
;
masm
.
moveToStackPtr
(
ReturnReg
)
;
masm
.
move32
(
Imm32
(
FailFP
)
FramePointer
)
;
masm
.
ret
(
)
;
return
FinishOffsets
(
masm
offsets
)
;
}
static
const
LiveRegisterSet
AllAllocatableRegs
=
LiveRegisterSet
(
GeneralRegisterSet
(
Registers
:
:
AllocatableMask
)
FloatRegisterSet
(
FloatRegisters
:
:
AllMask
)
)
;
static
bool
GenerateDebugTrapStub
(
MacroAssembler
&
masm
Label
*
throwLabel
CallableOffsets
*
offsets
)
{
masm
.
haltingAlign
(
CodeAlignment
)
;
masm
.
setFramePushed
(
0
)
;
GenerateExitPrologue
(
masm
0
ExitReason
:
:
Fixed
:
:
DebugTrap
offsets
)
;
masm
.
PushRegsInMask
(
AllAllocatableRegs
)
;
uint32_t
framePushed
=
masm
.
framePushed
(
)
;
Register
scratch
=
ABINonArgReturnReg0
;
masm
.
moveStackPtrTo
(
scratch
)
;
masm
.
subFromStackPtr
(
Imm32
(
sizeof
(
intptr_t
)
)
)
;
masm
.
andToStackPtr
(
Imm32
(
~
(
ABIStackAlignment
-
1
)
)
)
;
masm
.
storePtr
(
scratch
Address
(
masm
.
getStackPointer
(
)
0
)
)
;
if
(
ShadowStackSpace
)
masm
.
subFromStackPtr
(
Imm32
(
ShadowStackSpace
)
)
;
masm
.
assertStackAlignment
(
ABIStackAlignment
)
;
masm
.
call
(
SymbolicAddress
:
:
HandleDebugTrap
)
;
masm
.
branchIfFalseBool
(
ReturnReg
throwLabel
)
;
if
(
ShadowStackSpace
)
masm
.
addToStackPtr
(
Imm32
(
ShadowStackSpace
)
)
;
masm
.
Pop
(
scratch
)
;
masm
.
moveToStackPtr
(
scratch
)
;
masm
.
setFramePushed
(
framePushed
)
;
masm
.
PopRegsInMask
(
AllAllocatableRegs
)
;
GenerateExitEpilogue
(
masm
0
ExitReason
:
:
Fixed
:
:
DebugTrap
offsets
)
;
return
FinishOffsets
(
masm
offsets
)
;
}
bool
wasm
:
:
GenerateStubs
(
const
ModuleEnvironment
&
env
const
FuncImportVector
&
imports
const
FuncExportVector
&
exports
CompiledCode
*
code
)
{
LifoAlloc
lifo
(
STUBS_LIFO_DEFAULT_CHUNK_SIZE
)
;
TempAllocator
alloc
(
&
lifo
)
;
MacroAssembler
masm
(
MacroAssembler
:
:
WasmToken
(
)
alloc
)
;
if
(
!
code
-
>
swap
(
masm
)
)
return
false
;
Label
throwLabel
;
for
(
uint32_t
funcIndex
=
0
;
funcIndex
<
imports
.
length
(
)
;
funcIndex
+
+
)
{
const
FuncImport
&
fi
=
imports
[
funcIndex
]
;
CallableOffsets
interpOffsets
;
if
(
!
GenerateImportInterpExit
(
masm
fi
funcIndex
&
throwLabel
&
interpOffsets
)
)
return
false
;
if
(
!
code
-
>
codeRanges
.
emplaceBack
(
CodeRange
:
:
ImportInterpExit
funcIndex
interpOffsets
)
)
return
false
;
JitExitOffsets
jitOffsets
;
if
(
!
GenerateImportJitExit
(
masm
fi
&
throwLabel
&
jitOffsets
)
)
return
false
;
if
(
!
code
-
>
codeRanges
.
emplaceBack
(
funcIndex
jitOffsets
)
)
return
false
;
}
for
(
const
FuncExport
&
fe
:
exports
)
{
Offsets
offsets
;
if
(
!
GenerateInterpEntry
(
masm
fe
&
offsets
)
)
return
false
;
if
(
!
code
-
>
codeRanges
.
emplaceBack
(
CodeRange
:
:
InterpEntry
fe
.
funcIndex
(
)
offsets
)
)
return
false
;
}
for
(
Trap
trap
:
MakeEnumeratedRange
(
Trap
:
:
Limit
)
)
{
CallableOffsets
offsets
;
if
(
!
GenerateTrapExit
(
masm
trap
&
throwLabel
&
offsets
)
)
return
false
;
if
(
!
code
-
>
codeRanges
.
emplaceBack
(
trap
offsets
)
)
return
false
;
}
Offsets
offsets
;
if
(
!
GenerateOutOfBoundsExit
(
masm
&
throwLabel
&
offsets
)
)
return
false
;
if
(
!
code
-
>
codeRanges
.
emplaceBack
(
CodeRange
:
:
OutOfBoundsExit
offsets
)
)
return
false
;
if
(
!
GenerateUnalignedExit
(
masm
&
throwLabel
&
offsets
)
)
return
false
;
if
(
!
code
-
>
codeRanges
.
emplaceBack
(
CodeRange
:
:
UnalignedExit
offsets
)
)
return
false
;
if
(
!
GenerateInterruptExit
(
masm
&
throwLabel
&
offsets
)
)
return
false
;
if
(
!
code
-
>
codeRanges
.
emplaceBack
(
CodeRange
:
:
Interrupt
offsets
)
)
return
false
;
{
CallableOffsets
offsets
;
if
(
!
GenerateDebugTrapStub
(
masm
&
throwLabel
&
offsets
)
)
return
false
;
if
(
!
code
-
>
codeRanges
.
emplaceBack
(
CodeRange
:
:
DebugTrap
offsets
)
)
return
false
;
}
if
(
!
GenerateThrowStub
(
masm
&
throwLabel
&
offsets
)
)
return
false
;
if
(
!
code
-
>
codeRanges
.
emplaceBack
(
CodeRange
:
:
Throw
offsets
)
)
return
false
;
masm
.
finish
(
)
;
if
(
masm
.
oom
(
)
)
return
false
;
return
code
-
>
swap
(
masm
)
;
}
