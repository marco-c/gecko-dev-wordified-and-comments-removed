#
include
"
wasm
/
WasmBCClass
.
h
"
#
include
"
wasm
/
WasmBCDefs
.
h
"
#
include
"
wasm
/
WasmBCRegDefs
.
h
"
#
include
"
jit
/
MacroAssembler
-
inl
.
h
"
#
include
"
wasm
/
WasmBCClass
-
inl
.
h
"
#
include
"
wasm
/
WasmBCCodegen
-
inl
.
h
"
#
include
"
wasm
/
WasmBCRegDefs
-
inl
.
h
"
#
include
"
wasm
/
WasmBCRegMgmt
-
inl
.
h
"
#
include
"
wasm
/
WasmBCStkMgmt
-
inl
.
h
"
namespace
js
{
namespace
wasm
{
void
BaseCompiler
:
:
bceCheckLocal
(
MemoryAccessDesc
*
access
AccessCheck
*
check
uint32_t
local
)
{
if
(
local
>
=
sizeof
(
BCESet
)
*
8
)
{
return
;
}
uint32_t
offsetGuardLimit
=
GetMaxOffsetGuardLimit
(
moduleEnv_
.
hugeMemoryEnabled
(
)
)
;
if
(
(
bceSafe_
&
(
BCESet
(
1
)
<
<
local
)
)
&
&
access
-
>
offset64
(
)
<
offsetGuardLimit
)
{
check
-
>
omitBoundsCheck
=
true
;
}
bceSafe_
|
=
(
BCESet
(
1
)
<
<
local
)
;
}
void
BaseCompiler
:
:
bceLocalIsUpdated
(
uint32_t
local
)
{
if
(
local
>
=
sizeof
(
BCESet
)
*
8
)
{
return
;
}
bceSafe_
&
=
~
(
BCESet
(
1
)
<
<
local
)
;
}
template
<
>
RegI32
BaseCompiler
:
:
popConstMemoryAccess
<
RegI32
>
(
MemoryAccessDesc
*
access
AccessCheck
*
check
)
{
int32_t
addrTemp
;
MOZ_ALWAYS_TRUE
(
popConst
(
&
addrTemp
)
)
;
uint32_t
addr
=
addrTemp
;
uint32_t
offsetGuardLimit
=
GetMaxOffsetGuardLimit
(
moduleEnv_
.
hugeMemoryEnabled
(
)
)
;
uint64_t
ea
=
uint64_t
(
addr
)
+
uint64_t
(
access
-
>
offset
(
)
)
;
uint64_t
limit
=
moduleEnv_
.
memory
-
>
initialLength32
(
)
+
offsetGuardLimit
;
check
-
>
omitBoundsCheck
=
ea
<
limit
;
check
-
>
omitAlignmentCheck
=
(
ea
&
(
access
-
>
byteSize
(
)
-
1
)
)
=
=
0
;
if
(
ea
<
=
UINT32_MAX
)
{
addr
=
uint32_t
(
ea
)
;
access
-
>
clearOffset
(
)
;
}
RegI32
r
=
needI32
(
)
;
moveImm32
(
int32_t
(
addr
)
r
)
;
return
r
;
}
#
ifdef
ENABLE_WASM_MEMORY64
template
<
>
RegI64
BaseCompiler
:
:
popConstMemoryAccess
<
RegI64
>
(
MemoryAccessDesc
*
access
AccessCheck
*
check
)
{
int64_t
addrTemp
;
MOZ_ALWAYS_TRUE
(
popConst
(
&
addrTemp
)
)
;
uint64_t
addr
=
addrTemp
;
uint32_t
offsetGuardLimit
=
GetMaxOffsetGuardLimit
(
moduleEnv_
.
hugeMemoryEnabled
(
)
)
;
uint64_t
ea
=
addr
+
access
-
>
offset64
(
)
;
bool
overflow
=
ea
<
addr
;
uint64_t
limit
=
moduleEnv_
.
memory
-
>
initialLength64
(
)
+
offsetGuardLimit
;
if
(
!
overflow
)
{
check
-
>
omitBoundsCheck
=
ea
<
limit
;
check
-
>
omitAlignmentCheck
=
(
ea
&
(
access
-
>
byteSize
(
)
-
1
)
)
=
=
0
;
addr
=
uint64_t
(
ea
)
;
access
-
>
clearOffset
(
)
;
}
RegI64
r
=
needI64
(
)
;
moveImm64
(
int64_t
(
addr
)
r
)
;
return
r
;
}
#
endif
template
<
typename
RegType
>
RegType
BaseCompiler
:
:
popMemoryAccess
(
MemoryAccessDesc
*
access
AccessCheck
*
check
)
{
check
-
>
onlyPointerAlignment
=
(
access
-
>
offset64
(
)
&
(
access
-
>
byteSize
(
)
-
1
)
)
=
=
0
;
if
(
hasConst
(
)
)
{
return
popConstMemoryAccess
<
RegType
>
(
access
check
)
;
}
uint32_t
local
;
if
(
peekLocal
(
&
local
)
)
{
bceCheckLocal
(
access
check
local
)
;
}
return
pop
<
RegType
>
(
)
;
}
#
ifdef
JS_64BIT
static
inline
RegI64
RegPtrToRegIntptr
(
RegPtr
r
)
{
return
RegI64
(
Register64
(
Register
(
r
)
)
)
;
}
#
ifndef
WASM_HAS_HEAPREG
static
inline
RegPtr
RegIntptrToRegPtr
(
RegI64
r
)
{
return
RegPtr
(
Register64
(
r
)
.
reg
)
;
}
#
endif
#
else
static
inline
RegI32
RegPtrToRegIntptr
(
RegPtr
r
)
{
return
RegI32
(
Register
(
r
)
)
;
}
#
ifndef
WASM_HAS_HEAPREG
static
inline
RegPtr
RegIntptrToRegPtr
(
RegI32
r
)
{
return
RegPtr
(
Register
(
r
)
)
;
}
#
endif
#
endif
#
ifdef
WASM_HAS_HEAPREG
void
BaseCompiler
:
:
pushHeapBase
(
)
{
RegPtr
heapBase
=
need
<
RegPtr
>
(
)
;
move
(
RegPtr
(
HeapReg
)
heapBase
)
;
push
(
RegPtrToRegIntptr
(
heapBase
)
)
;
}
#
else
void
BaseCompiler
:
:
pushHeapBase
(
)
{
RegPtr
heapBase
=
need
<
RegPtr
>
(
)
;
fr
.
loadTlsPtr
(
heapBase
)
;
masm
.
loadPtr
(
Address
(
heapBase
TlsData
:
:
offsetOfMemoryBase
(
)
)
heapBase
)
;
push
(
RegPtrToRegIntptr
(
heapBase
)
)
;
}
#
endif
void
BaseCompiler
:
:
branchAddNoOverflow
(
uint64_t
offset
RegI32
ptr
Label
*
ok
)
{
MOZ_ASSERT
(
offset
<
=
UINT32_MAX
)
;
masm
.
branchAdd32
(
Assembler
:
:
CarryClear
Imm32
(
uint32_t
(
offset
)
)
ptr
ok
)
;
}
#
ifdef
ENABLE_WASM_MEMORY64
void
BaseCompiler
:
:
branchAddNoOverflow
(
uint64_t
offset
RegI64
ptr
Label
*
ok
)
{
#
if
defined
(
JS_64BIT
)
masm
.
branchAddPtr
(
Assembler
:
:
CarryClear
ImmWord
(
offset
)
Register64
(
ptr
)
.
reg
ok
)
;
#
else
masm
.
branchAdd64
(
Assembler
:
:
CarryClear
Imm64
(
offset
)
ptr
ok
)
;
#
endif
}
#
endif
void
BaseCompiler
:
:
branchTestLowZero
(
RegI32
ptr
Imm32
mask
Label
*
ok
)
{
masm
.
branchTest32
(
Assembler
:
:
Zero
ptr
mask
ok
)
;
}
#
ifdef
ENABLE_WASM_MEMORY64
void
BaseCompiler
:
:
branchTestLowZero
(
RegI64
ptr
Imm32
mask
Label
*
ok
)
{
#
ifdef
JS_64BIT
masm
.
branchTestPtr
(
Assembler
:
:
Zero
Register64
(
ptr
)
.
reg
mask
ok
)
;
#
else
masm
.
branchTestPtr
(
Assembler
:
:
Zero
ptr
.
low
mask
ok
)
;
#
endif
}
#
endif
void
BaseCompiler
:
:
boundsCheck4GBOrLargerAccess
(
RegPtr
tls
RegI32
ptr
Label
*
ok
)
{
#
ifdef
JS_64BIT
RegI64
ptr64
=
fromI32
(
ptr
)
;
#
ifdef
RABALDR_ZERO_EXTENDS
masm
.
debugAssertCanonicalInt32
(
ptr
)
;
#
else
masm
.
move32To64ZeroExtend
(
ptr
ptr64
)
;
#
endif
boundsCheck4GBOrLargerAccess
(
tls
ptr64
ok
)
;
#
ifdef
RABALDR_ZERO_EXTENDS
#
else
masm
.
move64To32
(
ptr64
ptr
)
;
#
endif
#
else
MOZ_CRASH
(
"
No
32
-
bit
support
"
)
;
#
endif
}
void
BaseCompiler
:
:
boundsCheckBelow4GBAccess
(
RegPtr
tls
RegI32
ptr
Label
*
ok
)
{
masm
.
wasmBoundsCheck32
(
Assembler
:
:
Below
ptr
Address
(
tls
TlsData
:
:
offsetOfBoundsCheckLimit
(
)
)
ok
)
;
}
void
BaseCompiler
:
:
boundsCheck4GBOrLargerAccess
(
RegPtr
tls
RegI64
ptr
Label
*
ok
)
{
masm
.
wasmBoundsCheck64
(
Assembler
:
:
Below
ptr
Address
(
tls
TlsData
:
:
offsetOfBoundsCheckLimit
(
)
)
ok
)
;
}
void
BaseCompiler
:
:
boundsCheckBelow4GBAccess
(
RegPtr
tls
RegI64
ptr
Label
*
ok
)
{
boundsCheck4GBOrLargerAccess
(
tls
ptr
ok
)
;
}
static
inline
void
ToValidIndex
(
MacroAssembler
&
masm
RegI32
ptr
)
{
#
if
defined
(
JS_CODEGEN_MIPS64
)
|
|
defined
(
JS_CODEGEN_LOONG64
)
masm
.
move32To64ZeroExtend
(
ptr
Register64
(
ptr
)
)
;
#
endif
}
#
if
defined
(
ENABLE_WASM_MEMORY64
)
static
inline
void
ToValidIndex
(
MacroAssembler
&
masm
RegI64
ptr
)
{
}
#
endif
template
<
typename
RegIndexType
>
void
BaseCompiler
:
:
prepareMemoryAccess
(
MemoryAccessDesc
*
access
AccessCheck
*
check
RegPtr
tls
RegIndexType
ptr
)
{
uint32_t
offsetGuardLimit
=
GetMaxOffsetGuardLimit
(
moduleEnv_
.
hugeMemoryEnabled
(
)
)
;
if
(
access
-
>
offset64
(
)
>
=
offsetGuardLimit
|
|
access
-
>
offset64
(
)
>
UINT32_MAX
|
|
(
access
-
>
isAtomic
(
)
&
&
!
check
-
>
omitAlignmentCheck
&
&
!
check
-
>
onlyPointerAlignment
)
)
{
Label
ok
;
branchAddNoOverflow
(
access
-
>
offset64
(
)
ptr
&
ok
)
;
masm
.
wasmTrap
(
Trap
:
:
OutOfBounds
bytecodeOffset
(
)
)
;
masm
.
bind
(
&
ok
)
;
access
-
>
clearOffset
(
)
;
check
-
>
onlyPointerAlignment
=
true
;
}
if
(
access
-
>
isAtomic
(
)
&
&
!
check
-
>
omitAlignmentCheck
)
{
MOZ_ASSERT
(
check
-
>
onlyPointerAlignment
)
;
Label
ok
;
branchTestLowZero
(
ptr
Imm32
(
access
-
>
byteSize
(
)
-
1
)
&
ok
)
;
masm
.
wasmTrap
(
Trap
:
:
UnalignedAccess
bytecodeOffset
(
)
)
;
masm
.
bind
(
&
ok
)
;
}
if
(
moduleEnv_
.
hugeMemoryEnabled
(
)
)
{
MOZ_ASSERT_IF
(
check
-
>
omitBoundsCheck
tls
.
isInvalid
(
)
)
;
}
#
ifdef
WASM_HAS_HEAPREG
MOZ_ASSERT_IF
(
check
-
>
omitBoundsCheck
tls
.
isInvalid
(
)
)
;
#
endif
if
(
!
moduleEnv_
.
hugeMemoryEnabled
(
)
&
&
!
check
-
>
omitBoundsCheck
)
{
Label
ok
;
#
ifdef
JS_64BIT
static_assert
(
0x100000000
%
PageSize
=
=
0
)
;
if
(
!
moduleEnv_
.
memory
-
>
boundsCheckLimitIs32Bits
(
)
&
&
MaxMemoryPages
(
moduleEnv_
.
memory
-
>
indexType
(
)
)
>
=
Pages
(
0x100000000
/
PageSize
)
)
{
boundsCheck4GBOrLargerAccess
(
tls
ptr
&
ok
)
;
}
else
{
boundsCheckBelow4GBAccess
(
tls
ptr
&
ok
)
;
}
#
else
boundsCheckBelow4GBAccess
(
tls
ptr
&
ok
)
;
#
endif
masm
.
wasmTrap
(
Trap
:
:
OutOfBounds
bytecodeOffset
(
)
)
;
masm
.
bind
(
&
ok
)
;
}
ToValidIndex
(
masm
ptr
)
;
}
template
<
typename
RegIndexType
>
void
BaseCompiler
:
:
computeEffectiveAddress
(
MemoryAccessDesc
*
access
)
{
if
(
access
-
>
offset
(
)
)
{
Label
ok
;
RegIndexType
ptr
=
pop
<
RegIndexType
>
(
)
;
branchAddNoOverflow
(
access
-
>
offset64
(
)
ptr
&
ok
)
;
masm
.
wasmTrap
(
Trap
:
:
OutOfBounds
bytecodeOffset
(
)
)
;
masm
.
bind
(
&
ok
)
;
access
-
>
clearOffset
(
)
;
push
(
ptr
)
;
}
}
bool
BaseCompiler
:
:
needTlsForAccess
(
const
AccessCheck
&
check
)
{
#
ifndef
WASM_HAS_HEAPREG
return
true
;
#
else
return
!
moduleEnv_
.
hugeMemoryEnabled
(
)
&
&
!
check
.
omitBoundsCheck
;
#
endif
}
RegPtr
BaseCompiler
:
:
maybeLoadTlsForAccess
(
const
AccessCheck
&
check
)
{
if
(
needTlsForAccess
(
check
)
)
{
RegPtr
tls
=
need
<
RegPtr
>
(
)
;
fr
.
loadTlsPtr
(
tls
)
;
return
tls
;
}
return
RegPtr
:
:
Invalid
(
)
;
}
RegPtr
BaseCompiler
:
:
maybeLoadTlsForAccess
(
const
AccessCheck
&
check
RegPtr
specific
)
{
if
(
needTlsForAccess
(
check
)
)
{
fr
.
loadTlsPtr
(
specific
)
;
return
specific
;
}
return
RegPtr
:
:
Invalid
(
)
;
}
void
BaseCompiler
:
:
executeLoad
(
MemoryAccessDesc
*
access
AccessCheck
*
check
RegPtr
tls
RegI32
ptr
AnyReg
dest
RegI32
temp
)
{
#
if
defined
(
JS_CODEGEN_X64
)
MOZ_ASSERT
(
temp
.
isInvalid
(
)
)
;
Operand
srcAddr
(
HeapReg
ptr
TimesOne
access
-
>
offset
(
)
)
;
if
(
dest
.
tag
=
=
AnyReg
:
:
I64
)
{
masm
.
wasmLoadI64
(
*
access
srcAddr
dest
.
i64
(
)
)
;
}
else
{
masm
.
wasmLoad
(
*
access
srcAddr
dest
.
any
(
)
)
;
}
#
elif
defined
(
JS_CODEGEN_X86
)
MOZ_ASSERT
(
temp
.
isInvalid
(
)
)
;
masm
.
addPtr
(
Address
(
tls
TlsData
:
:
offsetOfMemoryBase
(
)
)
ptr
)
;
Operand
srcAddr
(
ptr
access
-
>
offset
(
)
)
;
if
(
dest
.
tag
=
=
AnyReg
:
:
I64
)
{
MOZ_ASSERT
(
dest
.
i64
(
)
=
=
specific_
.
abiReturnRegI64
)
;
masm
.
wasmLoadI64
(
*
access
srcAddr
dest
.
i64
(
)
)
;
}
else
{
masm
.
wasmLoad
(
*
access
srcAddr
dest
.
any
(
)
)
;
}
#
elif
defined
(
JS_CODEGEN_MIPS64
)
if
(
IsUnaligned
(
*
access
)
)
{
switch
(
dest
.
tag
)
{
case
AnyReg
:
:
I64
:
masm
.
wasmUnalignedLoadI64
(
*
access
HeapReg
ptr
ptr
dest
.
i64
(
)
temp
)
;
break
;
case
AnyReg
:
:
F32
:
masm
.
wasmUnalignedLoadFP
(
*
access
HeapReg
ptr
ptr
dest
.
f32
(
)
temp
)
;
break
;
case
AnyReg
:
:
F64
:
masm
.
wasmUnalignedLoadFP
(
*
access
HeapReg
ptr
ptr
dest
.
f64
(
)
temp
)
;
break
;
case
AnyReg
:
:
I32
:
masm
.
wasmUnalignedLoad
(
*
access
HeapReg
ptr
ptr
dest
.
i32
(
)
temp
)
;
break
;
default
:
MOZ_CRASH
(
"
Unexpected
type
"
)
;
}
}
else
{
if
(
dest
.
tag
=
=
AnyReg
:
:
I64
)
{
masm
.
wasmLoadI64
(
*
access
HeapReg
ptr
ptr
dest
.
i64
(
)
)
;
}
else
{
masm
.
wasmLoad
(
*
access
HeapReg
ptr
ptr
dest
.
any
(
)
)
;
}
}
#
elif
defined
(
JS_CODEGEN_ARM
)
MOZ_ASSERT
(
temp
.
isInvalid
(
)
)
;
if
(
dest
.
tag
=
=
AnyReg
:
:
I64
)
{
masm
.
wasmLoadI64
(
*
access
HeapReg
ptr
ptr
dest
.
i64
(
)
)
;
}
else
{
masm
.
wasmLoad
(
*
access
HeapReg
ptr
ptr
dest
.
any
(
)
)
;
}
#
elif
defined
(
JS_CODEGEN_ARM64
)
MOZ_ASSERT
(
temp
.
isInvalid
(
)
)
;
if
(
dest
.
tag
=
=
AnyReg
:
:
I64
)
{
masm
.
wasmLoadI64
(
*
access
HeapReg
ptr
dest
.
i64
(
)
)
;
}
else
{
masm
.
wasmLoad
(
*
access
HeapReg
ptr
dest
.
any
(
)
)
;
}
#
elif
defined
(
JS_CODEGEN_LOONG64
)
MOZ_ASSERT
(
temp
.
isInvalid
(
)
)
;
if
(
dest
.
tag
=
=
AnyReg
:
:
I64
)
{
masm
.
wasmLoadI64
(
*
access
HeapReg
ptr
ptr
dest
.
i64
(
)
)
;
}
else
{
masm
.
wasmLoad
(
*
access
HeapReg
ptr
ptr
dest
.
any
(
)
)
;
}
#
else
MOZ_CRASH
(
"
BaseCompiler
platform
hook
:
load
"
)
;
#
endif
}
void
BaseCompiler
:
:
load
(
MemoryAccessDesc
*
access
AccessCheck
*
check
RegPtr
tls
RegI32
ptr
AnyReg
dest
RegI32
temp
)
{
prepareMemoryAccess
(
access
check
tls
ptr
)
;
executeLoad
(
access
check
tls
ptr
dest
temp
)
;
}
#
ifdef
ENABLE_WASM_MEMORY64
void
BaseCompiler
:
:
load
(
MemoryAccessDesc
*
access
AccessCheck
*
check
RegPtr
tls
RegI64
ptr
AnyReg
dest
RegI64
temp
)
{
prepareMemoryAccess
(
access
check
tls
ptr
)
;
#
if
!
defined
(
JS_64BIT
)
return
executeLoad
(
access
check
tls
RegI32
(
ptr
.
low
)
dest
maybeFromI64
(
temp
)
)
;
#
elif
defined
(
JS_CODEGEN_X64
)
|
|
defined
(
JS_CODEGEN_ARM64
)
return
executeLoad
(
access
check
tls
RegI32
(
ptr
.
reg
)
dest
maybeFromI64
(
temp
)
)
;
#
elif
defined
(
JS_CODEGEN_MIPS64
)
|
|
defined
(
JS_CODEGEN_LOONG64
)
return
executeLoad
(
access
check
tls
RegI32
(
ptr
.
reg
)
dest
maybeFromI64
(
temp
)
)
;
#
else
MOZ_CRASH
(
"
Missing
platform
hook
"
)
;
#
endif
}
#
endif
void
BaseCompiler
:
:
executeStore
(
MemoryAccessDesc
*
access
AccessCheck
*
check
RegPtr
tls
RegI32
ptr
AnyReg
src
RegI32
temp
)
{
#
if
defined
(
JS_CODEGEN_X64
)
MOZ_ASSERT
(
temp
.
isInvalid
(
)
)
;
Operand
dstAddr
(
HeapReg
ptr
TimesOne
access
-
>
offset
(
)
)
;
masm
.
wasmStore
(
*
access
src
.
any
(
)
dstAddr
)
;
#
elif
defined
(
JS_CODEGEN_X86
)
MOZ_ASSERT
(
temp
.
isInvalid
(
)
)
;
masm
.
addPtr
(
Address
(
tls
TlsData
:
:
offsetOfMemoryBase
(
)
)
ptr
)
;
Operand
dstAddr
(
ptr
access
-
>
offset
(
)
)
;
if
(
access
-
>
type
(
)
=
=
Scalar
:
:
Int64
)
{
masm
.
wasmStoreI64
(
*
access
src
.
i64
(
)
dstAddr
)
;
}
else
{
AnyRegister
value
;
ScratchI8
scratch
(
*
this
)
;
if
(
src
.
tag
=
=
AnyReg
:
:
I64
)
{
if
(
access
-
>
byteSize
(
)
=
=
1
&
&
!
ra
.
isSingleByteI32
(
src
.
i64
(
)
.
low
)
)
{
masm
.
mov
(
src
.
i64
(
)
.
low
scratch
)
;
value
=
AnyRegister
(
scratch
)
;
}
else
{
value
=
AnyRegister
(
src
.
i64
(
)
.
low
)
;
}
}
else
if
(
access
-
>
byteSize
(
)
=
=
1
&
&
!
ra
.
isSingleByteI32
(
src
.
i32
(
)
)
)
{
masm
.
mov
(
src
.
i32
(
)
scratch
)
;
value
=
AnyRegister
(
scratch
)
;
}
else
{
value
=
src
.
any
(
)
;
}
masm
.
wasmStore
(
*
access
value
dstAddr
)
;
}
#
elif
defined
(
JS_CODEGEN_ARM
)
MOZ_ASSERT
(
temp
.
isInvalid
(
)
)
;
if
(
access
-
>
type
(
)
=
=
Scalar
:
:
Int64
)
{
masm
.
wasmStoreI64
(
*
access
src
.
i64
(
)
HeapReg
ptr
ptr
)
;
}
else
if
(
src
.
tag
=
=
AnyReg
:
:
I64
)
{
masm
.
wasmStore
(
*
access
AnyRegister
(
src
.
i64
(
)
.
low
)
HeapReg
ptr
ptr
)
;
}
else
{
masm
.
wasmStore
(
*
access
src
.
any
(
)
HeapReg
ptr
ptr
)
;
}
#
elif
defined
(
JS_CODEGEN_MIPS64
)
if
(
IsUnaligned
(
*
access
)
)
{
switch
(
src
.
tag
)
{
case
AnyReg
:
:
I64
:
masm
.
wasmUnalignedStoreI64
(
*
access
src
.
i64
(
)
HeapReg
ptr
ptr
temp
)
;
break
;
case
AnyReg
:
:
F32
:
masm
.
wasmUnalignedStoreFP
(
*
access
src
.
f32
(
)
HeapReg
ptr
ptr
temp
)
;
break
;
case
AnyReg
:
:
F64
:
masm
.
wasmUnalignedStoreFP
(
*
access
src
.
f64
(
)
HeapReg
ptr
ptr
temp
)
;
break
;
case
AnyReg
:
:
I32
:
masm
.
wasmUnalignedStore
(
*
access
src
.
i32
(
)
HeapReg
ptr
ptr
temp
)
;
break
;
default
:
MOZ_CRASH
(
"
Unexpected
type
"
)
;
}
}
else
{
if
(
src
.
tag
=
=
AnyReg
:
:
I64
)
{
masm
.
wasmStoreI64
(
*
access
src
.
i64
(
)
HeapReg
ptr
ptr
)
;
}
else
{
masm
.
wasmStore
(
*
access
src
.
any
(
)
HeapReg
ptr
ptr
)
;
}
}
#
elif
defined
(
JS_CODEGEN_ARM64
)
MOZ_ASSERT
(
temp
.
isInvalid
(
)
)
;
if
(
access
-
>
type
(
)
=
=
Scalar
:
:
Int64
)
{
masm
.
wasmStoreI64
(
*
access
src
.
i64
(
)
HeapReg
ptr
)
;
}
else
{
masm
.
wasmStore
(
*
access
src
.
any
(
)
HeapReg
ptr
)
;
}
#
elif
defined
(
JS_CODEGEN_LOONG64
)
MOZ_ASSERT
(
temp
.
isInvalid
(
)
)
;
if
(
access
-
>
type
(
)
=
=
Scalar
:
:
Int64
)
{
masm
.
wasmStoreI64
(
*
access
src
.
i64
(
)
HeapReg
ptr
ptr
)
;
}
else
{
masm
.
wasmStore
(
*
access
src
.
any
(
)
HeapReg
ptr
ptr
)
;
}
#
else
MOZ_CRASH
(
"
BaseCompiler
platform
hook
:
store
"
)
;
#
endif
}
void
BaseCompiler
:
:
store
(
MemoryAccessDesc
*
access
AccessCheck
*
check
RegPtr
tls
RegI32
ptr
AnyReg
src
RegI32
temp
)
{
prepareMemoryAccess
(
access
check
tls
ptr
)
;
executeStore
(
access
check
tls
ptr
src
temp
)
;
}
#
ifdef
ENABLE_WASM_MEMORY64
void
BaseCompiler
:
:
store
(
MemoryAccessDesc
*
access
AccessCheck
*
check
RegPtr
tls
RegI64
ptr
AnyReg
src
RegI64
temp
)
{
prepareMemoryAccess
(
access
check
tls
ptr
)
;
#
if
!
defined
(
JS_64BIT
)
return
executeStore
(
access
check
tls
RegI32
(
ptr
.
low
)
src
maybeFromI64
(
temp
)
)
;
#
elif
defined
(
JS_CODEGEN_X64
)
|
|
defined
(
JS_CODEGEN_ARM64
)
|
|
\
defined
(
JS_CODEGEN_MIPS64
)
|
|
defined
(
JS_CODEGEN_LOONG64
)
return
executeStore
(
access
check
tls
RegI32
(
ptr
.
reg
)
src
maybeFromI64
(
temp
)
)
;
#
else
MOZ_CRASH
(
"
Missing
platform
hook
"
)
;
#
endif
}
#
endif
template
<
typename
RegType
>
void
BaseCompiler
:
:
doLoadCommon
(
MemoryAccessDesc
*
access
AccessCheck
check
ValType
type
)
{
RegPtr
tls
;
RegType
temp
;
#
if
defined
(
JS_CODEGEN_MIPS64
)
temp
=
need
<
RegType
>
(
)
;
#
endif
switch
(
type
.
kind
(
)
)
{
case
ValType
:
:
I32
:
{
RegType
rp
=
popMemoryAccess
<
RegType
>
(
access
&
check
)
;
RegI32
rv
=
needI32
(
)
;
tls
=
maybeLoadTlsForAccess
(
check
)
;
load
(
access
&
check
tls
rp
AnyReg
(
rv
)
temp
)
;
push
(
rv
)
;
free
(
rp
)
;
break
;
}
case
ValType
:
:
I64
:
{
RegI64
rv
;
RegType
rp
;
#
ifdef
JS_CODEGEN_X86
rv
=
specific_
.
abiReturnRegI64
;
needI64
(
rv
)
;
rp
=
popMemoryAccess
<
RegType
>
(
access
&
check
)
;
#
else
rp
=
popMemoryAccess
<
RegType
>
(
access
&
check
)
;
rv
=
needI64
(
)
;
#
endif
tls
=
maybeLoadTlsForAccess
(
check
)
;
load
(
access
&
check
tls
rp
AnyReg
(
rv
)
temp
)
;
push
(
rv
)
;
free
(
rp
)
;
break
;
}
case
ValType
:
:
F32
:
{
RegType
rp
=
popMemoryAccess
<
RegType
>
(
access
&
check
)
;
RegF32
rv
=
needF32
(
)
;
tls
=
maybeLoadTlsForAccess
(
check
)
;
load
(
access
&
check
tls
rp
AnyReg
(
rv
)
temp
)
;
push
(
rv
)
;
free
(
rp
)
;
break
;
}
case
ValType
:
:
F64
:
{
RegType
rp
=
popMemoryAccess
<
RegType
>
(
access
&
check
)
;
RegF64
rv
=
needF64
(
)
;
tls
=
maybeLoadTlsForAccess
(
check
)
;
load
(
access
&
check
tls
rp
AnyReg
(
rv
)
temp
)
;
push
(
rv
)
;
free
(
rp
)
;
break
;
}
#
ifdef
ENABLE_WASM_SIMD
case
ValType
:
:
V128
:
{
RegType
rp
=
popMemoryAccess
<
RegType
>
(
access
&
check
)
;
RegV128
rv
=
needV128
(
)
;
tls
=
maybeLoadTlsForAccess
(
check
)
;
load
(
access
&
check
tls
rp
AnyReg
(
rv
)
temp
)
;
push
(
rv
)
;
free
(
rp
)
;
break
;
}
#
endif
default
:
MOZ_CRASH
(
"
load
type
"
)
;
break
;
}
maybeFree
(
tls
)
;
maybeFree
(
temp
)
;
}
void
BaseCompiler
:
:
loadCommon
(
MemoryAccessDesc
*
access
AccessCheck
check
ValType
type
)
{
if
(
isMem32
(
)
)
{
doLoadCommon
<
RegI32
>
(
access
check
type
)
;
}
else
{
#
ifdef
ENABLE_WASM_MEMORY64
doLoadCommon
<
RegI64
>
(
access
check
type
)
;
#
else
MOZ_CRASH
(
"
Memory64
not
enabled
/
supported
on
this
platform
"
)
;
#
endif
}
}
template
<
typename
RegType
>
void
BaseCompiler
:
:
doStoreCommon
(
MemoryAccessDesc
*
access
AccessCheck
check
ValType
resultType
)
{
RegPtr
tls
;
RegType
temp
;
#
if
defined
(
JS_CODEGEN_MIPS64
)
temp
=
need
<
RegType
>
(
)
;
#
endif
switch
(
resultType
.
kind
(
)
)
{
case
ValType
:
:
I32
:
{
RegI32
rv
=
popI32
(
)
;
RegType
rp
=
popMemoryAccess
<
RegType
>
(
access
&
check
)
;
tls
=
maybeLoadTlsForAccess
(
check
)
;
store
(
access
&
check
tls
rp
AnyReg
(
rv
)
temp
)
;
free
(
rp
)
;
free
(
rv
)
;
break
;
}
case
ValType
:
:
I64
:
{
RegI64
rv
=
popI64
(
)
;
RegType
rp
=
popMemoryAccess
<
RegType
>
(
access
&
check
)
;
tls
=
maybeLoadTlsForAccess
(
check
)
;
store
(
access
&
check
tls
rp
AnyReg
(
rv
)
temp
)
;
free
(
rp
)
;
free
(
rv
)
;
break
;
}
case
ValType
:
:
F32
:
{
RegF32
rv
=
popF32
(
)
;
RegType
rp
=
popMemoryAccess
<
RegType
>
(
access
&
check
)
;
tls
=
maybeLoadTlsForAccess
(
check
)
;
store
(
access
&
check
tls
rp
AnyReg
(
rv
)
temp
)
;
free
(
rp
)
;
free
(
rv
)
;
break
;
}
case
ValType
:
:
F64
:
{
RegF64
rv
=
popF64
(
)
;
RegType
rp
=
popMemoryAccess
<
RegType
>
(
access
&
check
)
;
tls
=
maybeLoadTlsForAccess
(
check
)
;
store
(
access
&
check
tls
rp
AnyReg
(
rv
)
temp
)
;
free
(
rp
)
;
free
(
rv
)
;
break
;
}
#
ifdef
ENABLE_WASM_SIMD
case
ValType
:
:
V128
:
{
RegV128
rv
=
popV128
(
)
;
RegType
rp
=
popMemoryAccess
<
RegType
>
(
access
&
check
)
;
tls
=
maybeLoadTlsForAccess
(
check
)
;
store
(
access
&
check
tls
rp
AnyReg
(
rv
)
temp
)
;
free
(
rp
)
;
free
(
rv
)
;
break
;
}
#
endif
default
:
MOZ_CRASH
(
"
store
type
"
)
;
break
;
}
maybeFree
(
tls
)
;
maybeFree
(
temp
)
;
}
void
BaseCompiler
:
:
storeCommon
(
MemoryAccessDesc
*
access
AccessCheck
check
ValType
type
)
{
if
(
isMem32
(
)
)
{
doStoreCommon
<
RegI32
>
(
access
check
type
)
;
}
else
{
#
ifdef
ENABLE_WASM_MEMORY64
doStoreCommon
<
RegI64
>
(
access
check
type
)
;
#
else
MOZ_CRASH
(
"
Memory64
not
enabled
/
supported
on
this
platform
"
)
;
#
endif
}
}
static
inline
Register
ToRegister
(
RegI32
r
)
{
return
Register
(
r
)
;
}
#
ifdef
ENABLE_WASM_MEMORY64
#
ifdef
JS_PUNBOX64
static
inline
Register
ToRegister
(
RegI64
r
)
{
return
r
.
reg
;
}
#
else
static
inline
Register
ToRegister
(
RegI64
r
)
{
return
r
.
low
;
}
#
endif
#
endif
#
ifdef
WASM_HAS_HEAPREG
template
<
typename
RegIndexType
>
BaseIndex
BaseCompiler
:
:
prepareAtomicMemoryAccess
(
MemoryAccessDesc
*
access
AccessCheck
*
check
RegPtr
tls
RegIndexType
ptr
)
{
MOZ_ASSERT
(
needTlsForAccess
(
*
check
)
=
=
tls
.
isValid
(
)
)
;
prepareMemoryAccess
(
access
check
tls
ptr
)
;
return
BaseIndex
(
HeapReg
ToRegister
(
ptr
)
TimesOne
access
-
>
offset
(
)
)
;
}
#
else
template
<
typename
RegIndexType
>
Address
BaseCompiler
:
:
prepareAtomicMemoryAccess
(
MemoryAccessDesc
*
access
AccessCheck
*
check
RegPtr
tls
RegIndexType
ptr
)
{
MOZ_ASSERT
(
needTlsForAccess
(
*
check
)
=
=
tls
.
isValid
(
)
)
;
prepareMemoryAccess
(
access
check
tls
ptr
)
;
masm
.
addPtr
(
Address
(
tls
TlsData
:
:
offsetOfMemoryBase
(
)
)
ToRegister
(
ptr
)
)
;
return
Address
(
ToRegister
(
ptr
)
access
-
>
offset
(
)
)
;
}
#
endif
#
ifndef
WASM_HAS_HEAPREG
#
ifdef
JS_CODEGEN_X86
using
ScratchAtomicNoHeapReg
=
ScratchEBX
;
#
else
#
error
"
Unimplemented
porting
interface
"
#
endif
#
endif
namespace
atomic_load64
{
#
ifdef
JS_CODEGEN_ARM
static
void
Allocate
(
BaseCompiler
*
bc
RegI64
*
rd
RegI64
*
)
{
*
rd
=
bc
-
>
needI64Pair
(
)
;
}
static
void
Deallocate
(
BaseCompiler
*
bc
RegI64
)
{
}
#
elif
defined
JS_CODEGEN_X86
static
void
Allocate
(
BaseCompiler
*
bc
RegI64
*
rd
RegI64
*
temp
)
{
bc
-
>
needI32
(
bc
-
>
specific_
.
ecx
)
;
*
temp
=
bc
-
>
specific_
.
ecx_ebx
;
bc
-
>
needI64
(
bc
-
>
specific_
.
edx_eax
)
;
*
rd
=
bc
-
>
specific_
.
edx_eax
;
}
static
void
Deallocate
(
BaseCompiler
*
bc
RegI64
temp
)
{
MOZ_ASSERT
(
temp
.
high
=
=
js
:
:
jit
:
:
ecx
)
;
bc
-
>
freeI32
(
bc
-
>
specific_
.
ecx
)
;
}
#
elif
defined
(
__wasi__
)
|
|
(
defined
(
JS_CODEGEN_NONE
)
&
&
!
defined
(
JS_64BIT
)
)
static
void
Allocate
(
BaseCompiler
*
RegI64
*
RegI64
*
)
{
}
static
void
Deallocate
(
BaseCompiler
*
RegI64
)
{
}
#
endif
}
#
if
!
defined
(
JS_64BIT
)
template
<
typename
RegIndexType
>
void
BaseCompiler
:
:
atomicLoad64
(
MemoryAccessDesc
*
access
)
{
RegI64
rd
temp
;
atomic_load64
:
:
Allocate
(
this
&
rd
&
temp
)
;
AccessCheck
check
;
RegIndexType
rp
=
popMemoryAccess
<
RegIndexType
>
(
access
&
check
)
;
#
ifdef
WASM_HAS_HEAPREG
RegPtr
tls
=
maybeLoadTlsForAccess
(
check
)
;
auto
memaddr
=
prepareAtomicMemoryAccess
(
access
&
check
tls
rp
)
;
masm
.
wasmAtomicLoad64
(
*
access
memaddr
temp
rd
)
;
maybeFree
(
tls
)
;
#
else
ScratchAtomicNoHeapReg
scratch
(
*
this
)
;
RegPtr
tls
=
maybeLoadTlsForAccess
(
check
RegIntptrToRegPtr
(
scratch
)
)
;
auto
memaddr
=
prepareAtomicMemoryAccess
(
access
&
check
tls
rp
)
;
masm
.
wasmAtomicLoad64
(
*
access
memaddr
temp
rd
)
;
MOZ_ASSERT
(
tls
=
=
scratch
)
;
#
endif
free
(
rp
)
;
atomic_load64
:
:
Deallocate
(
this
temp
)
;
pushI64
(
rd
)
;
}
#
endif
void
BaseCompiler
:
:
atomicLoad
(
MemoryAccessDesc
*
access
ValType
type
)
{
Scalar
:
:
Type
viewType
=
access
-
>
type
(
)
;
if
(
Scalar
:
:
byteSize
(
viewType
)
<
=
sizeof
(
void
*
)
)
{
loadCommon
(
access
AccessCheck
(
)
type
)
;
return
;
}
MOZ_ASSERT
(
type
=
=
ValType
:
:
I64
&
&
Scalar
:
:
byteSize
(
viewType
)
=
=
8
)
;
#
if
!
defined
(
JS_64BIT
)
if
(
isMem32
(
)
)
{
atomicLoad64
<
RegI32
>
(
access
)
;
}
else
{
#
ifdef
ENABLE_WASM_MEMORY64
atomicLoad64
<
RegI64
>
(
access
)
;
#
else
MOZ_CRASH
(
"
Memory64
not
enabled
/
supported
on
this
platform
"
)
;
#
endif
}
#
else
MOZ_CRASH
(
"
Should
not
happen
"
)
;
#
endif
}
void
BaseCompiler
:
:
atomicStore
(
MemoryAccessDesc
*
access
ValType
type
)
{
Scalar
:
:
Type
viewType
=
access
-
>
type
(
)
;
if
(
Scalar
:
:
byteSize
(
viewType
)
<
=
sizeof
(
void
*
)
)
{
storeCommon
(
access
AccessCheck
(
)
type
)
;
return
;
}
MOZ_ASSERT
(
type
=
=
ValType
:
:
I64
&
&
Scalar
:
:
byteSize
(
viewType
)
=
=
8
)
;
#
if
!
defined
(
JS_64BIT
)
if
(
isMem32
(
)
)
{
atomicXchg64
<
RegI32
>
(
access
WantResult
(
false
)
)
;
}
else
{
#
ifdef
ENABLE_WASM_MEMORY64
atomicXchg64
<
RegI64
>
(
access
WantResult
(
false
)
)
;
#
else
MOZ_CRASH
(
"
Memory64
not
enabled
/
supported
on
this
platform
"
)
;
#
endif
}
#
else
MOZ_CRASH
(
"
Should
not
happen
"
)
;
#
endif
}
void
BaseCompiler
:
:
atomicRMW
(
MemoryAccessDesc
*
access
ValType
type
AtomicOp
op
)
{
Scalar
:
:
Type
viewType
=
access
-
>
type
(
)
;
if
(
Scalar
:
:
byteSize
(
viewType
)
<
=
4
)
{
if
(
isMem32
(
)
)
{
atomicRMW32
<
RegI32
>
(
access
type
op
)
;
}
else
{
#
ifdef
ENABLE_WASM_MEMORY64
atomicRMW32
<
RegI64
>
(
access
type
op
)
;
#
else
MOZ_CRASH
(
"
Memory64
not
enabled
/
supported
on
this
platform
"
)
;
#
endif
}
}
else
{
MOZ_ASSERT
(
type
=
=
ValType
:
:
I64
&
&
Scalar
:
:
byteSize
(
viewType
)
=
=
8
)
;
if
(
isMem32
(
)
)
{
atomicRMW64
<
RegI32
>
(
access
type
op
)
;
}
else
{
#
ifdef
ENABLE_WASM_MEMORY64
atomicRMW64
<
RegI64
>
(
access
type
op
)
;
#
else
MOZ_CRASH
(
"
Memory64
not
enabled
/
supported
on
this
platform
"
)
;
#
endif
}
}
}
namespace
atomic_rmw32
{
#
if
defined
(
JS_CODEGEN_X64
)
|
|
defined
(
JS_CODEGEN_X86
)
struct
Temps
{
#
if
defined
(
JS_CODEGEN_X64
)
RegI32
t0
;
#
endif
}
;
static
void
PopAndAllocate
(
BaseCompiler
*
bc
ValType
type
Scalar
:
:
Type
viewType
AtomicOp
op
RegI32
*
rd
RegI32
*
rv
Temps
*
temps
)
{
bc
-
>
needI32
(
bc
-
>
specific_
.
eax
)
;
if
(
op
=
=
AtomicFetchAddOp
|
|
op
=
=
AtomicFetchSubOp
)
{
if
(
type
=
=
ValType
:
:
I64
)
{
*
rv
=
bc
-
>
popI64ToSpecificI32
(
bc
-
>
specific_
.
eax
)
;
}
else
{
*
rv
=
bc
-
>
popI32ToSpecific
(
bc
-
>
specific_
.
eax
)
;
}
*
rd
=
*
rv
;
}
else
{
if
(
type
=
=
ValType
:
:
I64
)
{
*
rv
=
bc
-
>
popI64ToI32
(
)
;
}
else
{
*
rv
=
bc
-
>
popI32
(
)
;
}
*
rd
=
bc
-
>
specific_
.
eax
;
#
ifdef
JS_CODEGEN_X64
temps
-
>
t0
=
bc
-
>
needI32
(
)
;
#
endif
}
}
template
<
typename
T
>
static
void
Perform
(
BaseCompiler
*
bc
const
MemoryAccessDesc
&
access
T
srcAddr
AtomicOp
op
RegI32
rv
RegI32
rd
const
Temps
&
temps
)
{
#
ifdef
JS_CODEGEN_X64
RegI32
temp
=
temps
.
t0
;
#
else
RegI32
temp
;
ScratchI32
scratch
(
*
bc
)
;
if
(
op
!
=
AtomicFetchAddOp
&
&
op
!
=
AtomicFetchSubOp
)
{
temp
=
scratch
;
}
#
endif
bc
-
>
masm
.
wasmAtomicFetchOp
(
access
op
rv
srcAddr
temp
rd
)
;
}
static
void
Deallocate
(
BaseCompiler
*
bc
RegI32
rv
const
Temps
&
temps
)
{
if
(
rv
!
=
bc
-
>
specific_
.
eax
)
{
bc
-
>
freeI32
(
rv
)
;
}
#
ifdef
JS_CODEGEN_X64
bc
-
>
maybeFree
(
temps
.
t0
)
;
#
endif
}
#
elif
defined
(
JS_CODEGEN_ARM
)
|
|
defined
(
JS_CODEGEN_ARM64
)
struct
Temps
{
RegI32
t0
;
}
;
static
void
PopAndAllocate
(
BaseCompiler
*
bc
ValType
type
Scalar
:
:
Type
viewType
AtomicOp
op
RegI32
*
rd
RegI32
*
rv
Temps
*
temps
)
{
*
rv
=
type
=
=
ValType
:
:
I64
?
bc
-
>
popI64ToI32
(
)
:
bc
-
>
popI32
(
)
;
temps
-
>
t0
=
bc
-
>
needI32
(
)
;
*
rd
=
bc
-
>
needI32
(
)
;
}
static
void
Perform
(
BaseCompiler
*
bc
const
MemoryAccessDesc
&
access
BaseIndex
srcAddr
AtomicOp
op
RegI32
rv
RegI32
rd
const
Temps
&
temps
)
{
bc
-
>
masm
.
wasmAtomicFetchOp
(
access
op
rv
srcAddr
temps
.
t0
rd
)
;
}
static
void
Deallocate
(
BaseCompiler
*
bc
RegI32
rv
const
Temps
&
temps
)
{
bc
-
>
freeI32
(
rv
)
;
bc
-
>
freeI32
(
temps
.
t0
)
;
}
#
elif
defined
(
JS_CODEGEN_MIPS64
)
|
|
defined
(
JS_CODEGEN_LOONG64
)
struct
Temps
{
RegI32
t0
t1
t2
;
}
;
static
void
PopAndAllocate
(
BaseCompiler
*
bc
ValType
type
Scalar
:
:
Type
viewType
AtomicOp
op
RegI32
*
rd
RegI32
*
rv
Temps
*
temps
)
{
*
rv
=
type
=
=
ValType
:
:
I64
?
bc
-
>
popI64ToI32
(
)
:
bc
-
>
popI32
(
)
;
if
(
Scalar
:
:
byteSize
(
viewType
)
<
4
)
{
temps
-
>
t0
=
bc
-
>
needI32
(
)
;
temps
-
>
t1
=
bc
-
>
needI32
(
)
;
temps
-
>
t2
=
bc
-
>
needI32
(
)
;
}
*
rd
=
bc
-
>
needI32
(
)
;
}
static
void
Perform
(
BaseCompiler
*
bc
const
MemoryAccessDesc
&
access
BaseIndex
srcAddr
AtomicOp
op
RegI32
rv
RegI32
rd
const
Temps
&
temps
)
{
bc
-
>
masm
.
wasmAtomicFetchOp
(
access
op
rv
srcAddr
temps
.
t0
temps
.
t1
temps
.
t2
rd
)
;
}
static
void
Deallocate
(
BaseCompiler
*
bc
RegI32
rv
const
Temps
&
temps
)
{
bc
-
>
freeI32
(
rv
)
;
bc
-
>
maybeFree
(
temps
.
t0
)
;
bc
-
>
maybeFree
(
temps
.
t1
)
;
bc
-
>
maybeFree
(
temps
.
t2
)
;
}
#
elif
defined
(
JS_CODEGEN_NONE
)
using
Temps
=
Nothing
;
static
void
PopAndAllocate
(
BaseCompiler
*
ValType
Scalar
:
:
Type
AtomicOp
RegI32
*
RegI32
*
Temps
*
)
{
}
static
void
Perform
(
BaseCompiler
*
const
MemoryAccessDesc
&
BaseIndex
AtomicOp
RegI32
RegI32
const
Temps
&
)
{
}
static
void
Deallocate
(
BaseCompiler
*
RegI32
const
Temps
&
)
{
}
#
endif
}
template
<
typename
RegIndexType
>
void
BaseCompiler
:
:
atomicRMW32
(
MemoryAccessDesc
*
access
ValType
type
AtomicOp
op
)
{
Scalar
:
:
Type
viewType
=
access
-
>
type
(
)
;
RegI32
rd
rv
;
atomic_rmw32
:
:
Temps
temps
;
atomic_rmw32
:
:
PopAndAllocate
(
this
type
viewType
op
&
rd
&
rv
&
temps
)
;
AccessCheck
check
;
RegIndexType
rp
=
popMemoryAccess
<
RegIndexType
>
(
access
&
check
)
;
RegPtr
tls
=
maybeLoadTlsForAccess
(
check
)
;
auto
memaddr
=
prepareAtomicMemoryAccess
(
access
&
check
tls
rp
)
;
atomic_rmw32
:
:
Perform
(
this
*
access
memaddr
op
rv
rd
temps
)
;
maybeFree
(
tls
)
;
atomic_rmw32
:
:
Deallocate
(
this
rv
temps
)
;
free
(
rp
)
;
if
(
type
=
=
ValType
:
:
I64
)
{
pushU32AsI64
(
rd
)
;
}
else
{
pushI32
(
rd
)
;
}
}
namespace
atomic_rmw64
{
#
if
defined
(
JS_CODEGEN_X64
)
static
void
PopAndAllocate
(
BaseCompiler
*
bc
AtomicOp
op
RegI64
*
rd
RegI64
*
rv
RegI64
*
temp
)
{
if
(
op
=
=
AtomicFetchAddOp
|
|
op
=
=
AtomicFetchSubOp
)
{
*
rv
=
bc
-
>
popI64
(
)
;
*
rd
=
*
rv
;
}
else
{
bc
-
>
needI64
(
bc
-
>
specific_
.
rax
)
;
*
rd
=
bc
-
>
specific_
.
rax
;
*
rv
=
bc
-
>
popI64
(
)
;
*
temp
=
bc
-
>
needI64
(
)
;
}
}
static
void
Perform
(
BaseCompiler
*
bc
const
MemoryAccessDesc
&
access
BaseIndex
srcAddr
AtomicOp
op
RegI64
rv
RegI64
temp
RegI64
rd
)
{
bc
-
>
masm
.
wasmAtomicFetchOp64
(
access
op
rv
srcAddr
temp
rd
)
;
}
static
void
Deallocate
(
BaseCompiler
*
bc
AtomicOp
op
RegI64
rv
RegI64
temp
)
{
bc
-
>
maybeFree
(
temp
)
;
if
(
op
!
=
AtomicFetchAddOp
&
&
op
!
=
AtomicFetchSubOp
)
{
bc
-
>
freeI64
(
rv
)
;
}
}
#
elif
defined
(
JS_CODEGEN_X86
)
static
void
PopAndAllocate
(
BaseCompiler
*
bc
AtomicOp
op
RegI64
*
rd
RegI64
*
rv
RegI64
*
)
{
bc
-
>
needI32
(
bc
-
>
specific_
.
eax
)
;
bc
-
>
needI32
(
bc
-
>
specific_
.
ecx
)
;
bc
-
>
needI32
(
bc
-
>
specific_
.
edx
)
;
*
rv
=
RegI64
(
Register64
(
bc
-
>
specific_
.
ecx
bc
-
>
specific_
.
edx
)
)
;
bc
-
>
popI64ToSpecific
(
*
rv
)
;
}
static
void
Setup
(
BaseCompiler
*
bc
RegI64
*
rd
)
{
*
rd
=
bc
-
>
specific_
.
edx_eax
;
}
static
void
Perform
(
BaseCompiler
*
bc
const
MemoryAccessDesc
&
access
Address
srcAddr
AtomicOp
op
RegI64
rv
RegI64
RegI64
rd
const
ScratchAtomicNoHeapReg
&
scratch
)
{
MOZ_ASSERT
(
rv
.
high
=
=
bc
-
>
specific_
.
ecx
)
;
MOZ_ASSERT
(
Register
(
scratch
)
=
=
js
:
:
jit
:
:
ebx
)
;
bc
-
>
fr
.
pushGPR
(
rv
.
high
)
;
bc
-
>
fr
.
pushGPR
(
rv
.
low
)
;
Address
value
(
StackPointer
0
)
;
bc
-
>
masm
.
wasmAtomicFetchOp64
(
access
op
value
srcAddr
bc
-
>
specific_
.
ecx_ebx
rd
)
;
bc
-
>
fr
.
popBytes
(
8
)
;
}
static
void
Deallocate
(
BaseCompiler
*
bc
AtomicOp
RegI64
RegI64
)
{
bc
-
>
freeI32
(
bc
-
>
specific_
.
ecx
)
;
}
#
elif
defined
(
JS_CODEGEN_ARM
)
static
void
PopAndAllocate
(
BaseCompiler
*
bc
AtomicOp
op
RegI64
*
rd
RegI64
*
rv
RegI64
*
temp
)
{
*
rv
=
bc
-
>
popI64
(
)
;
*
temp
=
bc
-
>
needI64Pair
(
)
;
*
rd
=
bc
-
>
needI64Pair
(
)
;
}
static
void
Perform
(
BaseCompiler
*
bc
const
MemoryAccessDesc
&
access
BaseIndex
srcAddr
AtomicOp
op
RegI64
rv
RegI64
temp
RegI64
rd
)
{
bc
-
>
masm
.
wasmAtomicFetchOp64
(
access
op
rv
srcAddr
temp
rd
)
;
}
static
void
Deallocate
(
BaseCompiler
*
bc
AtomicOp
op
RegI64
rv
RegI64
temp
)
{
bc
-
>
freeI64
(
rv
)
;
bc
-
>
freeI64
(
temp
)
;
}
#
elif
defined
(
JS_CODEGEN_ARM64
)
|
|
defined
(
JS_CODEGEN_MIPS64
)
|
|
\
defined
(
JS_CODEGEN_LOONG64
)
static
void
PopAndAllocate
(
BaseCompiler
*
bc
AtomicOp
op
RegI64
*
rd
RegI64
*
rv
RegI64
*
temp
)
{
*
rv
=
bc
-
>
popI64
(
)
;
*
temp
=
bc
-
>
needI64
(
)
;
*
rd
=
bc
-
>
needI64
(
)
;
}
static
void
Perform
(
BaseCompiler
*
bc
const
MemoryAccessDesc
&
access
BaseIndex
srcAddr
AtomicOp
op
RegI64
rv
RegI64
temp
RegI64
rd
)
{
bc
-
>
masm
.
wasmAtomicFetchOp64
(
access
op
rv
srcAddr
temp
rd
)
;
}
static
void
Deallocate
(
BaseCompiler
*
bc
AtomicOp
op
RegI64
rv
RegI64
temp
)
{
bc
-
>
freeI64
(
rv
)
;
bc
-
>
freeI64
(
temp
)
;
}
#
elif
defined
(
JS_CODEGEN_NONE
)
static
void
PopAndAllocate
(
BaseCompiler
*
AtomicOp
RegI64
*
RegI64
*
RegI64
*
)
{
}
static
void
Perform
(
BaseCompiler
*
const
MemoryAccessDesc
&
BaseIndex
AtomicOp
op
RegI64
RegI64
RegI64
)
{
}
static
void
Deallocate
(
BaseCompiler
*
AtomicOp
RegI64
RegI64
)
{
}
#
endif
}
template
<
typename
RegIndexType
>
void
BaseCompiler
:
:
atomicRMW64
(
MemoryAccessDesc
*
access
ValType
type
AtomicOp
op
)
{
RegI64
rd
rv
temp
;
atomic_rmw64
:
:
PopAndAllocate
(
this
op
&
rd
&
rv
&
temp
)
;
AccessCheck
check
;
RegIndexType
rp
=
popMemoryAccess
<
RegIndexType
>
(
access
&
check
)
;
#
if
defined
(
WASM_HAS_HEAPREG
)
RegPtr
tls
=
maybeLoadTlsForAccess
(
check
)
;
auto
memaddr
=
prepareAtomicMemoryAccess
(
access
&
check
tls
rp
)
;
atomic_rmw64
:
:
Perform
(
this
*
access
memaddr
op
rv
temp
rd
)
;
maybeFree
(
tls
)
;
#
else
ScratchAtomicNoHeapReg
scratch
(
*
this
)
;
RegPtr
tls
=
maybeLoadTlsForAccess
(
check
RegIntptrToRegPtr
(
scratch
)
)
;
auto
memaddr
=
prepareAtomicMemoryAccess
(
access
&
check
tls
rp
)
;
atomic_rmw64
:
:
Setup
(
this
&
rd
)
;
atomic_rmw64
:
:
Perform
(
this
*
access
memaddr
op
rv
temp
rd
scratch
)
;
MOZ_ASSERT
(
tls
=
=
scratch
)
;
#
endif
free
(
rp
)
;
atomic_rmw64
:
:
Deallocate
(
this
op
rv
temp
)
;
pushI64
(
rd
)
;
}
void
BaseCompiler
:
:
atomicXchg
(
MemoryAccessDesc
*
access
ValType
type
)
{
Scalar
:
:
Type
viewType
=
access
-
>
type
(
)
;
if
(
Scalar
:
:
byteSize
(
viewType
)
<
=
4
)
{
if
(
isMem32
(
)
)
{
atomicXchg32
<
RegI32
>
(
access
type
)
;
}
else
{
#
ifdef
ENABLE_WASM_MEMORY64
atomicXchg32
<
RegI64
>
(
access
type
)
;
#
else
MOZ_CRASH
(
"
Memory64
not
enabled
/
supported
on
this
platform
"
)
;
#
endif
}
}
else
{
MOZ_ASSERT
(
type
=
=
ValType
:
:
I64
&
&
Scalar
:
:
byteSize
(
viewType
)
=
=
8
)
;
if
(
isMem32
(
)
)
{
atomicXchg64
<
RegI32
>
(
access
WantResult
(
true
)
)
;
}
else
{
#
ifdef
ENABLE_WASM_MEMORY64
atomicXchg64
<
RegI64
>
(
access
WantResult
(
true
)
)
;
#
else
MOZ_CRASH
(
"
Memory64
not
enabled
/
supported
on
this
platform
"
)
;
#
endif
}
}
}
namespace
atomic_xchg32
{
#
if
defined
(
JS_CODEGEN_X64
)
using
Temps
=
Nothing
;
static
void
PopAndAllocate
(
BaseCompiler
*
bc
ValType
type
Scalar
:
:
Type
viewType
RegI32
*
rd
RegI32
*
rv
Temps
*
)
{
*
rv
=
(
type
=
=
ValType
:
:
I64
)
?
bc
-
>
popI64ToI32
(
)
:
bc
-
>
popI32
(
)
;
*
rd
=
*
rv
;
}
static
void
Perform
(
BaseCompiler
*
bc
const
MemoryAccessDesc
&
access
BaseIndex
srcAddr
RegI32
rv
RegI32
rd
const
Temps
&
)
{
bc
-
>
masm
.
wasmAtomicExchange
(
access
srcAddr
rv
rd
)
;
}
static
void
Deallocate
(
BaseCompiler
*
bc
RegI32
const
Temps
&
)
{
}
#
elif
defined
(
JS_CODEGEN_X86
)
using
Temps
=
Nothing
;
static
void
PopAndAllocate
(
BaseCompiler
*
bc
ValType
type
Scalar
:
:
Type
viewType
RegI32
*
rd
RegI32
*
rv
Temps
*
)
{
*
rv
=
(
type
=
=
ValType
:
:
I64
)
?
bc
-
>
popI64ToI32
(
)
:
bc
-
>
popI32
(
)
;
*
rd
=
*
rv
;
}
static
void
Perform
(
BaseCompiler
*
bc
const
MemoryAccessDesc
&
access
Address
srcAddr
RegI32
rv
RegI32
rd
const
Temps
&
)
{
if
(
access
.
type
(
)
=
=
Scalar
:
:
Uint8
&
&
!
bc
-
>
ra
.
isSingleByteI32
(
rd
)
)
{
ScratchI8
scratch
(
*
bc
)
;
bc
-
>
masm
.
wasmAtomicExchange
(
access
srcAddr
rv
scratch
)
;
bc
-
>
masm
.
movl
(
scratch
rd
)
;
}
else
{
bc
-
>
masm
.
wasmAtomicExchange
(
access
srcAddr
rv
rd
)
;
}
}
static
void
Deallocate
(
BaseCompiler
*
bc
RegI32
const
Temps
&
)
{
}
#
elif
defined
(
JS_CODEGEN_ARM
)
|
|
defined
(
JS_CODEGEN_ARM64
)
using
Temps
=
Nothing
;
static
void
PopAndAllocate
(
BaseCompiler
*
bc
ValType
type
Scalar
:
:
Type
viewType
RegI32
*
rd
RegI32
*
rv
Temps
*
)
{
*
rv
=
(
type
=
=
ValType
:
:
I64
)
?
bc
-
>
popI64ToI32
(
)
:
bc
-
>
popI32
(
)
;
*
rd
=
bc
-
>
needI32
(
)
;
}
static
void
Perform
(
BaseCompiler
*
bc
const
MemoryAccessDesc
&
access
BaseIndex
srcAddr
RegI32
rv
RegI32
rd
const
Temps
&
)
{
bc
-
>
masm
.
wasmAtomicExchange
(
access
srcAddr
rv
rd
)
;
}
static
void
Deallocate
(
BaseCompiler
*
bc
RegI32
rv
const
Temps
&
)
{
bc
-
>
freeI32
(
rv
)
;
}
#
elif
defined
(
JS_CODEGEN_MIPS64
)
|
|
defined
(
JS_CODEGEN_LOONG64
)
struct
Temps
{
RegI32
t0
t1
t2
;
}
;
static
void
PopAndAllocate
(
BaseCompiler
*
bc
ValType
type
Scalar
:
:
Type
viewType
RegI32
*
rd
RegI32
*
rv
Temps
*
temps
)
{
*
rv
=
(
type
=
=
ValType
:
:
I64
)
?
bc
-
>
popI64ToI32
(
)
:
bc
-
>
popI32
(
)
;
if
(
Scalar
:
:
byteSize
(
viewType
)
<
4
)
{
temps
-
>
t0
=
bc
-
>
needI32
(
)
;
temps
-
>
t1
=
bc
-
>
needI32
(
)
;
temps
-
>
t2
=
bc
-
>
needI32
(
)
;
}
*
rd
=
bc
-
>
needI32
(
)
;
}
static
void
Perform
(
BaseCompiler
*
bc
const
MemoryAccessDesc
&
access
BaseIndex
srcAddr
RegI32
rv
RegI32
rd
const
Temps
&
temps
)
{
bc
-
>
masm
.
wasmAtomicExchange
(
access
srcAddr
rv
temps
.
t0
temps
.
t1
temps
.
t2
rd
)
;
}
static
void
Deallocate
(
BaseCompiler
*
bc
RegI32
rv
const
Temps
&
temps
)
{
bc
-
>
freeI32
(
rv
)
;
bc
-
>
maybeFree
(
temps
.
t0
)
;
bc
-
>
maybeFree
(
temps
.
t1
)
;
bc
-
>
maybeFree
(
temps
.
t2
)
;
}
#
elif
defined
(
JS_CODEGEN_NONE
)
using
Temps
=
Nothing
;
static
void
PopAndAllocate
(
BaseCompiler
*
ValType
Scalar
:
:
Type
RegI32
*
RegI32
*
Temps
*
)
{
}
static
void
Perform
(
BaseCompiler
*
const
MemoryAccessDesc
&
BaseIndex
RegI32
RegI32
const
Temps
&
)
{
}
static
void
Deallocate
(
BaseCompiler
*
RegI32
const
Temps
&
)
{
}
#
endif
}
template
<
typename
RegIndexType
>
void
BaseCompiler
:
:
atomicXchg32
(
MemoryAccessDesc
*
access
ValType
type
)
{
Scalar
:
:
Type
viewType
=
access
-
>
type
(
)
;
RegI32
rd
rv
;
atomic_xchg32
:
:
Temps
temps
;
atomic_xchg32
:
:
PopAndAllocate
(
this
type
viewType
&
rd
&
rv
&
temps
)
;
AccessCheck
check
;
RegIndexType
rp
=
popMemoryAccess
<
RegIndexType
>
(
access
&
check
)
;
RegPtr
tls
=
maybeLoadTlsForAccess
(
check
)
;
auto
memaddr
=
prepareAtomicMemoryAccess
(
access
&
check
tls
rp
)
;
atomic_xchg32
:
:
Perform
(
this
*
access
memaddr
rv
rd
temps
)
;
maybeFree
(
tls
)
;
free
(
rp
)
;
atomic_xchg32
:
:
Deallocate
(
this
rv
temps
)
;
if
(
type
=
=
ValType
:
:
I64
)
{
pushU32AsI64
(
rd
)
;
}
else
{
pushI32
(
rd
)
;
}
}
namespace
atomic_xchg64
{
#
if
defined
(
JS_CODEGEN_X64
)
static
void
PopAndAllocate
(
BaseCompiler
*
bc
RegI64
*
rd
RegI64
*
rv
)
{
*
rv
=
bc
-
>
popI64
(
)
;
*
rd
=
*
rv
;
}
static
void
Deallocate
(
BaseCompiler
*
bc
RegI64
rd
RegI64
)
{
bc
-
>
maybeFree
(
rd
)
;
}
#
elif
defined
(
JS_CODEGEN_X86
)
static
void
PopAndAllocate
(
BaseCompiler
*
bc
RegI64
*
rd
RegI64
*
rv
)
{
bc
-
>
needI32
(
bc
-
>
specific_
.
ecx
)
;
bc
-
>
needI32
(
bc
-
>
specific_
.
edx
)
;
bc
-
>
needI32
(
bc
-
>
specific_
.
eax
)
;
*
rv
=
RegI64
(
Register64
(
bc
-
>
specific_
.
ecx
bc
-
>
specific_
.
edx
)
)
;
bc
-
>
popI64ToSpecific
(
*
rv
)
;
}
static
void
Setup
(
BaseCompiler
*
bc
RegI64
*
rv
RegI64
*
rd
const
ScratchAtomicNoHeapReg
&
scratch
)
{
MOZ_ASSERT
(
rv
-
>
high
=
=
bc
-
>
specific_
.
ecx
)
;
MOZ_ASSERT
(
Register
(
scratch
)
=
=
js
:
:
jit
:
:
ebx
)
;
bc
-
>
masm
.
move32
(
rv
-
>
low
scratch
)
;
*
rv
=
bc
-
>
specific_
.
ecx_ebx
;
*
rd
=
bc
-
>
specific_
.
edx_eax
;
}
static
void
Deallocate
(
BaseCompiler
*
bc
RegI64
rd
RegI64
rv
)
{
MOZ_ASSERT
(
rd
=
=
bc
-
>
specific_
.
edx_eax
|
|
rd
=
=
RegI64
:
:
Invalid
(
)
)
;
bc
-
>
maybeFree
(
rd
)
;
bc
-
>
freeI32
(
bc
-
>
specific_
.
ecx
)
;
}
#
elif
defined
(
JS_CODEGEN_ARM64
)
|
|
defined
(
JS_CODEGEN_MIPS64
)
|
|
\
defined
(
JS_CODEGEN_LOONG64
)
static
void
PopAndAllocate
(
BaseCompiler
*
bc
RegI64
*
rd
RegI64
*
rv
)
{
*
rv
=
bc
-
>
popI64
(
)
;
*
rd
=
bc
-
>
needI64
(
)
;
}
static
void
Deallocate
(
BaseCompiler
*
bc
RegI64
rd
RegI64
rv
)
{
bc
-
>
freeI64
(
rv
)
;
bc
-
>
maybeFree
(
rd
)
;
}
#
elif
defined
(
JS_CODEGEN_ARM
)
static
void
PopAndAllocate
(
BaseCompiler
*
bc
RegI64
*
rd
RegI64
*
rv
)
{
*
rv
=
bc
-
>
popI64ToSpecific
(
bc
-
>
needI64Pair
(
)
)
;
*
rd
=
bc
-
>
needI64Pair
(
)
;
}
static
void
Deallocate
(
BaseCompiler
*
bc
RegI64
rd
RegI64
rv
)
{
bc
-
>
freeI64
(
rv
)
;
bc
-
>
maybeFree
(
rd
)
;
}
#
elif
defined
(
JS_CODEGEN_NONE
)
static
void
PopAndAllocate
(
BaseCompiler
*
RegI64
*
RegI64
*
)
{
}
static
void
Deallocate
(
BaseCompiler
*
RegI64
RegI64
)
{
}
#
endif
}
template
<
typename
RegIndexType
>
void
BaseCompiler
:
:
atomicXchg64
(
MemoryAccessDesc
*
access
WantResult
wantResult
)
{
RegI64
rd
rv
;
atomic_xchg64
:
:
PopAndAllocate
(
this
&
rd
&
rv
)
;
AccessCheck
check
;
RegIndexType
rp
=
popMemoryAccess
<
RegIndexType
>
(
access
&
check
)
;
#
ifdef
WASM_HAS_HEAPREG
RegPtr
tls
=
maybeLoadTlsForAccess
(
check
)
;
auto
memaddr
=
prepareAtomicMemoryAccess
<
RegIndexType
>
(
access
&
check
tls
rp
)
;
masm
.
wasmAtomicExchange64
(
*
access
memaddr
rv
rd
)
;
maybeFree
(
tls
)
;
#
else
ScratchAtomicNoHeapReg
scratch
(
*
this
)
;
RegPtr
tls
=
maybeLoadTlsForAccess
(
check
RegIntptrToRegPtr
(
scratch
)
)
;
Address
memaddr
=
prepareAtomicMemoryAccess
(
access
&
check
tls
rp
)
;
atomic_xchg64
:
:
Setup
(
this
&
rv
&
rd
scratch
)
;
masm
.
wasmAtomicExchange64
(
*
access
memaddr
rv
rd
)
;
MOZ_ASSERT
(
tls
=
=
scratch
)
;
#
endif
free
(
rp
)
;
if
(
wantResult
)
{
pushI64
(
rd
)
;
rd
=
RegI64
:
:
Invalid
(
)
;
}
atomic_xchg64
:
:
Deallocate
(
this
rd
rv
)
;
}
void
BaseCompiler
:
:
atomicCmpXchg
(
MemoryAccessDesc
*
access
ValType
type
)
{
Scalar
:
:
Type
viewType
=
access
-
>
type
(
)
;
if
(
Scalar
:
:
byteSize
(
viewType
)
<
=
4
)
{
if
(
isMem32
(
)
)
{
atomicCmpXchg32
<
RegI32
>
(
access
type
)
;
}
else
{
#
ifdef
ENABLE_WASM_MEMORY64
atomicCmpXchg32
<
RegI64
>
(
access
type
)
;
#
else
MOZ_CRASH
(
"
Memory64
not
enabled
/
supported
on
this
platform
"
)
;
#
endif
}
}
else
{
MOZ_ASSERT
(
type
=
=
ValType
:
:
I64
&
&
Scalar
:
:
byteSize
(
viewType
)
=
=
8
)
;
if
(
isMem32
(
)
)
{
atomicCmpXchg64
<
RegI32
>
(
access
type
)
;
}
else
{
#
ifdef
ENABLE_WASM_MEMORY64
atomicCmpXchg64
<
RegI64
>
(
access
type
)
;
#
else
MOZ_CRASH
(
"
Memory64
not
enabled
/
supported
on
this
platform
"
)
;
#
endif
}
}
}
namespace
atomic_cmpxchg32
{
#
if
defined
(
JS_CODEGEN_X64
)
|
|
defined
(
JS_CODEGEN_X86
)
using
Temps
=
Nothing
;
static
void
PopAndAllocate
(
BaseCompiler
*
bc
ValType
type
Scalar
:
:
Type
viewType
RegI32
*
rexpect
RegI32
*
rnew
RegI32
*
rd
Temps
*
)
{
bc
-
>
needI32
(
bc
-
>
specific_
.
eax
)
;
if
(
type
=
=
ValType
:
:
I64
)
{
*
rnew
=
bc
-
>
popI64ToI32
(
)
;
*
rexpect
=
bc
-
>
popI64ToSpecificI32
(
bc
-
>
specific_
.
eax
)
;
}
else
{
*
rnew
=
bc
-
>
popI32
(
)
;
*
rexpect
=
bc
-
>
popI32ToSpecific
(
bc
-
>
specific_
.
eax
)
;
}
*
rd
=
*
rexpect
;
}
template
<
typename
T
>
static
void
Perform
(
BaseCompiler
*
bc
const
MemoryAccessDesc
&
access
T
srcAddr
RegI32
rexpect
RegI32
rnew
RegI32
rd
const
Temps
&
)
{
#
if
defined
(
JS_CODEGEN_X86
)
ScratchI8
scratch
(
*
bc
)
;
if
(
access
.
type
(
)
=
=
Scalar
:
:
Uint8
)
{
MOZ_ASSERT
(
rd
=
=
bc
-
>
specific_
.
eax
)
;
if
(
!
bc
-
>
ra
.
isSingleByteI32
(
rnew
)
)
{
bc
-
>
masm
.
movl
(
rnew
scratch
)
;
rnew
=
scratch
;
}
}
#
endif
bc
-
>
masm
.
wasmCompareExchange
(
access
srcAddr
rexpect
rnew
rd
)
;
}
static
void
Deallocate
(
BaseCompiler
*
bc
RegI32
RegI32
rnew
const
Temps
&
)
{
bc
-
>
freeI32
(
rnew
)
;
}
#
elif
defined
(
JS_CODEGEN_ARM
)
|
|
defined
(
JS_CODEGEN_ARM64
)
using
Temps
=
Nothing
;
static
void
PopAndAllocate
(
BaseCompiler
*
bc
ValType
type
Scalar
:
:
Type
viewType
RegI32
*
rexpect
RegI32
*
rnew
RegI32
*
rd
Temps
*
)
{
if
(
type
=
=
ValType
:
:
I64
)
{
*
rnew
=
bc
-
>
popI64ToI32
(
)
;
*
rexpect
=
bc
-
>
popI64ToI32
(
)
;
}
else
{
*
rnew
=
bc
-
>
popI32
(
)
;
*
rexpect
=
bc
-
>
popI32
(
)
;
}
*
rd
=
bc
-
>
needI32
(
)
;
}
static
void
Perform
(
BaseCompiler
*
bc
const
MemoryAccessDesc
&
access
BaseIndex
srcAddr
RegI32
rexpect
RegI32
rnew
RegI32
rd
const
Temps
&
)
{
bc
-
>
masm
.
wasmCompareExchange
(
access
srcAddr
rexpect
rnew
rd
)
;
}
static
void
Deallocate
(
BaseCompiler
*
bc
RegI32
rexpect
RegI32
rnew
const
Temps
&
)
{
bc
-
>
freeI32
(
rnew
)
;
bc
-
>
freeI32
(
rexpect
)
;
}
#
elif
defined
(
JS_CODEGEN_MIPS64
)
|
|
defined
(
JS_CODEGEN_LOONG64
)
struct
Temps
{
RegI32
t0
t1
t2
;
}
;
static
void
PopAndAllocate
(
BaseCompiler
*
bc
ValType
type
Scalar
:
:
Type
viewType
RegI32
*
rexpect
RegI32
*
rnew
RegI32
*
rd
Temps
*
temps
)
{
if
(
type
=
=
ValType
:
:
I64
)
{
*
rnew
=
bc
-
>
popI64ToI32
(
)
;
*
rexpect
=
bc
-
>
popI64ToI32
(
)
;
}
else
{
*
rnew
=
bc
-
>
popI32
(
)
;
*
rexpect
=
bc
-
>
popI32
(
)
;
}
if
(
Scalar
:
:
byteSize
(
viewType
)
<
4
)
{
temps
-
>
t0
=
bc
-
>
needI32
(
)
;
temps
-
>
t1
=
bc
-
>
needI32
(
)
;
temps
-
>
t2
=
bc
-
>
needI32
(
)
;
}
*
rd
=
bc
-
>
needI32
(
)
;
}
static
void
Perform
(
BaseCompiler
*
bc
const
MemoryAccessDesc
&
access
BaseIndex
srcAddr
RegI32
rexpect
RegI32
rnew
RegI32
rd
const
Temps
&
temps
)
{
bc
-
>
masm
.
wasmCompareExchange
(
access
srcAddr
rexpect
rnew
temps
.
t0
temps
.
t1
temps
.
t2
rd
)
;
}
static
void
Deallocate
(
BaseCompiler
*
bc
RegI32
rexpect
RegI32
rnew
const
Temps
&
temps
)
{
bc
-
>
freeI32
(
rnew
)
;
bc
-
>
freeI32
(
rexpect
)
;
bc
-
>
maybeFree
(
temps
.
t0
)
;
bc
-
>
maybeFree
(
temps
.
t1
)
;
bc
-
>
maybeFree
(
temps
.
t2
)
;
}
#
elif
defined
(
JS_CODEGEN_NONE
)
using
Temps
=
Nothing
;
static
void
PopAndAllocate
(
BaseCompiler
*
ValType
Scalar
:
:
Type
RegI32
*
RegI32
*
RegI32
*
Temps
*
)
{
}
static
void
Perform
(
BaseCompiler
*
const
MemoryAccessDesc
&
BaseIndex
RegI32
RegI32
RegI32
const
Temps
&
temps
)
{
}
static
void
Deallocate
(
BaseCompiler
*
RegI32
RegI32
const
Temps
&
)
{
}
#
endif
}
template
<
typename
RegIndexType
>
void
BaseCompiler
:
:
atomicCmpXchg32
(
MemoryAccessDesc
*
access
ValType
type
)
{
Scalar
:
:
Type
viewType
=
access
-
>
type
(
)
;
RegI32
rexpect
rnew
rd
;
atomic_cmpxchg32
:
:
Temps
temps
;
atomic_cmpxchg32
:
:
PopAndAllocate
(
this
type
viewType
&
rexpect
&
rnew
&
rd
&
temps
)
;
AccessCheck
check
;
RegIndexType
rp
=
popMemoryAccess
<
RegIndexType
>
(
access
&
check
)
;
RegPtr
tls
=
maybeLoadTlsForAccess
(
check
)
;
auto
memaddr
=
prepareAtomicMemoryAccess
(
access
&
check
tls
rp
)
;
atomic_cmpxchg32
:
:
Perform
(
this
*
access
memaddr
rexpect
rnew
rd
temps
)
;
maybeFree
(
tls
)
;
free
(
rp
)
;
atomic_cmpxchg32
:
:
Deallocate
(
this
rexpect
rnew
temps
)
;
if
(
type
=
=
ValType
:
:
I64
)
{
pushU32AsI64
(
rd
)
;
}
else
{
pushI32
(
rd
)
;
}
}
namespace
atomic_cmpxchg64
{
template
<
typename
RegIndexType
>
static
void
PopAndAllocate
(
BaseCompiler
*
bc
RegI64
*
rexpect
RegI64
*
rnew
RegI64
*
rd
)
;
template
<
typename
RegIndexType
>
static
void
Deallocate
(
BaseCompiler
*
bc
RegI64
rexpect
RegI64
rnew
)
;
#
if
defined
(
JS_CODEGEN_X64
)
template
<
typename
RegIndexType
>
static
void
PopAndAllocate
(
BaseCompiler
*
bc
RegI64
*
rexpect
RegI64
*
rnew
RegI64
*
rd
)
{
bc
-
>
needI64
(
bc
-
>
specific_
.
rax
)
;
*
rnew
=
bc
-
>
popI64
(
)
;
*
rexpect
=
bc
-
>
popI64ToSpecific
(
bc
-
>
specific_
.
rax
)
;
*
rd
=
*
rexpect
;
}
static
void
Perform
(
BaseCompiler
*
bc
const
MemoryAccessDesc
&
access
BaseIndex
srcAddr
RegI64
rexpect
RegI64
rnew
RegI64
rd
)
{
bc
-
>
masm
.
wasmCompareExchange64
(
access
srcAddr
rexpect
rnew
rd
)
;
}
template
<
typename
RegIndexType
>
static
void
Deallocate
(
BaseCompiler
*
bc
RegI64
rexpect
RegI64
rnew
)
{
bc
-
>
freeI64
(
rnew
)
;
}
#
elif
defined
(
JS_CODEGEN_X86
)
template
<
typename
RegIndexType
>
static
void
Perform
(
BaseCompiler
*
bc
const
MemoryAccessDesc
&
access
Address
srcAddr
RegI64
rexpect
RegI64
rnew
RegI64
rd
ScratchAtomicNoHeapReg
&
scratch
)
;
template
<
>
void
PopAndAllocate
<
RegI32
>
(
BaseCompiler
*
bc
RegI64
*
rexpect
RegI64
*
rnew
RegI64
*
rd
)
{
bc
-
>
needI64
(
bc
-
>
specific_
.
edx_eax
)
;
bc
-
>
needI32
(
bc
-
>
specific_
.
ecx
)
;
RegI32
tmp
=
bc
-
>
needI32
(
)
;
*
rnew
=
bc
-
>
popI64ToSpecific
(
RegI64
(
Register64
(
bc
-
>
specific_
.
ecx
tmp
)
)
)
;
*
rexpect
=
bc
-
>
popI64ToSpecific
(
bc
-
>
specific_
.
edx_eax
)
;
*
rd
=
*
rexpect
;
}
template
<
>
void
Perform
<
RegI32
>
(
BaseCompiler
*
bc
const
MemoryAccessDesc
&
access
Address
srcAddr
RegI64
rexpect
RegI64
rnew
RegI64
rd
ScratchAtomicNoHeapReg
&
scratch
)
{
MOZ_ASSERT
(
Register
(
scratch
)
=
=
js
:
:
jit
:
:
ebx
)
;
MOZ_ASSERT
(
rnew
.
high
=
=
bc
-
>
specific_
.
ecx
)
;
bc
-
>
masm
.
move32
(
rnew
.
low
ebx
)
;
bc
-
>
masm
.
wasmCompareExchange64
(
access
srcAddr
rexpect
bc
-
>
specific_
.
ecx_ebx
rd
)
;
}
template
<
>
void
Deallocate
<
RegI32
>
(
BaseCompiler
*
bc
RegI64
rexpect
RegI64
rnew
)
{
bc
-
>
freeI64
(
rnew
)
;
}
#
ifdef
ENABLE_WASM_MEMORY64
template
<
>
void
PopAndAllocate
<
RegI64
>
(
BaseCompiler
*
bc
RegI64
*
rexpect
RegI64
*
rnew
RegI64
*
rd
)
{
bc
-
>
needI32
(
bc
-
>
specific_
.
eax
)
;
bc
-
>
needI32
(
bc
-
>
specific_
.
ecx
)
;
bc
-
>
needI32
(
bc
-
>
specific_
.
edx
)
;
RegI64
tmp
(
Register64
(
bc
-
>
specific_
.
ecx
bc
-
>
specific_
.
edx
)
)
;
bc
-
>
popI64ToSpecific
(
tmp
)
;
{
ScratchPtr
tlsScratch
(
*
bc
)
;
bc
-
>
stashI64
(
tlsScratch
tmp
)
;
}
*
rexpect
=
bc
-
>
popI64ToSpecific
(
bc
-
>
specific_
.
edx_eax
)
;
*
rd
=
*
rexpect
;
}
template
<
>
void
Perform
<
RegI64
>
(
BaseCompiler
*
bc
const
MemoryAccessDesc
&
access
Address
srcAddr
RegI64
rexpect
RegI64
rnew
RegI64
rd
ScratchAtomicNoHeapReg
&
scratch
)
{
MOZ_ASSERT
(
rnew
.
isInvalid
(
)
)
;
rnew
=
bc
-
>
specific_
.
ecx_ebx
;
bc
-
>
unstashI64
(
RegPtr
(
Register
(
bc
-
>
specific_
.
ecx
)
)
rnew
)
;
bc
-
>
masm
.
wasmCompareExchange64
(
access
srcAddr
rexpect
rnew
rd
)
;
}
template
<
>
void
Deallocate
<
RegI64
>
(
BaseCompiler
*
bc
RegI64
rexpect
RegI64
rnew
)
{
bc
-
>
free
(
bc
-
>
specific_
.
ecx
)
;
}
#
endif
#
elif
defined
(
JS_CODEGEN_ARM
)
template
<
typename
RegIndexType
>
static
void
PopAndAllocate
(
BaseCompiler
*
bc
RegI64
*
rexpect
RegI64
*
rnew
RegI64
*
rd
)
{
*
rnew
=
bc
-
>
popI64Pair
(
)
;
*
rexpect
=
bc
-
>
popI64
(
)
;
*
rd
=
bc
-
>
needI64Pair
(
)
;
}
static
void
Perform
(
BaseCompiler
*
bc
const
MemoryAccessDesc
&
access
BaseIndex
srcAddr
RegI64
rexpect
RegI64
rnew
RegI64
rd
)
{
bc
-
>
masm
.
wasmCompareExchange64
(
access
srcAddr
rexpect
rnew
rd
)
;
}
template
<
typename
RegIndexType
>
static
void
Deallocate
(
BaseCompiler
*
bc
RegI64
rexpect
RegI64
rnew
)
{
bc
-
>
freeI64
(
rexpect
)
;
bc
-
>
freeI64
(
rnew
)
;
}
#
elif
defined
(
JS_CODEGEN_ARM64
)
|
|
defined
(
JS_CODEGEN_MIPS64
)
|
|
\
defined
(
JS_CODEGEN_LOONG64
)
template
<
typename
RegIndexType
>
static
void
PopAndAllocate
(
BaseCompiler
*
bc
RegI64
*
rexpect
RegI64
*
rnew
RegI64
*
rd
)
{
*
rnew
=
bc
-
>
popI64
(
)
;
*
rexpect
=
bc
-
>
popI64
(
)
;
*
rd
=
bc
-
>
needI64
(
)
;
}
static
void
Perform
(
BaseCompiler
*
bc
const
MemoryAccessDesc
&
access
BaseIndex
srcAddr
RegI64
rexpect
RegI64
rnew
RegI64
rd
)
{
bc
-
>
masm
.
wasmCompareExchange64
(
access
srcAddr
rexpect
rnew
rd
)
;
}
template
<
typename
RegIndexType
>
static
void
Deallocate
(
BaseCompiler
*
bc
RegI64
rexpect
RegI64
rnew
)
{
bc
-
>
freeI64
(
rexpect
)
;
bc
-
>
freeI64
(
rnew
)
;
}
#
elif
defined
(
JS_CODEGEN_NONE
)
template
<
typename
RegIndexType
>
static
void
PopAndAllocate
(
BaseCompiler
*
bc
RegI64
*
rexpect
RegI64
*
rnew
RegI64
*
rd
)
{
}
static
void
Perform
(
BaseCompiler
*
bc
const
MemoryAccessDesc
&
access
BaseIndex
srcAddr
RegI64
rexpect
RegI64
rnew
RegI64
rd
)
{
}
template
<
typename
RegIndexType
>
static
void
Deallocate
(
BaseCompiler
*
bc
RegI64
rexpect
RegI64
rnew
)
{
}
#
endif
}
template
<
typename
RegIndexType
>
void
BaseCompiler
:
:
atomicCmpXchg64
(
MemoryAccessDesc
*
access
ValType
type
)
{
RegI64
rexpect
rnew
rd
;
atomic_cmpxchg64
:
:
PopAndAllocate
<
RegIndexType
>
(
this
&
rexpect
&
rnew
&
rd
)
;
AccessCheck
check
;
RegIndexType
rp
=
popMemoryAccess
<
RegIndexType
>
(
access
&
check
)
;
#
ifdef
WASM_HAS_HEAPREG
RegPtr
tls
=
maybeLoadTlsForAccess
(
check
)
;
auto
memaddr
=
prepareAtomicMemoryAccess
(
access
&
check
tls
rp
)
;
atomic_cmpxchg64
:
:
Perform
(
this
*
access
memaddr
rexpect
rnew
rd
)
;
maybeFree
(
tls
)
;
#
else
ScratchAtomicNoHeapReg
scratch
(
*
this
)
;
RegPtr
tls
=
maybeLoadTlsForAccess
(
check
RegIntptrToRegPtr
(
scratch
)
)
;
Address
memaddr
=
prepareAtomicMemoryAccess
(
access
&
check
tls
rp
)
;
atomic_cmpxchg64
:
:
Perform
<
RegIndexType
>
(
this
*
access
memaddr
rexpect
rnew
rd
scratch
)
;
MOZ_ASSERT
(
tls
=
=
scratch
)
;
#
endif
free
(
rp
)
;
atomic_cmpxchg64
:
:
Deallocate
<
RegIndexType
>
(
this
rexpect
rnew
)
;
pushI64
(
rd
)
;
}
bool
BaseCompiler
:
:
atomicWait
(
ValType
type
MemoryAccessDesc
*
access
uint32_t
lineOrBytecode
)
{
switch
(
type
.
kind
(
)
)
{
case
ValType
:
:
I32
:
{
RegI64
timeout
=
popI64
(
)
;
RegI32
val
=
popI32
(
)
;
if
(
isMem32
(
)
)
{
computeEffectiveAddress
<
RegI32
>
(
access
)
;
}
else
{
#
ifdef
ENABLE_WASM_MEMORY64
computeEffectiveAddress
<
RegI64
>
(
access
)
;
#
else
MOZ_CRASH
(
"
Memory64
not
enabled
/
supported
on
this
platform
"
)
;
#
endif
}
pushI32
(
val
)
;
pushI64
(
timeout
)
;
if
(
!
emitInstanceCall
(
lineOrBytecode
isMem32
(
)
?
SASigWaitI32M32
:
SASigWaitI32M64
)
)
{
return
false
;
}
break
;
}
case
ValType
:
:
I64
:
{
RegI64
timeout
=
popI64
(
)
;
RegI64
val
=
popI64
(
)
;
if
(
isMem32
(
)
)
{
computeEffectiveAddress
<
RegI32
>
(
access
)
;
}
else
{
#
ifdef
ENABLE_WASM_MEMORY64
#
ifdef
JS_CODEGEN_X86
{
ScratchPtr
scratch
(
*
this
)
;
stashI64
(
scratch
val
)
;
freeI64
(
val
)
;
}
#
endif
computeEffectiveAddress
<
RegI64
>
(
access
)
;
#
ifdef
JS_CODEGEN_X86
{
ScratchPtr
scratch
(
*
this
)
;
val
=
needI64
(
)
;
unstashI64
(
scratch
val
)
;
}
#
endif
#
else
MOZ_CRASH
(
"
Memory64
not
enabled
/
supported
on
this
platform
"
)
;
#
endif
}
pushI64
(
val
)
;
pushI64
(
timeout
)
;
if
(
!
emitInstanceCall
(
lineOrBytecode
isMem32
(
)
?
SASigWaitI64M32
:
SASigWaitI64M64
)
)
{
return
false
;
}
break
;
}
default
:
MOZ_CRASH
(
)
;
}
return
true
;
}
bool
BaseCompiler
:
:
atomicWake
(
MemoryAccessDesc
*
access
uint32_t
lineOrBytecode
)
{
RegI32
count
=
popI32
(
)
;
if
(
isMem32
(
)
)
{
computeEffectiveAddress
<
RegI32
>
(
access
)
;
}
else
{
#
ifdef
ENABLE_WASM_MEMORY64
computeEffectiveAddress
<
RegI64
>
(
access
)
;
#
else
MOZ_CRASH
(
"
Memory64
not
enabled
/
supported
on
this
platform
"
)
;
#
endif
}
pushI32
(
count
)
;
return
emitInstanceCall
(
lineOrBytecode
isMem32
(
)
?
SASigWakeM32
:
SASigWakeM64
)
;
}
void
BaseCompiler
:
:
memCopyInlineM32
(
)
{
MOZ_ASSERT
(
MaxInlineMemoryCopyLength
!
=
0
)
;
int32_t
signedLength
;
MOZ_ALWAYS_TRUE
(
popConst
(
&
signedLength
)
)
;
uint32_t
length
=
signedLength
;
MOZ_ASSERT
(
length
!
=
0
&
&
length
<
=
MaxInlineMemoryCopyLength
)
;
RegI32
src
=
popI32
(
)
;
RegI32
dest
=
popI32
(
)
;
size_t
remainder
=
length
;
#
ifdef
ENABLE_WASM_SIMD
size_t
numCopies16
=
0
;
if
(
MacroAssembler
:
:
SupportsFastUnalignedFPAccesses
(
)
)
{
numCopies16
=
remainder
/
sizeof
(
V128
)
;
remainder
%
=
sizeof
(
V128
)
;
}
#
endif
#
ifdef
JS_64BIT
size_t
numCopies8
=
remainder
/
sizeof
(
uint64_t
)
;
remainder
%
=
sizeof
(
uint64_t
)
;
#
endif
size_t
numCopies4
=
remainder
/
sizeof
(
uint32_t
)
;
remainder
%
=
sizeof
(
uint32_t
)
;
size_t
numCopies2
=
remainder
/
sizeof
(
uint16_t
)
;
remainder
%
=
sizeof
(
uint16_t
)
;
size_t
numCopies1
=
remainder
;
bool
omitBoundsCheck
=
false
;
size_t
offset
=
0
;
#
ifdef
ENABLE_WASM_SIMD
for
(
uint32_t
i
=
0
;
i
<
numCopies16
;
i
+
+
)
{
RegI32
temp
=
needI32
(
)
;
moveI32
(
src
temp
)
;
pushI32
(
temp
)
;
MemoryAccessDesc
access
(
Scalar
:
:
Simd128
1
offset
bytecodeOffset
(
)
)
;
AccessCheck
check
;
check
.
omitBoundsCheck
=
omitBoundsCheck
;
loadCommon
(
&
access
check
ValType
:
:
V128
)
;
offset
+
=
sizeof
(
V128
)
;
omitBoundsCheck
=
true
;
}
#
endif
#
ifdef
JS_64BIT
for
(
uint32_t
i
=
0
;
i
<
numCopies8
;
i
+
+
)
{
RegI32
temp
=
needI32
(
)
;
moveI32
(
src
temp
)
;
pushI32
(
temp
)
;
MemoryAccessDesc
access
(
Scalar
:
:
Int64
1
offset
bytecodeOffset
(
)
)
;
AccessCheck
check
;
check
.
omitBoundsCheck
=
omitBoundsCheck
;
loadCommon
(
&
access
check
ValType
:
:
I64
)
;
offset
+
=
sizeof
(
uint64_t
)
;
omitBoundsCheck
=
true
;
}
#
endif
for
(
uint32_t
i
=
0
;
i
<
numCopies4
;
i
+
+
)
{
RegI32
temp
=
needI32
(
)
;
moveI32
(
src
temp
)
;
pushI32
(
temp
)
;
MemoryAccessDesc
access
(
Scalar
:
:
Uint32
1
offset
bytecodeOffset
(
)
)
;
AccessCheck
check
;
check
.
omitBoundsCheck
=
omitBoundsCheck
;
loadCommon
(
&
access
check
ValType
:
:
I32
)
;
offset
+
=
sizeof
(
uint32_t
)
;
omitBoundsCheck
=
true
;
}
if
(
numCopies2
)
{
RegI32
temp
=
needI32
(
)
;
moveI32
(
src
temp
)
;
pushI32
(
temp
)
;
MemoryAccessDesc
access
(
Scalar
:
:
Uint16
1
offset
bytecodeOffset
(
)
)
;
AccessCheck
check
;
check
.
omitBoundsCheck
=
omitBoundsCheck
;
loadCommon
(
&
access
check
ValType
:
:
I32
)
;
offset
+
=
sizeof
(
uint16_t
)
;
omitBoundsCheck
=
true
;
}
if
(
numCopies1
)
{
RegI32
temp
=
needI32
(
)
;
moveI32
(
src
temp
)
;
pushI32
(
temp
)
;
MemoryAccessDesc
access
(
Scalar
:
:
Uint8
1
offset
bytecodeOffset
(
)
)
;
AccessCheck
check
;
check
.
omitBoundsCheck
=
omitBoundsCheck
;
loadCommon
(
&
access
check
ValType
:
:
I32
)
;
}
offset
=
length
;
omitBoundsCheck
=
false
;
if
(
numCopies1
)
{
offset
-
=
sizeof
(
uint8_t
)
;
RegI32
value
=
popI32
(
)
;
RegI32
temp
=
needI32
(
)
;
moveI32
(
dest
temp
)
;
pushI32
(
temp
)
;
pushI32
(
value
)
;
MemoryAccessDesc
access
(
Scalar
:
:
Uint8
1
offset
bytecodeOffset
(
)
)
;
AccessCheck
check
;
storeCommon
(
&
access
check
ValType
:
:
I32
)
;
omitBoundsCheck
=
true
;
}
if
(
numCopies2
)
{
offset
-
=
sizeof
(
uint16_t
)
;
RegI32
value
=
popI32
(
)
;
RegI32
temp
=
needI32
(
)
;
moveI32
(
dest
temp
)
;
pushI32
(
temp
)
;
pushI32
(
value
)
;
MemoryAccessDesc
access
(
Scalar
:
:
Uint16
1
offset
bytecodeOffset
(
)
)
;
AccessCheck
check
;
check
.
omitBoundsCheck
=
omitBoundsCheck
;
storeCommon
(
&
access
check
ValType
:
:
I32
)
;
omitBoundsCheck
=
true
;
}
for
(
uint32_t
i
=
0
;
i
<
numCopies4
;
i
+
+
)
{
offset
-
=
sizeof
(
uint32_t
)
;
RegI32
value
=
popI32
(
)
;
RegI32
temp
=
needI32
(
)
;
moveI32
(
dest
temp
)
;
pushI32
(
temp
)
;
pushI32
(
value
)
;
MemoryAccessDesc
access
(
Scalar
:
:
Uint32
1
offset
bytecodeOffset
(
)
)
;
AccessCheck
check
;
check
.
omitBoundsCheck
=
omitBoundsCheck
;
storeCommon
(
&
access
check
ValType
:
:
I32
)
;
omitBoundsCheck
=
true
;
}
#
ifdef
JS_64BIT
for
(
uint32_t
i
=
0
;
i
<
numCopies8
;
i
+
+
)
{
offset
-
=
sizeof
(
uint64_t
)
;
RegI64
value
=
popI64
(
)
;
RegI32
temp
=
needI32
(
)
;
moveI32
(
dest
temp
)
;
pushI32
(
temp
)
;
pushI64
(
value
)
;
MemoryAccessDesc
access
(
Scalar
:
:
Int64
1
offset
bytecodeOffset
(
)
)
;
AccessCheck
check
;
check
.
omitBoundsCheck
=
omitBoundsCheck
;
storeCommon
(
&
access
check
ValType
:
:
I64
)
;
omitBoundsCheck
=
true
;
}
#
endif
#
ifdef
ENABLE_WASM_SIMD
for
(
uint32_t
i
=
0
;
i
<
numCopies16
;
i
+
+
)
{
offset
-
=
sizeof
(
V128
)
;
RegV128
value
=
popV128
(
)
;
RegI32
temp
=
needI32
(
)
;
moveI32
(
dest
temp
)
;
pushI32
(
temp
)
;
pushV128
(
value
)
;
MemoryAccessDesc
access
(
Scalar
:
:
Simd128
1
offset
bytecodeOffset
(
)
)
;
AccessCheck
check
;
check
.
omitBoundsCheck
=
omitBoundsCheck
;
storeCommon
(
&
access
check
ValType
:
:
V128
)
;
omitBoundsCheck
=
true
;
}
#
endif
freeI32
(
dest
)
;
freeI32
(
src
)
;
}
void
BaseCompiler
:
:
memFillInlineM32
(
)
{
MOZ_ASSERT
(
MaxInlineMemoryFillLength
!
=
0
)
;
int32_t
signedLength
;
int32_t
signedValue
;
MOZ_ALWAYS_TRUE
(
popConst
(
&
signedLength
)
)
;
MOZ_ALWAYS_TRUE
(
popConst
(
&
signedValue
)
)
;
uint32_t
length
=
uint32_t
(
signedLength
)
;
uint32_t
value
=
uint32_t
(
signedValue
)
;
MOZ_ASSERT
(
length
!
=
0
&
&
length
<
=
MaxInlineMemoryFillLength
)
;
RegI32
dest
=
popI32
(
)
;
size_t
remainder
=
length
;
#
ifdef
ENABLE_WASM_SIMD
size_t
numCopies16
=
0
;
if
(
MacroAssembler
:
:
SupportsFastUnalignedFPAccesses
(
)
)
{
numCopies16
=
remainder
/
sizeof
(
V128
)
;
remainder
%
=
sizeof
(
V128
)
;
}
#
endif
#
ifdef
JS_64BIT
size_t
numCopies8
=
remainder
/
sizeof
(
uint64_t
)
;
remainder
%
=
sizeof
(
uint64_t
)
;
#
endif
size_t
numCopies4
=
remainder
/
sizeof
(
uint32_t
)
;
remainder
%
=
sizeof
(
uint32_t
)
;
size_t
numCopies2
=
remainder
/
sizeof
(
uint16_t
)
;
remainder
%
=
sizeof
(
uint16_t
)
;
size_t
numCopies1
=
remainder
;
MOZ_ASSERT
(
numCopies2
<
=
1
&
&
numCopies1
<
=
1
)
;
#
ifdef
ENABLE_WASM_SIMD
V128
val16
(
value
)
;
#
endif
#
ifdef
JS_64BIT
uint64_t
val8
=
SplatByteToUInt
<
uint64_t
>
(
value
8
)
;
#
endif
uint32_t
val4
=
SplatByteToUInt
<
uint32_t
>
(
value
4
)
;
uint32_t
val2
=
SplatByteToUInt
<
uint32_t
>
(
value
2
)
;
uint32_t
val1
=
value
;
size_t
offset
=
length
;
bool
omitBoundsCheck
=
false
;
if
(
numCopies1
)
{
offset
-
=
sizeof
(
uint8_t
)
;
RegI32
temp
=
needI32
(
)
;
moveI32
(
dest
temp
)
;
pushI32
(
temp
)
;
pushI32
(
val1
)
;
MemoryAccessDesc
access
(
Scalar
:
:
Uint8
1
offset
bytecodeOffset
(
)
)
;
AccessCheck
check
;
storeCommon
(
&
access
check
ValType
:
:
I32
)
;
omitBoundsCheck
=
true
;
}
if
(
numCopies2
)
{
offset
-
=
sizeof
(
uint16_t
)
;
RegI32
temp
=
needI32
(
)
;
moveI32
(
dest
temp
)
;
pushI32
(
temp
)
;
pushI32
(
val2
)
;
MemoryAccessDesc
access
(
Scalar
:
:
Uint16
1
offset
bytecodeOffset
(
)
)
;
AccessCheck
check
;
check
.
omitBoundsCheck
=
omitBoundsCheck
;
storeCommon
(
&
access
check
ValType
:
:
I32
)
;
omitBoundsCheck
=
true
;
}
for
(
uint32_t
i
=
0
;
i
<
numCopies4
;
i
+
+
)
{
offset
-
=
sizeof
(
uint32_t
)
;
RegI32
temp
=
needI32
(
)
;
moveI32
(
dest
temp
)
;
pushI32
(
temp
)
;
pushI32
(
val4
)
;
MemoryAccessDesc
access
(
Scalar
:
:
Uint32
1
offset
bytecodeOffset
(
)
)
;
AccessCheck
check
;
check
.
omitBoundsCheck
=
omitBoundsCheck
;
storeCommon
(
&
access
check
ValType
:
:
I32
)
;
omitBoundsCheck
=
true
;
}
#
ifdef
JS_64BIT
for
(
uint32_t
i
=
0
;
i
<
numCopies8
;
i
+
+
)
{
offset
-
=
sizeof
(
uint64_t
)
;
RegI32
temp
=
needI32
(
)
;
moveI32
(
dest
temp
)
;
pushI32
(
temp
)
;
pushI64
(
val8
)
;
MemoryAccessDesc
access
(
Scalar
:
:
Int64
1
offset
bytecodeOffset
(
)
)
;
AccessCheck
check
;
check
.
omitBoundsCheck
=
omitBoundsCheck
;
storeCommon
(
&
access
check
ValType
:
:
I64
)
;
omitBoundsCheck
=
true
;
}
#
endif
#
ifdef
ENABLE_WASM_SIMD
for
(
uint32_t
i
=
0
;
i
<
numCopies16
;
i
+
+
)
{
offset
-
=
sizeof
(
V128
)
;
RegI32
temp
=
needI32
(
)
;
moveI32
(
dest
temp
)
;
pushI32
(
temp
)
;
pushV128
(
val16
)
;
MemoryAccessDesc
access
(
Scalar
:
:
Simd128
1
offset
bytecodeOffset
(
)
)
;
AccessCheck
check
;
check
.
omitBoundsCheck
=
omitBoundsCheck
;
storeCommon
(
&
access
check
ValType
:
:
V128
)
;
omitBoundsCheck
=
true
;
}
#
endif
freeI32
(
dest
)
;
}
#
ifdef
ENABLE_WASM_SIMD
void
BaseCompiler
:
:
loadSplat
(
MemoryAccessDesc
*
access
)
{
RegV128
rd
=
needV128
(
)
;
switch
(
access
-
>
type
(
)
)
{
case
Scalar
:
:
Uint8
:
{
loadCommon
(
access
AccessCheck
(
)
ValType
:
:
I32
)
;
RegI32
rs
=
popI32
(
)
;
masm
.
splatX16
(
rs
rd
)
;
free
(
rs
)
;
break
;
}
case
Scalar
:
:
Uint16
:
{
loadCommon
(
access
AccessCheck
(
)
ValType
:
:
I32
)
;
RegI32
rs
=
popI32
(
)
;
masm
.
splatX8
(
rs
rd
)
;
free
(
rs
)
;
break
;
}
case
Scalar
:
:
Uint32
:
{
loadCommon
(
access
AccessCheck
(
)
ValType
:
:
I32
)
;
RegI32
rs
=
popI32
(
)
;
masm
.
splatX4
(
rs
rd
)
;
free
(
rs
)
;
break
;
}
case
Scalar
:
:
Int64
:
{
loadCommon
(
access
AccessCheck
(
)
ValType
:
:
I64
)
;
RegI64
rs
=
popI64
(
)
;
masm
.
splatX2
(
rs
rd
)
;
free
(
rs
)
;
break
;
}
default
:
MOZ_CRASH
(
)
;
}
pushV128
(
rd
)
;
}
void
BaseCompiler
:
:
loadZero
(
MemoryAccessDesc
*
access
)
{
access
-
>
setZeroExtendSimd128Load
(
)
;
loadCommon
(
access
AccessCheck
(
)
ValType
:
:
V128
)
;
}
void
BaseCompiler
:
:
loadExtend
(
MemoryAccessDesc
*
access
Scalar
:
:
Type
viewType
)
{
loadCommon
(
access
AccessCheck
(
)
ValType
:
:
I64
)
;
RegI64
rs
=
popI64
(
)
;
RegV128
rd
=
needV128
(
)
;
masm
.
moveGPR64ToDouble
(
rs
rd
)
;
switch
(
viewType
)
{
case
Scalar
:
:
Int8
:
masm
.
widenLowInt8x16
(
rd
rd
)
;
break
;
case
Scalar
:
:
Uint8
:
masm
.
unsignedWidenLowInt8x16
(
rd
rd
)
;
break
;
case
Scalar
:
:
Int16
:
masm
.
widenLowInt16x8
(
rd
rd
)
;
break
;
case
Scalar
:
:
Uint16
:
masm
.
unsignedWidenLowInt16x8
(
rd
rd
)
;
break
;
case
Scalar
:
:
Int32
:
masm
.
widenLowInt32x4
(
rd
rd
)
;
break
;
case
Scalar
:
:
Uint32
:
masm
.
unsignedWidenLowInt32x4
(
rd
rd
)
;
break
;
default
:
MOZ_CRASH
(
)
;
}
freeI64
(
rs
)
;
pushV128
(
rd
)
;
}
void
BaseCompiler
:
:
loadLane
(
MemoryAccessDesc
*
access
uint32_t
laneIndex
)
{
ValType
type
=
access
-
>
type
(
)
=
=
Scalar
:
:
Int64
?
ValType
:
:
I64
:
ValType
:
:
I32
;
RegV128
rsd
=
popV128
(
)
;
loadCommon
(
access
AccessCheck
(
)
type
)
;
if
(
type
=
=
ValType
:
:
I32
)
{
RegI32
rs
=
popI32
(
)
;
switch
(
access
-
>
type
(
)
)
{
case
Scalar
:
:
Uint8
:
masm
.
replaceLaneInt8x16
(
laneIndex
rs
rsd
)
;
break
;
case
Scalar
:
:
Uint16
:
masm
.
replaceLaneInt16x8
(
laneIndex
rs
rsd
)
;
break
;
case
Scalar
:
:
Int32
:
masm
.
replaceLaneInt32x4
(
laneIndex
rs
rsd
)
;
break
;
default
:
MOZ_CRASH
(
"
unsupported
access
type
"
)
;
}
freeI32
(
rs
)
;
}
else
{
MOZ_ASSERT
(
type
=
=
ValType
:
:
I64
)
;
RegI64
rs
=
popI64
(
)
;
masm
.
replaceLaneInt64x2
(
laneIndex
rs
rsd
)
;
freeI64
(
rs
)
;
}
pushV128
(
rsd
)
;
}
void
BaseCompiler
:
:
storeLane
(
MemoryAccessDesc
*
access
uint32_t
laneIndex
)
{
ValType
type
=
access
-
>
type
(
)
=
=
Scalar
:
:
Int64
?
ValType
:
:
I64
:
ValType
:
:
I32
;
RegV128
rs
=
popV128
(
)
;
if
(
type
=
=
ValType
:
:
I32
)
{
RegI32
tmp
=
needI32
(
)
;
switch
(
access
-
>
type
(
)
)
{
case
Scalar
:
:
Uint8
:
masm
.
extractLaneInt8x16
(
laneIndex
rs
tmp
)
;
break
;
case
Scalar
:
:
Uint16
:
masm
.
extractLaneInt16x8
(
laneIndex
rs
tmp
)
;
break
;
case
Scalar
:
:
Int32
:
masm
.
extractLaneInt32x4
(
laneIndex
rs
tmp
)
;
break
;
default
:
MOZ_CRASH
(
"
unsupported
laneSize
"
)
;
}
pushI32
(
tmp
)
;
}
else
{
MOZ_ASSERT
(
type
=
=
ValType
:
:
I64
)
;
RegI64
tmp
=
needI64
(
)
;
masm
.
extractLaneInt64x2
(
laneIndex
rs
tmp
)
;
pushI64
(
tmp
)
;
}
freeV128
(
rs
)
;
storeCommon
(
access
AccessCheck
(
)
type
)
;
}
#
endif
}
}
