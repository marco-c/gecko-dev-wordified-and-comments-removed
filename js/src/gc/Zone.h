#
ifndef
gc_Zone_h
#
define
gc_Zone_h
#
include
"
mozilla
/
Atomics
.
h
"
#
include
"
mozilla
/
DebugOnly
.
h
"
#
include
"
mozilla
/
MemoryReporting
.
h
"
#
include
"
jscntxt
.
h
"
#
include
"
ds
/
SpinLock
.
h
"
#
include
"
ds
/
SplayTree
.
h
"
#
include
"
gc
/
FindSCCs
.
h
"
#
include
"
gc
/
GCRuntime
.
h
"
#
include
"
js
/
TracingAPI
.
h
"
#
include
"
vm
/
MallocProvider
.
h
"
#
include
"
vm
/
TypeInference
.
h
"
namespace
js
{
namespace
jit
{
class
JitZone
;
}
namespace
gc
{
class
ZoneHeapThreshold
{
double
gcHeapGrowthFactor_
;
size_t
gcTriggerBytes_
;
public
:
ZoneHeapThreshold
(
)
:
gcHeapGrowthFactor_
(
3
.
0
)
gcTriggerBytes_
(
0
)
{
}
double
gcHeapGrowthFactor
(
)
const
{
return
gcHeapGrowthFactor_
;
}
size_t
gcTriggerBytes
(
)
const
{
return
gcTriggerBytes_
;
}
double
allocTrigger
(
bool
highFrequencyGC
)
const
;
void
updateAfterGC
(
size_t
lastBytes
JSGCInvocationKind
gckind
const
GCSchedulingTunables
&
tunables
const
GCSchedulingState
&
state
)
;
void
updateForRemovedArena
(
const
GCSchedulingTunables
&
tunables
)
;
private
:
static
double
computeZoneHeapGrowthFactorForHeapSize
(
size_t
lastBytes
const
GCSchedulingTunables
&
tunables
const
GCSchedulingState
&
state
)
;
static
size_t
computeZoneTriggerBytes
(
double
growthFactor
size_t
lastBytes
JSGCInvocationKind
gckind
const
GCSchedulingTunables
&
tunables
)
;
}
;
class
UniqueIdMap
{
struct
Pair
{
uint64_t
uniqueId
;
Cell
*
key
;
public
:
Pair
(
Cell
*
cell
uint64_t
uid
)
:
uniqueId
(
uid
)
key
(
cell
)
{
}
Pair
(
const
Pair
&
other
)
:
uniqueId
(
other
.
uniqueId
)
key
(
other
.
key
)
{
}
static
ptrdiff_t
compare
(
const
Pair
&
a
const
Pair
&
b
)
{
return
b
.
key
-
a
.
key
;
}
}
;
const
size_t
AllocChunkSize
=
mozilla
:
:
RoundUpPow2
(
16
*
sizeof
(
Pair
)
)
;
LifoAlloc
alloc
;
SplayTree
<
Pair
Pair
>
map
;
public
:
UniqueIdMap
(
)
:
alloc
(
AllocChunkSize
)
map
(
&
alloc
)
{
}
bool
isEmpty
(
)
{
return
map
.
empty
(
)
;
}
bool
has
(
Cell
*
cell
)
{
return
map
.
maybeLookup
(
Pair
(
cell
0
)
)
;
}
bool
lookup
(
Cell
*
cell
uint64_t
*
uidp
)
{
Pair
tmp
(
nullptr
0
)
;
if
(
!
map
.
contains
(
Pair
(
cell
0
)
&
tmp
)
)
return
false
;
MOZ_ASSERT
(
tmp
.
key
=
=
cell
)
;
MOZ_ASSERT
(
tmp
.
uniqueId
>
0
)
;
*
uidp
=
tmp
.
uniqueId
;
return
true
;
}
bool
put
(
Cell
*
cell
uint64_t
uid
)
{
MOZ_ASSERT
(
uid
>
0
)
;
return
map
.
insert
(
Pair
(
cell
uid
)
)
;
}
void
remove
(
Cell
*
cell
)
{
map
.
remove
(
Pair
(
cell
0
)
)
;
}
size_t
sizeOfExcludingThis
(
mozilla
:
:
MallocSizeOf
mallocSizeOf
)
const
{
return
alloc
.
sizeOfExcludingThis
(
mallocSizeOf
)
;
}
}
;
extern
uint64_t
NextCellUniqueId
(
JSRuntime
*
rt
)
;
}
}
namespace
JS
{
struct
Zone
:
public
JS
:
:
shadow
:
:
Zone
public
js
:
:
gc
:
:
GraphNodeBase
<
JS
:
:
Zone
>
public
js
:
:
MallocProvider
<
JS
:
:
Zone
>
{
explicit
Zone
(
JSRuntime
*
rt
)
;
~
Zone
(
)
;
bool
init
(
bool
isSystem
)
;
void
findOutgoingEdges
(
js
:
:
gc
:
:
ComponentFinder
<
JS
:
:
Zone
>
&
finder
)
;
void
discardJitCode
(
js
:
:
FreeOp
*
fop
)
;
void
addSizeOfIncludingThis
(
mozilla
:
:
MallocSizeOf
mallocSizeOf
size_t
*
typePool
size_t
*
baselineStubsOptimized
size_t
*
uniqueIdMap
)
;
void
resetGCMallocBytes
(
)
;
void
setGCMaxMallocBytes
(
size_t
value
)
;
void
updateMallocCounter
(
size_t
nbytes
)
{
gcMallocBytes
-
=
ptrdiff_t
(
nbytes
)
;
if
(
MOZ_UNLIKELY
(
isTooMuchMalloc
(
)
)
)
onTooMuchMalloc
(
)
;
}
bool
isTooMuchMalloc
(
)
const
{
return
gcMallocBytes
<
=
0
;
}
void
onTooMuchMalloc
(
)
;
void
*
onOutOfMemory
(
js
:
:
AllocFunction
allocFunc
size_t
nbytes
void
*
reallocPtr
=
nullptr
)
{
return
runtimeFromMainThread
(
)
-
>
onOutOfMemory
(
allocFunc
nbytes
reallocPtr
)
;
}
void
reportAllocationOverflow
(
)
{
js
:
:
ReportAllocationOverflow
(
nullptr
)
;
}
void
beginSweepTypes
(
js
:
:
FreeOp
*
fop
bool
releaseTypes
)
;
bool
hasMarkedCompartments
(
)
;
void
scheduleGC
(
)
{
MOZ_ASSERT
(
!
runtimeFromMainThread
(
)
-
>
isHeapBusy
(
)
)
;
gcScheduled_
=
true
;
}
void
unscheduleGC
(
)
{
gcScheduled_
=
false
;
}
bool
isGCScheduled
(
)
{
return
gcScheduled_
&
&
canCollect
(
)
;
}
void
setPreservingCode
(
bool
preserving
)
{
gcPreserveCode_
=
preserving
;
}
bool
isPreservingCode
(
)
const
{
return
gcPreserveCode_
;
}
bool
canCollect
(
)
;
void
notifyObservingDebuggers
(
)
;
enum
GCState
{
NoGC
Mark
MarkGray
Sweep
Finished
Compact
}
;
void
setGCState
(
GCState
state
)
{
MOZ_ASSERT
(
runtimeFromMainThread
(
)
-
>
isHeapBusy
(
)
)
;
MOZ_ASSERT_IF
(
state
!
=
NoGC
canCollect
(
)
)
;
gcState_
=
state
;
if
(
state
=
=
Finished
)
notifyObservingDebuggers
(
)
;
}
bool
isCollecting
(
)
const
{
if
(
runtimeFromMainThread
(
)
-
>
isHeapCollecting
(
)
)
return
gcState_
!
=
NoGC
;
else
return
needsIncrementalBarrier
(
)
;
}
bool
isCollectingFromAnyThread
(
)
const
{
if
(
runtimeFromAnyThread
(
)
-
>
isHeapCollecting
(
)
)
return
gcState_
!
=
NoGC
;
else
return
needsIncrementalBarrier
(
)
;
}
bool
requireGCTracer
(
)
const
{
JSRuntime
*
rt
=
runtimeFromAnyThread
(
)
;
return
rt
-
>
isHeapMajorCollecting
(
)
&
&
!
rt
-
>
gc
.
isHeapCompacting
(
)
&
&
gcState_
!
=
NoGC
;
}
bool
isGCMarking
(
)
{
if
(
runtimeFromMainThread
(
)
-
>
isHeapCollecting
(
)
)
return
gcState_
=
=
Mark
|
|
gcState_
=
=
MarkGray
;
else
return
needsIncrementalBarrier
(
)
;
}
bool
wasGCStarted
(
)
const
{
return
gcState_
!
=
NoGC
;
}
bool
isGCMarkingBlack
(
)
{
return
gcState_
=
=
Mark
;
}
bool
isGCMarkingGray
(
)
{
return
gcState_
=
=
MarkGray
;
}
bool
isGCSweeping
(
)
{
return
gcState_
=
=
Sweep
;
}
bool
isGCFinished
(
)
{
return
gcState_
=
=
Finished
;
}
bool
isGCCompacting
(
)
{
return
gcState_
=
=
Compact
;
}
bool
isGCSweepingOrCompacting
(
)
{
return
gcState_
=
=
Sweep
|
|
gcState_
=
=
Compact
;
}
uint64_t
gcNumber
(
)
;
bool
compileBarriers
(
)
const
{
return
compileBarriers
(
needsIncrementalBarrier
(
)
)
;
}
bool
compileBarriers
(
bool
needsIncrementalBarrier
)
const
{
return
needsIncrementalBarrier
|
|
runtimeFromMainThread
(
)
-
>
gcZeal
(
)
=
=
js
:
:
gc
:
:
ZealVerifierPreValue
;
}
enum
ShouldUpdateJit
{
DontUpdateJit
UpdateJit
}
;
void
setNeedsIncrementalBarrier
(
bool
needs
ShouldUpdateJit
updateJit
)
;
const
bool
*
addressOfNeedsIncrementalBarrier
(
)
const
{
return
&
needsIncrementalBarrier_
;
}
js
:
:
jit
:
:
JitZone
*
getJitZone
(
JSContext
*
cx
)
{
return
jitZone_
?
jitZone_
:
createJitZone
(
cx
)
;
}
js
:
:
jit
:
:
JitZone
*
jitZone
(
)
{
return
jitZone_
;
}
bool
isAtomsZone
(
)
const
{
return
runtimeFromAnyThread
(
)
-
>
isAtomsZone
(
this
)
;
}
bool
isSelfHostingZone
(
)
const
{
return
runtimeFromAnyThread
(
)
-
>
isSelfHostingZone
(
this
)
;
}
void
prepareForCompacting
(
)
;
#
ifdef
DEBUG
unsigned
lastZoneGroupIndex
(
)
{
return
gcLastZoneGroupIndex
;
}
#
endif
using
DebuggerVector
=
js
:
:
Vector
<
js
:
:
Debugger
*
0
js
:
:
SystemAllocPolicy
>
;
private
:
DebuggerVector
*
debuggers
;
using
LogTenurePromotionQueue
=
js
:
:
Vector
<
JSObject
*
0
js
:
:
SystemAllocPolicy
>
;
LogTenurePromotionQueue
awaitingTenureLogging
;
void
sweepBreakpoints
(
js
:
:
FreeOp
*
fop
)
;
void
sweepCompartments
(
js
:
:
FreeOp
*
fop
bool
keepAtleastOne
bool
lastGC
)
;
js
:
:
jit
:
:
JitZone
*
createJitZone
(
JSContext
*
cx
)
;
bool
isQueuedForBackgroundSweep
(
)
{
return
isOnList
(
)
;
}
js
:
:
gc
:
:
UniqueIdMap
uniqueIds_
;
js
:
:
SpinLock
uniqueIdsLock_
;
public
:
bool
hasDebuggers
(
)
const
{
return
debuggers
&
&
debuggers
-
>
length
(
)
;
}
DebuggerVector
*
getDebuggers
(
)
const
{
return
debuggers
;
}
DebuggerVector
*
getOrCreateDebuggers
(
JSContext
*
cx
)
;
void
enqueueForPromotionToTenuredLogging
(
JSObject
&
obj
)
{
MOZ_ASSERT
(
hasDebuggers
(
)
)
;
MOZ_ASSERT
(
!
IsInsideNursery
(
&
obj
)
)
;
if
(
!
awaitingTenureLogging
.
append
(
&
obj
)
)
js
:
:
CrashAtUnhandlableOOM
(
"
Zone
:
:
enqueueForPromotionToTenuredLogging
"
)
;
}
void
logPromotionsToTenured
(
)
;
js
:
:
gc
:
:
ArenaLists
arenas
;
js
:
:
TypeZone
types
;
typedef
js
:
:
Vector
<
JSCompartment
*
1
js
:
:
SystemAllocPolicy
>
CompartmentVector
;
CompartmentVector
compartments
;
typedef
js
:
:
Vector
<
js
:
:
gc
:
:
Cell
*
0
js
:
:
SystemAllocPolicy
>
GrayRootVector
;
GrayRootVector
gcGrayRoots
;
ZoneSet
gcZoneGroupEdges
;
mozilla
:
:
Atomic
<
ptrdiff_t
mozilla
:
:
ReleaseAcquire
>
gcMallocBytes
;
size_t
gcMaxMallocBytes
;
mozilla
:
:
Atomic
<
uint32_t
mozilla
:
:
ReleaseAcquire
>
gcMallocGCTriggered
;
js
:
:
gc
:
:
HeapUsage
usage
;
js
:
:
gc
:
:
ZoneHeapThreshold
threshold
;
size_t
gcDelayBytes
;
void
*
data
;
bool
isSystem
;
bool
usedByExclusiveThread
;
bool
active
;
mozilla
:
:
DebugOnly
<
unsigned
>
gcLastZoneGroupIndex
;
bool
getHashCode
(
js
:
:
gc
:
:
Cell
*
cell
js
:
:
HashNumber
*
hashp
)
{
uint64_t
uid
;
if
(
!
getUniqueId
(
cell
&
uid
)
)
return
false
;
*
hashp
=
(
uid
>
>
32
)
&
(
uid
&
0xFFFFFFFF
)
;
return
true
;
}
bool
getUniqueId
(
js
:
:
gc
:
:
Cell
*
cell
uint64_t
*
uidp
)
{
MOZ_ASSERT
(
uidp
)
;
js
:
:
AutoSpinLock
lock
(
uniqueIdsLock_
)
;
if
(
uniqueIds_
.
lookup
(
cell
uidp
)
)
return
true
;
*
uidp
=
js
:
:
gc
:
:
NextCellUniqueId
(
runtimeFromAnyThread
(
)
)
;
if
(
!
uniqueIds_
.
put
(
cell
*
uidp
)
)
return
false
;
if
(
!
runtimeFromAnyThread
(
)
-
>
gc
.
nursery
.
addedUniqueIdToCell
(
cell
)
)
js
:
:
CrashAtUnhandlableOOM
(
"
failed
to
allocate
tracking
data
for
a
nursery
uid
"
)
;
return
true
;
}
bool
hasUniqueId
(
js
:
:
gc
:
:
Cell
*
cell
)
{
js
:
:
AutoSpinLock
lock
(
uniqueIdsLock_
)
;
uint64_t
tmp
;
return
uniqueIds_
.
lookup
(
cell
&
tmp
)
;
}
void
transferUniqueId
(
js
:
:
gc
:
:
Cell
*
tgt
js
:
:
gc
:
:
Cell
*
src
)
{
MOZ_ASSERT
(
src
!
=
tgt
)
;
MOZ_ASSERT
(
!
IsInsideNursery
(
tgt
)
)
;
MOZ_ASSERT
(
CurrentThreadCanAccessRuntime
(
runtimeFromMainThread
(
)
)
)
;
js
:
:
AutoSpinLock
lock
(
uniqueIdsLock_
)
;
uint64_t
uid
=
0
;
if
(
!
uniqueIds_
.
lookup
(
src
&
uid
)
)
return
;
uniqueIds_
.
remove
(
src
)
;
MOZ_ASSERT
(
uid
>
0
)
;
mozilla
:
:
DebugOnly
<
bool
>
ok
=
uniqueIds_
.
put
(
tgt
uid
)
;
MOZ_ASSERT
(
ok
)
;
}
void
removeUniqueId
(
js
:
:
gc
:
:
Cell
*
cell
)
{
js
:
:
AutoSpinLock
lock
(
uniqueIdsLock_
)
;
uniqueIds_
.
remove
(
cell
)
;
}
private
:
js
:
:
jit
:
:
JitZone
*
jitZone_
;
GCState
gcState_
;
bool
gcScheduled_
;
bool
gcPreserveCode_
;
bool
jitUsingBarriers_
;
friend
class
js
:
:
gc
:
:
ZoneList
;
static
Zone
*
const
NotOnList
;
Zone
*
listNext_
;
bool
isOnList
(
)
const
;
Zone
*
nextZone
(
)
const
;
friend
bool
js
:
:
CurrentThreadCanAccessZone
(
Zone
*
zone
)
;
friend
class
js
:
:
gc
:
:
GCRuntime
;
}
;
}
namespace
js
{
enum
ZoneSelector
{
WithAtoms
SkipAtoms
}
;
class
ZonesIter
{
gc
:
:
AutoEnterIteration
iterMarker
;
JS
:
:
Zone
*
*
it
;
JS
:
:
Zone
*
*
end
;
public
:
ZonesIter
(
JSRuntime
*
rt
ZoneSelector
selector
)
:
iterMarker
(
&
rt
-
>
gc
)
{
it
=
rt
-
>
gc
.
zones
.
begin
(
)
;
end
=
rt
-
>
gc
.
zones
.
end
(
)
;
if
(
selector
=
=
SkipAtoms
)
{
MOZ_ASSERT
(
atAtomsZone
(
rt
)
)
;
it
+
+
;
}
}
bool
atAtomsZone
(
JSRuntime
*
rt
)
;
bool
done
(
)
const
{
return
it
=
=
end
;
}
void
next
(
)
{
MOZ_ASSERT
(
!
done
(
)
)
;
do
{
it
+
+
;
}
while
(
!
done
(
)
&
&
(
*
it
)
-
>
usedByExclusiveThread
)
;
}
JS
:
:
Zone
*
get
(
)
const
{
MOZ_ASSERT
(
!
done
(
)
)
;
return
*
it
;
}
operator
JS
:
:
Zone
*
(
)
const
{
return
get
(
)
;
}
JS
:
:
Zone
*
operator
-
>
(
)
const
{
return
get
(
)
;
}
}
;
struct
CompartmentsInZoneIter
{
explicit
CompartmentsInZoneIter
(
JS
:
:
Zone
*
zone
)
:
zone
(
zone
)
{
it
=
zone
-
>
compartments
.
begin
(
)
;
}
bool
done
(
)
const
{
MOZ_ASSERT
(
it
)
;
return
it
<
zone
-
>
compartments
.
begin
(
)
|
|
it
>
=
zone
-
>
compartments
.
end
(
)
;
}
void
next
(
)
{
MOZ_ASSERT
(
!
done
(
)
)
;
it
+
+
;
}
JSCompartment
*
get
(
)
const
{
MOZ_ASSERT
(
it
)
;
return
*
it
;
}
operator
JSCompartment
*
(
)
const
{
return
get
(
)
;
}
JSCompartment
*
operator
-
>
(
)
const
{
return
get
(
)
;
}
private
:
JS
:
:
Zone
*
zone
;
JSCompartment
*
*
it
;
CompartmentsInZoneIter
(
)
:
zone
(
nullptr
)
it
(
nullptr
)
{
}
friend
class
mozilla
:
:
Maybe
<
CompartmentsInZoneIter
>
;
}
;
template
<
class
ZonesIterT
>
class
CompartmentsIterT
{
gc
:
:
AutoEnterIteration
iterMarker
;
ZonesIterT
zone
;
mozilla
:
:
Maybe
<
CompartmentsInZoneIter
>
comp
;
public
:
explicit
CompartmentsIterT
(
JSRuntime
*
rt
)
:
iterMarker
(
&
rt
-
>
gc
)
zone
(
rt
)
{
if
(
zone
.
done
(
)
)
comp
.
emplace
(
)
;
else
comp
.
emplace
(
zone
)
;
}
CompartmentsIterT
(
JSRuntime
*
rt
ZoneSelector
selector
)
:
iterMarker
(
&
rt
-
>
gc
)
zone
(
rt
selector
)
{
if
(
zone
.
done
(
)
)
comp
.
emplace
(
)
;
else
comp
.
emplace
(
zone
)
;
}
bool
done
(
)
const
{
return
zone
.
done
(
)
;
}
void
next
(
)
{
MOZ_ASSERT
(
!
done
(
)
)
;
MOZ_ASSERT
(
!
comp
.
ref
(
)
.
done
(
)
)
;
comp
-
>
next
(
)
;
if
(
comp
-
>
done
(
)
)
{
comp
.
reset
(
)
;
zone
.
next
(
)
;
if
(
!
zone
.
done
(
)
)
comp
.
emplace
(
zone
)
;
}
}
JSCompartment
*
get
(
)
const
{
MOZ_ASSERT
(
!
done
(
)
)
;
return
*
comp
;
}
operator
JSCompartment
*
(
)
const
{
return
get
(
)
;
}
JSCompartment
*
operator
-
>
(
)
const
{
return
get
(
)
;
}
}
;
typedef
CompartmentsIterT
<
ZonesIter
>
CompartmentsIter
;
}
#
endif
