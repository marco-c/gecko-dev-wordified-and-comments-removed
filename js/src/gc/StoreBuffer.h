#
ifndef
gc_StoreBuffer_h
#
define
gc_StoreBuffer_h
#
include
"
mozilla
/
Attributes
.
h
"
#
include
"
mozilla
/
HashFunctions
.
h
"
#
include
"
mozilla
/
ReentrancyGuard
.
h
"
#
include
<
algorithm
>
#
include
"
ds
/
BitArray
.
h
"
#
include
"
ds
/
LifoAlloc
.
h
"
#
include
"
gc
/
Cell
.
h
"
#
include
"
gc
/
Nursery
.
h
"
#
include
"
gc
/
TraceKind
.
h
"
#
include
"
js
/
AllocPolicy
.
h
"
#
include
"
js
/
UniquePtr
.
h
"
#
include
"
threading
/
Mutex
.
h
"
namespace
JS
{
struct
GCSizes
;
}
namespace
js
{
class
NativeObject
;
#
ifdef
DEBUG
extern
bool
CurrentThreadIsGCMarking
(
)
;
#
endif
namespace
gc
{
class
Arena
;
class
ArenaCellSet
;
#
ifdef
DEBUG
extern
bool
CurrentThreadHasLockedGC
(
)
;
#
endif
class
BufferableRef
{
public
:
virtual
void
trace
(
JSTracer
*
trc
)
=
0
;
bool
maybeInRememberedSet
(
const
Nursery
&
)
const
{
return
true
;
}
}
;
typedef
HashSet
<
void
*
PointerHasher
<
void
*
>
SystemAllocPolicy
>
EdgeSet
;
static
const
size_t
LifoAllocBlockSize
=
8
*
1024
;
class
StoreBuffer
{
friend
class
mozilla
:
:
ReentrancyGuard
;
static
const
size_t
GenericBufferLowAvailableThreshold
=
LifoAllocBlockSize
/
2
;
static
const
size_t
BufferOverflowThresholdBytes
=
128
*
1024
;
template
<
typename
T
>
struct
MonoTypeBuffer
{
typedef
HashSet
<
T
typename
T
:
:
Hasher
SystemAllocPolicy
>
StoreSet
;
StoreSet
stores_
;
T
last_
;
StoreBuffer
*
owner_
;
JS
:
:
GCReason
gcReason_
;
const
static
size_t
MaxEntries
=
BufferOverflowThresholdBytes
/
sizeof
(
T
)
;
explicit
MonoTypeBuffer
(
StoreBuffer
*
owner
JS
:
:
GCReason
reason
)
:
last_
(
T
(
)
)
owner_
(
owner
)
gcReason_
(
reason
)
{
}
void
clear
(
)
{
last_
=
T
(
)
;
stores_
.
clear
(
)
;
}
void
put
(
const
T
&
t
)
{
sinkStore
(
)
;
last_
=
t
;
}
void
unput
(
const
T
&
v
)
{
if
(
last_
=
=
v
)
{
last_
=
T
(
)
;
return
;
}
stores_
.
remove
(
v
)
;
}
void
sinkStore
(
)
{
if
(
last_
)
{
AutoEnterOOMUnsafeRegion
oomUnsafe
;
if
(
!
stores_
.
put
(
last_
)
)
{
oomUnsafe
.
crash
(
"
Failed
to
allocate
for
MonoTypeBuffer
:
:
put
.
"
)
;
}
}
last_
=
T
(
)
;
if
(
MOZ_UNLIKELY
(
stores_
.
count
(
)
>
MaxEntries
)
)
{
owner_
-
>
setAboutToOverflow
(
gcReason_
)
;
}
}
void
trace
(
TenuringTracer
&
mover
)
;
size_t
sizeOfExcludingThis
(
mozilla
:
:
MallocSizeOf
mallocSizeOf
)
{
return
stores_
.
shallowSizeOfExcludingThis
(
mallocSizeOf
)
;
}
bool
isEmpty
(
)
const
{
return
last_
=
=
T
(
)
&
&
stores_
.
empty
(
)
;
}
private
:
MonoTypeBuffer
(
const
MonoTypeBuffer
&
other
)
=
delete
;
MonoTypeBuffer
&
operator
=
(
const
MonoTypeBuffer
&
other
)
=
delete
;
}
;
struct
WholeCellBuffer
{
UniquePtr
<
LifoAlloc
>
storage_
;
ArenaCellSet
*
stringHead_
=
nullptr
;
ArenaCellSet
*
nonStringHead_
=
nullptr
;
const
Cell
*
last_
=
nullptr
;
StoreBuffer
*
owner_
;
explicit
WholeCellBuffer
(
StoreBuffer
*
owner
)
:
owner_
(
owner
)
{
}
[
[
nodiscard
]
]
bool
init
(
)
;
void
clear
(
)
;
bool
isAboutToOverflow
(
)
const
{
return
!
storage_
-
>
isEmpty
(
)
&
&
storage_
-
>
used
(
)
>
BufferOverflowThresholdBytes
;
}
void
trace
(
TenuringTracer
&
mover
)
;
inline
void
put
(
const
Cell
*
cell
)
;
inline
void
putDontCheckLast
(
const
Cell
*
cell
)
;
size_t
sizeOfExcludingThis
(
mozilla
:
:
MallocSizeOf
mallocSizeOf
)
{
return
storage_
?
storage_
-
>
sizeOfIncludingThis
(
mallocSizeOf
)
:
0
;
}
bool
isEmpty
(
)
const
{
MOZ_ASSERT_IF
(
!
stringHead_
&
&
!
nonStringHead_
!
storage_
|
|
storage_
-
>
isEmpty
(
)
)
;
return
!
stringHead_
&
&
!
nonStringHead_
;
}
const
Cell
*
*
lastBufferedPtr
(
)
{
return
&
last_
;
}
private
:
ArenaCellSet
*
allocateCellSet
(
Arena
*
arena
)
;
WholeCellBuffer
(
const
WholeCellBuffer
&
other
)
=
delete
;
WholeCellBuffer
&
operator
=
(
const
WholeCellBuffer
&
other
)
=
delete
;
}
;
struct
GenericBuffer
{
UniquePtr
<
LifoAlloc
>
storage_
;
StoreBuffer
*
owner_
;
explicit
GenericBuffer
(
StoreBuffer
*
owner
)
:
storage_
(
nullptr
)
owner_
(
owner
)
{
}
[
[
nodiscard
]
]
bool
init
(
)
;
void
clear
(
)
{
if
(
storage_
)
{
storage_
-
>
used
(
)
?
storage_
-
>
releaseAll
(
)
:
storage_
-
>
freeAll
(
)
;
}
}
bool
isAboutToOverflow
(
)
const
{
return
!
storage_
-
>
isEmpty
(
)
&
&
storage_
-
>
availableInCurrentChunk
(
)
<
GenericBufferLowAvailableThreshold
;
}
void
trace
(
JSTracer
*
trc
)
;
template
<
typename
T
>
void
put
(
const
T
&
t
)
{
MOZ_ASSERT
(
storage_
)
;
(
void
)
static_cast
<
const
BufferableRef
*
>
(
&
t
)
;
AutoEnterOOMUnsafeRegion
oomUnsafe
;
unsigned
size
=
sizeof
(
T
)
;
unsigned
*
sizep
=
storage_
-
>
pod_malloc
<
unsigned
>
(
)
;
if
(
!
sizep
)
{
oomUnsafe
.
crash
(
"
Failed
to
allocate
for
GenericBuffer
:
:
put
.
"
)
;
}
*
sizep
=
size
;
T
*
tp
=
storage_
-
>
new_
<
T
>
(
t
)
;
if
(
!
tp
)
{
oomUnsafe
.
crash
(
"
Failed
to
allocate
for
GenericBuffer
:
:
put
.
"
)
;
}
if
(
isAboutToOverflow
(
)
)
{
owner_
-
>
setAboutToOverflow
(
JS
:
:
GCReason
:
:
FULL_GENERIC_BUFFER
)
;
}
}
size_t
sizeOfExcludingThis
(
mozilla
:
:
MallocSizeOf
mallocSizeOf
)
{
return
storage_
?
storage_
-
>
sizeOfIncludingThis
(
mallocSizeOf
)
:
0
;
}
bool
isEmpty
(
)
const
{
return
!
storage_
|
|
storage_
-
>
isEmpty
(
)
;
}
private
:
GenericBuffer
(
const
GenericBuffer
&
other
)
=
delete
;
GenericBuffer
&
operator
=
(
const
GenericBuffer
&
other
)
=
delete
;
}
;
template
<
typename
Edge
>
struct
PointerEdgeHasher
{
using
Lookup
=
Edge
;
static
HashNumber
hash
(
const
Lookup
&
l
)
{
return
mozilla
:
:
HashGeneric
(
l
.
edge
)
;
}
static
bool
match
(
const
Edge
&
k
const
Lookup
&
l
)
{
return
k
=
=
l
;
}
}
;
template
<
typename
T
>
struct
CellPtrEdge
{
T
*
*
edge
=
nullptr
;
CellPtrEdge
(
)
=
default
;
explicit
CellPtrEdge
(
T
*
*
v
)
:
edge
(
v
)
{
}
bool
operator
=
=
(
const
CellPtrEdge
&
other
)
const
{
return
edge
=
=
other
.
edge
;
}
bool
operator
!
=
(
const
CellPtrEdge
&
other
)
const
{
return
edge
!
=
other
.
edge
;
}
bool
maybeInRememberedSet
(
const
Nursery
&
nursery
)
const
{
MOZ_ASSERT
(
IsInsideNursery
(
*
edge
)
)
;
return
!
nursery
.
isInside
(
edge
)
;
}
void
trace
(
TenuringTracer
&
mover
)
const
;
explicit
operator
bool
(
)
const
{
return
edge
!
=
nullptr
;
}
using
Hasher
=
PointerEdgeHasher
<
CellPtrEdge
<
T
>
>
;
}
;
using
ObjectPtrEdge
=
CellPtrEdge
<
JSObject
>
;
using
StringPtrEdge
=
CellPtrEdge
<
JSString
>
;
using
BigIntPtrEdge
=
CellPtrEdge
<
JS
:
:
BigInt
>
;
struct
ValueEdge
{
JS
:
:
Value
*
edge
;
ValueEdge
(
)
:
edge
(
nullptr
)
{
}
explicit
ValueEdge
(
JS
:
:
Value
*
v
)
:
edge
(
v
)
{
}
bool
operator
=
=
(
const
ValueEdge
&
other
)
const
{
return
edge
=
=
other
.
edge
;
}
bool
operator
!
=
(
const
ValueEdge
&
other
)
const
{
return
edge
!
=
other
.
edge
;
}
Cell
*
deref
(
)
const
{
return
edge
-
>
isGCThing
(
)
?
static_cast
<
Cell
*
>
(
edge
-
>
toGCThing
(
)
)
:
nullptr
;
}
bool
maybeInRememberedSet
(
const
Nursery
&
nursery
)
const
{
MOZ_ASSERT
(
IsInsideNursery
(
deref
(
)
)
)
;
return
!
nursery
.
isInside
(
edge
)
;
}
void
trace
(
TenuringTracer
&
mover
)
const
;
explicit
operator
bool
(
)
const
{
return
edge
!
=
nullptr
;
}
using
Hasher
=
PointerEdgeHasher
<
ValueEdge
>
;
}
;
struct
SlotsEdge
{
const
static
int
SlotKind
=
0
;
const
static
int
ElementKind
=
1
;
uintptr_t
objectAndKind_
;
uint32_t
start_
;
uint32_t
count_
;
SlotsEdge
(
)
:
objectAndKind_
(
0
)
start_
(
0
)
count_
(
0
)
{
}
SlotsEdge
(
NativeObject
*
object
int
kind
uint32_t
start
uint32_t
count
)
:
objectAndKind_
(
uintptr_t
(
object
)
|
kind
)
start_
(
start
)
count_
(
count
)
{
MOZ_ASSERT
(
(
uintptr_t
(
object
)
&
1
)
=
=
0
)
;
MOZ_ASSERT
(
kind
<
=
1
)
;
MOZ_ASSERT
(
count
>
0
)
;
MOZ_ASSERT
(
start
+
count
>
start
)
;
}
NativeObject
*
object
(
)
const
{
return
reinterpret_cast
<
NativeObject
*
>
(
objectAndKind_
&
~
1
)
;
}
int
kind
(
)
const
{
return
(
int
)
(
objectAndKind_
&
1
)
;
}
bool
operator
=
=
(
const
SlotsEdge
&
other
)
const
{
return
objectAndKind_
=
=
other
.
objectAndKind_
&
&
start_
=
=
other
.
start_
&
&
count_
=
=
other
.
count_
;
}
bool
operator
!
=
(
const
SlotsEdge
&
other
)
const
{
return
!
(
*
this
=
=
other
)
;
}
bool
overlaps
(
const
SlotsEdge
&
other
)
const
{
if
(
objectAndKind_
!
=
other
.
objectAndKind_
)
{
return
false
;
}
uint32_t
end
=
start_
+
count_
+
1
;
uint32_t
start
=
start_
>
0
?
start_
-
1
:
0
;
MOZ_ASSERT
(
start
<
end
)
;
uint32_t
otherEnd
=
other
.
start_
+
other
.
count_
;
MOZ_ASSERT
(
other
.
start_
<
=
otherEnd
)
;
return
(
start
<
=
other
.
start_
&
&
other
.
start_
<
=
end
)
|
|
(
start
<
=
otherEnd
&
&
otherEnd
<
=
end
)
;
}
void
merge
(
const
SlotsEdge
&
other
)
{
MOZ_ASSERT
(
overlaps
(
other
)
)
;
uint32_t
end
=
std
:
:
max
(
start_
+
count_
other
.
start_
+
other
.
count_
)
;
start_
=
std
:
:
min
(
start_
other
.
start_
)
;
count_
=
end
-
start_
;
}
bool
maybeInRememberedSet
(
const
Nursery
&
n
)
const
{
return
!
IsInsideNursery
(
reinterpret_cast
<
Cell
*
>
(
object
(
)
)
)
;
}
void
trace
(
TenuringTracer
&
mover
)
const
;
explicit
operator
bool
(
)
const
{
return
objectAndKind_
!
=
0
;
}
typedef
struct
Hasher
{
using
Lookup
=
SlotsEdge
;
static
HashNumber
hash
(
const
Lookup
&
l
)
{
return
mozilla
:
:
HashGeneric
(
l
.
objectAndKind_
l
.
start_
l
.
count_
)
;
}
static
bool
match
(
const
SlotsEdge
&
k
const
Lookup
&
l
)
{
return
k
=
=
l
;
}
}
Hasher
;
}
;
#
ifdef
DEBUG
void
checkAccess
(
)
const
;
#
else
void
checkAccess
(
)
const
{
}
#
endif
template
<
typename
Buffer
typename
Edge
>
void
unput
(
Buffer
&
buffer
const
Edge
&
edge
)
{
checkAccess
(
)
;
if
(
!
isEnabled
(
)
)
{
return
;
}
mozilla
:
:
ReentrancyGuard
g
(
*
this
)
;
buffer
.
unput
(
edge
)
;
}
template
<
typename
Buffer
typename
Edge
>
void
put
(
Buffer
&
buffer
const
Edge
&
edge
)
{
checkAccess
(
)
;
if
(
!
isEnabled
(
)
)
{
return
;
}
mozilla
:
:
ReentrancyGuard
g
(
*
this
)
;
if
(
edge
.
maybeInRememberedSet
(
nursery_
)
)
{
buffer
.
put
(
edge
)
;
}
}
Mutex
lock_
MOZ_UNANNOTATED
;
MonoTypeBuffer
<
ValueEdge
>
bufferVal
;
MonoTypeBuffer
<
StringPtrEdge
>
bufStrCell
;
MonoTypeBuffer
<
BigIntPtrEdge
>
bufBigIntCell
;
MonoTypeBuffer
<
ObjectPtrEdge
>
bufObjCell
;
MonoTypeBuffer
<
SlotsEdge
>
bufferSlot
;
WholeCellBuffer
bufferWholeCell
;
GenericBuffer
bufferGeneric
;
JSRuntime
*
runtime_
;
Nursery
&
nursery_
;
bool
aboutToOverflow_
;
bool
enabled_
;
bool
mayHavePointersToDeadCells_
;
#
ifdef
DEBUG
bool
mEntered
;
#
endif
public
:
#
ifdef
DEBUG
bool
markingNondeduplicatable
;
#
endif
explicit
StoreBuffer
(
JSRuntime
*
rt
Nursery
&
nursery
)
;
[
[
nodiscard
]
]
bool
enable
(
)
;
void
disable
(
)
;
bool
isEnabled
(
)
const
{
return
enabled_
;
}
bool
isEmpty
(
)
const
;
void
clear
(
)
;
const
Nursery
&
nursery
(
)
const
{
return
nursery_
;
}
bool
isAboutToOverflow
(
)
const
{
return
aboutToOverflow_
;
}
bool
mayHavePointersToDeadCells
(
)
const
{
return
mayHavePointersToDeadCells_
;
}
void
putValue
(
JS
:
:
Value
*
vp
)
{
put
(
bufferVal
ValueEdge
(
vp
)
)
;
}
void
unputValue
(
JS
:
:
Value
*
vp
)
{
unput
(
bufferVal
ValueEdge
(
vp
)
)
;
}
void
putCell
(
JSString
*
*
strp
)
{
put
(
bufStrCell
StringPtrEdge
(
strp
)
)
;
}
void
unputCell
(
JSString
*
*
strp
)
{
unput
(
bufStrCell
StringPtrEdge
(
strp
)
)
;
}
void
putCell
(
JS
:
:
BigInt
*
*
bip
)
{
put
(
bufBigIntCell
BigIntPtrEdge
(
bip
)
)
;
}
void
unputCell
(
JS
:
:
BigInt
*
*
bip
)
{
unput
(
bufBigIntCell
BigIntPtrEdge
(
bip
)
)
;
}
void
putCell
(
JSObject
*
*
strp
)
{
put
(
bufObjCell
ObjectPtrEdge
(
strp
)
)
;
}
void
unputCell
(
JSObject
*
*
strp
)
{
unput
(
bufObjCell
ObjectPtrEdge
(
strp
)
)
;
}
void
putSlot
(
NativeObject
*
obj
int
kind
uint32_t
start
uint32_t
count
)
{
SlotsEdge
edge
(
obj
kind
start
count
)
;
if
(
bufferSlot
.
last_
.
overlaps
(
edge
)
)
{
bufferSlot
.
last_
.
merge
(
edge
)
;
}
else
{
put
(
bufferSlot
edge
)
;
}
}
inline
void
putWholeCell
(
Cell
*
cell
)
;
inline
void
putWholeCellDontCheckLast
(
Cell
*
cell
)
;
const
void
*
addressOfLastBufferedWholeCell
(
)
{
return
bufferWholeCell
.
lastBufferedPtr
(
)
;
}
template
<
typename
T
>
void
putGeneric
(
const
T
&
t
)
{
put
(
bufferGeneric
t
)
;
}
void
setMayHavePointersToDeadCells
(
)
{
mayHavePointersToDeadCells_
=
true
;
}
void
traceValues
(
TenuringTracer
&
mover
)
{
bufferVal
.
trace
(
mover
)
;
}
void
traceCells
(
TenuringTracer
&
mover
)
{
bufStrCell
.
trace
(
mover
)
;
bufBigIntCell
.
trace
(
mover
)
;
bufObjCell
.
trace
(
mover
)
;
}
void
traceSlots
(
TenuringTracer
&
mover
)
{
bufferSlot
.
trace
(
mover
)
;
}
void
traceWholeCells
(
TenuringTracer
&
mover
)
{
bufferWholeCell
.
trace
(
mover
)
;
}
void
traceGenericEntries
(
JSTracer
*
trc
)
{
bufferGeneric
.
trace
(
trc
)
;
}
void
setAboutToOverflow
(
JS
:
:
GCReason
)
;
void
addSizeOfExcludingThis
(
mozilla
:
:
MallocSizeOf
mallocSizeOf
JS
:
:
GCSizes
*
sizes
)
;
void
checkEmpty
(
)
const
;
void
lock
(
)
{
lock_
.
lock
(
)
;
}
void
unlock
(
)
{
lock_
.
unlock
(
)
;
}
}
;
class
ArenaCellSet
{
friend
class
StoreBuffer
;
using
ArenaCellBits
=
BitArray
<
MaxArenaCellIndex
>
;
Arena
*
arena
;
ArenaCellSet
*
next
;
ArenaCellBits
bits
;
#
ifdef
DEBUG
const
uint64_t
minorGCNumberAtCreation
;
#
endif
constexpr
ArenaCellSet
(
)
:
arena
(
nullptr
)
next
(
nullptr
)
#
ifdef
DEBUG
minorGCNumberAtCreation
(
0
)
#
endif
{
}
public
:
using
WordT
=
ArenaCellBits
:
:
WordT
;
const
size_t
BitsPerWord
=
ArenaCellBits
:
:
bitsPerElement
;
const
size_t
NumWords
=
ArenaCellBits
:
:
numSlots
;
ArenaCellSet
(
Arena
*
arena
ArenaCellSet
*
next
)
;
bool
hasCell
(
const
TenuredCell
*
cell
)
const
{
return
hasCell
(
getCellIndex
(
cell
)
)
;
}
void
putCell
(
const
TenuredCell
*
cell
)
{
putCell
(
getCellIndex
(
cell
)
)
;
}
bool
isEmpty
(
)
const
{
return
this
=
=
&
Empty
;
}
bool
hasCell
(
size_t
cellIndex
)
const
;
void
putCell
(
size_t
cellIndex
)
;
void
check
(
)
const
;
WordT
getWord
(
size_t
wordIndex
)
const
{
return
bits
.
getWord
(
wordIndex
)
;
}
void
trace
(
TenuringTracer
&
mover
)
;
static
ArenaCellSet
Empty
;
static
size_t
getCellIndex
(
const
TenuredCell
*
cell
)
;
static
void
getWordIndexAndMask
(
size_t
cellIndex
size_t
*
wordp
uint32_t
*
maskp
)
;
static
const
size_t
NurseryFreeThresholdBytes
=
64
*
1024
;
static
size_t
offsetOfArena
(
)
{
return
offsetof
(
ArenaCellSet
arena
)
;
}
static
size_t
offsetOfBits
(
)
{
return
offsetof
(
ArenaCellSet
bits
)
;
}
}
;
template
<
typename
T
>
MOZ_ALWAYS_INLINE
void
PostWriteBarrierImpl
(
void
*
cellp
T
*
prev
T
*
next
)
{
MOZ_ASSERT
(
cellp
)
;
StoreBuffer
*
buffer
;
if
(
next
&
&
(
buffer
=
next
-
>
storeBuffer
(
)
)
)
{
if
(
prev
&
&
prev
-
>
storeBuffer
(
)
)
{
return
;
}
buffer
-
>
putCell
(
static_cast
<
T
*
*
>
(
cellp
)
)
;
return
;
}
if
(
prev
&
&
(
buffer
=
prev
-
>
storeBuffer
(
)
)
)
{
buffer
-
>
unputCell
(
static_cast
<
T
*
*
>
(
cellp
)
)
;
}
}
template
<
typename
T
>
MOZ_ALWAYS_INLINE
void
PostWriteBarrier
(
T
*
*
vp
T
*
prev
T
*
next
)
{
static_assert
(
std
:
:
is_base_of_v
<
Cell
T
>
)
;
static_assert
(
!
std
:
:
is_same_v
<
Cell
T
>
&
&
!
std
:
:
is_same_v
<
TenuredCell
T
>
)
;
if
constexpr
(
!
GCTypeIsTenured
<
T
>
(
)
)
{
using
BaseT
=
typename
BaseGCType
<
T
>
:
:
type
;
PostWriteBarrierImpl
<
BaseT
>
(
vp
prev
next
)
;
return
;
}
MOZ_ASSERT_IF
(
next
!
IsInsideNursery
(
next
)
)
;
}
void
PostWriteBarrierCell
(
Cell
*
cell
Cell
*
prev
Cell
*
next
)
;
}
}
#
endif
