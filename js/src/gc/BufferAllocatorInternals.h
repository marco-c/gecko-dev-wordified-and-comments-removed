#
ifndef
gc_BufferAllocatorInternals_h
#
define
gc_BufferAllocatorInternals_h
#
include
"
ds
/
SlimLinkedList
.
h
"
#
include
"
gc
/
BufferAllocator
.
h
"
#
include
"
gc
/
IteratorUtils
.
h
"
namespace
js
:
:
gc
{
static
constexpr
size_t
MinFreeRegionSize
=
1
<
<
BufferAllocator
:
:
MinSizeClassShift
;
static
constexpr
size_t
SmallRegionShift
=
14
;
static
constexpr
size_t
SmallRegionSize
=
1
<
<
SmallRegionShift
;
static
constexpr
uintptr_t
SmallRegionMask
=
SmallRegionSize
-
1
;
static_assert
(
SmallRegionSize
>
=
MinMediumAllocSize
)
;
static_assert
(
SmallRegionSize
<
=
MaxMediumAllocSize
)
;
static
constexpr
size_t
MinSmallAllocClass
=
0
;
static
constexpr
size_t
MaxSmallAllocClass
=
BufferAllocator
:
:
SmallSizeClasses
-
1
;
static
constexpr
size_t
MinMediumAllocClass
=
MaxSmallAllocClass
+
1
;
static
constexpr
size_t
MaxMediumAllocClass
=
MinMediumAllocClass
+
BufferAllocator
:
:
MediumSizeClasses
-
1
;
static_assert
(
MaxMediumAllocClass
=
=
BufferAllocator
:
:
AllocSizeClasses
-
1
)
;
#
ifdef
DEBUG
static
constexpr
uint32_t
LargeBufferCheckValue
=
0xBFA110C2
;
static
constexpr
uint32_t
FreeRegionCheckValue
=
0xBFA110C3
;
#
endif
template
<
size_t
N
typename
Word
=
size_t
>
class
BitSetIter
{
using
BitSet
=
mozilla
:
:
BitSet
<
N
Word
>
;
const
BitSet
&
bitset
;
size_t
bit
=
0
;
public
:
explicit
BitSetIter
(
const
BitSet
&
bitset
)
:
bitset
(
bitset
)
{
MOZ_ASSERT
(
!
done
(
)
)
;
if
(
!
bitset
[
bit
]
)
{
next
(
)
;
}
}
bool
done
(
)
const
{
MOZ_ASSERT
(
bit
<
=
N
|
|
bit
=
=
SIZE_MAX
)
;
return
bit
>
=
N
;
}
void
next
(
)
{
MOZ_ASSERT
(
!
done
(
)
)
;
bit
+
+
;
if
(
bit
!
=
N
)
{
bit
=
bitset
.
FindNext
(
bit
)
;
}
}
size_t
get
(
)
const
{
MOZ_ASSERT
(
!
done
(
)
)
;
return
bit
;
}
operator
size_t
(
)
const
{
return
get
(
)
;
}
}
;
template
<
size_t
N
>
class
js
:
:
gc
:
:
AtomicBitmap
<
N
>
:
:
Iter
{
const
AtomicBitmap
&
bitmap
;
size_t
bit
=
0
;
public
:
explicit
Iter
(
AtomicBitmap
&
bitmap
)
:
bitmap
(
bitmap
)
{
if
(
!
bitmap
.
getBit
(
bit
)
)
{
next
(
)
;
}
}
bool
done
(
)
const
{
MOZ_ASSERT
(
bit
<
=
N
)
;
return
bit
=
=
N
;
}
void
next
(
)
{
MOZ_ASSERT
(
!
done
(
)
)
;
bit
+
+
;
if
(
bit
=
=
N
)
{
return
;
}
static
constexpr
size_t
bitsPerWord
=
sizeof
(
Word
)
*
CHAR_BIT
;
size_t
wordIndex
=
bit
/
bitsPerWord
;
size_t
bitIndex
=
bit
%
bitsPerWord
;
uintptr_t
word
=
bitmap
.
getWord
(
wordIndex
)
;
word
&
=
(
uintptr_t
(
-
1
)
<
<
bitIndex
)
;
while
(
word
=
=
0
)
{
wordIndex
+
+
;
if
(
wordIndex
=
=
WordCount
)
{
bit
=
N
;
return
;
}
word
=
bitmap
.
getWord
(
wordIndex
)
;
}
bitIndex
=
mozilla
:
:
CountTrailingZeroes
(
word
)
;
bit
=
wordIndex
*
bitsPerWord
+
bitIndex
;
}
size_t
get
(
)
const
{
MOZ_ASSERT
(
!
done
(
)
)
;
return
bit
;
}
}
;
template
<
typename
BitmapIter
size_t
Granularity
typename
T
=
void
>
class
BitmapToBlockIter
:
public
BitmapIter
{
uintptr_t
baseAddr
;
public
:
template
<
typename
S
>
BitmapToBlockIter
(
void
*
base
S
&
&
arg
)
:
BitmapIter
(
std
:
:
forward
<
S
>
(
arg
)
)
baseAddr
(
uintptr_t
(
base
)
)
{
}
size_t
getOffset
(
)
const
{
return
BitmapIter
:
:
get
(
)
*
Granularity
;
}
T
*
get
(
)
const
{
return
reinterpret_cast
<
T
*
>
(
baseAddr
+
getOffset
(
)
)
;
}
operator
T
*
(
)
const
{
return
get
(
)
;
}
T
*
operator
-
>
(
)
const
{
return
get
(
)
;
}
}
;
template
<
typename
T
>
class
LinkedListIter
{
T
*
element
;
public
:
explicit
LinkedListIter
(
SlimLinkedList
<
T
>
&
list
)
:
element
(
list
.
getFirst
(
)
)
{
}
bool
done
(
)
const
{
return
!
element
;
}
void
next
(
)
{
MOZ_ASSERT
(
!
done
(
)
)
;
element
=
element
-
>
getNext
(
)
;
}
T
*
get
(
)
const
{
return
element
;
}
operator
T
*
(
)
const
{
return
get
(
)
;
}
T
*
operator
-
>
(
)
const
{
return
get
(
)
;
}
}
;
class
BufferAllocator
:
:
FreeLists
:
:
FreeListIter
:
public
BitSetIter
<
AllocSizeClasses
uint32_t
>
{
FreeLists
&
freeLists
;
public
:
explicit
FreeListIter
(
FreeLists
&
freeLists
)
:
BitSetIter
(
freeLists
.
available
)
freeLists
(
freeLists
)
{
}
FreeList
&
get
(
)
{
size_t
sizeClass
=
BitSetIter
:
:
get
(
)
;
return
freeLists
.
lists
[
sizeClass
]
;
}
operator
FreeList
&
(
)
{
return
get
(
)
;
}
}
;
class
BufferAllocator
:
:
FreeLists
:
:
FreeRegionIter
:
public
NestedIterator
<
FreeListIter
LinkedListIter
<
FreeRegion
>
>
{
public
:
explicit
FreeRegionIter
(
FreeLists
&
freeLists
)
:
NestedIterator
(
freeLists
)
{
}
}
;
class
BufferAllocator
:
:
ChunkLists
:
:
ChunkListIter
:
public
BitSetIter
<
AllocSizeClasses
+
1
uint32_t
>
{
ChunkLists
&
chunkLists
;
public
:
explicit
ChunkListIter
(
ChunkLists
&
chunkLists
)
:
BitSetIter
(
chunkLists
.
available
)
chunkLists
(
chunkLists
)
{
}
BufferChunkList
&
get
(
)
{
return
chunkLists
.
lists
[
getSizeClass
(
)
]
;
}
size_t
getSizeClass
(
)
const
{
return
BitSetIter
:
:
get
(
)
;
}
operator
BufferChunkList
&
(
)
{
return
get
(
)
;
}
}
;
class
BufferAllocator
:
:
ChunkLists
:
:
ChunkIter
:
public
NestedIterator
<
ChunkListIter
LinkedListIter
<
BufferChunk
>
>
{
public
:
explicit
ChunkIter
(
ChunkLists
&
chunkLists
)
:
NestedIterator
(
chunkLists
)
{
}
size_t
getSizeClass
(
)
const
{
return
iterA
(
)
.
getSizeClass
(
)
;
}
}
;
struct
BufferChunk
:
public
ChunkBase
public
SlimLinkedListElement
<
BufferChunk
>
{
#
ifdef
DEBUG
MainThreadOrGCTaskData
<
Zone
*
>
zone
;
#
endif
MainThreadOrGCTaskData
<
bool
>
allocatedDuringCollection
;
MainThreadData
<
bool
>
hasNurseryOwnedAllocs
;
MainThreadOrGCTaskData
<
bool
>
hasNurseryOwnedAllocsAfterSweep
;
static
constexpr
size_t
MaxAllocsPerChunk
=
ChunkSize
/
MediumAllocGranularity
;
MainThreadOrGCTaskData
<
AtomicBitmap
<
MaxAllocsPerChunk
>
>
markBits
;
using
PerAllocBitmap
=
mozilla
:
:
BitSet
<
MaxAllocsPerChunk
>
;
using
AtomicPerAllocBitmap
=
mozilla
:
:
BitSet
<
MaxAllocsPerChunk
mozilla
:
:
Atomic
<
size_t
mozilla
:
:
Relaxed
>
>
;
MainThreadOrGCTaskData
<
PerAllocBitmap
>
allocStartBitmap
;
MainThreadOrGCTaskData
<
AtomicPerAllocBitmap
>
allocEndBitmap
;
MainThreadOrGCTaskData
<
PerAllocBitmap
>
nurseryOwnedBitmap
;
static
constexpr
size_t
PagesPerChunk
=
ChunkSize
/
PageSize
;
using
PerPageBitmap
=
mozilla
:
:
BitSet
<
PagesPerChunk
uint32_t
>
;
MainThreadOrGCTaskData
<
PerPageBitmap
>
decommittedPages
;
static
constexpr
size_t
SmallRegionsPerChunk
=
ChunkSize
/
SmallRegionSize
;
using
SmallRegionBitmap
=
AtomicBitmap
<
SmallRegionsPerChunk
>
;
MainThreadOrGCTaskData
<
SmallRegionBitmap
>
smallRegionBitmap
;
MainThreadOrGCTaskData
<
BufferAllocator
:
:
FreeLists
>
freeLists
;
MainThreadOrGCTaskData
<
bool
>
ownsFreeLists
;
using
AllocIter
=
BitmapToBlockIter
<
BitSetIter
<
MaxAllocsPerChunk
>
MediumAllocGranularity
>
;
AllocIter
allocIter
(
)
{
return
{
this
allocStartBitmap
.
ref
(
)
}
;
}
using
SmallRegionIter
=
BitmapToBlockIter
<
SmallRegionBitmap
:
:
Iter
SmallRegionSize
SmallBufferRegion
>
;
SmallRegionIter
smallRegionIter
(
)
{
return
{
this
smallRegionBitmap
.
ref
(
)
}
;
}
static
const
BufferChunk
*
from
(
const
void
*
alloc
)
{
return
from
(
const_cast
<
void
*
>
(
alloc
)
)
;
}
static
BufferChunk
*
from
(
void
*
alloc
)
{
ChunkBase
*
chunk
=
js
:
:
gc
:
:
detail
:
:
GetGCAddressChunkBase
(
alloc
)
;
MOZ_ASSERT
(
chunk
-
>
kind
=
=
ChunkKind
:
:
Buffers
)
;
return
static_cast
<
BufferChunk
*
>
(
chunk
)
;
}
explicit
BufferChunk
(
Zone
*
zone
)
;
~
BufferChunk
(
)
;
void
setAllocated
(
void
*
alloc
size_t
bytes
bool
allocated
)
;
bool
isAllocated
(
const
void
*
alloc
)
const
;
bool
isAllocated
(
uintptr_t
offset
)
const
;
void
updateEndOffset
(
void
*
alloc
size_t
oldBytes
size_t
newBytes
)
;
void
setNurseryOwned
(
void
*
alloc
bool
nurseryOwned
)
;
bool
isNurseryOwned
(
const
void
*
alloc
)
const
;
void
setSmallBufferRegion
(
void
*
alloc
bool
smallAlloc
)
;
bool
isSmallBufferRegion
(
const
void
*
alloc
)
const
;
size_t
allocBytes
(
const
void
*
alloc
)
const
;
bool
setMarked
(
void
*
alloc
)
;
void
setUnmarked
(
void
*
alloc
)
;
bool
isMarked
(
const
void
*
alloc
)
const
;
size_t
findNextAllocated
(
uintptr_t
offset
)
const
;
size_t
findPrevAllocated
(
uintptr_t
offset
)
const
;
using
FreeRegion
=
BufferAllocator
:
:
FreeRegion
;
FreeRegion
*
findFollowingFreeRegion
(
uintptr_t
startAddr
)
;
FreeRegion
*
findPrecedingFreeRegion
(
uintptr_t
endAddr
)
;
size_t
sizeClassForAvailableLists
(
)
const
;
bool
isPointerWithinAllocation
(
void
*
ptr
)
const
;
private
:
template
<
size_t
Divisor
=
MinMediumAllocSize
size_t
Align
=
Divisor
>
size_t
ptrToIndex
(
const
void
*
alloc
)
const
{
MOZ_ASSERT
(
(
uintptr_t
(
alloc
)
&
~
ChunkMask
)
=
=
uintptr_t
(
this
)
)
;
uintptr_t
offset
=
uintptr_t
(
alloc
)
&
ChunkMask
;
return
offsetToIndex
<
Divisor
Align
>
(
offset
)
;
}
template
<
size_t
Divisor
=
MinMediumAllocSize
size_t
Align
=
Divisor
>
static
size_t
offsetToIndex
(
uintptr_t
offset
)
{
MOZ_ASSERT
(
isValidOffset
(
offset
)
)
;
MOZ_ASSERT
(
offset
%
Align
=
=
0
)
;
return
offset
/
Divisor
;
}
const
void
*
ptrFromOffset
(
uintptr_t
offset
)
const
{
MOZ_ASSERT
(
isValidOffset
(
offset
)
)
;
MOZ_ASSERT
(
offset
%
MediumAllocGranularity
=
=
0
)
;
return
reinterpret_cast
<
void
*
>
(
uintptr_t
(
this
)
+
offset
)
;
}
size_t
findEndBit
(
size_t
startIndex
)
const
{
MOZ_ASSERT
(
startIndex
<
MaxAllocsPerChunk
)
;
if
(
startIndex
+
1
=
=
MaxAllocsPerChunk
)
{
return
MaxAllocsPerChunk
;
}
size_t
endIndex
=
allocEndBitmap
.
ref
(
)
.
FindNext
(
startIndex
+
1
)
;
if
(
endIndex
=
=
SIZE_MAX
)
{
return
MaxAllocsPerChunk
;
}
return
endIndex
;
}
#
ifdef
DEBUG
static
bool
isValidOffset
(
uintptr_t
offset
)
;
#
endif
}
;
constexpr
size_t
FirstMediumAllocOffset
=
RoundUp
(
sizeof
(
BufferChunk
)
MediumAllocGranularity
)
;
static_assert
(
FirstMediumAllocOffset
+
MaxMediumAllocSize
<
=
ChunkSize
)
;
#
ifdef
DEBUG
inline
bool
BufferChunk
:
:
isValidOffset
(
uintptr_t
offset
)
{
return
offset
>
=
FirstMediumAllocOffset
&
&
offset
<
ChunkSize
;
}
#
endif
struct
SmallBufferRegion
{
static
constexpr
size_t
MaxAllocsPerRegion
=
SmallRegionSize
/
SmallAllocGranularity
;
MainThreadOrGCTaskData
<
AtomicBitmap
<
MaxAllocsPerRegion
>
>
markBits
;
using
PerAllocBitmap
=
mozilla
:
:
BitSet
<
MaxAllocsPerRegion
>
;
using
AtomicPerAllocBitmap
=
mozilla
:
:
BitSet
<
MaxAllocsPerRegion
mozilla
:
:
Atomic
<
size_t
mozilla
:
:
Relaxed
>
>
;
MainThreadOrGCTaskData
<
PerAllocBitmap
>
allocStartBitmap
;
MainThreadOrGCTaskData
<
AtomicPerAllocBitmap
>
allocEndBitmap
;
MainThreadOrGCTaskData
<
PerAllocBitmap
>
nurseryOwnedBitmap
;
MainThreadOrGCTaskData
<
bool
>
hasNurseryOwnedAllocs_
;
using
AllocIter
=
BitmapToBlockIter
<
BitSetIter
<
MaxAllocsPerRegion
>
SmallAllocGranularity
>
;
AllocIter
allocIter
(
)
{
return
{
this
allocStartBitmap
.
ref
(
)
}
;
}
static
SmallBufferRegion
*
from
(
void
*
alloc
)
{
uintptr_t
addr
=
uintptr_t
(
alloc
)
&
~
SmallRegionMask
;
auto
*
region
=
reinterpret_cast
<
SmallBufferRegion
*
>
(
addr
)
;
#
ifdef
DEBUG
BufferChunk
*
chunk
=
BufferChunk
:
:
from
(
region
)
;
MOZ_ASSERT
(
chunk
-
>
isAllocated
(
region
)
)
;
MOZ_ASSERT
(
chunk
-
>
isSmallBufferRegion
(
region
)
)
;
#
endif
return
region
;
}
SmallBufferRegion
(
)
;
const
void
*
ptrFromOffset
(
uintptr_t
offset
)
const
;
void
setAllocated
(
void
*
alloc
size_t
bytes
bool
allocated
)
;
bool
isAllocated
(
const
void
*
alloc
)
const
;
bool
isAllocated
(
uintptr_t
offset
)
const
;
void
setNurseryOwned
(
void
*
alloc
bool
nurseryOwned
)
;
bool
isNurseryOwned
(
const
void
*
alloc
)
const
;
void
setHasNurseryOwnedAllocs
(
bool
value
)
;
bool
hasNurseryOwnedAllocs
(
)
const
;
size_t
allocBytes
(
const
void
*
alloc
)
const
;
bool
setMarked
(
void
*
alloc
)
;
void
setUnmarked
(
void
*
alloc
)
;
bool
isMarked
(
const
void
*
alloc
)
const
;
size_t
findNextAllocated
(
uintptr_t
offset
)
const
;
size_t
findPrevAllocated
(
uintptr_t
offset
)
const
;
bool
isPointerWithinAllocation
(
void
*
ptr
)
const
;
private
:
size_t
ptrToIndex
(
const
void
*
alloc
)
const
;
size_t
offsetToIndex
(
uintptr_t
offset
)
const
;
size_t
findEndBit
(
size_t
startIndex
)
const
{
MOZ_ASSERT
(
startIndex
<
MaxAllocsPerRegion
)
;
if
(
startIndex
+
1
=
=
MaxAllocsPerRegion
)
{
return
MaxAllocsPerRegion
;
}
size_t
endIndex
=
allocEndBitmap
.
ref
(
)
.
FindNext
(
startIndex
+
1
)
;
if
(
endIndex
=
=
SIZE_MAX
)
{
return
MaxAllocsPerRegion
;
}
return
endIndex
;
}
}
;
static
constexpr
size_t
FirstSmallAllocOffset
=
RoundUp
(
sizeof
(
SmallBufferRegion
)
SmallAllocGranularity
)
;
static_assert
(
FirstSmallAllocOffset
<
SmallRegionSize
)
;
struct
BufferAllocator
:
:
FreeRegion
:
public
SlimLinkedListElement
<
BufferAllocator
:
:
FreeRegion
>
{
uintptr_t
startAddr
;
bool
hasDecommittedPages
;
#
ifdef
DEBUG
uint32_t
checkValue
=
FreeRegionCheckValue
;
#
endif
explicit
FreeRegion
(
uintptr_t
startAddr
bool
decommitted
=
false
)
:
startAddr
(
startAddr
)
hasDecommittedPages
(
decommitted
)
{
}
static
FreeRegion
*
fromEndOffset
(
BufferChunk
*
chunk
uintptr_t
endOffset
)
{
MOZ_ASSERT
(
endOffset
<
=
ChunkSize
)
;
return
fromEndAddr
(
uintptr_t
(
chunk
)
+
endOffset
)
;
}
static
FreeRegion
*
fromEndOffset
(
SmallBufferRegion
*
region
uintptr_t
endOffset
)
{
MOZ_ASSERT
(
endOffset
<
=
SmallRegionSize
)
;
return
fromEndAddr
(
uintptr_t
(
region
)
+
endOffset
)
;
}
static
FreeRegion
*
fromEndAddr
(
uintptr_t
endAddr
)
{
MOZ_ASSERT
(
endAddr
%
SmallAllocGranularity
=
=
0
)
;
auto
*
region
=
reinterpret_cast
<
FreeRegion
*
>
(
endAddr
-
sizeof
(
FreeRegion
)
)
;
region
-
>
check
(
)
;
return
region
;
}
void
check
(
)
const
{
MOZ_ASSERT
(
checkValue
=
=
FreeRegionCheckValue
)
;
}
uintptr_t
getEnd
(
)
const
{
return
uintptr_t
(
this
+
1
)
;
}
size_t
size
(
)
const
{
return
getEnd
(
)
-
startAddr
;
}
}
;
struct
LargeBuffer
:
public
SlimLinkedListElement
<
LargeBuffer
>
{
void
*
alloc
;
size_t
bytes
;
bool
isNurseryOwned
;
bool
allocatedDuringCollection
=
false
;
#
ifdef
DEBUG
uint32_t
checkValue
=
LargeBufferCheckValue
;
#
endif
LargeBuffer
(
void
*
alloc
size_t
bytes
bool
nurseryOwned
)
:
alloc
(
alloc
)
bytes
(
bytes
)
isNurseryOwned
(
nurseryOwned
)
{
MOZ_ASSERT
(
(
bytes
%
ChunkSize
)
=
=
0
)
;
}
void
check
(
)
const
{
MOZ_ASSERT
(
checkValue
=
=
LargeBufferCheckValue
)
;
}
#
ifdef
DEBUG
inline
Zone
*
zone
(
)
;
inline
Zone
*
zoneFromAnyThread
(
)
;
#
endif
void
*
data
(
)
{
return
alloc
;
}
size_t
allocBytes
(
)
const
{
return
bytes
;
}
bool
isPointerWithinAllocation
(
void
*
ptr
)
const
;
}
;
}
#
endif
