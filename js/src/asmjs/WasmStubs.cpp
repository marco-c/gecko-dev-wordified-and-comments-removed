#
include
"
asmjs
/
WasmStubs
.
h
"
#
include
"
mozilla
/
ArrayUtils
.
h
"
#
include
"
jit
/
MacroAssembler
-
inl
.
h
"
using
namespace
js
;
using
namespace
js
:
:
jit
;
using
namespace
js
:
:
wasm
;
using
mozilla
:
:
ArrayLength
;
static
void
AssertStackAlignment
(
MacroAssembler
&
masm
uint32_t
alignment
uint32_t
addBeforeAssert
=
0
)
{
MOZ_ASSERT
(
(
sizeof
(
AsmJSFrame
)
+
masm
.
framePushed
(
)
+
addBeforeAssert
)
%
alignment
=
=
0
)
;
masm
.
assertStackAlignment
(
alignment
addBeforeAssert
)
;
}
static
unsigned
StackDecrementForCall
(
MacroAssembler
&
masm
uint32_t
alignment
unsigned
bytesToPush
)
{
return
StackDecrementForCall
(
alignment
sizeof
(
AsmJSFrame
)
+
masm
.
framePushed
(
)
bytesToPush
)
;
}
template
<
class
VectorT
>
static
unsigned
StackArgBytes
(
const
VectorT
&
args
)
{
ABIArgIter
<
VectorT
>
iter
(
args
)
;
while
(
!
iter
.
done
(
)
)
iter
+
+
;
return
iter
.
stackBytesConsumedSoFar
(
)
;
}
template
<
class
VectorT
>
static
unsigned
StackDecrementForCall
(
MacroAssembler
&
masm
uint32_t
alignment
const
VectorT
&
args
unsigned
extraBytes
=
0
)
{
return
StackDecrementForCall
(
masm
alignment
StackArgBytes
(
args
)
+
extraBytes
)
;
}
#
if
defined
(
JS_CODEGEN_ARM
)
static
const
LiveRegisterSet
NonVolatileRegs
=
LiveRegisterSet
(
GeneralRegisterSet
(
Registers
:
:
NonVolatileMask
&
~
(
uint32_t
(
1
)
<
<
Registers
:
:
lr
)
)
FloatRegisterSet
(
FloatRegisters
:
:
NonVolatileMask
|
(
1ULL
<
<
FloatRegisters
:
:
d15
)
|
(
1ULL
<
<
FloatRegisters
:
:
s31
)
)
)
;
#
else
static
const
LiveRegisterSet
NonVolatileRegs
=
LiveRegisterSet
(
GeneralRegisterSet
(
Registers
:
:
NonVolatileMask
)
FloatRegisterSet
(
FloatRegisters
:
:
NonVolatileMask
)
)
;
#
endif
#
if
defined
(
JS_CODEGEN_MIPS32
)
static
const
unsigned
FramePushedAfterSave
=
NonVolatileRegs
.
gprs
(
)
.
size
(
)
*
sizeof
(
intptr_t
)
+
NonVolatileRegs
.
fpus
(
)
.
getPushSizeInBytes
(
)
+
sizeof
(
double
)
;
#
elif
defined
(
JS_CODEGEN_NONE
)
static
const
unsigned
FramePushedAfterSave
=
0
;
#
else
static
const
unsigned
FramePushedAfterSave
=
NonVolatileRegs
.
gprs
(
)
.
size
(
)
*
sizeof
(
intptr_t
)
+
NonVolatileRegs
.
fpus
(
)
.
getPushSizeInBytes
(
)
;
#
endif
static
const
unsigned
FramePushedForEntrySP
=
FramePushedAfterSave
+
sizeof
(
void
*
)
;
Offsets
wasm
:
:
GenerateEntry
(
MacroAssembler
&
masm
unsigned
target
const
Sig
&
sig
bool
usesHeap
)
{
masm
.
haltingAlign
(
CodeAlignment
)
;
Offsets
offsets
;
offsets
.
begin
=
masm
.
currentOffset
(
)
;
#
if
defined
(
JS_CODEGEN_ARM
)
masm
.
push
(
lr
)
;
#
elif
defined
(
JS_CODEGEN_MIPS32
)
|
|
defined
(
JS_CODEGEN_MIPS64
)
masm
.
push
(
ra
)
;
#
elif
defined
(
JS_CODEGEN_X86
)
static
const
unsigned
EntryFrameSize
=
sizeof
(
void
*
)
;
#
endif
masm
.
setFramePushed
(
0
)
;
masm
.
PushRegsInMask
(
NonVolatileRegs
)
;
MOZ_ASSERT
(
masm
.
framePushed
(
)
=
=
FramePushedAfterSave
)
;
#
if
defined
(
JS_CODEGEN_ARM
)
|
|
defined
(
JS_CODEGEN_MIPS32
)
|
|
defined
(
JS_CODEGEN_MIPS64
)
masm
.
movePtr
(
IntArgReg1
GlobalReg
)
;
masm
.
addPtr
(
Imm32
(
AsmJSGlobalRegBias
)
GlobalReg
)
;
#
endif
if
(
usesHeap
)
masm
.
loadAsmJSHeapRegisterFromGlobalData
(
)
;
Register
argv
=
ABIArgGenerator
:
:
NonArgReturnReg0
;
Register
scratch
=
ABIArgGenerator
:
:
NonArgReturnReg1
;
Register64
scratch64
(
scratch
)
;
#
if
defined
(
JS_CODEGEN_X86
)
masm
.
loadPtr
(
Address
(
masm
.
getStackPointer
(
)
EntryFrameSize
+
masm
.
framePushed
(
)
)
argv
)
;
#
else
masm
.
movePtr
(
IntArgReg0
argv
)
;
#
endif
masm
.
Push
(
argv
)
;
MOZ_ASSERT
(
masm
.
framePushed
(
)
=
=
FramePushedForEntrySP
)
;
masm
.
loadWasmActivation
(
scratch
)
;
masm
.
storeStackPtr
(
Address
(
scratch
WasmActivation
:
:
offsetOfEntrySP
(
)
)
)
;
masm
.
andToStackPtr
(
Imm32
(
~
(
AsmJSStackAlignment
-
1
)
)
)
;
masm
.
reserveStack
(
AlignBytes
(
StackArgBytes
(
sig
.
args
(
)
)
AsmJSStackAlignment
)
)
;
for
(
ABIArgValTypeIter
iter
(
sig
.
args
(
)
)
;
!
iter
.
done
(
)
;
iter
+
+
)
{
unsigned
argOffset
=
iter
.
index
(
)
*
Module
:
:
SizeOfEntryArg
;
Address
src
(
argv
argOffset
)
;
MIRType
type
=
iter
.
mirType
(
)
;
MOZ_ASSERT_IF
(
type
=
=
MIRType
:
:
Int64
JitOptions
.
wasmTestMode
)
;
switch
(
iter
-
>
kind
(
)
)
{
case
ABIArg
:
:
GPR
:
if
(
type
=
=
MIRType
:
:
Int32
)
masm
.
load32
(
src
iter
-
>
gpr
(
)
)
;
else
if
(
type
=
=
MIRType
:
:
Int64
)
masm
.
load64
(
src
iter
-
>
gpr64
(
)
)
;
break
;
#
ifdef
JS_CODEGEN_REGISTER_PAIR
case
ABIArg
:
:
GPR_PAIR
:
MOZ_CRASH
(
"
wasm
uses
hardfp
for
function
calls
.
"
)
;
break
;
#
endif
case
ABIArg
:
:
FPU
:
{
static_assert
(
Module
:
:
SizeOfEntryArg
>
=
jit
:
:
Simd128DataSize
"
EntryArg
must
be
big
enough
to
store
SIMD
values
"
)
;
switch
(
type
)
{
case
MIRType
:
:
Int32x4
:
case
MIRType
:
:
Bool32x4
:
masm
.
loadUnalignedInt32x4
(
src
iter
-
>
fpu
(
)
)
;
break
;
case
MIRType
:
:
Float32x4
:
masm
.
loadUnalignedFloat32x4
(
src
iter
-
>
fpu
(
)
)
;
break
;
case
MIRType
:
:
Double
:
masm
.
loadDouble
(
src
iter
-
>
fpu
(
)
)
;
break
;
case
MIRType
:
:
Float32
:
masm
.
loadFloat32
(
src
iter
-
>
fpu
(
)
)
;
break
;
default
:
MOZ_MAKE_COMPILER_ASSUME_IS_UNREACHABLE
(
"
unexpected
FPU
type
"
)
;
break
;
}
break
;
}
case
ABIArg
:
:
Stack
:
switch
(
type
)
{
case
MIRType
:
:
Int32
:
masm
.
load32
(
src
scratch
)
;
masm
.
storePtr
(
scratch
Address
(
masm
.
getStackPointer
(
)
iter
-
>
offsetFromArgBase
(
)
)
)
;
break
;
case
MIRType
:
:
Int64
:
masm
.
load64
(
src
scratch64
)
;
masm
.
store64
(
scratch64
Address
(
masm
.
getStackPointer
(
)
iter
-
>
offsetFromArgBase
(
)
)
)
;
break
;
case
MIRType
:
:
Double
:
masm
.
loadDouble
(
src
ScratchDoubleReg
)
;
masm
.
storeDouble
(
ScratchDoubleReg
Address
(
masm
.
getStackPointer
(
)
iter
-
>
offsetFromArgBase
(
)
)
)
;
break
;
case
MIRType
:
:
Float32
:
masm
.
loadFloat32
(
src
ScratchFloat32Reg
)
;
masm
.
storeFloat32
(
ScratchFloat32Reg
Address
(
masm
.
getStackPointer
(
)
iter
-
>
offsetFromArgBase
(
)
)
)
;
break
;
case
MIRType
:
:
Int32x4
:
case
MIRType
:
:
Bool32x4
:
masm
.
loadUnalignedInt32x4
(
src
ScratchSimd128Reg
)
;
masm
.
storeAlignedInt32x4
(
ScratchSimd128Reg
Address
(
masm
.
getStackPointer
(
)
iter
-
>
offsetFromArgBase
(
)
)
)
;
break
;
case
MIRType
:
:
Float32x4
:
masm
.
loadUnalignedFloat32x4
(
src
ScratchSimd128Reg
)
;
masm
.
storeAlignedFloat32x4
(
ScratchSimd128Reg
Address
(
masm
.
getStackPointer
(
)
iter
-
>
offsetFromArgBase
(
)
)
)
;
break
;
default
:
MOZ_MAKE_COMPILER_ASSUME_IS_UNREACHABLE
(
"
unexpected
stack
arg
type
"
)
;
}
break
;
}
}
masm
.
assertStackAlignment
(
AsmJSStackAlignment
)
;
masm
.
call
(
CallSiteDesc
(
CallSiteDesc
:
:
Relative
)
AsmJSInternalCallee
(
target
)
)
;
masm
.
loadWasmActivation
(
scratch
)
;
masm
.
loadStackPtr
(
Address
(
scratch
WasmActivation
:
:
offsetOfEntrySP
(
)
)
)
;
masm
.
setFramePushed
(
FramePushedForEntrySP
)
;
masm
.
Pop
(
argv
)
;
switch
(
sig
.
ret
(
)
)
{
case
ExprType
:
:
Void
:
break
;
case
ExprType
:
:
I32
:
masm
.
store32
(
ReturnReg
Address
(
argv
0
)
)
;
break
;
case
ExprType
:
:
I64
:
MOZ_ASSERT
(
JitOptions
.
wasmTestMode
"
no
int64
in
asm
.
js
/
wasm
"
)
;
masm
.
store64
(
ReturnReg64
Address
(
argv
0
)
)
;
break
;
case
ExprType
:
:
F32
:
masm
.
convertFloat32ToDouble
(
ReturnFloat32Reg
ReturnDoubleReg
)
;
MOZ_FALLTHROUGH
;
case
ExprType
:
:
F64
:
masm
.
canonicalizeDouble
(
ReturnDoubleReg
)
;
masm
.
storeDouble
(
ReturnDoubleReg
Address
(
argv
0
)
)
;
break
;
case
ExprType
:
:
I32x4
:
case
ExprType
:
:
B32x4
:
masm
.
storeUnalignedInt32x4
(
ReturnSimd128Reg
Address
(
argv
0
)
)
;
break
;
case
ExprType
:
:
F32x4
:
masm
.
storeUnalignedFloat32x4
(
ReturnSimd128Reg
Address
(
argv
0
)
)
;
break
;
case
ExprType
:
:
Limit
:
MOZ_CRASH
(
"
Limit
"
)
;
}
masm
.
PopRegsInMask
(
NonVolatileRegs
)
;
MOZ_ASSERT
(
masm
.
framePushed
(
)
=
=
0
)
;
masm
.
move32
(
Imm32
(
true
)
ReturnReg
)
;
masm
.
ret
(
)
;
offsets
.
end
=
masm
.
currentOffset
(
)
;
return
offsets
;
}
typedef
bool
ToValue
;
static
void
FillArgumentArray
(
MacroAssembler
&
masm
const
ValTypeVector
&
args
unsigned
argOffset
unsigned
offsetToCallerStackArgs
Register
scratch
ToValue
toValue
)
{
Register64
scratch64
(
scratch
)
;
for
(
ABIArgValTypeIter
i
(
args
)
;
!
i
.
done
(
)
;
i
+
+
)
{
Address
dstAddr
(
masm
.
getStackPointer
(
)
argOffset
+
i
.
index
(
)
*
sizeof
(
Value
)
)
;
MIRType
type
=
i
.
mirType
(
)
;
MOZ_ASSERT_IF
(
type
=
=
MIRType
:
:
Int64
JitOptions
.
wasmTestMode
)
;
switch
(
i
-
>
kind
(
)
)
{
case
ABIArg
:
:
GPR
:
if
(
type
=
=
MIRType
:
:
Int32
)
{
if
(
toValue
)
masm
.
storeValue
(
JSVAL_TYPE_INT32
i
-
>
gpr
(
)
dstAddr
)
;
else
masm
.
store32
(
i
-
>
gpr
(
)
dstAddr
)
;
}
else
if
(
type
=
=
MIRType
:
:
Int64
)
{
if
(
toValue
)
masm
.
breakpoint
(
)
;
else
masm
.
store64
(
i
-
>
gpr64
(
)
dstAddr
)
;
}
else
{
MOZ_CRASH
(
"
unexpected
input
type
?
"
)
;
}
break
;
#
ifdef
JS_CODEGEN_REGISTER_PAIR
case
ABIArg
:
:
GPR_PAIR
:
MOZ_CRASH
(
"
AsmJS
uses
hardfp
for
function
calls
.
"
)
;
break
;
#
endif
case
ABIArg
:
:
FPU
:
{
MOZ_ASSERT
(
IsFloatingPointType
(
type
)
)
;
FloatRegister
srcReg
=
i
-
>
fpu
(
)
;
if
(
toValue
)
{
if
(
type
=
=
MIRType
:
:
Float32
)
{
masm
.
convertFloat32ToDouble
(
i
-
>
fpu
(
)
ScratchDoubleReg
)
;
srcReg
=
ScratchDoubleReg
;
}
masm
.
canonicalizeDouble
(
srcReg
)
;
}
masm
.
storeDouble
(
srcReg
dstAddr
)
;
break
;
}
case
ABIArg
:
:
Stack
:
if
(
type
=
=
MIRType
:
:
Int32
)
{
Address
src
(
masm
.
getStackPointer
(
)
offsetToCallerStackArgs
+
i
-
>
offsetFromArgBase
(
)
)
;
masm
.
load32
(
src
scratch
)
;
if
(
toValue
)
masm
.
storeValue
(
JSVAL_TYPE_INT32
scratch
dstAddr
)
;
else
masm
.
store32
(
scratch
dstAddr
)
;
}
else
if
(
type
=
=
MIRType
:
:
Int64
)
{
if
(
toValue
)
{
masm
.
breakpoint
(
)
;
}
else
{
Address
src
(
masm
.
getStackPointer
(
)
offsetToCallerStackArgs
+
i
-
>
offsetFromArgBase
(
)
)
;
masm
.
load64
(
src
scratch64
)
;
masm
.
store64
(
scratch64
dstAddr
)
;
}
}
else
{
MOZ_ASSERT
(
IsFloatingPointType
(
type
)
)
;
Address
src
(
masm
.
getStackPointer
(
)
offsetToCallerStackArgs
+
i
-
>
offsetFromArgBase
(
)
)
;
if
(
toValue
)
{
if
(
type
=
=
MIRType
:
:
Float32
)
{
masm
.
loadFloat32
(
src
ScratchFloat32Reg
)
;
masm
.
convertFloat32ToDouble
(
ScratchFloat32Reg
ScratchDoubleReg
)
;
}
else
{
masm
.
loadDouble
(
src
ScratchDoubleReg
)
;
}
masm
.
canonicalizeDouble
(
ScratchDoubleReg
)
;
}
else
{
masm
.
loadDouble
(
src
ScratchDoubleReg
)
;
}
masm
.
storeDouble
(
ScratchDoubleReg
dstAddr
)
;
}
break
;
}
}
}
ProfilingOffsets
wasm
:
:
GenerateInterpExit
(
MacroAssembler
&
masm
const
Import
&
import
uint32_t
importIndex
)
{
const
Sig
&
sig
=
import
.
sig
(
)
;
masm
.
setFramePushed
(
0
)
;
static
const
MIRType
typeArray
[
]
=
{
MIRType
:
:
Pointer
MIRType
:
:
Int32
MIRType
:
:
Pointer
}
;
MIRTypeVector
invokeArgTypes
;
MOZ_ALWAYS_TRUE
(
invokeArgTypes
.
append
(
typeArray
ArrayLength
(
typeArray
)
)
)
;
unsigned
argOffset
=
AlignBytes
(
StackArgBytes
(
invokeArgTypes
)
sizeof
(
double
)
)
;
unsigned
argBytes
=
Max
<
size_t
>
(
1
sig
.
args
(
)
.
length
(
)
)
*
sizeof
(
Value
)
;
unsigned
framePushed
=
StackDecrementForCall
(
masm
ABIStackAlignment
argOffset
+
argBytes
)
;
ProfilingOffsets
offsets
;
GenerateExitPrologue
(
masm
framePushed
ExitReason
:
:
ImportInterp
&
offsets
)
;
unsigned
offsetToCallerStackArgs
=
sizeof
(
AsmJSFrame
)
+
masm
.
framePushed
(
)
;
Register
scratch
=
ABIArgGenerator
:
:
NonArgReturnReg0
;
FillArgumentArray
(
masm
sig
.
args
(
)
argOffset
offsetToCallerStackArgs
scratch
ToValue
(
false
)
)
;
ABIArgMIRTypeIter
i
(
invokeArgTypes
)
;
if
(
i
-
>
kind
(
)
=
=
ABIArg
:
:
GPR
)
masm
.
mov
(
ImmWord
(
importIndex
)
i
-
>
gpr
(
)
)
;
else
masm
.
store32
(
Imm32
(
importIndex
)
Address
(
masm
.
getStackPointer
(
)
i
-
>
offsetFromArgBase
(
)
)
)
;
i
+
+
;
unsigned
argc
=
sig
.
args
(
)
.
length
(
)
;
if
(
i
-
>
kind
(
)
=
=
ABIArg
:
:
GPR
)
masm
.
mov
(
ImmWord
(
argc
)
i
-
>
gpr
(
)
)
;
else
masm
.
store32
(
Imm32
(
argc
)
Address
(
masm
.
getStackPointer
(
)
i
-
>
offsetFromArgBase
(
)
)
)
;
i
+
+
;
Address
argv
(
masm
.
getStackPointer
(
)
argOffset
)
;
if
(
i
-
>
kind
(
)
=
=
ABIArg
:
:
GPR
)
{
masm
.
computeEffectiveAddress
(
argv
i
-
>
gpr
(
)
)
;
}
else
{
masm
.
computeEffectiveAddress
(
argv
scratch
)
;
masm
.
storePtr
(
scratch
Address
(
masm
.
getStackPointer
(
)
i
-
>
offsetFromArgBase
(
)
)
)
;
}
i
+
+
;
MOZ_ASSERT
(
i
.
done
(
)
)
;
AssertStackAlignment
(
masm
ABIStackAlignment
)
;
switch
(
sig
.
ret
(
)
)
{
case
ExprType
:
:
Void
:
masm
.
call
(
SymbolicAddress
:
:
InvokeImport_Void
)
;
masm
.
branchTest32
(
Assembler
:
:
Zero
ReturnReg
ReturnReg
JumpTarget
:
:
Throw
)
;
break
;
case
ExprType
:
:
I32
:
masm
.
call
(
SymbolicAddress
:
:
InvokeImport_I32
)
;
masm
.
branchTest32
(
Assembler
:
:
Zero
ReturnReg
ReturnReg
JumpTarget
:
:
Throw
)
;
masm
.
load32
(
argv
ReturnReg
)
;
break
;
case
ExprType
:
:
I64
:
MOZ_ASSERT
(
JitOptions
.
wasmTestMode
)
;
masm
.
call
(
SymbolicAddress
:
:
InvokeImport_I64
)
;
masm
.
branchTest32
(
Assembler
:
:
Zero
ReturnReg
ReturnReg
JumpTarget
:
:
Throw
)
;
masm
.
load64
(
argv
ReturnReg64
)
;
break
;
case
ExprType
:
:
F32
:
masm
.
call
(
SymbolicAddress
:
:
InvokeImport_F64
)
;
masm
.
branchTest32
(
Assembler
:
:
Zero
ReturnReg
ReturnReg
JumpTarget
:
:
Throw
)
;
masm
.
loadDouble
(
argv
ReturnDoubleReg
)
;
masm
.
convertDoubleToFloat32
(
ReturnDoubleReg
ReturnFloat32Reg
)
;
break
;
case
ExprType
:
:
F64
:
masm
.
call
(
SymbolicAddress
:
:
InvokeImport_F64
)
;
masm
.
branchTest32
(
Assembler
:
:
Zero
ReturnReg
ReturnReg
JumpTarget
:
:
Throw
)
;
masm
.
loadDouble
(
argv
ReturnDoubleReg
)
;
break
;
case
ExprType
:
:
I32x4
:
case
ExprType
:
:
F32x4
:
case
ExprType
:
:
B32x4
:
MOZ_CRASH
(
"
SIMD
types
shouldn
'
t
be
returned
from
a
FFI
"
)
;
case
ExprType
:
:
Limit
:
MOZ_CRASH
(
"
Limit
"
)
;
}
GenerateExitEpilogue
(
masm
framePushed
ExitReason
:
:
ImportInterp
&
offsets
)
;
offsets
.
end
=
masm
.
currentOffset
(
)
;
return
offsets
;
}
#
if
defined
(
JS_CODEGEN_ARM
)
|
|
defined
(
JS_CODEGEN_MIPS32
)
|
|
defined
(
JS_CODEGEN_MIPS64
)
static
const
unsigned
MaybeSavedGlobalReg
=
sizeof
(
void
*
)
;
#
else
static
const
unsigned
MaybeSavedGlobalReg
=
0
;
#
endif
ProfilingOffsets
wasm
:
:
GenerateJitExit
(
MacroAssembler
&
masm
const
Import
&
import
bool
usesHeap
)
{
const
Sig
&
sig
=
import
.
sig
(
)
;
masm
.
setFramePushed
(
0
)
;
static_assert
(
AsmJSStackAlignment
>
=
JitStackAlignment
"
subsumes
"
)
;
unsigned
sizeOfRetAddr
=
sizeof
(
void
*
)
;
unsigned
jitFrameBytes
=
3
*
sizeof
(
void
*
)
+
(
1
+
sig
.
args
(
)
.
length
(
)
)
*
sizeof
(
Value
)
;
unsigned
totalJitFrameBytes
=
sizeOfRetAddr
+
jitFrameBytes
+
MaybeSavedGlobalReg
;
unsigned
jitFramePushed
=
StackDecrementForCall
(
masm
JitStackAlignment
totalJitFrameBytes
)
-
sizeOfRetAddr
;
ProfilingOffsets
offsets
;
GenerateExitPrologue
(
masm
jitFramePushed
ExitReason
:
:
ImportJit
&
offsets
)
;
size_t
argOffset
=
0
;
uint32_t
descriptor
=
MakeFrameDescriptor
(
jitFramePushed
JitFrame_Entry
JitFrameLayout
:
:
Size
(
)
)
;
masm
.
storePtr
(
ImmWord
(
uintptr_t
(
descriptor
)
)
Address
(
masm
.
getStackPointer
(
)
argOffset
)
)
;
argOffset
+
=
sizeof
(
size_t
)
;
Register
callee
=
ABIArgGenerator
:
:
NonArgReturnReg0
;
Register
scratch
=
ABIArgGenerator
:
:
NonArgReturnReg1
;
uint32_t
globalDataOffset
=
import
.
exitGlobalDataOffset
(
)
;
#
if
defined
(
JS_CODEGEN_X64
)
masm
.
append
(
AsmJSGlobalAccess
(
masm
.
leaRipRelative
(
callee
)
globalDataOffset
)
)
;
#
elif
defined
(
JS_CODEGEN_X86
)
masm
.
append
(
AsmJSGlobalAccess
(
masm
.
movlWithPatch
(
Imm32
(
0
)
callee
)
globalDataOffset
)
)
;
#
elif
defined
(
JS_CODEGEN_ARM
)
|
|
defined
(
JS_CODEGEN_ARM64
)
|
|
\
defined
(
JS_CODEGEN_MIPS32
)
|
|
defined
(
JS_CODEGEN_MIPS64
)
masm
.
computeEffectiveAddress
(
Address
(
GlobalReg
globalDataOffset
-
AsmJSGlobalRegBias
)
callee
)
;
#
endif
masm
.
loadPtr
(
Address
(
callee
Module
:
:
OffsetOfImportExitFun
)
callee
)
;
masm
.
storePtr
(
callee
Address
(
masm
.
getStackPointer
(
)
argOffset
)
)
;
argOffset
+
=
sizeof
(
size_t
)
;
masm
.
loadPtr
(
Address
(
callee
JSFunction
:
:
offsetOfNativeOrScript
(
)
)
callee
)
;
masm
.
loadBaselineOrIonNoArgCheck
(
callee
callee
nullptr
)
;
unsigned
argc
=
sig
.
args
(
)
.
length
(
)
;
masm
.
storePtr
(
ImmWord
(
uintptr_t
(
argc
)
)
Address
(
masm
.
getStackPointer
(
)
argOffset
)
)
;
argOffset
+
=
sizeof
(
size_t
)
;
masm
.
storeValue
(
UndefinedValue
(
)
Address
(
masm
.
getStackPointer
(
)
argOffset
)
)
;
argOffset
+
=
sizeof
(
Value
)
;
unsigned
offsetToCallerStackArgs
=
jitFramePushed
+
sizeof
(
AsmJSFrame
)
;
FillArgumentArray
(
masm
sig
.
args
(
)
argOffset
offsetToCallerStackArgs
scratch
ToValue
(
true
)
)
;
argOffset
+
=
sig
.
args
(
)
.
length
(
)
*
sizeof
(
Value
)
;
MOZ_ASSERT
(
argOffset
=
=
jitFrameBytes
)
;
#
if
defined
(
JS_CODEGEN_ARM
)
|
|
defined
(
JS_CODEGEN_MIPS32
)
|
|
defined
(
JS_CODEGEN_MIPS64
)
static_assert
(
MaybeSavedGlobalReg
=
=
sizeof
(
void
*
)
"
stack
frame
accounting
"
)
;
masm
.
storePtr
(
GlobalReg
Address
(
masm
.
getStackPointer
(
)
jitFrameBytes
)
)
;
#
endif
{
MOZ_ASSERT
(
callee
=
=
AsmJSIonExitRegCallee
)
;
Register
reg0
=
AsmJSIonExitRegE0
;
Register
reg1
=
AsmJSIonExitRegE1
;
Register
reg2
=
AsmJSIonExitRegE2
;
Register
reg3
=
AsmJSIonExitRegE3
;
size_t
offsetOfActivation
=
JSRuntime
:
:
offsetOfActivation
(
)
;
size_t
offsetOfJitTop
=
offsetof
(
JSRuntime
jitTop
)
;
size_t
offsetOfJitJSContext
=
offsetof
(
JSRuntime
jitJSContext
)
;
size_t
offsetOfJitActivation
=
offsetof
(
JSRuntime
jitActivation
)
;
size_t
offsetOfProfilingActivation
=
JSRuntime
:
:
offsetOfProfilingActivation
(
)
;
masm
.
loadWasmActivation
(
reg0
)
;
masm
.
loadPtr
(
Address
(
reg0
WasmActivation
:
:
offsetOfContext
(
)
)
reg3
)
;
masm
.
loadPtr
(
Address
(
reg3
JSContext
:
:
offsetOfRuntime
(
)
)
reg0
)
;
masm
.
loadPtr
(
Address
(
reg0
offsetOfActivation
)
reg1
)
;
masm
.
store8
(
Imm32
(
1
)
Address
(
reg1
JitActivation
:
:
offsetOfActiveUint8
(
)
)
)
;
masm
.
loadPtr
(
Address
(
reg0
offsetOfJitTop
)
reg2
)
;
masm
.
storePtr
(
reg2
Address
(
reg1
JitActivation
:
:
offsetOfPrevJitTop
(
)
)
)
;
masm
.
loadPtr
(
Address
(
reg0
offsetOfJitJSContext
)
reg2
)
;
masm
.
storePtr
(
reg2
Address
(
reg1
JitActivation
:
:
offsetOfPrevJitJSContext
(
)
)
)
;
masm
.
storePtr
(
reg3
Address
(
reg0
offsetOfJitJSContext
)
)
;
masm
.
loadPtr
(
Address
(
reg0
offsetOfJitActivation
)
reg2
)
;
masm
.
storePtr
(
reg2
Address
(
reg1
JitActivation
:
:
offsetOfPrevJitActivation
(
)
)
)
;
masm
.
storePtr
(
reg1
Address
(
reg0
offsetOfJitActivation
)
)
;
masm
.
loadPtr
(
Address
(
reg0
offsetOfProfilingActivation
)
reg2
)
;
masm
.
storePtr
(
reg2
Address
(
reg1
Activation
:
:
offsetOfPrevProfiling
(
)
)
)
;
masm
.
storePtr
(
reg1
Address
(
reg0
offsetOfProfilingActivation
)
)
;
}
AssertStackAlignment
(
masm
JitStackAlignment
sizeOfRetAddr
)
;
masm
.
callJitNoProfiler
(
callee
)
;
AssertStackAlignment
(
masm
JitStackAlignment
sizeOfRetAddr
)
;
{
MOZ_ASSERT
(
JSReturnReg_Data
=
=
AsmJSIonExitRegReturnData
)
;
MOZ_ASSERT
(
JSReturnReg_Type
=
=
AsmJSIonExitRegReturnType
)
;
Register
reg0
=
AsmJSIonExitRegD0
;
Register
reg1
=
AsmJSIonExitRegD1
;
Register
reg2
=
AsmJSIonExitRegD2
;
size_t
offsetOfActivation
=
JSRuntime
:
:
offsetOfActivation
(
)
;
size_t
offsetOfJitTop
=
offsetof
(
JSRuntime
jitTop
)
;
size_t
offsetOfJitJSContext
=
offsetof
(
JSRuntime
jitJSContext
)
;
size_t
offsetOfJitActivation
=
offsetof
(
JSRuntime
jitActivation
)
;
size_t
offsetOfProfilingActivation
=
JSRuntime
:
:
offsetOfProfilingActivation
(
)
;
masm
.
movePtr
(
SymbolicAddress
:
:
Runtime
reg0
)
;
masm
.
loadPtr
(
Address
(
reg0
offsetOfActivation
)
reg1
)
;
masm
.
loadPtr
(
Address
(
reg1
JitActivation
:
:
offsetOfPrevJitTop
(
)
)
reg2
)
;
masm
.
storePtr
(
reg2
Address
(
reg0
offsetOfJitTop
)
)
;
masm
.
loadPtr
(
Address
(
reg1
Activation
:
:
offsetOfPrevProfiling
(
)
)
reg2
)
;
masm
.
storePtr
(
reg2
Address
(
reg0
offsetOfProfilingActivation
)
)
;
masm
.
store8
(
Imm32
(
0
)
Address
(
reg1
JitActivation
:
:
offsetOfActiveUint8
(
)
)
)
;
masm
.
loadPtr
(
Address
(
reg1
JitActivation
:
:
offsetOfPrevJitJSContext
(
)
)
reg2
)
;
masm
.
storePtr
(
reg2
Address
(
reg0
offsetOfJitJSContext
)
)
;
masm
.
loadPtr
(
Address
(
reg1
JitActivation
:
:
offsetOfPrevJitActivation
(
)
)
reg2
)
;
masm
.
storePtr
(
reg2
Address
(
reg0
offsetOfJitActivation
)
)
;
}
#
if
defined
(
JS_CODEGEN_ARM
)
|
|
defined
(
JS_CODEGEN_MIPS32
)
|
|
defined
(
JS_CODEGEN_MIPS64
)
static_assert
(
MaybeSavedGlobalReg
=
=
sizeof
(
void
*
)
"
stack
frame
accounting
"
)
;
masm
.
loadPtr
(
Address
(
masm
.
getStackPointer
(
)
jitFrameBytes
)
GlobalReg
)
;
#
endif
static_assert
(
ABIStackAlignment
<
=
JitStackAlignment
"
subsumes
"
)
;
masm
.
reserveStack
(
sizeOfRetAddr
)
;
unsigned
nativeFramePushed
=
masm
.
framePushed
(
)
;
AssertStackAlignment
(
masm
ABIStackAlignment
)
;
masm
.
branchTestMagic
(
Assembler
:
:
Equal
JSReturnOperand
JumpTarget
:
:
Throw
)
;
Label
oolConvert
;
switch
(
sig
.
ret
(
)
)
{
case
ExprType
:
:
Void
:
break
;
case
ExprType
:
:
I32
:
masm
.
convertValueToInt32
(
JSReturnOperand
ReturnDoubleReg
ReturnReg
&
oolConvert
false
)
;
break
;
case
ExprType
:
:
I64
:
MOZ_ASSERT
(
JitOptions
.
wasmTestMode
"
no
int64
in
asm
.
js
/
wasm
"
)
;
masm
.
breakpoint
(
)
;
break
;
case
ExprType
:
:
F32
:
masm
.
convertValueToFloat
(
JSReturnOperand
ReturnFloat32Reg
&
oolConvert
)
;
break
;
case
ExprType
:
:
F64
:
masm
.
convertValueToDouble
(
JSReturnOperand
ReturnDoubleReg
&
oolConvert
)
;
break
;
case
ExprType
:
:
I32x4
:
case
ExprType
:
:
F32x4
:
case
ExprType
:
:
B32x4
:
MOZ_CRASH
(
"
SIMD
types
shouldn
'
t
be
returned
from
an
import
"
)
;
case
ExprType
:
:
Limit
:
MOZ_CRASH
(
"
Limit
"
)
;
}
Label
done
;
masm
.
bind
(
&
done
)
;
if
(
usesHeap
)
masm
.
loadAsmJSHeapRegisterFromGlobalData
(
)
;
GenerateExitEpilogue
(
masm
masm
.
framePushed
(
)
ExitReason
:
:
ImportJit
&
offsets
)
;
if
(
oolConvert
.
used
(
)
)
{
masm
.
bind
(
&
oolConvert
)
;
masm
.
setFramePushed
(
nativeFramePushed
)
;
MIRTypeVector
coerceArgTypes
;
JS_ALWAYS_TRUE
(
coerceArgTypes
.
append
(
MIRType
:
:
Pointer
)
)
;
unsigned
offsetToCoerceArgv
=
AlignBytes
(
StackArgBytes
(
coerceArgTypes
)
sizeof
(
Value
)
)
;
MOZ_ASSERT
(
nativeFramePushed
>
=
offsetToCoerceArgv
+
sizeof
(
Value
)
)
;
AssertStackAlignment
(
masm
ABIStackAlignment
)
;
masm
.
storeValue
(
JSReturnOperand
Address
(
masm
.
getStackPointer
(
)
offsetToCoerceArgv
)
)
;
ABIArgMIRTypeIter
i
(
coerceArgTypes
)
;
Address
argv
(
masm
.
getStackPointer
(
)
offsetToCoerceArgv
)
;
if
(
i
-
>
kind
(
)
=
=
ABIArg
:
:
GPR
)
{
masm
.
computeEffectiveAddress
(
argv
i
-
>
gpr
(
)
)
;
}
else
{
masm
.
computeEffectiveAddress
(
argv
scratch
)
;
masm
.
storePtr
(
scratch
Address
(
masm
.
getStackPointer
(
)
i
-
>
offsetFromArgBase
(
)
)
)
;
}
i
+
+
;
MOZ_ASSERT
(
i
.
done
(
)
)
;
AssertStackAlignment
(
masm
ABIStackAlignment
)
;
switch
(
sig
.
ret
(
)
)
{
case
ExprType
:
:
I32
:
masm
.
call
(
SymbolicAddress
:
:
CoerceInPlace_ToInt32
)
;
masm
.
branchTest32
(
Assembler
:
:
Zero
ReturnReg
ReturnReg
JumpTarget
:
:
Throw
)
;
masm
.
unboxInt32
(
Address
(
masm
.
getStackPointer
(
)
offsetToCoerceArgv
)
ReturnReg
)
;
break
;
case
ExprType
:
:
F64
:
masm
.
call
(
SymbolicAddress
:
:
CoerceInPlace_ToNumber
)
;
masm
.
branchTest32
(
Assembler
:
:
Zero
ReturnReg
ReturnReg
JumpTarget
:
:
Throw
)
;
masm
.
loadDouble
(
Address
(
masm
.
getStackPointer
(
)
offsetToCoerceArgv
)
ReturnDoubleReg
)
;
break
;
case
ExprType
:
:
F32
:
masm
.
call
(
SymbolicAddress
:
:
CoerceInPlace_ToNumber
)
;
masm
.
branchTest32
(
Assembler
:
:
Zero
ReturnReg
ReturnReg
JumpTarget
:
:
Throw
)
;
masm
.
loadDouble
(
Address
(
masm
.
getStackPointer
(
)
offsetToCoerceArgv
)
ReturnDoubleReg
)
;
masm
.
convertDoubleToFloat32
(
ReturnDoubleReg
ReturnFloat32Reg
)
;
break
;
default
:
MOZ_CRASH
(
"
Unsupported
convert
type
"
)
;
}
masm
.
jump
(
&
done
)
;
masm
.
setFramePushed
(
0
)
;
}
MOZ_ASSERT
(
masm
.
framePushed
(
)
=
=
0
)
;
offsets
.
end
=
masm
.
currentOffset
(
)
;
return
offsets
;
}
static
Offsets
GenerateStackOverflow
(
MacroAssembler
&
masm
)
{
masm
.
haltingAlign
(
CodeAlignment
)
;
Offsets
offsets
;
offsets
.
begin
=
masm
.
currentOffset
(
)
;
Register
activation
=
ABIArgGenerator
:
:
NonArgReturnReg0
;
masm
.
loadWasmActivation
(
activation
)
;
masm
.
storePtr
(
masm
.
getStackPointer
(
)
Address
(
activation
WasmActivation
:
:
offsetOfFP
(
)
)
)
;
if
(
uint32_t
d
=
StackDecrementForCall
(
ABIStackAlignment
sizeof
(
AsmJSFrame
)
ShadowStackSpace
)
)
masm
.
subFromStackPtr
(
Imm32
(
d
)
)
;
masm
.
assertStackAlignment
(
ABIStackAlignment
)
;
masm
.
call
(
SymbolicAddress
:
:
ReportOverRecursed
)
;
masm
.
jump
(
JumpTarget
:
:
Throw
)
;
offsets
.
end
=
masm
.
currentOffset
(
)
;
return
offsets
;
}
static
Offsets
GenerateErrorStub
(
MacroAssembler
&
masm
SymbolicAddress
address
)
{
masm
.
haltingAlign
(
CodeAlignment
)
;
Offsets
offsets
;
offsets
.
begin
=
masm
.
currentOffset
(
)
;
masm
.
andToStackPtr
(
Imm32
(
~
(
ABIStackAlignment
-
1
)
)
)
;
masm
.
assertStackAlignment
(
ABIStackAlignment
)
;
masm
.
call
(
address
)
;
masm
.
jump
(
JumpTarget
:
:
Throw
)
;
offsets
.
end
=
masm
.
currentOffset
(
)
;
return
offsets
;
}
static
Offsets
GenerateThrow
(
MacroAssembler
&
masm
)
{
masm
.
haltingAlign
(
CodeAlignment
)
;
Offsets
offsets
;
offsets
.
begin
=
masm
.
currentOffset
(
)
;
Register
scratch
=
ABIArgGenerator
:
:
NonArgReturnReg0
;
masm
.
loadWasmActivation
(
scratch
)
;
masm
.
storePtr
(
ImmWord
(
0
)
Address
(
scratch
WasmActivation
:
:
offsetOfFP
(
)
)
)
;
masm
.
setFramePushed
(
FramePushedForEntrySP
)
;
masm
.
loadStackPtr
(
Address
(
scratch
WasmActivation
:
:
offsetOfEntrySP
(
)
)
)
;
masm
.
Pop
(
scratch
)
;
masm
.
PopRegsInMask
(
NonVolatileRegs
)
;
MOZ_ASSERT
(
masm
.
framePushed
(
)
=
=
0
)
;
masm
.
mov
(
ImmWord
(
0
)
ReturnReg
)
;
masm
.
ret
(
)
;
offsets
.
end
=
masm
.
currentOffset
(
)
;
return
offsets
;
}
Offsets
wasm
:
:
GenerateJumpTarget
(
MacroAssembler
&
masm
JumpTarget
target
)
{
switch
(
target
)
{
case
JumpTarget
:
:
StackOverflow
:
return
GenerateStackOverflow
(
masm
)
;
case
JumpTarget
:
:
ConversionError
:
return
GenerateErrorStub
(
masm
SymbolicAddress
:
:
OnImpreciseConversion
)
;
case
JumpTarget
:
:
OutOfBounds
:
return
GenerateErrorStub
(
masm
SymbolicAddress
:
:
OnOutOfBounds
)
;
case
JumpTarget
:
:
BadIndirectCall
:
return
GenerateErrorStub
(
masm
SymbolicAddress
:
:
BadIndirectCall
)
;
case
JumpTarget
:
:
UnreachableTrap
:
return
GenerateErrorStub
(
masm
SymbolicAddress
:
:
UnreachableTrap
)
;
case
JumpTarget
:
:
Throw
:
return
GenerateThrow
(
masm
)
;
case
JumpTarget
:
:
Limit
:
break
;
}
MOZ_CRASH
(
"
bad
JumpTarget
"
)
;
}
ProfilingOffsets
wasm
:
:
GenerateBadIndirectCallExit
(
MacroAssembler
&
masm
)
{
MIRTypeVector
args
;
unsigned
framePushed
=
StackDecrementForCall
(
masm
ABIStackAlignment
args
)
;
ProfilingOffsets
offsets
;
GenerateExitPrologue
(
masm
framePushed
ExitReason
:
:
Error
&
offsets
)
;
AssertStackAlignment
(
masm
ABIStackAlignment
)
;
masm
.
call
(
SymbolicAddress
:
:
BadIndirectCall
)
;
masm
.
jump
(
JumpTarget
:
:
Throw
)
;
GenerateExitEpilogue
(
masm
framePushed
ExitReason
:
:
Error
&
offsets
)
;
offsets
.
end
=
masm
.
currentOffset
(
)
;
return
offsets
;
}
static
const
LiveRegisterSet
AllRegsExceptSP
(
GeneralRegisterSet
(
Registers
:
:
AllMask
&
~
(
uint32_t
(
1
)
<
<
Registers
:
:
StackPointer
)
)
FloatRegisterSet
(
FloatRegisters
:
:
AllMask
)
)
;
Offsets
wasm
:
:
GenerateInterruptStub
(
MacroAssembler
&
masm
)
{
masm
.
haltingAlign
(
CodeAlignment
)
;
Offsets
offsets
;
offsets
.
begin
=
masm
.
currentOffset
(
)
;
#
if
defined
(
JS_CODEGEN_X86
)
|
|
defined
(
JS_CODEGEN_X64
)
masm
.
push
(
Imm32
(
0
)
)
;
masm
.
pushFlags
(
)
;
masm
.
setFramePushed
(
0
)
;
masm
.
PushRegsInMask
(
AllRegsExceptSP
)
;
Register
scratch
=
ABIArgGenerator
:
:
NonArgReturnReg0
;
masm
.
loadWasmActivation
(
scratch
)
;
masm
.
loadPtr
(
Address
(
scratch
WasmActivation
:
:
offsetOfResumePC
(
)
)
scratch
)
;
masm
.
storePtr
(
scratch
Address
(
masm
.
getStackPointer
(
)
masm
.
framePushed
(
)
+
sizeof
(
void
*
)
)
)
;
masm
.
moveStackPtrTo
(
ABIArgGenerator
:
:
NonVolatileReg
)
;
masm
.
andToStackPtr
(
Imm32
(
~
(
ABIStackAlignment
-
1
)
)
)
;
if
(
ShadowStackSpace
)
masm
.
subFromStackPtr
(
Imm32
(
ShadowStackSpace
)
)
;
masm
.
assertStackAlignment
(
ABIStackAlignment
)
;
masm
.
call
(
SymbolicAddress
:
:
HandleExecutionInterrupt
)
;
masm
.
branchIfFalseBool
(
ReturnReg
JumpTarget
:
:
Throw
)
;
masm
.
moveToStackPtr
(
ABIArgGenerator
:
:
NonVolatileReg
)
;
masm
.
PopRegsInMask
(
AllRegsExceptSP
)
;
masm
.
popFlags
(
)
;
masm
.
ret
(
)
;
#
elif
defined
(
JS_CODEGEN_MIPS32
)
|
|
defined
(
JS_CODEGEN_MIPS64
)
masm
.
subFromStackPtr
(
Imm32
(
sizeof
(
intptr_t
)
)
)
;
masm
.
setFramePushed
(
0
)
;
JS_STATIC_ASSERT
(
!
SupportsSimd
)
;
masm
.
PushRegsInMask
(
AllRegsExceptSP
)
;
masm
.
moveStackPtrTo
(
s0
)
;
masm
.
ma_and
(
StackPointer
StackPointer
Imm32
(
~
(
ABIStackAlignment
-
1
)
)
)
;
masm
.
loadWasmActivation
(
IntArgReg0
)
;
masm
.
loadPtr
(
Address
(
IntArgReg0
WasmActivation
:
:
offsetOfResumePC
(
)
)
IntArgReg1
)
;
masm
.
storePtr
(
IntArgReg1
Address
(
s0
masm
.
framePushed
(
)
)
)
;
#
ifdef
USES_O32_ABI
masm
.
subFromStackPtr
(
Imm32
(
4
*
sizeof
(
intptr_t
)
)
)
;
#
endif
masm
.
assertStackAlignment
(
ABIStackAlignment
)
;
masm
.
call
(
SymbolicAddress
:
:
HandleExecutionInterrupt
)
;
#
ifdef
USES_O32_ABI
masm
.
addToStackPtr
(
Imm32
(
4
*
sizeof
(
intptr_t
)
)
)
;
#
endif
masm
.
branchIfFalseBool
(
ReturnReg
JumpTarget
:
:
Throw
)
;
masm
.
moveToStackPtr
(
s0
)
;
masm
.
PopRegsInMask
(
AllRegsExceptSP
)
;
masm
.
pop
(
HeapReg
)
;
masm
.
as_jr
(
HeapReg
)
;
masm
.
loadAsmJSHeapRegisterFromGlobalData
(
)
;
#
elif
defined
(
JS_CODEGEN_ARM
)
masm
.
setFramePushed
(
0
)
;
masm
.
PushRegsInMask
(
LiveRegisterSet
(
GeneralRegisterSet
(
Registers
:
:
AllMask
&
~
(
1
<
<
Registers
:
:
sp
)
)
FloatRegisterSet
(
uint32_t
(
0
)
)
)
)
;
masm
.
as_mrs
(
r4
)
;
masm
.
as_vmrs
(
r5
)
;
masm
.
mov
(
sp
r6
)
;
masm
.
ma_and
(
Imm32
(
~
7
)
sp
sp
)
;
masm
.
loadWasmActivation
(
IntArgReg0
)
;
masm
.
loadPtr
(
Address
(
IntArgReg0
WasmActivation
:
:
offsetOfResumePC
(
)
)
IntArgReg1
)
;
masm
.
storePtr
(
IntArgReg1
Address
(
r6
14
*
sizeof
(
uint32_t
*
)
)
)
;
JS_STATIC_ASSERT
(
!
SupportsSimd
)
;
masm
.
PushRegsInMask
(
LiveRegisterSet
(
GeneralRegisterSet
(
0
)
FloatRegisterSet
(
FloatRegisters
:
:
AllDoubleMask
)
)
)
;
masm
.
assertStackAlignment
(
ABIStackAlignment
)
;
masm
.
call
(
SymbolicAddress
:
:
HandleExecutionInterrupt
)
;
masm
.
branchIfFalseBool
(
ReturnReg
JumpTarget
:
:
Throw
)
;
masm
.
PopRegsInMask
(
LiveRegisterSet
(
GeneralRegisterSet
(
0
)
FloatRegisterSet
(
FloatRegisters
:
:
AllDoubleMask
)
)
)
;
masm
.
mov
(
r6
sp
)
;
masm
.
as_vmsr
(
r5
)
;
masm
.
as_msr
(
r4
)
;
masm
.
startDataTransferM
(
IsLoad
sp
IA
WriteBack
)
;
masm
.
transferReg
(
r0
)
;
masm
.
transferReg
(
r1
)
;
masm
.
transferReg
(
r2
)
;
masm
.
transferReg
(
r3
)
;
masm
.
transferReg
(
r4
)
;
masm
.
transferReg
(
r5
)
;
masm
.
transferReg
(
r6
)
;
masm
.
transferReg
(
r7
)
;
masm
.
transferReg
(
r8
)
;
masm
.
transferReg
(
r9
)
;
masm
.
transferReg
(
r10
)
;
masm
.
transferReg
(
r11
)
;
masm
.
transferReg
(
r12
)
;
masm
.
transferReg
(
lr
)
;
masm
.
finishDataTransfer
(
)
;
masm
.
ret
(
)
;
#
elif
defined
(
JS_CODEGEN_ARM64
)
MOZ_CRASH
(
)
;
#
elif
defined
(
JS_CODEGEN_NONE
)
MOZ_CRASH
(
)
;
#
else
#
error
"
Unknown
architecture
!
"
#
endif
offsets
.
end
=
masm
.
currentOffset
(
)
;
return
offsets
;
}
