#
include
"
asmjs
/
WasmStubs
.
h
"
#
include
"
mozilla
/
ArrayUtils
.
h
"
#
include
"
asmjs
/
WasmCode
.
h
"
#
include
"
asmjs
/
WasmIonCompile
.
h
"
#
include
"
jit
/
MacroAssembler
-
inl
.
h
"
using
namespace
js
;
using
namespace
js
:
:
jit
;
using
namespace
js
:
:
wasm
;
using
mozilla
:
:
ArrayLength
;
static
void
AssertStackAlignment
(
MacroAssembler
&
masm
uint32_t
alignment
uint32_t
addBeforeAssert
=
0
)
{
MOZ_ASSERT
(
(
sizeof
(
AsmJSFrame
)
+
masm
.
framePushed
(
)
+
addBeforeAssert
)
%
alignment
=
=
0
)
;
masm
.
assertStackAlignment
(
alignment
addBeforeAssert
)
;
}
static
unsigned
StackDecrementForCall
(
MacroAssembler
&
masm
uint32_t
alignment
unsigned
bytesToPush
)
{
return
StackDecrementForCall
(
alignment
sizeof
(
AsmJSFrame
)
+
masm
.
framePushed
(
)
bytesToPush
)
;
}
template
<
class
VectorT
>
static
unsigned
StackArgBytes
(
const
VectorT
&
args
)
{
ABIArgIter
<
VectorT
>
iter
(
args
)
;
while
(
!
iter
.
done
(
)
)
iter
+
+
;
return
iter
.
stackBytesConsumedSoFar
(
)
;
}
template
<
class
VectorT
>
static
unsigned
StackDecrementForCall
(
MacroAssembler
&
masm
uint32_t
alignment
const
VectorT
&
args
unsigned
extraBytes
=
0
)
{
return
StackDecrementForCall
(
masm
alignment
StackArgBytes
(
args
)
+
extraBytes
)
;
}
#
if
defined
(
JS_CODEGEN_ARM
)
static
const
LiveRegisterSet
NonVolatileRegs
=
LiveRegisterSet
(
GeneralRegisterSet
(
Registers
:
:
NonVolatileMask
&
~
(
uint32_t
(
1
)
<
<
Registers
:
:
lr
)
)
FloatRegisterSet
(
FloatRegisters
:
:
NonVolatileMask
|
(
1ULL
<
<
FloatRegisters
:
:
d15
)
|
(
1ULL
<
<
FloatRegisters
:
:
s31
)
)
)
;
#
else
static
const
LiveRegisterSet
NonVolatileRegs
=
LiveRegisterSet
(
GeneralRegisterSet
(
Registers
:
:
NonVolatileMask
)
FloatRegisterSet
(
FloatRegisters
:
:
NonVolatileMask
)
)
;
#
endif
#
if
defined
(
JS_CODEGEN_MIPS32
)
static
const
unsigned
FramePushedAfterSave
=
NonVolatileRegs
.
gprs
(
)
.
size
(
)
*
sizeof
(
intptr_t
)
+
NonVolatileRegs
.
fpus
(
)
.
getPushSizeInBytes
(
)
+
sizeof
(
double
)
;
#
elif
defined
(
JS_CODEGEN_NONE
)
static
const
unsigned
FramePushedAfterSave
=
0
;
#
else
static
const
unsigned
FramePushedAfterSave
=
NonVolatileRegs
.
gprs
(
)
.
size
(
)
*
sizeof
(
intptr_t
)
+
NonVolatileRegs
.
fpus
(
)
.
getPushSizeInBytes
(
)
;
#
endif
static
const
unsigned
FramePushedForEntrySP
=
FramePushedAfterSave
+
sizeof
(
void
*
)
;
Offsets
wasm
:
:
GenerateEntry
(
MacroAssembler
&
masm
const
FuncDefExport
&
func
)
{
masm
.
haltingAlign
(
CodeAlignment
)
;
Offsets
offsets
;
offsets
.
begin
=
masm
.
currentOffset
(
)
;
#
if
defined
(
JS_CODEGEN_ARM
)
masm
.
push
(
lr
)
;
#
elif
defined
(
JS_CODEGEN_MIPS32
)
|
|
defined
(
JS_CODEGEN_MIPS64
)
masm
.
push
(
ra
)
;
#
endif
masm
.
setFramePushed
(
0
)
;
masm
.
PushRegsInMask
(
NonVolatileRegs
)
;
MOZ_ASSERT
(
masm
.
framePushed
(
)
=
=
FramePushedAfterSave
)
;
Register
argv
=
ABINonArgReturnReg0
;
Register
scratch
=
ABINonArgReturnReg1
;
const
unsigned
argBase
=
sizeof
(
void
*
)
+
masm
.
framePushed
(
)
;
ABIArgGenerator
abi
;
ABIArg
arg
;
arg
=
abi
.
next
(
MIRType
:
:
Pointer
)
;
if
(
arg
.
kind
(
)
=
=
ABIArg
:
:
GPR
)
masm
.
movePtr
(
arg
.
gpr
(
)
argv
)
;
else
masm
.
loadPtr
(
Address
(
masm
.
getStackPointer
(
)
argBase
+
arg
.
offsetFromArgBase
(
)
)
argv
)
;
arg
=
abi
.
next
(
MIRType
:
:
Pointer
)
;
if
(
arg
.
kind
(
)
=
=
ABIArg
:
:
GPR
)
masm
.
movePtr
(
arg
.
gpr
(
)
WasmTlsReg
)
;
else
masm
.
loadPtr
(
Address
(
masm
.
getStackPointer
(
)
argBase
+
arg
.
offsetFromArgBase
(
)
)
WasmTlsReg
)
;
masm
.
loadWasmPinnedRegsFromTls
(
)
;
masm
.
Push
(
argv
)
;
MOZ_ASSERT
(
masm
.
framePushed
(
)
=
=
FramePushedForEntrySP
)
;
masm
.
loadWasmActivationFromTls
(
scratch
)
;
masm
.
storeStackPtr
(
Address
(
scratch
WasmActivation
:
:
offsetOfEntrySP
(
)
)
)
;
masm
.
andToStackPtr
(
Imm32
(
~
(
AsmJSStackAlignment
-
1
)
)
)
;
masm
.
reserveStack
(
AlignBytes
(
StackArgBytes
(
func
.
sig
(
)
.
args
(
)
)
AsmJSStackAlignment
)
)
;
for
(
ABIArgValTypeIter
iter
(
func
.
sig
(
)
.
args
(
)
)
;
!
iter
.
done
(
)
;
iter
+
+
)
{
unsigned
argOffset
=
iter
.
index
(
)
*
sizeof
(
ExportArg
)
;
Address
src
(
argv
argOffset
)
;
MIRType
type
=
iter
.
mirType
(
)
;
switch
(
iter
-
>
kind
(
)
)
{
case
ABIArg
:
:
GPR
:
if
(
type
=
=
MIRType
:
:
Int32
)
masm
.
load32
(
src
iter
-
>
gpr
(
)
)
;
else
if
(
type
=
=
MIRType
:
:
Int64
)
masm
.
load64
(
src
iter
-
>
gpr64
(
)
)
;
break
;
#
ifdef
JS_CODEGEN_REGISTER_PAIR
case
ABIArg
:
:
GPR_PAIR
:
if
(
type
=
=
MIRType
:
:
Int64
)
masm
.
load64
(
src
iter
-
>
gpr64
(
)
)
;
else
MOZ_CRASH
(
"
wasm
uses
hardfp
for
function
calls
.
"
)
;
break
;
#
endif
case
ABIArg
:
:
FPU
:
{
static_assert
(
sizeof
(
ExportArg
)
>
=
jit
:
:
Simd128DataSize
"
ExportArg
must
be
big
enough
to
store
SIMD
values
"
)
;
switch
(
type
)
{
case
MIRType
:
:
Int8x16
:
case
MIRType
:
:
Int16x8
:
case
MIRType
:
:
Int32x4
:
case
MIRType
:
:
Bool8x16
:
case
MIRType
:
:
Bool16x8
:
case
MIRType
:
:
Bool32x4
:
masm
.
loadUnalignedSimd128Int
(
src
iter
-
>
fpu
(
)
)
;
break
;
case
MIRType
:
:
Float32x4
:
masm
.
loadUnalignedSimd128Float
(
src
iter
-
>
fpu
(
)
)
;
break
;
case
MIRType
:
:
Double
:
masm
.
loadDouble
(
src
iter
-
>
fpu
(
)
)
;
break
;
case
MIRType
:
:
Float32
:
masm
.
loadFloat32
(
src
iter
-
>
fpu
(
)
)
;
break
;
default
:
MOZ_MAKE_COMPILER_ASSUME_IS_UNREACHABLE
(
"
unexpected
FPU
type
"
)
;
break
;
}
break
;
}
case
ABIArg
:
:
Stack
:
switch
(
type
)
{
case
MIRType
:
:
Int32
:
masm
.
load32
(
src
scratch
)
;
masm
.
storePtr
(
scratch
Address
(
masm
.
getStackPointer
(
)
iter
-
>
offsetFromArgBase
(
)
)
)
;
break
;
case
MIRType
:
:
Int64
:
{
Register
sp
=
masm
.
getStackPointer
(
)
;
#
if
JS_BITS_PER_WORD
=
=
32
masm
.
load32
(
Address
(
src
.
base
src
.
offset
+
INT64LOW_OFFSET
)
scratch
)
;
masm
.
store32
(
scratch
Address
(
sp
iter
-
>
offsetFromArgBase
(
)
+
INT64LOW_OFFSET
)
)
;
masm
.
load32
(
Address
(
src
.
base
src
.
offset
+
INT64HIGH_OFFSET
)
scratch
)
;
masm
.
store32
(
scratch
Address
(
sp
iter
-
>
offsetFromArgBase
(
)
+
INT64HIGH_OFFSET
)
)
;
#
else
Register64
scratch64
(
scratch
)
;
masm
.
load64
(
src
scratch64
)
;
masm
.
store64
(
scratch64
Address
(
sp
iter
-
>
offsetFromArgBase
(
)
)
)
;
#
endif
break
;
}
case
MIRType
:
:
Double
:
masm
.
loadDouble
(
src
ScratchDoubleReg
)
;
masm
.
storeDouble
(
ScratchDoubleReg
Address
(
masm
.
getStackPointer
(
)
iter
-
>
offsetFromArgBase
(
)
)
)
;
break
;
case
MIRType
:
:
Float32
:
masm
.
loadFloat32
(
src
ScratchFloat32Reg
)
;
masm
.
storeFloat32
(
ScratchFloat32Reg
Address
(
masm
.
getStackPointer
(
)
iter
-
>
offsetFromArgBase
(
)
)
)
;
break
;
case
MIRType
:
:
Int8x16
:
case
MIRType
:
:
Int16x8
:
case
MIRType
:
:
Int32x4
:
case
MIRType
:
:
Bool8x16
:
case
MIRType
:
:
Bool16x8
:
case
MIRType
:
:
Bool32x4
:
masm
.
loadUnalignedSimd128Int
(
src
ScratchSimd128Reg
)
;
masm
.
storeAlignedSimd128Int
(
ScratchSimd128Reg
Address
(
masm
.
getStackPointer
(
)
iter
-
>
offsetFromArgBase
(
)
)
)
;
break
;
case
MIRType
:
:
Float32x4
:
masm
.
loadUnalignedSimd128Float
(
src
ScratchSimd128Reg
)
;
masm
.
storeAlignedSimd128Float
(
ScratchSimd128Reg
Address
(
masm
.
getStackPointer
(
)
iter
-
>
offsetFromArgBase
(
)
)
)
;
break
;
default
:
MOZ_MAKE_COMPILER_ASSUME_IS_UNREACHABLE
(
"
unexpected
stack
arg
type
"
)
;
}
break
;
}
}
masm
.
assertStackAlignment
(
AsmJSStackAlignment
)
;
masm
.
call
(
CallSiteDesc
(
CallSiteDesc
:
:
FuncDef
)
func
.
funcDefIndex
(
)
)
;
masm
.
loadWasmActivationFromTls
(
scratch
)
;
masm
.
loadStackPtr
(
Address
(
scratch
WasmActivation
:
:
offsetOfEntrySP
(
)
)
)
;
masm
.
setFramePushed
(
FramePushedForEntrySP
)
;
masm
.
Pop
(
argv
)
;
switch
(
func
.
sig
(
)
.
ret
(
)
)
{
case
ExprType
:
:
Void
:
break
;
case
ExprType
:
:
I32
:
masm
.
store32
(
ReturnReg
Address
(
argv
0
)
)
;
break
;
case
ExprType
:
:
I64
:
masm
.
store64
(
ReturnReg64
Address
(
argv
0
)
)
;
break
;
case
ExprType
:
:
F32
:
if
(
!
JitOptions
.
wasmTestMode
)
masm
.
canonicalizeFloat
(
ReturnFloat32Reg
)
;
masm
.
storeFloat32
(
ReturnFloat32Reg
Address
(
argv
0
)
)
;
break
;
case
ExprType
:
:
F64
:
if
(
!
JitOptions
.
wasmTestMode
)
masm
.
canonicalizeDouble
(
ReturnDoubleReg
)
;
masm
.
storeDouble
(
ReturnDoubleReg
Address
(
argv
0
)
)
;
break
;
case
ExprType
:
:
I8x16
:
case
ExprType
:
:
I16x8
:
case
ExprType
:
:
I32x4
:
case
ExprType
:
:
B8x16
:
case
ExprType
:
:
B16x8
:
case
ExprType
:
:
B32x4
:
masm
.
storeUnalignedSimd128Int
(
ReturnSimd128Reg
Address
(
argv
0
)
)
;
break
;
case
ExprType
:
:
F32x4
:
masm
.
storeUnalignedSimd128Float
(
ReturnSimd128Reg
Address
(
argv
0
)
)
;
break
;
case
ExprType
:
:
Limit
:
MOZ_CRASH
(
"
Limit
"
)
;
}
masm
.
PopRegsInMask
(
NonVolatileRegs
)
;
MOZ_ASSERT
(
masm
.
framePushed
(
)
=
=
0
)
;
masm
.
move32
(
Imm32
(
true
)
ReturnReg
)
;
masm
.
ret
(
)
;
offsets
.
end
=
masm
.
currentOffset
(
)
;
return
offsets
;
}
typedef
bool
ToValue
;
static
void
FillArgumentArray
(
MacroAssembler
&
masm
const
ValTypeVector
&
args
unsigned
argOffset
unsigned
offsetToCallerStackArgs
Register
scratch
ToValue
toValue
)
{
for
(
ABIArgValTypeIter
i
(
args
)
;
!
i
.
done
(
)
;
i
+
+
)
{
Address
dstAddr
(
masm
.
getStackPointer
(
)
argOffset
+
i
.
index
(
)
*
sizeof
(
Value
)
)
;
MIRType
type
=
i
.
mirType
(
)
;
switch
(
i
-
>
kind
(
)
)
{
case
ABIArg
:
:
GPR
:
if
(
type
=
=
MIRType
:
:
Int32
)
{
if
(
toValue
)
masm
.
storeValue
(
JSVAL_TYPE_INT32
i
-
>
gpr
(
)
dstAddr
)
;
else
masm
.
store32
(
i
-
>
gpr
(
)
dstAddr
)
;
}
else
if
(
type
=
=
MIRType
:
:
Int64
)
{
if
(
toValue
)
masm
.
breakpoint
(
)
;
else
masm
.
store64
(
i
-
>
gpr64
(
)
dstAddr
)
;
}
else
{
MOZ_CRASH
(
"
unexpected
input
type
?
"
)
;
}
break
;
#
ifdef
JS_CODEGEN_REGISTER_PAIR
case
ABIArg
:
:
GPR_PAIR
:
if
(
type
=
=
MIRType
:
:
Int64
)
masm
.
store64
(
i
-
>
gpr64
(
)
dstAddr
)
;
else
MOZ_CRASH
(
"
AsmJS
uses
hardfp
for
function
calls
.
"
)
;
break
;
#
endif
case
ABIArg
:
:
FPU
:
{
MOZ_ASSERT
(
IsFloatingPointType
(
type
)
)
;
FloatRegister
srcReg
=
i
-
>
fpu
(
)
;
if
(
type
=
=
MIRType
:
:
Double
)
{
if
(
toValue
)
{
masm
.
moveDouble
(
srcReg
ScratchDoubleReg
)
;
srcReg
=
ScratchDoubleReg
;
masm
.
canonicalizeDouble
(
srcReg
)
;
}
masm
.
storeDouble
(
srcReg
dstAddr
)
;
}
else
{
MOZ_ASSERT
(
type
=
=
MIRType
:
:
Float32
)
;
if
(
toValue
)
{
masm
.
convertFloat32ToDouble
(
srcReg
ScratchDoubleReg
)
;
masm
.
canonicalizeDouble
(
ScratchDoubleReg
)
;
masm
.
storeDouble
(
ScratchDoubleReg
dstAddr
)
;
}
else
{
masm
.
moveFloat32
(
srcReg
ScratchFloat32Reg
)
;
masm
.
canonicalizeFloat
(
ScratchFloat32Reg
)
;
masm
.
storeFloat32
(
ScratchFloat32Reg
dstAddr
)
;
}
}
break
;
}
case
ABIArg
:
:
Stack
:
if
(
type
=
=
MIRType
:
:
Int32
)
{
Address
src
(
masm
.
getStackPointer
(
)
offsetToCallerStackArgs
+
i
-
>
offsetFromArgBase
(
)
)
;
masm
.
load32
(
src
scratch
)
;
if
(
toValue
)
masm
.
storeValue
(
JSVAL_TYPE_INT32
scratch
dstAddr
)
;
else
masm
.
store32
(
scratch
dstAddr
)
;
}
else
if
(
type
=
=
MIRType
:
:
Int64
)
{
if
(
toValue
)
{
masm
.
breakpoint
(
)
;
}
else
{
Address
src
(
masm
.
getStackPointer
(
)
offsetToCallerStackArgs
+
i
-
>
offsetFromArgBase
(
)
)
;
#
if
JS_BITS_PER_WORD
=
=
32
masm
.
load32
(
Address
(
src
.
base
src
.
offset
+
INT64LOW_OFFSET
)
scratch
)
;
masm
.
store32
(
scratch
Address
(
dstAddr
.
base
dstAddr
.
offset
+
INT64LOW_OFFSET
)
)
;
masm
.
load32
(
Address
(
src
.
base
src
.
offset
+
INT64HIGH_OFFSET
)
scratch
)
;
masm
.
store32
(
scratch
Address
(
dstAddr
.
base
dstAddr
.
offset
+
INT64HIGH_OFFSET
)
)
;
#
else
Register64
scratch64
(
scratch
)
;
masm
.
load64
(
src
scratch64
)
;
masm
.
store64
(
scratch64
dstAddr
)
;
#
endif
}
}
else
{
MOZ_ASSERT
(
IsFloatingPointType
(
type
)
)
;
Address
src
(
masm
.
getStackPointer
(
)
offsetToCallerStackArgs
+
i
-
>
offsetFromArgBase
(
)
)
;
if
(
toValue
)
{
if
(
type
=
=
MIRType
:
:
Float32
)
{
masm
.
loadFloat32
(
src
ScratchFloat32Reg
)
;
masm
.
convertFloat32ToDouble
(
ScratchFloat32Reg
ScratchDoubleReg
)
;
}
else
{
masm
.
loadDouble
(
src
ScratchDoubleReg
)
;
}
masm
.
canonicalizeDouble
(
ScratchDoubleReg
)
;
}
else
{
masm
.
loadDouble
(
src
ScratchDoubleReg
)
;
}
masm
.
storeDouble
(
ScratchDoubleReg
dstAddr
)
;
}
break
;
}
}
}
ProfilingOffsets
wasm
:
:
GenerateInterpExit
(
MacroAssembler
&
masm
const
FuncImport
&
fi
uint32_t
funcImportIndex
Label
*
throwLabel
)
{
const
Sig
&
sig
=
fi
.
sig
(
)
;
masm
.
setFramePushed
(
0
)
;
static
const
MIRType
typeArray
[
]
=
{
MIRType
:
:
Pointer
MIRType
:
:
Pointer
MIRType
:
:
Int32
MIRType
:
:
Pointer
}
;
MIRTypeVector
invokeArgTypes
;
MOZ_ALWAYS_TRUE
(
invokeArgTypes
.
append
(
typeArray
ArrayLength
(
typeArray
)
)
)
;
unsigned
argOffset
=
AlignBytes
(
StackArgBytes
(
invokeArgTypes
)
sizeof
(
double
)
)
;
unsigned
argBytes
=
Max
<
size_t
>
(
1
sig
.
args
(
)
.
length
(
)
)
*
sizeof
(
Value
)
;
unsigned
framePushed
=
StackDecrementForCall
(
masm
ABIStackAlignment
argOffset
+
argBytes
)
;
ProfilingOffsets
offsets
;
GenerateExitPrologue
(
masm
framePushed
ExitReason
:
:
ImportInterp
&
offsets
)
;
unsigned
offsetToCallerStackArgs
=
sizeof
(
AsmJSFrame
)
+
masm
.
framePushed
(
)
;
Register
scratch
=
ABINonArgReturnReg0
;
FillArgumentArray
(
masm
sig
.
args
(
)
argOffset
offsetToCallerStackArgs
scratch
ToValue
(
false
)
)
;
ABIArgMIRTypeIter
i
(
invokeArgTypes
)
;
Address
instancePtr
(
WasmTlsReg
offsetof
(
TlsData
instance
)
)
;
if
(
i
-
>
kind
(
)
=
=
ABIArg
:
:
GPR
)
{
masm
.
loadPtr
(
instancePtr
i
-
>
gpr
(
)
)
;
}
else
{
masm
.
loadPtr
(
instancePtr
scratch
)
;
masm
.
storePtr
(
scratch
Address
(
masm
.
getStackPointer
(
)
i
-
>
offsetFromArgBase
(
)
)
)
;
}
i
+
+
;
if
(
i
-
>
kind
(
)
=
=
ABIArg
:
:
GPR
)
masm
.
mov
(
ImmWord
(
funcImportIndex
)
i
-
>
gpr
(
)
)
;
else
masm
.
store32
(
Imm32
(
funcImportIndex
)
Address
(
masm
.
getStackPointer
(
)
i
-
>
offsetFromArgBase
(
)
)
)
;
i
+
+
;
unsigned
argc
=
sig
.
args
(
)
.
length
(
)
;
if
(
i
-
>
kind
(
)
=
=
ABIArg
:
:
GPR
)
masm
.
mov
(
ImmWord
(
argc
)
i
-
>
gpr
(
)
)
;
else
masm
.
store32
(
Imm32
(
argc
)
Address
(
masm
.
getStackPointer
(
)
i
-
>
offsetFromArgBase
(
)
)
)
;
i
+
+
;
Address
argv
(
masm
.
getStackPointer
(
)
argOffset
)
;
if
(
i
-
>
kind
(
)
=
=
ABIArg
:
:
GPR
)
{
masm
.
computeEffectiveAddress
(
argv
i
-
>
gpr
(
)
)
;
}
else
{
masm
.
computeEffectiveAddress
(
argv
scratch
)
;
masm
.
storePtr
(
scratch
Address
(
masm
.
getStackPointer
(
)
i
-
>
offsetFromArgBase
(
)
)
)
;
}
i
+
+
;
MOZ_ASSERT
(
i
.
done
(
)
)
;
AssertStackAlignment
(
masm
ABIStackAlignment
)
;
switch
(
sig
.
ret
(
)
)
{
case
ExprType
:
:
Void
:
masm
.
call
(
SymbolicAddress
:
:
CallImport_Void
)
;
masm
.
branchTest32
(
Assembler
:
:
Zero
ReturnReg
ReturnReg
throwLabel
)
;
break
;
case
ExprType
:
:
I32
:
masm
.
call
(
SymbolicAddress
:
:
CallImport_I32
)
;
masm
.
branchTest32
(
Assembler
:
:
Zero
ReturnReg
ReturnReg
throwLabel
)
;
masm
.
load32
(
argv
ReturnReg
)
;
break
;
case
ExprType
:
:
I64
:
masm
.
call
(
SymbolicAddress
:
:
CallImport_I64
)
;
masm
.
branchTest32
(
Assembler
:
:
Zero
ReturnReg
ReturnReg
throwLabel
)
;
masm
.
load64
(
argv
ReturnReg64
)
;
break
;
case
ExprType
:
:
F32
:
masm
.
call
(
SymbolicAddress
:
:
CallImport_F64
)
;
masm
.
branchTest32
(
Assembler
:
:
Zero
ReturnReg
ReturnReg
throwLabel
)
;
masm
.
loadDouble
(
argv
ReturnDoubleReg
)
;
masm
.
convertDoubleToFloat32
(
ReturnDoubleReg
ReturnFloat32Reg
)
;
break
;
case
ExprType
:
:
F64
:
masm
.
call
(
SymbolicAddress
:
:
CallImport_F64
)
;
masm
.
branchTest32
(
Assembler
:
:
Zero
ReturnReg
ReturnReg
throwLabel
)
;
masm
.
loadDouble
(
argv
ReturnDoubleReg
)
;
break
;
case
ExprType
:
:
I8x16
:
case
ExprType
:
:
I16x8
:
case
ExprType
:
:
I32x4
:
case
ExprType
:
:
F32x4
:
case
ExprType
:
:
B8x16
:
case
ExprType
:
:
B16x8
:
case
ExprType
:
:
B32x4
:
MOZ_CRASH
(
"
SIMD
types
shouldn
'
t
be
returned
from
a
FFI
"
)
;
case
ExprType
:
:
Limit
:
MOZ_CRASH
(
"
Limit
"
)
;
}
MOZ_ASSERT
(
NonVolatileRegs
.
has
(
WasmTlsReg
)
)
;
#
if
defined
(
JS_CODEGEN_X64
)
|
|
\
defined
(
JS_CODEGEN_ARM
)
|
|
defined
(
JS_CODEGEN_ARM64
)
|
|
\
defined
(
JS_CODEGEN_MIPS32
)
|
|
defined
(
JS_CODEGEN_MIPS64
)
MOZ_ASSERT
(
NonVolatileRegs
.
has
(
HeapReg
)
)
;
#
endif
#
if
defined
(
JS_CODEGEN_ARM
)
|
|
defined
(
JS_CODEGEN_ARM64
)
|
|
\
defined
(
JS_CODEGEN_MIPS32
)
|
|
defined
(
JS_CODEGEN_MIPS64
)
MOZ_ASSERT
(
NonVolatileRegs
.
has
(
GlobalReg
)
)
;
#
endif
GenerateExitEpilogue
(
masm
framePushed
ExitReason
:
:
ImportInterp
&
offsets
)
;
offsets
.
end
=
masm
.
currentOffset
(
)
;
return
offsets
;
}
static
const
unsigned
SavedTlsReg
=
sizeof
(
void
*
)
;
ProfilingOffsets
wasm
:
:
GenerateJitExit
(
MacroAssembler
&
masm
const
FuncImport
&
fi
Label
*
throwLabel
)
{
const
Sig
&
sig
=
fi
.
sig
(
)
;
masm
.
setFramePushed
(
0
)
;
static_assert
(
AsmJSStackAlignment
>
=
JitStackAlignment
"
subsumes
"
)
;
unsigned
sizeOfRetAddr
=
sizeof
(
void
*
)
;
unsigned
jitFrameBytes
=
3
*
sizeof
(
void
*
)
+
(
1
+
sig
.
args
(
)
.
length
(
)
)
*
sizeof
(
Value
)
;
unsigned
totalJitFrameBytes
=
sizeOfRetAddr
+
jitFrameBytes
+
SavedTlsReg
;
unsigned
jitFramePushed
=
StackDecrementForCall
(
masm
JitStackAlignment
totalJitFrameBytes
)
-
sizeOfRetAddr
;
ProfilingOffsets
offsets
;
GenerateExitPrologue
(
masm
jitFramePushed
ExitReason
:
:
ImportJit
&
offsets
)
;
size_t
argOffset
=
0
;
uint32_t
descriptor
=
MakeFrameDescriptor
(
jitFramePushed
JitFrame_Entry
JitFrameLayout
:
:
Size
(
)
)
;
masm
.
storePtr
(
ImmWord
(
uintptr_t
(
descriptor
)
)
Address
(
masm
.
getStackPointer
(
)
argOffset
)
)
;
argOffset
+
=
sizeof
(
size_t
)
;
Register
callee
=
ABINonArgReturnReg0
;
Register
scratch
=
ABINonArgReturnReg1
;
masm
.
loadWasmGlobalPtr
(
fi
.
tlsDataOffset
(
)
+
offsetof
(
FuncImportTls
obj
)
callee
)
;
masm
.
storePtr
(
callee
Address
(
masm
.
getStackPointer
(
)
argOffset
)
)
;
argOffset
+
=
sizeof
(
size_t
)
;
masm
.
loadPtr
(
Address
(
callee
JSFunction
:
:
offsetOfNativeOrScript
(
)
)
callee
)
;
masm
.
loadBaselineOrIonNoArgCheck
(
callee
callee
nullptr
)
;
unsigned
argc
=
sig
.
args
(
)
.
length
(
)
;
masm
.
storePtr
(
ImmWord
(
uintptr_t
(
argc
)
)
Address
(
masm
.
getStackPointer
(
)
argOffset
)
)
;
argOffset
+
=
sizeof
(
size_t
)
;
masm
.
storeValue
(
UndefinedValue
(
)
Address
(
masm
.
getStackPointer
(
)
argOffset
)
)
;
argOffset
+
=
sizeof
(
Value
)
;
unsigned
offsetToCallerStackArgs
=
jitFramePushed
+
sizeof
(
AsmJSFrame
)
;
FillArgumentArray
(
masm
sig
.
args
(
)
argOffset
offsetToCallerStackArgs
scratch
ToValue
(
true
)
)
;
argOffset
+
=
sig
.
args
(
)
.
length
(
)
*
sizeof
(
Value
)
;
MOZ_ASSERT
(
argOffset
=
=
jitFrameBytes
)
;
static_assert
(
SavedTlsReg
=
=
sizeof
(
void
*
)
"
stack
frame
accounting
"
)
;
masm
.
storePtr
(
WasmTlsReg
Address
(
masm
.
getStackPointer
(
)
jitFrameBytes
)
)
;
{
MOZ_ASSERT
(
callee
=
=
AsmJSIonExitRegCallee
)
;
Register
cx
=
AsmJSIonExitRegE0
;
Register
act
=
AsmJSIonExitRegE1
;
masm
.
movePtr
(
SymbolicAddress
:
:
Context
cx
)
;
masm
.
loadPtr
(
Address
(
cx
JSContext
:
:
offsetOfActivation
(
)
)
act
)
;
masm
.
store8
(
Imm32
(
1
)
Address
(
act
JitActivation
:
:
offsetOfActiveUint8
(
)
)
)
;
masm
.
storePtr
(
act
Address
(
cx
offsetof
(
JSContext
jitActivation
)
)
)
;
masm
.
storePtr
(
act
Address
(
cx
JSContext
:
:
offsetOfProfilingActivation
(
)
)
)
;
}
AssertStackAlignment
(
masm
JitStackAlignment
sizeOfRetAddr
)
;
masm
.
callJitNoProfiler
(
callee
)
;
AssertStackAlignment
(
masm
JitStackAlignment
sizeOfRetAddr
)
;
{
MOZ_ASSERT
(
JSReturnReg_Data
=
=
AsmJSIonExitRegReturnData
)
;
MOZ_ASSERT
(
JSReturnReg_Type
=
=
AsmJSIonExitRegReturnType
)
;
Register
cx
=
AsmJSIonExitRegD0
;
Register
act
=
AsmJSIonExitRegD1
;
Register
tmp
=
AsmJSIonExitRegD2
;
masm
.
movePtr
(
SymbolicAddress
:
:
Context
cx
)
;
masm
.
loadPtr
(
Address
(
cx
JSContext
:
:
offsetOfActivation
(
)
)
act
)
;
masm
.
loadPtr
(
Address
(
act
JitActivation
:
:
offsetOfPrevJitTop
(
)
)
tmp
)
;
masm
.
storePtr
(
tmp
Address
(
cx
offsetof
(
JSContext
jitTop
)
)
)
;
masm
.
loadPtr
(
Address
(
act
JitActivation
:
:
offsetOfPrevJitActivation
(
)
)
tmp
)
;
masm
.
storePtr
(
tmp
Address
(
cx
offsetof
(
JSContext
jitActivation
)
)
)
;
masm
.
loadPtr
(
Address
(
act
Activation
:
:
offsetOfPrevProfiling
(
)
)
tmp
)
;
masm
.
storePtr
(
tmp
Address
(
cx
JSContext
:
:
offsetOfProfilingActivation
(
)
)
)
;
masm
.
store8
(
Imm32
(
0
)
Address
(
act
JitActivation
:
:
offsetOfActiveUint8
(
)
)
)
;
}
static_assert
(
ABIStackAlignment
<
=
JitStackAlignment
"
subsumes
"
)
;
masm
.
reserveStack
(
sizeOfRetAddr
)
;
unsigned
nativeFramePushed
=
masm
.
framePushed
(
)
;
AssertStackAlignment
(
masm
ABIStackAlignment
)
;
masm
.
branchTestMagic
(
Assembler
:
:
Equal
JSReturnOperand
throwLabel
)
;
Label
oolConvert
;
switch
(
sig
.
ret
(
)
)
{
case
ExprType
:
:
Void
:
break
;
case
ExprType
:
:
I32
:
masm
.
convertValueToInt32
(
JSReturnOperand
ReturnDoubleReg
ReturnReg
&
oolConvert
false
)
;
break
;
case
ExprType
:
:
I64
:
masm
.
breakpoint
(
)
;
break
;
case
ExprType
:
:
F32
:
masm
.
convertValueToFloat
(
JSReturnOperand
ReturnFloat32Reg
&
oolConvert
)
;
break
;
case
ExprType
:
:
F64
:
masm
.
convertValueToDouble
(
JSReturnOperand
ReturnDoubleReg
&
oolConvert
)
;
break
;
case
ExprType
:
:
I8x16
:
case
ExprType
:
:
I16x8
:
case
ExprType
:
:
I32x4
:
case
ExprType
:
:
F32x4
:
case
ExprType
:
:
B8x16
:
case
ExprType
:
:
B16x8
:
case
ExprType
:
:
B32x4
:
MOZ_CRASH
(
"
SIMD
types
shouldn
'
t
be
returned
from
an
import
"
)
;
case
ExprType
:
:
Limit
:
MOZ_CRASH
(
"
Limit
"
)
;
}
Label
done
;
masm
.
bind
(
&
done
)
;
masm
.
loadPtr
(
Address
(
masm
.
getStackPointer
(
)
jitFrameBytes
+
sizeOfRetAddr
)
WasmTlsReg
)
;
GenerateExitEpilogue
(
masm
masm
.
framePushed
(
)
ExitReason
:
:
ImportJit
&
offsets
)
;
if
(
oolConvert
.
used
(
)
)
{
masm
.
bind
(
&
oolConvert
)
;
masm
.
setFramePushed
(
nativeFramePushed
)
;
MIRTypeVector
coerceArgTypes
;
JS_ALWAYS_TRUE
(
coerceArgTypes
.
append
(
MIRType
:
:
Pointer
)
)
;
unsigned
offsetToCoerceArgv
=
AlignBytes
(
StackArgBytes
(
coerceArgTypes
)
sizeof
(
Value
)
)
;
MOZ_ASSERT
(
nativeFramePushed
>
=
offsetToCoerceArgv
+
sizeof
(
Value
)
)
;
AssertStackAlignment
(
masm
ABIStackAlignment
)
;
masm
.
storeValue
(
JSReturnOperand
Address
(
masm
.
getStackPointer
(
)
offsetToCoerceArgv
)
)
;
ABIArgMIRTypeIter
i
(
coerceArgTypes
)
;
Address
argv
(
masm
.
getStackPointer
(
)
offsetToCoerceArgv
)
;
if
(
i
-
>
kind
(
)
=
=
ABIArg
:
:
GPR
)
{
masm
.
computeEffectiveAddress
(
argv
i
-
>
gpr
(
)
)
;
}
else
{
masm
.
computeEffectiveAddress
(
argv
scratch
)
;
masm
.
storePtr
(
scratch
Address
(
masm
.
getStackPointer
(
)
i
-
>
offsetFromArgBase
(
)
)
)
;
}
i
+
+
;
MOZ_ASSERT
(
i
.
done
(
)
)
;
AssertStackAlignment
(
masm
ABIStackAlignment
)
;
switch
(
sig
.
ret
(
)
)
{
case
ExprType
:
:
I32
:
masm
.
call
(
SymbolicAddress
:
:
CoerceInPlace_ToInt32
)
;
masm
.
branchTest32
(
Assembler
:
:
Zero
ReturnReg
ReturnReg
throwLabel
)
;
masm
.
unboxInt32
(
Address
(
masm
.
getStackPointer
(
)
offsetToCoerceArgv
)
ReturnReg
)
;
break
;
case
ExprType
:
:
F64
:
masm
.
call
(
SymbolicAddress
:
:
CoerceInPlace_ToNumber
)
;
masm
.
branchTest32
(
Assembler
:
:
Zero
ReturnReg
ReturnReg
throwLabel
)
;
masm
.
loadDouble
(
Address
(
masm
.
getStackPointer
(
)
offsetToCoerceArgv
)
ReturnDoubleReg
)
;
break
;
case
ExprType
:
:
F32
:
masm
.
call
(
SymbolicAddress
:
:
CoerceInPlace_ToNumber
)
;
masm
.
branchTest32
(
Assembler
:
:
Zero
ReturnReg
ReturnReg
throwLabel
)
;
masm
.
loadDouble
(
Address
(
masm
.
getStackPointer
(
)
offsetToCoerceArgv
)
ReturnDoubleReg
)
;
masm
.
convertDoubleToFloat32
(
ReturnDoubleReg
ReturnFloat32Reg
)
;
break
;
default
:
MOZ_CRASH
(
"
Unsupported
convert
type
"
)
;
}
masm
.
jump
(
&
done
)
;
masm
.
setFramePushed
(
0
)
;
}
MOZ_ASSERT
(
masm
.
framePushed
(
)
=
=
0
)
;
offsets
.
end
=
masm
.
currentOffset
(
)
;
return
offsets
;
}
static
Offsets
GenerateStackOverflow
(
MacroAssembler
&
masm
Label
*
throwLabel
)
{
masm
.
haltingAlign
(
CodeAlignment
)
;
Offsets
offsets
;
offsets
.
begin
=
masm
.
currentOffset
(
)
;
Register
activation
=
ABINonArgReturnReg0
;
masm
.
loadWasmActivationFromTls
(
activation
)
;
masm
.
storePtr
(
masm
.
getStackPointer
(
)
Address
(
activation
WasmActivation
:
:
offsetOfFP
(
)
)
)
;
if
(
uint32_t
d
=
StackDecrementForCall
(
ABIStackAlignment
sizeof
(
AsmJSFrame
)
ShadowStackSpace
)
)
masm
.
subFromStackPtr
(
Imm32
(
d
)
)
;
masm
.
assertStackAlignment
(
ABIStackAlignment
)
;
masm
.
call
(
SymbolicAddress
:
:
ReportOverRecursed
)
;
masm
.
jump
(
throwLabel
)
;
offsets
.
end
=
masm
.
currentOffset
(
)
;
return
offsets
;
}
static
Offsets
GenerateTrapStub
(
MacroAssembler
&
masm
Trap
reason
Label
*
throwLabel
)
{
masm
.
haltingAlign
(
CodeAlignment
)
;
Offsets
offsets
;
offsets
.
begin
=
masm
.
currentOffset
(
)
;
masm
.
andToStackPtr
(
Imm32
(
~
(
ABIStackAlignment
-
1
)
)
)
;
if
(
ShadowStackSpace
)
masm
.
subFromStackPtr
(
Imm32
(
ShadowStackSpace
)
)
;
MIRTypeVector
args
;
JS_ALWAYS_TRUE
(
args
.
append
(
MIRType
:
:
Int32
)
)
;
ABIArgMIRTypeIter
i
(
args
)
;
if
(
i
-
>
kind
(
)
=
=
ABIArg
:
:
GPR
)
{
masm
.
move32
(
Imm32
(
int32_t
(
reason
)
)
i
-
>
gpr
(
)
)
;
}
else
{
masm
.
store32
(
Imm32
(
int32_t
(
reason
)
)
Address
(
masm
.
getStackPointer
(
)
i
-
>
offsetFromArgBase
(
)
)
)
;
}
i
+
+
;
MOZ_ASSERT
(
i
.
done
(
)
)
;
masm
.
call
(
SymbolicAddress
:
:
HandleTrap
)
;
masm
.
jump
(
throwLabel
)
;
offsets
.
end
=
masm
.
currentOffset
(
)
;
return
offsets
;
}
Offsets
wasm
:
:
GenerateJumpTarget
(
MacroAssembler
&
masm
JumpTarget
target
Label
*
throwLabel
)
{
switch
(
target
)
{
case
JumpTarget
:
:
StackOverflow
:
return
GenerateStackOverflow
(
masm
throwLabel
)
;
case
JumpTarget
:
:
IndirectCallToNull
:
case
JumpTarget
:
:
IndirectCallBadSig
:
case
JumpTarget
:
:
OutOfBounds
:
case
JumpTarget
:
:
UnalignedAccess
:
case
JumpTarget
:
:
Unreachable
:
case
JumpTarget
:
:
IntegerOverflow
:
case
JumpTarget
:
:
InvalidConversionToInteger
:
case
JumpTarget
:
:
IntegerDivideByZero
:
case
JumpTarget
:
:
ImpreciseSimdConversion
:
return
GenerateTrapStub
(
masm
Trap
(
target
)
throwLabel
)
;
case
JumpTarget
:
:
Limit
:
break
;
}
MOZ_CRASH
(
"
bad
JumpTarget
"
)
;
}
static
const
LiveRegisterSet
AllRegsExceptSP
(
GeneralRegisterSet
(
Registers
:
:
AllMask
&
~
(
uint32_t
(
1
)
<
<
Registers
:
:
StackPointer
)
)
FloatRegisterSet
(
FloatRegisters
:
:
AllMask
)
)
;
Offsets
wasm
:
:
GenerateInterruptStub
(
MacroAssembler
&
masm
Label
*
throwLabel
)
{
masm
.
haltingAlign
(
CodeAlignment
)
;
Offsets
offsets
;
offsets
.
begin
=
masm
.
currentOffset
(
)
;
#
if
defined
(
JS_CODEGEN_X86
)
|
|
defined
(
JS_CODEGEN_X64
)
masm
.
push
(
Imm32
(
0
)
)
;
masm
.
pushFlags
(
)
;
masm
.
setFramePushed
(
0
)
;
masm
.
PushRegsInMask
(
AllRegsExceptSP
)
;
Register
scratch
=
ABINonArgReturnReg0
;
masm
.
loadWasmActivationFromSymbolicAddress
(
scratch
)
;
masm
.
loadPtr
(
Address
(
scratch
WasmActivation
:
:
offsetOfResumePC
(
)
)
scratch
)
;
masm
.
storePtr
(
scratch
Address
(
masm
.
getStackPointer
(
)
masm
.
framePushed
(
)
+
sizeof
(
void
*
)
)
)
;
masm
.
moveStackPtrTo
(
ABINonVolatileReg
)
;
masm
.
andToStackPtr
(
Imm32
(
~
(
ABIStackAlignment
-
1
)
)
)
;
if
(
ShadowStackSpace
)
masm
.
subFromStackPtr
(
Imm32
(
ShadowStackSpace
)
)
;
masm
.
assertStackAlignment
(
ABIStackAlignment
)
;
masm
.
call
(
SymbolicAddress
:
:
HandleExecutionInterrupt
)
;
masm
.
branchIfFalseBool
(
ReturnReg
throwLabel
)
;
masm
.
moveToStackPtr
(
ABINonVolatileReg
)
;
masm
.
PopRegsInMask
(
AllRegsExceptSP
)
;
masm
.
popFlags
(
)
;
masm
.
ret
(
)
;
#
elif
defined
(
JS_CODEGEN_MIPS32
)
|
|
defined
(
JS_CODEGEN_MIPS64
)
masm
.
subFromStackPtr
(
Imm32
(
2
*
sizeof
(
intptr_t
)
)
)
;
masm
.
setFramePushed
(
0
)
;
static_assert
(
!
SupportsSimd
"
high
lanes
of
SIMD
registers
need
to
be
saved
too
.
"
)
;
masm
.
PushRegsInMask
(
AllRegsExceptSP
)
;
masm
.
moveStackPtrTo
(
s0
)
;
masm
.
ma_and
(
StackPointer
StackPointer
Imm32
(
~
(
ABIStackAlignment
-
1
)
)
)
;
masm
.
loadWasmActivationFromSymbolicAddress
(
IntArgReg0
)
;
masm
.
loadPtr
(
Address
(
IntArgReg0
WasmActivation
:
:
offsetOfResumePC
(
)
)
IntArgReg1
)
;
masm
.
storePtr
(
IntArgReg1
Address
(
s0
masm
.
framePushed
(
)
)
)
;
masm
.
storePtr
(
HeapReg
Address
(
s0
masm
.
framePushed
(
)
+
sizeof
(
intptr_t
)
)
)
;
#
ifdef
USES_O32_ABI
masm
.
subFromStackPtr
(
Imm32
(
4
*
sizeof
(
intptr_t
)
)
)
;
#
endif
masm
.
assertStackAlignment
(
ABIStackAlignment
)
;
masm
.
call
(
SymbolicAddress
:
:
HandleExecutionInterrupt
)
;
#
ifdef
USES_O32_ABI
masm
.
addToStackPtr
(
Imm32
(
4
*
sizeof
(
intptr_t
)
)
)
;
#
endif
masm
.
branchIfFalseBool
(
ReturnReg
throwLabel
)
;
masm
.
moveToStackPtr
(
s0
)
;
masm
.
PopRegsInMask
(
AllRegsExceptSP
)
;
masm
.
loadPtr
(
Address
(
StackPointer
0
)
HeapReg
)
;
masm
.
addToStackPtr
(
Imm32
(
2
*
sizeof
(
intptr_t
)
)
)
;
masm
.
as_jr
(
HeapReg
)
;
masm
.
loadPtr
(
Address
(
StackPointer
-
sizeof
(
intptr_t
)
)
HeapReg
)
;
#
elif
defined
(
JS_CODEGEN_ARM
)
masm
.
setFramePushed
(
0
)
;
masm
.
PushRegsInMask
(
LiveRegisterSet
(
GeneralRegisterSet
(
Registers
:
:
AllMask
&
~
(
1
<
<
Registers
:
:
sp
)
)
FloatRegisterSet
(
uint32_t
(
0
)
)
)
)
;
masm
.
as_mrs
(
r4
)
;
masm
.
as_vmrs
(
r5
)
;
masm
.
mov
(
sp
r6
)
;
masm
.
as_bic
(
sp
sp
Imm8
(
7
)
)
;
masm
.
loadWasmActivationFromSymbolicAddress
(
IntArgReg0
)
;
masm
.
loadPtr
(
Address
(
IntArgReg0
WasmActivation
:
:
offsetOfResumePC
(
)
)
IntArgReg1
)
;
masm
.
storePtr
(
IntArgReg1
Address
(
r6
14
*
sizeof
(
uint32_t
*
)
)
)
;
static_assert
(
!
SupportsSimd
"
high
lanes
of
SIMD
registers
need
to
be
saved
too
.
"
)
;
masm
.
PushRegsInMask
(
LiveRegisterSet
(
GeneralRegisterSet
(
0
)
FloatRegisterSet
(
FloatRegisters
:
:
AllDoubleMask
)
)
)
;
masm
.
assertStackAlignment
(
ABIStackAlignment
)
;
masm
.
call
(
SymbolicAddress
:
:
HandleExecutionInterrupt
)
;
masm
.
branchIfFalseBool
(
ReturnReg
throwLabel
)
;
masm
.
PopRegsInMask
(
LiveRegisterSet
(
GeneralRegisterSet
(
0
)
FloatRegisterSet
(
FloatRegisters
:
:
AllDoubleMask
)
)
)
;
masm
.
mov
(
r6
sp
)
;
masm
.
as_vmsr
(
r5
)
;
masm
.
as_msr
(
r4
)
;
masm
.
startDataTransferM
(
IsLoad
sp
IA
WriteBack
)
;
masm
.
transferReg
(
r0
)
;
masm
.
transferReg
(
r1
)
;
masm
.
transferReg
(
r2
)
;
masm
.
transferReg
(
r3
)
;
masm
.
transferReg
(
r4
)
;
masm
.
transferReg
(
r5
)
;
masm
.
transferReg
(
r6
)
;
masm
.
transferReg
(
r7
)
;
masm
.
transferReg
(
r8
)
;
masm
.
transferReg
(
r9
)
;
masm
.
transferReg
(
r10
)
;
masm
.
transferReg
(
r11
)
;
masm
.
transferReg
(
r12
)
;
masm
.
transferReg
(
lr
)
;
masm
.
finishDataTransfer
(
)
;
masm
.
ret
(
)
;
#
elif
defined
(
JS_CODEGEN_ARM64
)
MOZ_CRASH
(
)
;
#
elif
defined
(
JS_CODEGEN_NONE
)
MOZ_CRASH
(
)
;
#
else
#
error
"
Unknown
architecture
!
"
#
endif
offsets
.
end
=
masm
.
currentOffset
(
)
;
return
offsets
;
}
Offsets
wasm
:
:
GenerateThrowStub
(
MacroAssembler
&
masm
Label
*
throwLabel
)
{
masm
.
haltingAlign
(
CodeAlignment
)
;
masm
.
bind
(
throwLabel
)
;
Offsets
offsets
;
offsets
.
begin
=
masm
.
currentOffset
(
)
;
Register
scratch
=
ABINonArgReturnReg0
;
masm
.
loadWasmActivationFromSymbolicAddress
(
scratch
)
;
masm
.
storePtr
(
ImmWord
(
0
)
Address
(
scratch
WasmActivation
:
:
offsetOfFP
(
)
)
)
;
masm
.
setFramePushed
(
FramePushedForEntrySP
)
;
masm
.
loadStackPtr
(
Address
(
scratch
WasmActivation
:
:
offsetOfEntrySP
(
)
)
)
;
masm
.
Pop
(
scratch
)
;
masm
.
PopRegsInMask
(
NonVolatileRegs
)
;
MOZ_ASSERT
(
masm
.
framePushed
(
)
=
=
0
)
;
masm
.
mov
(
ImmWord
(
0
)
ReturnReg
)
;
masm
.
ret
(
)
;
offsets
.
end
=
masm
.
currentOffset
(
)
;
return
offsets
;
}
