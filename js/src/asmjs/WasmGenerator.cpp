#
include
"
asmjs
/
WasmGenerator
.
h
"
#
include
"
mozilla
/
CheckedInt
.
h
"
#
include
"
mozilla
/
EnumeratedRange
.
h
"
#
include
"
asmjs
/
WasmBaselineCompile
.
h
"
#
include
"
asmjs
/
WasmIonCompile
.
h
"
#
include
"
asmjs
/
WasmStubs
.
h
"
#
include
"
jit
/
MacroAssembler
-
inl
.
h
"
using
namespace
js
;
using
namespace
js
:
:
jit
;
using
namespace
js
:
:
wasm
;
using
mozilla
:
:
CheckedInt
;
using
mozilla
:
:
MakeEnumeratedRange
;
static
const
unsigned
GENERATOR_LIFO_DEFAULT_CHUNK_SIZE
=
4
*
1024
;
static
const
unsigned
COMPILATION_LIFO_DEFAULT_CHUNK_SIZE
=
64
*
1024
;
ModuleGenerator
:
:
ModuleGenerator
(
)
:
alwaysBaseline_
(
false
)
numSigs_
(
0
)
lifo_
(
GENERATOR_LIFO_DEFAULT_CHUNK_SIZE
)
masmAlloc_
(
&
lifo_
)
masm_
(
MacroAssembler
:
:
AsmJSToken
(
)
masmAlloc_
)
lastPatchedCallsite_
(
0
)
startOfUnpatchedBranches_
(
0
)
parallel_
(
false
)
outstanding_
(
0
)
activeFunc_
(
nullptr
)
startedFuncDefs_
(
false
)
finishedFuncDefs_
(
false
)
{
MOZ_ASSERT
(
IsCompilingAsmJS
(
)
)
;
}
ModuleGenerator
:
:
~
ModuleGenerator
(
)
{
if
(
parallel_
)
{
if
(
outstanding_
)
{
AutoLockHelperThreadState
lock
;
while
(
true
)
{
IonCompileTaskPtrVector
&
worklist
=
HelperThreadState
(
)
.
wasmWorklist
(
)
;
MOZ_ASSERT
(
outstanding_
>
=
worklist
.
length
(
)
)
;
outstanding_
-
=
worklist
.
length
(
)
;
worklist
.
clear
(
)
;
IonCompileTaskPtrVector
&
finished
=
HelperThreadState
(
)
.
wasmFinishedList
(
)
;
MOZ_ASSERT
(
outstanding_
>
=
finished
.
length
(
)
)
;
outstanding_
-
=
finished
.
length
(
)
;
finished
.
clear
(
)
;
uint32_t
numFailed
=
HelperThreadState
(
)
.
harvestFailedWasmJobs
(
)
;
MOZ_ASSERT
(
outstanding_
>
=
numFailed
)
;
outstanding_
-
=
numFailed
;
if
(
!
outstanding_
)
break
;
HelperThreadState
(
)
.
wait
(
lock
GlobalHelperThreadState
:
:
CONSUMER
)
;
}
}
MOZ_ASSERT
(
HelperThreadState
(
)
.
wasmCompilationInProgress
)
;
HelperThreadState
(
)
.
wasmCompilationInProgress
=
false
;
}
else
{
MOZ_ASSERT
(
!
outstanding_
)
;
}
}
bool
ModuleGenerator
:
:
init
(
UniqueModuleGeneratorData
shared
CompileArgs
&
&
args
Metadata
*
maybeAsmJSMetadata
)
{
alwaysBaseline_
=
args
.
alwaysBaseline
;
if
(
!
funcIndexToExport_
.
init
(
)
)
return
false
;
linkData_
.
globalDataLength
=
AlignBytes
(
InitialGlobalDataBytes
sizeof
(
void
*
)
)
;
;
if
(
maybeAsmJSMetadata
)
{
MOZ_ASSERT
(
shared
-
>
kind
=
=
ModuleKind
:
:
AsmJS
)
;
metadata_
=
maybeAsmJSMetadata
;
}
else
{
metadata_
=
js_new
<
Metadata
>
(
)
;
if
(
!
metadata_
)
return
false
;
}
metadata_
-
>
kind
=
shared
-
>
kind
;
metadata_
-
>
heapUsage
=
HeapUsage
:
:
None
;
metadata_
-
>
filename
=
Move
(
args
.
filename
)
;
metadata_
-
>
assumptions
=
Move
(
args
.
assumptions
)
;
shared_
=
Move
(
shared
)
;
if
(
!
isAsmJS
(
)
)
{
numSigs_
=
shared_
-
>
sigs
.
length
(
)
;
for
(
ImportModuleGeneratorData
&
import
:
shared_
-
>
imports
)
{
MOZ_ASSERT
(
!
import
.
globalDataOffset
)
;
import
.
globalDataOffset
=
linkData_
.
globalDataLength
;
linkData_
.
globalDataLength
+
=
sizeof
(
ImportExit
)
;
if
(
!
addImport
(
*
import
.
sig
import
.
globalDataOffset
)
)
return
false
;
}
MOZ_ASSERT
(
linkData_
.
globalDataLength
%
sizeof
(
void
*
)
=
=
0
)
;
MOZ_ASSERT
(
shared_
-
>
asmJSSigToTable
.
empty
(
)
)
;
MOZ_ASSERT
(
shared_
-
>
wasmTable
.
numElems
=
=
shared_
-
>
wasmTable
.
elemFuncIndices
.
length
(
)
)
;
MOZ_ASSERT
(
!
shared_
-
>
wasmTable
.
globalDataOffset
)
;
shared_
-
>
wasmTable
.
globalDataOffset
=
linkData_
.
globalDataLength
;
linkData_
.
globalDataLength
+
=
shared_
-
>
wasmTable
.
numElems
*
sizeof
(
void
*
)
;
}
return
true
;
}
bool
ModuleGenerator
:
:
finishOutstandingTask
(
)
{
MOZ_ASSERT
(
parallel_
)
;
IonCompileTask
*
task
=
nullptr
;
{
AutoLockHelperThreadState
lock
;
while
(
true
)
{
MOZ_ASSERT
(
outstanding_
>
0
)
;
if
(
HelperThreadState
(
)
.
wasmFailed
(
)
)
return
false
;
if
(
!
HelperThreadState
(
)
.
wasmFinishedList
(
)
.
empty
(
)
)
{
outstanding_
-
-
;
task
=
HelperThreadState
(
)
.
wasmFinishedList
(
)
.
popCopy
(
)
;
break
;
}
HelperThreadState
(
)
.
wait
(
lock
GlobalHelperThreadState
:
:
CONSUMER
)
;
}
}
return
finishTask
(
task
)
;
}
static
const
uint32_t
BadCodeRange
=
UINT32_MAX
;
bool
ModuleGenerator
:
:
funcIsDefined
(
uint32_t
funcIndex
)
const
{
return
funcIndex
<
funcIndexToCodeRange_
.
length
(
)
&
&
funcIndexToCodeRange_
[
funcIndex
]
!
=
BadCodeRange
;
}
const
CodeRange
&
ModuleGenerator
:
:
funcCodeRange
(
uint32_t
funcIndex
)
const
{
MOZ_ASSERT
(
funcIsDefined
(
funcIndex
)
)
;
const
CodeRange
&
cr
=
metadata_
-
>
codeRanges
[
funcIndexToCodeRange_
[
funcIndex
]
]
;
MOZ_ASSERT
(
cr
.
isFunction
(
)
)
;
return
cr
;
}
static
uint32_t
JumpRange
(
)
{
return
Min
(
JitOptions
.
jumpThreshold
JumpImmediateRange
)
;
}
typedef
HashMap
<
uint32_t
uint32_t
DefaultHasher
<
uint32_t
>
SystemAllocPolicy
>
OffsetMap
;
bool
ModuleGenerator
:
:
convertOutOfRangeBranchesToThunks
(
)
{
masm_
.
haltingAlign
(
CodeAlignment
)
;
OffsetMap
alreadyThunked
;
if
(
!
alreadyThunked
.
init
(
)
)
return
false
;
for
(
;
lastPatchedCallsite_
<
masm_
.
callSites
(
)
.
length
(
)
;
lastPatchedCallsite_
+
+
)
{
const
CallSiteAndTarget
&
cs
=
masm_
.
callSites
(
)
[
lastPatchedCallsite_
]
;
if
(
!
cs
.
isInternal
(
)
)
continue
;
uint32_t
callerOffset
=
cs
.
returnAddressOffset
(
)
;
MOZ_RELEASE_ASSERT
(
callerOffset
<
INT32_MAX
)
;
if
(
funcIsDefined
(
cs
.
targetIndex
(
)
)
)
{
uint32_t
calleeOffset
=
funcCodeRange
(
cs
.
targetIndex
(
)
)
.
funcNonProfilingEntry
(
)
;
MOZ_RELEASE_ASSERT
(
calleeOffset
<
INT32_MAX
)
;
if
(
uint32_t
(
abs
(
int32_t
(
calleeOffset
)
-
int32_t
(
callerOffset
)
)
)
<
JumpRange
(
)
)
{
masm_
.
patchCall
(
callerOffset
calleeOffset
)
;
continue
;
}
}
OffsetMap
:
:
AddPtr
p
=
alreadyThunked
.
lookupForAdd
(
cs
.
targetIndex
(
)
)
;
if
(
!
p
)
{
Offsets
offsets
;
offsets
.
begin
=
masm_
.
currentOffset
(
)
;
uint32_t
thunkOffset
=
masm_
.
thunkWithPatch
(
)
.
offset
(
)
;
if
(
masm_
.
oom
(
)
)
return
false
;
offsets
.
end
=
masm_
.
currentOffset
(
)
;
if
(
!
metadata_
-
>
codeRanges
.
emplaceBack
(
CodeRange
:
:
CallThunk
offsets
)
)
return
false
;
if
(
!
metadata_
-
>
callThunks
.
emplaceBack
(
thunkOffset
cs
.
targetIndex
(
)
)
)
return
false
;
if
(
!
alreadyThunked
.
add
(
p
cs
.
targetIndex
(
)
offsets
.
begin
)
)
return
false
;
}
masm_
.
patchCall
(
callerOffset
p
-
>
value
(
)
)
;
}
for
(
JumpTarget
target
:
MakeEnumeratedRange
(
JumpTarget
:
:
Limit
)
)
{
if
(
masm_
.
jumpSites
(
)
[
target
]
.
empty
(
)
)
continue
;
for
(
uint32_t
jumpSite
:
masm_
.
jumpSites
(
)
[
target
]
)
{
RepatchLabel
label
;
label
.
use
(
jumpSite
)
;
masm_
.
bind
(
&
label
)
;
}
Offsets
offsets
;
offsets
.
begin
=
masm_
.
currentOffset
(
)
;
uint32_t
thunkOffset
=
masm_
.
thunkWithPatch
(
)
.
offset
(
)
;
if
(
masm_
.
oom
(
)
)
return
false
;
offsets
.
end
=
masm_
.
currentOffset
(
)
;
if
(
!
metadata_
-
>
codeRanges
.
emplaceBack
(
CodeRange
:
:
Inline
offsets
)
)
return
false
;
if
(
!
jumpThunks_
[
target
]
.
append
(
thunkOffset
)
)
return
false
;
}
masm_
.
clearJumpSites
(
)
;
return
true
;
}
bool
ModuleGenerator
:
:
finishTask
(
IonCompileTask
*
task
)
{
const
FuncBytes
&
func
=
task
-
>
func
(
)
;
FuncCompileResults
&
results
=
task
-
>
results
(
)
;
if
(
(
masm_
.
size
(
)
-
startOfUnpatchedBranches_
)
+
results
.
masm
(
)
.
size
(
)
>
JumpRange
(
)
)
{
startOfUnpatchedBranches_
=
masm_
.
size
(
)
;
if
(
!
convertOutOfRangeBranchesToThunks
(
)
)
return
false
;
}
uint32_t
offsetInWhole
=
masm_
.
size
(
)
;
results
.
offsets
(
)
.
offsetBy
(
offsetInWhole
)
;
uint32_t
funcCodeRangeIndex
=
metadata_
-
>
codeRanges
.
length
(
)
;
if
(
!
metadata_
-
>
codeRanges
.
emplaceBack
(
func
.
index
(
)
func
.
lineOrBytecode
(
)
results
.
offsets
(
)
)
)
return
false
;
if
(
func
.
index
(
)
>
=
funcIndexToCodeRange_
.
length
(
)
)
{
uint32_t
n
=
func
.
index
(
)
-
funcIndexToCodeRange_
.
length
(
)
+
1
;
if
(
!
funcIndexToCodeRange_
.
appendN
(
BadCodeRange
n
)
)
return
false
;
}
MOZ_ASSERT
(
!
funcIsDefined
(
func
.
index
(
)
)
)
;
funcIndexToCodeRange_
[
func
.
index
(
)
]
=
funcCodeRangeIndex
;
mozilla
:
:
DebugOnly
<
size_t
>
sizeBefore
=
masm_
.
size
(
)
;
if
(
!
masm_
.
asmMergeWith
(
results
.
masm
(
)
)
)
return
false
;
MOZ_ASSERT
(
masm_
.
size
(
)
=
=
offsetInWhole
+
results
.
masm
(
)
.
size
(
)
)
;
freeTasks_
.
infallibleAppend
(
task
)
;
return
true
;
}
typedef
Vector
<
Offsets
0
SystemAllocPolicy
>
OffsetVector
;
typedef
Vector
<
ProfilingOffsets
0
SystemAllocPolicy
>
ProfilingOffsetVector
;
bool
ModuleGenerator
:
:
finishCodegen
(
)
{
uint32_t
offsetInWhole
=
masm_
.
size
(
)
;
OffsetVector
entries
;
ProfilingOffsetVector
interpExits
;
ProfilingOffsetVector
jitExits
;
EnumeratedArray
<
JumpTarget
JumpTarget
:
:
Limit
Offsets
>
jumpTargets
;
Offsets
interruptExit
;
{
TempAllocator
alloc
(
&
lifo_
)
;
MacroAssembler
masm
(
MacroAssembler
:
:
AsmJSToken
(
)
alloc
)
;
if
(
!
entries
.
resize
(
numExports
(
)
)
)
return
false
;
for
(
uint32_t
i
=
0
;
i
<
numExports
(
)
;
i
+
+
)
entries
[
i
]
=
GenerateEntry
(
masm
metadata_
-
>
exports
[
i
]
usesHeap
(
)
)
;
if
(
!
interpExits
.
resize
(
numImports
(
)
)
)
return
false
;
if
(
!
jitExits
.
resize
(
numImports
(
)
)
)
return
false
;
for
(
uint32_t
i
=
0
;
i
<
numImports
(
)
;
i
+
+
)
{
interpExits
[
i
]
=
GenerateInterpExit
(
masm
metadata_
-
>
imports
[
i
]
i
)
;
jitExits
[
i
]
=
GenerateJitExit
(
masm
metadata_
-
>
imports
[
i
]
usesHeap
(
)
)
;
}
for
(
JumpTarget
target
:
MakeEnumeratedRange
(
JumpTarget
:
:
Limit
)
)
jumpTargets
[
target
]
=
GenerateJumpTarget
(
masm
target
)
;
interruptExit
=
GenerateInterruptStub
(
masm
)
;
if
(
masm
.
oom
(
)
|
|
!
masm_
.
asmMergeWith
(
masm
)
)
return
false
;
}
for
(
uint32_t
i
=
0
;
i
<
numExports
(
)
;
i
+
+
)
{
entries
[
i
]
.
offsetBy
(
offsetInWhole
)
;
metadata_
-
>
exports
[
i
]
.
initStubOffset
(
entries
[
i
]
.
begin
)
;
if
(
!
metadata_
-
>
codeRanges
.
emplaceBack
(
CodeRange
:
:
Entry
entries
[
i
]
)
)
return
false
;
}
for
(
uint32_t
i
=
0
;
i
<
numImports
(
)
;
i
+
+
)
{
interpExits
[
i
]
.
offsetBy
(
offsetInWhole
)
;
metadata_
-
>
imports
[
i
]
.
initInterpExitOffset
(
interpExits
[
i
]
.
begin
)
;
if
(
!
metadata_
-
>
codeRanges
.
emplaceBack
(
CodeRange
:
:
ImportInterpExit
interpExits
[
i
]
)
)
return
false
;
jitExits
[
i
]
.
offsetBy
(
offsetInWhole
)
;
metadata_
-
>
imports
[
i
]
.
initJitExitOffset
(
jitExits
[
i
]
.
begin
)
;
if
(
!
metadata_
-
>
codeRanges
.
emplaceBack
(
CodeRange
:
:
ImportJitExit
jitExits
[
i
]
)
)
return
false
;
}
for
(
JumpTarget
target
:
MakeEnumeratedRange
(
JumpTarget
:
:
Limit
)
)
{
jumpTargets
[
target
]
.
offsetBy
(
offsetInWhole
)
;
if
(
!
metadata_
-
>
codeRanges
.
emplaceBack
(
CodeRange
:
:
Inline
jumpTargets
[
target
]
)
)
return
false
;
}
interruptExit
.
offsetBy
(
offsetInWhole
)
;
if
(
!
metadata_
-
>
codeRanges
.
emplaceBack
(
CodeRange
:
:
Inline
interruptExit
)
)
return
false
;
linkData_
.
outOfBoundsOffset
=
jumpTargets
[
JumpTarget
:
:
OutOfBounds
]
.
begin
;
linkData_
.
unalignedAccessOffset
=
jumpTargets
[
JumpTarget
:
:
UnalignedAccess
]
.
begin
;
linkData_
.
interruptOffset
=
interruptExit
.
begin
;
if
(
!
convertOutOfRangeBranchesToThunks
(
)
)
return
false
;
for
(
CallThunk
&
callThunk
:
metadata_
-
>
callThunks
)
{
uint32_t
funcIndex
=
callThunk
.
u
.
funcIndex
;
callThunk
.
u
.
codeRangeIndex
=
funcIndexToCodeRange_
[
funcIndex
]
;
masm_
.
patchThunk
(
callThunk
.
offset
funcCodeRange
(
funcIndex
)
.
funcNonProfilingEntry
(
)
)
;
}
for
(
JumpTarget
target
:
MakeEnumeratedRange
(
JumpTarget
:
:
Limit
)
)
{
for
(
uint32_t
thunkOffset
:
jumpThunks_
[
target
]
)
masm_
.
patchThunk
(
thunkOffset
jumpTargets
[
target
]
.
begin
)
;
}
masm_
.
finish
(
)
;
return
!
masm_
.
oom
(
)
;
}
bool
ModuleGenerator
:
:
finishLinkData
(
Bytes
&
code
)
{
linkData_
.
globalDataLength
=
AlignBytes
(
linkData_
.
globalDataLength
gc
:
:
SystemPageSize
(
)
)
;
for
(
size_t
i
=
0
;
i
<
masm_
.
numAsmJSAbsoluteAddresses
(
)
;
i
+
+
)
{
AsmJSAbsoluteAddress
src
=
masm_
.
asmJSAbsoluteAddress
(
i
)
;
if
(
!
linkData_
.
symbolicLinks
[
src
.
target
]
.
append
(
src
.
patchAt
.
offset
(
)
)
)
return
false
;
}
for
(
size_t
i
=
0
;
i
<
masm_
.
numCodeLabels
(
)
;
i
+
+
)
{
CodeLabel
cl
=
masm_
.
codeLabel
(
i
)
;
LinkData
:
:
InternalLink
inLink
(
LinkData
:
:
InternalLink
:
:
CodeLabel
)
;
inLink
.
patchAtOffset
=
masm_
.
labelToPatchOffset
(
*
cl
.
patchAt
(
)
)
;
inLink
.
targetOffset
=
cl
.
target
(
)
-
>
offset
(
)
;
if
(
!
linkData_
.
internalLinks
.
append
(
inLink
)
)
return
false
;
}
#
if
defined
(
JS_CODEGEN_X86
)
for
(
size_t
i
=
0
;
i
<
masm_
.
numAsmJSGlobalAccesses
(
)
;
i
+
+
)
{
AsmJSGlobalAccess
a
=
masm_
.
asmJSGlobalAccess
(
i
)
;
LinkData
:
:
InternalLink
inLink
(
LinkData
:
:
InternalLink
:
:
RawPointer
)
;
inLink
.
patchAtOffset
=
masm_
.
labelToPatchOffset
(
a
.
patchAt
)
;
inLink
.
targetOffset
=
code
.
length
(
)
+
a
.
globalDataOffset
;
if
(
!
linkData_
.
internalLinks
.
append
(
inLink
)
)
return
false
;
}
#
elif
defined
(
JS_CODEGEN_X64
)
for
(
size_t
i
=
0
;
i
<
masm_
.
numAsmJSGlobalAccesses
(
)
;
i
+
+
)
{
AsmJSGlobalAccess
a
=
masm_
.
asmJSGlobalAccess
(
i
)
;
void
*
from
=
code
.
begin
(
)
+
a
.
patchAt
.
offset
(
)
;
void
*
to
=
code
.
end
(
)
+
a
.
globalDataOffset
;
X86Encoding
:
:
SetRel32
(
from
to
)
;
}
#
else
MOZ_ASSERT
(
masm_
.
numAsmJSGlobalAccesses
(
)
=
=
0
)
;
#
endif
if
(
shared_
-
>
wasmTable
.
numElems
>
0
)
{
const
TableModuleGeneratorData
&
table
=
shared_
-
>
wasmTable
;
Uint32Vector
elemOffsets
;
for
(
size_t
i
=
0
;
i
<
table
.
elemFuncIndices
.
length
(
)
;
i
+
+
)
{
if
(
!
elemOffsets
.
append
(
funcCodeRange
(
table
.
elemFuncIndices
[
i
]
)
.
funcTableEntry
(
)
)
)
return
false
;
}
if
(
!
linkData_
.
funcTables
.
emplaceBack
(
table
.
globalDataOffset
Move
(
elemOffsets
)
)
)
return
false
;
}
for
(
const
TableModuleGeneratorData
&
table
:
shared_
-
>
asmJSSigToTable
)
{
if
(
table
.
elemFuncIndices
.
empty
(
)
)
continue
;
Uint32Vector
elemOffsets
;
for
(
size_t
i
=
0
;
i
<
table
.
elemFuncIndices
.
length
(
)
;
i
+
+
)
{
if
(
!
elemOffsets
.
append
(
funcCodeRange
(
table
.
elemFuncIndices
[
i
]
)
.
funcNonProfilingEntry
(
)
)
)
return
false
;
}
if
(
!
linkData_
.
funcTables
.
emplaceBack
(
table
.
globalDataOffset
Move
(
elemOffsets
)
)
)
return
false
;
}
return
true
;
}
bool
ModuleGenerator
:
:
addImport
(
const
Sig
&
sig
uint32_t
globalDataOffset
)
{
Sig
copy
;
if
(
!
copy
.
clone
(
sig
)
)
return
false
;
return
metadata_
-
>
imports
.
emplaceBack
(
Move
(
copy
)
globalDataOffset
)
;
}
bool
ModuleGenerator
:
:
allocateGlobalBytes
(
uint32_t
bytes
uint32_t
align
uint32_t
*
globalDataOffset
)
{
CheckedInt
<
uint32_t
>
newGlobalDataLength
(
linkData_
.
globalDataLength
)
;
newGlobalDataLength
+
=
ComputeByteAlignment
(
newGlobalDataLength
.
value
(
)
align
)
;
if
(
!
newGlobalDataLength
.
isValid
(
)
)
return
false
;
*
globalDataOffset
=
newGlobalDataLength
.
value
(
)
;
newGlobalDataLength
+
=
bytes
;
if
(
!
newGlobalDataLength
.
isValid
(
)
)
return
false
;
linkData_
.
globalDataLength
=
newGlobalDataLength
.
value
(
)
;
return
true
;
}
bool
ModuleGenerator
:
:
allocateGlobal
(
ValType
type
bool
isConst
uint32_t
*
index
)
{
MOZ_ASSERT
(
!
startedFuncDefs_
)
;
unsigned
width
=
0
;
switch
(
type
)
{
case
ValType
:
:
I32
:
case
ValType
:
:
F32
:
width
=
4
;
break
;
case
ValType
:
:
I64
:
case
ValType
:
:
F64
:
width
=
8
;
break
;
case
ValType
:
:
I8x16
:
case
ValType
:
:
I16x8
:
case
ValType
:
:
I32x4
:
case
ValType
:
:
F32x4
:
case
ValType
:
:
B8x16
:
case
ValType
:
:
B16x8
:
case
ValType
:
:
B32x4
:
width
=
16
;
break
;
case
ValType
:
:
Limit
:
MOZ_CRASH
(
"
Limit
"
)
;
break
;
}
uint32_t
offset
;
if
(
!
allocateGlobalBytes
(
width
width
&
offset
)
)
return
false
;
*
index
=
shared_
-
>
globals
.
length
(
)
;
return
shared_
-
>
globals
.
append
(
GlobalDesc
(
type
offset
isConst
)
)
;
}
void
ModuleGenerator
:
:
initHeapUsage
(
HeapUsage
heapUsage
uint32_t
initialHeapLength
)
{
MOZ_ASSERT
(
metadata_
-
>
heapUsage
=
=
HeapUsage
:
:
None
)
;
metadata_
-
>
heapUsage
=
heapUsage
;
metadata_
-
>
initialHeapLength
=
initialHeapLength
;
if
(
isAsmJS
(
)
)
MOZ_ASSERT
(
initialHeapLength
=
=
0
)
;
else
shared_
-
>
minHeapLength
=
initialHeapLength
;
}
bool
ModuleGenerator
:
:
usesHeap
(
)
const
{
return
UsesHeap
(
metadata_
-
>
heapUsage
)
;
}
uint32_t
ModuleGenerator
:
:
initialHeapLength
(
)
const
{
MOZ_ASSERT
(
!
isAsmJS
(
)
)
;
return
metadata_
-
>
initialHeapLength
;
}
void
ModuleGenerator
:
:
initSig
(
uint32_t
sigIndex
Sig
&
&
sig
)
{
MOZ_ASSERT
(
isAsmJS
(
)
)
;
MOZ_ASSERT
(
sigIndex
=
=
numSigs_
)
;
numSigs_
+
+
;
MOZ_ASSERT
(
shared_
-
>
sigs
[
sigIndex
]
=
=
Sig
(
)
)
;
shared_
-
>
sigs
[
sigIndex
]
=
Move
(
sig
)
;
}
const
DeclaredSig
&
ModuleGenerator
:
:
sig
(
uint32_t
index
)
const
{
MOZ_ASSERT
(
index
<
numSigs_
)
;
return
shared_
-
>
sigs
[
index
]
;
}
void
ModuleGenerator
:
:
initFuncSig
(
uint32_t
funcIndex
uint32_t
sigIndex
)
{
MOZ_ASSERT
(
isAsmJS
(
)
)
;
MOZ_ASSERT
(
!
shared_
-
>
funcSigs
[
funcIndex
]
)
;
shared_
-
>
funcSigs
[
funcIndex
]
=
&
shared_
-
>
sigs
[
sigIndex
]
;
}
void
ModuleGenerator
:
:
bumpMinHeapLength
(
uint32_t
newMinHeapLength
)
{
MOZ_ASSERT
(
isAsmJS
(
)
)
;
MOZ_ASSERT
(
newMinHeapLength
>
=
shared_
-
>
minHeapLength
)
;
shared_
-
>
minHeapLength
=
newMinHeapLength
;
}
const
DeclaredSig
&
ModuleGenerator
:
:
funcSig
(
uint32_t
funcIndex
)
const
{
MOZ_ASSERT
(
shared_
-
>
funcSigs
[
funcIndex
]
)
;
return
*
shared_
-
>
funcSigs
[
funcIndex
]
;
}
bool
ModuleGenerator
:
:
initImport
(
uint32_t
importIndex
uint32_t
sigIndex
)
{
MOZ_ASSERT
(
isAsmJS
(
)
)
;
uint32_t
globalDataOffset
;
if
(
!
allocateGlobalBytes
(
sizeof
(
ImportExit
)
sizeof
(
void
*
)
&
globalDataOffset
)
)
return
false
;
MOZ_ASSERT
(
importIndex
=
=
metadata_
-
>
imports
.
length
(
)
)
;
if
(
!
addImport
(
sig
(
sigIndex
)
globalDataOffset
)
)
return
false
;
ImportModuleGeneratorData
&
import
=
shared_
-
>
imports
[
importIndex
]
;
MOZ_ASSERT
(
!
import
.
sig
)
;
import
.
sig
=
&
shared_
-
>
sigs
[
sigIndex
]
;
import
.
globalDataOffset
=
globalDataOffset
;
return
true
;
}
uint32_t
ModuleGenerator
:
:
numImports
(
)
const
{
return
metadata_
-
>
imports
.
length
(
)
;
}
const
ImportModuleGeneratorData
&
ModuleGenerator
:
:
import
(
uint32_t
index
)
const
{
MOZ_ASSERT
(
shared_
-
>
imports
[
index
]
.
sig
)
;
return
shared_
-
>
imports
[
index
]
;
}
bool
ModuleGenerator
:
:
declareExport
(
UniqueChars
fieldName
uint32_t
funcIndex
uint32_t
*
exportIndex
)
{
if
(
!
exportMap_
.
fieldNames
.
append
(
Move
(
fieldName
)
)
)
return
false
;
FuncIndexMap
:
:
AddPtr
p
=
funcIndexToExport_
.
lookupForAdd
(
funcIndex
)
;
if
(
p
)
{
if
(
exportIndex
)
*
exportIndex
=
p
-
>
value
(
)
;
return
exportMap_
.
fieldsToExports
.
append
(
p
-
>
value
(
)
)
;
}
uint32_t
newExportIndex
=
metadata_
-
>
exports
.
length
(
)
;
MOZ_ASSERT
(
newExportIndex
<
MaxExports
)
;
if
(
exportIndex
)
*
exportIndex
=
newExportIndex
;
Sig
copy
;
if
(
!
copy
.
clone
(
funcSig
(
funcIndex
)
)
)
return
false
;
return
metadata_
-
>
exports
.
emplaceBack
(
Move
(
copy
)
funcIndex
)
&
&
exportMap_
.
fieldsToExports
.
append
(
newExportIndex
)
&
&
funcIndexToExport_
.
add
(
p
funcIndex
newExportIndex
)
;
}
uint32_t
ModuleGenerator
:
:
numExports
(
)
const
{
return
metadata_
-
>
exports
.
length
(
)
;
}
bool
ModuleGenerator
:
:
addMemoryExport
(
UniqueChars
fieldName
)
{
return
exportMap_
.
fieldNames
.
append
(
Move
(
fieldName
)
)
&
&
exportMap_
.
fieldsToExports
.
append
(
MemoryExport
)
;
}
bool
ModuleGenerator
:
:
startFuncDefs
(
)
{
MOZ_ASSERT
(
!
startedFuncDefs_
)
;
MOZ_ASSERT
(
!
finishedFuncDefs_
)
;
GlobalHelperThreadState
&
threads
=
HelperThreadState
(
)
;
MOZ_ASSERT
(
threads
.
threadCount
>
1
)
;
uint32_t
numTasks
;
if
(
CanUseExtraThreads
(
)
&
&
threads
.
wasmCompilationInProgress
.
compareExchange
(
false
true
)
)
{
#
ifdef
DEBUG
{
AutoLockHelperThreadState
lock
;
MOZ_ASSERT
(
!
HelperThreadState
(
)
.
wasmFailed
(
)
)
;
MOZ_ASSERT
(
HelperThreadState
(
)
.
wasmWorklist
(
)
.
empty
(
)
)
;
MOZ_ASSERT
(
HelperThreadState
(
)
.
wasmFinishedList
(
)
.
empty
(
)
)
;
}
#
endif
parallel_
=
true
;
numTasks
=
threads
.
maxWasmCompilationThreads
(
)
;
}
else
{
numTasks
=
1
;
}
if
(
!
tasks_
.
initCapacity
(
numTasks
)
)
return
false
;
for
(
size_t
i
=
0
;
i
<
numTasks
;
i
+
+
)
tasks_
.
infallibleEmplaceBack
(
*
shared_
COMPILATION_LIFO_DEFAULT_CHUNK_SIZE
)
;
if
(
!
freeTasks_
.
reserve
(
numTasks
)
)
return
false
;
for
(
size_t
i
=
0
;
i
<
numTasks
;
i
+
+
)
freeTasks_
.
infallibleAppend
(
&
tasks_
[
i
]
)
;
startedFuncDefs_
=
true
;
MOZ_ASSERT
(
!
finishedFuncDefs_
)
;
return
true
;
}
bool
ModuleGenerator
:
:
startFuncDef
(
uint32_t
lineOrBytecode
FunctionGenerator
*
fg
)
{
MOZ_ASSERT
(
startedFuncDefs_
)
;
MOZ_ASSERT
(
!
activeFunc_
)
;
MOZ_ASSERT
(
!
finishedFuncDefs_
)
;
if
(
freeTasks_
.
empty
(
)
&
&
!
finishOutstandingTask
(
)
)
return
false
;
IonCompileTask
*
task
=
freeTasks_
.
popCopy
(
)
;
task
-
>
reset
(
&
fg
-
>
bytes_
)
;
fg
-
>
bytes_
.
clear
(
)
;
fg
-
>
lineOrBytecode_
=
lineOrBytecode
;
fg
-
>
m_
=
this
;
fg
-
>
task_
=
task
;
activeFunc_
=
fg
;
return
true
;
}
bool
ModuleGenerator
:
:
finishFuncDef
(
uint32_t
funcIndex
FunctionGenerator
*
fg
)
{
MOZ_ASSERT
(
activeFunc_
=
=
fg
)
;
auto
func
=
js
:
:
MakeUnique
<
FuncBytes
>
(
Move
(
fg
-
>
bytes_
)
funcIndex
funcSig
(
funcIndex
)
fg
-
>
lineOrBytecode_
Move
(
fg
-
>
callSiteLineNums_
)
)
;
if
(
!
func
)
return
false
;
auto
mode
=
alwaysBaseline_
&
&
BaselineCanCompile
(
fg
)
?
IonCompileTask
:
:
CompileMode
:
:
Baseline
:
IonCompileTask
:
:
CompileMode
:
:
Ion
;
fg
-
>
task_
-
>
init
(
Move
(
func
)
mode
)
;
if
(
parallel_
)
{
if
(
!
StartOffThreadWasmCompile
(
fg
-
>
task_
)
)
return
false
;
outstanding_
+
+
;
}
else
{
if
(
!
CompileFunction
(
fg
-
>
task_
)
)
return
false
;
if
(
!
finishTask
(
fg
-
>
task_
)
)
return
false
;
}
fg
-
>
m_
=
nullptr
;
fg
-
>
task_
=
nullptr
;
activeFunc_
=
nullptr
;
return
true
;
}
bool
ModuleGenerator
:
:
finishFuncDefs
(
)
{
MOZ_ASSERT
(
startedFuncDefs_
)
;
MOZ_ASSERT
(
!
activeFunc_
)
;
MOZ_ASSERT
(
!
finishedFuncDefs_
)
;
while
(
outstanding_
>
0
)
{
if
(
!
finishOutstandingTask
(
)
)
return
false
;
}
for
(
uint32_t
funcIndex
=
0
;
funcIndex
<
funcIndexToCodeRange_
.
length
(
)
;
funcIndex
+
+
)
MOZ_ASSERT
(
funcIsDefined
(
funcIndex
)
)
;
linkData_
.
functionCodeLength
=
masm_
.
size
(
)
;
finishedFuncDefs_
=
true
;
return
true
;
}
void
ModuleGenerator
:
:
setFuncNames
(
NameInBytecodeVector
&
&
funcNames
)
{
MOZ_ASSERT
(
metadata_
-
>
funcNames
.
empty
(
)
)
;
metadata_
-
>
funcNames
=
Move
(
funcNames
)
;
}
bool
ModuleGenerator
:
:
initSigTableLength
(
uint32_t
sigIndex
uint32_t
numElems
)
{
MOZ_ASSERT
(
isAsmJS
(
)
)
;
MOZ_ASSERT
(
numElems
!
=
0
)
;
MOZ_ASSERT
(
numElems
<
=
MaxTableElems
)
;
uint32_t
globalDataOffset
;
if
(
!
allocateGlobalBytes
(
numElems
*
sizeof
(
void
*
)
sizeof
(
void
*
)
&
globalDataOffset
)
)
return
false
;
TableModuleGeneratorData
&
table
=
shared_
-
>
asmJSSigToTable
[
sigIndex
]
;
MOZ_ASSERT
(
table
.
numElems
=
=
0
)
;
table
.
numElems
=
numElems
;
table
.
globalDataOffset
=
globalDataOffset
;
return
true
;
}
void
ModuleGenerator
:
:
initSigTableElems
(
uint32_t
sigIndex
Uint32Vector
&
&
elemFuncIndices
)
{
MOZ_ASSERT
(
isAsmJS
(
)
)
;
MOZ_ASSERT
(
!
elemFuncIndices
.
empty
(
)
)
;
TableModuleGeneratorData
&
table
=
shared_
-
>
asmJSSigToTable
[
sigIndex
]
;
MOZ_ASSERT
(
table
.
numElems
=
=
elemFuncIndices
.
length
(
)
)
;
MOZ_ASSERT
(
table
.
elemFuncIndices
.
empty
(
)
)
;
table
.
elemFuncIndices
=
Move
(
elemFuncIndices
)
;
}
UniqueModule
ModuleGenerator
:
:
finish
(
ImportNameVector
&
&
importNames
const
ShareableBytes
&
bytecode
)
{
MOZ_ASSERT
(
!
activeFunc_
)
;
MOZ_ASSERT
(
finishedFuncDefs_
)
;
if
(
!
finishCodegen
(
)
)
return
nullptr
;
uint32_t
bytesNeeded
=
masm_
.
bytesNeeded
(
)
;
uint32_t
padding
=
ComputeByteAlignment
(
bytesNeeded
gc
:
:
SystemPageSize
(
)
)
;
Bytes
code
;
if
(
!
code
.
initLengthUninitialized
(
bytesNeeded
+
padding
)
)
return
nullptr
;
{
AutoFlushICache
afc
(
"
ModuleGenerator
:
:
finish
"
true
)
;
masm_
.
executableCopy
(
code
.
begin
(
)
)
;
}
memset
(
code
.
begin
(
)
+
bytesNeeded
0
padding
)
;
if
(
!
metadata_
-
>
callSites
.
appendAll
(
masm_
.
callSites
(
)
)
)
return
nullptr
;
metadata_
-
>
memoryAccesses
=
masm_
.
extractMemoryAccesses
(
)
;
metadata_
-
>
boundsChecks
=
masm_
.
extractBoundsChecks
(
)
;
metadata_
-
>
memoryAccesses
.
podResizeToFit
(
)
;
metadata_
-
>
boundsChecks
.
podResizeToFit
(
)
;
metadata_
-
>
codeRanges
.
podResizeToFit
(
)
;
metadata_
-
>
callSites
.
podResizeToFit
(
)
;
metadata_
-
>
callThunks
.
podResizeToFit
(
)
;
#
ifdef
DEBUG
uint32_t
lastEnd
=
0
;
for
(
const
CodeRange
&
codeRange
:
metadata_
-
>
codeRanges
)
{
MOZ_ASSERT
(
codeRange
.
begin
(
)
>
=
lastEnd
)
;
lastEnd
=
codeRange
.
end
(
)
;
}
#
endif
if
(
!
finishLinkData
(
code
)
)
return
nullptr
;
return
js
:
:
MakeUnique
<
Module
>
(
Move
(
code
)
Move
(
linkData_
)
Move
(
importNames
)
Move
(
exportMap_
)
Move
(
dataSegments_
)
*
metadata_
bytecode
)
;
}
