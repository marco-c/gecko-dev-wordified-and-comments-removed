from
__future__
import
absolute_import
print_function
unicode_literals
import
os
import
re
from
collections
import
deque
import
taskgraph
from
taskgraph
.
transforms
.
base
import
TransformSequence
from
taskgraph
.
transforms
.
task
import
_run_task_suffix
from
.
.
import
GECKO
from
taskgraph
.
util
.
docker
import
(
    
generate_context_hash
)
from
taskgraph
.
util
.
taskcluster
import
get_root_url
from
taskgraph
.
util
.
schema
import
(
    
Schema
)
from
voluptuous
import
(
    
Optional
    
Required
)
from
.
task
import
task_description_schema
DIGEST_RE
=
re
.
compile
(
'
^
[
0
-
9a
-
f
]
{
64
}
'
)
transforms
=
TransformSequence
(
)
docker_image_schema
=
Schema
(
{
    
Required
(
'
name
'
)
:
basestring
    
Optional
(
'
parent
'
)
:
basestring
    
Required
(
'
symbol
'
)
:
basestring
    
Optional
(
'
job
-
from
'
)
:
basestring
    
Optional
(
'
args
'
)
:
{
basestring
:
basestring
}
    
Optional
(
'
definition
'
)
:
basestring
    
Optional
(
'
packages
'
)
:
[
basestring
]
    
Optional
(
        
"
index
"
        
description
=
"
information
for
indexing
this
build
so
its
artifacts
can
be
discovered
"
    
)
:
task_description_schema
[
'
index
'
]
    
Optional
(
        
"
cache
"
        
description
=
"
Whether
this
image
should
be
cached
based
on
inputs
.
"
    
)
:
bool
}
)
transforms
.
add_validate
(
docker_image_schema
)
def
order_image_tasks
(
config
tasks
)
:
    
"
"
"
Iterate
image
tasks
in
an
order
where
parent
images
come
first
.
"
"
"
    
pending
=
deque
(
tasks
)
    
task_names
=
{
task
[
'
name
'
]
for
task
in
pending
}
    
emitted
=
set
(
)
    
while
True
:
        
try
:
            
task
=
pending
.
popleft
(
)
        
except
IndexError
:
            
break
        
parent
=
task
.
get
(
'
parent
'
)
        
if
parent
and
parent
not
in
emitted
:
            
if
parent
not
in
task_names
:
                
raise
Exception
(
'
Missing
parent
image
for
{
}
-
{
}
:
{
}
'
.
format
(
                    
config
.
kind
task
[
'
name
'
]
parent
)
)
            
pending
.
append
(
task
)
            
continue
        
emitted
.
add
(
task
[
'
name
'
]
)
        
yield
task
transforms
.
add
def
fill_template
(
config
tasks
)
:
    
available_packages
=
set
(
)
    
for
task
in
config
.
kind_dependencies_tasks
:
        
if
task
.
kind
!
=
'
packages
'
:
            
continue
        
name
=
task
.
label
.
replace
(
'
packages
-
'
'
'
)
        
available_packages
.
add
(
name
)
    
context_hashes
=
{
}
    
for
task
in
order_image_tasks
(
config
tasks
)
:
        
image_name
=
task
.
pop
(
'
name
'
)
        
job_symbol
=
task
.
pop
(
'
symbol
'
)
        
args
=
task
.
pop
(
'
args
'
{
}
)
        
definition
=
task
.
pop
(
'
definition
'
image_name
)
        
packages
=
task
.
pop
(
'
packages
'
[
]
)
        
parent
=
task
.
pop
(
'
parent
'
None
)
        
for
p
in
packages
:
            
if
p
not
in
available_packages
:
                
raise
Exception
(
'
Missing
package
job
for
{
}
-
{
}
:
{
}
'
.
format
(
                    
config
.
kind
image_name
p
)
)
        
args
[
'
DOCKER_IMAGE_PACKAGES
'
]
=
'
'
.
join
(
'
<
{
}
>
'
.
format
(
p
)
                                                 
for
p
in
packages
)
        
if
parent
:
            
args
[
'
DOCKER_IMAGE_PARENT
'
]
=
'
{
}
:
{
}
'
.
format
(
parent
context_hashes
[
parent
]
)
        
args
[
'
TASKCLUSTER_ROOT_URL
'
]
=
get_root_url
(
)
        
if
not
taskgraph
.
fast
:
            
context_path
=
os
.
path
.
join
(
'
taskcluster
'
'
docker
'
definition
)
            
context_hash
=
generate_context_hash
(
                
GECKO
context_path
image_name
args
)
        
else
:
            
context_hash
=
'
0
'
*
40
        
digest_data
=
[
context_hash
]
        
context_hashes
[
image_name
]
=
context_hash
        
description
=
'
Build
the
docker
image
{
}
for
use
by
dependent
tasks
'
.
format
(
            
image_name
)
        
zstd_level
=
'
3
'
if
int
(
config
.
params
[
'
level
'
]
)
=
=
1
else
'
10
'
        
taskdesc
=
{
            
'
label
'
:
'
build
-
docker
-
image
-
'
+
image_name
            
'
description
'
:
description
            
'
attributes
'
:
{
'
image_name
'
:
image_name
}
            
'
expires
-
after
'
:
'
28
days
'
if
config
.
params
.
is_try
(
)
else
'
1
year
'
            
'
scopes
'
:
[
'
secrets
:
get
:
project
/
taskcluster
/
gecko
/
hgfingerprint
'
]
            
'
treeherder
'
:
{
                
'
symbol
'
:
job_symbol
                
'
platform
'
:
'
taskcluster
-
images
/
opt
'
                
'
kind
'
:
'
other
'
                
'
tier
'
:
1
            
}
            
'
run
-
on
-
projects
'
:
[
]
            
'
worker
-
type
'
:
'
aws
-
provisioner
-
v1
/
gecko
-
{
}
-
images
'
.
format
(
                
config
.
params
[
'
level
'
]
)
            
'
worker
'
:
{
                
'
implementation
'
:
'
docker
-
worker
'
                
'
os
'
:
'
linux
'
                
'
artifacts
'
:
[
{
                    
'
type
'
:
'
file
'
                    
'
path
'
:
'
/
builds
/
worker
/
workspace
/
artifacts
/
image
.
tar
.
zst
'
                    
'
name
'
:
'
public
/
image
.
tar
.
zst
'
                
}
]
                
'
env
'
:
{
                    
'
HG_STORE_PATH
'
:
'
/
builds
/
worker
/
checkouts
/
hg
-
store
'
                    
'
HASH
'
:
context_hash
                    
'
PROJECT
'
:
config
.
params
[
'
project
'
]
                    
'
IMAGE_NAME
'
:
image_name
                    
'
DOCKER_IMAGE_ZSTD_LEVEL
'
:
zstd_level
                    
'
GECKO_BASE_REPOSITORY
'
:
config
.
params
[
'
base_repository
'
]
                    
'
GECKO_HEAD_REPOSITORY
'
:
config
.
params
[
'
head_repository
'
]
                    
'
GECKO_HEAD_REV
'
:
config
.
params
[
'
head_rev
'
]
                
}
                
'
chain
-
of
-
trust
'
:
True
                
'
docker
-
in
-
docker
'
:
True
                
'
taskcluster
-
proxy
'
:
True
                
'
max
-
run
-
time
'
:
7200
                
'
retry
-
exit
-
status
'
:
[
100
]
            
}
        
}
        
if
image_name
in
[
'
funsize
-
update
-
generator
'
]
:
            
taskdesc
[
'
worker
'
]
[
'
retry
-
exit
-
status
'
]
=
[
-
1
]
        
worker
=
taskdesc
[
'
worker
'
]
        
if
image_name
=
=
'
image_builder
'
:
            
hash
=
'
sha256
:
c6622fd3e5794842ad83d129850330b26e6ba671e39c58ee288a616a3a1c4c73
'
            
worker
[
'
docker
-
image
'
]
=
'
taskcluster
/
image_builder
'
+
hash
            
worker
[
'
volumes
'
]
=
[
                
'
/
builds
/
worker
/
checkouts
'
                
'
/
builds
/
worker
/
workspace
'
            
]
            
cache_name
=
'
imagebuilder
-
v1
'
        
else
:
            
worker
[
'
docker
-
image
'
]
=
{
'
in
-
tree
'
:
'
image_builder
'
}
            
cache_name
=
'
imagebuilder
-
sparse
-
{
}
'
.
format
(
_run_task_suffix
(
)
)
            
digest_data
.
append
(
'
image_builder
'
)
        
worker
[
'
caches
'
]
=
[
{
            
'
type
'
:
'
persistent
'
            
'
name
'
:
'
level
-
{
}
-
{
}
'
.
format
(
config
.
params
[
'
level
'
]
cache_name
)
            
'
mount
-
point
'
:
'
/
builds
/
worker
/
checkouts
'
        
}
]
        
for
k
v
in
args
.
items
(
)
:
            
if
k
=
=
'
DOCKER_IMAGE_PACKAGES
'
:
                
worker
[
'
env
'
]
[
k
]
=
{
'
task
-
reference
'
:
v
}
            
else
:
                
worker
[
'
env
'
]
[
k
]
=
v
        
if
packages
:
            
deps
=
taskdesc
.
setdefault
(
'
dependencies
'
{
}
)
            
for
p
in
sorted
(
packages
)
:
                
deps
[
p
]
=
'
packages
-
{
}
'
.
format
(
p
)
        
if
parent
:
            
deps
=
taskdesc
.
setdefault
(
'
dependencies
'
{
}
)
            
deps
[
parent
]
=
'
build
-
docker
-
image
-
{
}
'
.
format
(
parent
)
            
worker
[
'
env
'
]
[
'
DOCKER_IMAGE_PARENT_TASK
'
]
=
{
                
'
task
-
reference
'
:
'
<
{
}
>
'
.
format
(
parent
)
            
}
        
if
'
index
'
in
task
:
            
taskdesc
[
'
index
'
]
=
task
[
'
index
'
]
        
if
task
.
get
(
'
cache
'
True
)
and
not
taskgraph
.
fast
:
            
taskdesc
[
'
cache
'
]
=
{
                
'
type
'
:
'
docker
-
images
.
v2
'
                
'
name
'
:
image_name
                
'
digest
-
data
'
:
digest_data
            
}
        
yield
taskdesc
