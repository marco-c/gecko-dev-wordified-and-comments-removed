"
"
"
These
transformations
take
a
task
description
and
turn
it
into
a
TaskCluster
task
definition
(
along
with
attributes
label
etc
.
)
.
The
input
to
these
transformations
is
generic
to
any
kind
of
task
but
abstracts
away
some
of
the
complexities
of
worker
implementations
scopes
and
treeherder
annotations
.
"
"
"
from
__future__
import
absolute_import
print_function
unicode_literals
import
hashlib
import
os
import
re
import
time
from
copy
import
deepcopy
from
mozbuild
.
util
import
memoize
from
taskgraph
.
util
.
attributes
import
TRUNK_PROJECTS
from
taskgraph
.
util
.
hash
import
hash_path
from
taskgraph
.
util
.
treeherder
import
split_symbol
from
taskgraph
.
transforms
.
base
import
TransformSequence
from
taskgraph
.
util
.
schema
import
(
    
validate_schema
    
Schema
    
optionally_keyed_by
    
resolve_keyed_by
    
OptimizationSchema
)
from
taskgraph
.
util
.
scriptworker
import
(
    
BALROG_ACTIONS
    
get_release_config
    
add_scope_prefix
)
from
voluptuous
import
Any
Required
Optional
Extra
from
taskgraph
import
GECKO
MAX_DEPENDENCIES
from
.
.
util
import
docker
as
dockerutil
RUN_TASK
=
os
.
path
.
join
(
GECKO
'
taskcluster
'
'
scripts
'
'
run
-
task
'
)
memoize
def
_run_task_suffix
(
)
:
    
"
"
"
String
to
append
to
cache
names
under
control
of
run
-
task
.
"
"
"
    
return
hash_path
(
RUN_TASK
)
[
0
:
20
]
taskref_or_string
=
Any
(
    
basestring
    
{
Required
(
'
task
-
reference
'
)
:
basestring
}
)
task_description_schema
=
Schema
(
{
    
Required
(
'
label
'
)
:
basestring
    
Required
(
'
description
'
)
:
basestring
    
Optional
(
'
attributes
'
)
:
{
basestring
:
object
}
    
Optional
(
'
job
-
from
'
)
:
basestring
    
Optional
(
'
dependencies
'
)
:
{
basestring
:
object
}
    
Optional
(
'
requires
'
)
:
Any
(
'
all
-
completed
'
'
all
-
resolved
'
)
    
Optional
(
'
expires
-
after
'
)
:
basestring
    
Optional
(
'
deadline
-
after
'
)
:
basestring
    
Optional
(
'
routes
'
)
:
[
basestring
]
    
Optional
(
'
scopes
'
)
:
[
basestring
]
    
Optional
(
'
tags
'
)
:
{
basestring
:
basestring
}
    
Optional
(
'
extra
'
)
:
{
basestring
:
object
}
    
Optional
(
'
treeherder
'
)
:
{
        
'
symbol
'
:
basestring
        
'
kind
'
:
Any
(
'
build
'
'
test
'
'
other
'
)
        
'
tier
'
:
int
        
'
platform
'
:
basestring
    
}
    
Optional
(
'
index
'
)
:
{
        
'
product
'
:
basestring
        
'
job
-
name
'
:
basestring
        
'
type
'
:
Any
(
'
generic
'
'
nightly
'
'
l10n
'
'
nightly
-
with
-
multi
-
l10n
'
                    
'
release
'
'
nightly
-
l10n
'
)
        
'
rank
'
:
Any
(
            
'
by
-
tier
'
            
int
            
'
build_date
'
        
)
        
'
channel
'
:
optionally_keyed_by
(
'
project
'
basestring
)
    
}
    
Optional
(
'
run
-
on
-
projects
'
)
:
optionally_keyed_by
(
'
build
-
platform
'
[
basestring
]
)
    
Required
(
'
shipping
-
phase
'
)
:
Any
(
        
None
        
'
build
'
        
'
promote
'
        
'
push
'
        
'
ship
'
    
)
    
Required
(
'
shipping
-
product
'
)
:
Any
(
        
None
        
basestring
    
)
    
Optional
(
'
coalesce
'
)
:
{
        
'
job
-
identifier
'
:
basestring
        
'
age
'
:
int
        
'
size
'
:
int
    
}
    
Required
(
'
always
-
target
'
)
:
bool
    
Required
(
'
optimization
'
)
:
OptimizationSchema
    
'
worker
-
type
'
:
basestring
    
Required
(
'
needs
-
sccache
'
)
:
bool
    
'
worker
'
:
Any
(
{
        
Required
(
'
implementation
'
)
:
Any
(
'
docker
-
worker
'
'
docker
-
engine
'
)
        
Required
(
'
os
'
)
:
'
linux
'
        
Required
(
'
docker
-
image
'
)
:
Any
(
            
basestring
            
{
'
in
-
tree
'
:
basestring
}
            
{
'
indexed
'
:
basestring
}
        
)
        
Required
(
'
relengapi
-
proxy
'
)
:
bool
        
Required
(
'
chain
-
of
-
trust
'
)
:
bool
        
Required
(
'
taskcluster
-
proxy
'
)
:
bool
        
Required
(
'
allow
-
ptrace
'
)
:
bool
        
Required
(
'
loopback
-
video
'
)
:
bool
        
Required
(
'
loopback
-
audio
'
)
:
bool
        
Required
(
'
docker
-
in
-
docker
'
)
:
bool
        
Optional
(
'
volumes
'
)
:
[
basestring
]
        
Optional
(
'
caches
'
)
:
[
{
            
'
type
'
:
'
persistent
'
            
'
name
'
:
basestring
            
'
mount
-
point
'
:
basestring
            
Optional
(
'
skip
-
untrusted
'
)
:
bool
        
}
]
        
Optional
(
'
artifacts
'
)
:
[
{
            
'
type
'
:
Any
(
'
file
'
'
directory
'
)
            
'
path
'
:
basestring
            
'
name
'
:
basestring
        
}
]
        
Required
(
'
env
'
)
:
{
basestring
:
taskref_or_string
}
        
Optional
(
'
command
'
)
:
[
taskref_or_string
]
        
Required
(
'
max
-
run
-
time
'
)
:
int
        
Optional
(
'
retry
-
exit
-
status
'
)
:
[
int
]
        
Optional
(
'
purge
-
caches
-
exit
-
status
'
)
:
[
int
]
        
Optional
(
'
skip
-
artifacts
'
)
:
bool
    
}
{
        
Required
(
'
implementation
'
)
:
'
generic
-
worker
'
        
Required
(
'
os
'
)
:
Any
(
'
windows
'
'
macosx
'
)
        
Required
(
'
command
'
)
:
Any
(
            
[
taskref_or_string
]
            
[
[
taskref_or_string
]
]
        
)
        
Optional
(
'
artifacts
'
)
:
[
{
            
'
type
'
:
Any
(
'
file
'
'
directory
'
)
            
'
path
'
:
basestring
            
Optional
(
'
name
'
)
:
basestring
        
}
]
        
Optional
(
'
mounts
'
)
:
[
{
            
Optional
(
'
cache
-
name
'
)
:
basestring
            
Optional
(
'
content
'
)
:
{
                
Optional
(
'
artifact
'
)
:
basestring
                
Optional
(
'
task
-
id
'
)
:
taskref_or_string
                
Optional
(
'
url
'
)
:
basestring
            
}
            
Optional
(
'
directory
'
)
:
basestring
            
Optional
(
'
file
'
)
:
basestring
            
Optional
(
'
format
'
)
:
Any
(
'
rar
'
'
tar
.
bz2
'
'
tar
.
gz
'
'
zip
'
)
        
}
]
        
Required
(
'
env
'
)
:
{
basestring
:
taskref_or_string
}
        
Required
(
'
max
-
run
-
time
'
)
:
int
        
Optional
(
'
os
-
groups
'
)
:
[
basestring
]
        
Required
(
'
chain
-
of
-
trust
'
)
:
bool
        
Optional
(
'
taskcluster
-
proxy
'
)
:
bool
        
Optional
(
'
skip
-
artifacts
'
)
:
bool
    
}
{
        
Required
(
'
implementation
'
)
:
'
native
-
engine
'
        
Required
(
'
os
'
)
:
Any
(
'
macosx
'
'
linux
'
)
        
Required
(
'
max
-
run
-
time
'
)
:
int
        
Optional
(
'
context
'
)
:
basestring
        
Optional
(
'
reboot
'
)
:
            
Any
(
'
always
'
'
on
-
exception
'
'
on
-
failure
'
)
        
Optional
(
'
command
'
)
:
[
taskref_or_string
]
        
Optional
(
'
env
'
)
:
{
basestring
:
taskref_or_string
}
        
Optional
(
'
artifacts
'
)
:
[
{
            
Required
(
'
type
'
)
:
Any
(
'
file
'
'
directory
'
)
            
Required
(
'
path
'
)
:
basestring
            
Required
(
'
name
'
)
:
basestring
        
}
]
        
Optional
(
'
skip
-
artifacts
'
)
:
bool
    
}
{
        
Required
(
'
implementation
'
)
:
'
script
-
engine
-
autophone
'
        
Required
(
'
os
'
)
:
Any
(
'
macosx
'
'
linux
'
)
        
Optional
(
'
context
'
)
:
basestring
        
Optional
(
'
reboot
'
)
:
            
Any
(
False
'
always
'
'
never
'
'
on
-
exception
'
'
on
-
failure
'
)
        
Optional
(
'
command
'
)
:
[
taskref_or_string
]
        
Optional
(
'
env
'
)
:
{
basestring
:
taskref_or_string
}
        
Optional
(
'
artifacts
'
)
:
[
{
            
Required
(
'
type
'
)
:
Any
(
'
file
'
'
directory
'
)
            
Required
(
'
path
'
)
:
basestring
            
Required
(
'
name
'
)
:
basestring
        
}
]
    
}
{
        
Required
(
'
implementation
'
)
:
'
scriptworker
-
signing
'
        
Required
(
'
max
-
run
-
time
'
)
:
int
        
Required
(
'
upstream
-
artifacts
'
)
:
[
{
            
Required
(
'
taskId
'
)
:
taskref_or_string
            
Required
(
'
taskType
'
)
:
basestring
            
Required
(
'
paths
'
)
:
[
basestring
]
            
Required
(
'
formats
'
)
:
[
basestring
]
        
}
]
    
}
{
        
Required
(
'
implementation
'
)
:
'
binary
-
transparency
'
    
}
{
        
Required
(
'
implementation
'
)
:
'
beetmover
'
        
Required
(
'
max
-
run
-
time
'
default
=
600
)
:
int
        
Optional
(
'
locale
'
)
:
basestring
        
Optional
(
'
partner
-
public
'
)
:
bool
        
Required
(
'
release
-
properties
'
)
:
{
            
'
app
-
name
'
:
basestring
            
'
app
-
version
'
:
basestring
            
'
branch
'
:
basestring
            
'
build
-
id
'
:
basestring
            
'
hash
-
type
'
:
basestring
            
'
platform
'
:
basestring
        
}
        
Required
(
'
upstream
-
artifacts
'
)
:
[
{
            
Required
(
'
taskId
'
)
:
taskref_or_string
            
Required
(
'
taskType
'
)
:
basestring
            
Required
(
'
paths
'
)
:
[
basestring
]
            
Required
(
'
locale
'
)
:
basestring
        
}
]
    
}
{
        
Required
(
'
implementation
'
)
:
'
beetmover
-
push
-
to
-
release
'
        
Required
(
'
max
-
run
-
time
'
)
:
int
        
Required
(
'
product
'
)
:
basestring
    
}
{
        
Required
(
'
implementation
'
)
:
'
balrog
'
        
Required
(
'
balrog
-
action
'
)
:
Any
(
*
BALROG_ACTIONS
)
        
Optional
(
'
product
'
)
:
basestring
        
Optional
(
'
platforms
'
)
:
[
basestring
]
        
Optional
(
'
release
-
eta
'
)
:
basestring
        
Optional
(
'
channel
-
names
'
)
:
optionally_keyed_by
(
'
project
'
[
basestring
]
)
        
Optional
(
'
require
-
mirrors
'
)
:
bool
        
Optional
(
'
publish
-
rules
'
)
:
optionally_keyed_by
(
'
project
'
[
int
]
)
        
Optional
(
'
rules
-
to
-
update
'
)
:
optionally_keyed_by
(
'
project
'
[
basestring
]
)
        
Optional
(
'
archive
-
domain
'
)
:
optionally_keyed_by
(
'
project
'
basestring
)
        
Optional
(
'
download
-
domain
'
)
:
optionally_keyed_by
(
'
project
'
basestring
)
        
Optional
(
'
upstream
-
artifacts
'
)
:
[
{
            
Required
(
'
taskId
'
)
:
taskref_or_string
            
Required
(
'
taskType
'
)
:
basestring
            
Required
(
'
paths
'
)
:
[
basestring
]
        
}
]
    
}
{
        
Required
(
'
implementation
'
)
:
'
bouncer
-
aliases
'
        
Required
(
'
entries
'
)
:
object
    
}
{
        
Required
(
'
implementation
'
)
:
'
bouncer
-
submission
'
        
Required
(
'
locales
'
)
:
[
basestring
]
        
Required
(
'
entries
'
)
:
object
    
}
{
        
Required
(
'
implementation
'
)
:
'
invalid
'
        
Extra
:
object
    
}
{
        
Required
(
'
implementation
'
)
:
'
always
-
optimized
'
        
Extra
:
object
    
}
{
        
Required
(
'
implementation
'
)
:
'
push
-
apk
'
        
Required
(
'
upstream
-
artifacts
'
)
:
[
{
            
Required
(
'
taskId
'
)
:
taskref_or_string
            
Required
(
'
taskType
'
)
:
basestring
            
Required
(
'
paths
'
)
:
[
basestring
]
            
Optional
(
'
optional
'
default
=
False
)
:
bool
        
}
]
        
Required
(
'
google
-
play
-
track
'
)
:
Any
(
'
production
'
'
beta
'
'
alpha
'
'
rollout
'
'
invalid
'
)
        
Required
(
'
commit
'
)
:
bool
        
Optional
(
'
rollout
-
percentage
'
)
:
Any
(
int
None
)
    
}
{
        
Required
(
'
implementation
'
)
:
'
push
-
snap
'
        
Required
(
'
upstream
-
artifacts
'
)
:
[
{
            
Required
(
'
taskId
'
)
:
taskref_or_string
            
Required
(
'
taskType
'
)
:
basestring
            
Required
(
'
paths
'
)
:
[
basestring
]
        
}
]
    
}
{
        
Required
(
'
implementation
'
)
:
'
sign
-
and
-
push
-
addons
'
        
Required
(
'
channel
'
)
:
Any
(
'
listed
'
'
unlisted
'
)
        
Required
(
'
upstream
-
artifacts
'
)
:
[
{
            
Required
(
'
taskId
'
)
:
taskref_or_string
            
Required
(
'
taskType
'
)
:
basestring
            
Required
(
'
paths
'
)
:
[
basestring
]
        
}
]
    
}
{
        
Required
(
'
implementation
'
)
:
'
shipit
-
shipped
'
        
Required
(
'
release
-
name
'
)
:
basestring
    
}
{
        
Required
(
'
implementation
'
)
:
'
treescript
'
        
Required
(
'
tags
'
)
:
[
Any
(
'
buildN
'
'
release
'
None
)
]
        
Required
(
'
bump
'
)
:
bool
        
Optional
(
'
bump
-
files
'
)
:
[
basestring
]
        
Optional
(
'
repo
-
param
-
prefix
'
)
:
basestring
        
Optional
(
'
dontbuild
'
)
:
bool
        
Required
(
'
force
-
dry
-
run
'
default
=
True
)
:
bool
        
Required
(
'
push
'
default
=
False
)
:
bool
    
}
)
}
)
TC_TREEHERDER_SCHEMA_URL
=
'
https
:
/
/
github
.
com
/
taskcluster
/
taskcluster
-
treeherder
/
'
\
                           
'
blob
/
master
/
schemas
/
task
-
treeherder
-
config
.
yml
'
UNKNOWN_GROUP_NAME
=
"
Treeherder
group
{
}
(
from
{
}
)
has
no
name
;
"
\
                     
"
add
it
to
taskcluster
/
ci
/
config
.
yml
"
V2_ROUTE_TEMPLATES
=
[
    
"
index
.
{
trust
-
domain
}
.
v2
.
{
project
}
.
latest
.
{
product
}
.
{
job
-
name
}
"
    
"
index
.
{
trust
-
domain
}
.
v2
.
{
project
}
.
pushdate
.
{
build_date_long
}
.
{
product
}
.
{
job
-
name
}
"
    
"
index
.
{
trust
-
domain
}
.
v2
.
{
project
}
.
pushlog
-
id
.
{
pushlog_id
}
.
{
product
}
.
{
job
-
name
}
"
    
"
index
.
{
trust
-
domain
}
.
v2
.
{
project
}
.
revision
.
{
branch_rev
}
.
{
product
}
.
{
job
-
name
}
"
]
V2_TRUNK_ROUTE_TEMPLATES
=
[
    
"
index
.
{
trust
-
domain
}
.
v2
.
trunk
.
revision
.
{
branch_rev
}
.
{
product
}
.
{
job
-
name
}
"
]
V2_NIGHTLY_TEMPLATES
=
[
    
"
index
.
{
trust
-
domain
}
.
v2
.
{
project
}
.
nightly
.
latest
.
{
product
}
.
{
job
-
name
}
"
    
"
index
.
{
trust
-
domain
}
.
v2
.
{
project
}
.
nightly
.
{
build_date
}
.
revision
.
{
branch_rev
}
.
{
product
}
.
{
job
-
name
}
"
    
"
index
.
{
trust
-
domain
}
.
v2
.
{
project
}
.
nightly
.
{
build_date
}
.
latest
.
{
product
}
.
{
job
-
name
}
"
    
"
index
.
{
trust
-
domain
}
.
v2
.
{
project
}
.
nightly
.
revision
.
{
branch_rev
}
.
{
product
}
.
{
job
-
name
}
"
]
V2_NIGHTLY_L10N_TEMPLATES
=
[
    
"
index
.
{
trust
-
domain
}
.
v2
.
{
project
}
.
nightly
.
latest
.
{
product
}
-
l10n
.
{
job
-
name
}
.
{
locale
}
"
    
"
index
.
{
trust
-
domain
}
.
v2
.
{
project
}
.
nightly
.
{
build_date
}
.
revision
.
{
branch_rev
}
.
{
product
}
-
l10n
.
{
job
-
name
}
.
{
locale
}
"
    
"
index
.
{
trust
-
domain
}
.
v2
.
{
project
}
.
nightly
.
{
build_date
}
.
latest
.
{
product
}
-
l10n
.
{
job
-
name
}
.
{
locale
}
"
    
"
index
.
{
trust
-
domain
}
.
v2
.
{
project
}
.
nightly
.
revision
.
{
branch_rev
}
.
{
product
}
-
l10n
.
{
job
-
name
}
.
{
locale
}
"
]
V2_L10N_TEMPLATES
=
[
    
"
index
.
{
trust
-
domain
}
.
v2
.
{
project
}
.
revision
.
{
branch_rev
}
.
{
product
}
-
l10n
.
{
job
-
name
}
.
{
locale
}
"
    
"
index
.
{
trust
-
domain
}
.
v2
.
{
project
}
.
pushdate
.
{
build_date_long
}
.
{
product
}
-
l10n
.
{
job
-
name
}
.
{
locale
}
"
    
"
index
.
{
trust
-
domain
}
.
v2
.
{
project
}
.
pushlog
-
id
.
{
pushlog_id
}
.
{
product
}
-
l10n
.
{
job
-
name
}
.
{
locale
}
"
    
"
index
.
{
trust
-
domain
}
.
v2
.
{
project
}
.
latest
.
{
product
}
-
l10n
.
{
job
-
name
}
.
{
locale
}
"
]
TREEHERDER_ROUTE_ROOT
=
'
tc
-
treeherder
'
def
get_branch_rev
(
config
)
:
    
return
config
.
params
[
'
{
}
head_rev
'
.
format
(
        
config
.
graph_config
[
'
project
-
repo
-
param
-
prefix
'
]
    
)
]
def
get_branch_repo
(
config
)
:
    
return
config
.
params
[
'
{
}
head_repository
'
.
format
(
        
config
.
graph_config
[
'
project
-
repo
-
param
-
prefix
'
]
    
)
]
COALESCE_KEY
=
'
{
project
}
.
{
job
-
identifier
}
'
SUPERSEDER_URL
=
'
https
:
/
/
coalesce
.
mozilla
-
releng
.
net
/
v1
/
list
/
{
age
}
/
{
size
}
/
{
key
}
'
DEFAULT_BRANCH_PRIORITY
=
'
low
'
BRANCH_PRIORITIES
=
{
    
'
mozilla
-
release
'
:
'
highest
'
    
'
comm
-
esr45
'
:
'
highest
'
    
'
comm
-
esr52
'
:
'
highest
'
    
'
mozilla
-
esr45
'
:
'
very
-
high
'
    
'
mozilla
-
esr52
'
:
'
very
-
high
'
    
'
mozilla
-
beta
'
:
'
high
'
    
'
comm
-
beta
'
:
'
high
'
    
'
mozilla
-
central
'
:
'
medium
'
    
'
comm
-
central
'
:
'
medium
'
    
'
comm
-
aurora
'
:
'
medium
'
    
'
autoland
'
:
'
low
'
    
'
mozilla
-
inbound
'
:
'
low
'
    
'
try
'
:
'
very
-
low
'
    
'
try
-
comm
-
central
'
:
'
very
-
low
'
    
'
alder
'
:
'
very
-
low
'
    
'
ash
'
:
'
very
-
low
'
    
'
birch
'
:
'
very
-
low
'
    
'
cedar
'
:
'
very
-
low
'
    
'
cypress
'
:
'
very
-
low
'
    
'
elm
'
:
'
very
-
low
'
    
'
fig
'
:
'
very
-
low
'
    
'
gum
'
:
'
very
-
low
'
    
'
holly
'
:
'
very
-
low
'
    
'
jamun
'
:
'
very
-
low
'
    
'
larch
'
:
'
very
-
low
'
    
'
maple
'
:
'
very
-
low
'
    
'
oak
'
:
'
very
-
low
'
    
'
pine
'
:
'
very
-
low
'
    
'
graphics
'
:
'
very
-
low
'
    
'
ux
'
:
'
very
-
low
'
}
payload_builders
=
{
}
def
payload_builder
(
name
)
:
    
def
wrap
(
func
)
:
        
payload_builders
[
name
]
=
func
        
return
func
    
return
wrap
index_builders
=
{
}
def
index_builder
(
name
)
:
    
def
wrap
(
func
)
:
        
index_builders
[
name
]
=
func
        
return
func
    
return
wrap
def
coalesce_key
(
config
task
)
:
    
return
COALESCE_KEY
.
format
(
*
*
{
               
'
project
'
:
config
.
params
[
'
project
'
]
               
'
job
-
identifier
'
:
task
[
'
coalesce
'
]
[
'
job
-
identifier
'
]
           
}
)
def
superseder_url
(
config
task
)
:
    
key
=
coalesce_key
(
config
task
)
    
age
=
task
[
'
coalesce
'
]
[
'
age
'
]
    
size
=
task
[
'
coalesce
'
]
[
'
size
'
]
    
return
SUPERSEDER_URL
.
format
(
        
age
=
age
        
size
=
size
        
key
=
key
    
)
UNSUPPORTED_INDEX_PRODUCT_ERROR
=
"
"
"
\
The
gecko
-
v2
product
{
product
}
is
not
in
the
list
of
configured
products
in
taskcluster
/
ci
/
config
.
yml
'
.
"
"
"
def
verify_index
(
config
index
)
:
    
product
=
index
[
'
product
'
]
    
if
product
not
in
config
.
graph_config
[
'
index
'
]
[
'
products
'
]
:
        
raise
Exception
(
UNSUPPORTED_INDEX_PRODUCT_ERROR
.
format
(
product
=
product
)
)
payload_builder
(
'
docker
-
worker
'
)
def
build_docker_worker_payload
(
config
task
task_def
)
:
    
worker
=
task
[
'
worker
'
]
    
level
=
int
(
config
.
params
[
'
level
'
]
)
    
image
=
worker
[
'
docker
-
image
'
]
    
if
isinstance
(
image
dict
)
:
        
if
'
in
-
tree
'
in
image
:
            
name
=
image
[
'
in
-
tree
'
]
            
docker_image_task
=
'
build
-
docker
-
image
-
'
+
image
[
'
in
-
tree
'
]
            
task
.
setdefault
(
'
dependencies
'
{
}
)
[
'
docker
-
image
'
]
=
docker_image_task
            
image
=
{
                
"
path
"
:
"
public
/
image
.
tar
.
zst
"
                
"
taskId
"
:
{
"
task
-
reference
"
:
"
<
docker
-
image
>
"
}
                
"
type
"
:
"
task
-
image
"
            
}
            
volumes
=
dockerutil
.
parse_volumes
(
name
)
            
for
v
in
sorted
(
volumes
)
:
                
if
v
in
worker
[
'
volumes
'
]
:
                    
raise
Exception
(
'
volume
%
s
already
defined
;
'
                                    
'
if
it
is
defined
in
a
Dockerfile
'
                                    
'
it
does
not
need
to
be
specified
in
the
'
                                    
'
worker
definition
'
%
v
)
                
worker
[
'
volumes
'
]
.
append
(
v
)
        
elif
'
indexed
'
in
image
:
            
image
=
{
                
"
path
"
:
"
public
/
image
.
tar
.
zst
"
                
"
namespace
"
:
image
[
'
indexed
'
]
                
"
type
"
:
"
indexed
-
image
"
            
}
        
else
:
            
raise
Exception
(
"
unknown
docker
image
type
"
)
    
features
=
{
}
    
if
worker
.
get
(
'
relengapi
-
proxy
'
)
:
        
features
[
'
relengAPIProxy
'
]
=
True
    
if
worker
.
get
(
'
taskcluster
-
proxy
'
)
:
        
features
[
'
taskclusterProxy
'
]
=
True
    
if
worker
.
get
(
'
allow
-
ptrace
'
)
:
        
features
[
'
allowPtrace
'
]
=
True
        
task_def
[
'
scopes
'
]
.
append
(
'
docker
-
worker
:
feature
:
allowPtrace
'
)
    
if
worker
.
get
(
'
chain
-
of
-
trust
'
)
:
        
features
[
'
chainOfTrust
'
]
=
True
    
if
worker
.
get
(
'
docker
-
in
-
docker
'
)
:
        
features
[
'
dind
'
]
=
True
    
if
task
.
get
(
'
needs
-
sccache
'
)
:
        
features
[
'
taskclusterProxy
'
]
=
True
        
task_def
[
'
scopes
'
]
.
append
(
            
'
assume
:
project
:
taskcluster
:
{
trust_domain
}
:
level
-
{
level
}
-
sccache
-
buckets
'
.
format
(
                
trust_domain
=
config
.
graph_config
[
'
trust
-
domain
'
]
                
level
=
config
.
params
[
'
level
'
]
)
        
)
        
worker
[
'
env
'
]
[
'
USE_SCCACHE
'
]
=
'
1
'
        
worker
[
'
env
'
]
[
'
SCCACHE_IDLE_TIMEOUT
'
]
=
'
0
'
    
else
:
        
worker
[
'
env
'
]
[
'
SCCACHE_DISABLE
'
]
=
'
1
'
    
capabilities
=
{
}
    
for
lo
in
'
audio
'
'
video
'
:
        
if
worker
.
get
(
'
loopback
-
'
+
lo
)
:
            
capitalized
=
'
loopback
'
+
lo
.
capitalize
(
)
            
devices
=
capabilities
.
setdefault
(
'
devices
'
{
}
)
            
devices
[
capitalized
]
=
True
            
task_def
[
'
scopes
'
]
.
append
(
'
docker
-
worker
:
capability
:
device
:
'
+
capitalized
)
    
task_def
[
'
payload
'
]
=
payload
=
{
        
'
image
'
:
image
        
'
env
'
:
worker
[
'
env
'
]
    
}
    
if
'
command
'
in
worker
:
        
payload
[
'
command
'
]
=
worker
[
'
command
'
]
    
if
'
max
-
run
-
time
'
in
worker
:
        
payload
[
'
maxRunTime
'
]
=
worker
[
'
max
-
run
-
time
'
]
    
run_task
=
payload
.
get
(
'
command
'
[
'
'
]
)
[
0
]
.
endswith
(
'
run
-
task
'
)
    
if
run_task
:
        
worker
.
setdefault
(
'
retry
-
exit
-
status
'
[
]
)
.
append
(
72
)
        
worker
.
setdefault
(
'
purge
-
caches
-
exit
-
status
'
[
]
)
.
append
(
72
)
    
payload
[
'
onExitStatus
'
]
=
{
}
    
if
'
retry
-
exit
-
status
'
in
worker
:
        
payload
[
'
onExitStatus
'
]
[
'
retry
'
]
=
worker
[
'
retry
-
exit
-
status
'
]
    
if
'
purge
-
caches
-
exit
-
status
'
in
worker
:
        
payload
[
'
onExitStatus
'
]
[
'
purgeCaches
'
]
=
worker
[
'
purge
-
caches
-
exit
-
status
'
]
    
if
'
artifacts
'
in
worker
:
        
artifacts
=
{
}
        
for
artifact
in
worker
[
'
artifacts
'
]
:
            
artifacts
[
artifact
[
'
name
'
]
]
=
{
                
'
path
'
:
artifact
[
'
path
'
]
                
'
type
'
:
artifact
[
'
type
'
]
                
'
expires
'
:
task_def
[
'
expires
'
]
            
}
        
payload
[
'
artifacts
'
]
=
artifacts
    
if
isinstance
(
worker
.
get
(
'
docker
-
image
'
)
basestring
)
:
        
out_of_tree_image
=
worker
[
'
docker
-
image
'
]
        
run_task
=
run_task
or
out_of_tree_image
.
startswith
(
            
'
taskcluster
/
image_builder
'
)
    
else
:
        
out_of_tree_image
=
None
        
image
=
worker
.
get
(
'
docker
-
image
'
{
}
)
.
get
(
'
in
-
tree
'
)
        
run_task
=
run_task
or
image
=
=
'
image_builder
'
    
if
'
caches
'
in
worker
:
        
caches
=
{
}
        
cache_version
=
'
v3
'
        
if
run_task
:
            
suffix
=
'
-
%
s
-
%
s
'
%
(
cache_version
_run_task_suffix
(
)
)
            
if
out_of_tree_image
:
                
name_hash
=
hashlib
.
sha256
(
out_of_tree_image
)
.
hexdigest
(
)
                
suffix
+
=
name_hash
[
0
:
12
]
        
else
:
            
suffix
=
'
-
%
s
'
%
cache_version
        
skip_untrusted
=
config
.
params
.
is_try
(
)
or
level
=
=
1
        
for
cache
in
worker
[
'
caches
'
]
:
            
if
cache
.
get
(
'
skip
-
untrusted
'
)
and
skip_untrusted
:
                
continue
            
name
=
'
%
s
%
s
'
%
(
cache
[
'
name
'
]
suffix
)
            
caches
[
name
]
=
cache
[
'
mount
-
point
'
]
            
task_def
[
'
scopes
'
]
.
append
(
'
docker
-
worker
:
cache
:
%
s
'
%
name
)
        
if
run_task
:
            
payload
[
'
env
'
]
[
'
TASKCLUSTER_CACHES
'
]
=
'
;
'
.
join
(
sorted
(
                
caches
.
values
(
)
)
)
        
payload
[
'
cache
'
]
=
caches
    
if
run_task
and
worker
.
get
(
'
volumes
'
)
:
        
payload
[
'
env
'
]
[
'
TASKCLUSTER_VOLUMES
'
]
=
'
;
'
.
join
(
            
sorted
(
worker
[
'
volumes
'
]
)
)
    
if
payload
.
get
(
'
cache
'
)
and
skip_untrusted
:
        
payload
[
'
env
'
]
[
'
TASKCLUSTER_UNTRUSTED_CACHES
'
]
=
'
1
'
    
if
features
:
        
payload
[
'
features
'
]
=
features
    
if
capabilities
:
        
payload
[
'
capabilities
'
]
=
capabilities
    
if
'
coalesce
'
in
task
:
        
payload
[
'
supersederUrl
'
]
=
superseder_url
(
config
task
)
    
check_caches_are_volumes
(
task
)
payload_builder
(
'
generic
-
worker
'
)
def
build_generic_worker_payload
(
config
task
task_def
)
:
    
worker
=
task
[
'
worker
'
]
    
artifacts
=
[
]
    
for
artifact
in
worker
.
get
(
'
artifacts
'
[
]
)
:
        
a
=
{
            
'
path
'
:
artifact
[
'
path
'
]
            
'
type
'
:
artifact
[
'
type
'
]
            
'
expires
'
:
task_def
[
'
expires
'
]
        
}
        
if
'
name
'
in
artifact
:
            
a
[
'
name
'
]
=
artifact
[
'
name
'
]
        
artifacts
.
append
(
a
)
    
mounts
=
deepcopy
(
worker
.
get
(
'
mounts
'
[
]
)
)
    
for
mount
in
mounts
:
        
if
'
cache
-
name
'
in
mount
:
            
mount
[
'
cacheName
'
]
=
mount
.
pop
(
'
cache
-
name
'
)
        
if
'
content
'
in
mount
:
            
if
'
task
-
id
'
in
mount
[
'
content
'
]
:
                
mount
[
'
content
'
]
[
'
taskId
'
]
=
mount
[
'
content
'
]
.
pop
(
'
task
-
id
'
)
    
task_def
[
'
payload
'
]
=
{
        
'
command
'
:
worker
[
'
command
'
]
        
'
artifacts
'
:
artifacts
        
'
env
'
:
worker
.
get
(
'
env
'
{
}
)
        
'
mounts
'
:
mounts
        
'
maxRunTime
'
:
worker
[
'
max
-
run
-
time
'
]
        
'
osGroups
'
:
worker
.
get
(
'
os
-
groups
'
[
]
)
    
}
    
if
task
.
get
(
'
needs
-
sccache
'
)
:
        
worker
[
'
env
'
]
[
'
USE_SCCACHE
'
]
=
'
1
'
    
else
:
        
worker
[
'
env
'
]
[
'
SCCACHE_DISABLE
'
]
=
'
1
'
    
features
=
{
}
    
if
worker
.
get
(
'
chain
-
of
-
trust
'
)
:
        
features
[
'
chainOfTrust
'
]
=
True
    
if
worker
.
get
(
'
taskcluster
-
proxy
'
)
:
        
features
[
'
taskclusterProxy
'
]
=
True
    
if
features
:
        
task_def
[
'
payload
'
]
[
'
features
'
]
=
features
    
if
'
coalesce
'
in
task
:
        
task_def
[
'
payload
'
]
[
'
supersederUrl
'
]
=
superseder_url
(
config
task
)
payload_builder
(
'
scriptworker
-
signing
'
)
def
build_scriptworker_signing_payload
(
config
task
task_def
)
:
    
worker
=
task
[
'
worker
'
]
    
task_def
[
'
payload
'
]
=
{
        
'
maxRunTime
'
:
worker
[
'
max
-
run
-
time
'
]
        
'
upstreamArtifacts
'
:
worker
[
'
upstream
-
artifacts
'
]
    
}
payload_builder
(
'
binary
-
transparency
'
)
def
build_binary_transparency_payload
(
config
task
task_def
)
:
    
release_config
=
get_release_config
(
config
)
    
task_def
[
'
payload
'
]
=
{
        
'
version
'
:
release_config
[
'
version
'
]
        
'
chain
'
:
'
TRANSPARENCY
.
pem
'
        
'
contact
'
:
task_def
[
'
metadata
'
]
[
'
owner
'
]
        
'
maxRunTime
'
:
600
        
'
stage
-
product
'
:
task
[
'
shipping
-
product
'
]
        
'
summary
'
:
(
            
'
https
:
/
/
archive
.
mozilla
.
org
/
pub
/
{
}
/
candidates
/
'
            
'
{
}
-
candidates
/
build
{
}
/
SHA256SUMMARY
'
        
)
.
format
(
            
task
[
'
shipping
-
product
'
]
            
release_config
[
'
version
'
]
            
release_config
[
'
build_number
'
]
        
)
    
}
payload_builder
(
'
beetmover
'
)
def
build_beetmover_payload
(
config
task
task_def
)
:
    
worker
=
task
[
'
worker
'
]
    
release_config
=
get_release_config
(
config
)
    
release_properties
=
worker
[
'
release
-
properties
'
]
    
task_def
[
'
payload
'
]
=
{
        
'
maxRunTime
'
:
worker
[
'
max
-
run
-
time
'
]
        
'
releaseProperties
'
:
{
            
'
appName
'
:
release_properties
[
'
app
-
name
'
]
            
'
appVersion
'
:
release_properties
[
'
app
-
version
'
]
            
'
branch
'
:
release_properties
[
'
branch
'
]
            
'
buildid
'
:
release_properties
[
'
build
-
id
'
]
            
'
hashType
'
:
release_properties
[
'
hash
-
type
'
]
            
'
platform
'
:
release_properties
[
'
platform
'
]
        
}
        
'
upload_date
'
:
config
.
params
[
'
build_date
'
]
        
'
upstreamArtifacts
'
:
worker
[
'
upstream
-
artifacts
'
]
    
}
    
if
worker
.
get
(
'
locale
'
)
:
        
task_def
[
'
payload
'
]
[
'
locale
'
]
=
worker
[
'
locale
'
]
    
if
worker
.
get
(
'
partner
-
public
'
)
:
        
task_def
[
'
payload
'
]
[
'
is_partner_repack_public
'
]
=
worker
[
'
partner
-
public
'
]
    
if
release_config
:
        
task_def
[
'
payload
'
]
.
update
(
release_config
)
payload_builder
(
'
beetmover
-
push
-
to
-
release
'
)
def
build_beetmover_push_to_release_payload
(
config
task
task_def
)
:
    
worker
=
task
[
'
worker
'
]
    
release_config
=
get_release_config
(
config
)
    
task_def
[
'
payload
'
]
=
{
        
'
maxRunTime
'
:
worker
[
'
max
-
run
-
time
'
]
        
'
product
'
:
worker
[
'
product
'
]
        
'
version
'
:
release_config
[
'
version
'
]
        
'
build_number
'
:
release_config
[
'
build_number
'
]
    
}
payload_builder
(
'
balrog
'
)
def
build_balrog_payload
(
config
task
task_def
)
:
    
worker
=
task
[
'
worker
'
]
    
release_config
=
get_release_config
(
config
)
    
if
worker
[
'
balrog
-
action
'
]
=
=
'
submit
-
locale
'
:
        
task_def
[
'
payload
'
]
=
{
            
'
upstreamArtifacts
'
:
worker
[
'
upstream
-
artifacts
'
]
        
}
    
else
:
        
for
prop
in
(
'
archive
-
domain
'
'
channel
-
names
'
'
download
-
domain
'
                     
'
publish
-
rules
'
'
rules
-
to
-
update
'
)
:
            
if
prop
in
worker
:
                
resolve_keyed_by
(
                    
worker
prop
task
[
'
description
'
]
                    
*
*
config
.
params
                
)
        
task_def
[
'
payload
'
]
=
{
            
'
build_number
'
:
release_config
[
'
build_number
'
]
            
'
product
'
:
worker
[
'
product
'
]
            
'
version
'
:
release_config
[
'
version
'
]
        
}
        
if
worker
[
'
balrog
-
action
'
]
=
=
'
submit
-
toplevel
'
:
            
task_def
[
'
payload
'
]
.
update
(
{
                
'
app_version
'
:
release_config
[
'
appVersion
'
]
                
'
archive_domain
'
:
worker
[
'
archive
-
domain
'
]
                
'
channel_names
'
:
worker
[
'
channel
-
names
'
]
                
'
download_domain
'
:
worker
[
'
download
-
domain
'
]
                
'
partial_versions
'
:
release_config
.
get
(
'
partial_versions
'
"
"
)
                
'
platforms
'
:
worker
[
'
platforms
'
]
                
'
rules_to_update
'
:
worker
[
'
rules
-
to
-
update
'
]
                
'
require_mirrors
'
:
worker
[
'
require
-
mirrors
'
]
            
}
)
        
else
:
            
task_def
[
'
payload
'
]
.
update
(
{
                
'
publish_rules
'
:
worker
[
'
publish
-
rules
'
]
                
'
release_eta
'
:
worker
.
get
(
'
release
-
eta
'
config
.
params
.
get
(
'
release_eta
'
)
)
or
'
'
            
}
)
payload_builder
(
'
bouncer
-
aliases
'
)
def
build_bouncer_aliases_payload
(
config
task
task_def
)
:
    
worker
=
task
[
'
worker
'
]
    
task_def
[
'
payload
'
]
=
{
        
'
aliases_entries
'
:
worker
[
'
entries
'
]
    
}
payload_builder
(
'
bouncer
-
submission
'
)
def
build_bouncer_submission_payload
(
config
task
task_def
)
:
    
worker
=
task
[
'
worker
'
]
    
task_def
[
'
payload
'
]
=
{
        
'
locales
'
:
worker
[
'
locales
'
]
        
'
submission_entries
'
:
worker
[
'
entries
'
]
    
}
payload_builder
(
'
push
-
apk
'
)
def
build_push_apk_payload
(
config
task
task_def
)
:
    
worker
=
task
[
'
worker
'
]
    
task_def
[
'
payload
'
]
=
{
        
'
commit
'
:
worker
[
'
commit
'
]
        
'
upstreamArtifacts
'
:
worker
[
'
upstream
-
artifacts
'
]
        
'
google_play_track
'
:
worker
[
'
google
-
play
-
track
'
]
    
}
    
if
worker
.
get
(
'
rollout
-
percentage
'
None
)
:
        
task_def
[
'
payload
'
]
[
'
rollout_percentage
'
]
=
worker
[
'
rollout
-
percentage
'
]
payload_builder
(
'
push
-
snap
'
)
def
build_push_snap_payload
(
config
task
task_def
)
:
    
worker
=
task
[
'
worker
'
]
    
task_def
[
'
payload
'
]
=
{
        
'
upstreamArtifacts
'
:
worker
[
'
upstream
-
artifacts
'
]
    
}
payload_builder
(
'
shipit
-
shipped
'
)
def
build_ship_it_shipped_payload
(
config
task
task_def
)
:
    
worker
=
task
[
'
worker
'
]
    
task_def
[
'
payload
'
]
=
{
        
'
release_name
'
:
worker
[
'
release
-
name
'
]
    
}
payload_builder
(
'
sign
-
and
-
push
-
addons
'
)
def
build_sign_and_push_addons_payload
(
config
task
task_def
)
:
    
worker
=
task
[
'
worker
'
]
    
task_def
[
'
payload
'
]
=
{
        
'
channel
'
:
worker
[
'
channel
'
]
        
'
upstreamArtifacts
'
:
worker
[
'
upstream
-
artifacts
'
]
    
}
payload_builder
(
'
treescript
'
)
def
build_treescript_payload
(
config
task
task_def
)
:
    
worker
=
task
[
'
worker
'
]
    
release_config
=
get_release_config
(
config
)
    
task_def
[
'
payload
'
]
=
{
}
    
task_def
.
setdefault
(
'
scopes
'
[
]
)
    
if
worker
[
'
tags
'
]
:
        
tag_names
=
[
]
        
product
=
task
[
'
shipping
-
product
'
]
.
upper
(
)
        
version
=
release_config
[
'
version
'
]
.
replace
(
'
.
'
'
_
'
)
        
buildnum
=
release_config
[
'
build_number
'
]
        
if
'
buildN
'
in
worker
[
'
tags
'
]
:
            
tag_names
.
extend
(
[
                
"
{
}
_
{
}
_BUILD
{
}
"
.
format
(
product
version
buildnum
)
            
]
)
        
if
'
release
'
in
worker
[
'
tags
'
]
:
            
tag_names
.
extend
(
[
              
"
{
}
_
{
}
_RELEASE
"
.
format
(
product
version
)
            
]
)
        
tag_info
=
{
            
'
tags
'
:
tag_names
            
'
revision
'
:
config
.
params
[
'
{
}
head_rev
'
.
format
(
worker
.
get
(
'
repo
-
param
-
prefix
'
'
'
)
)
]
        
}
        
task_def
[
'
payload
'
]
[
'
tag_info
'
]
=
tag_info
        
task_def
[
'
scopes
'
]
.
append
(
add_scope_prefix
(
config
'
treescript
:
action
:
tagging
'
)
)
    
if
worker
[
'
bump
'
]
:
        
if
not
worker
[
'
bump
-
files
'
]
:
            
raise
Exception
(
"
Version
Bump
requested
without
bump
-
files
"
)
        
bump_info
=
{
}
        
bump_info
[
'
next_version
'
]
=
release_config
[
'
next_version
'
]
        
bump_info
[
'
files
'
]
=
worker
[
'
bump
-
files
'
]
        
task_def
[
'
payload
'
]
[
'
version_bump_info
'
]
=
bump_info
        
task_def
[
'
scopes
'
]
.
append
(
add_scope_prefix
(
config
'
treescript
:
action
:
version_bump
'
)
)
    
if
worker
[
'
push
'
]
:
        
task_def
[
'
scopes
'
]
.
append
(
add_scope_prefix
(
config
'
treescript
:
action
:
push
'
)
)
    
if
worker
.
get
(
'
force
-
dry
-
run
'
)
:
        
task_def
[
'
payload
'
]
[
'
dry_run
'
]
=
True
    
if
worker
.
get
(
'
dontbuild
'
)
:
        
task_def
[
'
payload
'
]
[
'
dont_build
'
]
=
True
payload_builder
(
'
invalid
'
)
def
build_invalid_payload
(
config
task
task_def
)
:
    
task_def
[
'
payload
'
]
=
'
invalid
task
-
should
never
be
created
'
payload_builder
(
'
always
-
optimized
'
)
def
build_always_optimized_payload
(
config
task
task_def
)
:
    
task_def
[
'
payload
'
]
=
{
}
payload_builder
(
'
native
-
engine
'
)
def
build_macosx_engine_payload
(
config
task
task_def
)
:
    
worker
=
task
[
'
worker
'
]
    
artifacts
=
map
(
lambda
artifact
:
{
        
'
name
'
:
artifact
[
'
name
'
]
        
'
path
'
:
artifact
[
'
path
'
]
        
'
type
'
:
artifact
[
'
type
'
]
        
'
expires
'
:
task_def
[
'
expires
'
]
    
}
worker
.
get
(
'
artifacts
'
[
]
)
)
    
task_def
[
'
payload
'
]
=
{
        
'
context
'
:
worker
[
'
context
'
]
        
'
command
'
:
worker
[
'
command
'
]
        
'
env
'
:
worker
[
'
env
'
]
        
'
artifacts
'
:
artifacts
        
'
maxRunTime
'
:
worker
[
'
max
-
run
-
time
'
]
    
}
    
if
worker
.
get
(
'
reboot
'
)
:
        
task_def
[
'
payload
'
]
=
worker
[
'
reboot
'
]
    
if
task
.
get
(
'
needs
-
sccache
'
)
:
        
raise
Exception
(
'
needs
-
sccache
not
supported
in
native
-
engine
'
)
payload_builder
(
'
script
-
engine
-
autophone
'
)
def
build_script_engine_autophone_payload
(
config
task
task_def
)
:
    
worker
=
task
[
'
worker
'
]
    
artifacts
=
map
(
lambda
artifact
:
{
        
'
name
'
:
artifact
[
'
name
'
]
        
'
path
'
:
artifact
[
'
path
'
]
        
'
type
'
:
artifact
[
'
type
'
]
        
'
expires
'
:
task_def
[
'
expires
'
]
    
}
worker
.
get
(
'
artifacts
'
[
]
)
)
    
task_def
[
'
payload
'
]
=
{
        
'
context
'
:
worker
[
'
context
'
]
        
'
command
'
:
worker
[
'
command
'
]
        
'
env
'
:
worker
[
'
env
'
]
        
'
artifacts
'
:
artifacts
    
}
    
if
worker
.
get
(
'
reboot
'
)
:
        
task_def
[
'
payload
'
]
=
worker
[
'
reboot
'
]
    
if
task
.
get
(
'
needs
-
sccache
'
)
:
        
raise
Exception
(
'
needs
-
sccache
not
supported
in
taskcluster
-
worker
'
)
transforms
=
TransformSequence
(
)
transforms
.
add
def
set_defaults
(
config
tasks
)
:
    
for
task
in
tasks
:
        
task
.
setdefault
(
'
shipping
-
phase
'
None
)
        
task
.
setdefault
(
'
shipping
-
product
'
None
)
        
task
.
setdefault
(
'
always
-
target
'
False
)
        
task
.
setdefault
(
'
optimization
'
None
)
        
task
.
setdefault
(
'
needs
-
sccache
'
False
)
        
worker
=
task
[
'
worker
'
]
        
if
worker
[
'
implementation
'
]
in
(
'
docker
-
worker
'
'
docker
-
engine
'
)
:
            
worker
.
setdefault
(
'
relengapi
-
proxy
'
False
)
            
worker
.
setdefault
(
'
chain
-
of
-
trust
'
False
)
            
worker
.
setdefault
(
'
taskcluster
-
proxy
'
False
)
            
worker
.
setdefault
(
'
allow
-
ptrace
'
False
)
            
worker
.
setdefault
(
'
loopback
-
video
'
False
)
            
worker
.
setdefault
(
'
loopback
-
audio
'
False
)
            
worker
.
setdefault
(
'
docker
-
in
-
docker
'
False
)
            
worker
.
setdefault
(
'
volumes
'
[
]
)
            
worker
.
setdefault
(
'
env
'
{
}
)
            
if
'
caches
'
in
worker
:
                
for
c
in
worker
[
'
caches
'
]
:
                    
c
.
setdefault
(
'
skip
-
untrusted
'
False
)
        
elif
worker
[
'
implementation
'
]
=
=
'
generic
-
worker
'
:
            
worker
.
setdefault
(
'
env
'
{
}
)
            
worker
.
setdefault
(
'
os
-
groups
'
[
]
)
            
worker
.
setdefault
(
'
chain
-
of
-
trust
'
False
)
        
elif
worker
[
'
implementation
'
]
=
=
'
scriptworker
-
signing
'
:
            
worker
.
setdefault
(
'
max
-
run
-
time
'
600
)
        
elif
worker
[
'
implementation
'
]
=
=
'
beetmover
'
:
            
worker
.
setdefault
(
'
max
-
run
-
time
'
600
)
        
elif
worker
[
'
implementation
'
]
=
=
'
beetmover
-
push
-
to
-
release
'
:
            
worker
.
setdefault
(
'
max
-
run
-
time
'
600
)
        
elif
worker
[
'
implementation
'
]
=
=
'
push
-
apk
'
:
            
worker
.
setdefault
(
'
commit
'
False
)
        
yield
task
transforms
.
add
def
task_name_from_label
(
config
tasks
)
:
    
for
task
in
tasks
:
        
if
'
label
'
not
in
task
:
            
if
'
name
'
not
in
task
:
                
raise
Exception
(
"
task
has
neither
a
name
nor
a
label
"
)
            
task
[
'
label
'
]
=
'
{
}
-
{
}
'
.
format
(
config
.
kind
task
[
'
name
'
]
)
        
if
task
.
get
(
'
name
'
)
:
            
del
task
[
'
name
'
]
        
yield
task
UNSUPPORTED_SHIPPING_PRODUCT_ERROR
=
"
"
"
\
The
shipping
product
{
product
}
is
not
in
the
list
of
configured
products
in
taskcluster
/
ci
/
config
.
yml
'
.
"
"
"
def
validate_shipping_product
(
config
product
)
:
    
if
product
not
in
config
.
graph_config
[
'
release
-
promotion
'
]
[
'
products
'
]
:
        
raise
Exception
(
UNSUPPORTED_SHIPPING_PRODUCT_ERROR
.
format
(
product
=
product
)
)
transforms
.
add
def
validate
(
config
tasks
)
:
    
for
task
in
tasks
:
        
validate_schema
(
            
task_description_schema
task
            
"
In
task
{
!
r
}
:
"
.
format
(
task
.
get
(
'
label
'
'
?
no
-
label
?
'
)
)
)
        
if
task
[
'
shipping
-
product
'
]
is
not
None
:
            
validate_shipping_product
(
config
task
[
'
shipping
-
product
'
]
)
        
yield
task
index_builder
(
'
generic
'
)
def
add_generic_index_routes
(
config
task
)
:
    
index
=
task
.
get
(
'
index
'
)
    
routes
=
task
.
setdefault
(
'
routes
'
[
]
)
    
verify_index
(
config
index
)
    
subs
=
config
.
params
.
copy
(
)
    
subs
[
'
job
-
name
'
]
=
index
[
'
job
-
name
'
]
    
subs
[
'
build_date_long
'
]
=
time
.
strftime
(
"
%
Y
.
%
m
.
%
d
.
%
Y
%
m
%
d
%
H
%
M
%
S
"
                                            
time
.
gmtime
(
config
.
params
[
'
build_date
'
]
)
)
    
subs
[
'
product
'
]
=
index
[
'
product
'
]
    
subs
[
'
trust
-
domain
'
]
=
config
.
graph_config
[
'
trust
-
domain
'
]
    
subs
[
'
branch_rev
'
]
=
get_branch_rev
(
config
)
    
project
=
config
.
params
.
get
(
'
project
'
)
    
for
tpl
in
V2_ROUTE_TEMPLATES
:
        
routes
.
append
(
tpl
.
format
(
*
*
subs
)
)
    
if
project
and
project
in
TRUNK_PROJECTS
:
        
for
tpl
in
V2_TRUNK_ROUTE_TEMPLATES
:
            
routes
.
append
(
tpl
.
format
(
*
*
subs
)
)
    
return
task
index_builder
(
'
nightly
'
)
def
add_nightly_index_routes
(
config
task
)
:
    
index
=
task
.
get
(
'
index
'
)
    
routes
=
task
.
setdefault
(
'
routes
'
[
]
)
    
verify_index
(
config
index
)
    
subs
=
config
.
params
.
copy
(
)
    
subs
[
'
job
-
name
'
]
=
index
[
'
job
-
name
'
]
    
subs
[
'
build_date_long
'
]
=
time
.
strftime
(
"
%
Y
.
%
m
.
%
d
.
%
Y
%
m
%
d
%
H
%
M
%
S
"
                                            
time
.
gmtime
(
config
.
params
[
'
build_date
'
]
)
)
    
subs
[
'
build_date
'
]
=
time
.
strftime
(
"
%
Y
.
%
m
.
%
d
"
                                       
time
.
gmtime
(
config
.
params
[
'
build_date
'
]
)
)
    
subs
[
'
product
'
]
=
index
[
'
product
'
]
    
subs
[
'
trust
-
domain
'
]
=
config
.
graph_config
[
'
trust
-
domain
'
]
    
subs
[
'
branch_rev
'
]
=
get_branch_rev
(
config
)
    
for
tpl
in
V2_NIGHTLY_TEMPLATES
:
        
routes
.
append
(
tpl
.
format
(
*
*
subs
)
)
    
task
=
add_l10n_index_routes
(
config
task
force_locale
=
"
en
-
US
"
)
    
return
task
index_builder
(
'
release
'
)
def
add_release_index_routes
(
config
task
)
:
    
index
=
task
.
get
(
'
index
'
)
    
routes
=
[
]
    
release_config
=
get_release_config
(
config
)
    
subs
=
config
.
params
.
copy
(
)
    
subs
[
'
build_number
'
]
=
str
(
release_config
[
'
build_number
'
]
)
    
subs
[
'
revision
'
]
=
subs
[
'
head_rev
'
]
    
subs
[
'
underscore_version
'
]
=
release_config
[
'
version
'
]
.
replace
(
'
.
'
'
_
'
)
    
subs
[
'
product
'
]
=
index
[
'
product
'
]
    
subs
[
'
trust
-
domain
'
]
=
config
.
graph_config
[
'
trust
-
domain
'
]
    
subs
[
'
branch_rev
'
]
=
get_branch_rev
(
config
)
    
subs
[
'
branch
'
]
=
subs
[
'
project
'
]
    
if
'
channel
'
in
index
:
        
resolve_keyed_by
(
            
index
'
channel
'
item_name
=
task
[
'
label
'
]
project
=
config
.
params
[
'
project
'
]
        
)
        
subs
[
'
channel
'
]
=
index
[
'
channel
'
]
    
for
rt
in
task
.
get
(
'
routes
'
[
]
)
:
        
routes
.
append
(
rt
.
format
(
*
*
subs
)
)
    
task
[
'
routes
'
]
=
routes
    
return
task
index_builder
(
'
nightly
-
with
-
multi
-
l10n
'
)
def
add_nightly_multi_index_routes
(
config
task
)
:
    
task
=
add_nightly_index_routes
(
config
task
)
    
task
=
add_l10n_index_routes
(
config
task
force_locale
=
"
multi
"
)
    
return
task
index_builder
(
'
l10n
'
)
def
add_l10n_index_routes
(
config
task
force_locale
=
None
)
:
    
index
=
task
.
get
(
'
index
'
)
    
routes
=
task
.
setdefault
(
'
routes
'
[
]
)
    
verify_index
(
config
index
)
    
subs
=
config
.
params
.
copy
(
)
    
subs
[
'
job
-
name
'
]
=
index
[
'
job
-
name
'
]
    
subs
[
'
build_date_long
'
]
=
time
.
strftime
(
"
%
Y
.
%
m
.
%
d
.
%
Y
%
m
%
d
%
H
%
M
%
S
"
                                            
time
.
gmtime
(
config
.
params
[
'
build_date
'
]
)
)
    
subs
[
'
product
'
]
=
index
[
'
product
'
]
    
subs
[
'
trust
-
domain
'
]
=
config
.
graph_config
[
'
trust
-
domain
'
]
    
subs
[
'
branch_rev
'
]
=
get_branch_rev
(
config
)
    
locales
=
task
[
'
attributes
'
]
.
get
(
'
chunk_locales
'
                                     
task
[
'
attributes
'
]
.
get
(
'
all_locales
'
)
)
    
if
task
[
'
attributes
'
]
.
get
(
'
locale
'
)
:
        
locales
=
[
task
[
'
attributes
'
]
[
'
locale
'
]
]
    
if
force_locale
:
        
locales
=
[
force_locale
]
    
if
not
locales
:
        
raise
Exception
(
"
Error
:
Unable
to
use
l10n
index
for
tasks
without
locales
"
)
    
if
len
(
locales
)
>
18
:
        
return
task
    
for
locale
in
locales
:
        
for
tpl
in
V2_L10N_TEMPLATES
:
            
routes
.
append
(
tpl
.
format
(
locale
=
locale
*
*
subs
)
)
    
return
task
index_builder
(
'
nightly
-
l10n
'
)
def
add_nightly_l10n_index_routes
(
config
task
force_locale
=
None
)
:
    
index
=
task
.
get
(
'
index
'
)
    
routes
=
task
.
setdefault
(
'
routes
'
[
]
)
    
verify_index
(
config
index
)
    
subs
=
config
.
params
.
copy
(
)
    
subs
[
'
job
-
name
'
]
=
index
[
'
job
-
name
'
]
    
subs
[
'
build_date_long
'
]
=
time
.
strftime
(
"
%
Y
.
%
m
.
%
d
.
%
Y
%
m
%
d
%
H
%
M
%
S
"
                                            
time
.
gmtime
(
config
.
params
[
'
build_date
'
]
)
)
    
subs
[
'
build_date
'
]
=
time
.
strftime
(
"
%
Y
.
%
m
.
%
d
"
                                       
time
.
gmtime
(
config
.
params
[
'
build_date
'
]
)
)
    
subs
[
'
product
'
]
=
index
[
'
product
'
]
    
subs
[
'
trust
-
domain
'
]
=
config
.
graph_config
[
'
trust
-
domain
'
]
    
subs
[
'
branch_rev
'
]
=
get_branch_rev
(
config
)
    
locales
=
task
[
'
attributes
'
]
.
get
(
'
chunk_locales
'
                                     
task
[
'
attributes
'
]
.
get
(
'
all_locales
'
)
)
    
if
task
[
'
attributes
'
]
.
get
(
'
locale
'
)
:
        
locales
=
[
task
[
'
attributes
'
]
[
'
locale
'
]
]
    
if
force_locale
:
        
locales
=
[
force_locale
]
    
if
not
locales
:
        
raise
Exception
(
"
Error
:
Unable
to
use
l10n
index
for
tasks
without
locales
"
)
    
for
locale
in
locales
:
        
for
tpl
in
V2_NIGHTLY_L10N_TEMPLATES
:
            
routes
.
append
(
tpl
.
format
(
locale
=
locale
*
*
subs
)
)
    
return
task
transforms
.
add
def
add_index_routes
(
config
tasks
)
:
    
for
task
in
tasks
:
        
index
=
task
.
get
(
'
index
'
{
}
)
        
extra_index
=
task
.
setdefault
(
'
extra
'
{
}
)
.
setdefault
(
'
index
'
{
}
)
        
rank
=
index
.
get
(
'
rank
'
'
by
-
tier
'
)
        
if
rank
=
=
'
by
-
tier
'
:
            
tier
=
task
.
get
(
'
treeherder
'
{
}
)
.
get
(
'
tier
'
3
)
            
extra_index
[
'
rank
'
]
=
0
if
tier
>
1
else
int
(
config
.
params
[
'
build_date
'
]
)
        
elif
rank
=
=
'
build_date
'
:
            
extra_index
[
'
rank
'
]
=
int
(
config
.
params
[
'
build_date
'
]
)
        
else
:
            
extra_index
[
'
rank
'
]
=
rank
        
if
not
index
:
            
yield
task
            
continue
        
index_type
=
index
.
get
(
'
type
'
'
generic
'
)
        
task
=
index_builders
[
index_type
]
(
config
task
)
        
del
task
[
'
index
'
]
        
yield
task
transforms
.
add
def
build_task
(
config
tasks
)
:
    
for
task
in
tasks
:
        
level
=
str
(
config
.
params
[
'
level
'
]
)
        
worker_type
=
task
[
'
worker
-
type
'
]
.
format
(
level
=
level
)
        
provisioner_id
worker_type
=
worker_type
.
split
(
'
/
'
1
)
        
project
=
config
.
params
[
'
project
'
]
        
routes
=
task
.
get
(
'
routes
'
[
]
)
        
scopes
=
[
s
.
format
(
level
=
level
project
=
project
)
for
s
in
task
.
get
(
'
scopes
'
[
]
)
]
        
extra
=
task
.
get
(
'
extra
'
{
}
)
        
extra
[
'
parent
'
]
=
os
.
environ
.
get
(
'
TASK_ID
'
'
'
)
        
task_th
=
task
.
get
(
'
treeherder
'
)
        
if
task_th
:
            
extra
.
setdefault
(
'
treeherder
-
platform
'
task_th
[
'
platform
'
]
)
            
treeherder
=
extra
.
setdefault
(
'
treeherder
'
{
}
)
            
machine_platform
collection
=
task_th
[
'
platform
'
]
.
split
(
'
/
'
1
)
            
treeherder
[
'
machine
'
]
=
{
'
platform
'
:
machine_platform
}
            
treeherder
[
'
collection
'
]
=
{
collection
:
True
}
            
group_names
=
config
.
graph_config
[
'
treeherder
'
]
[
'
group
-
names
'
]
            
groupSymbol
symbol
=
split_symbol
(
task_th
[
'
symbol
'
]
)
            
if
groupSymbol
!
=
'
?
'
:
                
treeherder
[
'
groupSymbol
'
]
=
groupSymbol
                
if
groupSymbol
not
in
group_names
:
                    
path
=
os
.
path
.
join
(
config
.
path
task
.
get
(
'
job
-
from
'
'
'
)
)
                    
raise
Exception
(
UNKNOWN_GROUP_NAME
.
format
(
groupSymbol
path
)
)
                
treeherder
[
'
groupName
'
]
=
group_names
[
groupSymbol
]
            
treeherder
[
'
symbol
'
]
=
symbol
            
if
len
(
symbol
)
>
25
or
len
(
groupSymbol
)
>
25
:
                
raise
RuntimeError
(
"
Treeherder
group
and
symbol
names
must
not
be
longer
than
"
                                   
"
25
characters
:
{
}
(
see
{
}
)
"
.
format
(
                                       
task_th
[
'
symbol
'
]
                                       
TC_TREEHERDER_SCHEMA_URL
                                       
)
)
            
treeherder
[
'
jobKind
'
]
=
task_th
[
'
kind
'
]
            
treeherder
[
'
tier
'
]
=
task_th
[
'
tier
'
]
            
branch_rev
=
get_branch_rev
(
config
)
            
routes
.
append
(
                
'
{
}
.
v2
.
{
}
.
{
}
.
{
}
'
.
format
(
TREEHERDER_ROUTE_ROOT
                                        
config
.
params
[
'
project
'
]
                                        
branch_rev
                                        
config
.
params
[
'
pushlog_id
'
]
)
            
)
        
if
'
expires
-
after
'
not
in
task
:
            
task
[
'
expires
-
after
'
]
=
'
28
days
'
if
config
.
params
.
is_try
(
)
else
'
1
year
'
        
if
'
deadline
-
after
'
not
in
task
:
            
task
[
'
deadline
-
after
'
]
=
'
1
day
'
        
if
'
coalesce
'
in
task
:
            
key
=
coalesce_key
(
config
task
)
            
routes
.
append
(
'
coalesce
.
v1
.
'
+
key
)
        
if
'
priority
'
not
in
task
:
            
task
[
'
priority
'
]
=
BRANCH_PRIORITIES
.
get
(
                
config
.
params
[
'
project
'
]
                
DEFAULT_BRANCH_PRIORITY
)
        
tags
=
task
.
get
(
'
tags
'
{
}
)
        
tags
.
update
(
{
            
'
createdForUser
'
:
config
.
params
[
'
owner
'
]
            
'
kind
'
:
config
.
kind
            
'
label
'
:
task
[
'
label
'
]
        
}
)
        
task_def
=
{
            
'
provisionerId
'
:
provisioner_id
            
'
workerType
'
:
worker_type
            
'
routes
'
:
routes
            
'
created
'
:
{
'
relative
-
datestamp
'
:
'
0
seconds
'
}
            
'
deadline
'
:
{
'
relative
-
datestamp
'
:
task
[
'
deadline
-
after
'
]
}
            
'
expires
'
:
{
'
relative
-
datestamp
'
:
task
[
'
expires
-
after
'
]
}
            
'
scopes
'
:
scopes
            
'
metadata
'
:
{
                
'
description
'
:
task
[
'
description
'
]
                
'
name
'
:
task
[
'
label
'
]
                
'
owner
'
:
config
.
params
[
'
owner
'
]
                
'
source
'
:
config
.
params
.
file_url
(
config
.
path
)
            
}
            
'
extra
'
:
extra
            
'
tags
'
:
tags
            
'
priority
'
:
task
[
'
priority
'
]
        
}
        
if
task
.
get
(
'
requires
'
None
)
:
            
task_def
[
'
requires
'
]
=
task
[
'
requires
'
]
        
if
task_th
:
            
th_push_link
=
'
https
:
/
/
treeherder
.
mozilla
.
org
/
#
/
jobs
?
repo
=
{
}
&
revision
=
{
}
'
.
format
(
                
config
.
params
[
'
project
'
]
branch_rev
)
            
task_def
[
'
metadata
'
]
[
'
description
'
]
+
=
'
(
[
Treeherder
push
]
(
{
}
)
)
'
.
format
(
                
th_push_link
)
        
payload_builders
[
task
[
'
worker
'
]
[
'
implementation
'
]
]
(
config
task
task_def
)
        
attributes
=
task
.
get
(
'
attributes
'
{
}
)
        
build_platform
=
attributes
.
get
(
'
build_platform
'
)
        
resolve_keyed_by
(
task
'
run
-
on
-
projects
'
item_name
=
task
[
'
label
'
]
                         
*
*
{
'
build
-
platform
'
:
build_platform
}
)
        
attributes
[
'
run_on_projects
'
]
=
task
.
get
(
'
run
-
on
-
projects
'
[
'
all
'
]
)
        
attributes
[
'
always_target
'
]
=
task
[
'
always
-
target
'
]
        
if
task
.
get
(
'
shipping
-
phase
'
)
is
not
None
:
            
attributes
[
'
shipping_phase
'
]
=
task
[
'
shipping
-
phase
'
]
        
else
:
            
attributes
.
setdefault
(
'
shipping_phase
'
None
)
        
if
task
.
get
(
'
shipping
-
product
'
)
and
\
                
attributes
.
get
(
'
shipping_product
'
)
not
in
(
None
task
[
'
shipping
-
product
'
]
)
:
            
raise
Exception
(
                
"
{
}
shipping_product
{
}
doesn
'
t
match
task
shipping
-
product
{
}
!
"
.
format
(
                    
task
[
'
label
'
]
attributes
[
'
shipping_product
'
]
task
[
'
shipping
-
product
'
]
                
)
            
)
        
attributes
.
setdefault
(
'
shipping_product
'
task
[
'
shipping
-
product
'
]
)
        
if
task
[
'
worker
'
]
[
'
implementation
'
]
in
(
            
'
generic
-
worker
'
            
'
docker
-
engine
'
            
'
native
-
engine
'
            
'
docker
-
worker
'
        
)
:
            
payload
=
task_def
.
get
(
'
payload
'
)
            
if
payload
:
                
env
=
payload
.
setdefault
(
'
env
'
{
}
)
                
env
[
'
MOZ_AUTOMATION
'
]
=
'
1
'
        
yield
{
            
'
label
'
:
task
[
'
label
'
]
            
'
task
'
:
task_def
            
'
dependencies
'
:
task
.
get
(
'
dependencies
'
{
}
)
            
'
attributes
'
:
attributes
            
'
optimization
'
:
task
.
get
(
'
optimization
'
None
)
        
}
transforms
.
add
def
chain_of_trust
(
config
tasks
)
:
    
for
task
in
tasks
:
        
if
task
[
'
task
'
]
.
get
(
'
payload
'
{
}
)
.
get
(
'
features
'
{
}
)
.
get
(
'
chainOfTrust
'
)
:
            
image
=
task
.
get
(
'
dependencies
'
{
}
)
.
get
(
'
docker
-
image
'
)
            
if
image
:
                
cot
=
task
[
'
task
'
]
.
setdefault
(
'
extra
'
{
}
)
.
setdefault
(
'
chainOfTrust
'
{
}
)
                
cot
.
setdefault
(
'
inputs
'
{
}
)
[
'
docker
-
image
'
]
=
{
                    
'
task
-
reference
'
:
'
<
docker
-
image
>
'
                
}
        
yield
task
transforms
.
add
def
check_task_identifiers
(
config
tasks
)
:
    
"
"
"
Ensures
that
all
tasks
have
well
defined
identifiers
:
       
^
[
a
-
zA
-
Z0
-
9_
-
]
{
1
22
}
    
"
"
"
    
e
=
re
.
compile
(
"
^
[
a
-
zA
-
Z0
-
9_
-
]
{
1
22
}
"
)
    
for
task
in
tasks
:
        
for
attr
in
(
'
workerType
'
'
provisionerId
'
)
:
            
if
not
e
.
match
(
task
[
'
task
'
]
[
attr
]
)
:
                
raise
Exception
(
                    
'
task
{
}
.
{
}
is
not
a
valid
identifier
:
{
}
'
.
format
(
                        
task
[
'
label
'
]
attr
task
[
'
task
'
]
[
attr
]
)
)
        
yield
task
transforms
.
add
def
check_task_dependencies
(
config
tasks
)
:
    
"
"
"
Ensures
that
tasks
don
'
t
have
more
than
100
dependencies
.
"
"
"
    
for
task
in
tasks
:
        
if
len
(
task
[
'
dependencies
'
]
)
>
MAX_DEPENDENCIES
:
            
raise
Exception
(
                    
'
task
{
}
/
{
}
has
too
many
dependencies
(
{
}
>
{
}
)
'
.
format
(
                        
config
.
kind
task
[
'
label
'
]
len
(
task
[
'
dependencies
'
]
)
                        
MAX_DEPENDENCIES
)
)
        
yield
task
def
check_caches_are_volumes
(
task
)
:
    
"
"
"
Ensures
that
all
cache
paths
are
defined
as
volumes
.
    
Caches
and
volumes
are
the
only
filesystem
locations
whose
content
    
isn
'
t
defined
by
the
Docker
image
itself
.
Some
caches
are
optional
    
depending
on
the
job
environment
.
We
want
paths
that
are
potentially
    
caches
to
have
as
similar
behavior
regardless
of
whether
a
cache
is
    
used
.
To
help
enforce
this
we
require
that
all
paths
used
as
caches
    
to
be
declared
as
Docker
volumes
.
This
check
won
'
t
catch
all
offenders
.
    
But
it
is
better
than
nothing
.
    
"
"
"
    
volumes
=
set
(
task
[
'
worker
'
]
[
'
volumes
'
]
)
    
paths
=
set
(
c
[
'
mount
-
point
'
]
for
c
in
task
[
'
worker
'
]
.
get
(
'
caches
'
[
]
)
)
    
missing
=
paths
-
volumes
    
if
not
missing
:
        
return
    
raise
Exception
(
'
task
%
s
(
image
%
s
)
has
caches
that
are
not
declared
as
'
                    
'
Docker
volumes
:
%
s
'
                    
'
Have
you
added
them
as
VOLUMEs
in
the
Dockerfile
?
'
                    
%
(
task
[
'
label
'
]
task
[
'
worker
'
]
[
'
docker
-
image
'
]
                       
'
'
.
join
(
sorted
(
missing
)
)
)
)
transforms
.
add
def
check_run_task_caches
(
config
tasks
)
:
    
"
"
"
Audit
for
caches
requiring
run
-
task
.
    
run
-
task
manages
caches
in
certain
ways
.
If
a
cache
managed
by
run
-
task
    
is
used
by
a
non
run
-
task
task
it
could
cause
problems
.
So
we
audit
for
    
that
and
make
sure
certain
cache
names
are
exclusive
to
run
-
task
.
    
IF
YOU
ARE
TEMPTED
TO
MAKE
EXCLUSIONS
TO
THIS
POLICY
YOU
ARE
LIKELY
    
CONTRIBUTING
TECHNICAL
DEBT
AND
WILL
HAVE
TO
SOLVE
MANY
OF
THE
PROBLEMS
    
THAT
RUN
-
TASK
ALREADY
SOLVES
.
THINK
LONG
AND
HARD
BEFORE
DOING
THAT
.
    
"
"
"
    
re_reserved_caches
=
re
.
compile
(
'
'
'
^
        
(
level
-
\
d
+
-
checkouts
|
level
-
\
d
+
-
tooltool
-
cache
)
    
'
'
'
re
.
VERBOSE
)
    
re_sparse_checkout_cache
=
re
.
compile
(
'
^
level
-
\
d
+
-
checkouts
-
sparse
'
)
    
suffix
=
_run_task_suffix
(
)
    
for
task
in
tasks
:
        
payload
=
task
[
'
task
'
]
.
get
(
'
payload
'
{
}
)
        
command
=
payload
.
get
(
'
command
'
)
or
[
'
'
]
        
main_command
=
command
[
0
]
if
isinstance
(
command
[
0
]
basestring
)
else
'
'
        
run_task
=
main_command
.
endswith
(
'
run
-
task
'
)
        
require_sparse_cache
=
False
        
have_sparse_cache
=
False
        
if
run_task
:
            
for
arg
in
command
[
1
:
]
:
                
if
not
isinstance
(
arg
basestring
)
:
                    
continue
                
if
arg
=
=
'
-
-
'
:
                    
break
                
if
arg
.
startswith
(
'
-
-
sparse
-
profile
'
)
:
                    
require_sparse_cache
=
True
                    
break
        
for
cache
in
payload
.
get
(
'
cache
'
{
}
)
:
            
if
re_sparse_checkout_cache
.
match
(
cache
)
:
                
have_sparse_cache
=
True
            
if
not
re_reserved_caches
.
match
(
cache
)
:
                
continue
            
if
not
run_task
:
                
raise
Exception
(
                    
'
%
s
is
using
a
cache
(
%
s
)
reserved
for
run
-
task
'
                    
'
change
the
task
to
use
run
-
task
or
use
a
different
'
                    
'
cache
name
'
%
(
task
[
'
label
'
]
cache
)
)
            
if
not
cache
.
endswith
(
suffix
)
:
                
raise
Exception
(
                    
'
%
s
is
using
a
cache
(
%
s
)
reserved
for
run
-
task
'
                    
'
but
the
cache
name
is
not
dependent
on
the
contents
'
                    
'
of
run
-
task
;
change
the
cache
name
to
conform
to
the
'
                    
'
naming
requirements
'
%
(
task
[
'
label
'
]
cache
)
)
        
if
require_sparse_cache
and
not
have_sparse_cache
:
            
raise
Exception
(
'
%
s
is
using
a
sparse
checkout
but
not
using
'
                            
'
a
sparse
checkout
cache
;
change
the
checkout
'
                            
'
cache
name
so
it
is
sparse
aware
'
%
task
[
'
label
'
]
)
        
yield
task
