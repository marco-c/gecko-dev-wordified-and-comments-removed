"
"
"
These
transformations
take
a
task
description
and
turn
it
into
a
TaskCluster
task
definition
(
along
with
attributes
label
etc
.
)
.
The
input
to
these
transformations
is
generic
to
any
kind
of
task
but
abstracts
away
some
of
the
complexities
of
worker
implementations
scopes
and
treeherder
annotations
.
"
"
"
from
__future__
import
absolute_import
print_function
unicode_literals
import
json
import
time
from
taskgraph
.
util
.
treeherder
import
split_symbol
from
taskgraph
.
transforms
.
base
import
(
    
validate_schema
    
TransformSequence
)
from
voluptuous
import
Schema
Any
Required
Optional
Extra
from
.
gecko_v2_whitelist
import
JOB_NAME_WHITELIST
JOB_NAME_WHITELIST_ERROR
taskref_or_string
=
Any
(
    
basestring
    
{
Required
(
'
task
-
reference
'
)
:
basestring
}
)
task_description_schema
=
Schema
(
{
    
Required
(
'
label
'
)
:
basestring
    
Required
(
'
description
'
)
:
basestring
    
Optional
(
'
attributes
'
)
:
{
basestring
:
object
}
    
Optional
(
'
dependencies
'
)
:
{
basestring
:
object
}
    
Optional
(
'
expires
-
after
'
)
:
basestring
    
Optional
(
'
deadline
-
after
'
)
:
basestring
    
Optional
(
'
routes
'
)
:
[
basestring
]
    
Optional
(
'
scopes
'
)
:
[
basestring
]
    
Optional
(
'
extra
'
)
:
{
basestring
:
object
}
    
Optional
(
'
treeherder
'
)
:
{
        
'
symbol
'
:
basestring
        
'
kind
'
:
Any
(
'
build
'
'
test
'
'
other
'
)
        
'
tier
'
:
int
        
'
platform
'
:
basestring
        
Required
(
'
environments
'
default
=
[
'
production
'
'
staging
'
]
)
:
[
'
production
'
'
staging
'
]
    
}
    
Optional
(
'
index
'
)
:
{
        
'
product
'
:
Any
(
'
firefox
'
'
mobile
'
)
        
'
job
-
name
'
:
Any
(
            
basestring
            
{
                
Optional
(
'
buildbot
'
)
:
basestring
                
Required
(
'
gecko
-
v2
'
)
:
basestring
            
}
        
)
        
'
rank
'
:
Any
(
            
'
by
-
tier
'
            
int
            
'
pushdate
'
        
)
    
}
    
Optional
(
'
run
-
on
-
projects
'
)
:
[
basestring
]
    
Optional
(
'
coalesce
-
name
'
)
:
basestring
    
'
worker
-
type
'
:
basestring
    
'
worker
'
:
Any
(
{
        
Required
(
'
implementation
'
)
:
Any
(
'
docker
-
worker
'
'
docker
-
engine
'
)
        
Required
(
'
docker
-
image
'
)
:
Any
(
            
basestring
            
{
'
in
-
tree
'
:
basestring
}
        
)
        
Required
(
'
relengapi
-
proxy
'
default
=
False
)
:
bool
        
Required
(
'
chainOfTrust
'
default
=
False
)
:
bool
        
Required
(
'
taskcluster
-
proxy
'
default
=
False
)
:
bool
        
Required
(
'
allow
-
ptrace
'
default
=
False
)
:
bool
        
Required
(
'
loopback
-
video
'
default
=
False
)
:
bool
        
Required
(
'
loopback
-
audio
'
default
=
False
)
:
bool
        
Optional
(
'
caches
'
)
:
[
{
            
'
type
'
:
'
persistent
'
            
'
name
'
:
basestring
            
'
mount
-
point
'
:
basestring
        
}
]
        
Optional
(
'
artifacts
'
)
:
[
{
            
'
type
'
:
Any
(
'
file
'
'
directory
'
)
            
'
path
'
:
basestring
            
'
name
'
:
basestring
        
}
]
        
Required
(
'
env
'
default
=
{
}
)
:
{
basestring
:
taskref_or_string
}
        
'
command
'
:
[
taskref_or_string
]
        
'
max
-
run
-
time
'
:
int
        
Optional
(
'
retry
-
exit
-
status
'
)
:
int
    
}
{
        
Required
(
'
implementation
'
)
:
'
generic
-
worker
'
        
'
command
'
:
[
taskref_or_string
]
        
Optional
(
'
artifacts
'
)
:
[
{
            
'
type
'
:
Any
(
'
file
'
'
directory
'
)
            
'
path
'
:
basestring
        
}
]
        
Required
(
'
env
'
default
=
{
}
)
:
{
basestring
:
taskref_or_string
}
        
'
max
-
run
-
time
'
:
int
        
Optional
(
'
os
-
groups
'
default
=
[
]
)
:
[
basestring
]
    
}
{
        
Required
(
'
implementation
'
)
:
'
buildbot
-
bridge
'
        
'
buildername
'
:
basestring
        
'
sourcestamp
'
:
{
            
'
branch
'
:
basestring
            
Optional
(
'
revision
'
)
:
basestring
            
Optional
(
'
repository
'
)
:
basestring
            
Optional
(
'
project
'
)
:
basestring
        
}
        
'
properties
'
:
{
            
'
product
'
:
basestring
            
Extra
:
basestring
        
}
    
}
)
    
Optional
(
'
when
'
)
:
Any
(
{
        
Optional
(
'
files
-
changed
'
)
:
[
basestring
]
    
}
)
}
)
GROUP_NAMES
=
{
    
'
tc
'
:
'
Executed
by
TaskCluster
'
    
'
tc
-
e10s
'
:
'
Executed
by
TaskCluster
with
e10s
'
    
'
tc
-
Fxfn
-
l
'
:
'
Firefox
functional
tests
(
local
)
executed
by
TaskCluster
'
    
'
tc
-
Fxfn
-
l
-
e10s
'
:
'
Firefox
functional
tests
(
local
)
executed
by
TaskCluster
with
e10s
'
    
'
tc
-
Fxfn
-
r
'
:
'
Firefox
functional
tests
(
remote
)
executed
by
TaskCluster
'
    
'
tc
-
Fxfn
-
r
-
e10s
'
:
'
Firefox
functional
tests
(
remote
)
executed
by
TaskCluster
with
e10s
'
    
'
tc
-
M
'
:
'
Mochitests
executed
by
TaskCluster
'
    
'
tc
-
M
-
e10s
'
:
'
Mochitests
executed
by
TaskCluster
with
e10s
'
    
'
tc
-
R
'
:
'
Reftests
executed
by
TaskCluster
'
    
'
tc
-
R
-
e10s
'
:
'
Reftests
executed
by
TaskCluster
with
e10s
'
    
'
tc
-
VP
'
:
'
VideoPuppeteer
tests
executed
by
TaskCluster
'
    
'
tc
-
W
'
:
'
Web
platform
tests
executed
by
TaskCluster
'
    
'
tc
-
W
-
e10s
'
:
'
Web
platform
tests
executed
by
TaskCluster
with
e10s
'
    
'
tc
-
X
'
:
'
Xpcshell
tests
executed
by
TaskCluster
'
    
'
tc
-
X
-
e10s
'
:
'
Xpcshell
tests
executed
by
TaskCluster
with
e10s
'
    
'
Aries
'
:
'
Aries
Device
Image
'
    
'
Nexus
5
-
L
'
:
'
Nexus
5
-
L
Device
Image
'
    
'
Cc
'
:
'
Toolchain
builds
'
    
'
SM
-
tc
'
:
'
Spidermonkey
builds
'
}
UNKNOWN_GROUP_NAME
=
"
Treeherder
group
{
}
has
no
name
;
add
it
to
"
+
__file__
BUILDBOT_ROUTE_TEMPLATES
=
[
    
"
index
.
buildbot
.
branches
.
{
project
}
.
{
job
-
name
-
buildbot
}
"
    
"
index
.
buildbot
.
revisions
.
{
head_rev
}
.
{
project
}
.
{
job
-
name
-
buildbot
}
"
]
V2_ROUTE_TEMPLATES
=
[
    
"
index
.
gecko
.
v2
.
{
project
}
.
latest
.
{
product
}
.
{
job
-
name
-
gecko
-
v2
}
"
    
"
index
.
gecko
.
v2
.
{
project
}
.
pushdate
.
{
pushdate_long
}
.
{
product
}
.
{
job
-
name
-
gecko
-
v2
}
"
    
"
index
.
gecko
.
v2
.
{
project
}
.
revision
.
{
head_rev
}
.
{
product
}
.
{
job
-
name
-
gecko
-
v2
}
"
]
TREEHERDER_ROUTE_ROOTS
=
{
    
'
production
'
:
'
tc
-
treeherder
'
    
'
staging
'
:
'
tc
-
treeherder
-
stage
'
}
COALESCE_KEY
=
'
builds
.
{
project
}
.
{
name
}
'
payload_builders
=
{
}
def
payload_builder
(
name
)
:
    
def
wrap
(
func
)
:
        
payload_builders
[
name
]
=
func
        
return
func
    
return
wrap
payload_builder
(
'
docker
-
worker
'
)
def
build_docker_worker_payload
(
config
task
task_def
)
:
    
worker
=
task
[
'
worker
'
]
    
image
=
worker
[
'
docker
-
image
'
]
    
if
isinstance
(
image
dict
)
:
        
docker_image_task
=
'
build
-
docker
-
image
-
'
+
image
[
'
in
-
tree
'
]
        
task
.
setdefault
(
'
dependencies
'
{
}
)
[
'
docker
-
image
'
]
=
docker_image_task
        
image
=
{
            
"
path
"
:
"
public
/
image
.
tar
"
            
"
taskId
"
:
{
"
task
-
reference
"
:
"
<
docker
-
image
>
"
}
            
"
type
"
:
"
task
-
image
"
        
}
    
features
=
{
}
    
if
worker
.
get
(
'
relengapi
-
proxy
'
)
:
        
features
[
'
relengAPIProxy
'
]
=
True
    
if
worker
.
get
(
'
taskcluster
-
proxy
'
)
:
        
features
[
'
taskclusterProxy
'
]
=
True
    
if
worker
.
get
(
'
allow
-
ptrace
'
)
:
        
features
[
'
allowPtrace
'
]
=
True
        
task_def
[
'
scopes
'
]
.
append
(
'
docker
-
worker
:
feature
:
allowPtrace
'
)
    
if
worker
.
get
(
'
chainOfTrust
'
)
:
        
features
[
'
chainOfTrust
'
]
=
True
    
capabilities
=
{
}
    
for
lo
in
'
audio
'
'
video
'
:
        
if
worker
.
get
(
'
loopback
-
'
+
lo
)
:
            
capitalized
=
'
loopback
'
+
lo
.
capitalize
(
)
            
devices
=
capabilities
.
setdefault
(
'
devices
'
{
}
)
            
devices
[
capitalized
]
=
True
            
task_def
[
'
scopes
'
]
.
append
(
'
docker
-
worker
:
capability
:
device
:
'
+
capitalized
)
    
task_def
[
'
payload
'
]
=
payload
=
{
        
'
command
'
:
worker
[
'
command
'
]
        
'
image
'
:
image
        
'
env
'
:
worker
[
'
env
'
]
    
}
    
if
'
max
-
run
-
time
'
in
worker
:
        
payload
[
'
maxRunTime
'
]
=
worker
[
'
max
-
run
-
time
'
]
    
if
'
retry
-
exit
-
status
'
in
worker
:
        
payload
[
'
onExitStatus
'
]
=
{
'
retry
'
:
[
worker
[
'
retry
-
exit
-
status
'
]
]
}
    
if
'
artifacts
'
in
worker
:
        
artifacts
=
{
}
        
for
artifact
in
worker
[
'
artifacts
'
]
:
            
artifacts
[
artifact
[
'
name
'
]
]
=
{
                
'
path
'
:
artifact
[
'
path
'
]
                
'
type
'
:
artifact
[
'
type
'
]
                
'
expires
'
:
task_def
[
'
expires
'
]
            
}
        
payload
[
'
artifacts
'
]
=
artifacts
    
if
'
caches
'
in
worker
:
        
caches
=
{
}
        
for
cache
in
worker
[
'
caches
'
]
:
            
caches
[
cache
[
'
name
'
]
]
=
cache
[
'
mount
-
point
'
]
            
task_def
[
'
scopes
'
]
.
append
(
'
docker
-
worker
:
cache
:
'
+
cache
[
'
name
'
]
)
        
payload
[
'
cache
'
]
=
caches
    
if
features
:
        
payload
[
'
features
'
]
=
features
    
if
capabilities
:
        
payload
[
'
capabilities
'
]
=
capabilities
    
if
'
coalesce
-
name
'
in
task
and
int
(
config
.
params
[
'
level
'
]
)
>
1
:
        
key
=
COALESCE_KEY
.
format
(
            
project
=
config
.
params
[
'
project
'
]
            
name
=
task
[
'
coalesce
-
name
'
]
)
        
payload
[
'
supersederUrl
'
]
=
"
https
:
/
/
coalesce
.
mozilla
-
releng
.
net
/
v1
/
list
/
"
+
key
payload_builder
(
'
generic
-
worker
'
)
def
build_generic_worker_payload
(
config
task
task_def
)
:
    
worker
=
task
[
'
worker
'
]
    
artifacts
=
[
]
    
for
artifact
in
worker
[
'
artifacts
'
]
:
        
artifacts
.
append
(
{
            
'
path
'
:
artifact
[
'
path
'
]
            
'
type
'
:
artifact
[
'
type
'
]
            
'
expires
'
:
task_def
[
'
expires
'
]
        
}
)
    
task_def
[
'
payload
'
]
=
{
        
'
command
'
:
worker
[
'
command
'
]
        
'
artifacts
'
:
artifacts
        
'
env
'
:
worker
.
get
(
'
env
'
{
}
)
        
'
maxRunTime
'
:
worker
[
'
max
-
run
-
time
'
]
        
'
osGroups
'
:
worker
.
get
(
'
os
-
groups
'
[
]
)
    
}
    
if
'
retry
-
exit
-
status
'
in
worker
:
        
raise
Exception
(
"
retry
-
exit
-
status
not
supported
in
generic
-
worker
"
)
transforms
=
TransformSequence
(
)
transforms
.
add
def
validate
(
config
tasks
)
:
    
for
task
in
tasks
:
        
yield
validate_schema
(
            
task_description_schema
task
            
"
In
task
{
!
r
}
:
"
.
format
(
task
.
get
(
'
label
'
'
?
no
-
label
?
'
)
)
)
transforms
.
add
def
add_index_routes
(
config
tasks
)
:
    
for
task
in
tasks
:
        
index
=
task
.
get
(
'
index
'
)
        
routes
=
task
.
setdefault
(
'
routes
'
[
]
)
        
if
not
index
:
            
yield
task
            
continue
        
job_name
=
index
[
'
job
-
name
'
]
        
if
isinstance
(
job_name
basestring
)
:
            
base_name
type_name
=
job_name
.
rsplit
(
'
-
'
1
)
            
job_name
=
{
                
'
buildbot
'
:
base_name
                
'
gecko
-
v2
'
:
'
{
}
-
{
}
'
.
format
(
base_name
type_name
)
            
}
        
if
job_name
[
'
gecko
-
v2
'
]
not
in
JOB_NAME_WHITELIST
:
            
raise
Exception
(
JOB_NAME_WHITELIST_ERROR
.
format
(
job_name
[
'
gecko
-
v2
'
]
)
)
        
subs
=
config
.
params
.
copy
(
)
        
for
n
in
job_name
:
            
subs
[
'
job
-
name
-
'
+
n
]
=
job_name
[
n
]
        
subs
[
'
pushdate_long
'
]
=
time
.
strftime
(
            
"
%
Y
.
%
m
.
%
d
.
%
Y
%
m
%
d
%
H
%
M
%
S
"
            
time
.
gmtime
(
config
.
params
[
'
pushdate
'
]
)
)
        
subs
[
'
product
'
]
=
index
[
'
product
'
]
        
if
'
buildbot
'
in
job_name
:
            
for
tpl
in
BUILDBOT_ROUTE_TEMPLATES
:
                
routes
.
append
(
tpl
.
format
(
*
*
subs
)
)
        
if
'
gecko
-
v2
'
in
job_name
:
            
for
tpl
in
V2_ROUTE_TEMPLATES
:
                
routes
.
append
(
tpl
.
format
(
*
*
subs
)
)
        
extra_index
=
task
.
setdefault
(
'
extra
'
{
}
)
.
setdefault
(
'
index
'
{
}
)
        
rank
=
index
.
get
(
'
rank
'
'
by
-
tier
'
)
        
if
rank
=
=
'
by
-
tier
'
:
            
tier
=
task
.
get
(
'
treeherder
'
{
}
)
.
get
(
'
tier
'
3
)
            
extra_index
[
'
rank
'
]
=
0
if
tier
>
1
else
int
(
config
.
params
[
'
pushdate
'
]
)
        
elif
rank
=
=
'
pushdate
'
:
            
extra_index
[
'
rank
'
]
=
int
(
config
.
params
[
'
pushdate
'
]
)
        
else
:
            
extra_index
[
'
rank
'
]
=
rank
        
del
task
[
'
index
'
]
        
yield
task
transforms
.
add
def
build_task
(
config
tasks
)
:
    
for
task
in
tasks
:
        
worker_type
=
task
[
'
worker
-
type
'
]
.
format
(
level
=
str
(
config
.
params
[
'
level
'
]
)
)
        
provisioner_id
worker_type
=
worker_type
.
split
(
'
/
'
1
)
        
routes
=
task
.
get
(
'
routes
'
[
]
)
        
scopes
=
task
.
get
(
'
scopes
'
[
]
)
        
extra
=
task
.
get
(
'
extra
'
{
}
)
        
task_th
=
task
.
get
(
'
treeherder
'
)
        
if
task_th
:
            
extra
[
'
treeherderEnv
'
]
=
task_th
[
'
environments
'
]
            
treeherder
=
extra
.
setdefault
(
'
treeherder
'
{
}
)
            
machine_platform
collection
=
task_th
[
'
platform
'
]
.
split
(
'
/
'
1
)
            
treeherder
[
'
machine
'
]
=
{
'
platform
'
:
machine_platform
}
            
treeherder
[
'
collection
'
]
=
{
collection
:
True
}
            
groupSymbol
symbol
=
split_symbol
(
task_th
[
'
symbol
'
]
)
            
if
groupSymbol
!
=
'
?
'
:
                
treeherder
[
'
groupSymbol
'
]
=
groupSymbol
                
if
groupSymbol
not
in
GROUP_NAMES
:
                    
raise
Exception
(
UNKNOWN_GROUP_NAME
.
format
(
groupSymbol
)
)
                
treeherder
[
'
groupName
'
]
=
GROUP_NAMES
[
groupSymbol
]
            
treeherder
[
'
symbol
'
]
=
symbol
            
treeherder
[
'
jobKind
'
]
=
task_th
[
'
kind
'
]
            
treeherder
[
'
tier
'
]
=
task_th
[
'
tier
'
]
            
routes
.
extend
(
[
                
'
{
}
.
v2
.
{
}
.
{
}
.
{
}
'
.
format
(
TREEHERDER_ROUTE_ROOTS
[
env
]
                                        
config
.
params
[
'
project
'
]
                                        
config
.
params
[
'
head_rev
'
]
                                        
config
.
params
[
'
pushlog_id
'
]
)
                
for
env
in
task_th
[
'
environments
'
]
            
]
)
        
if
'
expires
-
after
'
not
in
task
:
            
task
[
'
expires
-
after
'
]
=
'
14
days
'
if
config
.
params
[
'
project
'
]
=
=
'
try
'
else
'
1
year
'
        
if
'
deadline
-
after
'
not
in
task
:
            
task
[
'
deadline
-
after
'
]
=
'
1
day
'
        
if
'
coalesce
-
name
'
in
task
and
int
(
config
.
params
[
'
level
'
]
)
>
1
:
            
key
=
COALESCE_KEY
.
format
(
                
project
=
config
.
params
[
'
project
'
]
                
name
=
task
[
'
coalesce
-
name
'
]
)
            
routes
.
append
(
'
coalesce
.
v1
.
'
+
key
)
        
task_def
=
{
            
'
provisionerId
'
:
provisioner_id
            
'
workerType
'
:
worker_type
            
'
routes
'
:
routes
            
'
created
'
:
{
'
relative
-
datestamp
'
:
'
0
seconds
'
}
            
'
deadline
'
:
{
'
relative
-
datestamp
'
:
task
[
'
deadline
-
after
'
]
}
            
'
expires
'
:
{
'
relative
-
datestamp
'
:
task
[
'
expires
-
after
'
]
}
            
'
scopes
'
:
scopes
            
'
metadata
'
:
{
                
'
description
'
:
task
[
'
description
'
]
                
'
name
'
:
task
[
'
label
'
]
                
'
owner
'
:
config
.
params
[
'
owner
'
]
                
'
source
'
:
'
{
}
/
file
/
{
}
/
{
}
'
.
format
(
                    
config
.
params
[
'
head_repository
'
]
                    
config
.
params
[
'
head_rev
'
]
                    
config
.
path
)
            
}
            
'
extra
'
:
extra
            
'
tags
'
:
{
'
createdForUser
'
:
config
.
params
[
'
owner
'
]
}
        
}
        
payload_builders
[
task
[
'
worker
'
]
[
'
implementation
'
]
]
(
config
task
task_def
)
        
attributes
=
task
.
get
(
'
attributes
'
{
}
)
        
attributes
[
'
run_on_projects
'
]
=
task
.
get
(
'
run
-
on
-
projects
'
[
'
all
'
]
)
        
yield
{
            
'
label
'
:
task
[
'
label
'
]
            
'
task
'
:
task_def
            
'
dependencies
'
:
task
.
get
(
'
dependencies
'
{
}
)
            
'
attributes
'
:
attributes
            
'
when
'
:
task
.
get
(
'
when
'
{
}
)
        
}
def
check_v2_routes
(
)
:
    
with
open
(
"
testing
/
mozharness
/
configs
/
routes
.
json
"
"
rb
"
)
as
f
:
        
routes_json
=
json
.
load
(
f
)
    
routes
=
routes_json
[
'
routes
'
]
    
for
mh
tg
in
[
            
(
'
{
index
}
'
'
index
'
)
            
(
'
{
build_product
}
'
'
{
product
}
'
)
            
(
'
{
build_name
}
-
{
build_type
}
'
'
{
job
-
name
-
gecko
-
v2
}
'
)
            
(
'
{
year
}
.
{
month
}
.
{
day
}
.
{
pushdate
}
'
'
{
pushdate_long
}
'
)
]
:
        
routes
=
[
r
.
replace
(
mh
tg
)
for
r
in
routes
]
    
if
sorted
(
routes
)
!
=
sorted
(
V2_ROUTE_TEMPLATES
)
:
        
raise
Exception
(
"
V2_ROUTE_TEMPLATES
does
not
match
Mozharness
'
s
routes
.
json
:
"
                        
"
%
s
vs
%
s
"
%
(
V2_ROUTE_TEMPLATES
routes
)
)
check_v2_routes
(
)
