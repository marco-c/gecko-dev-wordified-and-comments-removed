from
__future__
import
absolute_import
print_function
unicode_literals
import
concurrent
.
futures
as
futures
import
requests
import
requests
.
adapters
import
json
import
os
import
logging
from
slugid
import
nice
as
slugid
from
taskgraph
.
util
.
time
import
(
    
current_json_time
    
json_time_from_now
)
logger
=
logging
.
getLogger
(
__name__
)
CONCURRENCY
=
50
def
create_tasks
(
taskgraph
label_to_taskid
params
)
:
    
taskid_to_label
=
{
t
:
l
for
l
t
in
label_to_taskid
.
iteritems
(
)
}
    
session
=
requests
.
Session
(
)
    
http_adapter
=
requests
.
adapters
.
HTTPAdapter
(
pool_connections
=
CONCURRENCY
                                                 
pool_maxsize
=
CONCURRENCY
)
    
session
.
mount
(
'
https
:
/
/
'
http_adapter
)
    
session
.
mount
(
'
http
:
/
/
'
http_adapter
)
    
decision_task_id
=
os
.
environ
.
get
(
'
TASK_ID
'
)
    
task_group_id
=
decision_task_id
or
slugid
(
)
    
scheduler_id
=
'
gecko
-
level
-
{
}
'
.
format
(
params
[
'
level
'
]
)
    
with
futures
.
ThreadPoolExecutor
(
CONCURRENCY
)
as
e
:
        
fs
=
{
}
        
for
task_id
in
taskgraph
.
graph
.
visit_postorder
(
)
:
            
task_def
=
taskgraph
.
tasks
[
task_id
]
.
task
            
attributes
=
taskgraph
.
tasks
[
task_id
]
.
attributes
            
if
decision_task_id
and
not
task_def
.
get
(
'
dependencies
'
)
:
                
task_def
[
'
dependencies
'
]
=
[
decision_task_id
]
            
task_def
[
'
taskGroupId
'
]
=
task_group_id
            
task_def
[
'
schedulerId
'
]
=
scheduler_id
            
deps_fs
=
[
fs
[
dep
]
for
dep
in
task_def
.
get
(
'
dependencies
'
[
]
)
                       
if
dep
in
fs
]
            
for
f
in
futures
.
as_completed
(
deps_fs
)
:
                
f
.
result
(
)
            
fs
[
task_id
]
=
e
.
submit
(
_create_task
session
task_id
                                   
taskid_to_label
[
task_id
]
task_def
)
            
for
i
in
range
(
1
attributes
.
get
(
'
task_duplicates
'
1
)
)
:
                
fs
[
task_id
]
=
e
.
submit
(
_create_task
session
slugid
(
)
                                       
taskid_to_label
[
task_id
]
task_def
)
        
for
f
in
futures
.
as_completed
(
fs
.
values
(
)
)
:
            
f
.
result
(
)
def
_create_task
(
session
task_id
label
task_def
)
:
    
now
=
current_json_time
(
datetime_format
=
True
)
    
task_def
=
resolve_timestamps
(
now
task_def
)
    
logger
.
debug
(
"
Creating
task
with
taskId
{
}
for
{
}
"
.
format
(
task_id
label
)
)
    
res
=
session
.
put
(
'
http
:
/
/
taskcluster
/
queue
/
v1
/
task
/
{
}
'
.
format
(
task_id
)
                      
data
=
json
.
dumps
(
task_def
)
)
    
if
res
.
status_code
!
=
200
:
        
try
:
            
logger
.
error
(
res
.
json
(
)
[
'
message
'
]
)
        
except
:
            
logger
.
error
(
res
.
text
)
        
res
.
raise_for_status
(
)
def
resolve_timestamps
(
now
task_def
)
:
    
def
recurse
(
val
)
:
        
if
isinstance
(
val
list
)
:
            
return
[
recurse
(
v
)
for
v
in
val
]
        
elif
isinstance
(
val
dict
)
:
            
if
val
.
keys
(
)
=
=
[
'
relative
-
datestamp
'
]
:
                
return
json_time_from_now
(
val
[
'
relative
-
datestamp
'
]
now
)
            
else
:
                
return
{
k
:
recurse
(
v
)
for
k
v
in
val
.
iteritems
(
)
}
        
else
:
            
return
val
    
return
recurse
(
task_def
)
