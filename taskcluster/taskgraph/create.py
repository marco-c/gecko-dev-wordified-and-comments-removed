from
__future__
import
absolute_import
print_function
unicode_literals
import
concurrent
.
futures
as
futures
import
requests
import
requests
.
adapters
import
json
import
os
import
sys
import
logging
from
slugid
import
nice
as
slugid
from
taskgraph
.
util
.
parameterization
import
resolve_timestamps
from
taskgraph
.
util
.
time
import
current_json_time
logger
=
logging
.
getLogger
(
__name__
)
CONCURRENCY
=
50
testing
=
False
def
create_tasks
(
taskgraph
label_to_taskid
params
decision_task_id
=
None
)
:
    
taskid_to_label
=
{
t
:
l
for
l
t
in
label_to_taskid
.
iteritems
(
)
}
    
session
=
requests
.
Session
(
)
    
http_adapter
=
requests
.
adapters
.
HTTPAdapter
(
pool_connections
=
CONCURRENCY
                                                 
pool_maxsize
=
CONCURRENCY
)
    
session
.
mount
(
'
https
:
/
/
'
http_adapter
)
    
session
.
mount
(
'
http
:
/
/
'
http_adapter
)
    
decision_task_id
=
decision_task_id
or
os
.
environ
.
get
(
'
TASK_ID
'
)
    
task_group_id
=
decision_task_id
or
slugid
(
)
    
scheduler_id
=
'
gecko
-
level
-
{
}
'
.
format
(
params
[
'
level
'
]
)
    
for
task_id
in
taskgraph
.
graph
.
nodes
:
        
task_def
=
taskgraph
.
tasks
[
task_id
]
.
task
        
if
decision_task_id
:
            
if
not
any
(
t
in
taskgraph
.
tasks
for
t
in
task_def
.
get
(
'
dependencies
'
[
]
)
)
:
                
task_def
.
setdefault
(
'
dependencies
'
[
]
)
.
append
(
decision_task_id
)
        
task_def
[
'
taskGroupId
'
]
=
task_group_id
        
task_def
[
'
schedulerId
'
]
=
scheduler_id
    
with
futures
.
ThreadPoolExecutor
(
CONCURRENCY
)
as
e
:
        
fs
=
{
}
        
tasklist
=
set
(
taskgraph
.
graph
.
visit_postorder
(
)
)
        
alltasks
=
tasklist
.
copy
(
)
        
def
schedule_tasks
(
f
=
None
)
:
            
to_remove
=
set
(
)
            
for
task_id
in
tasklist
:
                
task_def
=
taskgraph
.
tasks
[
task_id
]
.
task
                
deps
=
set
(
task_def
.
get
(
'
dependencies
'
[
]
)
)
&
alltasks
                
if
any
(
(
d
not
in
fs
or
not
fs
[
d
]
.
done
(
)
)
for
d
in
deps
)
:
                    
continue
                
fs
[
task_id
]
=
e
.
submit
(
create_task
session
task_id
                                       
taskid_to_label
[
task_id
]
task_def
)
                
to_remove
.
add
(
task_id
)
                
attributes
=
taskgraph
.
tasks
[
task_id
]
.
attributes
                
for
i
in
range
(
1
attributes
.
get
(
'
task_duplicates
'
1
)
)
:
                    
fs
[
task_id
]
=
e
.
submit
(
create_task
session
slugid
(
)
                                           
taskid_to_label
[
task_id
]
task_def
)
            
tasklist
.
difference_update
(
to_remove
)
        
schedule_tasks
(
)
        
while
tasklist
:
            
for
f
in
futures
.
as_completed
(
fs
.
values
(
)
)
:
                
f
.
result
(
)
            
schedule_tasks
(
)
def
create_task
(
session
task_id
label
task_def
)
:
    
now
=
current_json_time
(
datetime_format
=
True
)
    
task_def
=
resolve_timestamps
(
now
task_def
)
    
if
testing
:
        
json
.
dump
(
[
task_id
task_def
]
sys
.
stdout
                  
sort_keys
=
True
indent
=
4
separators
=
(
'
'
'
:
'
)
)
        
return
    
logger
.
debug
(
"
Creating
task
with
taskId
{
}
for
{
}
"
.
format
(
task_id
label
)
)
    
res
=
session
.
put
(
'
http
:
/
/
taskcluster
/
queue
/
v1
/
task
/
{
}
'
.
format
(
task_id
)
                      
data
=
json
.
dumps
(
task_def
)
)
    
if
res
.
status_code
!
=
200
:
        
try
:
            
logger
.
error
(
res
.
json
(
)
[
'
message
'
]
)
        
except
:
            
logger
.
error
(
res
.
text
)
        
res
.
raise_for_status
(
)
