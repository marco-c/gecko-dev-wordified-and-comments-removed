import
concurrent
.
futures
as
futures
import
json
import
sys
import
logging
from
slugid
import
nice
as
slugid
from
gecko_taskgraph
.
util
.
parameterization
import
resolve_timestamps
from
gecko_taskgraph
.
util
.
time
import
current_json_time
from
gecko_taskgraph
.
util
.
taskcluster
import
get_session
CONCURRENCY
logger
=
logging
.
getLogger
(
__name__
)
testing
=
False
def
create_tasks
(
graph_config
taskgraph
label_to_taskid
params
decision_task_id
)
:
    
taskid_to_label
=
{
t
:
l
for
l
t
in
label_to_taskid
.
items
(
)
}
    
scheduler_id
=
"
{
}
-
level
-
{
}
"
.
format
(
graph_config
[
"
trust
-
domain
"
]
params
[
"
level
"
]
)
    
for
task_id
in
taskgraph
.
graph
.
nodes
:
        
task_def
=
taskgraph
.
tasks
[
task_id
]
.
task
        
if
not
any
(
t
in
taskgraph
.
tasks
for
t
in
task_def
.
get
(
"
dependencies
"
[
]
)
)
:
            
task_def
.
setdefault
(
"
dependencies
"
[
]
)
.
append
(
decision_task_id
)
        
task_def
[
"
taskGroupId
"
]
=
decision_task_id
        
task_def
[
"
schedulerId
"
]
=
scheduler_id
    
concurrency
=
CONCURRENCY
if
not
testing
else
1
    
session
=
get_session
(
)
    
with
futures
.
ThreadPoolExecutor
(
concurrency
)
as
e
:
        
fs
=
{
}
        
tasklist
=
set
(
taskgraph
.
graph
.
visit_postorder
(
)
)
        
alltasks
=
tasklist
.
copy
(
)
        
def
schedule_tasks
(
)
:
            
if
any
(
f
.
done
(
)
and
f
.
exception
(
)
for
f
in
fs
.
values
(
)
)
:
                
return
            
to_remove
=
set
(
)
            
new
=
set
(
)
            
def
submit
(
task_id
label
task_def
)
:
                
fut
=
e
.
submit
(
create_task
session
task_id
label
task_def
)
                
new
.
add
(
fut
)
                
fs
[
task_id
]
=
fut
            
for
task_id
in
tasklist
:
                
task_def
=
taskgraph
.
tasks
[
task_id
]
.
task
                
deps
=
set
(
task_def
.
get
(
"
dependencies
"
[
]
)
)
&
alltasks
                
if
any
(
(
d
not
in
fs
or
not
fs
[
d
]
.
done
(
)
)
for
d
in
deps
)
:
                    
continue
                
submit
(
task_id
taskid_to_label
[
task_id
]
task_def
)
                
to_remove
.
add
(
task_id
)
                
attributes
=
taskgraph
.
tasks
[
task_id
]
.
attributes
                
for
i
in
range
(
1
attributes
.
get
(
"
task_duplicates
"
1
)
)
:
                    
submit
(
slugid
(
)
taskid_to_label
[
task_id
]
task_def
)
            
tasklist
.
difference_update
(
to_remove
)
            
for
f
in
futures
.
as_completed
(
new
)
:
                
schedule_tasks
(
)
        
schedule_tasks
(
)
        
for
f
in
futures
.
as_completed
(
fs
.
values
(
)
)
:
            
f
.
result
(
)
def
create_task
(
session
task_id
label
task_def
)
:
    
now
=
current_json_time
(
datetime_format
=
True
)
    
task_def
=
resolve_timestamps
(
now
task_def
)
    
if
testing
:
        
json
.
dump
(
            
[
task_id
task_def
]
            
sys
.
stdout
            
sort_keys
=
True
            
indent
=
4
            
separators
=
(
"
"
"
:
"
)
        
)
        
print
(
"
"
)
        
return
    
logger
.
debug
(
f
"
Creating
task
with
taskId
{
task_id
}
for
{
label
}
"
)
    
res
=
session
.
put
(
        
f
"
http
:
/
/
taskcluster
/
queue
/
v1
/
task
/
{
task_id
}
"
data
=
json
.
dumps
(
task_def
)
    
)
    
if
res
.
status_code
!
=
200
:
        
try
:
            
logger
.
error
(
res
.
json
(
)
[
"
message
"
]
)
        
except
Exception
:
            
logger
.
error
(
res
.
text
)
        
res
.
raise_for_status
(
)
