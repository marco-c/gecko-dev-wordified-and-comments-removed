from
mozperftest
.
metrics
.
common
import
filtered_metrics
COMMON_ARGS
from
mozperftest
.
layers
import
Layer
RESULTS_TEMPLATE
=
"
"
"
\
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
                    
Results
(
{
}
)
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
{
}
"
"
"
class
ConsoleOutput
(
Layer
)
:
    
"
"
"
Output
metrics
in
the
console
.
    
"
"
"
    
name
=
"
console
"
    
activated
=
False
    
arguments
=
COMMON_ARGS
    
def
run
(
self
metadata
)
:
        
results
=
filtered_metrics
(
            
metadata
            
self
.
get_arg
(
"
output
"
)
            
self
.
get_arg
(
"
prefix
"
)
            
metrics
=
self
.
get_arg
(
"
metrics
"
)
            
split_by
=
self
.
get_arg
(
"
split
-
by
"
)
        
)
        
if
not
results
:
            
self
.
warning
(
"
No
results
left
after
filtering
"
)
            
return
metadata
        
for
name
res
in
results
.
items
(
)
:
            
subtests
=
[
                
"
{
}
:
{
}
"
.
format
(
r
[
"
subtest
"
]
[
v
[
"
value
"
]
for
v
in
r
[
"
data
"
]
]
)
                
for
r
in
res
            
]
            
self
.
info
(
                
"
\
n
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
\
n
"
                
"
=
Results
=
\
n
"
                
"
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
=
"
                
"
\
n
"
+
"
\
n
"
.
join
(
subtests
)
+
"
\
n
"
            
)
        
return
metadata
