"
use
strict
"
;
var
EXPORTED_SYMBOLS
=
[
"
UrlbarTokenizer
"
]
;
const
{
XPCOMUtils
}
=
ChromeUtils
.
import
(
"
resource
:
/
/
gre
/
modules
/
XPCOMUtils
.
jsm
"
)
;
const
{
Services
}
=
ChromeUtils
.
import
(
"
resource
:
/
/
gre
/
modules
/
Services
.
jsm
"
)
;
ChromeUtils
.
defineModuleGetter
(
this
"
Log
"
"
resource
:
/
/
gre
/
modules
/
Log
.
jsm
"
)
;
XPCOMUtils
.
defineLazyGetter
(
this
"
logger
"
(
)
=
>
Log
.
repository
.
getLogger
(
"
Urlbar
.
Tokenizer
"
)
)
;
var
UrlbarTokenizer
=
{
REGEXP_SPACES
:
/
\
s
+
/
REGEXP_LIKE_PROTOCOL
:
/
^
[
A
-
Z
+
.
-
]
+
:
\
/
{
0
2
}
(
?
!
\
/
)
/
i
REGEXP_USERINFO_INVALID_CHARS
:
/
[
^
\
w
.
~
%
!
&
'
(
)
*
+
;
=
:
-
]
/
REGEXP_HOSTPORT_INVALID_CHARS
:
/
[
^
\
[
\
]
A
-
Z0
-
9
.
:
-
]
/
i
REGEXP_HOSTPORT_IP_LIKE
:
/
^
[
a
-
f0
-
9
\
.
\
[
\
]
:
]
+
/
i
REGEXP_HOSTPORT_INVALID_IP
:
/
\
.
{
2
}
|
\
d
{
5
}
|
\
d
{
4
}
(
?
!
[
:
\
]
]
)
|
^
\
.
|
\
.
|
^
(
\
d
+
\
.
)
{
4
}
\
d
+
|
^
\
d
+
/
REGEXP_HOSTPORT_IPV4
:
/
^
(
\
d
{
1
3
}
\
.
)
{
3
}
\
d
{
1
3
}
(
:
\
d
+
)
?
/
REGEXP_HOSTPORT_IPV6
:
/
^
[
0
-
9A
-
F
:
\
[
\
]
]
{
1
4
}
/
i
REGEXP_COMMON_EMAIL
:
/
^
[
\
w
!
#
%
&
'
*
+
\
/
=
?
^
{
|
}
~
-
]
+
[
\
[
\
]
A
-
Z0
-
9
.
-
]
+
/
i
TYPE
:
{
TEXT
:
1
POSSIBLE_ORIGIN
:
2
POSSIBLE_URL
:
3
RESTRICT_HISTORY
:
4
RESTRICT_BOOKMARK
:
5
RESTRICT_TAG
:
6
RESTRICT_OPENPAGE
:
7
RESTRICT_SEARCH
:
8
RESTRICT_TITLE
:
9
RESTRICT_URL
:
10
}
RESTRICT
:
{
HISTORY
:
"
^
"
BOOKMARK
:
"
*
"
TAG
:
"
+
"
OPENPAGE
:
"
%
"
SEARCH
:
"
?
"
TITLE
:
"
#
"
URL
:
"
"
}
looksLikeUrl
(
token
options
=
{
}
)
{
if
(
token
.
length
<
2
)
return
false
;
if
(
this
.
REGEXP_SPACES
.
test
(
token
)
)
return
false
;
if
(
this
.
REGEXP_LIKE_PROTOCOL
.
test
(
token
)
)
return
true
;
let
slashIndex
=
token
.
indexOf
(
"
/
"
)
;
let
prePath
=
slashIndex
!
=
-
1
?
token
.
slice
(
0
slashIndex
)
:
token
;
if
(
!
this
.
looksLikeOrigin
(
prePath
)
)
return
false
;
let
path
=
slashIndex
!
=
-
1
?
token
.
slice
(
slashIndex
)
:
"
"
;
logger
.
debug
(
"
path
"
path
)
;
if
(
options
.
requirePath
&
&
!
path
)
return
false
;
let
atIndex
=
prePath
.
indexOf
(
"
"
)
;
let
userinfo
=
atIndex
!
=
-
1
?
prePath
.
slice
(
0
atIndex
)
:
"
"
;
if
(
path
.
length
&
&
userinfo
.
length
)
return
true
;
if
(
/
^
\
/
[
a
-
z
]
/
i
.
test
(
path
)
)
{
return
true
;
}
if
(
[
"
%
"
"
?
"
"
#
"
]
.
some
(
c
=
>
path
.
includes
(
c
)
)
)
return
true
;
let
hostPort
=
atIndex
!
=
-
1
?
prePath
.
slice
(
atIndex
+
1
)
:
prePath
;
if
(
this
.
REGEXP_HOSTPORT_IPV4
.
test
(
hostPort
)
)
return
true
;
if
(
this
.
REGEXP_HOSTPORT_IPV6
.
test
(
hostPort
)
&
&
[
"
[
"
"
]
"
"
:
"
]
.
some
(
c
=
>
hostPort
.
includes
(
c
)
)
)
return
true
;
if
(
Services
.
uriFixup
.
isDomainWhitelisted
(
hostPort
-
1
)
)
return
true
;
return
false
;
}
looksLikeOrigin
(
token
)
{
if
(
token
.
length
=
=
0
)
{
return
false
;
}
let
atIndex
=
token
.
indexOf
(
"
"
)
;
if
(
atIndex
!
=
-
1
&
&
this
.
REGEXP_COMMON_EMAIL
.
test
(
token
)
)
{
return
false
;
}
let
userinfo
=
atIndex
!
=
-
1
?
token
.
slice
(
0
atIndex
)
:
"
"
;
let
hostPort
=
atIndex
!
=
-
1
?
token
.
slice
(
atIndex
+
1
)
:
token
;
logger
.
debug
(
"
userinfo
"
userinfo
)
;
logger
.
debug
(
"
hostPort
"
hostPort
)
;
if
(
this
.
REGEXP_HOSTPORT_IPV4
.
test
(
hostPort
)
|
|
this
.
REGEXP_HOSTPORT_IPV6
.
test
(
hostPort
)
)
{
return
true
;
}
return
!
this
.
REGEXP_LIKE_PROTOCOL
.
test
(
hostPort
)
&
&
!
this
.
REGEXP_USERINFO_INVALID_CHARS
.
test
(
userinfo
)
&
&
!
this
.
REGEXP_HOSTPORT_INVALID_CHARS
.
test
(
hostPort
)
&
&
(
!
this
.
REGEXP_HOSTPORT_IP_LIKE
.
test
(
hostPort
)
|
|
!
this
.
REGEXP_HOSTPORT_INVALID_IP
.
test
(
hostPort
)
)
;
}
tokenize
(
queryContext
)
{
logger
.
info
(
"
Tokenizing
"
queryContext
)
;
let
searchString
=
queryContext
.
searchString
;
if
(
!
searchString
.
trim
(
)
)
{
queryContext
.
tokens
=
[
]
;
return
queryContext
;
}
let
unfiltered
=
splitString
(
searchString
)
;
let
tokens
=
filterTokens
(
unfiltered
)
;
queryContext
.
tokens
=
tokens
;
return
queryContext
;
}
isRestrictionToken
(
token
)
{
return
token
.
type
>
=
this
.
TYPE
.
RESTRICT_HISTORY
&
&
token
.
type
<
=
this
.
TYPE
.
RESTRICT_URL
;
}
}
;
const
CHAR_TO_TYPE_MAP
=
new
Map
(
Object
.
entries
(
UrlbarTokenizer
.
RESTRICT
)
.
map
(
(
[
type
char
]
)
=
>
[
char
UrlbarTokenizer
.
TYPE
[
RESTRICT_
{
type
}
]
]
)
)
;
function
splitString
(
searchString
)
{
let
tokens
=
searchString
.
trim
(
)
.
split
(
UrlbarTokenizer
.
REGEXP_SPACES
)
;
let
accumulator
=
[
]
;
let
hasRestrictionToken
=
tokens
.
some
(
t
=
>
CHAR_TO_TYPE_MAP
.
has
(
t
)
)
;
let
chars
=
Array
.
from
(
CHAR_TO_TYPE_MAP
.
keys
(
)
)
.
join
(
"
"
)
;
logger
.
debug
(
"
Restriction
chars
"
chars
)
;
for
(
let
token
of
tokens
)
{
if
(
!
hasRestrictionToken
&
&
token
.
length
>
1
&
&
!
UrlbarTokenizer
.
looksLikeUrl
(
token
{
requirePath
:
true
}
)
)
{
if
(
chars
.
includes
(
token
[
0
]
)
)
{
hasRestrictionToken
=
true
;
accumulator
.
push
(
token
[
0
]
)
;
accumulator
.
push
(
token
.
slice
(
1
)
)
;
continue
;
}
else
if
(
chars
.
includes
(
token
[
token
.
length
-
1
]
)
)
{
hasRestrictionToken
=
true
;
accumulator
.
push
(
token
.
slice
(
0
token
.
length
-
1
)
)
;
accumulator
.
push
(
token
[
token
.
length
-
1
]
)
;
continue
;
}
}
accumulator
.
push
(
token
)
;
}
logger
.
info
(
"
Found
tokens
"
accumulator
)
;
return
accumulator
;
}
function
filterTokens
(
tokens
)
{
let
filtered
=
[
]
;
let
restrictions
=
[
]
;
for
(
let
i
=
0
;
i
<
tokens
.
length
;
+
+
i
)
{
let
token
=
tokens
[
i
]
;
let
tokenObj
=
{
value
:
token
type
:
UrlbarTokenizer
.
TYPE
.
TEXT
}
;
let
restrictionType
=
CHAR_TO_TYPE_MAP
.
get
(
token
)
;
if
(
restrictionType
)
{
restrictions
.
push
(
{
index
:
i
type
:
restrictionType
}
)
;
}
else
if
(
UrlbarTokenizer
.
looksLikeOrigin
(
token
)
)
{
tokenObj
.
type
=
UrlbarTokenizer
.
TYPE
.
POSSIBLE_ORIGIN
;
}
else
if
(
UrlbarTokenizer
.
looksLikeUrl
(
token
{
requirePath
:
true
}
)
)
{
tokenObj
.
type
=
UrlbarTokenizer
.
TYPE
.
POSSIBLE_URL
;
}
filtered
.
push
(
tokenObj
)
;
}
if
(
restrictions
.
length
>
0
)
{
let
matchingRestrictionFound
=
false
;
let
typeRestrictionFound
=
false
;
function
assignRestriction
(
r
)
{
if
(
r
&
&
!
(
matchingRestrictionFound
&
&
typeRestrictionFound
)
)
{
if
(
[
UrlbarTokenizer
.
TYPE
.
RESTRICT_TITLE
UrlbarTokenizer
.
TYPE
.
RESTRICT_URL
]
.
includes
(
r
.
type
)
)
{
if
(
!
matchingRestrictionFound
)
{
matchingRestrictionFound
=
true
;
filtered
[
r
.
index
]
.
type
=
r
.
type
;
return
true
;
}
}
else
if
(
!
typeRestrictionFound
)
{
typeRestrictionFound
=
true
;
filtered
[
r
.
index
]
.
type
=
r
.
type
;
return
true
;
}
}
return
false
;
}
let
found
=
assignRestriction
(
restrictions
.
find
(
r
=
>
r
.
index
=
=
0
)
)
;
if
(
found
)
{
assignRestriction
(
restrictions
.
find
(
r
=
>
r
.
index
=
=
1
)
)
;
}
let
lastIndex
=
tokens
.
length
-
1
;
found
=
assignRestriction
(
restrictions
.
find
(
r
=
>
r
.
index
=
=
lastIndex
)
)
;
if
(
found
)
{
assignRestriction
(
restrictions
.
find
(
r
=
>
r
.
index
=
=
lastIndex
-
1
)
)
;
}
}
logger
.
info
(
"
Filtered
Tokens
"
tokens
)
;
return
filtered
;
}
