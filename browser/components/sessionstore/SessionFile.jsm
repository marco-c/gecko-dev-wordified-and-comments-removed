"
use
strict
"
;
var
EXPORTED_SYMBOLS
=
[
"
SessionFile
"
]
;
const
{
Services
}
=
ChromeUtils
.
import
(
"
resource
:
/
/
gre
/
modules
/
Services
.
jsm
"
)
;
const
{
XPCOMUtils
}
=
ChromeUtils
.
import
(
"
resource
:
/
/
gre
/
modules
/
XPCOMUtils
.
jsm
"
)
;
const
{
OS
}
=
ChromeUtils
.
import
(
"
resource
:
/
/
gre
/
modules
/
osfile
.
jsm
"
)
;
const
{
AsyncShutdown
}
=
ChromeUtils
.
import
(
"
resource
:
/
/
gre
/
modules
/
AsyncShutdown
.
jsm
"
)
;
XPCOMUtils
.
defineLazyServiceGetter
(
this
"
Telemetry
"
"
mozilla
.
org
/
base
/
telemetry
;
1
"
"
nsITelemetry
"
)
;
XPCOMUtils
.
defineLazyModuleGetters
(
this
{
RunState
:
"
resource
:
/
/
/
modules
/
sessionstore
/
RunState
.
jsm
"
SessionStore
:
"
resource
:
/
/
/
modules
/
sessionstore
/
SessionStore
.
jsm
"
SessionWorker
:
"
resource
:
/
/
/
modules
/
sessionstore
/
SessionWorker
.
jsm
"
}
)
;
const
PREF_UPGRADE_BACKUP
=
"
browser
.
sessionstore
.
upgradeBackup
.
latestBuildID
"
;
const
PREF_MAX_UPGRADE_BACKUPS
=
"
browser
.
sessionstore
.
upgradeBackup
.
maxUpgradeBackups
"
;
const
PREF_MAX_SERIALIZE_BACK
=
"
browser
.
sessionstore
.
max_serialize_back
"
;
const
PREF_MAX_SERIALIZE_FWD
=
"
browser
.
sessionstore
.
max_serialize_forward
"
;
XPCOMUtils
.
defineLazyPreferenceGetter
(
this
"
kMaxWriteFailures
"
"
browser
.
sessionstore
.
max_write_failures
"
5
)
;
var
SessionFile
=
{
read
(
)
{
return
SessionFileInternal
.
read
(
)
;
}
write
(
aData
)
{
return
SessionFileInternal
.
write
(
aData
)
;
}
wipe
(
)
{
return
SessionFileInternal
.
wipe
(
)
;
}
get
Paths
(
)
{
return
SessionFileInternal
.
Paths
;
}
get
MaxWriteFailures
(
)
{
return
kMaxWriteFailures
;
}
}
;
Object
.
freeze
(
SessionFile
)
;
var
Path
=
OS
.
Path
;
var
profileDir
=
OS
.
Constants
.
Path
.
profileDir
;
var
SessionFileInternal
=
{
Paths
:
Object
.
freeze
(
{
clean
:
Path
.
join
(
profileDir
"
sessionstore
.
jsonlz4
"
)
cleanBackup
:
Path
.
join
(
profileDir
"
sessionstore
-
backups
"
"
previous
.
jsonlz4
"
)
backups
:
Path
.
join
(
profileDir
"
sessionstore
-
backups
"
)
recovery
:
Path
.
join
(
profileDir
"
sessionstore
-
backups
"
"
recovery
.
jsonlz4
"
)
recoveryBackup
:
Path
.
join
(
profileDir
"
sessionstore
-
backups
"
"
recovery
.
baklz4
"
)
upgradeBackupPrefix
:
Path
.
join
(
profileDir
"
sessionstore
-
backups
"
"
upgrade
.
jsonlz4
-
"
)
get
upgradeBackup
(
)
{
let
latestBackupID
=
SessionFileInternal
.
latestUpgradeBackupID
;
if
(
!
latestBackupID
)
{
return
"
"
;
}
return
this
.
upgradeBackupPrefix
+
latestBackupID
;
}
get
nextUpgradeBackup
(
)
{
return
this
.
upgradeBackupPrefix
+
Services
.
appinfo
.
platformBuildID
;
}
get
loadOrder
(
)
{
let
order
=
[
"
clean
"
"
recovery
"
"
recoveryBackup
"
"
cleanBackup
"
]
;
if
(
SessionFileInternal
.
latestUpgradeBackupID
)
{
order
.
push
(
"
upgradeBackup
"
)
;
}
return
order
;
}
}
)
_attempts
:
0
_successes
:
0
_failures
:
0
_workerHealth
:
{
failures
:
0
}
_initializationStarted
:
false
_readOrigin
:
null
_usingOldExtension
:
false
get
latestUpgradeBackupID
(
)
{
try
{
return
Services
.
prefs
.
getCharPref
(
PREF_UPGRADE_BACKUP
)
;
}
catch
(
ex
)
{
return
undefined
;
}
}
async
_readInternal
(
useOldExtension
)
{
let
result
;
let
noFilesFound
=
true
;
this
.
_usingOldExtension
=
useOldExtension
;
for
(
let
key
of
this
.
Paths
.
loadOrder
)
{
let
corrupted
=
false
;
let
exists
=
true
;
try
{
let
path
;
let
startMs
=
Date
.
now
(
)
;
let
options
=
{
encoding
:
"
utf
-
8
"
}
;
if
(
useOldExtension
)
{
path
=
this
.
Paths
[
key
]
.
replace
(
"
jsonlz4
"
"
js
"
)
.
replace
(
"
baklz4
"
"
bak
"
)
;
}
else
{
path
=
this
.
Paths
[
key
]
;
options
.
compression
=
"
lz4
"
;
}
let
source
=
await
OS
.
File
.
read
(
path
options
)
;
let
parsed
=
JSON
.
parse
(
source
)
;
if
(
!
SessionStore
.
isFormatVersionCompatible
(
parsed
.
version
|
|
[
"
sessionrestore
"
0
]
)
)
{
Cu
.
reportError
(
"
Cannot
extract
data
from
Session
Restore
file
"
+
path
+
"
.
Wrong
format
/
version
:
"
+
JSON
.
stringify
(
parsed
.
version
)
+
"
.
"
)
;
continue
;
}
result
=
{
origin
:
key
source
parsed
useOldExtension
}
;
Telemetry
.
getHistogramById
(
"
FX_SESSION_RESTORE_CORRUPT_FILE
"
)
.
add
(
false
)
;
Telemetry
.
getHistogramById
(
"
FX_SESSION_RESTORE_READ_FILE_MS
"
)
.
add
(
Date
.
now
(
)
-
startMs
)
;
break
;
}
catch
(
ex
)
{
if
(
ex
instanceof
OS
.
File
.
Error
&
&
ex
.
becauseNoSuchFile
)
{
exists
=
false
;
}
else
if
(
ex
instanceof
OS
.
File
.
Error
)
{
console
.
error
(
"
Could
not
read
session
file
"
ex
ex
.
stack
)
;
corrupted
=
true
;
}
else
if
(
ex
instanceof
SyntaxError
)
{
console
.
error
(
"
Corrupt
session
file
(
invalid
JSON
found
)
"
ex
ex
.
stack
)
;
corrupted
=
true
;
}
}
finally
{
if
(
exists
)
{
noFilesFound
=
false
;
Telemetry
.
getHistogramById
(
"
FX_SESSION_RESTORE_CORRUPT_FILE
"
)
.
add
(
corrupted
)
;
}
}
}
return
{
result
noFilesFound
}
;
}
async
read
(
)
{
let
{
result
noFilesFound
}
=
await
this
.
_readInternal
(
false
)
;
if
(
!
result
)
{
let
r
=
await
this
.
_readInternal
(
true
)
;
result
=
r
.
result
;
}
let
allCorrupt
=
!
noFilesFound
&
&
!
result
;
Telemetry
.
getHistogramById
(
"
FX_SESSION_RESTORE_ALL_FILES_CORRUPT
"
)
.
add
(
allCorrupt
)
;
if
(
!
result
)
{
result
=
{
origin
:
"
empty
"
source
:
"
"
parsed
:
null
useOldExtension
:
false
}
;
}
this
.
_readOrigin
=
result
.
origin
;
result
.
noFilesFound
=
noFilesFound
;
this
.
_initWorker
(
)
;
return
result
;
}
_initWorker
(
)
{
return
new
Promise
(
resolve
=
>
{
if
(
this
.
_initializationStarted
)
{
resolve
(
)
;
return
;
}
if
(
!
this
.
_readOrigin
)
{
throw
new
Error
(
"
_initWorker
called
too
early
!
Please
read
the
session
file
from
disk
first
.
"
)
;
}
this
.
_initializationStarted
=
true
;
SessionWorker
.
post
(
"
init
"
[
this
.
_readOrigin
this
.
_usingOldExtension
this
.
Paths
{
maxUpgradeBackups
:
Services
.
prefs
.
getIntPref
(
PREF_MAX_UPGRADE_BACKUPS
3
)
maxSerializeBack
:
Services
.
prefs
.
getIntPref
(
PREF_MAX_SERIALIZE_BACK
10
)
maxSerializeForward
:
Services
.
prefs
.
getIntPref
(
PREF_MAX_SERIALIZE_FWD
-
1
)
}
]
)
.
catch
(
err
=
>
{
Promise
.
reject
(
err
)
;
}
)
.
then
(
resolve
)
;
}
)
;
}
async
_postToWorker
(
.
.
.
args
)
{
await
this
.
_initWorker
(
)
;
return
SessionWorker
.
post
(
.
.
.
args
)
;
}
_checkWorkerHealth
(
)
{
if
(
this
.
_workerHealth
.
failures
>
=
kMaxWriteFailures
)
{
SessionWorker
.
terminate
(
)
;
this
.
_initializationStarted
=
false
;
this
.
_workerHealth
.
failures
=
0
;
}
}
write
(
aData
)
{
if
(
RunState
.
isClosed
)
{
return
Promise
.
reject
(
new
Error
(
"
SessionFile
is
closed
"
)
)
;
}
let
isFinalWrite
=
false
;
if
(
RunState
.
isClosing
)
{
isFinalWrite
=
true
;
RunState
.
setClosed
(
)
;
}
let
performShutdownCleanup
=
isFinalWrite
&
&
!
SessionStore
.
willAutoRestore
;
this
.
_attempts
+
+
;
let
options
=
{
isFinalWrite
performShutdownCleanup
}
;
let
promise
=
this
.
_postToWorker
(
"
write
"
[
aData
options
]
)
;
promise
=
promise
.
then
(
msg
=
>
{
this
.
_recordTelemetry
(
msg
.
telemetry
)
;
this
.
_successes
+
+
;
if
(
msg
.
result
.
upgradeBackup
)
{
Services
.
prefs
.
setCharPref
(
PREF_UPGRADE_BACKUP
Services
.
appinfo
.
platformBuildID
)
;
}
}
err
=
>
{
console
.
error
(
"
Could
not
write
session
state
file
"
err
err
.
stack
)
;
this
.
_failures
+
+
;
this
.
_workerHealth
.
failures
+
+
;
}
)
;
AsyncShutdown
.
profileBeforeChange
.
addBlocker
(
"
SessionFile
:
Finish
writing
Session
Restore
data
"
promise
{
fetchState
:
(
)
=
>
(
{
options
attempts
:
this
.
_attempts
successes
:
this
.
_successes
failures
:
this
.
_failures
}
)
}
)
;
return
promise
.
then
(
(
)
=
>
{
AsyncShutdown
.
profileBeforeChange
.
removeBlocker
(
promise
)
;
if
(
isFinalWrite
)
{
Services
.
obs
.
notifyObservers
(
null
"
sessionstore
-
final
-
state
-
write
-
complete
"
)
;
}
else
{
this
.
_checkWorkerHealth
(
)
;
}
}
)
;
}
wipe
(
)
{
return
this
.
_postToWorker
(
"
wipe
"
)
.
then
(
(
)
=
>
{
this
.
_initializationStarted
=
false
;
}
)
;
}
_recordTelemetry
(
telemetry
)
{
for
(
let
id
of
Object
.
keys
(
telemetry
)
)
{
let
value
=
telemetry
[
id
]
;
let
samples
=
[
]
;
if
(
Array
.
isArray
(
value
)
)
{
samples
.
push
(
.
.
.
value
)
;
}
else
{
samples
.
push
(
value
)
;
}
let
histogram
=
Telemetry
.
getHistogramById
(
id
)
;
for
(
let
sample
of
samples
)
{
histogram
.
add
(
sample
)
;
}
}
}
}
;
