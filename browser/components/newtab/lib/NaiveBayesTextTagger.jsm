"
use
strict
"
;
const
{
toksToTfIdfVector
}
=
ChromeUtils
.
import
(
"
resource
:
/
/
activity
-
stream
/
lib
/
Tokenize
.
jsm
"
)
;
this
.
NaiveBayesTextTagger
=
class
NaiveBayesTextTagger
{
constructor
(
model
)
{
this
.
model
=
model
;
}
tagTokens
(
tokens
)
{
let
fv
=
toksToTfIdfVector
(
tokens
this
.
model
.
vocab_idfs
)
;
let
bestLogProb
=
null
;
let
bestClassId
=
-
1
;
let
bestClassLabel
=
null
;
let
logSumExp
=
0
.
0
;
for
(
let
classId
=
0
;
classId
<
this
.
model
.
classes
.
length
;
classId
+
+
)
{
let
classModel
=
this
.
model
.
classes
[
classId
]
;
let
classLogProb
=
classModel
.
log_prior
;
for
(
let
pair
of
Object
.
values
(
fv
)
)
{
let
[
termId
tfidf
]
=
pair
;
classLogProb
+
=
tfidf
*
classModel
.
feature_log_probs
[
termId
]
;
}
if
(
(
bestLogProb
=
=
=
null
)
|
|
(
classLogProb
>
bestLogProb
)
)
{
bestLogProb
=
classLogProb
;
bestClassId
=
classId
;
}
logSumExp
+
=
Math
.
exp
(
classLogProb
)
;
}
logSumExp
=
Math
.
log
(
logSumExp
)
;
bestLogProb
-
=
logSumExp
;
if
(
bestClassId
=
=
=
this
.
model
.
positive_class_id
)
{
bestClassLabel
=
this
.
model
.
positive_class_label
;
}
else
{
bestClassLabel
=
null
;
}
let
confident
=
(
(
bestClassId
=
=
=
this
.
model
.
positive_class_id
)
&
&
(
bestLogProb
>
this
.
model
.
positive_class_threshold_log_prob
)
)
;
return
{
"
label
"
:
bestClassLabel
"
logProb
"
:
bestLogProb
"
confident
"
:
confident
}
;
}
}
;
const
EXPORTED_SYMBOLS
=
[
"
NaiveBayesTextTagger
"
]
;
