"
use
strict
"
;
var
EXPORTED_SYMBOLS
=
[
"
NaiveBayesTextTagger
"
]
;
const
NaiveBayesTextTagger
=
class
NaiveBayesTextTagger
{
constructor
(
model
toksToTfIdfVector
)
{
this
.
model
=
model
;
this
.
toksToTfIdfVector
=
toksToTfIdfVector
;
}
tagTokens
(
tokens
)
{
let
fv
=
this
.
toksToTfIdfVector
(
tokens
this
.
model
.
vocab_idfs
)
;
let
bestLogProb
=
null
;
let
bestClassId
=
-
1
;
let
bestClassLabel
=
null
;
let
logSumExp
=
0
.
0
;
for
(
let
classId
=
0
;
classId
<
this
.
model
.
classes
.
length
;
classId
+
+
)
{
let
classModel
=
this
.
model
.
classes
[
classId
]
;
let
classLogProb
=
classModel
.
log_prior
;
for
(
let
pair
of
Object
.
values
(
fv
)
)
{
let
[
termId
tfidf
]
=
pair
;
classLogProb
+
=
tfidf
*
classModel
.
feature_log_probs
[
termId
]
;
}
if
(
bestLogProb
=
=
=
null
|
|
classLogProb
>
bestLogProb
)
{
bestLogProb
=
classLogProb
;
bestClassId
=
classId
;
}
logSumExp
+
=
Math
.
exp
(
classLogProb
)
;
}
logSumExp
=
Math
.
log
(
logSumExp
)
;
bestLogProb
-
=
logSumExp
;
if
(
bestClassId
=
=
=
this
.
model
.
positive_class_id
)
{
bestClassLabel
=
this
.
model
.
positive_class_label
;
}
else
{
bestClassLabel
=
null
;
}
let
confident
=
bestClassId
=
=
=
this
.
model
.
positive_class_id
&
&
bestLogProb
>
this
.
model
.
positive_class_threshold_log_prob
;
return
{
label
:
bestClassLabel
logProb
:
bestLogProb
confident
}
;
}
}
;
