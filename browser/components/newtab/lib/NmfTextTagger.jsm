"
use
strict
"
;
const
{
toksToTfIdfVector
}
=
ChromeUtils
.
import
(
"
resource
:
/
/
activity
-
stream
/
lib
/
Tokenize
.
jsm
"
)
;
this
.
NmfTextTagger
=
class
NmfTextTagger
{
constructor
(
model
)
{
this
.
model
=
model
;
}
tagTokens
(
tokens
)
{
let
fv
=
toksToTfIdfVector
(
tokens
this
.
model
.
vocab_idfs
)
;
let
fve
=
Object
.
values
(
fv
)
;
let
sum
=
0
.
0
;
for
(
let
pair
of
fve
)
{
sum
+
=
pair
[
1
]
;
}
for
(
let
i
=
0
;
i
<
fve
.
length
;
i
+
+
)
{
fve
[
i
]
[
1
]
/
=
sum
;
}
let
toksInLatentSpace
=
[
]
;
for
(
let
topicVect
of
this
.
model
.
topic_word
)
{
let
fvDotTwv
=
0
;
for
(
let
pair
of
fve
)
{
let
[
termId
tfidf
]
=
pair
;
fvDotTwv
+
=
tfidf
*
topicVect
[
termId
]
;
}
toksInLatentSpace
.
push
(
fvDotTwv
)
;
}
let
predictions
=
{
}
;
Object
.
keys
(
this
.
model
.
document_topic
)
.
forEach
(
topic
=
>
{
let
score
=
0
;
for
(
let
i
=
0
;
i
<
toksInLatentSpace
.
length
;
i
+
+
)
{
score
+
=
toksInLatentSpace
[
i
]
*
this
.
model
.
document_topic
[
topic
]
[
i
]
;
}
predictions
[
topic
]
=
score
;
}
)
;
return
predictions
;
}
}
;
const
EXPORTED_SYMBOLS
=
[
"
NmfTextTagger
"
]
;
