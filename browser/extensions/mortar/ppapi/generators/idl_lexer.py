"
"
"
Lexer
for
PPAPI
IDL
"
"
"
import
os
.
path
import
re
import
sys
try
:
  
from
ply
import
lex
except
:
  
module_path
module_name
=
os
.
path
.
split
(
__file__
)
  
third_party
=
os
.
path
.
join
(
module_path
'
.
.
'
'
.
.
'
'
third_party
'
)
  
sys
.
path
.
append
(
third_party
)
  
from
ply
import
lex
from
idl_option
import
GetOption
Option
ParseOptions
Option
(
'
output
'
'
Generate
output
.
'
)
class
IDLLexer
(
object
)
:
  
tokens
=
[
      
'
COMMENT
'
      
'
DESCRIBE
'
      
'
ENUM
'
      
'
LABEL
'
      
'
SYMBOL
'
      
'
INLINE
'
      
'
INTERFACE
'
      
'
STRUCT
'
      
'
TYPEDEF
'
      
'
OR
'
      
'
CALLBACK
'
      
'
DICTIONARY
'
      
'
OPTIONAL
'
      
'
STATIC
'
      
'
NAMESPACE
'
      
'
FLOAT
'
      
'
OCT
'
      
'
INT
'
      
'
HEX
'
      
'
STRING
'
      
'
LSHIFT
'
      
'
RSHIFT
'
  
]
  
keywords
=
{
    
'
describe
'
:
'
DESCRIBE
'
    
'
enum
'
:
'
ENUM
'
    
'
label
'
:
'
LABEL
'
    
'
interface
'
:
'
INTERFACE
'
    
'
readonly
'
:
'
READONLY
'
    
'
struct
'
:
'
STRUCT
'
    
'
typedef
'
:
'
TYPEDEF
'
    
'
callback
'
:
'
CALLBACK
'
    
'
dictionary
'
:
'
DICTIONARY
'
    
'
optional
'
:
'
OPTIONAL
'
    
'
static
'
:
'
STATIC
'
    
'
namespace
'
:
'
NAMESPACE
'
    
'
or
'
:
'
OR
'
  
}
  
literals
=
'
"
*
.
(
)
{
}
[
]
;
:
=
+
-
/
~
|
&
^
?
'
  
t_ignore
=
'
\
t
'
  
t_FLOAT
=
r
'
-
?
(
\
d
+
\
.
\
d
*
|
\
d
*
\
.
\
d
+
)
(
[
Ee
]
[
+
-
]
?
\
d
+
)
?
|
-
?
\
d
+
[
Ee
]
[
+
-
]
?
\
d
+
'
  
t_INT
=
r
'
-
?
[
0
-
9
]
+
[
uU
]
?
'
  
t_OCT
=
r
'
-
?
0
[
0
-
7
]
+
'
  
t_HEX
=
r
'
-
?
0
[
Xx
]
[
0
-
9A
-
Fa
-
f
]
+
'
  
t_LSHIFT
=
r
'
<
<
'
  
t_RSHIFT
=
r
'
>
>
'
  
def
t_LINE_END
(
self
t
)
:
    
r
'
\
n
+
'
    
self
.
AddLines
(
len
(
t
.
value
)
)
  
def
t_STRING
(
self
t
)
:
    
r
'
"
[
^
"
]
*
"
'
    
t
.
value
=
t
.
value
[
1
:
-
1
]
    
self
.
AddLines
(
t
.
value
.
count
(
'
\
n
'
)
)
    
return
t
  
def
t_COMMENT
(
self
t
)
:
    
r
'
(
/
\
*
(
.
|
\
n
)
*
?
\
*
/
)
|
(
/
/
.
*
(
\
n
[
\
t
]
*
/
/
.
*
)
*
)
'
    
self
.
AddLines
(
t
.
value
.
count
(
'
\
n
'
)
)
    
return
t
  
def
t_INLINE
(
self
t
)
:
    
r
'
\
#
inline
(
.
|
\
n
)
*
?
\
#
endinl
.
*
'
    
self
.
AddLines
(
t
.
value
.
count
(
'
\
n
'
)
)
    
return
t
  
def
t_KEYWORD_SYMBOL
(
self
t
)
:
    
r
'
_
?
[
A
-
Za
-
z
]
[
A
-
Za
-
z_0
-
9
]
*
'
    
t
.
type
=
self
.
keywords
.
get
(
t
.
value
'
SYMBOL
'
)
    
if
t
.
value
[
0
]
=
=
'
_
'
:
      
t
.
value
=
t
.
value
[
1
:
]
    
return
t
  
def
t_ANY_error
(
self
t
)
:
    
msg
=
"
Unrecognized
input
"
    
line
=
self
.
lexobj
.
lineno
    
if
line
>
=
len
(
self
.
index
)
:
      
word
=
t
.
value
.
split
(
)
[
0
]
      
offs
=
self
.
lines
[
line
-
1
]
.
find
(
word
)
      
self
.
index
.
append
(
self
.
lexobj
.
lexpos
-
offs
)
      
msg
=
"
Unexpected
EoF
reached
after
"
    
pos
=
self
.
lexobj
.
lexpos
-
self
.
index
[
line
]
    
file
=
self
.
lexobj
.
filename
    
out
=
self
.
ErrorMessage
(
file
line
pos
msg
)
    
sys
.
stderr
.
write
(
out
+
'
\
n
'
)
    
self
.
lex_errors
+
=
1
  
def
AddLines
(
self
count
)
:
    
self
.
lexobj
.
lineno
+
=
count
    
for
i
in
range
(
count
)
:
      
self
.
index
.
append
(
self
.
lexobj
.
lexpos
)
  
def
FileLineMsg
(
self
file
line
msg
)
:
    
if
file
:
return
"
%
s
(
%
d
)
:
%
s
"
%
(
file
line
+
1
msg
)
    
return
"
<
BuiltIn
>
:
%
s
"
%
msg
  
def
SourceLine
(
self
file
line
pos
)
:
    
caret
=
'
\
t
^
'
.
expandtabs
(
pos
)
    
return
"
%
s
\
n
%
s
"
%
(
self
.
lines
[
line
-
1
]
caret
)
  
def
ErrorMessage
(
self
file
line
pos
msg
)
:
    
return
"
\
n
%
s
\
n
%
s
"
%
(
        
self
.
FileLineMsg
(
file
line
msg
)
        
self
.
SourceLine
(
file
line
pos
)
)
  
def
SetData
(
self
filename
data
)
:
    
self
.
lexobj
.
lineno
=
1
    
self
.
lexobj
.
filename
=
filename
    
self
.
lines
=
data
.
split
(
'
\
n
'
)
    
self
.
index
=
[
0
]
    
self
.
lexobj
.
input
(
data
)
    
self
.
lex_errors
=
0
  
def
__init__
(
self
)
:
    
self
.
lexobj
=
lex
.
lex
(
object
=
self
lextab
=
None
optimize
=
0
)
def
FilesToTokens
(
filenames
verbose
=
False
)
:
  
lexer
=
IDLLexer
(
)
  
outlist
=
[
]
  
for
filename
in
filenames
:
    
data
=
open
(
filename
)
.
read
(
)
    
lexer
.
SetData
(
filename
data
)
    
if
verbose
:
sys
.
stdout
.
write
(
'
Loaded
%
s
.
.
.
\
n
'
%
filename
)
    
while
1
:
      
t
=
lexer
.
lexobj
.
token
(
)
      
if
t
is
None
:
break
      
outlist
.
append
(
t
)
  
return
outlist
def
TokensFromText
(
text
)
:
  
lexer
=
IDLLexer
(
)
  
lexer
.
SetData
(
'
unknown
'
text
)
  
outlist
=
[
]
  
while
1
:
    
t
=
lexer
.
lexobj
.
token
(
)
    
if
t
is
None
:
break
    
outlist
.
append
(
t
.
value
)
  
return
outlist
def
TextToTokens
(
source
)
:
  
lexer
=
IDLLexer
(
)
  
outlist
=
[
]
  
lexer
.
SetData
(
'
AUTO
'
source
)
  
while
1
:
    
t
=
lexer
.
lexobj
.
token
(
)
    
if
t
is
None
:
break
    
outlist
.
append
(
t
.
value
)
  
return
outlist
def
TestSame
(
values1
)
:
  
text
=
'
\
n
'
.
join
(
values1
)
  
values2
=
TextToTokens
(
text
)
  
count1
=
len
(
values1
)
  
count2
=
len
(
values2
)
  
if
count1
!
=
count2
:
    
print
"
Size
mismatch
original
%
d
vs
%
d
\
n
"
%
(
count1
count2
)
    
if
count1
>
count2
:
count1
=
count2
  
for
i
in
range
(
count1
)
:
    
if
values1
[
i
]
!
=
values2
[
i
]
:
      
print
"
%
d
>
>
%
s
<
<
>
>
%
s
<
<
"
%
(
i
values1
[
i
]
values2
[
i
]
)
  
if
GetOption
(
'
output
'
)
:
    
sys
.
stdout
.
write
(
'
Generating
original
.
txt
and
tokenized
.
txt
\
n
'
)
    
open
(
'
original
.
txt
'
'
w
'
)
.
write
(
src1
)
    
open
(
'
tokenized
.
txt
'
'
w
'
)
.
write
(
src2
)
  
if
values1
=
=
values2
:
    
sys
.
stdout
.
write
(
'
Same
:
Pass
\
n
'
)
    
return
0
  
print
"
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
\
n
%
s
\
n
%
s
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
\
n
"
%
(
src1
src2
)
  
sys
.
stdout
.
write
(
'
Same
:
Failed
\
n
'
)
  
return
-
1
def
TestExpect
(
tokens
)
:
  
count
=
len
(
tokens
)
  
index
=
0
  
errors
=
0
  
while
index
<
count
:
    
type
=
tokens
[
index
]
.
value
    
token
=
tokens
[
index
+
1
]
    
index
+
=
2
    
if
type
!
=
token
.
type
:
      
sys
.
stderr
.
write
(
'
Mismatch
:
Expected
%
s
but
got
%
s
=
%
s
.
\
n
'
%
                       
(
type
token
.
type
token
.
value
)
)
      
errors
+
=
1
  
if
not
errors
:
    
sys
.
stdout
.
write
(
'
Expect
:
Pass
\
n
'
)
    
return
0
  
sys
.
stdout
.
write
(
'
Expect
:
Failed
\
n
'
)
  
return
-
1
def
Main
(
args
)
:
  
filenames
=
ParseOptions
(
args
)
  
try
:
    
tokens
=
FilesToTokens
(
filenames
GetOption
(
'
verbose
'
)
)
    
values
=
[
tok
.
value
for
tok
in
tokens
]
    
if
GetOption
(
'
output
'
)
:
sys
.
stdout
.
write
(
'
<
>
'
.
join
(
values
)
+
'
\
n
'
)
    
if
GetOption
(
'
test
'
)
:
      
if
TestSame
(
values
)
:
        
return
-
1
      
if
TestExpect
(
tokens
)
:
        
return
-
1
    
return
0
  
except
lex
.
LexError
as
le
:
    
sys
.
stderr
.
write
(
'
%
s
\
n
'
%
str
(
le
)
)
  
return
-
1
if
__name__
=
=
'
__main__
'
:
  
sys
.
exit
(
Main
(
sys
.
argv
[
1
:
]
)
)
