#
include
"
MediaPipeline
.
h
"
#
include
<
inttypes
.
h
>
#
include
<
math
.
h
>
#
include
"
AudioSegment
.
h
"
#
include
"
AudioConverter
.
h
"
#
include
"
CSFLog
.
h
"
#
include
"
DOMMediaStream
.
h
"
#
include
"
ImageContainer
.
h
"
#
include
"
ImageTypes
.
h
"
#
include
"
Layers
.
h
"
#
include
"
LayersLogging
.
h
"
#
include
"
MediaEngine
.
h
"
#
include
"
MediaPipelineFilter
.
h
"
#
include
"
MediaSegment
.
h
"
#
include
"
MediaStreamGraphImpl
.
h
"
#
include
"
MediaStreamListener
.
h
"
#
include
"
MediaStreamTrack
.
h
"
#
include
"
MediaStreamVideoSink
.
h
"
#
include
"
RtpLogger
.
h
"
#
include
"
VideoSegment
.
h
"
#
include
"
VideoStreamTrack
.
h
"
#
include
"
VideoUtils
.
h
"
#
include
"
libyuv
/
convert
.
h
"
#
include
"
mozilla
/
PeerIdentity
.
h
"
#
include
"
mozilla
/
Preferences
.
h
"
#
include
"
mozilla
/
SharedThreadPool
.
h
"
#
include
"
mozilla
/
Sprintf
.
h
"
#
include
"
mozilla
/
TaskQueue
.
h
"
#
include
"
mozilla
/
UniquePtr
.
h
"
#
include
"
mozilla
/
UniquePtrExtensions
.
h
"
#
include
"
mozilla
/
dom
/
RTCStatsReportBinding
.
h
"
#
include
"
mozilla
/
gfx
/
Point
.
h
"
#
include
"
mozilla
/
gfx
/
Types
.
h
"
#
include
"
nsError
.
h
"
#
include
"
nsThreadUtils
.
h
"
#
include
"
nspr
.
h
"
#
include
"
runnable_utils
.
h
"
#
include
"
srtp
.
h
"
#
include
"
transportflow
.
h
"
#
include
"
transportlayer
.
h
"
#
include
"
transportlayerdtls
.
h
"
#
include
"
transportlayerice
.
h
"
#
include
"
Tracing
.
h
"
#
include
"
webrtc
/
base
/
bind
.
h
"
#
include
"
webrtc
/
base
/
keep_ref_until_done
.
h
"
#
include
"
webrtc
/
common_types
.
h
"
#
include
"
webrtc
/
common_video
/
include
/
i420_buffer_pool
.
h
"
#
include
"
webrtc
/
common_video
/
include
/
video_frame_buffer
.
h
"
#
include
"
webrtc
/
common_video
/
libyuv
/
include
/
webrtc_libyuv
.
h
"
#
define
AUDIO_SAMPLE_BUFFER_MAX_BYTES
(
480
*
2
*
2
)
static_assert
(
(
WEBRTC_MAX_SAMPLE_RATE
/
100
)
*
sizeof
(
uint16_t
)
*
2
<
=
AUDIO_SAMPLE_BUFFER_MAX_BYTES
"
AUDIO_SAMPLE_BUFFER_MAX_BYTES
is
not
large
enough
"
)
;
#
define
CONVERTER_BUFFER_POOL_SIZE
5
using
namespace
mozilla
;
using
namespace
mozilla
:
:
dom
;
using
namespace
mozilla
:
:
gfx
;
using
namespace
mozilla
:
:
layers
;
static
const
char
*
mpLogTag
=
"
MediaPipeline
"
;
#
ifdef
LOGTAG
#
undef
LOGTAG
#
endif
#
define
LOGTAG
mpLogTag
namespace
mozilla
{
extern
mozilla
:
:
LogModule
*
AudioLogModule
(
)
;
class
VideoConverterListener
{
public
:
NS_INLINE_DECL_THREADSAFE_REFCOUNTING
(
VideoConverterListener
)
virtual
void
OnVideoFrameConverted
(
const
webrtc
:
:
VideoFrame
&
aVideoFrame
)
=
0
;
protected
:
virtual
~
VideoConverterListener
(
)
{
}
}
;
class
VideoFrameConverter
{
public
:
NS_INLINE_DECL_THREADSAFE_REFCOUNTING
(
VideoFrameConverter
)
VideoFrameConverter
(
)
:
mLength
(
0
)
mTaskQueue
(
new
TaskQueue
(
GetMediaThreadPool
(
MediaThreadType
:
:
WEBRTC_DECODER
)
"
VideoFrameConverter
"
)
)
mBufferPool
(
false
CONVERTER_BUFFER_POOL_SIZE
)
mLastImage
(
-
1
)
#
ifdef
DEBUG
mThrottleCount
(
0
)
mThrottleRecord
(
0
)
#
endif
mMutex
(
"
VideoFrameConverter
"
)
{
MOZ_COUNT_CTOR
(
VideoFrameConverter
)
;
}
void
QueueVideoChunk
(
const
VideoChunk
&
aChunk
bool
aForceBlack
)
{
IntSize
size
=
aChunk
.
mFrame
.
GetIntrinsicSize
(
)
;
if
(
size
.
width
=
=
0
|
|
size
.
width
=
=
0
)
{
return
;
}
if
(
aChunk
.
IsNull
(
)
)
{
aForceBlack
=
true
;
}
else
{
aForceBlack
=
aChunk
.
mFrame
.
GetForceBlack
(
)
;
}
int32_t
serial
;
if
(
aForceBlack
)
{
serial
=
-
1
;
}
else
{
serial
=
aChunk
.
mFrame
.
GetImage
(
)
-
>
GetSerial
(
)
;
}
const
double
duplicateMinFps
=
1
.
0
;
TimeStamp
t
=
aChunk
.
mTimeStamp
;
MOZ_ASSERT
(
!
t
.
IsNull
(
)
)
;
if
(
!
t
.
IsNull
(
)
&
&
serial
=
=
mLastImage
&
&
!
mLastFrameSent
.
IsNull
(
)
&
&
(
t
-
mLastFrameSent
)
.
ToSeconds
(
)
<
(
1
.
0
/
duplicateMinFps
)
)
{
return
;
}
mLastFrameSent
=
t
;
mLastImage
=
serial
;
const
int32_t
queueThrottlingLimit
=
1
;
if
(
mLength
>
queueThrottlingLimit
)
{
CSFLogDebug
(
LOGTAG
"
VideoFrameConverter
%
p
queue
is
full
.
Throttling
by
"
"
throwing
away
a
frame
.
"
this
)
;
#
ifdef
DEBUG
+
+
mThrottleCount
;
mThrottleRecord
=
std
:
:
max
(
mThrottleCount
mThrottleRecord
)
;
#
endif
return
;
}
#
ifdef
DEBUG
if
(
mThrottleCount
>
0
)
{
if
(
mThrottleCount
>
5
)
{
CSFLogInfo
(
LOGTAG
"
VideoFrameConverter
%
p
stopped
throttling
after
throwing
"
"
away
%
d
frames
.
Longest
throttle
so
far
was
%
d
frames
.
"
this
mThrottleCount
mThrottleRecord
)
;
}
else
{
CSFLogDebug
(
LOGTAG
"
VideoFrameConverter
%
p
stopped
throttling
after
throwing
"
"
away
%
d
frames
.
Longest
throttle
so
far
was
%
d
frames
.
"
this
mThrottleCount
mThrottleRecord
)
;
}
mThrottleCount
=
0
;
}
#
endif
+
+
mLength
;
nsCOMPtr
<
nsIRunnable
>
runnable
=
NewRunnableMethod
<
StoreRefPtrPassByPtr
<
Image
>
IntSize
bool
>
(
"
VideoFrameConverter
:
:
ProcessVideoFrame
"
this
&
VideoFrameConverter
:
:
ProcessVideoFrame
aChunk
.
mFrame
.
GetImage
(
)
size
aForceBlack
)
;
nsresult
rv
=
mTaskQueue
-
>
Dispatch
(
runnable
.
forget
(
)
)
;
MOZ_DIAGNOSTIC_ASSERT
(
NS_SUCCEEDED
(
rv
)
)
;
Unused
<
<
rv
;
}
void
AddListener
(
VideoConverterListener
*
aListener
)
{
MutexAutoLock
lock
(
mMutex
)
;
MOZ_ASSERT
(
!
mListeners
.
Contains
(
aListener
)
)
;
mListeners
.
AppendElement
(
aListener
)
;
}
bool
RemoveListener
(
VideoConverterListener
*
aListener
)
{
MutexAutoLock
lock
(
mMutex
)
;
return
mListeners
.
RemoveElement
(
aListener
)
;
}
void
Shutdown
(
)
{
MutexAutoLock
lock
(
mMutex
)
;
mListeners
.
Clear
(
)
;
}
protected
:
virtual
~
VideoFrameConverter
(
)
{
MOZ_COUNT_DTOR
(
VideoFrameConverter
)
;
}
static
void
DeleteBuffer
(
uint8_t
*
aData
)
{
delete
[
]
aData
;
}
void
VideoFrameConverted
(
UniquePtr
<
uint8_t
[
]
>
aBuffer
unsigned
int
aVideoFrameLength
unsigned
short
aWidth
unsigned
short
aHeight
VideoType
aVideoType
uint64_t
aCaptureTime
)
{
if
(
!
aBuffer
|
|
aVideoFrameLength
=
=
0
|
|
aWidth
=
=
0
|
|
aHeight
=
=
0
)
{
CSFLogError
(
LOGTAG
"
%
s
Invalid
Parameters
"
__FUNCTION__
)
;
MOZ_ASSERT
(
false
)
;
return
;
}
MOZ_ASSERT
(
aVideoType
=
=
VideoType
:
:
kVideoI420
)
;
const
int
stride_y
=
aWidth
;
const
int
stride_uv
=
(
aWidth
+
1
)
/
2
;
const
uint8_t
*
buffer_y
=
aBuffer
.
get
(
)
;
const
uint8_t
*
buffer_u
=
buffer_y
+
stride_y
*
aHeight
;
const
uint8_t
*
buffer_v
=
buffer_u
+
stride_uv
*
(
(
aHeight
+
1
)
/
2
)
;
rtc
:
:
scoped_refptr
<
webrtc
:
:
WrappedI420Buffer
>
video_frame_buffer
(
new
rtc
:
:
RefCountedObject
<
webrtc
:
:
WrappedI420Buffer
>
(
aWidth
aHeight
buffer_y
stride_y
buffer_u
stride_uv
buffer_v
stride_uv
rtc
:
:
Bind
(
&
DeleteBuffer
aBuffer
.
release
(
)
)
)
)
;
webrtc
:
:
VideoFrame
video_frame
(
video_frame_buffer
aCaptureTime
aCaptureTime
webrtc
:
:
kVideoRotation_0
)
;
VideoFrameConverted
(
video_frame
)
;
}
void
VideoFrameConverted
(
const
webrtc
:
:
VideoFrame
&
aVideoFrame
)
{
MutexAutoLock
lock
(
mMutex
)
;
for
(
RefPtr
<
VideoConverterListener
>
&
listener
:
mListeners
)
{
listener
-
>
OnVideoFrameConverted
(
aVideoFrame
)
;
}
}
void
ProcessVideoFrame
(
Image
*
aImage
IntSize
aSize
bool
aForceBlack
)
{
-
-
mLength
;
MOZ_ASSERT
(
mLength
>
=
0
)
;
if
(
aForceBlack
)
{
rtc
:
:
scoped_refptr
<
webrtc
:
:
I420Buffer
>
buffer
=
mBufferPool
.
CreateBuffer
(
aSize
.
width
aSize
.
height
)
;
if
(
!
buffer
)
{
MOZ_DIAGNOSTIC_ASSERT
(
false
"
Buffers
not
leaving
scope
except
for
"
"
reconfig
should
never
leak
"
)
;
CSFLogWarn
(
LOGTAG
"
Creating
a
buffer
for
a
black
video
frame
failed
"
)
;
return
;
}
CSFLogDebug
(
LOGTAG
"
Sending
a
black
video
frame
"
)
;
webrtc
:
:
I420Buffer
:
:
SetBlack
(
buffer
)
;
webrtc
:
:
VideoFrame
frame
(
buffer
0
0
webrtc
:
:
kVideoRotation_0
)
;
VideoFrameConverted
(
frame
)
;
return
;
}
if
(
!
aImage
)
{
MOZ_ASSERT_UNREACHABLE
(
"
Must
have
image
if
not
forcing
black
"
)
;
return
;
}
ImageFormat
format
=
aImage
-
>
GetFormat
(
)
;
if
(
format
=
=
ImageFormat
:
:
PLANAR_YCBCR
)
{
const
PlanarYCbCrData
*
data
=
static_cast
<
const
PlanarYCbCrImage
*
>
(
aImage
)
-
>
GetData
(
)
;
if
(
data
)
{
uint8_t
*
y
=
data
-
>
mYChannel
;
uint8_t
*
cb
=
data
-
>
mCbChannel
;
uint8_t
*
cr
=
data
-
>
mCrChannel
;
int32_t
yStride
=
data
-
>
mYStride
;
int32_t
cbCrStride
=
data
-
>
mCbCrStride
;
uint32_t
width
=
aImage
-
>
GetSize
(
)
.
width
;
uint32_t
height
=
aImage
-
>
GetSize
(
)
.
height
;
rtc
:
:
scoped_refptr
<
webrtc
:
:
WrappedI420Buffer
>
video_frame_buffer
(
new
rtc
:
:
RefCountedObject
<
webrtc
:
:
WrappedI420Buffer
>
(
width
height
y
yStride
cb
cbCrStride
cr
cbCrStride
rtc
:
:
KeepRefUntilDone
(
aImage
)
)
)
;
webrtc
:
:
VideoFrame
i420_frame
(
video_frame_buffer
0
0
webrtc
:
:
kVideoRotation_0
)
;
CSFLogDebug
(
LOGTAG
"
Sending
an
I420
video
frame
"
)
;
VideoFrameConverted
(
i420_frame
)
;
return
;
}
}
RefPtr
<
SourceSurface
>
surf
=
aImage
-
>
GetAsSourceSurface
(
)
;
if
(
!
surf
)
{
CSFLogError
(
LOGTAG
"
Getting
surface
from
%
s
image
failed
"
Stringify
(
format
)
.
c_str
(
)
)
;
return
;
}
RefPtr
<
DataSourceSurface
>
data
=
surf
-
>
GetDataSurface
(
)
;
if
(
!
data
)
{
CSFLogError
(
LOGTAG
"
Getting
data
surface
from
%
s
image
with
%
s
(
%
s
)
surface
failed
"
Stringify
(
format
)
.
c_str
(
)
Stringify
(
surf
-
>
GetType
(
)
)
.
c_str
(
)
Stringify
(
surf
-
>
GetFormat
(
)
)
.
c_str
(
)
)
;
return
;
}
if
(
aImage
-
>
GetSize
(
)
!
=
aSize
)
{
MOZ_DIAGNOSTIC_ASSERT
(
false
"
Unexpected
intended
size
"
)
;
return
;
}
rtc
:
:
scoped_refptr
<
webrtc
:
:
I420Buffer
>
buffer
=
mBufferPool
.
CreateBuffer
(
aSize
.
width
aSize
.
height
)
;
if
(
!
buffer
)
{
CSFLogWarn
(
LOGTAG
"
Creating
a
buffer
for
a
black
video
frame
failed
"
)
;
return
;
}
DataSourceSurface
:
:
ScopedMap
map
(
data
DataSourceSurface
:
:
READ
)
;
if
(
!
map
.
IsMapped
(
)
)
{
CSFLogError
(
LOGTAG
"
Reading
DataSourceSurface
from
%
s
image
with
%
s
(
%
s
)
surface
failed
"
Stringify
(
format
)
.
c_str
(
)
Stringify
(
surf
-
>
GetType
(
)
)
.
c_str
(
)
Stringify
(
surf
-
>
GetFormat
(
)
)
.
c_str
(
)
)
;
return
;
}
int
rv
;
switch
(
surf
-
>
GetFormat
(
)
)
{
case
SurfaceFormat
:
:
B8G8R8A8
:
case
SurfaceFormat
:
:
B8G8R8X8
:
rv
=
libyuv
:
:
ARGBToI420
(
static_cast
<
uint8_t
*
>
(
map
.
GetData
(
)
)
map
.
GetStride
(
)
buffer
-
>
MutableDataY
(
)
buffer
-
>
StrideY
(
)
buffer
-
>
MutableDataU
(
)
buffer
-
>
StrideU
(
)
buffer
-
>
MutableDataV
(
)
buffer
-
>
StrideV
(
)
aSize
.
width
aSize
.
height
)
;
break
;
case
SurfaceFormat
:
:
R5G6B5_UINT16
:
rv
=
libyuv
:
:
RGB565ToI420
(
static_cast
<
uint8_t
*
>
(
map
.
GetData
(
)
)
map
.
GetStride
(
)
buffer
-
>
MutableDataY
(
)
buffer
-
>
StrideY
(
)
buffer
-
>
MutableDataU
(
)
buffer
-
>
StrideU
(
)
buffer
-
>
MutableDataV
(
)
buffer
-
>
StrideV
(
)
aSize
.
width
aSize
.
height
)
;
break
;
default
:
CSFLogError
(
LOGTAG
"
Unsupported
RGB
video
format
%
s
"
Stringify
(
surf
-
>
GetFormat
(
)
)
.
c_str
(
)
)
;
MOZ_ASSERT
(
PR_FALSE
)
;
return
;
}
if
(
rv
!
=
0
)
{
CSFLogError
(
LOGTAG
"
%
s
to
I420
conversion
failed
"
Stringify
(
surf
-
>
GetFormat
(
)
)
.
c_str
(
)
)
;
return
;
}
CSFLogDebug
(
LOGTAG
"
Sending
an
I420
video
frame
converted
from
%
s
"
Stringify
(
surf
-
>
GetFormat
(
)
)
.
c_str
(
)
)
;
webrtc
:
:
VideoFrame
frame
(
buffer
0
0
webrtc
:
:
kVideoRotation_0
)
;
VideoFrameConverted
(
frame
)
;
}
Atomic
<
int32_t
Relaxed
>
mLength
;
const
RefPtr
<
TaskQueue
>
mTaskQueue
;
webrtc
:
:
I420BufferPool
mBufferPool
;
int32_t
mLastImage
;
TimeStamp
mLastFrameSent
;
#
ifdef
DEBUG
uint32_t
mThrottleCount
;
uint32_t
mThrottleRecord
;
#
endif
Mutex
mMutex
;
nsTArray
<
RefPtr
<
VideoConverterListener
>
>
mListeners
;
}
;
class
AudioProxyThread
{
public
:
NS_INLINE_DECL_THREADSAFE_REFCOUNTING
(
AudioProxyThread
)
explicit
AudioProxyThread
(
AudioSessionConduit
*
aConduit
)
:
mConduit
(
aConduit
)
mTaskQueue
(
new
TaskQueue
(
GetMediaThreadPool
(
MediaThreadType
:
:
WEBRTC_DECODER
)
"
AudioProxy
"
)
)
mAudioConverter
(
nullptr
)
{
MOZ_ASSERT
(
mConduit
)
;
MOZ_COUNT_CTOR
(
AudioProxyThread
)
;
}
uint32_t
AppropriateSendingRateForInputRate
(
uint32_t
aInputRate
)
{
AudioSessionConduit
*
conduit
=
static_cast
<
AudioSessionConduit
*
>
(
mConduit
.
get
(
)
)
;
if
(
conduit
-
>
IsSamplingFreqSupported
(
aInputRate
)
)
{
return
aInputRate
;
}
if
(
aInputRate
<
16000
)
{
return
16000
;
}
else
if
(
aInputRate
<
32000
)
{
return
32000
;
}
else
if
(
aInputRate
<
44100
)
{
return
44100
;
}
else
{
return
48000
;
}
}
void
InternalProcessAudioChunk
(
TrackRate
aRate
const
AudioChunk
&
aChunk
bool
aEnabled
)
{
MOZ_ASSERT
(
mTaskQueue
-
>
IsCurrentThreadIn
(
)
)
;
uint32_t
outputChannels
=
aChunk
.
ChannelCount
(
)
=
=
1
?
1
:
2
;
int32_t
transmissionRate
=
AppropriateSendingRateForInputRate
(
aRate
)
;
if
(
aEnabled
&
&
outputChannels
=
=
1
&
&
aChunk
.
mBufferFormat
=
=
AUDIO_FORMAT_S16
&
&
transmissionRate
=
=
aRate
)
{
const
int16_t
*
samples
=
aChunk
.
ChannelData
<
int16_t
>
(
)
.
Elements
(
)
[
0
]
;
PacketizeAndSend
(
samples
transmissionRate
outputChannels
aChunk
.
mDuration
)
;
return
;
}
uint32_t
sampleCount
=
aChunk
.
mDuration
*
outputChannels
;
if
(
mInterleavedAudio
.
Length
(
)
<
sampleCount
)
{
mInterleavedAudio
.
SetLength
(
sampleCount
)
;
}
if
(
!
aEnabled
|
|
aChunk
.
mBufferFormat
=
=
AUDIO_FORMAT_SILENCE
)
{
PodZero
(
mInterleavedAudio
.
Elements
(
)
sampleCount
)
;
}
else
if
(
aChunk
.
mBufferFormat
=
=
AUDIO_FORMAT_FLOAT32
)
{
DownmixAndInterleave
(
aChunk
.
ChannelData
<
float
>
(
)
aChunk
.
mDuration
aChunk
.
mVolume
outputChannels
mInterleavedAudio
.
Elements
(
)
)
;
}
else
if
(
aChunk
.
mBufferFormat
=
=
AUDIO_FORMAT_S16
)
{
DownmixAndInterleave
(
aChunk
.
ChannelData
<
int16_t
>
(
)
aChunk
.
mDuration
aChunk
.
mVolume
outputChannels
mInterleavedAudio
.
Elements
(
)
)
;
}
int16_t
*
inputAudio
=
mInterleavedAudio
.
Elements
(
)
;
size_t
inputAudioFrameCount
=
aChunk
.
mDuration
;
AudioConfig
inputConfig
(
AudioConfig
:
:
ChannelLayout
(
outputChannels
)
aRate
AudioConfig
:
:
FORMAT_S16
)
;
AudioConfig
outputConfig
(
AudioConfig
:
:
ChannelLayout
(
outputChannels
)
transmissionRate
AudioConfig
:
:
FORMAT_S16
)
;
if
(
!
mAudioConverter
|
|
mAudioConverter
-
>
InputConfig
(
)
!
=
inputConfig
|
|
mAudioConverter
-
>
OutputConfig
(
)
!
=
outputConfig
)
{
mAudioConverter
=
MakeUnique
<
AudioConverter
>
(
inputConfig
outputConfig
)
;
}
int16_t
*
processedAudio
=
nullptr
;
size_t
framesProcessed
=
mAudioConverter
-
>
Process
(
inputAudio
inputAudioFrameCount
)
;
if
(
framesProcessed
=
=
0
)
{
framesProcessed
=
mAudioConverter
-
>
Process
(
mOutputAudio
inputAudio
inputAudioFrameCount
)
;
processedAudio
=
mOutputAudio
.
Data
(
)
;
}
else
{
processedAudio
=
inputAudio
;
}
PacketizeAndSend
(
processedAudio
transmissionRate
outputChannels
framesProcessed
)
;
}
void
PacketizeAndSend
(
const
int16_t
*
aAudioData
uint32_t
aRate
uint32_t
aChannels
uint32_t
aFrameCount
)
{
MOZ_ASSERT
(
AppropriateSendingRateForInputRate
(
aRate
)
=
=
aRate
)
;
MOZ_ASSERT
(
aChannels
=
=
1
|
|
aChannels
=
=
2
)
;
MOZ_ASSERT
(
aAudioData
)
;
uint32_t
audio_10ms
=
aRate
/
100
;
if
(
!
mPacketizer
|
|
mPacketizer
-
>
PacketSize
(
)
!
=
audio_10ms
|
|
mPacketizer
-
>
Channels
(
)
!
=
aChannels
)
{
mPacketizer
=
MakeUnique
<
AudioPacketizer
<
int16_t
int16_t
>
>
(
audio_10ms
aChannels
)
;
mPacket
=
MakeUnique
<
int16_t
[
]
>
(
audio_10ms
*
aChannels
)
;
}
mPacketizer
-
>
Input
(
aAudioData
aFrameCount
)
;
while
(
mPacketizer
-
>
PacketsAvailable
(
)
)
{
mPacketizer
-
>
Output
(
mPacket
.
get
(
)
)
;
mConduit
-
>
SendAudioFrame
(
mPacket
.
get
(
)
mPacketizer
-
>
PacketSize
(
)
aRate
mPacketizer
-
>
Channels
(
)
0
)
;
}
}
void
QueueAudioChunk
(
TrackRate
aRate
const
AudioChunk
&
aChunk
bool
aEnabled
)
{
RefPtr
<
AudioProxyThread
>
self
=
this
;
nsresult
rv
=
mTaskQueue
-
>
Dispatch
(
NS_NewRunnableFunction
(
"
AudioProxyThread
:
:
QueueAudioChunk
"
[
self
aRate
aChunk
aEnabled
]
(
)
{
self
-
>
InternalProcessAudioChunk
(
aRate
aChunk
aEnabled
)
;
}
)
)
;
MOZ_DIAGNOSTIC_ASSERT
(
NS_SUCCEEDED
(
rv
)
)
;
Unused
<
<
rv
;
}
protected
:
virtual
~
AudioProxyThread
(
)
{
NS_ReleaseOnMainThreadSystemGroup
(
"
AudioProxyThread
:
:
mConduit
"
mConduit
.
forget
(
)
)
;
MOZ_COUNT_DTOR
(
AudioProxyThread
)
;
}
RefPtr
<
AudioSessionConduit
>
mConduit
;
const
RefPtr
<
TaskQueue
>
mTaskQueue
;
UniquePtr
<
AudioPacketizer
<
int16_t
int16_t
>
>
mPacketizer
;
UniquePtr
<
int16_t
[
]
>
mPacket
;
nsTArray
<
int16_t
>
mInterleavedAudio
;
AlignedShortBuffer
mOutputAudio
;
UniquePtr
<
AudioConverter
>
mAudioConverter
;
}
;
MediaPipeline
:
:
MediaPipeline
(
const
std
:
:
string
&
aPc
DirectionType
aDirection
nsCOMPtr
<
nsIEventTarget
>
aMainThread
nsCOMPtr
<
nsIEventTarget
>
aStsThread
RefPtr
<
MediaSessionConduit
>
aConduit
)
:
mDirection
(
aDirection
)
mLevel
(
0
)
mConduit
(
aConduit
)
mRtp
(
nullptr
RTP
)
mRtcp
(
nullptr
RTCP
)
mMainThread
(
aMainThread
)
mStsThread
(
aStsThread
)
mTransport
(
new
PipelineTransport
(
aStsThread
)
)
mRtpPacketsSent
(
0
)
mRtcpPacketsSent
(
0
)
mRtpPacketsReceived
(
0
)
mRtcpPacketsReceived
(
0
)
mRtpBytesSent
(
0
)
mRtpBytesReceived
(
0
)
mPc
(
aPc
)
mRtpParser
(
webrtc
:
:
RtpHeaderParser
:
:
Create
(
)
)
mPacketDumper
(
new
PacketDumper
(
mPc
)
)
{
if
(
mDirection
=
=
DirectionType
:
:
RECEIVE
)
{
mConduit
-
>
SetReceiverTransport
(
mTransport
)
;
}
else
{
mConduit
-
>
SetTransmitterTransport
(
mTransport
)
;
}
}
MediaPipeline
:
:
~
MediaPipeline
(
)
{
CSFLogInfo
(
LOGTAG
"
Destroying
MediaPipeline
:
%
s
"
mDescription
.
c_str
(
)
)
;
NS_ReleaseOnMainThreadSystemGroup
(
"
MediaPipeline
:
:
mConduit
"
mConduit
.
forget
(
)
)
;
}
void
MediaPipeline
:
:
Shutdown_m
(
)
{
Stop
(
)
;
DetachMedia
(
)
;
RUN_ON_THREAD
(
mStsThread
WrapRunnable
(
RefPtr
<
MediaPipeline
>
(
this
)
&
MediaPipeline
:
:
DetachTransport_s
)
NS_DISPATCH_NORMAL
)
;
}
void
MediaPipeline
:
:
DetachTransport_s
(
)
{
ASSERT_ON_THREAD
(
mStsThread
)
;
CSFLogInfo
(
LOGTAG
"
%
s
in
%
s
"
mDescription
.
c_str
(
)
__FUNCTION__
)
;
disconnect_all
(
)
;
mTransport
-
>
Detach
(
)
;
mRtp
.
Detach
(
)
;
mRtcp
.
Detach
(
)
;
mPacketDumper
=
nullptr
;
}
nsresult
MediaPipeline
:
:
AttachTransport_s
(
)
{
ASSERT_ON_THREAD
(
mStsThread
)
;
nsresult
res
;
MOZ_ASSERT
(
mRtp
.
mTransport
)
;
MOZ_ASSERT
(
mRtcp
.
mTransport
)
;
res
=
ConnectTransport_s
(
mRtp
)
;
if
(
NS_FAILED
(
res
)
)
{
return
res
;
}
if
(
mRtcp
.
mTransport
!
=
mRtp
.
mTransport
)
{
res
=
ConnectTransport_s
(
mRtcp
)
;
if
(
NS_FAILED
(
res
)
)
{
return
res
;
}
}
mTransport
-
>
Attach
(
this
)
;
return
NS_OK
;
}
void
MediaPipeline
:
:
UpdateTransport_m
(
RefPtr
<
TransportFlow
>
aRtpTransport
RefPtr
<
TransportFlow
>
aRtcpTransport
nsAutoPtr
<
MediaPipelineFilter
>
aFilter
)
{
RUN_ON_THREAD
(
mStsThread
WrapRunnable
(
RefPtr
<
MediaPipeline
>
(
this
)
&
MediaPipeline
:
:
UpdateTransport_s
aRtpTransport
aRtcpTransport
aFilter
)
NS_DISPATCH_NORMAL
)
;
}
void
MediaPipeline
:
:
UpdateTransport_s
(
RefPtr
<
TransportFlow
>
aRtpTransport
RefPtr
<
TransportFlow
>
aRtcpTransport
nsAutoPtr
<
MediaPipelineFilter
>
aFilter
)
{
bool
rtcp_mux
=
false
;
if
(
!
aRtcpTransport
)
{
aRtcpTransport
=
aRtpTransport
;
rtcp_mux
=
true
;
}
if
(
(
aRtpTransport
!
=
mRtp
.
mTransport
)
|
|
(
aRtcpTransport
!
=
mRtcp
.
mTransport
)
)
{
disconnect_all
(
)
;
mTransport
-
>
Detach
(
)
;
mRtp
.
Detach
(
)
;
mRtcp
.
Detach
(
)
;
if
(
aRtpTransport
&
&
aRtcpTransport
)
{
mRtp
=
TransportInfo
(
aRtpTransport
rtcp_mux
?
MUX
:
RTP
)
;
mRtcp
=
TransportInfo
(
aRtcpTransport
rtcp_mux
?
MUX
:
RTCP
)
;
AttachTransport_s
(
)
;
}
}
if
(
mFilter
&
&
aFilter
)
{
mFilter
-
>
Update
(
*
aFilter
)
;
}
else
{
mFilter
=
aFilter
;
}
}
void
MediaPipeline
:
:
AddRIDExtension_m
(
size_t
aExtensionId
)
{
RUN_ON_THREAD
(
mStsThread
WrapRunnable
(
RefPtr
<
MediaPipeline
>
(
this
)
&
MediaPipeline
:
:
AddRIDExtension_s
aExtensionId
)
NS_DISPATCH_NORMAL
)
;
}
void
MediaPipeline
:
:
AddRIDExtension_s
(
size_t
aExtensionId
)
{
mRtpParser
-
>
RegisterRtpHeaderExtension
(
webrtc
:
:
kRtpExtensionRtpStreamId
aExtensionId
)
;
}
void
MediaPipeline
:
:
AddRIDFilter_m
(
const
std
:
:
string
&
aRid
)
{
RUN_ON_THREAD
(
mStsThread
WrapRunnable
(
RefPtr
<
MediaPipeline
>
(
this
)
&
MediaPipeline
:
:
AddRIDFilter_s
aRid
)
NS_DISPATCH_NORMAL
)
;
}
void
MediaPipeline
:
:
AddRIDFilter_s
(
const
std
:
:
string
&
aRid
)
{
mFilter
=
new
MediaPipelineFilter
;
mFilter
-
>
AddRemoteRtpStreamId
(
aRid
)
;
}
void
MediaPipeline
:
:
GetContributingSourceStats
(
const
nsString
&
aInboundRtpStreamId
FallibleTArray
<
dom
:
:
RTCRTPContributingSourceStats
>
&
aArr
)
const
{
DOMHighResTimeStamp
expiry
=
RtpCSRCStats
:
:
GetExpiryFromTime
(
GetNow
(
)
)
;
for
(
auto
info
:
mCsrcStats
)
{
if
(
!
info
.
second
.
Expired
(
expiry
)
)
{
RTCRTPContributingSourceStats
stats
;
info
.
second
.
GetWebidlInstance
(
stats
aInboundRtpStreamId
)
;
aArr
.
AppendElement
(
stats
fallible
)
;
}
}
}
void
MediaPipeline
:
:
StateChange
(
TransportLayer
*
aLayer
TransportLayer
:
:
State
aState
)
{
TransportInfo
*
info
=
GetTransportInfo_s
(
aLayer
)
;
MOZ_ASSERT
(
info
)
;
if
(
aState
=
=
TransportLayer
:
:
TS_OPEN
)
{
CSFLogInfo
(
LOGTAG
"
Flow
is
ready
"
)
;
TransportReady_s
(
*
info
)
;
}
else
if
(
aState
=
=
TransportLayer
:
:
TS_CLOSED
|
|
aState
=
=
TransportLayer
:
:
TS_ERROR
)
{
TransportFailed_s
(
*
info
)
;
}
}
static
bool
MakeRtpTypeToStringArray
(
const
char
*
*
aArray
)
{
static
const
char
*
RTP_str
=
"
RTP
"
;
static
const
char
*
RTCP_str
=
"
RTCP
"
;
static
const
char
*
MUX_str
=
"
RTP
/
RTCP
mux
"
;
aArray
[
MediaPipeline
:
:
RTP
]
=
RTP_str
;
aArray
[
MediaPipeline
:
:
RTCP
]
=
RTCP_str
;
aArray
[
MediaPipeline
:
:
MUX
]
=
MUX_str
;
return
true
;
}
static
const
char
*
ToString
(
MediaPipeline
:
:
RtpType
type
)
{
static
const
char
*
array
[
(
int
)
MediaPipeline
:
:
MAX_RTP_TYPE
]
=
{
nullptr
}
;
static
bool
dummy
=
MakeRtpTypeToStringArray
(
array
)
;
(
void
)
dummy
;
return
array
[
type
]
;
}
nsresult
MediaPipeline
:
:
TransportReady_s
(
TransportInfo
&
aInfo
)
{
if
(
aInfo
.
mState
!
=
StateType
:
:
MP_CONNECTING
)
{
CSFLogError
(
LOGTAG
"
Transport
ready
for
flow
in
wrong
state
:
%
s
:
%
s
"
mDescription
.
c_str
(
)
ToString
(
aInfo
.
mType
)
)
;
return
NS_ERROR_FAILURE
;
}
CSFLogInfo
(
LOGTAG
"
Transport
ready
for
pipeline
%
p
flow
%
s
:
%
s
"
this
mDescription
.
c_str
(
)
ToString
(
aInfo
.
mType
)
)
;
if
(
mDirection
=
=
DirectionType
:
:
RECEIVE
)
{
CSFLogInfo
(
LOGTAG
"
Listening
for
%
s
packets
received
on
%
p
"
ToString
(
aInfo
.
mType
)
aInfo
.
mSrtp
)
;
aInfo
.
mSrtp
-
>
SignalPacketReceived
.
connect
(
this
&
MediaPipeline
:
:
PacketReceived
)
;
}
aInfo
.
mState
=
StateType
:
:
MP_OPEN
;
UpdateRtcpMuxState
(
aInfo
)
;
return
NS_OK
;
}
nsresult
MediaPipeline
:
:
TransportFailed_s
(
TransportInfo
&
aInfo
)
{
ASSERT_ON_THREAD
(
mStsThread
)
;
aInfo
.
mState
=
StateType
:
:
MP_CLOSED
;
UpdateRtcpMuxState
(
aInfo
)
;
CSFLogInfo
(
LOGTAG
"
Transport
closed
for
flow
%
s
"
ToString
(
aInfo
.
mType
)
)
;
NS_WARNING
(
"
MediaPipeline
Transport
failed
.
This
is
not
properly
cleaned
up
yet
"
)
;
return
NS_OK
;
}
void
MediaPipeline
:
:
UpdateRtcpMuxState
(
TransportInfo
&
aInfo
)
{
if
(
aInfo
.
mType
=
=
MUX
)
{
if
(
aInfo
.
mTransport
=
=
mRtcp
.
mTransport
)
{
mRtcp
.
mState
=
aInfo
.
mState
;
}
}
}
nsresult
MediaPipeline
:
:
SendPacket
(
TransportLayer
*
aLayer
MediaPacket
&
packet
)
{
ASSERT_ON_THREAD
(
mStsThread
)
;
int
len
=
packet
.
len
(
)
;
TransportResult
res
=
aLayer
-
>
SendPacket
(
packet
)
;
if
(
res
!
=
len
)
{
if
(
res
=
=
TE_WOULDBLOCK
)
return
NS_OK
;
CSFLogError
(
LOGTAG
"
Failed
write
on
stream
%
s
"
mDescription
.
c_str
(
)
)
;
return
NS_BASE_STREAM_CLOSED
;
}
return
NS_OK
;
}
void
MediaPipeline
:
:
IncrementRtpPacketsSent
(
int32_t
aBytes
)
{
+
+
mRtpPacketsSent
;
mRtpBytesSent
+
=
aBytes
;
if
(
!
(
mRtpPacketsSent
%
100
)
)
{
CSFLogInfo
(
LOGTAG
"
RTP
sent
packet
count
for
%
s
Pipeline
%
p
Flow
:
%
p
:
%
u
(
%
"
PRId64
"
bytes
)
"
mDescription
.
c_str
(
)
this
static_cast
<
void
*
>
(
mRtp
.
mTransport
)
mRtpPacketsSent
mRtpBytesSent
)
;
}
}
void
MediaPipeline
:
:
IncrementRtcpPacketsSent
(
)
{
+
+
mRtcpPacketsSent
;
if
(
!
(
mRtcpPacketsSent
%
100
)
)
{
CSFLogInfo
(
LOGTAG
"
RTCP
sent
packet
count
for
%
s
Pipeline
%
p
Flow
:
%
p
:
%
u
"
mDescription
.
c_str
(
)
this
static_cast
<
void
*
>
(
mRtp
.
mTransport
)
mRtcpPacketsSent
)
;
}
}
void
MediaPipeline
:
:
IncrementRtpPacketsReceived
(
int32_t
aBytes
)
{
+
+
mRtpPacketsReceived
;
mRtpBytesReceived
+
=
aBytes
;
if
(
!
(
mRtpPacketsReceived
%
100
)
)
{
CSFLogInfo
(
LOGTAG
"
RTP
received
packet
count
for
%
s
Pipeline
%
p
Flow
:
%
p
:
%
u
(
%
"
PRId64
"
bytes
)
"
mDescription
.
c_str
(
)
this
static_cast
<
void
*
>
(
mRtp
.
mTransport
)
mRtpPacketsReceived
mRtpBytesReceived
)
;
}
}
void
MediaPipeline
:
:
IncrementRtcpPacketsReceived
(
)
{
+
+
mRtcpPacketsReceived
;
if
(
!
(
mRtcpPacketsReceived
%
100
)
)
{
CSFLogInfo
(
LOGTAG
"
RTCP
received
packet
count
for
%
s
Pipeline
%
p
Flow
:
%
p
:
%
u
"
mDescription
.
c_str
(
)
this
static_cast
<
void
*
>
(
mRtp
.
mTransport
)
mRtcpPacketsReceived
)
;
}
}
void
MediaPipeline
:
:
RtpPacketReceived
(
TransportLayer
*
aLayer
MediaPacket
&
packet
)
{
if
(
mDirection
=
=
DirectionType
:
:
TRANSMIT
)
{
return
;
}
if
(
!
mTransport
-
>
Pipeline
(
)
)
{
CSFLogError
(
LOGTAG
"
Discarding
incoming
packet
;
transport
disconnected
"
)
;
return
;
}
if
(
!
mConduit
)
{
CSFLogDebug
(
LOGTAG
"
Discarding
incoming
packet
;
media
disconnected
"
)
;
return
;
}
if
(
mRtp
.
mState
!
=
StateType
:
:
MP_OPEN
)
{
CSFLogError
(
LOGTAG
"
Discarding
incoming
packet
;
pipeline
not
open
"
)
;
return
;
}
if
(
mRtp
.
mSrtp
-
>
state
(
)
!
=
TransportLayer
:
:
TS_OPEN
)
{
CSFLogError
(
LOGTAG
"
Discarding
incoming
packet
;
transport
not
open
"
)
;
return
;
}
if
(
!
packet
.
len
(
)
)
{
return
;
}
webrtc
:
:
RTPHeader
header
;
if
(
!
mRtpParser
-
>
Parse
(
packet
.
data
(
)
packet
.
len
(
)
&
header
true
)
)
{
return
;
}
if
(
mFilter
&
&
!
mFilter
-
>
Filter
(
header
)
)
{
return
;
}
DOMHighResTimeStamp
now
=
0
.
0
;
bool
hasTime
=
false
;
if
(
!
mCsrcStats
.
empty
(
)
)
{
if
(
!
hasTime
)
{
now
=
GetNow
(
)
;
hasTime
=
true
;
}
auto
expiry
=
RtpCSRCStats
:
:
GetExpiryFromTime
(
now
)
;
for
(
auto
p
=
mCsrcStats
.
begin
(
)
;
p
!
=
mCsrcStats
.
end
(
)
;
)
{
if
(
p
-
>
second
.
Expired
(
expiry
)
)
{
p
=
mCsrcStats
.
erase
(
p
)
;
continue
;
}
p
+
+
;
}
}
if
(
header
.
numCSRCs
)
{
for
(
auto
i
=
0
;
i
<
header
.
numCSRCs
;
i
+
+
)
{
if
(
!
hasTime
)
{
now
=
GetNow
(
)
;
hasTime
=
true
;
}
auto
csrcInfo
=
mCsrcStats
.
find
(
header
.
arrOfCSRCs
[
i
]
)
;
if
(
csrcInfo
=
=
mCsrcStats
.
end
(
)
)
{
mCsrcStats
.
insert
(
std
:
:
make_pair
(
header
.
arrOfCSRCs
[
i
]
RtpCSRCStats
(
header
.
arrOfCSRCs
[
i
]
now
)
)
)
;
}
else
{
csrcInfo
-
>
second
.
SetTimestamp
(
now
)
;
}
}
}
CSFLogDebug
(
LOGTAG
"
%
s
received
RTP
packet
.
"
mDescription
.
c_str
(
)
)
;
IncrementRtpPacketsReceived
(
packet
.
len
(
)
)
;
OnRtpPacketReceived
(
)
;
RtpLogger
:
:
LogPacket
(
packet
true
mDescription
)
;
mPacketDumper
-
>
Dump
(
mLevel
dom
:
:
mozPacketDumpType
:
:
Srtp
false
packet
.
encrypted_data
(
)
packet
.
encrypted_len
(
)
)
;
mPacketDumper
-
>
Dump
(
mLevel
dom
:
:
mozPacketDumpType
:
:
Rtp
false
packet
.
data
(
)
packet
.
len
(
)
)
;
(
void
)
mConduit
-
>
ReceivedRTPPacket
(
packet
.
data
(
)
packet
.
len
(
)
header
.
ssrc
)
;
}
void
MediaPipeline
:
:
RtcpPacketReceived
(
TransportLayer
*
aLayer
MediaPacket
&
packet
)
{
if
(
!
mTransport
-
>
Pipeline
(
)
)
{
CSFLogDebug
(
LOGTAG
"
Discarding
incoming
packet
;
transport
disconnected
"
)
;
return
;
}
if
(
!
mConduit
)
{
CSFLogDebug
(
LOGTAG
"
Discarding
incoming
packet
;
media
disconnected
"
)
;
return
;
}
if
(
mRtcp
.
mState
!
=
StateType
:
:
MP_OPEN
)
{
CSFLogDebug
(
LOGTAG
"
Discarding
incoming
packet
;
pipeline
not
open
"
)
;
return
;
}
if
(
mRtcp
.
mSrtp
-
>
state
(
)
!
=
TransportLayer
:
:
TS_OPEN
)
{
CSFLogError
(
LOGTAG
"
Discarding
incoming
packet
;
transport
not
open
"
)
;
return
;
}
if
(
!
packet
.
len
(
)
)
{
return
;
}
CSFLogDebug
(
LOGTAG
"
%
s
received
RTCP
packet
.
"
mDescription
.
c_str
(
)
)
;
IncrementRtcpPacketsReceived
(
)
;
RtpLogger
:
:
LogPacket
(
packet
true
mDescription
)
;
mPacketDumper
-
>
Dump
(
mLevel
dom
:
:
mozPacketDumpType
:
:
Srtcp
false
packet
.
encrypted_data
(
)
packet
.
encrypted_len
(
)
)
;
mPacketDumper
-
>
Dump
(
mLevel
dom
:
:
mozPacketDumpType
:
:
Rtcp
false
packet
.
data
(
)
packet
.
len
(
)
)
;
(
void
)
mConduit
-
>
ReceivedRTCPPacket
(
packet
.
data
(
)
packet
.
len
(
)
)
;
}
void
MediaPipeline
:
:
PacketReceived
(
TransportLayer
*
aLayer
MediaPacket
&
packet
)
{
if
(
!
mTransport
-
>
Pipeline
(
)
)
{
CSFLogDebug
(
LOGTAG
"
Discarding
incoming
packet
;
transport
disconnected
"
)
;
return
;
}
switch
(
packet
.
type
(
)
)
{
case
MediaPacket
:
:
RTP
:
RtpPacketReceived
(
aLayer
packet
)
;
break
;
case
MediaPacket
:
:
RTCP
:
RtcpPacketReceived
(
aLayer
packet
)
;
break
;
default
:
MOZ_CRASH
(
"
TransportLayerSrtp
let
something
other
than
RTP
/
RTCP
through
"
)
;
}
}
class
MediaPipelineTransmit
:
:
PipelineListener
:
public
MediaStreamVideoSink
{
friend
class
MediaPipelineTransmit
;
public
:
explicit
PipelineListener
(
const
RefPtr
<
MediaSessionConduit
>
&
aConduit
)
:
mConduit
(
aConduit
)
mActive
(
false
)
mEnabled
(
false
)
mDirectConnect
(
false
)
{
}
~
PipelineListener
(
)
{
NS_ReleaseOnMainThreadSystemGroup
(
"
MediaPipeline
:
:
mConduit
"
mConduit
.
forget
(
)
)
;
if
(
mConverter
)
{
mConverter
-
>
Shutdown
(
)
;
}
}
void
SetActive
(
bool
aActive
)
{
mActive
=
aActive
;
}
void
SetEnabled
(
bool
aEnabled
)
{
mEnabled
=
aEnabled
;
}
void
SetAudioProxy
(
const
RefPtr
<
AudioProxyThread
>
&
aProxy
)
{
mAudioProcessing
=
aProxy
;
}
void
SetVideoFrameConverter
(
const
RefPtr
<
VideoFrameConverter
>
&
aConverter
)
{
mConverter
=
aConverter
;
}
void
OnVideoFrameConverted
(
const
webrtc
:
:
VideoFrame
&
aVideoFrame
)
{
MOZ_RELEASE_ASSERT
(
mConduit
-
>
type
(
)
=
=
MediaSessionConduit
:
:
VIDEO
)
;
static_cast
<
VideoSessionConduit
*
>
(
mConduit
.
get
(
)
)
-
>
SendVideoFrame
(
aVideoFrame
)
;
}
void
NotifyQueuedChanges
(
MediaStreamGraph
*
aGraph
StreamTime
aTrackOffset
const
MediaSegment
&
aQueuedMedia
)
override
;
void
NotifyRealtimeTrackData
(
MediaStreamGraph
*
aGraph
StreamTime
aTrackOffset
const
MediaSegment
&
aMedia
)
override
;
void
NotifyDirectListenerInstalled
(
InstallationResult
aResult
)
override
;
void
NotifyDirectListenerUninstalled
(
)
override
;
void
SetCurrentFrames
(
const
VideoSegment
&
aSegment
)
override
;
void
ClearFrames
(
)
override
{
}
private
:
void
NewData
(
const
MediaSegment
&
aMedia
TrackRate
aRate
=
0
)
;
RefPtr
<
MediaSessionConduit
>
mConduit
;
RefPtr
<
AudioProxyThread
>
mAudioProcessing
;
RefPtr
<
VideoFrameConverter
>
mConverter
;
mozilla
:
:
Atomic
<
bool
>
mActive
;
mozilla
:
:
Atomic
<
bool
>
mEnabled
;
bool
mDirectConnect
;
}
;
class
MediaPipelineTransmit
:
:
VideoFrameFeeder
:
public
VideoConverterListener
{
public
:
explicit
VideoFrameFeeder
(
const
RefPtr
<
PipelineListener
>
&
aListener
)
:
mMutex
(
"
VideoFrameFeeder
"
)
mListener
(
aListener
)
{
MOZ_COUNT_CTOR
(
VideoFrameFeeder
)
;
}
void
Detach
(
)
{
MutexAutoLock
lock
(
mMutex
)
;
mListener
=
nullptr
;
}
void
OnVideoFrameConverted
(
const
webrtc
:
:
VideoFrame
&
aVideoFrame
)
override
{
MutexAutoLock
lock
(
mMutex
)
;
if
(
!
mListener
)
{
return
;
}
mListener
-
>
OnVideoFrameConverted
(
aVideoFrame
)
;
}
protected
:
virtual
~
VideoFrameFeeder
(
)
{
MOZ_COUNT_DTOR
(
VideoFrameFeeder
)
;
}
Mutex
mMutex
;
RefPtr
<
PipelineListener
>
mListener
;
}
;
MediaPipelineTransmit
:
:
MediaPipelineTransmit
(
const
std
:
:
string
&
aPc
nsCOMPtr
<
nsIEventTarget
>
aMainThread
nsCOMPtr
<
nsIEventTarget
>
aStsThread
bool
aIsVideo
RefPtr
<
MediaSessionConduit
>
aConduit
)
:
MediaPipeline
(
aPc
DirectionType
:
:
TRANSMIT
aMainThread
aStsThread
aConduit
)
mIsVideo
(
aIsVideo
)
mListener
(
new
PipelineListener
(
aConduit
)
)
mFeeder
(
aIsVideo
?
MakeAndAddRef
<
VideoFrameFeeder
>
(
mListener
)
:
nullptr
)
mTransmitting
(
false
)
{
if
(
!
IsVideo
(
)
)
{
mAudioProcessing
=
MakeAndAddRef
<
AudioProxyThread
>
(
static_cast
<
AudioSessionConduit
*
>
(
aConduit
.
get
(
)
)
)
;
mListener
-
>
SetAudioProxy
(
mAudioProcessing
)
;
}
else
{
mConverter
=
MakeAndAddRef
<
VideoFrameConverter
>
(
)
;
mConverter
-
>
AddListener
(
mFeeder
)
;
mListener
-
>
SetVideoFrameConverter
(
mConverter
)
;
}
}
MediaPipelineTransmit
:
:
~
MediaPipelineTransmit
(
)
{
if
(
mFeeder
)
{
mFeeder
-
>
Detach
(
)
;
}
MOZ_ASSERT
(
!
mDomTrack
)
;
}
void
MediaPipeline
:
:
SetDescription_s
(
const
std
:
:
string
&
description
)
{
mDescription
=
description
;
}
void
MediaPipelineTransmit
:
:
SetDescription
(
)
{
std
:
:
string
description
;
description
=
mPc
+
"
|
"
;
description
+
=
mConduit
-
>
type
(
)
=
=
MediaSessionConduit
:
:
AUDIO
?
"
Transmit
audio
[
"
:
"
Transmit
video
[
"
;
if
(
!
mDomTrack
)
{
description
+
=
"
no
track
]
"
;
}
else
{
nsString
nsTrackId
;
mDomTrack
-
>
GetId
(
nsTrackId
)
;
std
:
:
string
trackId
(
NS_ConvertUTF16toUTF8
(
nsTrackId
)
.
get
(
)
)
;
description
+
=
trackId
;
description
+
=
"
]
"
;
}
RUN_ON_THREAD
(
mStsThread
WrapRunnable
(
RefPtr
<
MediaPipeline
>
(
this
)
&
MediaPipelineTransmit
:
:
SetDescription_s
description
)
NS_DISPATCH_NORMAL
)
;
}
void
MediaPipelineTransmit
:
:
Stop
(
)
{
ASSERT_ON_THREAD
(
mMainThread
)
;
if
(
!
mDomTrack
|
|
!
mTransmitting
)
{
return
;
}
mTransmitting
=
false
;
if
(
mDomTrack
-
>
AsAudioStreamTrack
(
)
)
{
mDomTrack
-
>
RemoveDirectListener
(
mListener
)
;
mDomTrack
-
>
RemoveListener
(
mListener
)
;
}
else
if
(
VideoStreamTrack
*
video
=
mDomTrack
-
>
AsVideoStreamTrack
(
)
)
{
video
-
>
RemoveVideoOutput
(
mListener
)
;
}
else
{
MOZ_ASSERT
(
false
"
Unknown
track
type
"
)
;
}
mConduit
-
>
StopTransmitting
(
)
;
}
void
MediaPipelineTransmit
:
:
Start
(
)
{
ASSERT_ON_THREAD
(
mMainThread
)
;
if
(
!
mDomTrack
|
|
mTransmitting
)
{
return
;
}
mTransmitting
=
true
;
mConduit
-
>
StartTransmitting
(
)
;
CSFLogDebug
(
LOGTAG
"
Attaching
pipeline
to
track
%
p
conduit
type
=
%
s
"
this
(
mConduit
-
>
type
(
)
=
=
MediaSessionConduit
:
:
AUDIO
?
"
audio
"
:
"
video
"
)
)
;
#
if
!
defined
(
MOZILLA_EXTERNAL_LINKAGE
)
const
bool
enableDirectListener
=
!
Preferences
:
:
GetBool
(
"
media
.
navigator
.
audio
.
full_duplex
"
false
)
;
#
else
const
bool
enableDirectListener
=
true
;
#
endif
if
(
mDomTrack
-
>
AsAudioStreamTrack
(
)
)
{
if
(
enableDirectListener
)
{
mDomTrack
-
>
AddDirectListener
(
mListener
)
;
}
mDomTrack
-
>
AddListener
(
mListener
)
;
}
else
if
(
VideoStreamTrack
*
video
=
mDomTrack
-
>
AsVideoStreamTrack
(
)
)
{
video
-
>
AddVideoOutput
(
mListener
)
;
}
else
{
MOZ_ASSERT
(
false
"
Unknown
track
type
"
)
;
}
}
bool
MediaPipelineTransmit
:
:
IsVideo
(
)
const
{
return
mIsVideo
;
}
void
MediaPipelineTransmit
:
:
UpdateSinkIdentity_m
(
const
MediaStreamTrack
*
aTrack
nsIPrincipal
*
aPrincipal
const
PeerIdentity
*
aSinkIdentity
)
{
ASSERT_ON_THREAD
(
mMainThread
)
;
if
(
aTrack
!
=
nullptr
&
&
aTrack
!
=
mDomTrack
)
{
return
;
}
bool
enableTrack
=
aPrincipal
-
>
Subsumes
(
mDomTrack
-
>
GetPrincipal
(
)
)
;
if
(
!
enableTrack
)
{
const
PeerIdentity
*
trackIdentity
=
mDomTrack
-
>
GetPeerIdentity
(
)
;
if
(
aSinkIdentity
&
&
trackIdentity
)
{
enableTrack
=
(
*
aSinkIdentity
=
=
*
trackIdentity
)
;
}
}
mListener
-
>
SetEnabled
(
enableTrack
)
;
}
void
MediaPipelineTransmit
:
:
DetachMedia
(
)
{
ASSERT_ON_THREAD
(
mMainThread
)
;
mDomTrack
=
nullptr
;
}
nsresult
MediaPipelineTransmit
:
:
TransportReady_s
(
TransportInfo
&
aInfo
)
{
ASSERT_ON_THREAD
(
mStsThread
)
;
MediaPipeline
:
:
TransportReady_s
(
aInfo
)
;
if
(
&
aInfo
=
=
&
mRtp
)
{
mListener
-
>
SetActive
(
true
)
;
}
return
NS_OK
;
}
nsresult
MediaPipelineTransmit
:
:
SetTrack
(
MediaStreamTrack
*
aDomTrack
)
{
if
(
aDomTrack
)
{
nsString
nsTrackId
;
aDomTrack
-
>
GetId
(
nsTrackId
)
;
std
:
:
string
track_id
(
NS_ConvertUTF16toUTF8
(
nsTrackId
)
.
get
(
)
)
;
CSFLogDebug
(
LOGTAG
"
Reattaching
pipeline
to
track
%
p
track
%
s
conduit
type
:
%
s
"
&
aDomTrack
track_id
.
c_str
(
)
(
mConduit
-
>
type
(
)
=
=
MediaSessionConduit
:
:
AUDIO
?
"
audio
"
:
"
video
"
)
)
;
}
RefPtr
<
dom
:
:
MediaStreamTrack
>
oldTrack
=
mDomTrack
;
bool
wasTransmitting
=
oldTrack
&
&
mTransmitting
;
Stop
(
)
;
mDomTrack
=
aDomTrack
;
SetDescription
(
)
;
if
(
wasTransmitting
)
{
Start
(
)
;
}
return
NS_OK
;
}
nsresult
MediaPipeline
:
:
ConnectTransport_s
(
TransportInfo
&
aInfo
)
{
MOZ_ASSERT
(
aInfo
.
mTransport
)
;
MOZ_ASSERT
(
aInfo
.
mSrtp
)
;
ASSERT_ON_THREAD
(
mStsThread
)
;
if
(
aInfo
.
mSrtp
-
>
state
(
)
=
=
TransportLayer
:
:
TS_OPEN
)
{
nsresult
res
=
TransportReady_s
(
aInfo
)
;
if
(
NS_FAILED
(
res
)
)
{
CSFLogError
(
LOGTAG
"
Error
calling
TransportReady
(
)
;
res
=
%
u
in
%
s
"
static_cast
<
uint32_t
>
(
res
)
__FUNCTION__
)
;
return
res
;
}
}
else
if
(
aInfo
.
mSrtp
-
>
state
(
)
=
=
TransportLayer
:
:
TS_ERROR
)
{
CSFLogError
(
LOGTAG
"
%
s
transport
is
already
in
error
state
"
ToString
(
aInfo
.
mType
)
)
;
TransportFailed_s
(
aInfo
)
;
return
NS_ERROR_FAILURE
;
}
aInfo
.
mSrtp
-
>
SignalStateChange
.
connect
(
this
&
MediaPipeline
:
:
StateChange
)
;
return
NS_OK
;
}
MediaPipeline
:
:
TransportInfo
*
MediaPipeline
:
:
GetTransportInfo_s
(
TransportLayer
*
aLayer
)
{
ASSERT_ON_THREAD
(
mStsThread
)
;
if
(
aLayer
=
=
mRtp
.
mSrtp
)
{
return
&
mRtp
;
}
if
(
aLayer
=
=
mRtcp
.
mSrtp
)
{
return
&
mRtcp
;
}
return
nullptr
;
}
nsresult
MediaPipeline
:
:
PipelineTransport
:
:
SendRtpPacket
(
const
uint8_t
*
aData
size_t
aLen
)
{
nsAutoPtr
<
MediaPacket
>
packet
(
new
MediaPacket
)
;
packet
-
>
Copy
(
aData
aLen
aLen
+
SRTP_MAX_EXPANSION
)
;
packet
-
>
SetType
(
MediaPacket
:
:
RTP
)
;
RUN_ON_THREAD
(
mStsThread
WrapRunnable
(
RefPtr
<
MediaPipeline
:
:
PipelineTransport
>
(
this
)
&
MediaPipeline
:
:
PipelineTransport
:
:
SendRtpRtcpPacket_s
packet
)
NS_DISPATCH_NORMAL
)
;
return
NS_OK
;
}
nsresult
MediaPipeline
:
:
PipelineTransport
:
:
SendRtpRtcpPacket_s
(
nsAutoPtr
<
MediaPacket
>
aPacket
)
{
bool
isRtp
=
aPacket
-
>
type
(
)
=
=
MediaPacket
:
:
RTP
;
ASSERT_ON_THREAD
(
mStsThread
)
;
if
(
!
mPipeline
)
{
return
NS_OK
;
}
TransportInfo
&
transport
=
isRtp
?
mPipeline
-
>
mRtp
:
mPipeline
-
>
mRtcp
;
if
(
transport
.
mSrtp
-
>
state
(
)
!
=
TransportLayer
:
:
TS_OPEN
)
{
return
NS_OK
;
}
MOZ_ASSERT
(
transport
.
mTransport
)
;
NS_ENSURE_TRUE
(
transport
.
mTransport
NS_ERROR_NULL_POINTER
)
;
MediaPacket
packet
(
std
:
:
move
(
*
aPacket
)
)
;
packet
.
sdp_level
(
)
=
Some
(
mPipeline
-
>
Level
(
)
)
;
if
(
RtpLogger
:
:
IsPacketLoggingOn
(
)
)
{
RtpLogger
:
:
LogPacket
(
packet
false
mPipeline
-
>
mDescription
)
;
}
if
(
isRtp
)
{
mPipeline
-
>
mPacketDumper
-
>
Dump
(
mPipeline
-
>
Level
(
)
dom
:
:
mozPacketDumpType
:
:
Rtp
true
packet
.
data
(
)
packet
.
len
(
)
)
;
mPipeline
-
>
IncrementRtpPacketsSent
(
packet
.
len
(
)
)
;
}
else
{
mPipeline
-
>
mPacketDumper
-
>
Dump
(
mPipeline
-
>
Level
(
)
dom
:
:
mozPacketDumpType
:
:
Rtcp
true
packet
.
data
(
)
packet
.
len
(
)
)
;
mPipeline
-
>
IncrementRtcpPacketsSent
(
)
;
}
CSFLogDebug
(
LOGTAG
"
%
s
sending
%
s
packet
"
mPipeline
-
>
mDescription
.
c_str
(
)
(
isRtp
?
"
RTP
"
:
"
RTCP
"
)
)
;
return
mPipeline
-
>
SendPacket
(
transport
.
mSrtp
packet
)
;
}
nsresult
MediaPipeline
:
:
PipelineTransport
:
:
SendRtcpPacket
(
const
uint8_t
*
aData
size_t
aLen
)
{
nsAutoPtr
<
MediaPacket
>
packet
(
new
MediaPacket
)
;
packet
-
>
Copy
(
aData
aLen
aLen
+
SRTP_MAX_EXPANSION
)
;
packet
-
>
SetType
(
MediaPacket
:
:
RTCP
)
;
RUN_ON_THREAD
(
mStsThread
WrapRunnable
(
RefPtr
<
MediaPipeline
:
:
PipelineTransport
>
(
this
)
&
MediaPipeline
:
:
PipelineTransport
:
:
SendRtpRtcpPacket_s
packet
)
NS_DISPATCH_NORMAL
)
;
return
NS_OK
;
}
void
MediaPipelineTransmit
:
:
PipelineListener
:
:
NotifyRealtimeTrackData
(
MediaStreamGraph
*
aGraph
StreamTime
aOffset
const
MediaSegment
&
aMedia
)
{
CSFLogDebug
(
LOGTAG
"
MediaPipeline
:
:
NotifyRealtimeTrackData
(
)
listener
=
%
p
offset
=
%
"
PRId64
"
duration
=
%
"
PRId64
this
aOffset
aMedia
.
GetDuration
(
)
)
;
if
(
aMedia
.
GetType
(
)
=
=
MediaSegment
:
:
VIDEO
)
{
TRACE_COMMENT
(
"
Video
"
)
;
MediaStreamVideoSink
:
:
NotifyRealtimeTrackData
(
aGraph
aOffset
aMedia
)
;
return
;
}
TRACE_COMMENT
(
"
Audio
"
)
;
NewData
(
aMedia
aGraph
-
>
GraphRate
(
)
)
;
}
void
MediaPipelineTransmit
:
:
PipelineListener
:
:
NotifyQueuedChanges
(
MediaStreamGraph
*
aGraph
StreamTime
aOffset
const
MediaSegment
&
aQueuedMedia
)
{
CSFLogDebug
(
LOGTAG
"
MediaPipeline
:
:
NotifyQueuedChanges
(
)
"
)
;
if
(
aQueuedMedia
.
GetType
(
)
=
=
MediaSegment
:
:
VIDEO
)
{
return
;
}
TRACE_AUDIO_CALLBACK_COMMENT
(
"
Audio
"
)
;
if
(
mDirectConnect
)
{
return
;
}
size_t
rate
;
if
(
aGraph
)
{
rate
=
aGraph
-
>
GraphRate
(
)
;
}
else
{
rate
=
16000
;
}
NewData
(
aQueuedMedia
rate
)
;
}
void
MediaPipelineTransmit
:
:
PipelineListener
:
:
NotifyDirectListenerInstalled
(
InstallationResult
aResult
)
{
CSFLogInfo
(
LOGTAG
"
MediaPipeline
:
:
NotifyDirectListenerInstalled
(
)
listener
=
%
p
result
=
%
d
"
this
static_cast
<
int32_t
>
(
aResult
)
)
;
mDirectConnect
=
InstallationResult
:
:
SUCCESS
=
=
aResult
;
}
void
MediaPipelineTransmit
:
:
PipelineListener
:
:
NotifyDirectListenerUninstalled
(
)
{
CSFLogInfo
(
LOGTAG
"
MediaPipeline
:
:
NotifyDirectListenerUninstalled
(
)
listener
=
%
p
"
this
)
;
mDirectConnect
=
false
;
}
void
MediaPipelineTransmit
:
:
PipelineListener
:
:
NewData
(
const
MediaSegment
&
aMedia
TrackRate
aRate
)
{
if
(
!
mActive
)
{
CSFLogDebug
(
LOGTAG
"
Discarding
packets
because
transport
not
ready
"
)
;
return
;
}
if
(
mConduit
-
>
type
(
)
!
=
(
aMedia
.
GetType
(
)
=
=
MediaSegment
:
:
AUDIO
?
MediaSessionConduit
:
:
AUDIO
:
MediaSessionConduit
:
:
VIDEO
)
)
{
MOZ_ASSERT
(
false
"
The
media
type
should
always
be
correct
since
the
"
"
listener
is
locked
to
a
specific
track
"
)
;
return
;
}
if
(
aMedia
.
GetType
(
)
=
=
MediaSegment
:
:
AUDIO
)
{
MOZ_RELEASE_ASSERT
(
aRate
>
0
)
;
const
AudioSegment
*
audio
=
static_cast
<
const
AudioSegment
*
>
(
&
aMedia
)
;
for
(
AudioSegment
:
:
ConstChunkIterator
iter
(
*
audio
)
;
!
iter
.
IsEnded
(
)
;
iter
.
Next
(
)
)
{
mAudioProcessing
-
>
QueueAudioChunk
(
aRate
*
iter
mEnabled
)
;
}
}
else
{
const
VideoSegment
*
video
=
static_cast
<
const
VideoSegment
*
>
(
&
aMedia
)
;
for
(
VideoSegment
:
:
ConstChunkIterator
iter
(
*
video
)
;
!
iter
.
IsEnded
(
)
;
iter
.
Next
(
)
)
{
mConverter
-
>
QueueVideoChunk
(
*
iter
!
mEnabled
)
;
}
}
}
void
MediaPipelineTransmit
:
:
PipelineListener
:
:
SetCurrentFrames
(
const
VideoSegment
&
aSegment
)
{
NewData
(
aSegment
)
;
}
class
GenericReceiveListener
:
public
MediaStreamListener
{
public
:
explicit
GenericReceiveListener
(
dom
:
:
MediaStreamTrack
*
aTrack
)
:
mTrack
(
aTrack
)
mTrackId
(
aTrack
-
>
GetInputTrackId
(
)
)
mSource
(
mTrack
-
>
GetInputStream
(
)
-
>
AsSourceStream
(
)
)
mPlayedTicks
(
0
)
mPrincipalHandle
(
PRINCIPAL_HANDLE_NONE
)
mListening
(
false
)
mMaybeTrackNeedsUnmute
(
true
)
{
MOZ_RELEASE_ASSERT
(
mSource
"
Must
be
used
with
a
SourceMediaStream
"
)
;
}
virtual
~
GenericReceiveListener
(
)
{
NS_ReleaseOnMainThreadSystemGroup
(
"
GenericReceiveListener
:
:
track_
"
mTrack
.
forget
(
)
)
;
}
void
AddTrackToSource
(
uint32_t
aRate
=
0
)
{
MOZ_ASSERT
(
(
aRate
!
=
0
&
&
mTrack
-
>
AsAudioStreamTrack
(
)
)
|
|
mTrack
-
>
AsVideoStreamTrack
(
)
)
;
if
(
mTrack
-
>
AsAudioStreamTrack
(
)
)
{
mSource
-
>
AddAudioTrack
(
mTrackId
aRate
0
new
AudioSegment
(
)
)
;
}
else
if
(
mTrack
-
>
AsVideoStreamTrack
(
)
)
{
mSource
-
>
AddTrack
(
mTrackId
0
new
VideoSegment
(
)
)
;
}
CSFLogDebug
(
LOGTAG
"
GenericReceiveListener
added
%
s
track
%
d
(
%
p
)
to
stream
%
p
"
mTrack
-
>
AsAudioStreamTrack
(
)
?
"
audio
"
:
"
video
"
mTrackId
mTrack
.
get
(
)
mSource
.
get
(
)
)
;
mSource
-
>
AdvanceKnownTracksTime
(
STREAM_TIME_MAX
)
;
mSource
-
>
AddListener
(
this
)
;
}
void
AddSelf
(
)
{
if
(
!
mListening
)
{
mListening
=
true
;
mSource
-
>
SetPullEnabled
(
true
)
;
mMaybeTrackNeedsUnmute
=
true
;
}
}
void
RemoveSelf
(
)
{
if
(
mListening
)
{
mListening
=
false
;
mSource
-
>
SetPullEnabled
(
false
)
;
}
}
void
OnRtpReceived
(
)
{
if
(
mMaybeTrackNeedsUnmute
)
{
mMaybeTrackNeedsUnmute
=
false
;
NS_DispatchToMainThread
(
NewRunnableMethod
(
"
GenericReceiveListener
:
:
OnRtpReceived_m
"
this
&
GenericReceiveListener
:
:
OnRtpReceived_m
)
)
;
}
}
void
OnRtpReceived_m
(
)
{
if
(
mListening
&
&
mTrack
-
>
Muted
(
)
)
{
mTrack
-
>
MutedChanged
(
false
)
;
}
}
void
EndTrack
(
)
{
CSFLogDebug
(
LOGTAG
"
GenericReceiveListener
ending
track
"
)
;
mSource
-
>
RemoveListener
(
this
)
;
mSource
-
>
EndTrack
(
mTrackId
)
;
}
void
SetPrincipalHandle_m
(
const
PrincipalHandle
&
aPrincipalHandle
)
{
class
Message
:
public
ControlMessage
{
public
:
Message
(
GenericReceiveListener
*
aListener
const
PrincipalHandle
&
aPrincipalHandle
)
:
ControlMessage
(
nullptr
)
mListener
(
aListener
)
mPrincipalHandle
(
aPrincipalHandle
)
{
}
void
Run
(
)
override
{
mListener
-
>
SetPrincipalHandle_msg
(
mPrincipalHandle
)
;
}
const
RefPtr
<
GenericReceiveListener
>
mListener
;
PrincipalHandle
mPrincipalHandle
;
}
;
mTrack
-
>
GraphImpl
(
)
-
>
AppendMessage
(
MakeUnique
<
Message
>
(
this
aPrincipalHandle
)
)
;
}
void
SetPrincipalHandle_msg
(
const
PrincipalHandle
&
aPrincipalHandle
)
{
mPrincipalHandle
=
aPrincipalHandle
;
}
protected
:
RefPtr
<
dom
:
:
MediaStreamTrack
>
mTrack
;
const
TrackID
mTrackId
;
const
RefPtr
<
SourceMediaStream
>
mSource
;
TrackTicks
mPlayedTicks
;
PrincipalHandle
mPrincipalHandle
;
bool
mListening
;
Atomic
<
bool
>
mMaybeTrackNeedsUnmute
;
}
;
MediaPipelineReceive
:
:
MediaPipelineReceive
(
const
std
:
:
string
&
aPc
nsCOMPtr
<
nsIEventTarget
>
aMainThread
nsCOMPtr
<
nsIEventTarget
>
aStsThread
RefPtr
<
MediaSessionConduit
>
aConduit
)
:
MediaPipeline
(
aPc
DirectionType
:
:
RECEIVE
aMainThread
aStsThread
aConduit
)
{
}
MediaPipelineReceive
:
:
~
MediaPipelineReceive
(
)
{
}
class
MediaPipelineReceiveAudio
:
:
PipelineListener
:
public
GenericReceiveListener
{
public
:
PipelineListener
(
dom
:
:
MediaStreamTrack
*
aTrack
const
RefPtr
<
MediaSessionConduit
>
&
aConduit
)
:
GenericReceiveListener
(
aTrack
)
mConduit
(
aConduit
)
mRate
(
static_cast
<
AudioSessionConduit
*
>
(
mConduit
.
get
(
)
)
-
>
IsSamplingFreqSupported
(
mSource
-
>
GraphRate
(
)
)
?
mSource
-
>
GraphRate
(
)
:
WEBRTC_MAX_SAMPLE_RATE
)
mTaskQueue
(
new
TaskQueue
(
GetMediaThreadPool
(
MediaThreadType
:
:
WEBRTC_DECODER
)
"
AudioPipelineListener
"
)
)
mLastLog
(
0
)
{
AddTrackToSource
(
mRate
)
;
}
void
NotifyPull
(
MediaStreamGraph
*
aGraph
StreamTime
aDesiredTime
)
override
{
NotifyPullImpl
(
aDesiredTime
)
;
}
private
:
~
PipelineListener
(
)
{
NS_ReleaseOnMainThreadSystemGroup
(
"
MediaPipeline
:
:
mConduit
"
mConduit
.
forget
(
)
)
;
}
void
NotifyPullImpl
(
StreamTime
aDesiredTime
)
{
TRACE_AUDIO_CALLBACK_COMMENT
(
"
Track
%
i
"
mTrackId
)
;
uint32_t
samplesPer10ms
=
mRate
/
100
;
TrackTicks
desired
=
mSource
-
>
TimeToTicksRoundUp
(
mRate
aDesiredTime
)
;
TrackTicks
framesNeeded
=
desired
-
mPlayedTicks
;
while
(
framesNeeded
>
=
0
)
{
const
int
scratchBufferLength
=
AUDIO_SAMPLE_BUFFER_MAX_BYTES
/
sizeof
(
int16_t
)
;
int16_t
scratchBuffer
[
scratchBufferLength
]
;
int
samplesLength
=
scratchBufferLength
;
MediaConduitErrorCode
err
=
static_cast
<
AudioSessionConduit
*
>
(
mConduit
.
get
(
)
)
-
>
GetAudioFrame
(
scratchBuffer
mRate
0
samplesLength
)
;
if
(
err
!
=
kMediaConduitNoError
)
{
CSFLogError
(
LOGTAG
"
Audio
conduit
failed
(
%
d
)
to
return
data
%
"
PRId64
"
(
desired
%
"
PRId64
"
-
>
%
f
)
"
err
mPlayedTicks
aDesiredTime
mSource
-
>
StreamTimeToSeconds
(
aDesiredTime
)
)
;
samplesLength
=
samplesPer10ms
;
PodArrayZero
(
scratchBuffer
)
;
}
MOZ_RELEASE_ASSERT
(
samplesLength
<
=
scratchBufferLength
)
;
CSFLogDebug
(
LOGTAG
"
Audio
conduit
returned
buffer
of
length
%
u
"
samplesLength
)
;
RefPtr
<
SharedBuffer
>
samples
=
SharedBuffer
:
:
Create
(
samplesLength
*
sizeof
(
uint16_t
)
)
;
int16_t
*
samplesData
=
static_cast
<
int16_t
*
>
(
samples
-
>
Data
(
)
)
;
AudioSegment
segment
;
uint32_t
channelCount
=
samplesLength
/
samplesPer10ms
;
AutoTArray
<
int16_t
*
2
>
channels
;
AutoTArray
<
const
int16_t
*
2
>
outputChannels
;
size_t
frames
=
samplesLength
/
channelCount
;
channels
.
SetLength
(
channelCount
)
;
size_t
offset
=
0
;
for
(
size_t
i
=
0
;
i
<
channelCount
;
i
+
+
)
{
channels
[
i
]
=
samplesData
+
offset
;
offset
+
=
frames
;
}
DeinterleaveAndConvertBuffer
(
scratchBuffer
frames
channelCount
channels
.
Elements
(
)
)
;
outputChannels
.
AppendElements
(
channels
)
;
segment
.
AppendFrames
(
samples
.
forget
(
)
outputChannels
frames
mPrincipalHandle
)
;
if
(
mSource
-
>
AppendToTrack
(
mTrackId
&
segment
)
)
{
framesNeeded
-
=
frames
;
mPlayedTicks
+
=
frames
;
if
(
MOZ_LOG_TEST
(
AudioLogModule
(
)
LogLevel
:
:
Debug
)
)
{
if
(
mPlayedTicks
>
mLastLog
+
mRate
)
{
MOZ_LOG
(
AudioLogModule
(
)
LogLevel
:
:
Debug
(
"
%
p
:
Inserting
samples
into
track
%
d
total
=
"
"
%
"
PRIu64
(
void
*
)
this
mTrackId
mPlayedTicks
)
)
;
mLastLog
=
mPlayedTicks
;
}
}
}
else
{
CSFLogError
(
LOGTAG
"
AppendToTrack
failed
"
)
;
break
;
}
}
}
RefPtr
<
MediaSessionConduit
>
mConduit
;
const
TrackRate
mRate
;
const
RefPtr
<
TaskQueue
>
mTaskQueue
;
TrackTicks
mLastLog
=
0
;
}
;
MediaPipelineReceiveAudio
:
:
MediaPipelineReceiveAudio
(
const
std
:
:
string
&
aPc
nsCOMPtr
<
nsIEventTarget
>
aMainThread
nsCOMPtr
<
nsIEventTarget
>
aStsThread
RefPtr
<
AudioSessionConduit
>
aConduit
dom
:
:
MediaStreamTrack
*
aTrack
)
:
MediaPipelineReceive
(
aPc
aMainThread
aStsThread
aConduit
)
mListener
(
aTrack
?
new
PipelineListener
(
aTrack
mConduit
)
:
nullptr
)
{
mDescription
=
mPc
+
"
|
Receive
audio
"
;
}
void
MediaPipelineReceiveAudio
:
:
DetachMedia
(
)
{
ASSERT_ON_THREAD
(
mMainThread
)
;
if
(
mListener
)
{
mListener
-
>
EndTrack
(
)
;
}
}
void
MediaPipelineReceiveAudio
:
:
SetPrincipalHandle_m
(
const
PrincipalHandle
&
aPrincipalHandle
)
{
if
(
mListener
)
{
mListener
-
>
SetPrincipalHandle_m
(
aPrincipalHandle
)
;
}
}
void
MediaPipelineReceiveAudio
:
:
Start
(
)
{
mConduit
-
>
StartReceiving
(
)
;
if
(
mListener
)
{
mListener
-
>
AddSelf
(
)
;
}
}
void
MediaPipelineReceiveAudio
:
:
Stop
(
)
{
if
(
mListener
)
{
mListener
-
>
RemoveSelf
(
)
;
}
mConduit
-
>
StopReceiving
(
)
;
}
void
MediaPipelineReceiveAudio
:
:
OnRtpPacketReceived
(
)
{
if
(
mListener
)
{
mListener
-
>
OnRtpReceived
(
)
;
}
}
class
MediaPipelineReceiveVideo
:
:
PipelineListener
:
public
GenericReceiveListener
{
public
:
explicit
PipelineListener
(
dom
:
:
MediaStreamTrack
*
aTrack
)
:
GenericReceiveListener
(
aTrack
)
mWidth
(
0
)
mHeight
(
0
)
mImageContainer
(
LayerManager
:
:
CreateImageContainer
(
ImageContainer
:
:
ASYNCHRONOUS
)
)
mMutex
(
"
Video
PipelineListener
"
)
{
AddTrackToSource
(
)
;
}
void
NotifyPull
(
MediaStreamGraph
*
aGraph
StreamTime
aDesiredTime
)
override
{
TRACE_AUDIO_CALLBACK_COMMENT
(
"
Track
%
i
"
mTrackId
)
;
MutexAutoLock
lock
(
mMutex
)
;
RefPtr
<
Image
>
image
=
mImage
;
StreamTime
delta
=
aDesiredTime
-
mPlayedTicks
;
if
(
delta
>
0
)
{
VideoSegment
segment
;
IntSize
size
=
image
?
image
-
>
GetSize
(
)
:
IntSize
(
mWidth
mHeight
)
;
segment
.
AppendFrame
(
image
.
forget
(
)
delta
size
mPrincipalHandle
)
;
if
(
!
mSource
-
>
AppendToTrack
(
mTrackId
&
segment
)
)
{
CSFLogError
(
LOGTAG
"
AppendToTrack
failed
"
)
;
return
;
}
mPlayedTicks
=
aDesiredTime
;
}
}
void
FrameSizeChange
(
unsigned
int
aWidth
unsigned
int
aHeight
unsigned
int
aNumberOfStreams
)
{
MutexAutoLock
enter
(
mMutex
)
;
mWidth
=
aWidth
;
mHeight
=
aHeight
;
}
void
RenderVideoFrame
(
const
webrtc
:
:
VideoFrameBuffer
&
aBuffer
uint32_t
aTimeStamp
int64_t
aRenderTime
)
{
if
(
aBuffer
.
native_handle
(
)
)
{
RefPtr
<
Image
>
image
=
static_cast
<
Image
*
>
(
aBuffer
.
native_handle
(
)
)
;
MutexAutoLock
lock
(
mMutex
)
;
mImage
=
image
;
return
;
}
MOZ_ASSERT
(
aBuffer
.
DataY
(
)
)
;
RefPtr
<
PlanarYCbCrImage
>
yuvImage
=
mImageContainer
-
>
CreatePlanarYCbCrImage
(
)
;
PlanarYCbCrData
yuvData
;
yuvData
.
mYChannel
=
const_cast
<
uint8_t
*
>
(
aBuffer
.
DataY
(
)
)
;
yuvData
.
mYSize
=
IntSize
(
aBuffer
.
width
(
)
aBuffer
.
height
(
)
)
;
yuvData
.
mYStride
=
aBuffer
.
StrideY
(
)
;
MOZ_ASSERT
(
aBuffer
.
StrideU
(
)
=
=
aBuffer
.
StrideV
(
)
)
;
yuvData
.
mCbCrStride
=
aBuffer
.
StrideU
(
)
;
yuvData
.
mCbChannel
=
const_cast
<
uint8_t
*
>
(
aBuffer
.
DataU
(
)
)
;
yuvData
.
mCrChannel
=
const_cast
<
uint8_t
*
>
(
aBuffer
.
DataV
(
)
)
;
yuvData
.
mCbCrSize
=
IntSize
(
(
aBuffer
.
width
(
)
+
1
)
>
>
1
(
aBuffer
.
height
(
)
+
1
)
>
>
1
)
;
yuvData
.
mPicX
=
0
;
yuvData
.
mPicY
=
0
;
yuvData
.
mPicSize
=
IntSize
(
aBuffer
.
width
(
)
aBuffer
.
height
(
)
)
;
yuvData
.
mStereoMode
=
StereoMode
:
:
MONO
;
if
(
!
yuvImage
-
>
CopyData
(
yuvData
)
)
{
MOZ_ASSERT
(
false
)
;
return
;
}
MutexAutoLock
lock
(
mMutex
)
;
mImage
=
yuvImage
;
}
private
:
int
mWidth
;
int
mHeight
;
RefPtr
<
layers
:
:
ImageContainer
>
mImageContainer
;
RefPtr
<
layers
:
:
Image
>
mImage
;
Mutex
mMutex
;
}
;
class
MediaPipelineReceiveVideo
:
:
PipelineRenderer
:
public
mozilla
:
:
VideoRenderer
{
public
:
explicit
PipelineRenderer
(
MediaPipelineReceiveVideo
*
aPipeline
)
:
mPipeline
(
aPipeline
)
{
}
void
Detach
(
)
{
mPipeline
=
nullptr
;
}
void
FrameSizeChange
(
unsigned
int
aWidth
unsigned
int
aHeight
unsigned
int
aNumberOfStreams
)
override
{
mPipeline
-
>
mListener
-
>
FrameSizeChange
(
aWidth
aHeight
aNumberOfStreams
)
;
}
void
RenderVideoFrame
(
const
webrtc
:
:
VideoFrameBuffer
&
aBuffer
uint32_t
aTimeStamp
int64_t
aRenderTime
)
override
{
mPipeline
-
>
mListener
-
>
RenderVideoFrame
(
aBuffer
aTimeStamp
aRenderTime
)
;
}
private
:
MediaPipelineReceiveVideo
*
mPipeline
;
}
;
MediaPipelineReceiveVideo
:
:
MediaPipelineReceiveVideo
(
const
std
:
:
string
&
aPc
nsCOMPtr
<
nsIEventTarget
>
aMainThread
nsCOMPtr
<
nsIEventTarget
>
aStsThread
RefPtr
<
VideoSessionConduit
>
aConduit
dom
:
:
MediaStreamTrack
*
aTrack
)
:
MediaPipelineReceive
(
aPc
aMainThread
aStsThread
aConduit
)
mRenderer
(
new
PipelineRenderer
(
this
)
)
mListener
(
aTrack
?
new
PipelineListener
(
aTrack
)
:
nullptr
)
{
mDescription
=
mPc
+
"
|
Receive
video
"
;
aConduit
-
>
AttachRenderer
(
mRenderer
)
;
}
void
MediaPipelineReceiveVideo
:
:
DetachMedia
(
)
{
ASSERT_ON_THREAD
(
mMainThread
)
;
static_cast
<
VideoSessionConduit
*
>
(
mConduit
.
get
(
)
)
-
>
DetachRenderer
(
)
;
if
(
mListener
)
{
mListener
-
>
EndTrack
(
)
;
}
}
void
MediaPipelineReceiveVideo
:
:
SetPrincipalHandle_m
(
const
PrincipalHandle
&
aPrincipalHandle
)
{
if
(
mListener
)
{
mListener
-
>
SetPrincipalHandle_m
(
aPrincipalHandle
)
;
}
}
void
MediaPipelineReceiveVideo
:
:
Start
(
)
{
mConduit
-
>
StartReceiving
(
)
;
if
(
mListener
)
{
mListener
-
>
AddSelf
(
)
;
}
}
void
MediaPipelineReceiveVideo
:
:
Stop
(
)
{
if
(
mListener
)
{
mListener
-
>
RemoveSelf
(
)
;
}
mConduit
-
>
StopReceiving
(
)
;
}
void
MediaPipelineReceiveVideo
:
:
OnRtpPacketReceived
(
)
{
if
(
mListener
)
{
mListener
-
>
OnRtpReceived
(
)
;
}
}
DOMHighResTimeStamp
MediaPipeline
:
:
GetNow
(
)
{
return
webrtc
:
:
Clock
:
:
GetRealTimeClock
(
)
-
>
TimeInMilliseconds
(
)
;
}
DOMHighResTimeStamp
MediaPipeline
:
:
RtpCSRCStats
:
:
GetExpiryFromTime
(
const
DOMHighResTimeStamp
aTime
)
{
return
aTime
-
EXPIRY_TIME_MILLISECONDS
;
}
MediaPipeline
:
:
RtpCSRCStats
:
:
RtpCSRCStats
(
const
uint32_t
aCsrc
const
DOMHighResTimeStamp
aTime
)
:
mCsrc
(
aCsrc
)
mTimestamp
(
aTime
)
{
}
void
MediaPipeline
:
:
RtpCSRCStats
:
:
GetWebidlInstance
(
dom
:
:
RTCRTPContributingSourceStats
&
aWebidlObj
const
nsString
&
aInboundRtpStreamId
)
const
{
nsString
statId
=
NS_LITERAL_STRING
(
"
csrc_
"
)
+
aInboundRtpStreamId
;
statId
.
AppendLiteral
(
"
_
"
)
;
statId
.
AppendInt
(
mCsrc
)
;
aWebidlObj
.
mId
.
Construct
(
statId
)
;
aWebidlObj
.
mType
.
Construct
(
RTCStatsType
:
:
Csrc
)
;
aWebidlObj
.
mTimestamp
.
Construct
(
mTimestamp
)
;
aWebidlObj
.
mContributorSsrc
.
Construct
(
mCsrc
)
;
aWebidlObj
.
mInboundRtpStreamId
.
Construct
(
aInboundRtpStreamId
)
;
}
}
