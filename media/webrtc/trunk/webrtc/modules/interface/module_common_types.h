#
ifndef
MODULE_COMMON_TYPES_H
#
define
MODULE_COMMON_TYPES_H
#
include
<
assert
.
h
>
#
include
<
string
.
h
>
#
include
<
algorithm
>
#
include
<
limits
>
#
include
"
webrtc
/
base
/
constructormagic
.
h
"
#
include
"
webrtc
/
common_types
.
h
"
#
include
"
webrtc
/
common_video
/
rotation
.
h
"
#
include
"
webrtc
/
typedefs
.
h
"
namespace
webrtc
{
struct
RTPAudioHeader
{
uint8_t
numEnergy
;
uint8_t
arrOfEnergy
[
kRtpCsrcSize
]
;
bool
isCNG
;
uint8_t
channel
;
}
;
const
int16_t
kNoPictureId
=
-
1
;
const
int16_t
kMaxOneBytePictureId
=
0x7F
;
const
int16_t
kMaxTwoBytePictureId
=
0x7FFF
;
const
int16_t
kNoTl0PicIdx
=
-
1
;
const
uint8_t
kNoTemporalIdx
=
0xFF
;
const
uint8_t
kNoSpatialIdx
=
0xFF
;
const
uint8_t
kNoGofIdx
=
0xFF
;
const
uint8_t
kNumVp9Buffers
=
8
;
const
size_t
kMaxVp9RefPics
=
3
;
const
size_t
kMaxVp9FramesInGof
=
0xFF
;
const
size_t
kMaxVp9NumberOfSpatialLayers
=
8
;
const
int
kNoKeyIdx
=
-
1
;
struct
RTPVideoHeaderVP8
{
void
InitRTPVideoHeaderVP8
(
)
{
nonReference
=
false
;
pictureId
=
kNoPictureId
;
tl0PicIdx
=
kNoTl0PicIdx
;
temporalIdx
=
kNoTemporalIdx
;
layerSync
=
false
;
keyIdx
=
kNoKeyIdx
;
partitionId
=
0
;
beginningOfPartition
=
false
;
}
bool
nonReference
;
int16_t
pictureId
;
int16_t
tl0PicIdx
;
uint8_t
temporalIdx
;
bool
layerSync
;
int
keyIdx
;
int
partitionId
;
bool
beginningOfPartition
;
}
;
enum
TemporalStructureMode
{
kTemporalStructureMode1
kTemporalStructureMode2
kTemporalStructureMode3
}
;
struct
GofInfoVP9
{
void
SetGofInfoVP9
(
TemporalStructureMode
tm
)
{
switch
(
tm
)
{
case
kTemporalStructureMode1
:
num_frames_in_gof
=
1
;
temporal_idx
[
0
]
=
0
;
temporal_up_switch
[
0
]
=
false
;
num_ref_pics
[
0
]
=
1
;
pid_diff
[
0
]
[
0
]
=
1
;
break
;
case
kTemporalStructureMode2
:
num_frames_in_gof
=
2
;
temporal_idx
[
0
]
=
0
;
temporal_up_switch
[
0
]
=
false
;
num_ref_pics
[
0
]
=
1
;
pid_diff
[
0
]
[
0
]
=
2
;
temporal_idx
[
1
]
=
1
;
temporal_up_switch
[
1
]
=
true
;
num_ref_pics
[
1
]
=
1
;
pid_diff
[
1
]
[
0
]
=
1
;
break
;
case
kTemporalStructureMode3
:
num_frames_in_gof
=
4
;
temporal_idx
[
0
]
=
0
;
temporal_up_switch
[
0
]
=
false
;
num_ref_pics
[
0
]
=
1
;
pid_diff
[
0
]
[
0
]
=
4
;
temporal_idx
[
1
]
=
2
;
temporal_up_switch
[
1
]
=
true
;
num_ref_pics
[
1
]
=
1
;
pid_diff
[
1
]
[
0
]
=
1
;
temporal_idx
[
2
]
=
1
;
temporal_up_switch
[
2
]
=
true
;
num_ref_pics
[
2
]
=
1
;
pid_diff
[
2
]
[
0
]
=
2
;
temporal_idx
[
3
]
=
2
;
temporal_up_switch
[
3
]
=
false
;
num_ref_pics
[
3
]
=
2
;
pid_diff
[
3
]
[
0
]
=
1
;
pid_diff
[
3
]
[
1
]
=
2
;
break
;
default
:
assert
(
false
)
;
}
}
void
CopyGofInfoVP9
(
const
GofInfoVP9
&
src
)
{
num_frames_in_gof
=
src
.
num_frames_in_gof
;
for
(
size_t
i
=
0
;
i
<
num_frames_in_gof
;
+
+
i
)
{
temporal_idx
[
i
]
=
src
.
temporal_idx
[
i
]
;
temporal_up_switch
[
i
]
=
src
.
temporal_up_switch
[
i
]
;
num_ref_pics
[
i
]
=
src
.
num_ref_pics
[
i
]
;
for
(
uint8_t
r
=
0
;
r
<
num_ref_pics
[
i
]
;
+
+
r
)
{
pid_diff
[
i
]
[
r
]
=
src
.
pid_diff
[
i
]
[
r
]
;
}
}
}
size_t
num_frames_in_gof
;
uint8_t
temporal_idx
[
kMaxVp9FramesInGof
]
;
bool
temporal_up_switch
[
kMaxVp9FramesInGof
]
;
uint8_t
num_ref_pics
[
kMaxVp9FramesInGof
]
;
uint8_t
pid_diff
[
kMaxVp9FramesInGof
]
[
kMaxVp9RefPics
]
;
}
;
struct
RTPVideoHeaderVP9
{
void
InitRTPVideoHeaderVP9
(
)
{
inter_pic_predicted
=
false
;
flexible_mode
=
false
;
beginning_of_frame
=
false
;
end_of_frame
=
false
;
ss_data_available
=
false
;
picture_id
=
kNoPictureId
;
max_picture_id
=
kMaxTwoBytePictureId
;
tl0_pic_idx
=
kNoTl0PicIdx
;
temporal_idx
=
kNoTemporalIdx
;
spatial_idx
=
kNoSpatialIdx
;
temporal_up_switch
=
false
;
inter_layer_predicted
=
false
;
gof_idx
=
kNoGofIdx
;
num_ref_pics
=
0
;
num_spatial_layers
=
1
;
}
bool
inter_pic_predicted
;
bool
flexible_mode
;
bool
beginning_of_frame
;
bool
end_of_frame
;
bool
ss_data_available
;
int16_t
picture_id
;
int16_t
max_picture_id
;
int16_t
tl0_pic_idx
;
uint8_t
temporal_idx
;
uint8_t
spatial_idx
;
bool
temporal_up_switch
;
bool
inter_layer_predicted
;
uint8_t
gof_idx
;
uint8_t
num_ref_pics
;
uint8_t
pid_diff
[
kMaxVp9RefPics
]
;
int16_t
ref_picture_id
[
kMaxVp9RefPics
]
;
size_t
num_spatial_layers
;
bool
spatial_layer_resolution_present
;
uint16_t
width
[
kMaxVp9NumberOfSpatialLayers
]
;
uint16_t
height
[
kMaxVp9NumberOfSpatialLayers
]
;
GofInfoVP9
gof
;
}
;
#
if
WEBRTC_48_H264_IMPL
enum
H264PacketizationTypes
{
kH264SingleNalu
kH264StapA
kH264FuA
}
;
struct
RTPVideoHeaderH264
{
uint8_t
nalu_type
;
H264PacketizationTypes
packetization_type
;
}
;
#
else
struct
RTPVideoHeaderH264
{
bool
stap_a
;
bool
single_nalu
;
}
;
#
endif
union
RTPVideoTypeHeader
{
RTPVideoHeaderVP8
VP8
;
RTPVideoHeaderVP9
VP9
;
RTPVideoHeaderH264
H264
;
}
;
enum
RtpVideoCodecTypes
{
kRtpVideoNone
kRtpVideoGeneric
kRtpVideoVp8
kRtpVideoVp9
kRtpVideoH264
}
;
struct
RTPVideoHeader
{
uint16_t
width
;
uint16_t
height
;
VideoRotation
rotation
;
bool
isFirstPacket
;
uint8_t
simulcastIdx
;
RtpVideoCodecTypes
codec
;
RTPVideoTypeHeader
codecHeader
;
}
;
union
RTPTypeHeader
{
RTPAudioHeader
Audio
;
RTPVideoHeader
Video
;
}
;
struct
WebRtcRTPHeader
{
RTPHeader
header
;
FrameType
frameType
;
RTPTypeHeader
type
;
int64_t
ntp_time_ms
;
}
;
class
RTPFragmentationHeader
{
public
:
RTPFragmentationHeader
(
)
:
fragmentationVectorSize
(
0
)
fragmentationOffset
(
NULL
)
fragmentationLength
(
NULL
)
fragmentationTimeDiff
(
NULL
)
fragmentationPlType
(
NULL
)
{
}
;
~
RTPFragmentationHeader
(
)
{
delete
[
]
fragmentationOffset
;
delete
[
]
fragmentationLength
;
delete
[
]
fragmentationTimeDiff
;
delete
[
]
fragmentationPlType
;
}
void
CopyFrom
(
const
RTPFragmentationHeader
&
src
)
{
if
(
this
=
=
&
src
)
{
return
;
}
if
(
src
.
fragmentationVectorSize
!
=
fragmentationVectorSize
)
{
delete
[
]
fragmentationOffset
;
fragmentationOffset
=
NULL
;
delete
[
]
fragmentationLength
;
fragmentationLength
=
NULL
;
delete
[
]
fragmentationTimeDiff
;
fragmentationTimeDiff
=
NULL
;
delete
[
]
fragmentationPlType
;
fragmentationPlType
=
NULL
;
if
(
src
.
fragmentationVectorSize
>
0
)
{
if
(
src
.
fragmentationOffset
)
{
fragmentationOffset
=
new
size_t
[
src
.
fragmentationVectorSize
]
;
}
if
(
src
.
fragmentationLength
)
{
fragmentationLength
=
new
size_t
[
src
.
fragmentationVectorSize
]
;
}
if
(
src
.
fragmentationTimeDiff
)
{
fragmentationTimeDiff
=
new
uint16_t
[
src
.
fragmentationVectorSize
]
;
}
if
(
src
.
fragmentationPlType
)
{
fragmentationPlType
=
new
uint8_t
[
src
.
fragmentationVectorSize
]
;
}
}
fragmentationVectorSize
=
src
.
fragmentationVectorSize
;
}
if
(
src
.
fragmentationVectorSize
>
0
)
{
if
(
src
.
fragmentationOffset
)
{
memcpy
(
fragmentationOffset
src
.
fragmentationOffset
src
.
fragmentationVectorSize
*
sizeof
(
size_t
)
)
;
}
if
(
src
.
fragmentationLength
)
{
memcpy
(
fragmentationLength
src
.
fragmentationLength
src
.
fragmentationVectorSize
*
sizeof
(
size_t
)
)
;
}
if
(
src
.
fragmentationTimeDiff
)
{
memcpy
(
fragmentationTimeDiff
src
.
fragmentationTimeDiff
src
.
fragmentationVectorSize
*
sizeof
(
uint16_t
)
)
;
}
if
(
src
.
fragmentationPlType
)
{
memcpy
(
fragmentationPlType
src
.
fragmentationPlType
src
.
fragmentationVectorSize
*
sizeof
(
uint8_t
)
)
;
}
}
}
void
VerifyAndAllocateFragmentationHeader
(
const
uint16_t
size
)
{
if
(
fragmentationVectorSize
<
size
)
{
uint16_t
oldVectorSize
=
fragmentationVectorSize
;
{
size_t
*
oldOffsets
=
fragmentationOffset
;
fragmentationOffset
=
new
size_t
[
size
]
;
memset
(
fragmentationOffset
+
oldVectorSize
0
sizeof
(
size_t
)
*
(
size
-
oldVectorSize
)
)
;
memcpy
(
fragmentationOffset
oldOffsets
sizeof
(
size_t
)
*
oldVectorSize
)
;
delete
[
]
oldOffsets
;
}
{
size_t
*
oldLengths
=
fragmentationLength
;
fragmentationLength
=
new
size_t
[
size
]
;
memset
(
fragmentationLength
+
oldVectorSize
0
sizeof
(
size_t
)
*
(
size
-
oldVectorSize
)
)
;
memcpy
(
fragmentationLength
oldLengths
sizeof
(
size_t
)
*
oldVectorSize
)
;
delete
[
]
oldLengths
;
}
{
uint16_t
*
oldTimeDiffs
=
fragmentationTimeDiff
;
fragmentationTimeDiff
=
new
uint16_t
[
size
]
;
memset
(
fragmentationTimeDiff
+
oldVectorSize
0
sizeof
(
uint16_t
)
*
(
size
-
oldVectorSize
)
)
;
memcpy
(
fragmentationTimeDiff
oldTimeDiffs
sizeof
(
uint16_t
)
*
oldVectorSize
)
;
delete
[
]
oldTimeDiffs
;
}
{
uint8_t
*
oldTimePlTypes
=
fragmentationPlType
;
fragmentationPlType
=
new
uint8_t
[
size
]
;
memset
(
fragmentationPlType
+
oldVectorSize
0
sizeof
(
uint8_t
)
*
(
size
-
oldVectorSize
)
)
;
memcpy
(
fragmentationPlType
oldTimePlTypes
sizeof
(
uint8_t
)
*
oldVectorSize
)
;
delete
[
]
oldTimePlTypes
;
}
fragmentationVectorSize
=
size
;
}
}
uint16_t
fragmentationVectorSize
;
size_t
*
fragmentationOffset
;
size_t
*
fragmentationLength
;
uint16_t
*
fragmentationTimeDiff
;
uint8_t
*
fragmentationPlType
;
private
:
DISALLOW_COPY_AND_ASSIGN
(
RTPFragmentationHeader
)
;
}
;
struct
RTCPVoIPMetric
{
uint8_t
lossRate
;
uint8_t
discardRate
;
uint8_t
burstDensity
;
uint8_t
gapDensity
;
uint16_t
burstDuration
;
uint16_t
gapDuration
;
uint16_t
roundTripDelay
;
uint16_t
endSystemDelay
;
uint8_t
signalLevel
;
uint8_t
noiseLevel
;
uint8_t
RERL
;
uint8_t
Gmin
;
uint8_t
Rfactor
;
uint8_t
extRfactor
;
uint8_t
MOSLQ
;
uint8_t
MOSCQ
;
uint8_t
RXconfig
;
uint16_t
JBnominal
;
uint16_t
JBmax
;
uint16_t
JBabsMax
;
}
;
enum
FecMaskType
{
kFecMaskRandom
kFecMaskBursty
}
;
struct
FecProtectionParams
{
int
fec_rate
;
bool
use_uep_protection
;
int
max_fec_frames
;
FecMaskType
fec_mask_type
;
}
;
class
CallStatsObserver
{
public
:
virtual
void
OnRttUpdate
(
int64_t
rtt_ms
)
=
0
;
virtual
~
CallStatsObserver
(
)
{
}
}
;
class
EncodedVideoData
{
public
:
EncodedVideoData
(
)
:
payloadType
(
0
)
timeStamp
(
0
)
renderTimeMs
(
0
)
encodedWidth
(
0
)
encodedHeight
(
0
)
completeFrame
(
false
)
missingFrame
(
false
)
payloadData
(
NULL
)
payloadSize
(
0
)
bufferSize
(
0
)
fragmentationHeader
(
)
frameType
(
kVideoFrameDelta
)
codec
(
kVideoCodecUnknown
)
{
}
;
EncodedVideoData
(
const
EncodedVideoData
&
data
)
{
payloadType
=
data
.
payloadType
;
timeStamp
=
data
.
timeStamp
;
renderTimeMs
=
data
.
renderTimeMs
;
encodedWidth
=
data
.
encodedWidth
;
encodedHeight
=
data
.
encodedHeight
;
completeFrame
=
data
.
completeFrame
;
missingFrame
=
data
.
missingFrame
;
payloadSize
=
data
.
payloadSize
;
fragmentationHeader
.
CopyFrom
(
data
.
fragmentationHeader
)
;
frameType
=
data
.
frameType
;
codec
=
data
.
codec
;
if
(
data
.
payloadSize
>
0
)
{
payloadData
=
new
uint8_t
[
data
.
payloadSize
]
;
memcpy
(
payloadData
data
.
payloadData
data
.
payloadSize
)
;
bufferSize
=
data
.
payloadSize
;
}
else
{
payloadData
=
NULL
;
}
}
~
EncodedVideoData
(
)
{
delete
[
]
payloadData
;
}
;
EncodedVideoData
&
operator
=
(
const
EncodedVideoData
&
data
)
{
if
(
this
=
=
&
data
)
{
return
*
this
;
}
payloadType
=
data
.
payloadType
;
timeStamp
=
data
.
timeStamp
;
renderTimeMs
=
data
.
renderTimeMs
;
encodedWidth
=
data
.
encodedWidth
;
encodedHeight
=
data
.
encodedHeight
;
completeFrame
=
data
.
completeFrame
;
missingFrame
=
data
.
missingFrame
;
payloadSize
=
data
.
payloadSize
;
fragmentationHeader
.
CopyFrom
(
data
.
fragmentationHeader
)
;
frameType
=
data
.
frameType
;
codec
=
data
.
codec
;
if
(
data
.
payloadSize
>
0
)
{
delete
[
]
payloadData
;
payloadData
=
new
uint8_t
[
data
.
payloadSize
]
;
memcpy
(
payloadData
data
.
payloadData
data
.
payloadSize
)
;
bufferSize
=
data
.
payloadSize
;
}
return
*
this
;
}
;
void
VerifyAndAllocate
(
const
size_t
size
)
{
if
(
bufferSize
<
size
)
{
uint8_t
*
oldPayload
=
payloadData
;
payloadData
=
new
uint8_t
[
size
]
;
memcpy
(
payloadData
oldPayload
sizeof
(
uint8_t
)
*
payloadSize
)
;
bufferSize
=
size
;
delete
[
]
oldPayload
;
}
}
uint8_t
payloadType
;
uint32_t
timeStamp
;
int64_t
renderTimeMs
;
uint32_t
encodedWidth
;
uint32_t
encodedHeight
;
bool
completeFrame
;
bool
missingFrame
;
uint8_t
*
payloadData
;
size_t
payloadSize
;
size_t
bufferSize
;
RTPFragmentationHeader
fragmentationHeader
;
FrameType
frameType
;
VideoCodecType
codec
;
}
;
struct
VideoContentMetrics
{
VideoContentMetrics
(
)
:
motion_magnitude
(
0
.
0f
)
spatial_pred_err
(
0
.
0f
)
spatial_pred_err_h
(
0
.
0f
)
spatial_pred_err_v
(
0
.
0f
)
{
}
void
Reset
(
)
{
motion_magnitude
=
0
.
0f
;
spatial_pred_err
=
0
.
0f
;
spatial_pred_err_h
=
0
.
0f
;
spatial_pred_err_v
=
0
.
0f
;
}
float
motion_magnitude
;
float
spatial_pred_err
;
float
spatial_pred_err_h
;
float
spatial_pred_err_v
;
}
;
class
AudioFrame
{
public
:
static
const
int
kMaxDataSizeSamples
=
3840
;
enum
VADActivity
{
kVadActive
=
0
kVadPassive
=
1
kVadUnknown
=
2
}
;
enum
SpeechType
{
kNormalSpeech
=
0
kPLC
=
1
kCNG
=
2
kPLCCNG
=
3
kUndefined
=
4
}
;
AudioFrame
(
)
;
virtual
~
AudioFrame
(
)
{
}
void
Reset
(
)
;
void
UpdateFrame
(
int
id
uint32_t
timestamp
const
int16_t
*
data
int
samples_per_channel
int
sample_rate_hz
SpeechType
speech_type
VADActivity
vad_activity
int
num_channels
=
1
uint32_t
energy
=
-
1
)
;
AudioFrame
&
Append
(
const
AudioFrame
&
rhs
)
;
void
CopyFrom
(
const
AudioFrame
&
src
)
;
void
Mute
(
)
;
AudioFrame
&
operator
>
>
=
(
const
int
rhs
)
;
AudioFrame
&
operator
+
=
(
const
AudioFrame
&
rhs
)
;
AudioFrame
&
operator
-
=
(
const
AudioFrame
&
rhs
)
;
int
id_
;
uint32_t
timestamp_
;
int64_t
elapsed_time_ms_
;
int64_t
ntp_time_ms_
;
int16_t
data_
[
kMaxDataSizeSamples
]
;
int
samples_per_channel_
;
int
sample_rate_hz_
;
int
num_channels_
;
SpeechType
speech_type_
;
VADActivity
vad_activity_
;
uint32_t
energy_
;
bool
interleaved_
;
private
:
DISALLOW_COPY_AND_ASSIGN
(
AudioFrame
)
;
}
;
inline
AudioFrame
:
:
AudioFrame
(
)
:
data_
(
)
{
Reset
(
)
;
}
inline
void
AudioFrame
:
:
Reset
(
)
{
id_
=
-
1
;
timestamp_
=
0
;
elapsed_time_ms_
=
-
1
;
ntp_time_ms_
=
-
1
;
samples_per_channel_
=
0
;
sample_rate_hz_
=
0
;
num_channels_
=
0
;
speech_type_
=
kUndefined
;
vad_activity_
=
kVadUnknown
;
energy_
=
0xffffffff
;
interleaved_
=
true
;
}
inline
void
AudioFrame
:
:
UpdateFrame
(
int
id
uint32_t
timestamp
const
int16_t
*
data
int
samples_per_channel
int
sample_rate_hz
SpeechType
speech_type
VADActivity
vad_activity
int
num_channels
uint32_t
energy
)
{
id_
=
id
;
timestamp_
=
timestamp
;
samples_per_channel_
=
samples_per_channel
;
sample_rate_hz_
=
sample_rate_hz
;
speech_type_
=
speech_type
;
vad_activity_
=
vad_activity
;
num_channels_
=
num_channels
;
energy_
=
energy
;
const
int
length
=
samples_per_channel
*
num_channels
;
assert
(
length
<
=
kMaxDataSizeSamples
&
&
length
>
=
0
)
;
if
(
data
!
=
NULL
)
{
memcpy
(
data_
data
sizeof
(
int16_t
)
*
length
)
;
}
else
{
memset
(
data_
0
sizeof
(
int16_t
)
*
length
)
;
}
}
inline
void
AudioFrame
:
:
CopyFrom
(
const
AudioFrame
&
src
)
{
if
(
this
=
=
&
src
)
return
;
id_
=
src
.
id_
;
timestamp_
=
src
.
timestamp_
;
elapsed_time_ms_
=
src
.
elapsed_time_ms_
;
ntp_time_ms_
=
src
.
ntp_time_ms_
;
samples_per_channel_
=
src
.
samples_per_channel_
;
sample_rate_hz_
=
src
.
sample_rate_hz_
;
speech_type_
=
src
.
speech_type_
;
vad_activity_
=
src
.
vad_activity_
;
num_channels_
=
src
.
num_channels_
;
energy_
=
src
.
energy_
;
interleaved_
=
src
.
interleaved_
;
const
int
length
=
samples_per_channel_
*
num_channels_
;
assert
(
length
<
=
kMaxDataSizeSamples
&
&
length
>
=
0
)
;
memcpy
(
data_
src
.
data_
sizeof
(
int16_t
)
*
length
)
;
}
inline
void
AudioFrame
:
:
Mute
(
)
{
memset
(
data_
0
samples_per_channel_
*
num_channels_
*
sizeof
(
int16_t
)
)
;
}
inline
AudioFrame
&
AudioFrame
:
:
operator
>
>
=
(
const
int
rhs
)
{
assert
(
(
num_channels_
>
0
)
&
&
(
num_channels_
<
3
)
)
;
if
(
(
num_channels_
>
2
)
|
|
(
num_channels_
<
1
)
)
return
*
this
;
for
(
int
i
=
0
;
i
<
samples_per_channel_
*
num_channels_
;
i
+
+
)
{
data_
[
i
]
=
static_cast
<
int16_t
>
(
data_
[
i
]
>
>
rhs
)
;
}
return
*
this
;
}
inline
AudioFrame
&
AudioFrame
:
:
Append
(
const
AudioFrame
&
rhs
)
{
assert
(
(
num_channels_
>
0
)
&
&
(
num_channels_
<
3
)
)
;
assert
(
interleaved_
=
=
rhs
.
interleaved_
)
;
if
(
(
num_channels_
>
2
)
|
|
(
num_channels_
<
1
)
)
return
*
this
;
if
(
num_channels_
!
=
rhs
.
num_channels_
)
return
*
this
;
if
(
(
vad_activity_
=
=
kVadActive
)
|
|
rhs
.
vad_activity_
=
=
kVadActive
)
{
vad_activity_
=
kVadActive
;
}
else
if
(
vad_activity_
=
=
kVadUnknown
|
|
rhs
.
vad_activity_
=
=
kVadUnknown
)
{
vad_activity_
=
kVadUnknown
;
}
if
(
speech_type_
!
=
rhs
.
speech_type_
)
{
speech_type_
=
kUndefined
;
}
int
offset
=
samples_per_channel_
*
num_channels_
;
for
(
int
i
=
0
;
i
<
rhs
.
samples_per_channel_
*
rhs
.
num_channels_
;
i
+
+
)
{
data_
[
offset
+
i
]
=
rhs
.
data_
[
i
]
;
}
samples_per_channel_
+
=
rhs
.
samples_per_channel_
;
return
*
this
;
}
namespace
{
inline
int16_t
ClampToInt16
(
int32_t
input
)
{
if
(
input
<
-
0x00008000
)
{
return
-
0x8000
;
}
else
if
(
input
>
0x00007FFF
)
{
return
0x7FFF
;
}
else
{
return
static_cast
<
int16_t
>
(
input
)
;
}
}
}
inline
AudioFrame
&
AudioFrame
:
:
operator
+
=
(
const
AudioFrame
&
rhs
)
{
assert
(
(
num_channels_
>
0
)
&
&
(
num_channels_
<
3
)
)
;
assert
(
interleaved_
=
=
rhs
.
interleaved_
)
;
if
(
(
num_channels_
>
2
)
|
|
(
num_channels_
<
1
)
)
return
*
this
;
if
(
num_channels_
!
=
rhs
.
num_channels_
)
return
*
this
;
bool
noPrevData
=
false
;
if
(
samples_per_channel_
!
=
rhs
.
samples_per_channel_
)
{
if
(
samples_per_channel_
=
=
0
)
{
samples_per_channel_
=
rhs
.
samples_per_channel_
;
noPrevData
=
true
;
}
else
{
return
*
this
;
}
}
if
(
(
vad_activity_
=
=
kVadActive
)
|
|
rhs
.
vad_activity_
=
=
kVadActive
)
{
vad_activity_
=
kVadActive
;
}
else
if
(
vad_activity_
=
=
kVadUnknown
|
|
rhs
.
vad_activity_
=
=
kVadUnknown
)
{
vad_activity_
=
kVadUnknown
;
}
if
(
speech_type_
!
=
rhs
.
speech_type_
)
speech_type_
=
kUndefined
;
if
(
noPrevData
)
{
memcpy
(
data_
rhs
.
data_
sizeof
(
int16_t
)
*
rhs
.
samples_per_channel_
*
num_channels_
)
;
}
else
{
for
(
int
i
=
0
;
i
<
samples_per_channel_
*
num_channels_
;
i
+
+
)
{
int32_t
wrap_guard
=
static_cast
<
int32_t
>
(
data_
[
i
]
)
+
static_cast
<
int32_t
>
(
rhs
.
data_
[
i
]
)
;
data_
[
i
]
=
ClampToInt16
(
wrap_guard
)
;
}
}
energy_
=
0xffffffff
;
return
*
this
;
}
inline
AudioFrame
&
AudioFrame
:
:
operator
-
=
(
const
AudioFrame
&
rhs
)
{
assert
(
(
num_channels_
>
0
)
&
&
(
num_channels_
<
3
)
)
;
assert
(
interleaved_
=
=
rhs
.
interleaved_
)
;
if
(
(
num_channels_
>
2
)
|
|
(
num_channels_
<
1
)
)
return
*
this
;
if
(
(
samples_per_channel_
!
=
rhs
.
samples_per_channel_
)
|
|
(
num_channels_
!
=
rhs
.
num_channels_
)
)
{
return
*
this
;
}
if
(
(
vad_activity_
!
=
kVadPassive
)
|
|
rhs
.
vad_activity_
!
=
kVadPassive
)
{
vad_activity_
=
kVadUnknown
;
}
speech_type_
=
kUndefined
;
for
(
int
i
=
0
;
i
<
samples_per_channel_
*
num_channels_
;
i
+
+
)
{
int32_t
wrap_guard
=
static_cast
<
int32_t
>
(
data_
[
i
]
)
-
static_cast
<
int32_t
>
(
rhs
.
data_
[
i
]
)
;
data_
[
i
]
=
ClampToInt16
(
wrap_guard
)
;
}
energy_
=
0xffffffff
;
return
*
this
;
}
inline
bool
IsNewerSequenceNumber
(
uint16_t
sequence_number
uint16_t
prev_sequence_number
)
{
if
(
static_cast
<
uint16_t
>
(
sequence_number
-
prev_sequence_number
)
=
=
0x8000
)
{
return
sequence_number
>
prev_sequence_number
;
}
return
sequence_number
!
=
prev_sequence_number
&
&
static_cast
<
uint16_t
>
(
sequence_number
-
prev_sequence_number
)
<
0x8000
;
}
inline
bool
IsNewerTimestamp
(
uint32_t
timestamp
uint32_t
prev_timestamp
)
{
if
(
static_cast
<
uint32_t
>
(
timestamp
-
prev_timestamp
)
=
=
0x80000000
)
{
return
timestamp
>
prev_timestamp
;
}
return
timestamp
!
=
prev_timestamp
&
&
static_cast
<
uint32_t
>
(
timestamp
-
prev_timestamp
)
<
0x80000000
;
}
inline
bool
IsNewerOrSameTimestamp
(
uint32_t
timestamp
uint32_t
prev_timestamp
)
{
return
timestamp
=
=
prev_timestamp
|
|
static_cast
<
uint32_t
>
(
timestamp
-
prev_timestamp
)
<
0x80000000
;
}
inline
uint16_t
LatestSequenceNumber
(
uint16_t
sequence_number1
uint16_t
sequence_number2
)
{
return
IsNewerSequenceNumber
(
sequence_number1
sequence_number2
)
?
sequence_number1
:
sequence_number2
;
}
inline
uint32_t
LatestTimestamp
(
uint32_t
timestamp1
uint32_t
timestamp2
)
{
return
IsNewerTimestamp
(
timestamp1
timestamp2
)
?
timestamp1
:
timestamp2
;
}
class
SequenceNumberUnwrapper
{
public
:
SequenceNumberUnwrapper
(
)
:
last_seq_
(
-
1
)
{
}
int64_t
UnwrapWithoutUpdate
(
uint16_t
sequence_number
)
{
if
(
last_seq_
=
=
-
1
)
return
sequence_number
;
uint16_t
cropped_last
=
static_cast
<
uint16_t
>
(
last_seq_
)
;
int64_t
delta
=
sequence_number
-
cropped_last
;
if
(
IsNewerSequenceNumber
(
sequence_number
cropped_last
)
)
{
if
(
delta
<
0
)
delta
+
=
(
1
<
<
16
)
;
}
else
if
(
delta
>
0
&
&
(
last_seq_
+
delta
-
(
1
<
<
16
)
)
>
=
0
)
{
delta
-
=
(
1
<
<
16
)
;
}
return
last_seq_
+
delta
;
}
void
UpdateLast
(
int64_t
last_sequence
)
{
last_seq_
=
last_sequence
;
}
int64_t
Unwrap
(
uint16_t
sequence_number
)
{
int64_t
unwrapped
=
UnwrapWithoutUpdate
(
sequence_number
)
;
UpdateLast
(
unwrapped
)
;
return
unwrapped
;
}
private
:
int64_t
last_seq_
;
}
;
}
#
endif
