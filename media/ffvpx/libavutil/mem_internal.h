#
ifndef
AVUTIL_MEM_INTERNAL_H
#
define
AVUTIL_MEM_INTERNAL_H
#
include
"
config
.
h
"
#
include
<
stdint
.
h
>
#
include
"
avassert
.
h
"
#
include
"
mem
.
h
"
#
include
"
version
.
h
"
#
if
!
FF_API_DECLARE_ALIGNED
#
if
defined
(
__INTEL_COMPILER
)
&
&
__INTEL_COMPILER
<
1110
|
|
defined
(
__SUNPRO_C
)
#
define
DECLARE_ALIGNED
(
n
t
v
)
t
__attribute__
(
(
aligned
(
n
)
)
)
v
#
define
DECLARE_ASM_ALIGNED
(
n
t
v
)
t
__attribute__
(
(
aligned
(
n
)
)
)
v
#
define
DECLARE_ASM_CONST
(
n
t
v
)
const
t
__attribute__
(
(
aligned
(
n
)
)
)
v
#
elif
defined
(
__DJGPP__
)
#
define
DECLARE_ALIGNED
(
n
t
v
)
t
__attribute__
(
(
aligned
(
FFMIN
(
n
16
)
)
)
)
v
#
define
DECLARE_ASM_ALIGNED
(
n
t
v
)
t
av_used
__attribute__
(
(
aligned
(
FFMIN
(
n
16
)
)
)
)
v
#
define
DECLARE_ASM_CONST
(
n
t
v
)
static
const
t
av_used
__attribute__
(
(
aligned
(
FFMIN
(
n
16
)
)
)
)
v
#
elif
defined
(
__GNUC__
)
|
|
defined
(
__clang__
)
#
define
DECLARE_ALIGNED
(
n
t
v
)
t
__attribute__
(
(
aligned
(
n
)
)
)
v
#
define
DECLARE_ASM_ALIGNED
(
n
t
v
)
t
av_used
__attribute__
(
(
aligned
(
n
)
)
)
v
#
define
DECLARE_ASM_CONST
(
n
t
v
)
static
const
t
av_used
__attribute__
(
(
aligned
(
n
)
)
)
v
#
elif
defined
(
_MSC_VER
)
#
define
DECLARE_ALIGNED
(
n
t
v
)
__declspec
(
align
(
n
)
)
t
v
#
define
DECLARE_ASM_ALIGNED
(
n
t
v
)
__declspec
(
align
(
n
)
)
t
v
#
define
DECLARE_ASM_CONST
(
n
t
v
)
__declspec
(
align
(
n
)
)
static
const
t
v
#
else
#
define
DECLARE_ALIGNED
(
n
t
v
)
t
v
#
define
DECLARE_ASM_ALIGNED
(
n
t
v
)
t
v
#
define
DECLARE_ASM_CONST
(
n
t
v
)
static
const
t
v
#
endif
#
endif
#
define
E1
(
x
)
x
#
define
LOCAL_ALIGNED_A
(
a
t
v
s
o
.
.
.
)
\
uint8_t
la_
#
#
v
[
sizeof
(
t
s
o
)
+
(
a
)
]
;
\
t
(
*
v
)
o
=
(
void
*
)
FFALIGN
(
(
uintptr_t
)
la_
#
#
v
a
)
#
define
LOCAL_ALIGNED_D
(
a
t
v
s
o
.
.
.
)
\
DECLARE_ALIGNED
(
a
t
la_
#
#
v
)
s
o
;
\
t
(
*
v
)
o
=
la_
#
#
v
#
define
LOCAL_ALIGNED
(
a
t
v
.
.
.
)
LOCAL_ALIGNED_
#
#
a
(
t
v
__VA_ARGS__
)
#
if
HAVE_LOCAL_ALIGNED
#
define
LOCAL_ALIGNED_4
(
t
v
.
.
.
)
E1
(
LOCAL_ALIGNED_D
(
4
t
v
__VA_ARGS__
)
)
#
else
#
define
LOCAL_ALIGNED_4
(
t
v
.
.
.
)
E1
(
LOCAL_ALIGNED_A
(
4
t
v
__VA_ARGS__
)
)
#
endif
#
if
HAVE_LOCAL_ALIGNED
#
define
LOCAL_ALIGNED_8
(
t
v
.
.
.
)
E1
(
LOCAL_ALIGNED_D
(
8
t
v
__VA_ARGS__
)
)
#
else
#
define
LOCAL_ALIGNED_8
(
t
v
.
.
.
)
E1
(
LOCAL_ALIGNED_A
(
8
t
v
__VA_ARGS__
)
)
#
endif
#
if
HAVE_LOCAL_ALIGNED
#
define
LOCAL_ALIGNED_16
(
t
v
.
.
.
)
E1
(
LOCAL_ALIGNED_D
(
16
t
v
__VA_ARGS__
)
)
#
else
#
define
LOCAL_ALIGNED_16
(
t
v
.
.
.
)
E1
(
LOCAL_ALIGNED_A
(
16
t
v
__VA_ARGS__
)
)
#
endif
#
if
HAVE_LOCAL_ALIGNED
#
define
LOCAL_ALIGNED_32
(
t
v
.
.
.
)
E1
(
LOCAL_ALIGNED_D
(
32
t
v
__VA_ARGS__
)
)
#
else
#
define
LOCAL_ALIGNED_32
(
t
v
.
.
.
)
E1
(
LOCAL_ALIGNED_A
(
32
t
v
__VA_ARGS__
)
)
#
endif
#
endif
