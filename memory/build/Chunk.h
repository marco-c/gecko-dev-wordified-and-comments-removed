#
ifndef
CHUNK_H
#
define
CHUNK_H
#
include
"
mozilla
/
Atomics
.
h
"
#
include
"
RadixTree
.
h
"
#
include
"
RedBlackTree
.
h
"
#
include
"
mozilla
/
DoublyLinkedList
.
h
"
struct
arena_t
;
enum
ChunkType
{
UNKNOWN_CHUNK
ZEROED_CHUNK
ARENA_CHUNK
HUGE_CHUNK
RECYCLED_CHUNK
}
;
struct
arena_chunk_map_t
{
RedBlackTreeNode
<
arena_chunk_map_t
>
link
;
size_t
bits
;
#
define
CHUNK_MAP_BUSY
(
(
size_t
)
0x100U
)
#
define
CHUNK_MAP_FRESH
(
(
size_t
)
0x80U
)
#
define
CHUNK_MAP_MADVISED
(
(
size_t
)
0x40U
)
#
define
CHUNK_MAP_DECOMMITTED
(
(
size_t
)
0x20U
)
#
define
CHUNK_MAP_MADVISED_OR_DECOMMITTED
\
(
CHUNK_MAP_MADVISED
|
CHUNK_MAP_DECOMMITTED
)
#
define
CHUNK_MAP_FRESH_MADVISED_OR_DECOMMITTED
\
(
CHUNK_MAP_FRESH
|
CHUNK_MAP_MADVISED
|
CHUNK_MAP_DECOMMITTED
)
#
define
CHUNK_MAP_FRESH_MADVISED_DECOMMITTED_OR_BUSY
\
(
CHUNK_MAP_FRESH
|
CHUNK_MAP_MADVISED
|
CHUNK_MAP_DECOMMITTED
|
\
CHUNK_MAP_BUSY
)
#
define
CHUNK_MAP_KEY
(
(
size_t
)
0x10U
)
#
define
CHUNK_MAP_DIRTY
(
(
size_t
)
0x08U
)
#
define
CHUNK_MAP_ZEROED
(
(
size_t
)
0x04U
)
#
define
CHUNK_MAP_LARGE
(
(
size_t
)
0x02U
)
#
define
CHUNK_MAP_ALLOCATED
(
(
size_t
)
0x01U
)
}
;
struct
arena_chunk_t
{
arena_t
*
mArena
;
mozilla
:
:
DoublyLinkedListElement
<
arena_chunk_t
>
mChunksDirtyElim
;
#
ifdef
MALLOC_DOUBLE_PURGE
mozilla
:
:
DoublyLinkedListElement
<
arena_chunk_t
>
mChunksMavisedElim
;
#
endif
uint16_t
mNumDirty
=
0
;
uint16_t
mDirtyRunHint
;
bool
mIsPurging
=
false
;
bool
mDying
=
false
;
arena_chunk_map_t
mPageMap
[
]
;
explicit
arena_chunk_t
(
arena_t
*
aArena
)
;
bool
IsEmpty
(
)
;
}
;
[
[
nodiscard
]
]
bool
pages_commit
(
void
*
aAddr
size_t
aSize
)
;
void
pages_decommit
(
void
*
aAddr
size_t
aSize
)
;
void
chunks_init
(
)
;
void
*
chunk_alloc
(
size_t
aSize
size_t
aAlignment
bool
aBase
)
;
void
chunk_dealloc
(
void
*
aChunk
size_t
aSize
ChunkType
aType
)
;
#
ifdef
MOZ_DEBUG
void
chunk_assert_zero
(
void
*
aPtr
size_t
aSize
)
;
#
endif
extern
mozilla
:
:
Atomic
<
size_t
>
gRecycledSize
;
extern
AddressRadixTree
<
(
sizeof
(
void
*
)
<
<
3
)
-
LOG2
(
kChunkSize
)
>
gChunkRTree
;
enum
ShouldCommit
{
ReserveOnly
ReserveAndCommit
}
;
void
*
pages_mmap_aligned
(
size_t
size
size_t
alignment
ShouldCommit
should_commit
)
;
#
endif
