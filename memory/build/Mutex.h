#
ifndef
Mutex_h
#
define
Mutex_h
#
if
defined
(
XP_WIN
)
#
include
<
windows
.
h
>
#
elif
defined
(
XP_DARWIN
)
#
include
<
libkern
/
OSAtomic
.
h
>
#
include
<
os
/
lock
.
h
>
#
else
#
include
<
pthread
.
h
>
#
endif
#
include
"
mozilla
/
Attributes
.
h
"
#
include
"
mozilla
/
ThreadSafety
.
h
"
#
if
defined
(
XP_DARWIN
)
#
define
OS_UNFAIR_LOCK_DATA_SYNCHRONIZATION
(
0x00010000
)
#
define
OS_UNFAIR_LOCK_ADAPTIVE_SPIN
(
0x00040000
)
extern
"
C
"
{
typedef
uint32_t
os_unfair_lock_options_t
;
OS_UNFAIR_LOCK_AVAILABILITY
OS_EXPORT
OS_NOTHROW
OS_NONNULL_ALL
void
os_unfair_lock_lock_with_options
(
os_unfair_lock_t
lock
os_unfair_lock_options_t
options
)
;
}
static_assert
(
OS_UNFAIR_LOCK_INIT
.
_os_unfair_lock_opaque
=
=
OS_SPINLOCK_INIT
"
OS_UNFAIR_LOCK_INIT
and
OS_SPINLOCK_INIT
have
the
same
"
"
value
"
)
;
static_assert
(
sizeof
(
os_unfair_lock
)
=
=
sizeof
(
OSSpinLock
)
"
os_unfair_lock
and
OSSpinLock
are
the
same
size
"
)
;
#
endif
struct
CAPABILITY
Mutex
{
#
if
defined
(
XP_WIN
)
CRITICAL_SECTION
mMutex
;
#
elif
defined
(
XP_DARWIN
)
union
{
os_unfair_lock
mUnfairLock
;
OSSpinLock
mSpinLock
;
}
mMutex
;
#
else
pthread_mutex_t
mMutex
;
#
endif
inline
bool
Init
(
)
{
#
if
defined
(
XP_WIN
)
if
(
!
InitializeCriticalSectionAndSpinCount
(
&
mMutex
5000
)
)
{
return
false
;
}
#
elif
defined
(
XP_DARWIN
)
mMutex
.
mUnfairLock
=
OS_UNFAIR_LOCK_INIT
;
#
elif
defined
(
XP_LINUX
)
&
&
!
defined
(
ANDROID
)
pthread_mutexattr_t
attr
;
if
(
pthread_mutexattr_init
(
&
attr
)
!
=
0
)
{
return
false
;
}
pthread_mutexattr_settype
(
&
attr
PTHREAD_MUTEX_ADAPTIVE_NP
)
;
if
(
pthread_mutex_init
(
&
mMutex
&
attr
)
!
=
0
)
{
pthread_mutexattr_destroy
(
&
attr
)
;
return
false
;
}
pthread_mutexattr_destroy
(
&
attr
)
;
#
else
if
(
pthread_mutex_init
(
&
mMutex
nullptr
)
!
=
0
)
{
return
false
;
}
#
endif
return
true
;
}
inline
void
Lock
(
)
CAPABILITY_ACQUIRE
(
)
{
#
if
defined
(
XP_WIN
)
EnterCriticalSection
(
&
mMutex
)
;
#
elif
defined
(
XP_DARWIN
)
if
(
Mutex
:
:
gFallbackToOSSpinLock
)
{
OSSpinLockLock
(
&
mMutex
.
mSpinLock
)
;
}
else
{
os_unfair_lock_lock_with_options
(
&
mMutex
.
mUnfairLock
OS_UNFAIR_LOCK_DATA_SYNCHRONIZATION
|
OS_UNFAIR_LOCK_ADAPTIVE_SPIN
)
;
}
#
else
pthread_mutex_lock
(
&
mMutex
)
;
#
endif
}
inline
void
Unlock
(
)
CAPABILITY_RELEASE
(
)
{
#
if
defined
(
XP_WIN
)
LeaveCriticalSection
(
&
mMutex
)
;
#
elif
defined
(
XP_DARWIN
)
if
(
Mutex
:
:
gFallbackToOSSpinLock
)
{
OSSpinLockUnlock
(
&
mMutex
.
mSpinLock
)
;
}
else
{
os_unfair_lock_unlock
(
&
mMutex
.
mUnfairLock
)
;
}
#
else
pthread_mutex_unlock
(
&
mMutex
)
;
#
endif
}
#
if
defined
(
XP_DARWIN
)
static
bool
UseUnfairLocks
(
)
;
static
bool
gFallbackToOSSpinLock
;
#
endif
}
;
#
if
defined
(
XP_WIN
)
struct
CAPABILITY
StaticMutex
{
SRWLOCK
mMutex
;
inline
void
Lock
(
)
CAPABILITY_ACQUIRE
(
)
{
AcquireSRWLockExclusive
(
&
mMutex
)
;
}
inline
void
Unlock
(
)
CAPABILITY_RELEASE
(
)
{
ReleaseSRWLockExclusive
(
&
mMutex
)
;
}
}
;
#
define
STATIC_MUTEX_INIT
SRWLOCK_INIT
#
else
typedef
Mutex
StaticMutex
;
#
if
defined
(
XP_DARWIN
)
#
define
STATIC_MUTEX_INIT
\
{
.
mUnfairLock
=
OS_UNFAIR_LOCK_INIT
}
#
elif
defined
(
XP_LINUX
)
&
&
!
defined
(
ANDROID
)
#
define
STATIC_MUTEX_INIT
PTHREAD_ADAPTIVE_MUTEX_INITIALIZER_NP
#
else
#
define
STATIC_MUTEX_INIT
PTHREAD_MUTEX_INITIALIZER
#
endif
#
endif
template
<
typename
T
>
struct
SCOPED_CAPABILITY
MOZ_RAII
AutoLock
{
explicit
AutoLock
(
T
&
aMutex
)
CAPABILITY_ACQUIRE
(
aMutex
)
:
mMutex
(
aMutex
)
{
mMutex
.
Lock
(
)
;
}
~
AutoLock
(
)
CAPABILITY_RELEASE
(
)
{
mMutex
.
Unlock
(
)
;
}
AutoLock
(
const
AutoLock
&
)
=
delete
;
AutoLock
(
AutoLock
&
&
)
=
delete
;
private
:
T
&
mMutex
;
}
;
using
MutexAutoLock
=
AutoLock
<
Mutex
>
;
#
endif
