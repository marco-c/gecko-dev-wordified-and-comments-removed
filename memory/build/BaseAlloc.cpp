#
include
"
BaseAlloc
.
h
"
#
include
<
cstring
>
#
include
"
Globals
.
h
"
using
namespace
mozilla
;
constinit
BaseAlloc
sBaseAlloc
;
void
BaseAlloc
:
:
Init
(
)
MOZ_REQUIRES
(
gInitLock
)
{
mMutex
.
Init
(
)
;
}
bool
BaseAlloc
:
:
pages_alloc
(
size_t
minsize
)
MOZ_REQUIRES
(
mMutex
)
{
MOZ_ASSERT
(
minsize
!
=
0
)
;
size_t
csize
=
CHUNK_CEILING
(
minsize
)
;
uintptr_t
base_pages
=
reinterpret_cast
<
uintptr_t
>
(
chunk_alloc
(
csize
kChunkSize
true
)
)
;
if
(
base_pages
=
=
0
)
{
return
false
;
}
mNextAddr
=
reinterpret_cast
<
uintptr_t
>
(
base_pages
)
;
mPastAddr
=
base_pages
+
csize
;
size_t
pminsize
=
REAL_PAGE_CEILING
(
minsize
)
;
mNextDecommitted
=
base_pages
+
pminsize
;
if
(
pminsize
<
csize
)
{
pages_decommit
(
reinterpret_cast
<
void
*
>
(
mNextDecommitted
)
csize
-
pminsize
)
;
}
mStats
.
mMapped
+
=
csize
;
mStats
.
mCommitted
+
=
pminsize
;
return
true
;
}
void
*
BaseAlloc
:
:
alloc
(
size_t
aSize
)
{
size_t
csize
=
CACHELINE_CEILING
(
aSize
)
;
MutexAutoLock
lock
(
mMutex
)
;
if
(
mNextAddr
+
csize
>
mPastAddr
)
{
if
(
!
pages_alloc
(
csize
)
)
{
return
nullptr
;
}
}
void
*
ret
=
reinterpret_cast
<
void
*
>
(
mNextAddr
)
;
mNextAddr
=
mNextAddr
+
csize
;
if
(
mNextAddr
>
mNextDecommitted
)
{
uintptr_t
pbase_next_addr
=
REAL_PAGE_CEILING
(
mNextAddr
)
;
if
(
!
pages_commit
(
reinterpret_cast
<
void
*
>
(
mNextDecommitted
)
mNextAddr
-
mNextDecommitted
)
)
{
return
nullptr
;
}
mStats
.
mCommitted
+
=
pbase_next_addr
-
mNextDecommitted
;
mNextDecommitted
=
pbase_next_addr
;
}
return
ret
;
}
void
*
BaseAlloc
:
:
calloc
(
size_t
aNumber
size_t
aSize
)
{
void
*
ret
=
alloc
(
aNumber
*
aSize
)
;
if
(
ret
)
{
memset
(
ret
0
aNumber
*
aSize
)
;
}
return
ret
;
}
