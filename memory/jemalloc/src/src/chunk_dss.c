#
define
JEMALLOC_CHUNK_DSS_C_
#
include
"
jemalloc
/
internal
/
jemalloc_internal
.
h
"
const
char
*
dss_prec_names
[
]
=
{
"
disabled
"
"
primary
"
"
secondary
"
"
N
/
A
"
}
;
static
unsigned
dss_prec_default
=
(
unsigned
)
DSS_PREC_DEFAULT
;
static
void
*
dss_base
;
static
unsigned
dss_exhausted
;
static
void
*
dss_max
;
static
void
*
chunk_dss_sbrk
(
intptr_t
increment
)
{
#
ifdef
JEMALLOC_DSS
return
(
sbrk
(
increment
)
)
;
#
else
not_implemented
(
)
;
return
(
NULL
)
;
#
endif
}
dss_prec_t
chunk_dss_prec_get
(
void
)
{
dss_prec_t
ret
;
if
(
!
have_dss
)
return
(
dss_prec_disabled
)
;
ret
=
(
dss_prec_t
)
atomic_read_u
(
&
dss_prec_default
)
;
return
(
ret
)
;
}
bool
chunk_dss_prec_set
(
dss_prec_t
dss_prec
)
{
if
(
!
have_dss
)
return
(
dss_prec
!
=
dss_prec_disabled
)
;
atomic_write_u
(
&
dss_prec_default
(
unsigned
)
dss_prec
)
;
return
(
false
)
;
}
static
void
*
chunk_dss_max_update
(
void
*
new_addr
)
{
void
*
max_cur
;
spin_t
spinner
;
spin_init
(
&
spinner
)
;
while
(
true
)
{
void
*
max_prev
=
atomic_read_p
(
&
dss_max
)
;
max_cur
=
chunk_dss_sbrk
(
0
)
;
if
(
(
uintptr_t
)
max_prev
>
(
uintptr_t
)
max_cur
)
{
spin_adaptive
(
&
spinner
)
;
continue
;
}
if
(
!
atomic_cas_p
(
&
dss_max
max_prev
max_cur
)
)
break
;
}
if
(
new_addr
!
=
NULL
&
&
max_cur
!
=
new_addr
)
return
(
NULL
)
;
return
(
max_cur
)
;
}
void
*
chunk_alloc_dss
(
tsdn_t
*
tsdn
arena_t
*
arena
void
*
new_addr
size_t
size
size_t
alignment
bool
*
zero
bool
*
commit
)
{
cassert
(
have_dss
)
;
assert
(
size
>
0
&
&
(
size
&
chunksize_mask
)
=
=
0
)
;
assert
(
alignment
>
0
&
&
(
alignment
&
chunksize_mask
)
=
=
0
)
;
if
(
(
intptr_t
)
size
<
0
)
return
(
NULL
)
;
if
(
!
atomic_read_u
(
&
dss_exhausted
)
)
{
while
(
true
)
{
void
*
ret
*
cpad
*
max_cur
*
dss_next
*
dss_prev
;
size_t
gap_size
cpad_size
;
intptr_t
incr
;
max_cur
=
chunk_dss_max_update
(
new_addr
)
;
if
(
max_cur
=
=
NULL
)
goto
label_oom
;
gap_size
=
(
chunksize
-
CHUNK_ADDR2OFFSET
(
dss_max
)
)
&
chunksize_mask
;
cpad
=
(
void
*
)
(
(
uintptr_t
)
dss_max
+
gap_size
)
;
ret
=
(
void
*
)
ALIGNMENT_CEILING
(
(
uintptr_t
)
dss_max
alignment
)
;
cpad_size
=
(
uintptr_t
)
ret
-
(
uintptr_t
)
cpad
;
dss_next
=
(
void
*
)
(
(
uintptr_t
)
ret
+
size
)
;
if
(
(
uintptr_t
)
ret
<
(
uintptr_t
)
dss_max
|
|
(
uintptr_t
)
dss_next
<
(
uintptr_t
)
dss_max
)
goto
label_oom
;
incr
=
gap_size
+
cpad_size
+
size
;
if
(
atomic_cas_p
(
&
dss_max
max_cur
dss_next
)
)
continue
;
dss_prev
=
chunk_dss_sbrk
(
incr
)
;
if
(
dss_prev
=
=
max_cur
)
{
if
(
cpad_size
!
=
0
)
{
chunk_hooks_t
chunk_hooks
=
CHUNK_HOOKS_INITIALIZER
;
chunk_dalloc_wrapper
(
tsdn
arena
&
chunk_hooks
cpad
cpad_size
arena_extent_sn_next
(
arena
)
false
true
)
;
}
if
(
*
zero
)
{
JEMALLOC_VALGRIND_MAKE_MEM_UNDEFINED
(
ret
size
)
;
memset
(
ret
0
size
)
;
}
if
(
!
*
commit
)
*
commit
=
pages_decommit
(
ret
size
)
;
return
(
ret
)
;
}
atomic_cas_p
(
&
dss_max
dss_next
max_cur
)
;
if
(
dss_prev
=
=
(
void
*
)
-
1
)
{
atomic_write_u
(
&
dss_exhausted
(
unsigned
)
true
)
;
goto
label_oom
;
}
}
}
label_oom
:
return
(
NULL
)
;
}
static
bool
chunk_in_dss_helper
(
void
*
chunk
void
*
max
)
{
return
(
(
uintptr_t
)
chunk
>
=
(
uintptr_t
)
dss_base
&
&
(
uintptr_t
)
chunk
<
(
uintptr_t
)
max
)
;
}
bool
chunk_in_dss
(
void
*
chunk
)
{
cassert
(
have_dss
)
;
return
(
chunk_in_dss_helper
(
chunk
atomic_read_p
(
&
dss_max
)
)
)
;
}
bool
chunk_dss_mergeable
(
void
*
chunk_a
void
*
chunk_b
)
{
void
*
max
;
cassert
(
have_dss
)
;
max
=
atomic_read_p
(
&
dss_max
)
;
return
(
chunk_in_dss_helper
(
chunk_a
max
)
=
=
chunk_in_dss_helper
(
chunk_b
max
)
)
;
}
void
chunk_dss_boot
(
void
)
{
cassert
(
have_dss
)
;
dss_base
=
chunk_dss_sbrk
(
0
)
;
dss_exhausted
=
(
unsigned
)
(
dss_base
=
=
(
void
*
)
-
1
)
;
dss_max
=
dss_base
;
}
