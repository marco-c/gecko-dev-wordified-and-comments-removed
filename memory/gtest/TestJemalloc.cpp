#
include
"
mozilla
/
mozalloc
.
h
"
#
include
"
mozilla
/
UniquePtr
.
h
"
#
include
"
mozilla
/
Vector
.
h
"
#
include
"
mozmemory
.
h
"
#
include
"
nsCOMPtr
.
h
"
#
include
"
nsICrashReporter
.
h
"
#
include
"
nsServiceManagerUtils
.
h
"
#
include
"
Utils
.
h
"
#
include
"
gtest
/
gtest
.
h
"
#
if
defined
(
DEBUG
)
&
&
!
defined
(
XP_WIN
)
&
&
!
defined
(
ANDROID
)
#
define
HAS_GDB_SLEEP_DURATION
1
extern
unsigned
int
_gdb_sleep_duration
;
#
endif
#
ifndef
XP_DARWIN
static
void
DisableCrashReporter
(
)
{
nsCOMPtr
<
nsICrashReporter
>
crashreporter
=
do_GetService
(
"
mozilla
.
org
/
toolkit
/
crash
-
reporter
;
1
"
)
;
if
(
crashreporter
)
{
crashreporter
-
>
SetEnabled
(
false
)
;
}
}
#
define
ASSERT_DEATH_WRAP
(
a
b
)
\
ASSERT_DEATH_IF_SUPPORTED
(
{
DisableCrashReporter
(
)
;
a
;
}
b
)
#
else
#
define
ASSERT_DEATH_WRAP
(
a
b
)
#
endif
using
namespace
mozilla
;
static
inline
void
TestOne
(
size_t
size
)
{
size_t
req
=
size
;
size_t
adv
=
malloc_good_size
(
req
)
;
char
*
p
=
(
char
*
)
malloc
(
req
)
;
size_t
usable
=
moz_malloc_usable_size
(
p
)
;
EXPECT_EQ
(
adv
usable
)
<
<
"
malloc_good_size
(
"
<
<
req
<
<
"
)
-
-
>
"
<
<
adv
<
<
"
;
"
"
malloc_usable_size
(
"
<
<
req
<
<
"
)
-
-
>
"
<
<
usable
;
free
(
p
)
;
}
static
inline
void
TestThree
(
size_t
size
)
{
ASSERT_NO_FATAL_FAILURE
(
TestOne
(
size
-
1
)
)
;
ASSERT_NO_FATAL_FAILURE
(
TestOne
(
size
)
)
;
ASSERT_NO_FATAL_FAILURE
(
TestOne
(
size
+
1
)
)
;
}
TEST
(
Jemalloc
UsableSizeInAdvance
)
{
for
(
size_t
n
=
0
;
n
<
16_KiB
;
n
+
+
)
ASSERT_NO_FATAL_FAILURE
(
TestOne
(
n
)
)
;
for
(
size_t
n
=
16_KiB
;
n
<
1_MiB
;
n
+
=
4_KiB
)
ASSERT_NO_FATAL_FAILURE
(
TestThree
(
n
)
)
;
for
(
size_t
n
=
1_MiB
;
n
<
8_MiB
;
n
+
=
128_KiB
)
ASSERT_NO_FATAL_FAILURE
(
TestThree
(
n
)
)
;
}
static
int
gStaticVar
;
bool
InfoEq
(
jemalloc_ptr_info_t
&
aInfo
PtrInfoTag
aTag
void
*
aAddr
size_t
aSize
)
{
return
aInfo
.
tag
=
=
aTag
&
&
aInfo
.
addr
=
=
aAddr
&
&
aInfo
.
size
=
=
aSize
;
}
bool
InfoEqFreedPage
(
jemalloc_ptr_info_t
&
aInfo
void
*
aAddr
size_t
aPageSize
)
{
size_t
pageSizeMask
=
aPageSize
-
1
;
return
jemalloc_ptr_is_freed_page
(
&
aInfo
)
&
&
aInfo
.
addr
=
=
(
void
*
)
(
uintptr_t
(
aAddr
)
&
~
pageSizeMask
)
&
&
aInfo
.
size
=
=
aPageSize
;
}
TEST
(
Jemalloc
PtrInfo
)
{
jemalloc_thread_local_arena
(
true
)
;
jemalloc_stats_t
stats
;
jemalloc_stats
(
&
stats
)
;
jemalloc_ptr_info_t
info
;
Vector
<
char
*
>
small
large
huge
;
size_t
small_max
=
stats
.
page_size
/
2
;
for
(
size_t
n
=
0
;
n
<
=
small_max
;
n
+
=
8
)
{
auto
p
=
(
char
*
)
malloc
(
n
)
;
size_t
usable
=
moz_malloc_size_of
(
p
)
;
ASSERT_TRUE
(
small
.
append
(
p
)
)
;
for
(
size_t
j
=
0
;
j
<
usable
;
j
+
+
)
{
jemalloc_ptr_info
(
&
p
[
j
]
&
info
)
;
ASSERT_TRUE
(
InfoEq
(
info
TagLiveSmall
p
usable
)
)
;
}
}
for
(
size_t
n
=
small_max
+
1_KiB
;
n
<
=
stats
.
large_max
;
n
+
=
1_KiB
)
{
auto
p
=
(
char
*
)
malloc
(
n
)
;
size_t
usable
=
moz_malloc_size_of
(
p
)
;
ASSERT_TRUE
(
large
.
append
(
p
)
)
;
for
(
size_t
j
=
0
;
j
<
usable
;
j
+
=
347
)
{
jemalloc_ptr_info
(
&
p
[
j
]
&
info
)
;
ASSERT_TRUE
(
InfoEq
(
info
TagLiveLarge
p
usable
)
)
;
}
}
for
(
size_t
n
=
stats
.
chunksize
;
n
<
=
10_MiB
;
n
+
=
512_KiB
)
{
auto
p
=
(
char
*
)
malloc
(
n
)
;
size_t
usable
=
moz_malloc_size_of
(
p
)
;
ASSERT_TRUE
(
huge
.
append
(
p
)
)
;
for
(
size_t
j
=
0
;
j
<
usable
;
j
+
=
567
)
{
jemalloc_ptr_info
(
&
p
[
j
]
&
info
)
;
ASSERT_TRUE
(
InfoEq
(
info
TagLiveHuge
p
usable
)
)
;
}
}
size_t
len
;
int
isFreedSmall
=
0
isFreedPage
=
0
;
len
=
small
.
length
(
)
;
for
(
size_t
i
=
0
j
=
0
;
i
<
len
;
i
+
+
j
=
(
j
+
19
)
%
len
)
{
char
*
p
=
small
[
j
]
;
size_t
usable
=
moz_malloc_size_of
(
p
)
;
free
(
p
)
;
for
(
size_t
k
=
0
;
k
<
usable
;
k
+
+
)
{
jemalloc_ptr_info
(
&
p
[
k
]
&
info
)
;
if
(
InfoEq
(
info
TagFreedSmall
p
usable
)
)
{
isFreedSmall
+
+
;
}
else
if
(
InfoEqFreedPage
(
info
&
p
[
k
]
stats
.
page_size
)
)
{
isFreedPage
+
+
;
}
else
{
ASSERT_TRUE
(
false
)
;
}
}
}
ASSERT_TRUE
(
isFreedSmall
!
=
0
)
;
ASSERT_TRUE
(
isFreedPage
!
=
0
)
;
ASSERT_TRUE
(
isFreedSmall
/
isFreedPage
>
10
)
;
len
=
large
.
length
(
)
;
for
(
size_t
i
=
0
j
=
0
;
i
<
len
;
i
+
+
j
=
(
j
+
31
)
%
len
)
{
char
*
p
=
large
[
j
]
;
size_t
usable
=
moz_malloc_size_of
(
p
)
;
free
(
p
)
;
for
(
size_t
k
=
0
;
k
<
usable
;
k
+
=
357
)
{
jemalloc_ptr_info
(
&
p
[
k
]
&
info
)
;
ASSERT_TRUE
(
InfoEqFreedPage
(
info
&
p
[
k
]
stats
.
page_size
)
)
;
}
}
len
=
huge
.
length
(
)
;
for
(
size_t
i
=
0
j
=
0
;
i
<
len
;
i
+
+
j
=
(
j
+
7
)
%
len
)
{
char
*
p
=
huge
[
j
]
;
size_t
usable
=
moz_malloc_size_of
(
p
)
;
free
(
p
)
;
for
(
size_t
k
=
0
;
k
<
usable
;
k
+
=
587
)
{
jemalloc_ptr_info
(
&
p
[
k
]
&
info
)
;
ASSERT_TRUE
(
InfoEq
(
info
TagUnknown
nullptr
0U
)
)
;
}
}
jemalloc_ptr_info
(
nullptr
&
info
)
;
ASSERT_TRUE
(
InfoEq
(
info
TagUnknown
nullptr
0U
)
)
;
jemalloc_ptr_info
(
(
void
*
)
0x123
&
info
)
;
ASSERT_TRUE
(
InfoEq
(
info
TagUnknown
nullptr
0U
)
)
;
jemalloc_ptr_info
(
(
void
*
)
uintptr_t
(
-
1
)
&
info
)
;
ASSERT_TRUE
(
InfoEq
(
info
TagUnknown
nullptr
0U
)
)
;
int
stackVar
;
jemalloc_ptr_info
(
&
stackVar
&
info
)
;
ASSERT_TRUE
(
InfoEq
(
info
TagUnknown
nullptr
0U
)
)
;
jemalloc_ptr_info
(
(
const
void
*
)
&
jemalloc_ptr_info
&
info
)
;
ASSERT_TRUE
(
InfoEq
(
info
TagUnknown
nullptr
0U
)
)
;
jemalloc_ptr_info
(
&
gStaticVar
&
info
)
;
ASSERT_TRUE
(
InfoEq
(
info
TagUnknown
nullptr
0U
)
)
;
UniquePtr
<
int
>
p
=
MakeUnique
<
int
>
(
)
;
size_t
chunksizeMask
=
stats
.
chunksize
-
1
;
char
*
chunk
=
(
char
*
)
(
uintptr_t
(
p
.
get
(
)
)
&
~
chunksizeMask
)
;
size_t
chunkHeaderSize
=
stats
.
chunksize
-
stats
.
large_max
;
for
(
size_t
i
=
0
;
i
<
chunkHeaderSize
;
i
+
=
64
)
{
jemalloc_ptr_info
(
&
chunk
[
i
]
&
info
)
;
ASSERT_TRUE
(
InfoEq
(
info
TagUnknown
nullptr
0U
)
)
;
}
size_t
page_sizeMask
=
stats
.
page_size
-
1
;
char
*
run
=
(
char
*
)
(
uintptr_t
(
p
.
get
(
)
)
&
~
page_sizeMask
)
;
for
(
size_t
i
=
0
;
i
<
4
*
sizeof
(
void
*
)
;
i
+
+
)
{
jemalloc_ptr_info
(
&
run
[
i
]
&
info
)
;
ASSERT_TRUE
(
InfoEq
(
info
TagUnknown
nullptr
0U
)
)
;
}
for
(
size_t
i
=
0
;
i
<
stats
.
chunksize
;
i
+
=
256
)
{
jemalloc_ptr_info
(
&
chunk
[
i
]
&
info
)
;
}
jemalloc_thread_local_arena
(
false
)
;
}
size_t
sSizes
[
]
=
{
1
42
79
918
1
.
5_KiB
73_KiB
129_KiB
1
.
1_MiB
2
.
6_MiB
5
.
1_MiB
}
;
TEST
(
Jemalloc
Arenas
)
{
arena_id_t
arena
=
moz_create_arena
(
)
;
ASSERT_TRUE
(
arena
!
=
0
)
;
void
*
ptr
=
moz_arena_malloc
(
arena
42
)
;
ASSERT_TRUE
(
ptr
!
=
nullptr
)
;
ptr
=
moz_arena_realloc
(
arena
ptr
64
)
;
ASSERT_TRUE
(
ptr
!
=
nullptr
)
;
moz_arena_free
(
arena
ptr
)
;
ptr
=
moz_arena_calloc
(
arena
24
2
)
;
free
(
ptr
)
;
#
ifdef
HAS_GDB_SLEEP_DURATION
unsigned
int
old_gdb_sleep_duration
=
_gdb_sleep_duration
;
_gdb_sleep_duration
=
0
;
#
endif
ASSERT_DEATH_WRAP
(
moz_arena_malloc
(
0
80
)
"
"
)
;
arena
=
moz_create_arena
(
)
;
arena_id_t
arena2
=
moz_create_arena
(
)
;
(
void
)
arena2
;
for
(
size_t
from_size
:
sSizes
)
{
SCOPED_TRACE
(
testing
:
:
Message
(
)
<
<
"
from_size
=
"
<
<
from_size
)
;
for
(
size_t
to_size
:
sSizes
)
{
SCOPED_TRACE
(
testing
:
:
Message
(
)
<
<
"
to_size
=
"
<
<
to_size
)
;
ptr
=
moz_arena_malloc
(
arena
from_size
)
;
ptr
=
realloc
(
ptr
to_size
)
;
ASSERT_DEATH_WRAP
(
moz_arena_free
(
arena2
ptr
)
"
"
)
;
ASSERT_DEATH_WRAP
(
moz_arena_realloc
(
arena2
ptr
from_size
)
"
"
)
;
moz_arena_free
(
arena
ptr
)
;
}
}
#
ifdef
HAS_GDB_SLEEP_DURATION
_gdb_sleep_duration
=
old_gdb_sleep_duration
;
#
endif
}
static
void
bulk_compare
(
char
*
aPtr
size_t
aOffset
size_t
aSize
char
*
aReference
size_t
aReferenceSize
)
{
for
(
size_t
i
=
aOffset
;
i
<
aSize
;
i
+
=
aReferenceSize
)
{
size_t
length
=
std
:
:
min
(
aSize
-
i
aReferenceSize
)
;
if
(
memcmp
(
aPtr
+
i
aReference
length
)
)
{
for
(
size_t
j
=
i
;
j
<
i
+
length
;
j
+
+
)
{
ASSERT_EQ
(
aPtr
[
j
]
*
aReference
)
;
}
}
}
}
class
SizeClassesBetween
{
public
:
SizeClassesBetween
(
size_t
aStart
size_t
aEnd
)
:
mStart
(
aStart
)
mEnd
(
aEnd
)
{
}
class
Iterator
{
public
:
explicit
Iterator
(
size_t
aValue
)
:
mValue
(
malloc_good_size
(
aValue
)
)
{
}
operator
size_t
(
)
const
{
return
mValue
;
}
size_t
operator
*
(
)
const
{
return
mValue
;
}
Iterator
&
operator
+
+
(
)
{
mValue
=
malloc_good_size
(
mValue
+
1
)
;
return
*
this
;
}
private
:
size_t
mValue
;
}
;
Iterator
begin
(
)
{
return
Iterator
(
mStart
)
;
}
Iterator
end
(
)
{
return
Iterator
(
mEnd
)
;
}
private
:
size_t
mStart
mEnd
;
}
;
#
define
ALIGNMENT_CEILING
(
s
alignment
)
\
(
(
(
s
)
+
(
alignment
-
1
)
)
&
(
~
(
alignment
-
1
)
)
)
static
bool
IsSameRoundedHugeClass
(
size_t
aSize1
size_t
aSize2
jemalloc_stats_t
&
aStats
)
{
return
(
aSize1
>
aStats
.
large_max
&
&
aSize2
>
aStats
.
large_max
&
&
ALIGNMENT_CEILING
(
aSize1
aStats
.
chunksize
)
=
=
ALIGNMENT_CEILING
(
aSize2
aStats
.
chunksize
)
)
;
}
static
bool
CanReallocInPlace
(
size_t
aFromSize
size_t
aToSize
jemalloc_stats_t
&
aStats
)
{
if
(
aFromSize
=
=
malloc_good_size
(
aToSize
)
)
{
return
true
;
}
if
(
aFromSize
>
=
aStats
.
page_size
&
&
aFromSize
<
=
aStats
.
large_max
&
&
aToSize
>
=
aStats
.
page_size
&
&
aToSize
<
=
aStats
.
large_max
)
{
return
true
;
}
if
(
IsSameRoundedHugeClass
(
aFromSize
aToSize
aStats
)
)
{
return
true
;
}
return
false
;
}
TEST
(
Jemalloc
InPlace
)
{
jemalloc_stats_t
stats
;
jemalloc_stats
(
&
stats
)
;
arena_id_t
arena
=
moz_create_arena
(
)
;
for
(
size_t
from_size
:
SizeClassesBetween
(
1
2
*
stats
.
chunksize
)
)
{
SCOPED_TRACE
(
testing
:
:
Message
(
)
<
<
"
from_size
=
"
<
<
from_size
)
;
for
(
size_t
to_size
:
sSizes
)
{
SCOPED_TRACE
(
testing
:
:
Message
(
)
<
<
"
to_size
=
"
<
<
to_size
)
;
char
*
ptr
=
(
char
*
)
moz_arena_malloc
(
arena
from_size
)
;
char
*
ptr2
=
(
char
*
)
moz_arena_realloc
(
arena
ptr
to_size
)
;
if
(
CanReallocInPlace
(
from_size
to_size
stats
)
)
{
EXPECT_EQ
(
ptr
ptr2
)
;
}
else
{
EXPECT_NE
(
ptr
ptr2
)
;
}
moz_arena_free
(
arena
ptr2
)
;
}
}
}
#
if
!
defined
(
XP_WIN
)
|
|
!
defined
(
MOZ_CODE_COVERAGE
)
TEST
(
Jemalloc
JunkPoison
)
{
jemalloc_stats_t
stats
;
jemalloc_stats
(
&
stats
)
;
arena_id_t
buf_arena
=
moz_create_arena
(
)
;
char
*
junk_buf
=
(
char
*
)
moz_arena_malloc
(
buf_arena
stats
.
page_size
)
;
char
junk
=
stats
.
opt_junk
?
'
\
xe4
'
:
'
\
0
'
;
for
(
size_t
i
=
0
;
i
<
stats
.
page_size
;
i
+
+
)
{
ASSERT_EQ
(
junk_buf
[
i
]
junk
)
;
}
char
*
poison_buf
=
(
char
*
)
moz_arena_malloc
(
buf_arena
stats
.
page_size
)
;
memset
(
poison_buf
0xe5
stats
.
page_size
)
;
static
const
char
fill
=
0x42
;
char
*
fill_buf
=
(
char
*
)
moz_arena_malloc
(
buf_arena
stats
.
page_size
)
;
memset
(
fill_buf
fill
stats
.
page_size
)
;
arena_params_t
params
;
params
.
mMaxDirty
=
size_t
(
-
1
)
;
arena_id_t
arena
=
moz_create_arena_with_params
(
&
params
)
;
for
(
size_t
size
:
sSizes
)
{
if
(
size
<
=
stats
.
large_max
)
{
SCOPED_TRACE
(
testing
:
:
Message
(
)
<
<
"
size
=
"
<
<
size
)
;
char
*
buf
=
(
char
*
)
moz_arena_malloc
(
arena
size
)
;
size_t
allocated
=
moz_malloc_usable_size
(
buf
)
;
if
(
stats
.
opt_junk
|
|
stats
.
opt_zero
)
{
ASSERT_NO_FATAL_FAILURE
(
bulk_compare
(
buf
0
allocated
junk_buf
stats
.
page_size
)
)
;
}
moz_arena_free
(
arena
buf
)
;
ASSERT_NO_FATAL_FAILURE
(
bulk_compare
(
buf
0
allocated
poison_buf
stats
.
page_size
)
)
;
}
}
size_t
prev
=
0
;
for
(
size_t
size
:
SizeClassesBetween
(
1
2
*
stats
.
chunksize
)
)
{
SCOPED_TRACE
(
testing
:
:
Message
(
)
<
<
"
size
=
"
<
<
size
)
;
SCOPED_TRACE
(
testing
:
:
Message
(
)
<
<
"
prev
=
"
<
<
prev
)
;
char
*
ptr
=
(
char
*
)
moz_arena_malloc
(
arena
size
)
;
memset
(
ptr
fill
moz_malloc_usable_size
(
ptr
)
)
;
char
*
ptr2
=
(
char
*
)
moz_arena_realloc
(
arena
ptr
prev
+
1
)
;
ASSERT_EQ
(
ptr
ptr2
)
;
ASSERT_NO_FATAL_FAILURE
(
bulk_compare
(
ptr
0
prev
+
1
fill_buf
stats
.
page_size
)
)
;
ASSERT_NO_FATAL_FAILURE
(
bulk_compare
(
ptr
prev
+
1
size
poison_buf
stats
.
page_size
)
)
;
moz_arena_free
(
arena
ptr
)
;
prev
=
size
;
}
for
(
size_t
from_size
:
SizeClassesBetween
(
1
2
*
stats
.
chunksize
)
)
{
SCOPED_TRACE
(
testing
:
:
Message
(
)
<
<
"
from_size
=
"
<
<
from_size
)
;
for
(
size_t
to_size
:
sSizes
)
{
SCOPED_TRACE
(
testing
:
:
Message
(
)
<
<
"
to_size
=
"
<
<
to_size
)
;
if
(
CanReallocInPlace
(
from_size
to_size
stats
)
)
{
char
*
ptr
=
(
char
*
)
moz_arena_malloc
(
arena
from_size
)
;
memset
(
ptr
fill
moz_malloc_usable_size
(
ptr
)
)
;
char
*
ptr2
=
(
char
*
)
moz_arena_realloc
(
arena
ptr
to_size
)
;
ASSERT_EQ
(
ptr
ptr2
)
;
if
(
from_size
>
=
to_size
)
{
ASSERT_NO_FATAL_FAILURE
(
bulk_compare
(
ptr
0
to_size
fill_buf
stats
.
page_size
)
)
;
#
ifdef
XP_WIN
if
(
to_size
>
stats
.
large_max
)
{
size_t
page_limit
=
ALIGNMENT_CEILING
(
to_size
stats
.
page_size
)
;
ASSERT_NO_FATAL_FAILURE
(
bulk_compare
(
ptr
to_size
page_limit
poison_buf
stats
.
page_size
)
)
;
ASSERT_DEATH_WRAP
(
ptr
[
page_limit
]
=
0
"
"
)
;
}
else
#
endif
{
ASSERT_NO_FATAL_FAILURE
(
bulk_compare
(
ptr
to_size
from_size
poison_buf
stats
.
page_size
)
)
;
}
}
else
{
ASSERT_NO_FATAL_FAILURE
(
bulk_compare
(
ptr
0
from_size
fill_buf
stats
.
page_size
)
)
;
if
(
stats
.
opt_junk
|
|
stats
.
opt_zero
)
{
ASSERT_NO_FATAL_FAILURE
(
bulk_compare
(
ptr
from_size
to_size
junk_buf
stats
.
page_size
)
)
;
}
}
moz_arena_free
(
arena
ptr2
)
;
}
}
}
for
(
size_t
from_size
:
SizeClassesBetween
(
1
2
*
stats
.
chunksize
)
)
{
SCOPED_TRACE
(
testing
:
:
Message
(
)
<
<
"
from_size
=
"
<
<
from_size
)
;
for
(
size_t
to_size
:
sSizes
)
{
if
(
from_size
<
to_size
&
&
malloc_good_size
(
to_size
)
!
=
from_size
&
&
!
IsSameRoundedHugeClass
(
from_size
to_size
stats
)
)
{
SCOPED_TRACE
(
testing
:
:
Message
(
)
<
<
"
to_size
=
"
<
<
to_size
)
;
char
*
ptr
=
(
char
*
)
moz_arena_malloc
(
arena
from_size
)
;
memset
(
ptr
fill
moz_malloc_usable_size
(
ptr
)
)
;
char
*
avoid_inplace
=
nullptr
;
if
(
from_size
>
=
stats
.
page_size
&
&
from_size
<
stats
.
large_max
)
{
avoid_inplace
=
(
char
*
)
moz_arena_malloc
(
arena
stats
.
page_size
)
;
ASSERT_EQ
(
ptr
+
from_size
avoid_inplace
)
;
}
char
*
ptr2
=
(
char
*
)
moz_arena_realloc
(
arena
ptr
to_size
)
;
ASSERT_NE
(
ptr
ptr2
)
;
if
(
from_size
<
=
stats
.
large_max
)
{
ASSERT_NO_FATAL_FAILURE
(
bulk_compare
(
ptr
0
from_size
poison_buf
stats
.
page_size
)
)
;
}
ASSERT_NO_FATAL_FAILURE
(
bulk_compare
(
ptr2
0
from_size
fill_buf
stats
.
page_size
)
)
;
if
(
stats
.
opt_junk
|
|
stats
.
opt_zero
)
{
size_t
rounded_to_size
=
malloc_good_size
(
to_size
)
;
ASSERT_NE
(
to_size
rounded_to_size
)
;
ASSERT_NO_FATAL_FAILURE
(
bulk_compare
(
ptr2
from_size
rounded_to_size
junk_buf
stats
.
page_size
)
)
;
}
moz_arena_free
(
arena
ptr2
)
;
moz_arena_free
(
arena
avoid_inplace
)
;
}
}
}
for
(
size_t
from_size
:
SizeClassesBetween
(
1
2
*
stats
.
chunksize
)
)
{
SCOPED_TRACE
(
testing
:
:
Message
(
)
<
<
"
from_size
=
"
<
<
from_size
)
;
for
(
size_t
to_size
:
sSizes
)
{
if
(
from_size
>
to_size
&
&
!
CanReallocInPlace
(
from_size
to_size
stats
)
)
{
SCOPED_TRACE
(
testing
:
:
Message
(
)
<
<
"
to_size
=
"
<
<
to_size
)
;
char
*
ptr
=
(
char
*
)
moz_arena_malloc
(
arena
from_size
)
;
memset
(
ptr
fill
from_size
)
;
char
*
ptr2
=
(
char
*
)
moz_arena_realloc
(
arena
ptr
to_size
)
;
ASSERT_NE
(
ptr
ptr2
)
;
if
(
from_size
<
=
stats
.
large_max
)
{
ASSERT_NO_FATAL_FAILURE
(
bulk_compare
(
ptr
0
from_size
poison_buf
stats
.
page_size
)
)
;
}
ASSERT_NO_FATAL_FAILURE
(
bulk_compare
(
ptr2
0
to_size
fill_buf
stats
.
page_size
)
)
;
if
(
stats
.
opt_junk
|
|
stats
.
opt_zero
)
{
size_t
rounded_to_size
=
malloc_good_size
(
to_size
)
;
ASSERT_NE
(
to_size
rounded_to_size
)
;
ASSERT_NO_FATAL_FAILURE
(
bulk_compare
(
ptr2
from_size
rounded_to_size
junk_buf
stats
.
page_size
)
)
;
}
moz_arena_free
(
arena
ptr2
)
;
}
}
}
moz_arena_free
(
buf_arena
poison_buf
)
;
moz_arena_free
(
buf_arena
junk_buf
)
;
}
#
endif
