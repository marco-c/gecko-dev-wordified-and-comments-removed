use
Atom
;
use
cssparser
:
:
{
Delimiter
Parser
ParserInput
SourcePosition
Token
TokenSerializationType
}
;
use
parser
:
:
ParserContext
;
use
precomputed_hash
:
:
PrecomputedHash
;
use
properties
:
:
{
CSSWideKeyword
DeclaredValue
}
;
use
selector_map
:
:
{
PrecomputedHashSet
PrecomputedHashMap
}
;
use
selectors
:
:
parser
:
:
SelectorParseError
;
use
servo_arc
:
:
Arc
;
use
std
:
:
ascii
:
:
AsciiExt
;
use
std
:
:
borrow
:
:
{
Borrow
Cow
}
;
use
std
:
:
fmt
;
use
std
:
:
hash
:
:
Hash
;
use
style_traits
:
:
{
ToCss
StyleParseError
ParseError
}
;
pub
type
Name
=
Atom
;
pub
fn
parse_name
(
s
:
&
str
)
-
>
Result
<
&
str
(
)
>
{
if
s
.
starts_with
(
"
-
-
"
)
{
Ok
(
&
s
[
2
.
.
]
)
}
else
{
Err
(
(
)
)
}
}
#
[
derive
(
Clone
Debug
PartialEq
)
]
#
[
cfg_attr
(
feature
=
"
gecko
"
derive
(
MallocSizeOf
)
)
]
#
[
cfg_attr
(
feature
=
"
servo
"
derive
(
HeapSizeOf
)
)
]
pub
struct
SpecifiedValue
{
css
:
String
first_token_type
:
TokenSerializationType
last_token_type
:
TokenSerializationType
references
:
PrecomputedHashSet
<
Name
>
}
pub
struct
BorrowedSpecifiedValue
<
'
a
>
{
css
:
&
'
a
str
first_token_type
:
TokenSerializationType
last_token_type
:
TokenSerializationType
references
:
Option
<
&
'
a
PrecomputedHashSet
<
Name
>
>
}
#
[
derive
(
Clone
Debug
Eq
PartialEq
)
]
#
[
cfg_attr
(
feature
=
"
servo
"
derive
(
HeapSizeOf
)
)
]
pub
struct
ComputedValue
{
css
:
String
first_token_type
:
TokenSerializationType
last_token_type
:
TokenSerializationType
}
impl
ToCss
for
SpecifiedValue
{
fn
to_css
<
W
>
(
&
self
dest
:
&
mut
W
)
-
>
fmt
:
:
Result
where
W
:
fmt
:
:
Write
{
dest
.
write_str
(
&
self
.
css
)
}
}
impl
ToCss
for
ComputedValue
{
fn
to_css
<
W
>
(
&
self
dest
:
&
mut
W
)
-
>
fmt
:
:
Result
where
W
:
fmt
:
:
Write
{
dest
.
write_str
(
&
self
.
css
)
}
}
pub
type
CustomPropertiesMap
=
OrderedMap
<
Name
ComputedValue
>
;
#
[
derive
(
Clone
Debug
Eq
PartialEq
)
]
pub
struct
OrderedMap
<
K
V
>
where
K
:
PrecomputedHash
+
Hash
+
Eq
+
Clone
{
index
:
Vec
<
K
>
values
:
PrecomputedHashMap
<
K
V
>
}
impl
<
K
V
>
OrderedMap
<
K
V
>
where
K
:
Eq
+
PrecomputedHash
+
Hash
+
Clone
{
pub
fn
new
(
)
-
>
Self
{
OrderedMap
{
index
:
Vec
:
:
new
(
)
values
:
PrecomputedHashMap
:
:
default
(
)
}
}
pub
fn
insert
(
&
mut
self
key
:
K
value
:
V
)
{
if
!
self
.
values
.
contains_key
(
&
key
)
{
self
.
index
.
push
(
key
.
clone
(
)
)
;
}
self
.
values
.
insert
(
key
value
)
;
}
pub
fn
get
(
&
self
key
:
&
K
)
-
>
Option
<
&
V
>
{
let
value
=
self
.
values
.
get
(
key
)
;
debug_assert_eq
!
(
value
.
is_some
(
)
self
.
index
.
contains
(
key
)
)
;
value
}
pub
fn
get_key_at
(
&
self
index
:
u32
)
-
>
Option
<
&
K
>
{
self
.
index
.
get
(
index
as
usize
)
}
pub
fn
iter
<
'
a
>
(
&
'
a
self
)
-
>
OrderedMapIterator
<
'
a
K
V
>
{
OrderedMapIterator
{
inner
:
self
pos
:
0
}
}
pub
fn
len
(
&
self
)
-
>
usize
{
debug_assert_eq
!
(
self
.
values
.
len
(
)
self
.
index
.
len
(
)
)
;
self
.
values
.
len
(
)
}
fn
remove
<
Q
:
?
Sized
>
(
&
mut
self
key
:
&
Q
)
-
>
Option
<
V
>
where
K
:
Borrow
<
Q
>
Q
:
PrecomputedHash
+
Hash
+
Eq
{
let
index
=
match
self
.
index
.
iter
(
)
.
position
(
|
k
|
k
.
borrow
(
)
=
=
key
)
{
Some
(
p
)
=
>
p
None
=
>
return
None
}
;
self
.
index
.
remove
(
index
)
;
self
.
values
.
remove
(
key
)
}
}
pub
struct
OrderedMapIterator
<
'
a
K
V
>
where
K
:
'
a
+
Eq
+
PrecomputedHash
+
Hash
+
Clone
V
:
'
a
{
inner
:
&
'
a
OrderedMap
<
K
V
>
pos
:
usize
}
impl
<
'
a
K
V
>
Iterator
for
OrderedMapIterator
<
'
a
K
V
>
where
K
:
Eq
+
PrecomputedHash
+
Hash
+
Clone
{
type
Item
=
(
&
'
a
K
&
'
a
V
)
;
fn
next
(
&
mut
self
)
-
>
Option
<
Self
:
:
Item
>
{
let
ref
index
=
self
.
inner
.
index
;
if
self
.
pos
>
=
index
.
len
(
)
{
return
None
;
}
let
ref
key
=
index
[
index
.
len
(
)
-
self
.
pos
-
1
]
;
self
.
pos
+
=
1
;
let
value
=
self
.
inner
.
values
.
get
(
key
)
.
unwrap
(
)
;
Some
(
(
key
value
)
)
}
}
impl
ComputedValue
{
fn
empty
(
)
-
>
ComputedValue
{
ComputedValue
{
css
:
String
:
:
new
(
)
last_token_type
:
TokenSerializationType
:
:
nothing
(
)
first_token_type
:
TokenSerializationType
:
:
nothing
(
)
}
}
fn
push
(
&
mut
self
css
:
&
str
css_first_token_type
:
TokenSerializationType
css_last_token_type
:
TokenSerializationType
)
{
if
css
.
is_empty
(
)
{
return
}
self
.
first_token_type
.
set_if_nothing
(
css_first_token_type
)
;
if
self
.
last_token_type
.
needs_separator_when_before
(
css_first_token_type
)
{
self
.
css
.
push_str
(
"
/
*
*
/
"
)
}
self
.
css
.
push_str
(
css
)
;
self
.
last_token_type
=
css_last_token_type
}
fn
push_from
(
&
mut
self
position
:
(
SourcePosition
TokenSerializationType
)
input
:
&
Parser
last_token_type
:
TokenSerializationType
)
{
self
.
push
(
input
.
slice_from
(
position
.
0
)
position
.
1
last_token_type
)
}
fn
push_variable
(
&
mut
self
variable
:
&
ComputedValue
)
{
self
.
push
(
&
variable
.
css
variable
.
first_token_type
variable
.
last_token_type
)
}
}
impl
SpecifiedValue
{
pub
fn
parse
<
'
i
'
t
>
(
_context
:
&
ParserContext
input
:
&
mut
Parser
<
'
i
'
t
>
)
-
>
Result
<
Box
<
Self
>
ParseError
<
'
i
>
>
{
let
mut
references
=
Some
(
PrecomputedHashSet
:
:
default
(
)
)
;
let
(
first
css
last
)
=
parse_self_contained_declaration_value
(
input
&
mut
references
)
?
;
Ok
(
Box
:
:
new
(
SpecifiedValue
{
css
:
css
.
into_owned
(
)
first_token_type
:
first
last_token_type
:
last
references
:
references
.
unwrap
(
)
}
)
)
}
}
pub
fn
parse_non_custom_with_var
<
'
i
'
t
>
(
input
:
&
mut
Parser
<
'
i
'
t
>
)
-
>
Result
<
(
TokenSerializationType
Cow
<
'
i
str
>
)
ParseError
<
'
i
>
>
{
let
(
first_token_type
css
_
)
=
parse_self_contained_declaration_value
(
input
&
mut
None
)
?
;
Ok
(
(
first_token_type
css
)
)
}
fn
parse_self_contained_declaration_value
<
'
i
'
t
>
(
input
:
&
mut
Parser
<
'
i
'
t
>
references
:
&
mut
Option
<
PrecomputedHashSet
<
Name
>
>
)
-
>
Result
<
(
TokenSerializationType
Cow
<
'
i
str
>
TokenSerializationType
)
ParseError
<
'
i
>
>
{
let
start_position
=
input
.
position
(
)
;
let
mut
missing_closing_characters
=
String
:
:
new
(
)
;
let
(
first
last
)
=
parse_declaration_value
(
input
references
&
mut
missing_closing_characters
)
?
;
let
mut
css
:
Cow
<
str
>
=
input
.
slice_from
(
start_position
)
.
into
(
)
;
if
!
missing_closing_characters
.
is_empty
(
)
{
if
css
.
ends_with
(
"
\
\
"
)
&
&
matches
!
(
missing_closing_characters
.
as_bytes
(
)
[
0
]
b
'
"
'
|
b
'
\
'
'
)
{
css
.
to_mut
(
)
.
pop
(
)
;
}
css
.
to_mut
(
)
.
push_str
(
&
missing_closing_characters
)
;
}
Ok
(
(
first
css
last
)
)
}
fn
parse_declaration_value
<
'
i
'
t
>
(
input
:
&
mut
Parser
<
'
i
'
t
>
references
:
&
mut
Option
<
PrecomputedHashSet
<
Name
>
>
missing_closing_characters
:
&
mut
String
)
-
>
Result
<
(
TokenSerializationType
TokenSerializationType
)
ParseError
<
'
i
>
>
{
input
.
parse_until_before
(
Delimiter
:
:
Bang
|
Delimiter
:
:
Semicolon
|
input
|
{
let
start
=
input
.
state
(
)
;
input
.
next_including_whitespace
(
)
?
;
input
.
reset
(
&
start
)
;
parse_declaration_value_block
(
input
references
missing_closing_characters
)
}
)
}
fn
parse_declaration_value_block
<
'
i
'
t
>
(
input
:
&
mut
Parser
<
'
i
'
t
>
references
:
&
mut
Option
<
PrecomputedHashSet
<
Name
>
>
missing_closing_characters
:
&
mut
String
)
-
>
Result
<
(
TokenSerializationType
TokenSerializationType
)
ParseError
<
'
i
>
>
{
let
mut
token_start
=
input
.
position
(
)
;
let
mut
token
=
match
input
.
next_including_whitespace_and_comments
(
)
{
Ok
(
token
)
=
>
token
.
clone
(
)
Err
(
_
)
=
>
return
Ok
(
(
TokenSerializationType
:
:
nothing
(
)
TokenSerializationType
:
:
nothing
(
)
)
)
}
;
let
first_token_type
=
token
.
serialization_type
(
)
;
loop
{
macro_rules
!
nested
{
(
)
=
>
{
input
.
parse_nested_block
(
|
input
|
{
parse_declaration_value_block
(
input
references
missing_closing_characters
)
}
)
?
}
}
macro_rules
!
check_closed
{
(
closing
:
expr
)
=
>
{
if
!
input
.
slice_from
(
token_start
)
.
ends_with
(
closing
)
{
missing_closing_characters
.
push_str
(
closing
)
}
}
}
let
last_token_type
=
match
token
{
Token
:
:
Comment
(
_
)
=
>
{
let
token_slice
=
input
.
slice_from
(
token_start
)
;
if
!
token_slice
.
ends_with
(
"
*
/
"
)
{
missing_closing_characters
.
push_str
(
if
token_slice
.
ends_with
(
'
*
'
)
{
"
/
"
}
else
{
"
*
/
"
}
)
}
token
.
serialization_type
(
)
}
Token
:
:
BadUrl
(
u
)
=
>
return
Err
(
StyleParseError
:
:
BadUrlInDeclarationValueBlock
(
u
)
.
into
(
)
)
Token
:
:
BadString
(
s
)
=
>
return
Err
(
StyleParseError
:
:
BadStringInDeclarationValueBlock
(
s
)
.
into
(
)
)
Token
:
:
CloseParenthesis
=
>
return
Err
(
StyleParseError
:
:
UnbalancedCloseParenthesisInDeclarationValueBlock
.
into
(
)
)
Token
:
:
CloseSquareBracket
=
>
return
Err
(
StyleParseError
:
:
UnbalancedCloseSquareBracketInDeclarationValueBlock
.
into
(
)
)
Token
:
:
CloseCurlyBracket
=
>
return
Err
(
StyleParseError
:
:
UnbalancedCloseCurlyBracketInDeclarationValueBlock
.
into
(
)
)
Token
:
:
Function
(
ref
name
)
=
>
{
if
name
.
eq_ignore_ascii_case
(
"
var
"
)
{
let
args_start
=
input
.
state
(
)
;
input
.
parse_nested_block
(
|
input
|
{
parse_var_function
(
input
references
)
}
)
?
;
input
.
reset
(
&
args_start
)
;
}
nested
!
(
)
;
check_closed
!
(
"
)
"
)
;
Token
:
:
CloseParenthesis
.
serialization_type
(
)
}
Token
:
:
ParenthesisBlock
=
>
{
nested
!
(
)
;
check_closed
!
(
"
)
"
)
;
Token
:
:
CloseParenthesis
.
serialization_type
(
)
}
Token
:
:
CurlyBracketBlock
=
>
{
nested
!
(
)
;
check_closed
!
(
"
}
"
)
;
Token
:
:
CloseCurlyBracket
.
serialization_type
(
)
}
Token
:
:
SquareBracketBlock
=
>
{
nested
!
(
)
;
check_closed
!
(
"
]
"
)
;
Token
:
:
CloseSquareBracket
.
serialization_type
(
)
}
Token
:
:
QuotedString
(
_
)
=
>
{
let
token_slice
=
input
.
slice_from
(
token_start
)
;
let
quote
=
&
token_slice
[
.
.
1
]
;
debug_assert
!
(
matches
!
(
quote
"
\
"
"
|
"
'
"
)
)
;
if
!
(
token_slice
.
ends_with
(
quote
)
&
&
token_slice
.
len
(
)
>
1
)
{
missing_closing_characters
.
push_str
(
quote
)
}
token
.
serialization_type
(
)
}
Token
:
:
Ident
(
ref
value
)
|
Token
:
:
AtKeyword
(
ref
value
)
|
Token
:
:
Hash
(
ref
value
)
|
Token
:
:
IDHash
(
ref
value
)
|
Token
:
:
UnquotedUrl
(
ref
value
)
|
Token
:
:
Dimension
{
unit
:
ref
value
.
.
}
=
>
{
if
value
.
ends_with
(
"
"
)
&
&
input
.
slice_from
(
token_start
)
.
ends_with
(
"
\
\
"
)
{
missing_closing_characters
.
push_str
(
"
"
)
}
if
matches
!
(
token
Token
:
:
UnquotedUrl
(
_
)
)
{
check_closed
!
(
"
)
"
)
;
}
token
.
serialization_type
(
)
}
_
=
>
{
token
.
serialization_type
(
)
}
}
;
token_start
=
input
.
position
(
)
;
token
=
match
input
.
next_including_whitespace_and_comments
(
)
{
Ok
(
token
)
=
>
token
.
clone
(
)
Err
(
.
.
)
=
>
return
Ok
(
(
first_token_type
last_token_type
)
)
}
;
}
}
fn
parse_var_function
<
'
i
'
t
>
(
input
:
&
mut
Parser
<
'
i
'
t
>
references
:
&
mut
Option
<
PrecomputedHashSet
<
Name
>
>
)
-
>
Result
<
(
)
ParseError
<
'
i
>
>
{
let
name
=
input
.
expect_ident_cloned
(
)
?
;
let
name
:
Result
<
_
ParseError
>
=
parse_name
(
&
name
)
.
map_err
(
|
(
)
|
SelectorParseError
:
:
UnexpectedIdent
(
name
.
clone
(
)
)
.
into
(
)
)
;
let
name
=
name
?
;
if
input
.
try
(
|
input
|
input
.
expect_comma
(
)
)
.
is_ok
(
)
{
input
.
parse_until_before
(
Delimiter
:
:
Bang
|
Delimiter
:
:
Semicolon
|
input
|
{
input
.
next_including_whitespace
(
)
?
;
while
let
Ok
(
_
)
=
input
.
next_including_whitespace_and_comments
(
)
{
}
Ok
(
(
)
)
}
)
?
;
}
if
let
Some
(
ref
mut
refs
)
=
*
references
{
refs
.
insert
(
Atom
:
:
from
(
name
)
)
;
}
Ok
(
(
)
)
}
pub
fn
cascade
<
'
a
>
(
custom_properties
:
&
mut
Option
<
OrderedMap
<
&
'
a
Name
BorrowedSpecifiedValue
<
'
a
>
>
>
inherited
:
&
'
a
Option
<
Arc
<
CustomPropertiesMap
>
>
seen
:
&
mut
PrecomputedHashSet
<
&
'
a
Name
>
name
:
&
'
a
Name
specified_value
:
DeclaredValue
<
'
a
Box
<
SpecifiedValue
>
>
)
{
let
was_already_present
=
!
seen
.
insert
(
name
)
;
if
was_already_present
{
return
;
}
let
map
=
match
*
custom_properties
{
Some
(
ref
mut
map
)
=
>
map
None
=
>
{
let
mut
map
=
OrderedMap
:
:
new
(
)
;
if
let
Some
(
ref
inherited
)
=
*
inherited
{
for
name
in
&
inherited
.
index
{
let
inherited_value
=
inherited
.
get
(
name
)
.
unwrap
(
)
;
map
.
insert
(
name
BorrowedSpecifiedValue
{
css
:
&
inherited_value
.
css
first_token_type
:
inherited_value
.
first_token_type
last_token_type
:
inherited_value
.
last_token_type
references
:
None
}
)
}
}
*
custom_properties
=
Some
(
map
)
;
custom_properties
.
as_mut
(
)
.
unwrap
(
)
}
}
;
match
specified_value
{
DeclaredValue
:
:
Value
(
ref
specified_value
)
=
>
{
map
.
insert
(
name
BorrowedSpecifiedValue
{
css
:
&
specified_value
.
css
first_token_type
:
specified_value
.
first_token_type
last_token_type
:
specified_value
.
last_token_type
references
:
Some
(
&
specified_value
.
references
)
}
)
;
}
DeclaredValue
:
:
WithVariables
(
_
)
=
>
unreachable
!
(
)
DeclaredValue
:
:
CSSWideKeyword
(
keyword
)
=
>
match
keyword
{
CSSWideKeyword
:
:
Initial
=
>
{
map
.
remove
(
&
name
)
;
}
CSSWideKeyword
:
:
Unset
|
CSSWideKeyword
:
:
Inherit
=
>
{
}
}
}
}
pub
fn
finish_cascade
(
specified_values_map
:
Option
<
OrderedMap
<
&
Name
BorrowedSpecifiedValue
>
>
inherited
:
&
Option
<
Arc
<
CustomPropertiesMap
>
>
)
-
>
Option
<
Arc
<
CustomPropertiesMap
>
>
{
if
let
Some
(
mut
map
)
=
specified_values_map
{
remove_cycles
(
&
mut
map
)
;
Some
(
Arc
:
:
new
(
substitute_all
(
map
)
)
)
}
else
{
inherited
.
clone
(
)
}
}
fn
remove_cycles
(
map
:
&
mut
OrderedMap
<
&
Name
BorrowedSpecifiedValue
>
)
{
let
mut
to_remove
=
PrecomputedHashSet
:
:
default
(
)
;
{
let
mut
visited
=
PrecomputedHashSet
:
:
default
(
)
;
let
mut
stack
=
Vec
:
:
new
(
)
;
for
name
in
&
map
.
index
{
walk
(
map
name
&
mut
stack
&
mut
visited
&
mut
to_remove
)
;
fn
walk
<
'
a
>
(
map
:
&
OrderedMap
<
&
'
a
Name
BorrowedSpecifiedValue
<
'
a
>
>
name
:
&
'
a
Name
stack
:
&
mut
Vec
<
&
'
a
Name
>
visited
:
&
mut
PrecomputedHashSet
<
&
'
a
Name
>
to_remove
:
&
mut
PrecomputedHashSet
<
Name
>
)
{
let
already_visited_before
=
!
visited
.
insert
(
name
)
;
if
already_visited_before
{
return
}
if
let
Some
(
value
)
=
map
.
get
(
&
name
)
{
if
let
Some
(
references
)
=
value
.
references
{
stack
.
push
(
name
)
;
for
next
in
references
{
if
let
Some
(
position
)
=
stack
.
iter
(
)
.
position
(
|
&
x
|
x
=
=
next
)
{
for
&
in_cycle
in
&
stack
[
position
.
.
]
{
to_remove
.
insert
(
in_cycle
.
clone
(
)
)
;
}
}
else
{
walk
(
map
next
stack
visited
to_remove
)
;
}
}
stack
.
pop
(
)
;
}
}
}
}
}
for
name
in
to_remove
{
map
.
remove
(
&
name
)
;
}
}
fn
substitute_all
(
specified_values_map
:
OrderedMap
<
&
Name
BorrowedSpecifiedValue
>
)
-
>
CustomPropertiesMap
{
let
mut
custom_properties_map
=
CustomPropertiesMap
:
:
new
(
)
;
let
mut
invalid
=
PrecomputedHashSet
:
:
default
(
)
;
for
name
in
&
specified_values_map
.
index
{
let
value
=
specified_values_map
.
get
(
name
)
.
unwrap
(
)
;
let
_
=
substitute_one
(
name
value
&
specified_values_map
None
&
mut
custom_properties_map
&
mut
invalid
)
;
}
custom_properties_map
}
fn
substitute_one
(
name
:
&
Name
specified_value
:
&
BorrowedSpecifiedValue
specified_values_map
:
&
OrderedMap
<
&
Name
BorrowedSpecifiedValue
>
partial_computed_value
:
Option
<
&
mut
ComputedValue
>
custom_properties_map
:
&
mut
CustomPropertiesMap
invalid
:
&
mut
PrecomputedHashSet
<
Name
>
)
-
>
Result
<
TokenSerializationType
(
)
>
{
if
let
Some
(
computed_value
)
=
custom_properties_map
.
get
(
&
name
)
{
if
let
Some
(
partial_computed_value
)
=
partial_computed_value
{
partial_computed_value
.
push_variable
(
computed_value
)
}
return
Ok
(
computed_value
.
last_token_type
)
}
if
invalid
.
contains
(
name
)
{
return
Err
(
(
)
)
;
}
let
computed_value
=
if
specified_value
.
references
.
map
(
|
set
|
set
.
is_empty
(
)
)
=
=
Some
(
false
)
{
let
mut
partial_computed_value
=
ComputedValue
:
:
empty
(
)
;
let
mut
input
=
ParserInput
:
:
new
(
&
specified_value
.
css
)
;
let
mut
input
=
Parser
:
:
new
(
&
mut
input
)
;
let
mut
position
=
(
input
.
position
(
)
specified_value
.
first_token_type
)
;
let
result
=
substitute_block
(
&
mut
input
&
mut
position
&
mut
partial_computed_value
&
mut
|
name
partial_computed_value
|
{
if
let
Some
(
other_specified_value
)
=
specified_values_map
.
get
(
&
name
)
{
substitute_one
(
name
other_specified_value
specified_values_map
Some
(
partial_computed_value
)
custom_properties_map
invalid
)
}
else
{
Err
(
(
)
)
}
}
)
;
if
let
Ok
(
last_token_type
)
=
result
{
partial_computed_value
.
push_from
(
position
&
input
last_token_type
)
;
partial_computed_value
}
else
{
invalid
.
insert
(
name
.
clone
(
)
)
;
return
Err
(
(
)
)
}
}
else
{
ComputedValue
{
css
:
specified_value
.
css
.
to_owned
(
)
first_token_type
:
specified_value
.
first_token_type
last_token_type
:
specified_value
.
last_token_type
}
}
;
if
let
Some
(
partial_computed_value
)
=
partial_computed_value
{
partial_computed_value
.
push_variable
(
&
computed_value
)
}
let
last_token_type
=
computed_value
.
last_token_type
;
custom_properties_map
.
insert
(
name
.
clone
(
)
computed_value
)
;
Ok
(
last_token_type
)
}
fn
substitute_block
<
'
i
'
t
F
>
(
input
:
&
mut
Parser
<
'
i
'
t
>
position
:
&
mut
(
SourcePosition
TokenSerializationType
)
partial_computed_value
:
&
mut
ComputedValue
substitute_one
:
&
mut
F
)
-
>
Result
<
TokenSerializationType
ParseError
<
'
i
>
>
where
F
:
FnMut
(
&
Name
&
mut
ComputedValue
)
-
>
Result
<
TokenSerializationType
(
)
>
{
let
mut
last_token_type
=
TokenSerializationType
:
:
nothing
(
)
;
let
mut
set_position_at_next_iteration
=
false
;
loop
{
let
before_this_token
=
input
.
position
(
)
;
let
next
=
input
.
next_including_whitespace_and_comments
(
)
.
map
(
|
t
|
t
.
clone
(
)
)
;
if
set_position_at_next_iteration
{
*
position
=
(
before_this_token
match
next
{
Ok
(
ref
token
)
=
>
token
.
serialization_type
(
)
Err
(
_
)
=
>
TokenSerializationType
:
:
nothing
(
)
}
)
;
set_position_at_next_iteration
=
false
;
}
let
token
=
match
next
{
Ok
(
token
)
=
>
token
Err
(
.
.
)
=
>
break
}
;
match
token
{
Token
:
:
Function
(
ref
name
)
if
name
.
eq_ignore_ascii_case
(
"
var
"
)
=
>
{
partial_computed_value
.
push
(
input
.
slice
(
position
.
0
.
.
before_this_token
)
position
.
1
last_token_type
)
;
input
.
parse_nested_block
(
|
input
|
{
let
name
=
input
.
expect_ident_cloned
(
)
.
unwrap
(
)
;
let
name
=
Atom
:
:
from
(
parse_name
(
&
name
)
.
unwrap
(
)
)
;
if
let
Ok
(
last
)
=
substitute_one
(
&
name
partial_computed_value
)
{
last_token_type
=
last
;
while
let
Ok
(
_
)
=
input
.
next
(
)
{
}
}
else
{
input
.
expect_comma
(
)
?
;
let
after_comma
=
input
.
state
(
)
;
let
first_token_type
=
input
.
next_including_whitespace_and_comments
(
)
.
unwrap
(
)
.
serialization_type
(
)
;
input
.
reset
(
&
after_comma
)
;
let
mut
position
=
(
after_comma
.
position
(
)
first_token_type
)
;
last_token_type
=
substitute_block
(
input
&
mut
position
partial_computed_value
substitute_one
)
?
;
partial_computed_value
.
push_from
(
position
input
last_token_type
)
;
}
Ok
(
(
)
)
}
)
?
;
set_position_at_next_iteration
=
true
}
Token
:
:
Function
(
_
)
|
Token
:
:
ParenthesisBlock
|
Token
:
:
CurlyBracketBlock
|
Token
:
:
SquareBracketBlock
=
>
{
input
.
parse_nested_block
(
|
input
|
{
substitute_block
(
input
position
partial_computed_value
substitute_one
)
}
)
?
;
last_token_type
=
Token
:
:
CloseParenthesis
.
serialization_type
(
)
;
}
_
=
>
last_token_type
=
token
.
serialization_type
(
)
}
}
Ok
(
last_token_type
)
}
pub
fn
substitute
<
'
i
>
(
input
:
&
'
i
str
first_token_type
:
TokenSerializationType
computed_values_map
:
&
Option
<
Arc
<
CustomPropertiesMap
>
>
)
-
>
Result
<
String
ParseError
<
'
i
>
>
{
let
mut
substituted
=
ComputedValue
:
:
empty
(
)
;
let
mut
input
=
ParserInput
:
:
new
(
input
)
;
let
mut
input
=
Parser
:
:
new
(
&
mut
input
)
;
let
mut
position
=
(
input
.
position
(
)
first_token_type
)
;
let
last_token_type
=
substitute_block
(
&
mut
input
&
mut
position
&
mut
substituted
&
mut
|
name
substituted
|
{
if
let
Some
(
value
)
=
computed_values_map
.
as_ref
(
)
.
and_then
(
|
map
|
map
.
get
(
name
)
)
{
substituted
.
push_variable
(
value
)
;
Ok
(
value
.
last_token_type
)
}
else
{
Err
(
(
)
)
}
}
)
?
;
substituted
.
push_from
(
position
&
input
last_token_type
)
;
Ok
(
substituted
.
css
)
}
