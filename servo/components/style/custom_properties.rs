use
Atom
;
use
cssparser
:
:
{
Delimiter
Parser
ParserInput
SourcePosition
Token
TokenSerializationType
}
;
use
hash
:
:
map
:
:
Entry
;
use
precomputed_hash
:
:
PrecomputedHash
;
use
properties
:
:
{
CSSWideKeyword
DeclaredValue
}
;
use
selector_map
:
:
{
PrecomputedHashSet
PrecomputedHashMap
}
;
use
selectors
:
:
parser
:
:
SelectorParseErrorKind
;
use
servo_arc
:
:
Arc
;
use
smallvec
:
:
SmallVec
;
#
[
allow
(
unused_imports
)
]
use
std
:
:
ascii
:
:
AsciiExt
;
use
std
:
:
borrow
:
:
{
Borrow
Cow
}
;
use
std
:
:
cmp
;
use
std
:
:
fmt
:
:
{
self
Write
}
;
use
std
:
:
hash
:
:
Hash
;
use
style_traits
:
:
{
CssWriter
ToCss
StyleParseErrorKind
ParseError
}
;
pub
type
Name
=
Atom
;
pub
fn
parse_name
(
s
:
&
str
)
-
>
Result
<
&
str
(
)
>
{
if
s
.
starts_with
(
"
-
-
"
)
{
Ok
(
&
s
[
2
.
.
]
)
}
else
{
Err
(
(
)
)
}
}
#
[
derive
(
Clone
Debug
MallocSizeOf
PartialEq
)
]
pub
struct
VariableValue
{
css
:
String
first_token_type
:
TokenSerializationType
last_token_type
:
TokenSerializationType
references
:
PrecomputedHashSet
<
Name
>
}
impl
ToCss
for
SpecifiedValue
{
fn
to_css
<
W
>
(
&
self
dest
:
&
mut
CssWriter
<
W
>
)
-
>
fmt
:
:
Result
where
W
:
Write
{
dest
.
write_str
(
&
self
.
css
)
}
}
pub
type
CustomPropertiesMap
=
OrderedMap
<
Name
Arc
<
VariableValue
>
>
;
pub
type
SpecifiedValue
=
VariableValue
;
pub
type
ComputedValue
=
VariableValue
;
#
[
derive
(
Clone
Debug
Eq
PartialEq
)
]
pub
struct
OrderedMap
<
K
V
>
where
K
:
PrecomputedHash
+
Hash
+
Eq
+
Clone
{
index
:
Vec
<
K
>
values
:
PrecomputedHashMap
<
K
V
>
}
impl
<
K
V
>
OrderedMap
<
K
V
>
where
K
:
Eq
+
PrecomputedHash
+
Hash
+
Clone
{
pub
fn
new
(
)
-
>
Self
{
OrderedMap
{
index
:
Vec
:
:
new
(
)
values
:
PrecomputedHashMap
:
:
default
(
)
}
}
#
[
allow
(
unused_mut
)
]
pub
fn
insert
(
&
mut
self
key
:
K
value
:
V
)
{
let
OrderedMap
{
ref
mut
index
ref
mut
values
}
=
*
self
;
match
values
.
entry
(
key
)
{
Entry
:
:
Vacant
(
mut
entry
)
=
>
{
index
.
push
(
entry
.
key
(
)
.
clone
(
)
)
;
entry
.
insert
(
value
)
;
}
Entry
:
:
Occupied
(
mut
entry
)
=
>
{
entry
.
insert
(
value
)
;
}
}
}
pub
fn
get
(
&
self
key
:
&
K
)
-
>
Option
<
&
V
>
{
let
value
=
self
.
values
.
get
(
key
)
;
debug_assert_eq
!
(
value
.
is_some
(
)
self
.
index
.
contains
(
key
)
)
;
value
}
pub
fn
contains_key
(
&
self
key
:
&
K
)
-
>
bool
{
self
.
values
.
contains_key
(
key
)
}
pub
fn
get_key_at
(
&
self
index
:
u32
)
-
>
Option
<
&
K
>
{
self
.
index
.
get
(
index
as
usize
)
}
pub
fn
iter
<
'
a
>
(
&
'
a
self
)
-
>
OrderedMapIterator
<
'
a
K
V
>
{
OrderedMapIterator
{
inner
:
self
pos
:
0
}
}
pub
fn
len
(
&
self
)
-
>
usize
{
debug_assert_eq
!
(
self
.
values
.
len
(
)
self
.
index
.
len
(
)
)
;
self
.
values
.
len
(
)
}
pub
fn
is_empty
(
&
self
)
-
>
bool
{
self
.
len
(
)
=
=
0
}
fn
remove
<
Q
:
?
Sized
>
(
&
mut
self
key
:
&
Q
)
-
>
Option
<
V
>
where
K
:
Borrow
<
Q
>
Q
:
PrecomputedHash
+
Hash
+
Eq
{
let
index
=
self
.
index
.
iter
(
)
.
position
(
|
k
|
k
.
borrow
(
)
=
=
key
)
?
;
self
.
index
.
remove
(
index
)
;
self
.
values
.
remove
(
key
)
}
fn
remove_set
<
S
>
(
&
mut
self
set
:
&
:
:
hash
:
:
HashSet
<
K
S
>
)
where
S
:
:
:
std
:
:
hash
:
:
BuildHasher
{
if
set
.
is_empty
(
)
{
return
;
}
self
.
index
.
retain
(
|
key
|
!
set
.
contains
(
key
)
)
;
self
.
values
.
retain
(
|
key
_
|
!
set
.
contains
(
key
)
)
;
debug_assert_eq
!
(
self
.
values
.
len
(
)
self
.
index
.
len
(
)
)
;
}
}
pub
struct
OrderedMapIterator
<
'
a
K
V
>
where
K
:
'
a
+
Eq
+
PrecomputedHash
+
Hash
+
Clone
V
:
'
a
{
inner
:
&
'
a
OrderedMap
<
K
V
>
pos
:
usize
}
impl
<
'
a
K
V
>
Iterator
for
OrderedMapIterator
<
'
a
K
V
>
where
K
:
Eq
+
PrecomputedHash
+
Hash
+
Clone
{
type
Item
=
(
&
'
a
K
&
'
a
V
)
;
fn
next
(
&
mut
self
)
-
>
Option
<
Self
:
:
Item
>
{
let
key
=
self
.
inner
.
index
.
get
(
self
.
pos
)
?
;
self
.
pos
+
=
1
;
let
value
=
&
self
.
inner
.
values
[
key
]
;
Some
(
(
key
value
)
)
}
}
impl
VariableValue
{
fn
empty
(
)
-
>
Self
{
Self
{
css
:
String
:
:
new
(
)
last_token_type
:
TokenSerializationType
:
:
nothing
(
)
first_token_type
:
TokenSerializationType
:
:
nothing
(
)
references
:
PrecomputedHashSet
:
:
default
(
)
}
}
fn
push
(
&
mut
self
css
:
&
str
css_first_token_type
:
TokenSerializationType
css_last_token_type
:
TokenSerializationType
)
{
if
css
.
is_empty
(
)
{
return
}
self
.
first_token_type
.
set_if_nothing
(
css_first_token_type
)
;
if
self
.
last_token_type
.
needs_separator_when_before
(
css_first_token_type
)
{
self
.
css
.
push_str
(
"
/
*
*
/
"
)
}
self
.
css
.
push_str
(
css
)
;
self
.
last_token_type
=
css_last_token_type
}
fn
push_from
(
&
mut
self
position
:
(
SourcePosition
TokenSerializationType
)
input
:
&
Parser
last_token_type
:
TokenSerializationType
)
{
self
.
push
(
input
.
slice_from
(
position
.
0
)
position
.
1
last_token_type
)
}
fn
push_variable
(
&
mut
self
variable
:
&
ComputedValue
)
{
debug_assert
!
(
variable
.
references
.
is_empty
(
)
)
;
self
.
push
(
&
variable
.
css
variable
.
first_token_type
variable
.
last_token_type
)
}
pub
fn
parse
<
'
i
'
t
>
(
input
:
&
mut
Parser
<
'
i
'
t
>
)
-
>
Result
<
Arc
<
Self
>
ParseError
<
'
i
>
>
{
let
mut
references
=
PrecomputedHashSet
:
:
default
(
)
;
let
(
first_token_type
css
last_token_type
)
=
parse_self_contained_declaration_value
(
input
Some
(
&
mut
references
)
)
?
;
Ok
(
Arc
:
:
new
(
VariableValue
{
css
:
css
.
into_owned
(
)
first_token_type
last_token_type
references
}
)
)
}
}
pub
fn
parse_non_custom_with_var
<
'
i
'
t
>
(
input
:
&
mut
Parser
<
'
i
'
t
>
)
-
>
Result
<
(
TokenSerializationType
Cow
<
'
i
str
>
)
ParseError
<
'
i
>
>
{
let
(
first_token_type
css
_
)
=
parse_self_contained_declaration_value
(
input
None
)
?
;
Ok
(
(
first_token_type
css
)
)
}
fn
parse_self_contained_declaration_value
<
'
i
'
t
>
(
input
:
&
mut
Parser
<
'
i
'
t
>
references
:
Option
<
&
mut
PrecomputedHashSet
<
Name
>
>
)
-
>
Result
<
(
TokenSerializationType
Cow
<
'
i
str
>
TokenSerializationType
)
ParseError
<
'
i
>
>
{
let
start_position
=
input
.
position
(
)
;
let
mut
missing_closing_characters
=
String
:
:
new
(
)
;
let
(
first
last
)
=
parse_declaration_value
(
input
references
&
mut
missing_closing_characters
)
?
;
let
mut
css
:
Cow
<
str
>
=
input
.
slice_from
(
start_position
)
.
into
(
)
;
if
!
missing_closing_characters
.
is_empty
(
)
{
if
css
.
ends_with
(
"
\
\
"
)
&
&
matches
!
(
missing_closing_characters
.
as_bytes
(
)
[
0
]
b
'
"
'
|
b
'
\
'
'
)
{
css
.
to_mut
(
)
.
pop
(
)
;
}
css
.
to_mut
(
)
.
push_str
(
&
missing_closing_characters
)
;
}
Ok
(
(
first
css
last
)
)
}
fn
parse_declaration_value
<
'
i
'
t
>
(
input
:
&
mut
Parser
<
'
i
'
t
>
references
:
Option
<
&
mut
PrecomputedHashSet
<
Name
>
>
missing_closing_characters
:
&
mut
String
)
-
>
Result
<
(
TokenSerializationType
TokenSerializationType
)
ParseError
<
'
i
>
>
{
input
.
parse_until_before
(
Delimiter
:
:
Bang
|
Delimiter
:
:
Semicolon
|
input
|
{
let
start
=
input
.
state
(
)
;
input
.
next_including_whitespace
(
)
?
;
input
.
reset
(
&
start
)
;
parse_declaration_value_block
(
input
references
missing_closing_characters
)
}
)
}
fn
parse_declaration_value_block
<
'
i
'
t
>
(
input
:
&
mut
Parser
<
'
i
'
t
>
mut
references
:
Option
<
&
mut
PrecomputedHashSet
<
Name
>
>
missing_closing_characters
:
&
mut
String
)
-
>
Result
<
(
TokenSerializationType
TokenSerializationType
)
ParseError
<
'
i
>
>
{
let
mut
token_start
=
input
.
position
(
)
;
let
mut
token
=
match
input
.
next_including_whitespace_and_comments
(
)
{
Ok
(
token
)
=
>
token
.
clone
(
)
Err
(
_
)
=
>
return
Ok
(
(
TokenSerializationType
:
:
nothing
(
)
TokenSerializationType
:
:
nothing
(
)
)
)
}
;
let
first_token_type
=
token
.
serialization_type
(
)
;
loop
{
macro_rules
!
nested
{
(
)
=
>
{
input
.
parse_nested_block
(
|
input
|
{
parse_declaration_value_block
(
input
references
.
as_mut
(
)
.
map
(
|
r
|
&
mut
*
*
r
)
missing_closing_characters
)
}
)
?
}
}
macro_rules
!
check_closed
{
(
closing
:
expr
)
=
>
{
if
!
input
.
slice_from
(
token_start
)
.
ends_with
(
closing
)
{
missing_closing_characters
.
push_str
(
closing
)
}
}
}
let
last_token_type
=
match
token
{
Token
:
:
Comment
(
_
)
=
>
{
let
token_slice
=
input
.
slice_from
(
token_start
)
;
if
!
token_slice
.
ends_with
(
"
*
/
"
)
{
missing_closing_characters
.
push_str
(
if
token_slice
.
ends_with
(
'
*
'
)
{
"
/
"
}
else
{
"
*
/
"
}
)
}
token
.
serialization_type
(
)
}
Token
:
:
BadUrl
(
u
)
=
>
{
return
Err
(
input
.
new_custom_error
(
StyleParseErrorKind
:
:
BadUrlInDeclarationValueBlock
(
u
)
)
)
}
Token
:
:
BadString
(
s
)
=
>
{
return
Err
(
input
.
new_custom_error
(
StyleParseErrorKind
:
:
BadStringInDeclarationValueBlock
(
s
)
)
)
}
Token
:
:
CloseParenthesis
=
>
{
return
Err
(
input
.
new_custom_error
(
StyleParseErrorKind
:
:
UnbalancedCloseParenthesisInDeclarationValueBlock
)
)
}
Token
:
:
CloseSquareBracket
=
>
{
return
Err
(
input
.
new_custom_error
(
StyleParseErrorKind
:
:
UnbalancedCloseSquareBracketInDeclarationValueBlock
)
)
}
Token
:
:
CloseCurlyBracket
=
>
{
return
Err
(
input
.
new_custom_error
(
StyleParseErrorKind
:
:
UnbalancedCloseCurlyBracketInDeclarationValueBlock
)
)
}
Token
:
:
Function
(
ref
name
)
=
>
{
if
name
.
eq_ignore_ascii_case
(
"
var
"
)
{
let
args_start
=
input
.
state
(
)
;
input
.
parse_nested_block
(
|
input
|
{
parse_var_function
(
input
references
.
as_mut
(
)
.
map
(
|
r
|
&
mut
*
*
r
)
)
}
)
?
;
input
.
reset
(
&
args_start
)
;
}
nested
!
(
)
;
check_closed
!
(
"
)
"
)
;
Token
:
:
CloseParenthesis
.
serialization_type
(
)
}
Token
:
:
ParenthesisBlock
=
>
{
nested
!
(
)
;
check_closed
!
(
"
)
"
)
;
Token
:
:
CloseParenthesis
.
serialization_type
(
)
}
Token
:
:
CurlyBracketBlock
=
>
{
nested
!
(
)
;
check_closed
!
(
"
}
"
)
;
Token
:
:
CloseCurlyBracket
.
serialization_type
(
)
}
Token
:
:
SquareBracketBlock
=
>
{
nested
!
(
)
;
check_closed
!
(
"
]
"
)
;
Token
:
:
CloseSquareBracket
.
serialization_type
(
)
}
Token
:
:
QuotedString
(
_
)
=
>
{
let
token_slice
=
input
.
slice_from
(
token_start
)
;
let
quote
=
&
token_slice
[
.
.
1
]
;
debug_assert
!
(
matches
!
(
quote
"
\
"
"
|
"
'
"
)
)
;
if
!
(
token_slice
.
ends_with
(
quote
)
&
&
token_slice
.
len
(
)
>
1
)
{
missing_closing_characters
.
push_str
(
quote
)
}
token
.
serialization_type
(
)
}
Token
:
:
Ident
(
ref
value
)
|
Token
:
:
AtKeyword
(
ref
value
)
|
Token
:
:
Hash
(
ref
value
)
|
Token
:
:
IDHash
(
ref
value
)
|
Token
:
:
UnquotedUrl
(
ref
value
)
|
Token
:
:
Dimension
{
unit
:
ref
value
.
.
}
=
>
{
if
value
.
ends_with
(
"
"
)
&
&
input
.
slice_from
(
token_start
)
.
ends_with
(
"
\
\
"
)
{
missing_closing_characters
.
push_str
(
"
"
)
}
if
matches
!
(
token
Token
:
:
UnquotedUrl
(
_
)
)
{
check_closed
!
(
"
)
"
)
;
}
token
.
serialization_type
(
)
}
_
=
>
{
token
.
serialization_type
(
)
}
}
;
token_start
=
input
.
position
(
)
;
token
=
match
input
.
next_including_whitespace_and_comments
(
)
{
Ok
(
token
)
=
>
token
.
clone
(
)
Err
(
.
.
)
=
>
return
Ok
(
(
first_token_type
last_token_type
)
)
}
;
}
}
fn
parse_var_function
<
'
i
'
t
>
(
input
:
&
mut
Parser
<
'
i
'
t
>
references
:
Option
<
&
mut
PrecomputedHashSet
<
Name
>
>
)
-
>
Result
<
(
)
ParseError
<
'
i
>
>
{
let
name
=
input
.
expect_ident_cloned
(
)
?
;
let
name
:
Result
<
_
ParseError
>
=
parse_name
(
&
name
)
.
map_err
(
|
(
)
|
input
.
new_custom_error
(
SelectorParseErrorKind
:
:
UnexpectedIdent
(
name
.
clone
(
)
)
)
)
;
let
name
=
name
?
;
if
input
.
try
(
|
input
|
input
.
expect_comma
(
)
)
.
is_ok
(
)
{
input
.
parse_until_before
(
Delimiter
:
:
Bang
|
Delimiter
:
:
Semicolon
|
input
|
{
input
.
next_including_whitespace
(
)
?
;
while
let
Ok
(
_
)
=
input
.
next_including_whitespace_and_comments
(
)
{
}
Ok
(
(
)
)
}
)
?
;
}
if
let
Some
(
refs
)
=
references
{
refs
.
insert
(
Atom
:
:
from
(
name
)
)
;
}
Ok
(
(
)
)
}
pub
struct
CustomPropertiesBuilder
<
'
a
>
{
seen
:
PrecomputedHashSet
<
&
'
a
Name
>
may_have_cycles
:
bool
custom_properties
:
Option
<
CustomPropertiesMap
>
inherited
:
Option
<
&
'
a
Arc
<
CustomPropertiesMap
>
>
}
impl
<
'
a
>
CustomPropertiesBuilder
<
'
a
>
{
pub
fn
new
(
inherited
:
Option
<
&
'
a
Arc
<
CustomPropertiesMap
>
>
)
-
>
Self
{
Self
{
seen
:
PrecomputedHashSet
:
:
default
(
)
may_have_cycles
:
false
custom_properties
:
None
inherited
}
}
pub
fn
cascade
(
&
mut
self
name
:
&
'
a
Name
specified_value
:
DeclaredValue
<
'
a
Arc
<
SpecifiedValue
>
>
)
{
let
was_already_present
=
!
self
.
seen
.
insert
(
name
)
;
if
was_already_present
{
return
;
}
if
!
self
.
value_may_affect_style
(
name
&
specified_value
)
{
return
;
}
if
self
.
custom_properties
.
is_none
(
)
{
self
.
custom_properties
=
Some
(
match
self
.
inherited
{
Some
(
inherited
)
=
>
(
*
*
inherited
)
.
clone
(
)
None
=
>
CustomPropertiesMap
:
:
new
(
)
}
)
;
}
let
map
=
self
.
custom_properties
.
as_mut
(
)
.
unwrap
(
)
;
match
specified_value
{
DeclaredValue
:
:
Value
(
ref
specified_value
)
=
>
{
self
.
may_have_cycles
|
=
!
specified_value
.
references
.
is_empty
(
)
;
map
.
insert
(
name
.
clone
(
)
(
*
specified_value
)
.
clone
(
)
)
;
}
DeclaredValue
:
:
WithVariables
(
_
)
=
>
unreachable
!
(
)
DeclaredValue
:
:
CSSWideKeyword
(
keyword
)
=
>
match
keyword
{
CSSWideKeyword
:
:
Initial
=
>
{
map
.
remove
(
name
)
;
}
CSSWideKeyword
:
:
Unset
|
CSSWideKeyword
:
:
Inherit
=
>
unreachable
!
(
)
}
}
}
fn
value_may_affect_style
(
&
self
name
:
&
Name
value
:
&
DeclaredValue
<
Arc
<
SpecifiedValue
>
>
)
-
>
bool
{
match
*
value
{
DeclaredValue
:
:
CSSWideKeyword
(
CSSWideKeyword
:
:
Unset
)
|
DeclaredValue
:
:
CSSWideKeyword
(
CSSWideKeyword
:
:
Inherit
)
=
>
{
return
false
;
}
_
=
>
{
}
}
let
existing_value
=
self
.
custom_properties
.
as_ref
(
)
.
and_then
(
|
m
|
m
.
get
(
name
)
)
.
or_else
(
|
|
self
.
inherited
.
and_then
(
|
m
|
m
.
get
(
name
)
)
)
;
match
(
existing_value
value
)
{
(
None
&
DeclaredValue
:
:
CSSWideKeyword
(
CSSWideKeyword
:
:
Initial
)
)
=
>
{
return
false
;
}
(
Some
(
existing_value
)
&
DeclaredValue
:
:
Value
(
specified_value
)
)
=
>
{
if
existing_value
=
=
specified_value
{
return
false
;
}
}
_
=
>
{
}
}
true
}
pub
fn
build
(
mut
self
)
-
>
Option
<
Arc
<
CustomPropertiesMap
>
>
{
let
mut
map
=
match
self
.
custom_properties
.
take
(
)
{
Some
(
m
)
=
>
m
None
=
>
return
self
.
inherited
.
cloned
(
)
}
;
if
self
.
may_have_cycles
{
substitute_all
(
&
mut
map
)
;
}
Some
(
Arc
:
:
new
(
map
)
)
}
}
fn
substitute_all
(
custom_properties_map
:
&
mut
CustomPropertiesMap
)
{
struct
VarInfo
{
name
:
Option
<
Name
>
lowlink
:
usize
}
struct
Context
<
'
a
>
{
count
:
usize
index_map
:
PrecomputedHashMap
<
Name
usize
>
var_info
:
SmallVec
<
[
VarInfo
;
5
]
>
stack
:
SmallVec
<
[
usize
;
5
]
>
map
:
&
'
a
mut
CustomPropertiesMap
invalid
:
&
'
a
mut
PrecomputedHashSet
<
Name
>
}
fn
traverse
<
'
a
>
(
name
:
Name
context
:
&
mut
Context
<
'
a
>
)
-
>
Option
<
usize
>
{
let
(
name
value
)
=
if
let
Some
(
value
)
=
context
.
map
.
get
(
&
name
)
{
if
value
.
references
.
is_empty
(
)
|
|
context
.
invalid
.
contains
(
&
name
)
{
return
None
;
}
let
key
;
match
context
.
index_map
.
entry
(
name
)
{
Entry
:
:
Occupied
(
entry
)
=
>
{
return
Some
(
*
entry
.
get
(
)
)
;
}
Entry
:
:
Vacant
(
entry
)
=
>
{
key
=
entry
.
key
(
)
.
clone
(
)
;
entry
.
insert
(
context
.
count
)
;
}
}
(
key
value
.
clone
(
)
)
}
else
{
return
None
;
}
;
let
index
=
context
.
count
;
context
.
count
+
=
1
;
debug_assert_eq
!
(
index
context
.
var_info
.
len
(
)
)
;
context
.
var_info
.
push
(
VarInfo
{
name
:
Some
(
name
)
lowlink
:
index
}
)
;
context
.
stack
.
push
(
index
)
;
let
mut
self_ref
=
false
;
let
mut
lowlink
=
index
;
for
next
in
value
.
references
.
iter
(
)
{
let
next_index
=
match
traverse
(
next
.
clone
(
)
context
)
{
Some
(
index
)
=
>
index
None
=
>
{
continue
;
}
}
;
let
next_info
=
&
context
.
var_info
[
next_index
]
;
if
next_index
>
index
{
lowlink
=
cmp
:
:
min
(
lowlink
next_info
.
lowlink
)
;
}
else
if
next_index
=
=
index
{
self_ref
=
true
;
}
else
if
next_info
.
name
.
is_some
(
)
{
lowlink
=
cmp
:
:
min
(
lowlink
next_index
)
;
}
}
context
.
var_info
[
index
]
.
lowlink
=
lowlink
;
if
lowlink
!
=
index
{
return
Some
(
index
)
;
}
let
mut
in_loop
=
self_ref
;
let
name
;
loop
{
let
var_index
=
context
.
stack
.
pop
(
)
.
expect
(
"
The
current
variable
should
still
be
in
stack
"
)
;
let
var_info
=
&
mut
context
.
var_info
[
var_index
]
;
let
var_name
=
var_info
.
name
.
take
(
)
.
expect
(
"
Variable
should
not
be
poped
from
stack
twice
"
)
;
if
var_index
=
=
index
{
name
=
var_name
;
break
;
}
context
.
invalid
.
insert
(
var_name
)
;
in_loop
=
true
;
}
if
in_loop
{
context
.
invalid
.
insert
(
name
)
;
return
None
;
}
let
mut
computed_value
=
ComputedValue
:
:
empty
(
)
;
let
mut
input
=
ParserInput
:
:
new
(
&
value
.
css
)
;
let
mut
input
=
Parser
:
:
new
(
&
mut
input
)
;
let
mut
position
=
(
input
.
position
(
)
value
.
first_token_type
)
;
let
result
=
substitute_block
(
&
mut
input
&
mut
position
&
mut
computed_value
&
mut
|
name
partial_computed_value
|
{
if
let
Some
(
value
)
=
context
.
map
.
get
(
name
)
{
if
!
context
.
invalid
.
contains
(
name
)
{
partial_computed_value
.
push_variable
(
value
)
;
return
Ok
(
value
.
last_token_type
)
;
}
}
Err
(
(
)
)
}
)
;
if
let
Ok
(
last_token_type
)
=
result
{
computed_value
.
push_from
(
position
&
input
last_token_type
)
;
context
.
map
.
insert
(
name
Arc
:
:
new
(
computed_value
)
)
;
}
else
{
context
.
invalid
.
insert
(
name
)
;
}
None
}
let
names
=
custom_properties_map
.
index
.
clone
(
)
;
let
mut
invalid
=
PrecomputedHashSet
:
:
default
(
)
;
for
name
in
names
.
into_iter
(
)
{
let
mut
context
=
Context
{
count
:
0
index_map
:
PrecomputedHashMap
:
:
default
(
)
stack
:
SmallVec
:
:
new
(
)
var_info
:
SmallVec
:
:
new
(
)
map
:
custom_properties_map
invalid
:
&
mut
invalid
}
;
traverse
(
name
&
mut
context
)
;
}
custom_properties_map
.
remove_set
(
&
invalid
)
;
}
fn
substitute_block
<
'
i
'
t
F
>
(
input
:
&
mut
Parser
<
'
i
'
t
>
position
:
&
mut
(
SourcePosition
TokenSerializationType
)
partial_computed_value
:
&
mut
ComputedValue
substitute_one
:
&
mut
F
)
-
>
Result
<
TokenSerializationType
ParseError
<
'
i
>
>
where
F
:
FnMut
(
&
Name
&
mut
ComputedValue
)
-
>
Result
<
TokenSerializationType
(
)
>
{
let
mut
last_token_type
=
TokenSerializationType
:
:
nothing
(
)
;
let
mut
set_position_at_next_iteration
=
false
;
loop
{
let
before_this_token
=
input
.
position
(
)
;
let
next
=
input
.
next_including_whitespace_and_comments
(
)
.
map
(
|
t
|
t
.
clone
(
)
)
;
if
set_position_at_next_iteration
{
*
position
=
(
before_this_token
match
next
{
Ok
(
ref
token
)
=
>
token
.
serialization_type
(
)
Err
(
_
)
=
>
TokenSerializationType
:
:
nothing
(
)
}
)
;
set_position_at_next_iteration
=
false
;
}
let
token
=
match
next
{
Ok
(
token
)
=
>
token
Err
(
.
.
)
=
>
break
}
;
match
token
{
Token
:
:
Function
(
ref
name
)
if
name
.
eq_ignore_ascii_case
(
"
var
"
)
=
>
{
partial_computed_value
.
push
(
input
.
slice
(
position
.
0
.
.
before_this_token
)
position
.
1
last_token_type
)
;
input
.
parse_nested_block
(
|
input
|
{
let
name
=
input
.
expect_ident_cloned
(
)
.
unwrap
(
)
;
let
name
=
Atom
:
:
from
(
parse_name
(
&
name
)
.
unwrap
(
)
)
;
if
let
Ok
(
last
)
=
substitute_one
(
&
name
partial_computed_value
)
{
last_token_type
=
last
;
while
let
Ok
(
_
)
=
input
.
next
(
)
{
}
}
else
{
input
.
expect_comma
(
)
?
;
let
after_comma
=
input
.
state
(
)
;
let
first_token_type
=
input
.
next_including_whitespace_and_comments
(
)
.
unwrap
(
)
.
serialization_type
(
)
;
input
.
reset
(
&
after_comma
)
;
let
mut
position
=
(
after_comma
.
position
(
)
first_token_type
)
;
last_token_type
=
substitute_block
(
input
&
mut
position
partial_computed_value
substitute_one
)
?
;
partial_computed_value
.
push_from
(
position
input
last_token_type
)
;
}
Ok
(
(
)
)
}
)
?
;
set_position_at_next_iteration
=
true
}
Token
:
:
Function
(
_
)
|
Token
:
:
ParenthesisBlock
|
Token
:
:
CurlyBracketBlock
|
Token
:
:
SquareBracketBlock
=
>
{
input
.
parse_nested_block
(
|
input
|
{
substitute_block
(
input
position
partial_computed_value
substitute_one
)
}
)
?
;
last_token_type
=
Token
:
:
CloseParenthesis
.
serialization_type
(
)
;
}
_
=
>
last_token_type
=
token
.
serialization_type
(
)
}
}
Ok
(
last_token_type
)
}
pub
fn
substitute
<
'
i
>
(
input
:
&
'
i
str
first_token_type
:
TokenSerializationType
computed_values_map
:
Option
<
&
Arc
<
CustomPropertiesMap
>
>
)
-
>
Result
<
String
ParseError
<
'
i
>
>
{
let
mut
substituted
=
ComputedValue
:
:
empty
(
)
;
let
mut
input
=
ParserInput
:
:
new
(
input
)
;
let
mut
input
=
Parser
:
:
new
(
&
mut
input
)
;
let
mut
position
=
(
input
.
position
(
)
first_token_type
)
;
let
last_token_type
=
substitute_block
(
&
mut
input
&
mut
position
&
mut
substituted
&
mut
|
name
substituted
|
{
if
let
Some
(
value
)
=
computed_values_map
.
and_then
(
|
map
|
map
.
get
(
name
)
)
{
substituted
.
push_variable
(
value
)
;
Ok
(
value
.
last_token_type
)
}
else
{
Err
(
(
)
)
}
}
)
?
;
substituted
.
push_from
(
position
&
input
last_token_type
)
;
Ok
(
substituted
.
css
)
}
